<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>1645</ISSUENO>
  <ISSUEURL>https://github.com/seaweedfs/seaweedfs/issues/1645</ISSUEURL>
  <TITLE>Very slow read speeds when running impala queries against seaweedfs</TITLE>
  <DESCRIPTION>**Describe the bug** Very slow read speeds when running a query against seaweed files via impala **System Setup** - List the command line to start &quot;weed master&quot;, &quot;weed volume&quot;, &quot;weed filer&quot;, &quot;weed s3&quot;, &quot;weed mount&quot;. ``` weed -logdir /var/log/seaweedfs/filer filer -ip 127.0.0.1 -port 8888 -master 10.0.0.1:9333 -collection COL1 -maxMB 128 -defaultReplicaPlacement 001 weed -logdir /var/log/seaweedfs/master master -defaultReplication 001 -ip 10.0.0.1 -port 9333 -peers 10.0.0.1:9333 -mdir /var/lib/seaweedfs/master -volumeSizeLimitMB 64000 -volumePreallocate weed -logdir /var/log/seaweedfs/volume volume -max=2 -dataCenter DC1 -rack rack1 -dir=/data/d2/seaweedfs -mserver 10.0.0.1:9333 -port 5200 ``` - OS version `Ubuntu 16.04.6 LTS` - output of `weed version` `version 8000GB 2.13 0e99531 linux amd64` - seaweed hadoop client `seaweedfs-hadoop2-client-1.5.6.jar` - seaweed hadoop client properties ``` &lt;property&gt; &lt;name&gt;fs.seaweedfs.impl&lt;/name&gt; &lt;value&gt;seaweed.hdfs.SeaweedFileSystem&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.AbstractFileSystem.seaweedfs.impl&lt;/name&gt; &lt;value&gt;seaweed.hdfs.SeaweedAbstractFileSystem&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.seaweed.buffer.size&lt;/name&gt; &lt;value&gt;134217728&lt;/value&gt; &lt;/property&gt; ``` - if using filer, show the content of `filer.toml` ``` # A sample TOML config file for SeaweedFS filer store # Used with &quot;weed filer&quot; or &quot;weed server -filer&quot; # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml #################################################### # Customizable filer server options #################################################### [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to &quot;rm -Rf&quot; recursive_delete = false # directories under this folder will be automatically creating a separate bucket buckets_folder = &quot;/buckets&quot; buckets_fsync = [ # a list of buckets with all write requests fsync=true &quot;important_bucket&quot;, &quot;should_always_fsync&quot;, ] #################################################### # The following are filer store options #################################################### [redis2] enabled = true address = &quot;10.0.0.1:6390&quot; password = &quot;SOMEPASSWORD&quot; database = 0 ``` **Additional context** When running a query via impala, the query evetually completes but takes an extremely long time compared to a query ran against data that exists on hdfs. Im seeing the following error on the impala daemons: `readDirect: FSDataInputStream#read error: UnsupportedOperationException: Byte-buffer read unsupported by input streamjava.lang.UnsupportedOperationException: Byte-buffer read unsupported by input stream` This error scrolls over and over until the query completes. Im able to cat out files, read and write files fine via hdfs but when queries are ran against the data it takes an extremely long time to complete.</DESCRIPTION>
  <REPONAME>seaweedfs</REPONAME>
  <TIMEDIFFERENCEDAYS>0</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>fix nil</MESSAGE>
    <SHA>003b6245e701bfb6b7f118552a2b4e82d1d7de67</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>Hadoop: switch to ByteBuffer fix https://github.com/chrislusf/seaweedfs/issues/1645</MESSAGE>
      <SHA>3857f9c8404c6f251135268e42c79bb83c13b2b0</SHA>
      <PATCHEDFILES>
        <FILE>other/java/client/pom_debug.xml</FILE>
        <FILE>other/java/client/src/main/java/seaweedfs/client/SeaweedRead.java</FILE>
        <FILE>other/java/hdfs2/src/main/java/seaweed/hdfs/SeaweedInputStream.java</FILE>
        <FILE>other/java/hdfs3/src/main/java/seaweed/hdfs/SeaweedFileSystemStore.java</FILE>
        <FILE>other/java/hdfs3/src/main/java/seaweed/hdfs/SeaweedInputStream.java</FILE>
      </PATCHEDFILES>
    </COMMIT>
    <COMMIT>
      <MESSAGE>Hadoop: add BufferedByteBufferReadableInputStream fix https://github.com/chrislusf/seaweedfs/issues/1645</MESSAGE>
      <SHA>4d2855476c35a2762a225c6707731067e84c71bc</SHA>
      <PATCHEDFILES>
        <FILE>other/java/hdfs2/src/main/java/seaweed/hdfs/BufferedByteBufferReadableInputStream.java</FILE>
        <FILE>other/java/hdfs2/src/main/java/seaweed/hdfs/SeaweedFileSystem.java</FILE>
        <FILE>other/java/hdfs3/src/main/java/seaweed/hdfs/BufferedByteBufferReadableInputStream.java</FILE>
        <FILE>other/java/hdfs3/src/main/java/seaweed/hdfs/SeaweedFileSystem.java</FILE>
        <FILE>other/java/hdfs3/src/main/java/seaweed/hdfs/SeaweedInputStream.java</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
