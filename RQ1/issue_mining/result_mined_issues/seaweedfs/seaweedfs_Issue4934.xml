<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>4934</ISSUENO>
  <ISSUEURL>https://github.com/seaweedfs/seaweedfs/issues/4934</ISSUEURL>
  <TITLE>volume.configure.replication seems to not work</TITLE>
  <DESCRIPTION>**Describe the bug** When using volume.configure.replication, the actual volume files still retain their old configuration. **Test case** Start a weed master (defaultReplication=020) and 3 volume servers: ``` weed master -defaultReplication=020 weed volume -port=8081 -dir=/tmp/volume1 -max=100 -mserver=&quot;127.0.0.1:9333&quot; -dataCenter=dc1 -rack=rack1 weed volume -port=8082 -dir=/tmp/volume2 -max=100 -mserver=&quot;127.0.0.1:9333&quot; -dataCenter=dc1 -rack=rack2 weed volume -port=8083 -dir=/tmp/volume3 -max=100 -mserver=&quot;127.0.0.1:9333&quot; -dataCenter=dc1 -rack=rack3 ``` Create some volumes: ``` curl http://localhost:9333/dir/assign ``` It should look like this: ![Screenshot from 2023-10-23 16-49-42](https://github.com/seaweedfs/seaweedfs/assets/7746192/e9eea85c-6f77-4d12-9b48-740d0cd94c59) Now, let's change the replication settings using weed shell: ``` weed shell volume.configure.replication -collectionPattern * -replication 010 ``` The volume servers correctly show the change in the logs: ``` I1023 14:52:01.272205 disk_location.go:182 data file /tmp/volume2/1.dat, replication=010 v=3 size=8 ttl= ``` The API also thinks, it is changed: ``` $ curl http://localhost:9333/vol/status?pretty=y|grep &quot;ReplicaPlacement&quot; -A 2 &quot;ReplicaPlacement&quot;: { &quot;rack&quot;: 1 }, ``` But when we look at the .dat files using `change_superblock.go`, we see that it is still 020: ``` $ go run change_superblock.go -volumeId=1 -dir=/tmp/volume1 Current Volume Replication: 020 Current Volume TTL: ``` Just to make sure, we run some tests. First, we fix the replication: ``` $ weed shell lock volume.fix.replication &gt; volume 2 replication 010, but over replicated +3 &gt; volume 3 replication 010, but over replicated +3 &gt; volume 1 replication 010, but over replicated +3 &gt; deleting volume 2 from 10.23.1.43:8083 ... &gt; deleting volume 3 from 10.23.1.43:8083 ... &gt; deleting volume 1 from 10.23.1.43:8083 ... ``` Looks good. We now have 2 copies of every volume file: ![Screenshot from 2023-10-23 16-58-31](https://github.com/seaweedfs/seaweedfs/assets/7746192/58ec1a28-2cde-4d3d-a590-127338fcd9ca) If we delete one and fix replication again, it should add it back. ``` weed shell lock volume.delete -node 10.23.1.43:8081 -volumeId 1 volume.fix.replication &gt; the number of locations for volume 1 has not increased yet, let's wait &gt; the number of locations for volume 1 has not increased yet, let's wait &gt; the number of locations for volume 1 has not increased yet, let's wait &gt; the number of locations for volume 1 has not increased yet, let's wait &gt; the number of locations for volume 1 has not increased yet, let's wait &gt; error: replicas volume 1 mismatch in topology ``` It did restore the missing copy but showed the error `error: replicas volume 1 mismatch in topology`. The volume server log shows that it added the volume with replication 020: ``` I1023 15:03:29.264620 disk_location.go:182 data file /tmp/volume3/1.dat, replication=020 v=3 size=8 ttl= ``` If we query the API, it now also shows replication 020 for the restored copy: ``` curl http://localhost:9333/vol/status?pretty=y|grep &quot;ReplicaPlacement&quot; -A 2 &quot;ReplicaPlacement&quot;: { &quot;rack&quot;: 1 }, &quot;ReplicaPlacement&quot;: { &quot;rack&quot;: 2 }, ``` **System Setup** - Ubuntu 22.04 - output of `weed version`: version 30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559 linux amd64 **Expected behavior** `volume.configure.replication` changes the replication setting in the volume files.</DESCRIPTION>
  <REPONAME>seaweedfs</REPONAME>
  <TIMEDIFFERENCEDAYS>1</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>Remove hardcoded podManagmentPolicy value in a helm chart (#4941)</MESSAGE>
    <SHA>8dfb66880e0982f46f237db32ff6df2adcd38268</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>fix copying .vif file in VolumeCopy closes #4934 fixes #2633 might fix #3528</MESSAGE>
      <SHA>ef5503198a47f2ec7564da50aa76570048f0b6fa</SHA>
      <PATCHEDFILES>
        <FILE>weed/server/volume_grpc_copy.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
    <COMMIT>
      <MESSAGE>fix copying .vif file in VolumeCopy (#4943) closes #4934 fixes #2633 might fix #3528</MESSAGE>
      <SHA>8b39bbbe2fa34704ad46cb717471220e8002c360</SHA>
      <PATCHEDFILES>
        <FILE>weed/server/volume_grpc_copy.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
    <COMMIT>
      <MESSAGE>fix copying .vif file in VolumeCopy (#4943) closes #4934 fixes #2633 might fix #3528</MESSAGE>
      <SHA>9f8e1f44506a188998483a51bee002b5782318c1</SHA>
      <PATCHEDFILES>
        <FILE>weed/server/volume_grpc_copy.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
