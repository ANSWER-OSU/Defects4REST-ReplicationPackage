<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>59</ISSUENO>
  <ISSUEURL>https://github.com/NatLibFi/Annif/issues/59</ISSUEURL>
  <TITLE>Filter words / tokens</TITLE>
  <DESCRIPTION>Analyzers should support a method for filtering words. The basic rules should be: * words should have a minimum length (3 is OK as a starting value) * the word should have at least one letter character, based on Unicode character properties</DESCRIPTION>
  <REPONAME>Annif</REPONAME>
  <TIMEDIFFERENCEDAYS>1</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>Combine Snowball analyzers into one parametrized analyzer. Fixes #53</MESSAGE>
    <SHA>d2c4df8c1e2e326e033f19346efd592481c7f166</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>Filter and normalize words when tokenizing. Fixes #59</MESSAGE>
      <SHA>f379ee867a87043418ace8cca839d8136d31b799</SHA>
      <PATCHEDFILES>
        <FILE>annif/analyzer/analyzer.py</FILE>
        <FILE>annif/analyzer/snowball.py</FILE>
        <FILE>tests/test_analyzer.py</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
