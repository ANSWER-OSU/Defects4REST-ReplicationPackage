<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>20903</ISSUENO>
  <ISSUEURL>https://github.com/containers/podman/issues/20903</ISSUEURL>
  <TITLE>restartpolicy not working for pod livenessprobe</TITLE>
  <DESCRIPTION>### Issue Description When running podman on 4.8 and using a liveness probe to check the health of my pod/container and have spec.restartPolicy set to always. The container in my pod is marked as unhealthy but not restarted ### Steps to reproduce the issue Add the files in the attachment to your setup and run podman kube play ./&lt;path to file&gt;.yml `apiVersion: v1 kind: Pod metadata: name: ubi8-httpd-24 spec: restartPolicy: Always containers: - name: ubi8-httpd-24 image: registry.access.redhat.com/rhscl/httpd-24-rhel7:2.4-217 ports: - containerPort: 8081 hostPort: 8081 livenessProbe: httpGet: path: / port: 8081 failureThreshold: 3 ` You will see with podman ps that the container is marked unhealthy but is not restarted ### Describe the results you received I the container is up and running, but is marked unhealthy `[azureuser@test-fedora ~]$ podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 98511a5f285b localhost/podman-pause:4.8.0-1701165512 6 minutes ago Up 6 minutes 0.0.0.0:8081-&gt;8081/tcp 0aaf96d1316b-infra 1f3929259ec4 registry.access.redhat.com/rhscl/httpd-24-rhel7:2.4-217 /usr/bin/run-http... 6 minutes ago Up 6 minutes (unhealthy) 0.0.0.0:8081-&gt;8081/tcp ubi8-httpd-24-ubi8-httpd-24 ` ### Describe the results you expected I would have expected to see that the container is continously restarted based on the settting restartPolicy: always ### podman info output ```yaml host: arch: amd64 buildahVersion: 1.33.2 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.8-2.fc39.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.8, commit: ' cpuUtilization: idlePercent: 87.94 systemPercent: 2.4 userPercent: 9.66 cpus: 2 databaseBackend: sqlite distribution: distribution: fedora variant: server version: &quot;39&quot; eventLogger: journald freeLocks: 2045 hostname: test-fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 kernel: 6.5.7-300.fc39.x86_64 linkmode: dynamic logDriver: journald memFree: 6446141440 memTotal: 8312799232 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.8.0-1.fc39.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.8.0 package: netavark-1.8.0-2.fc39.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.8.0 ociRuntime: name: crun package: crun-1.12-1.fc39.x86_64 path: /usr/bin/crun version: |- crun version 1.12 commit: ce429cb2e277d001c2179df1ac66a470f00802ae rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20231119.g4f1709d-1.fc39.x86_64 version: | pasta 0^20231119.g4f1709d-1.fc39.x86_64 Copyright Red Hat GNU General Public License, version 2 or later &lt;https://www.gnu.org/licenses/old-licenses/gpl-2.0.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: false path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc39.x86_64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 0h 12m 36.00s variant: &quot;&quot; plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /home/azureuser/.config/containers/storage.conf containerStore: number: 2 paused: 0 running: 2 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/azureuser/.local/share/containers/storage graphRootAllocated: 19965583360 graphRootUsed: 2512203776 graphStatus: Backing Filesystem: extfs Native Overlay Diff: &quot;true&quot; Supports d_type: &quot;true&quot; Supports shifting: &quot;false&quot; Supports volatile: &quot;true&quot; Using metacopy: &quot;false&quot; imageCopyTmpDir: /var/tmp imageStore: number: 2 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/azureuser/.local/share/containers/storage/volumes version: APIVersion: 4.8.0 Built: 1701165512 BuiltTime: Tue Nov 28 04:58:32 2023 GitCommit: &quot;&quot; GoVersion: go1.21.4 Os: linux OsArch: linux/amd64 Version: 4.8.0 ``` ### Podman in a container No ### Privileged Or Rootless Rootless ### Upstream Latest Release Yes ### Additional environment details none ### Additional information none</DESCRIPTION>
  <REPONAME>podman</REPONAME>
  <TIMEDIFFERENCEDAYS>100</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>Merge pull request #22416 from openshift-cherrypick-robot/cherry-pick-22253-to-v5.0 [v5.0] [CI:DOCS] Add GitHub action to update version on Podman.io</MESSAGE>
    <SHA>5fc761566b5477bc987977f44913adce3eaa480c</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>Pass the restart policy to the individual containers Healthchecks, defined in a .yaml file as livenessProbe did not had any effect. They were executing as intended, containers were marked as unhealthy, yet no action was taken. This was never the intended behaviour, as observed by the comment: &gt; if restart policy is in place, ensure the health check enforces it A minimal example is tracked in containers/podman#20903 [1] with the following YAML: ```yaml apiVersion: v1 kind: Pod metadata: name: ubi-httpd-24 spec: restartPolicy: Always containers: - name: ubi8-httpd image: registry.access.redhat.com/rhscl/httpd-24-rhel7:2.4-217 livenessProbe: httpGet: path: &quot;/&quot; port: 8081 ``` By passing down the restart policy (and using constants instead of actually wrong hard-coded ones), Podman actually restarts the container now. [1]: https://github.com/containers/podman/issues/20903 Closes #20903. Signed-off-by: Jasmin Oster &lt;nachtjasmin@posteo.de&gt;</MESSAGE>
      <SHA>585d7cd87cd24658c760066f2afb5f58dd9e9afc</SHA>
      <PATCHEDFILES>
        <FILE>pkg/domain/infra/abi/play.go</FILE>
        <FILE>pkg/specgen/generate/kube/kube.go</FILE>
        <FILE>pkg/specgen/generate/kube/play_test.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
