<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>20055</ISSUENO>
  <ISSUEURL>https://github.com/containers/podman/issues/20055</ISSUEURL>
  <TITLE>failed to mmp when use bind mount</TITLE>
  <DESCRIPTION>### Issue Description i just run this commannd in my mac m2, and it issue like: ```bash $ podman run --rm -it -p 9090:9090 -v $(pwd):/prometheus --user 0:0 prom/prometheus:v2.46.0 130 ↵ ts=2023-09-20T08:30:35.316Z caller=main.go:541 level=info msg=&quot;No time or size retention was set so using the default time retention&quot; duration=15d ts=2023-09-20T08:30:35.317Z caller=main.go:585 level=info msg=&quot;Starting Prometheus Server&quot; mode=server version=&quot;(version=2.46.0, branch=HEAD, revision=cbb69e51423565ec40f46e74f4ff2dbb3b7fb4f0)&quot; ts=2023-09-20T08:30:35.317Z caller=main.go:590 level=info build_context=&quot;(go=go1.20.6, platform=linux/arm64, user=root@42454fc0f41e, date=20230725-12:37:33, tags=netgo,builtinassets,stringlabels)&quot; ts=2023-09-20T08:30:35.317Z caller=main.go:591 level=info host_details=&quot;(Linux 6.4.15-200.fc38.aarch64 #1 SMP PREEMPT_DYNAMIC Thu Sep 7 00:51:10 UTC 2023 aarch64 40df65556270 (none))&quot; ts=2023-09-20T08:30:35.318Z caller=main.go:592 level=info fd_limits=&quot;(soft=524288, hard=524288)&quot; ts=2023-09-20T08:30:35.318Z caller=main.go:593 level=info vm_limits=&quot;(soft=unlimited, hard=unlimited)&quot; ts=2023-09-20T08:30:35.332Z caller=query_logger.go:105 level=error component=activeQueryTracker msg=&quot;Failed to mmap&quot; file=/prometheus/queries.active Attemptedsize=20001 err=&quot;invalid argument&quot; panic: Unable to create mmap-ed active query log goroutine 1 [running]: github.com/prometheus/prometheus/promql.NewActiveQueryTracker({0xffffc5171ee6, 0xb}, 0x14, {0x374a840, 0x400004d1d0}) /app/promql/query_logger.go:123 +0x2fc main.main() /app/cmd/prometheus/main.go:647 +0x6710 ``` I have tried this in orbstack docker, it`s ok event i not set the user to root. ### Steps to reproduce the issue just run ` podman run --rm -it -p 9090:9090 -v $(pwd):/prometheus --user 0:0 prom/prometheus:v2.46.0` in termianl. ### Describe the results you received got error like &quot;failed to mmap&quot; ### Describe the results you expected it should be ok like orbstack docker: ```bash $ docker run --rm -it -p 9090:9090 -v $(pwd):/prometheus --user 0:0 prom/prometheus:v2.46.0 130 ↵ ts=2023-09-20T08:35:37.309Z caller=main.go:541 level=info msg=&quot;No time or size retention was set so using the default time retention&quot; duration=15d ts=2023-09-20T08:35:37.309Z caller=main.go:585 level=info msg=&quot;Starting Prometheus Server&quot; mode=server version=&quot;(version=2.46.0, branch=HEAD, revision=cbb69e51423565ec40f46e74f4ff2dbb3b7fb4f0)&quot; ts=2023-09-20T08:35:37.309Z caller=main.go:590 level=info build_context=&quot;(go=go1.20.6, platform=linux/arm64, user=root@42454fc0f41e, date=20230725-12:37:33, tags=netgo,builtinassets,stringlabels)&quot; ts=2023-09-20T08:35:37.309Z caller=main.go:591 level=info host_details=&quot;(Linux 6.4.16-orbstack-00103-g02b40eb69695 #1 SMP Wed Sep 13 10:13:30 UTC 2023 aarch64 bee8a30acd51 (none))&quot; ts=2023-09-20T08:35:37.309Z caller=main.go:592 level=info fd_limits=&quot;(soft=1048576, hard=1048576)&quot; ts=2023-09-20T08:35:37.309Z caller=main.go:593 level=info vm_limits=&quot;(soft=unlimited, hard=unlimited)&quot; ts=2023-09-20T08:35:37.311Z caller=web.go:563 level=info component=web msg=&quot;Start listening for connections&quot; address=0.0.0.0:9090 ts=2023-09-20T08:35:37.311Z caller=main.go:1026 level=info msg=&quot;Starting TSDB ...&quot; ts=2023-09-20T08:35:37.313Z caller=tls_config.go:274 level=info component=web msg=&quot;Listening on&quot; address=[::]:9090 ts=2023-09-20T08:35:37.313Z caller=tls_config.go:277 level=info component=web msg=&quot;TLS is disabled.&quot; http2=false address=[::]:9090 ts=2023-09-20T08:35:37.318Z caller=head.go:595 level=info component=tsdb msg=&quot;Replaying on-disk memory mappable chunks if any&quot; ts=2023-09-20T08:35:37.318Z caller=head.go:676 level=info component=tsdb msg=&quot;On-disk memory mappable chunks replay completed&quot; duration=1.792µs ts=2023-09-20T08:35:37.318Z caller=head.go:684 level=info component=tsdb msg=&quot;Replaying WAL, this may take a while&quot; ts=2023-09-20T08:35:37.319Z caller=head.go:755 level=info component=tsdb msg=&quot;WAL segment loaded&quot; segment=0 maxSegment=0 ts=2023-09-20T08:35:37.319Z caller=head.go:792 level=info component=tsdb msg=&quot;WAL replay completed&quot; checkpoint_replay_duration=423.206µs wal_replay_duration=410.164µs wbl_replay_duration=0s total_replay_duration=864.62µs ts=2023-09-20T08:35:37.321Z caller=main.go:1047 level=info fs_type=65735546 ts=2023-09-20T08:35:37.321Z caller=main.go:1050 level=info msg=&quot;TSDB started&quot; ts=2023-09-20T08:35:37.321Z caller=main.go:1231 level=info msg=&quot;Loading configuration file&quot; filename=/etc/prometheus/prometheus.yml ts=2023-09-20T08:35:37.322Z caller=main.go:1268 level=info msg=&quot;Completed loading of configuration file&quot; filename=/etc/prometheus/prometheus.yml totalDuration=431.206µs db_storage=667ns remote_storage=708ns web_handler=375ns query_engine=541ns scrape=185.707µs scrape_sd=24.791µs notify=23.209µs notify_sd=23.749µs rules=1.125µs tracing=15.625µs ts=2023-09-20T08:35:37.322Z caller=main.go:1011 level=info msg=&quot;Server is ready to receive web requests.&quot; ts=2023-09-20T08:35:37.322Z caller=manager.go:1009 level=info component=&quot;rule manager&quot; msg=&quot;Starting rule manager...&quot; ``` ### podman info output ```yaml $ podman info host: arch: arm64 buildahVersion: 1.31.2 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-2.fc38.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 98.93 systemPercent: 0.52 userPercent: 0.55 cpus: 1 databaseBackend: boltdb distribution: distribution: fedora variant: coreos version: &quot;38&quot; eventLogger: journald freeLocks: 2048 hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 1000000 uidmap: - container_id: 0 host_id: 501 size: 1 - container_id: 1 host_id: 100000 size: 1000000 kernel: 6.4.15-200.fc38.aarch64 linkmode: dynamic logDriver: journald memFree: 1361387520 memTotal: 2048544768 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.7.0-1.fc38.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.7.0 package: netavark-1.7.0-1.fc38.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.7.0 ociRuntime: name: crun package: crun-1.8.7-1.fc38.aarch64 path: /usr/bin/crun version: |- crun version 1.8.7 commit: 53a9996ce82d1ee818349bdcc64797a1fa0433c4 rundir: /run/user/501/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20230823.ga7e4bfb-1.fc38.aarch64 version: | pasta 0^20230823.ga7e4bfb-1.fc38.aarch64 Copyright Red Hat GNU Affero GPL version 3 or later &lt;https://www.gnu.org/licenses/agpl-3.0.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/user/501/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.1-1.fc38.aarch64 version: |- slirp4netns version 1.2.1 commit: 09e31e92fa3d2a1d3ca261adaeb012c8d75a8194 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 0h 32m 19.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /var/home/core/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/core/.local/share/containers/storage graphRootAllocated: 106769133568 graphRootUsed: 2797142016 graphStatus: Backing Filesystem: xfs Native Overlay Diff: &quot;true&quot; Supports d_type: &quot;true&quot; Using metacopy: &quot;false&quot; imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/501/containers transientStore: false volumePath: /var/home/core/.local/share/containers/storage/volumes version: APIVersion: 4.6.2 Built: 1693251554 BuiltTime: Tue Aug 29 03:39:14 2023 GitCommit: &quot;&quot; GoVersion: go1.20.7 Os: linux OsArch: linux/arm64 Version: 4.6.2 ``` ### Podman in a container No ### Privileged Or Rootless None ### Upstream Latest Release Yes ### Additional environment details _No response_ ### Additional information _No response_</DESCRIPTION>
  <REPONAME>podman</REPONAME>
  <TIMEDIFFERENCEDAYS>8</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>Merge pull request #21067 from containers/renovate/go-github.com/containerd/containerd-vulnerability chore(deps): update module github.com/containerd/containerd to v1.7.11 [security]</MESSAGE>
    <SHA>7dc7cbfd9b0440ddc86e210a2272fdaccd6376bb</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>Add mmap cache option to QEMU mount This is required for mmap'ing on mounted files on MacOS Host. Closes #19639, #20055. Signed-off-by: Byoungchan Lee &lt;daniel.l@hpcnt.com&gt;</MESSAGE>
      <SHA>f10a7bfd4cb57c6325992d86d4bf9161d4bb0072</SHA>
      <PATCHEDFILES>
        <FILE>pkg/machine/qemu/machine.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
