<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>18424</ISSUENO>
  <ISSUEURL>https://github.com/containers/podman/issues/18424</ISSUEURL>
  <TITLE>Podman ExecIDs report inaccurate Running state.</TITLE>
  <DESCRIPTION>### Issue Description It seems that podman ExecIDs are persisting and reporting as &quot;running&quot; for ~5 minutes before being removed. I've only tested this using the podman Golang bindings. Here is a demonstration program: https://gist.github.com/AndroidKitKat/2e1233b17316d96173fe1cf9f3e8aa48 ### Steps to reproduce the issue Steps to reproduce the issue 1. Create a new container ``` podman create --name alpine-test --tty alpine:latest ``` 2. Start the container ``` podman start alpine-test ``` 3. Start an exec in the container using the REST API. I did this using the Go program referenced in the GitHub Gist above I compiled it by doing: ``` go mod init inspectbug curl &quot;https://gist.githubusercontent.com/AndroidKitKat/2e1233b17316d96173fe1cf9f3e8aa48/raw/40c2b071a53275d0e270d71aee34051140094e46/main.go&quot; &gt; main.go go get go build ./inspectbug ``` ### Describe the results you received In that file, I have an Exec with the command `sleep 5` and I have a loop running checking the status of the Exec every 1 second. For a duration of 5 seconds (the duration of the sleep command) + 5 minutes, the `inspectResult` struct's `Running` member is `true`, until eventually the program crashes due to no error handling when checking `containers.ExecInspect` because the ExecID seems to no longer exist at all. Here's the output of the program: ``` [developer@guthix inspectbug]$ ./inspectbug 2023/05/02 14:12:21 Exec ID: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:12:21 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 ... 2023/05/02 14:17:23 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:17:24 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:17:25 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x43 pc=0xe79322] ``` ### Describe the results you expected After 5 seconds, the Exec shows as &quot;Not running&quot; due to sleep exiting. ### podman info output ```yaml [developer@guthix inspectbug]$ podman info host: arch: amd64 buildahVersion: 1.27.3 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.4-1.module+el8.7.0+1154+147ffa21.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.4, commit: ddbeffc1e2a247aef04a1be0bc9b1b5ef5f1cd09' cpuUtilization: idlePercent: 99.9 systemPercent: 0.04 userPercent: 0.06 cpus: 8 distribution: distribution: '&quot;rocky&quot;' version: &quot;8.7&quot; eventLogger: file hostname: guthix idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 4.18.0-425.19.2.el8_7.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 27185180672 memTotal: 33146671104 networkBackend: cni ociRuntime: name: runc package: runc-1.1.4-1.module+el8.7.0+1154+147ffa21.x86_64 path: /usr/bin/runc version: |- runc version 1.1.4 spec: 1.0.2-dev go: go1.18.9 libseccomp: 2.5.2 os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-2.module+el8.7.0+1154+147ffa21.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 16741560320 swapTotal: 16741560320 uptime: 100h 45m 33.00s (Approximately 4.17 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.access.redhat.com - registry.redhat.io - docker.io store: configFile: /home/developer/.config/containers/storage.conf containerStore: number: 7 paused: 0 running: 7 stopped: 0 graphDriverName: overlay graphOptions: overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: fuse-overlayfs-1.9-1.module+el8.7.0+1154+147ffa21.x86_64 Version: |- fusermount3 version: 3.3.0 fuse-overlayfs: version 1.9 FUSE library version 3.3.0 using FUSE kernel interface version 7.26 graphRoot: /storage/containers/storage graphRootAllocated: 502921392128 graphRootUsed: 1801228288 graphStatus: Backing Filesystem: extfs Native Overlay Diff: &quot;false&quot; Supports d_type: &quot;true&quot; Using metacopy: &quot;false&quot; imageCopyTmpDir: /var/tmp imageStore: number: 9 runRoot: /run/user/1000 volumePath: /storage/containers/storage/volumes version: APIVersion: 4.2.0 Built: 1677003394 BuiltTime: Tue Feb 21 13:16:34 2023 GitCommit: &quot;&quot; GoVersion: go1.18.9 Os: linux OsArch: linux/amd64 Version: 4.2.0 ``` ### Podman in a container No ### Privileged Or Rootless Rootless ### Upstream Latest Release No ### Additional environment details Running on bare metal on Intel NUCs with 11th gen Intel processors. I am accessing Podman using the golang bindings. ### Additional information I verified that the sleep command exits by looking at the process list of the container.</DESCRIPTION>
  <REPONAME>podman</REPONAME>
  <TIMEDIFFERENCEDAYS>0</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>Merge pull request #18394 from containers/renovate/github.com-godbus-dbus-v5-digest fix(deps): update github.com/godbus/dbus/v5 digest to 6cc540d</MESSAGE>
    <SHA>f149d49335a13f6015fc4eedef14783f39296ffa</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>remote: exec inspect update exec session status The remote API will wait 300s by default before conmon will call the cleanup. In the meantime when you inspect an exec session started with ExecStart() (so not attached) and it did exit we do not know that. If a caller inspects it they think it is still running. To prevent this we should sync the session based on the exec pid and update the state accordingly. For a reproducer see the test in this commit or the issue. Fixes #18424 Signed-off-by: Paul Holzinger &lt;pholzing@redhat.com&gt;</MESSAGE>
      <SHA>19aabf440e4e30662080e52ca1c88c7fd376997d</SHA>
      <PATCHEDFILES>
        <FILE>libpod/container.go</FILE>
        <FILE>pkg/bindings/test/exec_test.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
    <COMMIT>
      <MESSAGE>remote: exec inspect update exec session status The remote API will wait 300s by default before conmon will call the cleanup. In the meantime when you inspect an exec session started with ExecStart() (so not attached) and it did exit we do not know that. If a caller inspects it they think it is still running. To prevent this we should sync the session based on the exec pid and update the state accordingly. For a reproducer see the test in this commit or the issue. Fixes #18424 Signed-off-by: Paul Holzinger &lt;pholzing@redhat.com&gt;</MESSAGE>
      <SHA>66fb7c9bb52ceded75fe2f798dfcd52217ca675a</SHA>
      <PATCHEDFILES>
        <FILE>libpod/container.go</FILE>
        <FILE>pkg/bindings/test/exec_test.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
