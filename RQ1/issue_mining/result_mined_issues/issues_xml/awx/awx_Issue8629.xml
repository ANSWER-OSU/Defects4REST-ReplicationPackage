<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>8629</ISSUENO>
  <ISSUEURL>https://github.com/ansible/awx/issues/8629</ISSUEURL>
  <TITLE>Observability and metrics for AWX Job execution pipeline</TITLE>
  <DESCRIPTION>##### ISSUE TYPE - Feature Idea ##### SUMMARY * How many jobs per minute&lt;or some time unit&gt; is my AWX capable of running? To answer this question you must consider the entire job running pipeline from the API, where jobs are launched or created, to the Task Manager, where jobs are put into waiting, through the Dispatcher, where jobs are put into running &amp; finished, next is the callback receiver where job events from running jobs are saved to the database, websockets where job events are sent to clients in the browser, and even notifications, which run after everything is complete. The runtime of each of these subsystems is needed to answer the seemingly simple question of &quot;How many jobs per second is my AWX capable of running?&quot; ### Define Metrics Concretely, the first step to answering the above question is to first understand the performance of each subsystem. To do so, we must be able to observe those subsystem. We do so through metrics. To start with we should define the sub-systems in the pipeline. Then, discover what metrics tell the story. Defining the metrics that are valuable is the hard part. My thought is that each subsystem is like a queue so information that you might want to know about a queue would be useful i.e. depth, push vs. pop rate, average per-item duration in the queue, max latency of item in the queue. We have successfully defined the metrics that provide value for the callback receiver. | Sub-System | Metrics | | ----------------- | ------------------------------------------------------------ | | API | job launches per time unit | | Task Manager | average time to first process a pending job, number of jobs transitioned from pending -&gt; waiting per time unit (not sure about these) | | Dispatcher | latency from waiting -&gt; running start, average time spent pre-start work, average time spent post-run work | | Callback Receiver | Events per time processed (existing stats) | | Websockets | Similar to the callback receiver + number of messages dropped when overloaded | | Notifications | Maybe this rolls into the dispatcher as post-run work | To be clear, the above metrics are mostly guesses. We do know what metrics are useful for the callback receiver &amp; some of the websockets. I've explored tracing individual job timings as they flow through the task manager and below here https://github.com/ansible/awx/pull/8631 ### Work Items * Save metrics in Redis https://github.com/ansible/awx/issues/9012 * Expose metrics in the API as Prometheus data https://github.com/ansible/awx/issues/9019 * Broadcast metrics to every AWX node https://github.com/ansible/awx/issues/9020 * metrics dashboard https://github.com/ansible/awx/issues/9056 * periodically output metrics to log file https://github.com/ansible/awx/issues/9021 * sosreport-elk reconstruct metrics https://github.com/ansible/awx/issues/9022</DESCRIPTION>
  <REPONAME>awx</REPONAME>
  <TIMEDIFFERENCEDAYS>127</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>Update minikube.md</MESSAGE>
    <SHA>f8a698d12727692eb96b8fc59d4dfa3f13fc86f5</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>Merge pull request #9461 from fosterseth/feat_metrics_via_redis Add subsystem metrics that propagate through Redis SUMMARY #9019 -- list of metrics and their purpose / description #9012 #9056 #8629 Use Redis to store metrics pertaining to the performance and health of subsystems such as the callback receiver and task manager. It is thread / multiprocess safe and should be fast enough to handle a high volume of data. This data shows up at the /api/v2/metrics endpoint You can filter down nodes using /api/v2/metrics/?subsystemonly=1&amp;node=awx-1 You can also filter down to a specific metric, /api/v2/metrics/?subsystemonly=1&amp;metrics=callback_receiver_events_insert_db_seconds&amp;node=awx-1 ISSUE TYPE Feature Pull Request COMPONENT NAME API AWX VERSION awx: 17.0.1 Reviewed-by: Ryan Petrello &lt;None&gt; Reviewed-by: Chris Meyers &lt;None&gt; Reviewed-by: Seth Foster &lt;None&gt; Reviewed-by: Elijah DeLee &lt;kdelee@redhat.com&gt;</MESSAGE>
      <SHA>6087d5cb9cac81fa657ada62f8545dc252f0ae19</SHA>
      <PATCHEDFILES>
        <FILE>awx/api/renderers.py</FILE>
        <FILE>awx/api/templates/api/metrics_view.md</FILE>
        <FILE>awx/api/views/metrics.py</FILE>
        <FILE>awx/main/analytics/analytics_tasks.py</FILE>
        <FILE>awx/main/analytics/subsystem_metrics.py</FILE>
        <FILE>awx/main/consumers.py</FILE>
        <FILE>awx/main/dispatch/worker/callback.py</FILE>
        <FILE>awx/main/queue.py</FILE>
        <FILE>awx/main/tasks.py</FILE>
        <FILE>awx/main/tests/functional/analytics/test_metrics.py</FILE>
        <FILE>awx/main/wsbroadcast.py</FILE>
        <FILE>awx/settings/defaults.py</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
