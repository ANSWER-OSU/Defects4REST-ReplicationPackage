<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>5615</ISSUENO>
  <ISSUEURL>https://github.com/seaweedfs/seaweedfs/issues/5615</ISSUEURL>
  <TITLE>Major issues with EC - &quot;too few shards given&quot; during nearly every reconstruction</TITLE>
  <DESCRIPTION>**Describe the bug** Despite having enough shards to reconstruct my volumes, I fail to reconstruct volumes during ec.rebuild. Example 1: ``` &gt; ec.rebuild -force rebuildEcVolumes collections 2 rebuildEcVolumes collection rebuildEcVolumes rebuildOneEcVolume 1572 missing shard 1572.0 vaxis.storage.riff.cc:8080 copied 1572.1 from atris.storage.riff.cc:8080 use existing shard 1572.2 vaxis.storage.riff.cc:8080 copied 1572.3 from sizer.storage.riff.cc:8080 missing shard 1572.4 missing shard 1572.5 vaxis.storage.riff.cc:8080 copied 1572.6 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.7 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.8 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.9 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.10 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.11 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.12 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.13 from ambellina.storage.riff.cc:8080 delete 1572.[1 3 6 7 8 9 10 11 12 13] from vaxis.storage.riff.cc:8080 error: rpc error: code = Unknown desc = RebuildEcFiles /mnt/brick.tgc-jbod.9/seaweedfs/1572: rebuildEcFiles: reconstruct: too few shards given ``` **too few shards given** despite 3 shards being missing which shouldn't be enough to ruin that volume A much worse example: ``` &gt; ec.rebuild -force rebuildEcVolumes collections 2 rebuildEcVolumes collection rebuildEcVolumes rebuildOneEcVolume 113 missing shard 113.0 vaxis.storage.riff.cc:8080 copied 113.1 from atris.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.2 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.3 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.4 from ambellina.storage.riff.cc:8080 use existing shard 113.5 vaxis.storage.riff.cc:8080 copied 113.6 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.7 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.8 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.9 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.10 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.11 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.12 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.13 from al.storage.riff.cc:8080 delete 113.[1 2 3 4 6 7 8 9 10 11 12 13] from vaxis.storage.riff.cc:8080 error: rpc error: code = Unknown desc = RebuildEcFiles /mnt/brick.tgc-jbod.6/seaweedfs/113: rebuildEcFiles: reconstruct: too few shards given ``` In this example, we fail to reconstruct our volume even though only 1 shard is missing. In a 10+4 erasure code such as this , we should be able to lose a minimum of 4 shards at a time and not fail reconstruction. **System Setup** - List the command line to start &quot;weed master&quot;, &quot;weed volume&quot;, &quot;weed filer&quot;, &quot;weed s3&quot;, &quot;weed mount&quot;. Starting via systemd. Standard command lines as used in the docs. - OS version Debian 12 - output of `weed version` `version 8000GB 3.67 d3032d1e805ab363242c833d9a61db59b3941f21 linux amd64` - if using filer, show the content of `filer.toml` ``` root@seaweedfs-filer01:~# cat /etc/seaweedfs/filer.toml # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml #################################################### # Customizable filer server options #################################################### [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to &quot;rm -Rf&quot; recursive_delete = false #max_file_name_length = 255 #################################################### # The following are filer store options #################################################### [postgres] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT, # name VARCHAR(65535), # directory VARCHAR(65535), # meta bytea, # PRIMARY KEY (dirhash, name) # ); enabled = true hostname = &quot;redacted.riff.cc&quot; port = 5433 username = &quot;seaweedfs&quot; password = &quot;redacted&quot; database = &quot;seaweedfs&quot; # create or use an existing database schema = &quot;&quot; sslmode = &quot;disable&quot; connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0 # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true #upsertQuery = &quot;&quot;&quot;UPSERT INTO &quot;%[1]s&quot; (dirhash,name,directory,meta) VALUES($1,$2,$3,$4)&quot;&quot;&quot; upsertQuery = &quot;&quot;&quot; INSERT INTO &quot;%[1]s&quot; (dirhash, name, directory, meta) VALUES ($1, $2, $3, $4) ON CONFLICT (dirhash, name) DO UPDATE SET directory = EXCLUDED.directory, meta = EXCLUDED.meta; &quot;&quot;&quot; # Add an index: # yugabyte=# \c seaweedfs # You are now connected to database &quot;seaweedfs&quot; as user &quot;yugabyte&quot;. # seaweedfs=# ALTER TABLE filemeta ADD CONSTRAINT unique_dirhash UNIQUE (dirhash); ``` **Expected behavior** EC should cleanly reconstruct. **Additional context** This is a major issue for us and until fixed we may have to stop using EC entirely out of safety concerns</DESCRIPTION>
  <REPONAME>seaweedfs</REPONAME>
  <TIMEDIFFERENCEDAYS>102</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>chore(deps): bump github.com/ydb-platform/ydb-go-sdk/v3 from 3.76.6 to 3.77.1 (#5963)</MESSAGE>
    <SHA>3ca4069d86fc048c230e5f708a8cd5a3e4cf6c9c</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>copy ec shards to disks already having ec volumes fix https://github.com/seaweedfs/seaweedfs/issues/5615</MESSAGE>
      <SHA>8e4bffc66b212a44a57dd03ee6c5869e921069ad</SHA>
      <PATCHEDFILES>
        <FILE>weed/server/volume_grpc_copy.go</FILE>
        <FILE>weed/server/volume_grpc_erasure_coding.go</FILE>
        <FILE>weed/storage/store.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
