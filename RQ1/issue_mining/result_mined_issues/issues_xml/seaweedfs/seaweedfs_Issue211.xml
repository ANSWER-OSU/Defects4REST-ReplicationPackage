<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>211</ISSUENO>
  <ISSUEURL>https://github.com/seaweedfs/seaweedfs/issues/211</ISSUEURL>
  <TITLE>seaweedfs will read the whole content into memory, and duplicate ones for many clients reading the same file</TITLE>
  <DESCRIPTION>When downloading a file, seaweedfs will read the whole content into memory, and then send that. And if many clients are downloading big files simultaneously, seaweedfs will generate many copies(not cache the content for the same file), and that will cost too much memory, so that linux OOM killer will kill volume process. seaweedfs will generate many copies, and that will cost too much memory, so that OOM killer will kill volume process. There are 2 solutions for this: 1. use NeedleCache, and make sure only one file content stays in memory 2. use syscall.Sendfile for downloading(but that doesnot support the CRC, picture rotating, resizing very well)</DESCRIPTION>
  <REPONAME>seaweedfs</REPONAME>
  <TIMEDIFFERENCEDAYS>2</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>fmt</MESSAGE>
    <SHA>3fb98a904bf5d67e7f51797fbee0aa7ddffb5903</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>add []byte caching and pooling fixes https://github.com/chrislusf/seaweedfs/issues/211</MESSAGE>
      <SHA>b03e7b26b53c2c579ae13755c3fac47f67c6f40c</SHA>
      <PATCHEDFILES>
        <FILE>go/storage/needle.go</FILE>
        <FILE>go/storage/needle_byte_cache.go</FILE>
        <FILE>go/storage/needle_read_write.go</FILE>
        <FILE>go/weed/weed_server/volume_server_handlers_sync.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
