<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>4467</ISSUENO>
  <ISSUEURL>https://github.com/seaweedfs/seaweedfs/issues/4467</ISSUEURL>
  <TITLE>Master assigns write requests to unavailable volumes</TITLE>
  <DESCRIPTION>**Describe the bug** We performed reliability test for SeaweedFS in such a manner: - We wrote files through Filer in a loop - Sometimes we restarted one of Volume Servers (by random) to check how it will work, how many time will take recovery process depending on data size stored in SeaweedFS, how write process will work during partial outage (outage one of Volume Servers), etc. And during this simple test sometimes we observed such a problem: Filer reports that it cannot save the file with one of the following errors: ``` {&quot;error&quot;:&quot;unmarshalled error http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612: failed to write to replicas for volume 16498: [seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444]: upload 489.part 4194304 bytes to http://seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612?ts=1683812487\u0026ttl=\u0026type=replicate: Post \&quot;http://seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612?ts=1683812487\u0026ttl=\u0026type=replicate\&quot;: dial tcp 10.183.0.39:8444: connect: connection refused&quot;} ``` or ``` {&quot;error&quot;:&quot;upload 486.part 4194304 bytes to http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/5122,1740bcaa7be3be: Post \&quot;http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/5122,1740bcaa7be3be\&quot;: dial tcp 10.161.3.122:8444: connect: connection refused&quot;} ``` So, on a first sight it looks quite obvious, we shutdown one of Volume Servers, and Filer cannot write to it (we see `connection refused`). The question is: **_why_** Master assigns volumes for write, if they should be unwritable? Deeper investigation into the issue showed that it could be some issue of synchronization between threads on Master's side. This is a piece of SeaweedFS Volume Server log which was shutdown: ``` I0511 13:40:18.303550 signal_handling.go:48 exec interrupt hook func name:github.com/seaweedfs/seaweedfs/weed/command.VolumeServerOptions.startVolumeServer.func1 I0511 13:40:18.303585 volume_server.go:139 Stopping volume server... volume server has been killed I0511 13:40:18.303671 volume_grpc_client_to_master.go:258 volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 stops and deletes all volumes I0511 13:40:19.587873 volume.go:280 stop send heartbeat and wait 10 seconds until shutdown ... I0511 13:40:19.587922 store.go:166 In dir /data0 adds volume:16498 collection:test replicaPlacement:001 ttl: I0511 13:40:19.587969 volume_info.go:20 maybeLoadVolumeInfo checks /data0/test_16498.vif I0511 13:40:19.588117 volume_loading.go:121 open to write file /data0/test_16498.idx I0511 13:40:19.588154 volume_loading.go:142 loading memory index /data0/test_16498.idx to memory I0511 13:40:19.588208 needle_map_memory.go:54 max file key: 0 for file: /data0/test_16498.idx I0511 13:40:19.588721 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.588734 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.588750 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{&quot;error&quot;:&quot;replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.606846 common.go:106 error writing JSON status /status 200: write tcp 10.183.0.38:8444-&gt;10.183.0.1:46920: write: connection reset by peer I0511 13:40:19.606865 common.go:107 JSON content: map[DiskStatuses:[dir:&quot;/data0&quot; all:98953909501952 used:9914417262592 free:89039492239360 percent_free:89.980774 percent_used:10.019227] &lt;omitted&gt; I0511 13:40:19.731598 disk_location.go:440 dir /data0 disk free 89.98% &gt;= required 1.00% I0511 13:40:19.916394 store.go:170 add volume 16498 I0511 13:40:19.916412 volume_grpc_admin.go:60 assign volume volume_id:16498 collection:&quot;test&quot; replication:&quot;001&quot; I0511 13:40:20.074794 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.074812 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.074826 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{&quot;error&quot;:&quot;replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798244 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798261 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798275 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{&quot;error&quot;:&quot;replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:29.588357 volume.go:304 graceful stop cluster http server ... I0511 13:40:29.588947 volume.go:309 graceful stop gRPC ... I0511 13:40:29.589452 volume_server.go:149 Shutting down volume server... I0511 13:40:29.695784 volume_server.go:151 Shut down successfully! ``` Point to take a look is assignment of new volume (id=16498) on this Volume Server after its termination. And piece of log from Master: ``` I0511 13:40:18.304201 master_grpc_server.go:162 master received heartbeat ip:&quot;seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test&quot; port:8444 public_url:&quot;seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444&quot; has_no_volumes:true I0511 13:40:18.446855 cluster_commands.go:32 max volume id 16497 ==&gt; 16498 I0511 13:40:18.464245 volume_growth.go:244 Created Volume 16498 on topo:DefaultDataCenter:DefaultRack:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.464308 master_grpc_server.go:162 master received heartbeat ip:&quot;seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test&quot; port:8444 new_volumes:{id:16498 collection:&quot;test&quot; replica_placement:1 version:3} I0511 13:40:18.464338 volume_layout.go:223 volume 16498 does not have enough copies I0511 13:40:18.464344 volume_layout.go:228 volume 16498 remove from writable I0511 13:40:18.464453 masterclient.go:277 .master: seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:18.464460 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter:DefaultDataCenter GrpcPort:0} W0511 13:40:18.469625 master_grpc_server.go:100 SendHeartbeat.Recv server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 : rpc error: code = Canceled desc = context canceled I0511 13:40:18.469648 node.go:237 topo:DefaultDataCenter:DefaultRack removes seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.469655 master_grpc_server.go:87 unregister disconnected volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.469659 master_grpc_server.go:58 remove volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444, online volume server: map[seaweedfs-test-volume-0.seaweedfs-test-volume-peer.seaweedfs-test:8444:[b81f6a9c-e4c1-4702-88d5-51974f4ca3d6] seaweedfs-test-volume-1.seaweedfs-test-volume-peer.seaweedfs-test:8444:[58a7e74e-84e2-48df-b52b-dc9555afb548] seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444:[ff43c257-c736-4b6b-a930-db16c409c12b]] I0511 13:40:18.527309 masterclient.go:292 updateVidMap(DefaultDataCenter) .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 volume add: 0, del: 8263, add ec: 0 del ec: 0 I0511 13:40:19.771416 master_grpc_server.go:162 master received heartbeat ip:&quot;seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test&quot; port:8444 public_url:&quot;seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444&quot; max_file_key:5192448 volumes:{id:10324 size:1128282400 &lt;omitted&gt; I0511 13:40:19.916729 volume_growth.go:244 Created Volume 16498 on seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.916752 volume_layout.go:223 volume 16498 does not have enough copies I0511 13:40:19.916756 volume_layout.go:228 volume 16498 remove from writable I0511 13:40:19.916761 volume_growth.go:257 Registered Volume 16498 on topo:DefaultDataCenter:DefaultRack:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.916771 volume_layout.go:393 Volume 16498 becomes writable I0511 13:40:19.916776 volume_growth.go:257 Registered Volume 16498 on seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.919012 cluster_commands.go:32 max volume id 16498 ==&gt; 16499 I0511 13:40:19.957609 masterclient.go:277 .master: seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:19.957611 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter:DefaultDataCenter GrpcPort:0} I0511 13:40:19.957620 masterclient.go:277 .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:19.957622 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter: GrpcPort:0} I0511 13:40:19.957626 masterclient.go:292 updateVidMap() .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 volume add: 1, del: 0, add ec: 0 del ec: 0 ``` There also were a lot of messages like these: ``` I0511 13:40:18.329755 topology.go:252 removing volume info: Id:2458, Size:1329612128, ReplicaPlacement:001, Collection:test, Version:3, FileCount:317, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.431844 master_grpc_server.go:203 master see deleted volume 2458 from seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 ``` But there is no such message for Volume 16498, so it is writeable from Master's perspective (but in fact it doesn't), and Filer gets assignments for write requests on this volume. **System Setup** We have SeaweedFS running on Kubernetes via SeaweedFS Operator. There are 3 Masters, 4 Volume Servers, 4 Filers (with Scylla as its backend) - List the command line to start &quot;weed master&quot;, &quot;weed volume&quot;, &quot;weed filer&quot;, &quot;weed s3&quot;, &quot;weed mount&quot;: - Master: ``` weed -v 4 -logtostderr=true master -volumeSizeLimitMB=1024 -defaultReplication=001 -ip=$(POD_NAME).seaweedfs-test-master-peer.seaweedfs-test -peers=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -metricsPort=9999 ``` - Volume Server: ``` weed -v 4 -logtostderr=true volume -port=8444 -max=0 -ip=$(POD_NAME).seaweedfs-test-volume-peer.seaweedfs-test -metricsPort=9999 -mserver=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -dir=/data0 ``` - Filer: ``` weed -v 4 -logtostderr=true filer -port=8888 -ip=$(POD_NAME).seaweedfs-test-filer-peer.seaweedfs-test -master=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -metricsPort=9999 -s3 ``` - OS version: Fedora CoreOS 33.20210426.3.0 - output of `weed version`: `version 8000GB 3.43 673214574 linux amd64` - if using filer, show the content of `filer.toml`: ``` [leveldb2] enabled = false [etcd] enabled = false servers = &quot;seaweed-etcd.seaweedfs-test:2379&quot; timeout = &quot;3s&quot; [cassandra] enabled = true keyspace=&quot;seaweedfs&quot; hosts=[ &quot;seaweed-scylla-client.seaweedfs-test:9042&quot;, ] superLargeDirectories = [ ] ``` **Expected behavior** We expect unwritable (de facto) volumes will not be assigned for write requests.</DESCRIPTION>
  <REPONAME>seaweedfs</REPONAME>
  <TIMEDIFFERENCEDAYS>15</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>upgrade rocksdb versions</MESSAGE>
    <SHA>b0da8788a1294714d90f2f0dd6918b00a100ef6f</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>reduce the window size between unregistering a volume server and creating volumes on that server fix https://github.com/seaweedfs/seaweedfs/issues/4467</MESSAGE>
      <SHA>ca7cc613194b88985548ddaf90fc1687af21a7d6</SHA>
      <PATCHEDFILES>
        <FILE>weed/topology/data_node.go</FILE>
        <FILE>weed/topology/node.go</FILE>
        <FILE>weed/topology/topology_event_handling.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
