<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>5276</ISSUENO>
  <ISSUEURL>https://github.com/seaweedfs/seaweedfs/issues/5276</ISSUEURL>
  <TITLE>The second of two consecutive chunks with the same modified_ts_ns would be determined as garbage chunk</TITLE>
  <DESCRIPTION>**Describe the bug** when using s3 multipart upload to upload large files, sometimes the uploaded file is not complete. the filer log shows that some chunks were deleted in s3 CompleteMultipartUpload process: ``` s3api_object_multipart_handlers.go:87 CompleteMultipartUploadHandler&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;CompleteMultipartUploadResult xmlns=&quot;http://s3.amazonaws.com/doc/2006-03-01/&quot;&gt;&lt;Bucket&gt;test&lt;/Bucket&gt;&lt;ETag&gt;&quot;5fcca6e6a9d993c696e93a4ff590e876-25601&quot;&lt;/ETag&gt;&lt;Key&gt;test_100G&lt;/Key&gt;&lt;Location&gt;http://10.2.8.15:8888/buckets/test/test_100G&lt;/Location&gt;&lt;/CompleteMultipartUploadResult&gt;0 error_handler.go:96 status 200 application/xml: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;CompleteMultipartUploadResult xmlns=&quot;http://s3.amazonaws.com/doc/2006-03-01/&quot;&gt;&lt;Bucket&gt;test&lt;/Bucket&gt;&lt;ETag&gt;&quot;5fcca6e6a9d993c696e93a4ff590e876-25601&quot;&lt;/ETag&gt;&lt;Key&gt;test_100G&lt;/Key&gt;&lt;Location&gt;http://10.2.8.15:8888/buckets/test/test_100G&lt;/Location&gt;&lt;/CompleteMultipartUploadResult&gt; filer_deletion.go:63 deleting fileIds [209,06fcc9d0c356d9 267,07111283476be2 120,0734dda3e94fcf 23,07380b4872bb69] ``` I printed deleted chunks' info: ``` 209,06fcc9d0c356d9, offset: 31423725568, size:4194304, modified_ts_ns:1704948775800315374 267,07111283476be2, offset: 53183774720, size:4194304, modified_ts_ns:1704949043164890748 120,0734dda3e94fcf, offset: 91574239232, size:4194304, modified_ts_ns:1704949642723286286 23,07380b4872bb69, offset: 94984208384, size:4194304, modified_ts_ns:1704949720478107269 ``` take chunk 209,06fcc9d0c356d9 as example, the chunk belongs to 1499.part, and 1499.part has totally 5 chunks: ``` filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 1 to 178,06fcc7ef2a9ee1 [0,4194304) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 2 to 12,06fcc81e2bf1ad [4194304,8388608) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 3 to 209,06fcc9d0c356d9 [8388608,12582912) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 4 to 133,06fcca90fe005d [12582912,16777216) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 5 to 226,06fccb9dfa4413 [16777216,20971520) ``` the uploaded file's metadata shows that chunk 12,06fcc81e2bf1ad has the same modified_ts_ns as chunk 209,06fcc9d0c356d9: ``` HTTP/1.1 200 OK Content-Type: application/json Server: SeaweedFS Filer 30GB 3.59 Date: Thu, 11 Jan 2024 06:07:51 GMT Transfer-Encoding: chunked { &quot;FullPath&quot;: &quot;/buckets/test/test_100G&quot;, &quot;Mtime&quot;: &quot;2024-01-11T13:13:29+08:00&quot;, &quot;Crtime&quot;: &quot;2024-01-11T13:13:29+08:00&quot;, &quot;Mode&quot;: 504, &quot;Uid&quot;: 0, &quot;Gid&quot;: 0, &quot;Mime&quot;: &quot;&quot;, &quot;TtlSec&quot;: 0, &quot;UserName&quot;: &quot;&quot;, &quot;GroupNames&quot;: null, &quot;SymlinkTarget&quot;: &quot;&quot;, &quot;Md5&quot;: null, &quot;FileSize&quot;: 107374182432, &quot;Rdev&quot;: 0, &quot;Inode&quot;: 0, &quot;Extended&quot;: null, &quot;chunks&quot;: [ ... { &quot;file_id&quot;: &quot;178,06fcc7ef2a9ee1&quot;, &quot;offset&quot;: 31415336960, &quot;size&quot;: 4194304, &quot;modified_ts_ns&quot;: 1704948775742876389, &quot;e_tag&quot;: &quot;T1WHruL2rdcNzpBNzzYLow==&quot;, &quot;fid&quot;: { &quot;volume_id&quot;: 178, &quot;file_key&quot;: 457927, &quot;cookie&quot;: 4012547809 } }, { &quot;file_id&quot;: &quot;12,06fcc81e2bf1ad&quot;, &quot;offset&quot;: 31419531264, &quot;size&quot;: 4194304, &quot;modified_ts_ns&quot;: 1704948775800315374, &quot;e_tag&quot;: &quot;Wi+o67I2ISAyEGL1vvGDGA==&quot;, &quot;fid&quot;: { &quot;volume_id&quot;: 12, &quot;file_key&quot;: 457928, &quot;cookie&quot;: 506196397 } }, { &quot;file_id&quot;: &quot;133,06fcca90fe005d&quot;, &quot;offset&quot;: 31427919872, &quot;size&quot;: 4194304, &quot;modified_ts_ns&quot;: 1704948775802870518, &quot;e_tag&quot;: &quot;gxyHCpAf2vECDOmwgTBF3g==&quot;, &quot;fid&quot;: { &quot;volume_id&quot;: 133, &quot;file_key&quot;: 457930, &quot;cookie&quot;: 2432565341 } }, { &quot;file_id&quot;: &quot;226,06fccb9dfa4413&quot;, &quot;offset&quot;: 31432114176, &quot;size&quot;: 4194304, &quot;modified_ts_ns&quot;: 1704948775809675155, &quot;e_tag&quot;: &quot;XHMn+bM40q0ysKIG5ajD3Q==&quot;, &quot;fid&quot;: { &quot;volume_id&quot;: 226, &quot;file_key&quot;: 457931, &quot;cookie&quot;: 2650424339 } } ... ], &quot;HardLinkId&quot;: null, &quot;HardLinkCounter&quot;: 0, &quot;Content&quot;: null, &quot;Remote&quot;: null, &quot;Quota&quot;: 0 } ``` the other deleted chunks shows the same feature. then I added a test case in filechunks_test.go: ``` func TestCompactFileChunks3(t *testing.T) { chunks := []*filer_pb.FileChunk{ {Offset: 0, Size: 100, FileId: &quot;abc&quot;, ModifiedTsNs: 50}, {Offset: 100, Size: 100, FileId: &quot;ghi&quot;, ModifiedTsNs: 50}, {Offset: 200, Size: 100, FileId: &quot;jkl&quot;, ModifiedTsNs: 100}, {Offset: 300, Size: 100, FileId: &quot;def&quot;, ModifiedTsNs: 200}, } compacted, _ := CompactFileChunks(nil, chunks) if len(compacted) != 4 { t.Fatalf(&quot;unexpected compacted: %d&quot;, len(compacted)) } } ``` the test case did not pass **System Setup** seaweedfs version: 3.59</DESCRIPTION>
  <REPONAME>seaweedfs</REPONAME>
  <TIMEDIFFERENCEDAYS>0</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>Adapt S3 POST ContentType (#5275)</MESSAGE>
    <SHA>0b49c163618646927a058b189b03883c6981591e</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>fix when two consecutive chunks with the same modified_ts_ns fix https://github.com/seaweedfs/seaweedfs/issues/5276</MESSAGE>
      <SHA>56df44845f02d9c1f37e957df1b09fd1a6d9a7fd</SHA>
      <PATCHEDFILES>
        <FILE>weed/filer/filechunks_read.go</FILE>
        <FILE>weed/filer/filechunks_test.go</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
