<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>127535</ISSUENO>
  <ISSUEURL>https://github.com/elastic/elasticsearch/issues/127535</ISSUEURL>
  <TITLE>[CI] EsqlDataTypeConverterTests testSuggestedCast failing</TITLE>
  <DESCRIPTION>**Build Scans:** - [elasticsearch-periodic #7934 / openjdk23_entitlements_false_checkpart3_java-matrix](https://gradle-enterprise.elastic.co/s/rwgz2xsgyatg2) - [elasticsearch-pull-request #69907 / part-3](https://gradle-enterprise.elastic.co/s/uqsiqch3f2t4o) - [elasticsearch-intake #22448 / part3](https://gradle-enterprise.elastic.co/s/fvwmby366ozqy) - [elasticsearch-periodic-platform-support #7943 / ubuntu-2404_platform-support-unix](https://gradle-enterprise.elastic.co/s/ryngufgc3tyno) - [elasticsearch-periodic-platform-support #7943 / almalinux-9_platform-support-unix](https://gradle-enterprise.elastic.co/s/dfe7rrznczwny) - [elasticsearch-pull-request #69898 / part-3](https://gradle-enterprise.elastic.co/s/wfcaznrny4l6m) - [elasticsearch-periodic-platform-support #7943 / almalinux-8-aarch64_checkpart3_platform-support-arm](https://gradle-enterprise.elastic.co/s/dnx642e37xuek) - [elasticsearch-periodic #7922 / openjdk23_entitlements_true_checkpart3_java-matrix](https://gradle-enterprise.elastic.co/s/gwenyep2k6tg4) - [elasticsearch-periodic-platform-support #7943 / ubuntu-2004-aarch64_checkpart3_platform-support-arm](https://gradle-enterprise.elastic.co/s/i2ravjrpuf3am) - [elasticsearch-pull-request #69893 / part-3](https://gradle-enterprise.elastic.co/s/imsjd22av4uze) **Reproduction Line:** ``` ./gradlew &quot;:x-pack:plugin:esql:test&quot; --tests &quot;org.elasticsearch.xpack.esql.type.EsqlDataTypeConverterTests.testSuggestedCast&quot; -Dtests.seed=D219B25112E3E6BA -Dtests.jvm.argline=&quot;-Des.entitlements.enabled=false&quot; -Dtests.locale=ur-IN -Dtests.timezone=Europe/Dublin -Druntime.java=23 ``` **Applicable branches:** main **Reproduces locally?:** N/A **Failure History:** [See dashboard](https://es-delivery-stats.elastic.dev/app/dashboards#/view/dcec9e60-72ac-11ee-8f39-55975ded9e63?_g=(refreshInterval:(pause:!t,value:60000),time:(from:now-7d%2Fd,to:now))&amp;_a=(controlGroupState:(initialChildControlState:('0c0c9cb8-ccd2-45c6-9b13-96bac4abc542':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:task.keyword,order:0,selectedOptions:!(),title:'GradleTask',type:optionsListControl),'4e6ad9d6-6fdc-4fcc-bf1a-aa6ca79e0850':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:className.keyword,order:1,selectedOptions:!(org.elasticsearch.xpack.esql.type.EsqlDataTypeConverterTests),title:'Suite',type:optionsListControl),'144933da-5c1b-4257-a969-7f43455a7901':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:name.keyword,order:2,selectedOptions:!(testSuggestedCast),title:'Test',type:optionsListControl))))) **Failure Message:** ``` java.lang.AssertionError: expected:&lt;KEYWORD&gt; but was:&lt;null&gt; ``` **Issue Reasons:** - [main] 13 failures in test testSuggestedCast (12.3% fail rate in 106 executions) - [main] 6 failures in step part-3 (10.0% fail rate in 60 executions) - [main] 2 failures in pipeline elasticsearch-periodic (100.0% fail rate in 2 executions) - [main] 6 failures in pipeline elasticsearch-pull-request (10.0% fail rate in 60 executions) **Note:** This issue was created using new test triage automation. Please report issues or feedback to es-delivery.</DESCRIPTION>
  <REPONAME>elasticsearch</REPONAME>
  <TIMEDIFFERENCEDAYS>0</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>ESQL: Speed loading stored fields (#127348) This speeds up loading from stored fields by opting more blocks into the &quot;sequential&quot; strategy. This really kicks in when loading stored fields like `text`. And when you need less than 100% of documents, but more than, say, 10%. This is most useful when you need 99.9% of field documents. That sort of thing. Here's the perf numbers: ``` %100.0 {&quot;took&quot;: 403 -&gt; 401,&quot;documents_found&quot;:1000000} %099.9 {&quot;took&quot;:3990 -&gt; 436,&quot;documents_found&quot;: 999000} %099.0 {&quot;took&quot;:4069 -&gt; 440,&quot;documents_found&quot;: 990000} %090.0 {&quot;took&quot;:3468 -&gt; 421,&quot;documents_found&quot;: 900000} %030.0 {&quot;took&quot;:1213 -&gt; 152,&quot;documents_found&quot;: 300000} %020.0 {&quot;took&quot;: 766 -&gt; 104,&quot;documents_found&quot;: 200000} %010.0 {&quot;took&quot;: 397 -&gt; 55,&quot;documents_found&quot;: 100000} %009.0 {&quot;took&quot;: 352 -&gt; 375,&quot;documents_found&quot;: 90000} %008.0 {&quot;took&quot;: 304 -&gt; 317,&quot;documents_found&quot;: 80000} %007.0 {&quot;took&quot;: 273 -&gt; 287,&quot;documents_found&quot;: 70000} %005.0 {&quot;took&quot;: 199 -&gt; 204,&quot;documents_found&quot;: 50000} %001.0 {&quot;took&quot;: 46 -&gt; 46,&quot;documents_found&quot;: 10000} ``` Let's explain this with an example. First, jump to `main` and load a million documents: ``` rm -f /tmp/bulk for a in {1..1000}; do echo '{&quot;index&quot;:{}}' &gt;&gt; /tmp/bulk echo '{&quot;text&quot;:&quot;text '$(printf %04d $a)'&quot;}' &gt;&gt; /tmp/bulk done curl -s -uelastic:password -HContent-Type:application/json -XDELETE localhost:9200/test for a in {1..1000}; do echo -n $a: curl -s -uelastic:password -HContent-Type:application/json -XPOST localhost:9200/test/_bulk?pretty --data-binary @/tmp/bulk | grep errors done curl -s -uelastic:password -HContent-Type:application/json -XPOST localhost:9200/test/_forcemerge?max_num_segments=1 curl -s -uelastic:password -HContent-Type:application/json -XPOST localhost:9200/test/_refresh echo ``` Now query them all. Run this a few times until it's stable: ``` echo -n &quot;%100.0 &quot; curl -s -uelastic:password -HContent-Type:application/json -XPOST 'localhost:9200/_query?pretty' -d'{ &quot;query&quot;: &quot;FROM test | STATS SUM(LENGTH(text))&quot;, &quot;pragma&quot;: { &quot;data_partitioning&quot;: &quot;shard&quot; } }' | jq -c '{took, documents_found}' ``` Now fetch 99.9% of documents: ``` echo -n &quot;%099.9 &quot; curl -s -uelastic:password -HContent-Type:application/json -XPOST 'localhost:9200/_query?pretty' -d'{ &quot;query&quot;: &quot;FROM test | WHERE NOT text.keyword IN (\&quot;text 0998\&quot;) | STATS SUM(LENGTH(text))&quot;, &quot;pragma&quot;: { &quot;data_partitioning&quot;: &quot;shard&quot; } }' | jq -c '{took, documents_found}' ``` This should spit out something like: ``` %100.0 { &quot;took&quot;:403,&quot;documents_found&quot;:1000000} %099.9 {&quot;took&quot;:4098, &quot;documents_found&quot;:999000} ``` We're loading *fewer* documents but it's slower! What in the world?! If you dig into the profile you'll see that it's value loading: ``` $ curl -s -uelastic:password -HContent-Type:application/json -XPOST 'localhost:9200/_query?pretty' -d'{ &quot;query&quot;: &quot;FROM test | STATS SUM(LENGTH(text))&quot;, &quot;pragma&quot;: { &quot;data_partitioning&quot;: &quot;shard&quot; }, &quot;profile&quot;: true }' | jq '.profile.drivers[].operators[] | select(.operator | contains(&quot;ValuesSourceReaderOperator&quot;))' { &quot;operator&quot;: &quot;ValuesSourceReaderOperator[fields = [text]]&quot;, &quot;status&quot;: { &quot;readers_built&quot;: { &quot;stored_fields[requires_source:true, fields:0, sequential: true]&quot;: 222, &quot;text:column_at_a_time:null&quot;: 222, &quot;text:row_stride:BlockSourceReader.Bytes&quot;: 1 }, &quot;values_loaded&quot;: 1000000, &quot;process_nanos&quot;: 370687157, &quot;pages_processed&quot;: 222, &quot;rows_received&quot;: 1000000, &quot;rows_emitted&quot;: 1000000 } } $ curl -s -uelastic:password -HContent-Type:application/json -XPOST 'localhost:9200/_query?pretty' -d'{ &quot;query&quot;: &quot;FROM test | WHERE NOT text.keyword IN (\&quot;text 0998\&quot;) | STATS SUM(LENGTH(text))&quot;, &quot;pragma&quot;: { &quot;data_partitioning&quot;: &quot;shard&quot; }, &quot;profile&quot;: true }' | jq '.profile.drivers[].operators[] | select(.operator | contains(&quot;ValuesSourceReaderOperator&quot;))' { &quot;operator&quot;: &quot;ValuesSourceReaderOperator[fields = [text]]&quot;, &quot;status&quot;: { &quot;readers_built&quot;: { &quot;stored_fields[requires_source:true, fields:0, sequential: false]&quot;: 222, &quot;text:column_at_a_time:null&quot;: 222, &quot;text:row_stride:BlockSourceReader.Bytes&quot;: 1 }, &quot;values_loaded&quot;: 999000, &quot;process_nanos&quot;: 3965803793, &quot;pages_processed&quot;: 222, &quot;rows_received&quot;: 999000, &quot;rows_emitted&quot;: 999000 } } ``` It jumps from 370ms to almost four seconds! Loading fewer values! The second big difference is in the `stored_fields` marker. In the second on it's `sequential: false` and in the first `sequential: true`. `sequential: true` uses Lucene's &quot;merge&quot; stored fields reader instead of the default one. It's much more optimized at decoding sequences of documents. Previously we only enabled this reader when loading compact sequences of documents - when the entire block looks like ``` 1, 2, 3, 4, 5, ... 1230, 1231 ``` If there are any gaps we wouldn't enable it. That was a very conservative thing we did long ago without doing any experiments. We knew it was faster without any gaps, but not otherwise. It turns out it's a lot faster in a lot more cases. I've measured it as faster for 99% gaps, at least on simple documents. I'm a bit worried that this is too aggressive, so I've set made it configurable and made the default being to use the &quot;merge&quot; loader with 10% gaps. So we'd use the merge loader with a block like: ``` 1, 11, 21, 31, ..., 1231, 1241 ```</MESSAGE>
    <SHA>10336c950ca2defe8ba651f1cdba346b1c0eabc5</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>Mute org.elasticsearch.xpack.esql.type.EsqlDataTypeConverterTests testSuggestedCast #127535</MESSAGE>
      <SHA>7b3f43fb552a8b6a4aa95977e7c3de7ec0a19b0e</SHA>
      <PATCHEDFILES>
        <FILE>muted-tests.yml</FILE>
      </PATCHEDFILES>
    </COMMIT>
    <COMMIT>
      <MESSAGE>Revert &quot;Mute org.elasticsearch.xpack.esql.type.EsqlDataTypeConverterTests testSuggestedCast #127535&quot; This reverts commit 7b3f43fb552a8b6a4aa95977e7c3de7ec0a19b0e.</MESSAGE>
      <SHA>cf52d071bbbab9ff5bc1855dfa04ff5b9e05b847</SHA>
      <PATCHEDFILES>
        <FILE>muted-tests.yml</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
