<?xml version="1.0" ?>
<ISSUE>
  <ISSUENO>141</ISSUENO>
  <ISSUEURL>https://github.com/NatLibFi/Annif/issues/141</ISSUEURL>
  <TITLE>Support additional metrics</TITLE>
  <DESCRIPTION>Sklearn has a few more metrics for multilabel evaluation. Especially interesting are metrics that can work with large result sets without needing to specify a limit. To use these we probably need to turn the results into vectors instead of the current approach which evaluates one document at a time. The evaldir and optimize commands should also show how many documents were evaluated.</DESCRIPTION>
  <REPONAME>Annif</REPONAME>
  <TIMEDIFFERENCEDAYS>127</TIMEDIFFERENCEDAYS>
  <BUGGYCOMMIT>
    <MESSAGE>Merge pull request #165 from NatLibFi/ndcg-from-arrays reimplement NDCG metric using NumPy arrays for input</MESSAGE>
    <SHA>017a3b23e46c2dd09c7992d047bf0f7284c1383f</SHA>
  </BUGGYCOMMIT>
  <PATCHCOMMITS>
    <COMMIT>
      <MESSAGE>Add some more DCG/nDCG unit tests based on Wikipedia examples (part of #141)</MESSAGE>
      <SHA>01f0cabe0e512d2a0fcf91bea59c0d14362aa2b7</SHA>
      <PATCHEDFILES>
        <FILE>tests/test_eval.py</FILE>
      </PATCHEDFILES>
    </COMMIT>
  </PATCHCOMMITS>
</ISSUE>
