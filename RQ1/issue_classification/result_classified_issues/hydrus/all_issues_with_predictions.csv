issue_no,repo,issue_url,title,description,patched_file_types,text_for_topic_modeling,prediction,confidence
424,hydrus,https://github.com/HTTP-APIs/hydrus/issues/424,General refactoring," Current Behaviour: A lot of functions have many if-else branches and the procedures implemented by these branches have too much code in them. This makes readability and testability hard. For example the branch in this [chunk of code](https://github.com/HTTP-APIs/hydrus/blob/42205ab4d4984f591310b19f3b5d6c1610e95e4d/hydrus/resources.py#L108) should be ported into a function like:  if checkClassOp(class_path, ""GET""): items_get_check_support() abort(405)  Into a dedicated module called `itemshelpers.py` the above functions should be defined by incorporating the current code:  def items_get_check_support():  Check if class_type supports GET operation try: # Try getting the Item based on ID and Class type response = crud.get( id_, class_type, api_name=get_api_name(), session=get_session()) response = finalize_response(class_path, response) return set_response_headers( jsonify(hydrafy(response, path=path except (ClassNotFound, InstanceNotFound) as e: error = e.get_HTTP() return set_response_headers(jsonify(error.generate()), status_code=error.code)  Each of these helpers functions should be tested separately.  Expected Behaviour: All functions should perform well-scoped units of work and have their own tests. Handlers in endpoints classes should be much more concise, all the units of work for each branch should be moved into helpers functions. Main functions should look something like this:  def post():  Docstring   some code  if condition_1: run_helper_1() elif condition_2: run_helper_2() else: run_helper_3()  rest of the code  ",source-file | source-file | source-file | source-file | source-file | source-file,"General refactoring  Current Behaviour: A lot of functions have many if-else branches and the procedures implemented by these branches have too much code in them. This makes readability and testability hard. For example the branch in this [chunk of code](https://github.com/HTTP-APIs/hydrus/blob/42205ab4d4984f591310b19f3b5d6c1610e95e4d/hydrus/resources.py#L108) should be ported into a function like:  if checkClassOp(class_path, ""GET""): items_get_check_support() abort(405)  Into a dedicated module called `itemshelpers.py` the above functions should be defined by incorporating the current code:  def items_get_check_support():  Check if class_type supports GET operation try: # Try getting the Item based on ID and Class type response = crud.get( id_, class_type, api_name=get_api_name(), session=get_session()) response = finalize_response(class_path, response) return set_response_headers( jsonify(hydrafy(response, path=path except (ClassNotFound, InstanceNotFound) as e: error = e.get_HTTP() return set_response_headers(jsonify(error.generate()), status_code=error.code)  Each of these helpers functions should be tested separately.  Expected Behaviour: All functions should perform well-scoped units of work and have their own tests. Handlers in endpoints classes should be much more concise, all the units of work for each branch should be moved into helpers functions. Main functions should look something like this:  def post():  Docstring   some code  if condition_1: run_helper_1() elif condition_2: run_helper_2() else: run_helper_3()  rest of the code   source-file source-file source-file source-file source-file source-file",no-bug,0.95
614,hydrus,https://github.com/HTTP-APIs/hydrus/issues/614,`hydrus serve` gives error," I'm submitting a - [x] bug report. - [ ] feature request.  Current Behaviour: <!-- Describe about the bug --> `hydrus serve` gives error `hydrus: no such file or directory`  Expected Behaviour: <!-- Describe what will happen if bug is removed --> After `hydrus serve` we should have a demo up and running on http://localhost:8080/serverapi/  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug --> Follow the instructions to run a demo for hydrus using the sample API, and after running `hydrus serve` we get error `hydrus: no such file or directory`  Snapshot: <!-- If you can then please provide the screenshot of the issue you are facing --> ![Screenshot from 2022-02-25 11-05-22](https://user-images.githubusercontent.com/50960175/155660150-395c1aa2-720c-455e-aeb4-a23077125342.png)  Environment: <!-- Please provide the following environment details --> * python version: 3.7 * pip version: 20.0.2 * OS details: Ubuntu 20.04.4 LTS x86_64  Do you want to work on this issue? <!-- yes/no --> yes",source-file | source-file,"`hydrus serve` gives error  I'm submitting a - [x] bug report. - [ ] feature request.  Current Behaviour: <!-- Describe about the bug --> `hydrus serve` gives error `hydrus: no such file or directory`  Expected Behaviour: <!-- Describe what will happen if bug is removed --> After `hydrus serve` we should have a demo up and running on http://localhost:8080/serverapi/  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug --> Follow the instructions to run a demo for hydrus using the sample API, and after running `hydrus serve` we get error `hydrus: no such file or directory`  Snapshot: <!-- If you can then please provide the screenshot of the issue you are facing --> ![Screenshot from 2022-02-25 11-05-22](https://user-images.githubusercontent.com/50960175/155660150-395c1aa2-720c-455e-aeb4-a23077125342.png)  Environment: <!-- Please provide the following environment details --> * python version: 3.7 * pip version: 20.0.2 * OS details: Ubuntu 20.04.4 LTS x86_64  Do you want to work on this issue? <!-- yes/no --> yes source-file source-file",no-bug,0.9
79,hydrus,https://github.com/HTTP-APIs/hydrus/issues/79,Coding Conventions,"Currently the code has many functions that doesn't follow proper naming conventions and also lines are greater than 79 characters, which is not according to Conventions and standards followed. Some of the functions with improper naming convention : ![image](https://user-images.githubusercontent.com/18033231/36139099-3ddc9a16-10c2-11e8-8a48-888a8b69dc70.png) __Working status__: Yes I am working on it.",source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file,"Coding Conventions Currently the code has many functions that doesn't follow proper naming conventions and also lines are greater than 79 characters, which is not according to Conventions and standards followed. Some of the functions with improper naming convention : ![image](https://user-images.githubusercontent.com/18033231/36139099-3ddc9a16-10c2-11e8-8a48-888a8b69dc70.png) __Working status__: Yes I am working on it. source-file source-file source-file test-file test-file source-file source-file source-file source-file test-file test-file source-file source-file source-file source-file test-file test-file source-file",no-bug,0.95
160,hydrus,https://github.com/HTTP-APIs/hydrus/issues/160,Add option to add database and server url in CLI, I'm submitting a - [ ] bug report. - [x] feature request.  Current Behaviour: <!-- Describe about the bug --> If we want to use a database file instead of using sqlite in memory database we can not give it as database url through cli.  Expected Behaviour: <!-- Describe what will happen if bug is removed --> User will be able to give database and server url as argument in hydrus CLI  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug -->  Do you want to work on this issue? <!-- yes/no --> Yes,source-file,Add option to add database and server url in CLI  I'm submitting a - [ ] bug report. - [x] feature request.  Current Behaviour: <!-- Describe about the bug --> If we want to use a database file instead of using sqlite in memory database we can not give it as database url through cli.  Expected Behaviour: <!-- Describe what will happen if bug is removed --> User will be able to give database and server url as argument in hydrus CLI  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug -->  Do you want to work on this issue? <!-- yes/no --> Yes source-file,no-bug,0.95
1,hydrus,https://github.com/HTTP-APIs/hydrus/issues/1,Define an HYDRA-featured response template for astronomy collection,We need a template to wrap the data into a well-formed JSON-LD,source-file | source-file | source-file | source-file | source-file | source-file | other-file | documentation-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | documentation-file | documentation-file | other-file | documentation-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | documentation-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file,Define an HYDRA-featured response template for astronomy collection We need a template to wrap the data into a well-formed JSON-LD source-file source-file source-file source-file source-file source-file other-file documentation-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file documentation-file documentation-file other-file documentation-file source-file other-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file documentation-file test-file test-file test-file test-file test-file source-file source-file,no-bug,0.85
6,hydrus,https://github.com/HTTP-APIs/hydrus/issues/6,Backend choice,"In #2, @Mec-iS wrote: > At first impression I would avoid Triple Stores and try to use a Graph Database or try to prototype something with Apache TinkerPop or also Spark GraphX, to gain in flexibility to switch to different solutions. I tend to disagree. JSON-LD uses JSON as its concrete syntax, and RDF as its abstract syntax (i.e. data model), so the most natural fits would be either * a triple-store (fitting the abstract syntax), or * a document-oriented database (fitting the concrete syntax -- see http://greggkellogg.net/2012/08/json-ld-and-mongodb/)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,"Backend choice In #2, @Mec-iS wrote: > At first impression I would avoid Triple Stores and try to use a Graph Database or try to prototype something with Apache TinkerPop or also Spark GraphX, to gain in flexibility to switch to different solutions. I tend to disagree. JSON-LD uses JSON as its concrete syntax, and RDF as its abstract syntax (i.e. data model), so the most natural fits would be either * a triple-store (fitting the abstract syntax), or * a document-oriented database (fitting the concrete syntax -- see http://greggkellogg.net/2012/08/json-ld-and-mongodb/) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file",no-bug,0.9
3,hydrus,https://github.com/HTTP-APIs/hydrus/issues/3,A Starting Design for the Endpoints,"This is a more general overlook about the API's endpoints. The implementation described here is the application of the use-case no.2 described [here](https://github.com/HTTP-APIs/hydrus/issues/2#issue-206778515) in issue #2 . For the use-case no.2, the demo API we are going to develop is about Commercial Off The Shelves (COTS) spare parts for pico- and nano-satellites. Has been a recent trend in commercial space industry to develop super-light and super-compact satellites for the sake of research, prototyping, Earth observation and product testing. The kind of parts we are talking about are basically microcontrollers and processors that allows the spacecraft to operate. Each of these ""boards"" is meant to provide a function; there are 8-9 different functions (subsystems) to be carried on for the spacecraft to accomplish its mission. Some of them are critical, some other are supporting functions but likely almost every spacecraft needs almost all of them to work properly. This is a comprehensive list as they are written in the ""subsystems"" vocabulary: * propulsion * primary power * backup power * thermal active * thermal passive * structure * command and data handling * communication * attitude and navigation (AODCS) active or passive This API will serve objects related to this kind of hardware. The simple starting endpoints can be: * `/api/cots/`: from which the single hardware parts are store and retrieved. In particular: * `GET /api/cots/<id>` to fetch a particular object, * `PUT /api/cots/<id>` to store a new object with some characteristics * `PATCH /api/cots/<id>`: only for some properties * `DELETE /api/cots/<id>` Mandatory fields for every category of subsystem are specified in the vocabulary itself. An example of COTS spare part is represented by this JSON, this is a backup power subsystem:  { ""id"": 1, ""object"": { ""category"": ""backup power"", ""maxWorkingTemp"": 61, ""volume"": 126, ""minWorkingTemp"": -21, ""mass"": 252, ""power"": 638, ""cost"": 10208 }, ""name"": ""2KV backup power"", ""year"": ""2015"", ""manufacturer"": ""Invented Corp."" }  This JSON is ported into a JSON-LD using this two vocabularies: one for the [spacecraft](http://ontology.projectchronos.eu/documentation/spacecraft), one for [different subsystems](http://ontology.projectchronos.eu/documentation/subsystems) :  { ""@context"": { ""spacecraft"" : ""http://ontology.projectchronos.eu/spacecraft/"", ""subsystems"" : ""http://ontology.projectchronos.eu/subsystems/"" }, ""@id"": ""/api/cots/1"", ""@type"": ""spacecraft:Subsystem_Spacecraft"", ""subsystems:subSystemType"": ""subsystems:Spacecraft_BackupPower"", ""subsystems:function"": ""Backup and restore energy if Power no. 1 goes down"", ""subsystems:isStandard"": ""Cubesat"", ""subsystems:maxWorkingTemp"": 61, ""subsystems:volume"": 126, ""subsystems:minWorkingTemp"": -21, ""subsystems:mass"": 252, ""subsystems:power"": 638, ""subsystems:cost"": 10208, ""subsystems:manufacturer"": ""Invented Corp."" }, ""skos:name"": ""2KV backup power"", ""subsystems:year"": ""2015"" }  * `/api/spacecraft/<id>`: an assembled group of COTS that can be used to make up an actual satellite. Each COTS object is categorized into a group that represents its function. For this endpoint: * `GET /api/spacecraft/<id>`: retrieve a blueprint * `PUT /api/spacecraft/<id>`: create a new blueprint * `PATCH /api/spacecraft/<id>`: emend some component of the blueprint * `DELETE /api/spacecraft/<id>`: remove ablueprint As for the subsytem objects above a JSON and a JSON-LD desctiption will be provided. These are the endpoints that need to be served by the server with the proper description provided using the HYDRA framework.",source-file | source-file | other-file | source-file | other-file | source-file | source-file | documentation-file | source-file | source-file | other-file,"A Starting Design for the Endpoints This is a more general overlook about the API's endpoints. The implementation described here is the application of the use-case no.2 described [here](https://github.com/HTTP-APIs/hydrus/issues/2#issue-206778515) in issue #2 . For the use-case no.2, the demo API we are going to develop is about Commercial Off The Shelves (COTS) spare parts for pico- and nano-satellites. Has been a recent trend in commercial space industry to develop super-light and super-compact satellites for the sake of research, prototyping, Earth observation and product testing. The kind of parts we are talking about are basically microcontrollers and processors that allows the spacecraft to operate. Each of these ""boards"" is meant to provide a function; there are 8-9 different functions (subsystems) to be carried on for the spacecraft to accomplish its mission. Some of them are critical, some other are supporting functions but likely almost every spacecraft needs almost all of them to work properly. This is a comprehensive list as they are written in the ""subsystems"" vocabulary: * propulsion * primary power * backup power * thermal active * thermal passive * structure * command and data handling * communication * attitude and navigation (AODCS) active or passive This API will serve objects related to this kind of hardware. The simple starting endpoints can be: * `/api/cots/`: from which the single hardware parts are store and retrieved. In particular: * `GET /api/cots/<id>` to fetch a particular object, * `PUT /api/cots/<id>` to store a new object with some characteristics * `PATCH /api/cots/<id>`: only for some properties * `DELETE /api/cots/<id>` Mandatory fields for every category of subsystem are specified in the vocabulary itself. An example of COTS spare part is represented by this JSON, this is a backup power subsystem:  { ""id"": 1, ""object"": { ""category"": ""backup power"", ""maxWorkingTemp"": 61, ""volume"": 126, ""minWorkingTemp"": -21, ""mass"": 252, ""power"": 638, ""cost"": 10208 }, ""name"": ""2KV backup power"", ""year"": ""2015"", ""manufacturer"": ""Invented Corp."" }  This JSON is ported into a JSON-LD using this two vocabularies: one for the [spacecraft](http://ontology.projectchronos.eu/documentation/spacecraft), one for [different subsystems](http://ontology.projectchronos.eu/documentation/subsystems) :  { ""@context"": { ""spacecraft"" : ""http://ontology.projectchronos.eu/spacecraft/"", ""subsystems"" : ""http://ontology.projectchronos.eu/subsystems/"" }, ""@id"": ""/api/cots/1"", ""@type"": ""spacecraft:Subsystem_Spacecraft"", ""subsystems:subSystemType"": ""subsystems:Spacecraft_BackupPower"", ""subsystems:function"": ""Backup and restore energy if Power no. 1 goes down"", ""subsystems:isStandard"": ""Cubesat"", ""subsystems:maxWorkingTemp"": 61, ""subsystems:volume"": 126, ""subsystems:minWorkingTemp"": -21, ""subsystems:mass"": 252, ""subsystems:power"": 638, ""subsystems:cost"": 10208, ""subsystems:manufacturer"": ""Invented Corp."" }, ""skos:name"": ""2KV backup power"", ""subsystems:year"": ""2015"" }  * `/api/spacecraft/<id>`: an assembled group of COTS that can be used to make up an actual satellite. Each COTS object is categorized into a group that represents its function. For this endpoint: * `GET /api/spacecraft/<id>`: retrieve a blueprint * `PUT /api/spacecraft/<id>`: create a new blueprint * `PATCH /api/spacecraft/<id>`: emend some component of the blueprint * `DELETE /api/spacecraft/<id>`: remove ablueprint As for the subsytem objects above a JSON and a JSON-LD desctiption will be provided. These are the endpoints that need to be served by the server with the proper description provided using the HYDRA framework. source-file source-file other-file source-file other-file source-file source-file documentation-file source-file source-file other-file",no-bug,0.9
95,hydrus,https://github.com/HTTP-APIs/hydrus/issues/95,Refactoring key validation in a dictionary body, I'm submitting a - [x] Enhancement Request.  Current Behaviour: <!-- Describe about the bug --> We are using try catch to check every key in the dictionary and assigning it to new variable. rather to validate the current payload we should have a generic function in which we can pass the key and value to check and it will return the keys or exception from that function [Current Sample code structure] (https://ibb.co/ciM4Vn)  Do you want to work on this issue ? <!-- yes/no --> yes @Mec-iS -can you provide any suggestion here,source-file,Refactoring key validation in a dictionary body  I'm submitting a - [x] Enhancement Request.  Current Behaviour: <!-- Describe about the bug --> We are using try catch to check every key in the dictionary and assigning it to new variable. rather to validate the current payload we should have a generic function in which we can pass the key and value to check and it will return the keys or exception from that function [Current Sample code structure] (https://ibb.co/ciM4Vn)  Do you want to work on this issue ? <!-- yes/no --> yes @Mec-iS -can you provide any suggestion here source-file,no-bug,0.9
473,hydrus,https://github.com/HTTP-APIs/hydrus/issues/473,Docker compose container not building," I'm submitting a - [x] bug report. - [ ] feature request.  Current Behaviour: <!-- Describe about the bug --> The `docker-compose` command gives error,  Running command git clone -q https://github.com/HTTP-APIs/hydra-python-core /tmp/pip-install-2n02rlfc/hydra-python-core fatal: unable to access 'https://github.com/HTTP-APIs/hydra-python-core/': server certificate verification failed. CAfile: none CRLfile: none ERROR: Command errored out with exit status 128: git clone -q https://github.com/HTTP-APIs/hydra-python-core /tmp/pip-install-2n02rlfc/hydra-python-core Check the logs for full command output. ERROR: Service 'hydrus_server' failed to build: The command '/bin/sh -c pip install -U pip && pip install --upgrade pip setuptools && pip install -r requirements.txt && rm -rf *' returned a non-zero code: 1  and hydrus does not serve the api. Screenshot for reference: ![image](https://user-images.githubusercontent.com/43701530/82672694-50856600-9c5e-11ea-95c6-c2ff1e514fe7.png) **NOTE**: This happens only on develop branch and not master branch.  Expected Behaviour: <!-- Describe what will happen if bug is removed --> The `docker-compose` command should have executed without any errors, and the hydrus server should serve the api.  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug --> * clone the repo * git checkout develop * docker-compose up --build  Do you want to work on this issue? <!-- yes/no --> Yes",container-file,"Docker compose container not building  I'm submitting a - [x] bug report. - [ ] feature request.  Current Behaviour: <!-- Describe about the bug --> The `docker-compose` command gives error,  Running command git clone -q https://github.com/HTTP-APIs/hydra-python-core /tmp/pip-install-2n02rlfc/hydra-python-core fatal: unable to access 'https://github.com/HTTP-APIs/hydra-python-core/': server certificate verification failed. CAfile: none CRLfile: none ERROR: Command errored out with exit status 128: git clone -q https://github.com/HTTP-APIs/hydra-python-core /tmp/pip-install-2n02rlfc/hydra-python-core Check the logs for full command output. ERROR: Service 'hydrus_server' failed to build: The command '/bin/sh -c pip install -U pip && pip install --upgrade pip setuptools && pip install -r requirements.txt && rm -rf *' returned a non-zero code: 1  and hydrus does not serve the api. Screenshot for reference: ![image](https://user-images.githubusercontent.com/43701530/82672694-50856600-9c5e-11ea-95c6-c2ff1e514fe7.png) **NOTE**: This happens only on develop branch and not master branch.  Expected Behaviour: <!-- Describe what will happen if bug is removed --> The `docker-compose` command should have executed without any errors, and the hydrus server should serve the api.  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug --> * clone the repo * git checkout develop * docker-compose up --build  Do you want to work on this issue? <!-- yes/no --> Yes container-file",no-bug,0.9
429,hydrus,https://github.com/HTTP-APIs/hydrus/issues/429,demo returns incomplete contexts," I'm submitting a - [X] bug report.  Current Behaviour: I'm exploring the hydrus demo to understand how Hydra works. From what I understand, the linked JSON-LD contexts do not provide enough information to parse a response as RDF. Requesting the `DroneCollection` returns the following JSON-LD document: jsonc // GET http://localhost:8080/serverapi/DroneCollection { ""@context"": ""/serverapi/contexts/DroneCollection.jsonld"", ""@id"": ""/serverapi/DroneCollection/"", ""@type"": ""DroneCollection"", ""members"": [], ""search"": { ""@type"": ""IriTemplate"", ""mapping"": [ { ""@type"": ""IriTemplateMapping"", ""property"": ""http://auto.schema.org/speed"", ""required"": false, ""variable"": ""DroneState[Speed]"" }, //  ], ""template"": ""/serverapi/Drone(DroneState[Speed], DroneState[Position], DroneState[Direction], DroneState[Battery], DroneState[SensorStatus], DroneState[DroneID], name, model, MaxSpeed, Sensor, pageIndex, limit, offset)"", ""variableRepresentation"": ""hydra:BasicRepresentation"" }, ""totalItems"": 0, ""view"": { ""@id"": ""/serverapi/DroneCollection?page=1"", ""@type"": ""PartialCollectionView"", ""first"": ""/serverapi/DroneCollection?page=1"", ""last"": ""/serverapi/DroneCollection?page=1"" } }  However, the linked JSON-LD context does not contain mappings for all the Hydra-specific identifiers: jsonc // GET http://localhost:8080/serverapi/contexts/DroneCollection.jsonld { ""@context"": { ""Drone"": ""vocab:Drone"", ""DroneCollection"": ""vocab:DroneCollection"", ""hydra"": ""http://www.w3.org/ns/hydra/core#"", ""members"": ""http://www.w3.org/ns/hydra/core#member"", ""vocab"": ""http://localhost:8080/serverapi/vocab#"" } }  Almost none of the Hydra-identifiers in the response (`search`, `IriTemplate`, `totalItems`, `first`, `last`, etc.) can be mapped to their URIs. The issue becomes obvious, when you paste the JSON-LD along with the JSON-LD context into the JSON-LD playground: http://tinyurl.com/rrq6cc8  Expected Behaviour: Either the JSON-LD context maps all the identifiers to their URIs or the identifiers are prefixed with `hydra:` in the document. E.g. like this: jsonc { ""@context"": ""/serverapi/contexts/DroneCollection.jsonld"", ""@id"": ""/serverapi/DroneCollection/"", ""@type"": ""DroneCollection"", ""members"": [], ""hydra:search"": { ""@type"": ""hydra:IriTemplate"", ""hydra:mapping"": [ { ""@type"": ""hydra:IriTemplateMapping"", ""hydra:property"": ""http://auto.schema.org/speed"", ""hydra:required"": false, ""hydra:variable"": ""DroneState[Speed]"" }, //  ], ""hydra:template"": ""/serverapi/Drone(DroneState[Speed], DroneState[Position], DroneState[Direction], DroneState[Battery], DroneState[SensorStatus], DroneState[DroneID], name, model, MaxSpeed, Sensor, pageIndex, limit, offset)"", ""hydra:variableRepresentation"": ""hydra:BasicRepresentation"" }, ""hydra:totalItems"": 0, ""hydra:view"": { ""@id"": ""/serverapi/DroneCollection?page=1"", ""@type"": ""hydra:PartialCollectionView"", ""hydra:first"": ""/serverapi/DroneCollection?page=1"", ""hydra:last"": ""/serverapi/DroneCollection?page=1"" } }  Here's the JSON-LD playground for this document: http://tinyurl.com/r2oje6q The same applies to other responses, e.g. the `Drone` representation, which links to the same JSON-LD context as the collection leaving `MaxSpeed`, `Sensor`, `model` and `name` undefined: jsonc // GET http://localhost:8080/serverapi/DroneCollection/9299bee8-bdc6-4d6f-9f48-f5884b3ef29c { ""@context"": ""/serverapi/contexts/DroneCollection.jsonld"", ""@id"": ""/serverapi/DroneCollection/9299bee8-bdc6-4d6f-9f48-f5884b3ef29c"", ""@type"": ""Drone"", ""MaxSpeed"": ""100"", ""Sensor"": ""Temperature"", ""model"": ""xyz"", ""name"": ""Drone 1"" }   Steps to reproduce: - Start the demo according to README - Authenticate - `GET http://localhost:8080/serverapi/DroneCollection` - `GET http://localhost:8080/serverapi/contexts/DroneCollection.jsonld` - Copy/paste both, document and context, into the JSON-LD playground (or click link above)  Do you want to work on this issue? no, I'm not familiar with python and only wanted to learn about Hydra.",source-file | source-file | source-file | source-file | source-file | test-file,"demo returns incomplete contexts  I'm submitting a - [X] bug report.  Current Behaviour: I'm exploring the hydrus demo to understand how Hydra works. From what I understand, the linked JSON-LD contexts do not provide enough information to parse a response as RDF. Requesting the `DroneCollection` returns the following JSON-LD document: jsonc // GET http://localhost:8080/serverapi/DroneCollection { ""@context"": ""/serverapi/contexts/DroneCollection.jsonld"", ""@id"": ""/serverapi/DroneCollection/"", ""@type"": ""DroneCollection"", ""members"": [], ""search"": { ""@type"": ""IriTemplate"", ""mapping"": [ { ""@type"": ""IriTemplateMapping"", ""property"": ""http://auto.schema.org/speed"", ""required"": false, ""variable"": ""DroneState[Speed]"" }, //  ], ""template"": ""/serverapi/Drone(DroneState[Speed], DroneState[Position], DroneState[Direction], DroneState[Battery], DroneState[SensorStatus], DroneState[DroneID], name, model, MaxSpeed, Sensor, pageIndex, limit, offset)"", ""variableRepresentation"": ""hydra:BasicRepresentation"" }, ""totalItems"": 0, ""view"": { ""@id"": ""/serverapi/DroneCollection?page=1"", ""@type"": ""PartialCollectionView"", ""first"": ""/serverapi/DroneCollection?page=1"", ""last"": ""/serverapi/DroneCollection?page=1"" } }  However, the linked JSON-LD context does not contain mappings for all the Hydra-specific identifiers: jsonc // GET http://localhost:8080/serverapi/contexts/DroneCollection.jsonld { ""@context"": { ""Drone"": ""vocab:Drone"", ""DroneCollection"": ""vocab:DroneCollection"", ""hydra"": ""http://www.w3.org/ns/hydra/core#"", ""members"": ""http://www.w3.org/ns/hydra/core#member"", ""vocab"": ""http://localhost:8080/serverapi/vocab#"" } }  Almost none of the Hydra-identifiers in the response (`search`, `IriTemplate`, `totalItems`, `first`, `last`, etc.) can be mapped to their URIs. The issue becomes obvious, when you paste the JSON-LD along with the JSON-LD context into the JSON-LD playground: http://tinyurl.com/rrq6cc8  Expected Behaviour: Either the JSON-LD context maps all the identifiers to their URIs or the identifiers are prefixed with `hydra:` in the document. E.g. like this: jsonc { ""@context"": ""/serverapi/contexts/DroneCollection.jsonld"", ""@id"": ""/serverapi/DroneCollection/"", ""@type"": ""DroneCollection"", ""members"": [], ""hydra:search"": { ""@type"": ""hydra:IriTemplate"", ""hydra:mapping"": [ { ""@type"": ""hydra:IriTemplateMapping"", ""hydra:property"": ""http://auto.schema.org/speed"", ""hydra:required"": false, ""hydra:variable"": ""DroneState[Speed]"" }, //  ], ""hydra:template"": ""/serverapi/Drone(DroneState[Speed], DroneState[Position], DroneState[Direction], DroneState[Battery], DroneState[SensorStatus], DroneState[DroneID], name, model, MaxSpeed, Sensor, pageIndex, limit, offset)"", ""hydra:variableRepresentation"": ""hydra:BasicRepresentation"" }, ""hydra:totalItems"": 0, ""hydra:view"": { ""@id"": ""/serverapi/DroneCollection?page=1"", ""@type"": ""hydra:PartialCollectionView"", ""hydra:first"": ""/serverapi/DroneCollection?page=1"", ""hydra:last"": ""/serverapi/DroneCollection?page=1"" } }  Here's the JSON-LD playground for this document: http://tinyurl.com/r2oje6q The same applies to other responses, e.g. the `Drone` representation, which links to the same JSON-LD context as the collection leaving `MaxSpeed`, `Sensor`, `model` and `name` undefined: jsonc // GET http://localhost:8080/serverapi/DroneCollection/9299bee8-bdc6-4d6f-9f48-f5884b3ef29c { ""@context"": ""/serverapi/contexts/DroneCollection.jsonld"", ""@id"": ""/serverapi/DroneCollection/9299bee8-bdc6-4d6f-9f48-f5884b3ef29c"", ""@type"": ""Drone"", ""MaxSpeed"": ""100"", ""Sensor"": ""Temperature"", ""model"": ""xyz"", ""name"": ""Drone 1"" }   Steps to reproduce: - Start the demo according to README - Authenticate - `GET http://localhost:8080/serverapi/DroneCollection` - `GET http://localhost:8080/serverapi/contexts/DroneCollection.jsonld` - Copy/paste both, document and context, into the JSON-LD playground (or click link above)  Do you want to work on this issue? no, I'm not familiar with python and only wanted to learn about Hydra. source-file source-file source-file source-file source-file test-file",bug,0.95
462,hydrus,https://github.com/HTTP-APIs/hydrus/issues/462,Possible mistake while refactoring," I'm submitting a - [x] bug report. - [ ] feature request.  Current Behaviour: <!-- Describe about the bug --> @xadahiya I came across this while I was refactoring hydrus. I am referencing the commit https://github.com/HTTP-APIs/hydrus/commit/c0b492982b7093b38084d59afcfbbc52bb73d5e5#diff-57bc8a5a89375175a4bf37d573213377R353 (by @de-sh )which is already merged. In the changes to `hydrus/resources.py` under the POST method of the Item Collection class, line 353 the change made is  headers_ = [{""Location"": get_hydrus_server_url() + get_api_name() + ""/"" + path + ""/""}]  to  headers_ = [{""Location"": ""{}/{}/"".format(get_hydrus_server_url(),get_api_name(),path)}]   Expected Behaviour: <!-- Describe what will happen if bug is removed --> I think that there has been a mistake while refactoring as the `path` variable is not correctly used in the newly formated string. I think it should be (notice the extra `{}` in the string formating.  headers_ = [{""Location"": ""{}{}/{}/"".format(get_hydrus_server_url(),get_api_name(),path)}]   Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug -->  Do you want to work on this issue? <!-- yes/no --> Yes",source-file | source-file | source-file,"Possible mistake while refactoring  I'm submitting a - [x] bug report. - [ ] feature request.  Current Behaviour: <!-- Describe about the bug --> @xadahiya I came across this while I was refactoring hydrus. I am referencing the commit https://github.com/HTTP-APIs/hydrus/commit/c0b492982b7093b38084d59afcfbbc52bb73d5e5#diff-57bc8a5a89375175a4bf37d573213377R353 (by @de-sh )which is already merged. In the changes to `hydrus/resources.py` under the POST method of the Item Collection class, line 353 the change made is  headers_ = [{""Location"": get_hydrus_server_url() + get_api_name() + ""/"" + path + ""/""}]  to  headers_ = [{""Location"": ""{}/{}/"".format(get_hydrus_server_url(),get_api_name(),path)}]   Expected Behaviour: <!-- Describe what will happen if bug is removed --> I think that there has been a mistake while refactoring as the `path` variable is not correctly used in the newly formated string. I think it should be (notice the extra `{}` in the string formating.  headers_ = [{""Location"": ""{}{}/{}/"".format(get_hydrus_server_url(),get_api_name(),path)}]   Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug -->  Do you want to work on this issue? <!-- yes/no --> Yes source-file source-file source-file",bug,0.85
5,hydrus,https://github.com/HTTP-APIs/hydrus/issues/5,Independent server and client,"In #2, @Mec-iS wrote > A HYDRA server that can serve data and metadata to a client (this layer can be split into a traditional lower level server relying on a graph database plus a ""HYDRA middleware""), > A client that can ""understand"" HYDRA metadata and connect to HYDRA-enabled services, and possibly ""learn and remember"" about past interactions with other services to store its own set of concepts to be used in the usage's domain. I think we *must* insist on developing the client and server as independently as possible. Ideally, different people would work on each part. If we end up with tightly coupled client and server, we will fail to demonstrate the value of Hydra.",source-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file,"Independent server and client In #2, @Mec-iS wrote > A HYDRA server that can serve data and metadata to a client (this layer can be split into a traditional lower level server relying on a graph database plus a ""HYDRA middleware""), > A client that can ""understand"" HYDRA metadata and connect to HYDRA-enabled services, and possibly ""learn and remember"" about past interactions with other services to store its own set of concepts to be used in the usage's domain. I think we *must* insist on developing the client and server as independently as possible. Ideally, different people would work on each part. If we end up with tightly coupled client and server, we will fail to demonstrate the value of Hydra. source-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file",no-bug,0.9
203,hydrus,https://github.com/HTTP-APIs/hydrus/issues/203,Single abstract method for OpenAPI parser," I'm submitting a - [ ] bug report. - [x] feature request.  Current Behaviour: <!-- Describe about the bug --> In OpenAPI parser, there are global variables such as `classAndClassDefinition` and `definitionSet` in L214 and L215 respectively. These variables are not explicitly declared as global, and are defined under the condition `if __name__ == ""__main__""`. In case the methods of the parser are imported from another script, this portion of code would not run, thus causing the declarations/initialisation of the variables to be ignored and causing errors in the code. It is advisable to not use global variables unless it is absolutely necessary. Any user must otherwise create such global variables before he/she actually uses the methods defined in the parser.  Expected Behaviour: <!-- Describe what will happen if bug is removed --> There should be a much more abstract method that takes an OpenAPI spec(as a json object) and returns a Hydra API Documentation(as a json object). This method must take care of all the necessary declarations and initialisation and must pass variables as parameters, rather than using global declarations. Once the objects have been modified, they can be returned to the parent method using the `return` statement. Please note that you can return multiple objects in using the `return` statement in Python.  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug -->  Do you want to work on this issue? <!-- yes/no --> No",source-file,"Single abstract method for OpenAPI parser  I'm submitting a - [ ] bug report. - [x] feature request.  Current Behaviour: <!-- Describe about the bug --> In OpenAPI parser, there are global variables such as `classAndClassDefinition` and `definitionSet` in L214 and L215 respectively. These variables are not explicitly declared as global, and are defined under the condition `if __name__ == ""__main__""`. In case the methods of the parser are imported from another script, this portion of code would not run, thus causing the declarations/initialisation of the variables to be ignored and causing errors in the code. It is advisable to not use global variables unless it is absolutely necessary. Any user must otherwise create such global variables before he/she actually uses the methods defined in the parser.  Expected Behaviour: <!-- Describe what will happen if bug is removed --> There should be a much more abstract method that takes an OpenAPI spec(as a json object) and returns a Hydra API Documentation(as a json object). This method must take care of all the necessary declarations and initialisation and must pass variables as parameters, rather than using global declarations. Once the objects have been modified, they can be returned to the parent method using the `return` statement. Please note that you can return multiple objects in using the `return` statement in Python.  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug -->  Do you want to work on this issue? <!-- yes/no --> No source-file",no-bug,0.9
102,hydrus,https://github.com/HTTP-APIs/hydrus/issues/102,Hydrus dependencies are not installed automatically with distutils in setup.py, I'm submitting a - [x] bug report. - [ ] feature request.  Current Behaviour: distutils does not support `install_requires()`. It gives a warning when you try to install hydrus using setup.py and the dependencies are not installed. The user will have to install the dependencies using the requirements.txt file.  Expected Behaviour: All the dependencies must be installed automatically when we setup hydrus.  Steps to reproduce: Run the setup.py file as `python3 setup.py install`.  Do you want to work on this issue? yes We can move to setuptools (https://packaging.python.org/key_projects/#setuptools) which supports `install_requires()` and will further ease the process of setting up hydrus for pip as a package. https://packaging.python.org/discussions/install-requires-vs-requirements/.,source-file | source-file | source-file,Hydrus dependencies are not installed automatically with distutils in setup.py  I'm submitting a - [x] bug report. - [ ] feature request.  Current Behaviour: distutils does not support `install_requires()`. It gives a warning when you try to install hydrus using setup.py and the dependencies are not installed. The user will have to install the dependencies using the requirements.txt file.  Expected Behaviour: All the dependencies must be installed automatically when we setup hydrus.  Steps to reproduce: Run the setup.py file as `python3 setup.py install`.  Do you want to work on this issue? yes We can move to setuptools (https://packaging.python.org/key_projects/#setuptools) which supports `install_requires()` and will further ease the process of setting up hydrus for pip as a package. https://packaging.python.org/discussions/install-requires-vs-requirements/. source-file source-file source-file,no-bug,0.95
12,hydrus,https://github.com/HTTP-APIs/hydrus/issues/12,Write views,"Write the REST API views to serve the data with method GET, POST, PUT as defined in #3",source-file | source-file | source-file | test-file,"Write views Write the REST API views to serve the data with method GET, POST, PUT as defined in #3 source-file source-file source-file test-file",no-bug,0.9
74,hydrus,https://github.com/HTTP-APIs/hydrus/issues/74,Error while Setup the Project,"The Project is using some files from inside a package directory, but that directory is not listed as a package due to which it is throwing import error while executing the `main.py` script. OS : Debian 9 Python 2.7 Screenshot : ![image](https://user-images.githubusercontent.com/18033231/36127576-3e7d73f2-1084-11e8-8268-19dc6f2cb141.png)",source-file | source-file | source-file | source-file | source-file | source-file,"Error while Setup the Project The Project is using some files from inside a package directory, but that directory is not listed as a package due to which it is throwing import error while executing the `main.py` script. OS : Debian 9 Python 2.7 Screenshot : ![image](https://user-images.githubusercontent.com/18033231/36127576-3e7d73f2-1084-11e8-8268-19dc6f2cb141.png) source-file source-file source-file source-file source-file source-file",no-bug,0.95
4,hydrus,https://github.com/HTTP-APIs/hydrus/issues/4,Choosing a framework for backend/server,"To the best of my knowledge, here are some of the key factors I think you should considered while reviewing python based web frameworks: - Framework Architectures - Community Support - Supported Tools - Robustness and Scalability - Flexibility - Learning curve The three frameworks that are most used out there would definitely be **Django**, **Pyramid** and **Flask** I would like for everyones opinions on which framework would be suitable to build the demo web application. Here is what I think: - Both Django and Pyramid follow an MVC based architecture, this allows them to isolate their data, views and controllers natively. Both these frameworks also insist on good coding practices when it comes to arrangement of code. Flask on the other hand is a micro-framework, as such everything must be defined from scratch, this however, allows more flexibility, although from my experience the other two have good workarounds for almost everything. - Django has by far the largest community along with lots of documentation and a number of tutorials, including their own well documented tutorials that are extremely useful in getting started. I don't know much about Pyramid's documentation, maybe someone else can comment upon it. Flask has minimal basic documentation and there are a number of tutorials for it too. Given the ease of use of Flask, much documentation isn't needed for developement. - Django and Pyramid come with a number of built in tools to help the developement process. It also reduces developement time by a large amount by having server implementations such as security, requests and access control built in. Flask offers the basic necessities in the same areas, but additional features may need to be implemented. - Robustness and scalability wise, both Django and Pyramid beat Flask. Flask is a micro-framework which was essentially designed for small scale applications. Although I haven't used Flask myself, this is what is mentioned on their website. - Learning curve of all the three would be the easiest for Flask, with most people being able to start developement almost instantly. Django has a steep learning curve and I don't have much knowledge about Pyramid. Given the fact that this project would lay the foundation stone for something bigger, I would suggest using something robust that would be both extendable and scalable. There is no saying as to what the project might branch out into in the future and as such, a strong foundation would be recommended. Keeping this in mind, I would suggest that Django be used for developement. This is purely my opinion and I would like for alternate views on the same. Extremely sorry if this thread was unnecessary, but I felt that it was better to have some sort of discussion to get things started.",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | test-file | source-file,"Choosing a framework for backend/server To the best of my knowledge, here are some of the key factors I think you should considered while reviewing python based web frameworks: - Framework Architectures - Community Support - Supported Tools - Robustness and Scalability - Flexibility - Learning curve The three frameworks that are most used out there would definitely be **Django**, **Pyramid** and **Flask** I would like for everyones opinions on which framework would be suitable to build the demo web application. Here is what I think: - Both Django and Pyramid follow an MVC based architecture, this allows them to isolate their data, views and controllers natively. Both these frameworks also insist on good coding practices when it comes to arrangement of code. Flask on the other hand is a micro-framework, as such everything must be defined from scratch, this however, allows more flexibility, although from my experience the other two have good workarounds for almost everything. - Django has by far the largest community along with lots of documentation and a number of tutorials, including their own well documented tutorials that are extremely useful in getting started. I don't know much about Pyramid's documentation, maybe someone else can comment upon it. Flask has minimal basic documentation and there are a number of tutorials for it too. Given the ease of use of Flask, much documentation isn't needed for developement. - Django and Pyramid come with a number of built in tools to help the developement process. It also reduces developement time by a large amount by having server implementations such as security, requests and access control built in. Flask offers the basic necessities in the same areas, but additional features may need to be implemented. - Robustness and scalability wise, both Django and Pyramid beat Flask. Flask is a micro-framework which was essentially designed for small scale applications. Although I haven't used Flask myself, this is what is mentioned on their website. - Learning curve of all the three would be the easiest for Flask, with most people being able to start developement almost instantly. Django has a steep learning curve and I don't have much knowledge about Pyramid. Given the fact that this project would lay the foundation stone for something bigger, I would suggest using something robust that would be both extendable and scalable. There is no saying as to what the project might branch out into in the future and as such, a strong foundation would be recommended. Keeping this in mind, I would suggest that Django be used for developement. This is purely my opinion and I would like for alternate views on the same. Extremely sorry if this thread was unnecessary, but I felt that it was better to have some sort of discussion to get things started. other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file test-file source-file",no-bug,0.95
9,hydrus,https://github.com/HTTP-APIs/hydrus/issues/9,Evolving database models,"After a starting implementation that applies some nice basic concepts, we need to find the right way for improving the models. ## Temporary models segregation I segregated the models for properties (`AbstractPropery` and `Property`) but I don't exclude that in the future they will be in the same table as records that inherits from the same base model. A similar thing can be designed for records in the `Graph` relation, we may have three different ""kinds"" of triples that inherits from the same ""Triple"" class and are then stored in the same table. ## How to implement Graph For `Graph` that is really sparse a this moment. At first I came out with a solution like: > Add an Entity() class to build up every type of triple (instantiated, abstracted, terminated). To have for every record something like a triple: >> (Entity(Instance('A')), Entity(Property('B')), Entity(Terminal('C'. > Or split the triple into tuples: >> (Entity(Instance('A')), Entity(Property('B' , (Entity(Property('B')), Entity(Terminal('C'. > These solutions can lead to difficulties in querying by joining though. Check this interesting [video about optimizing hashmaps](https://www.youtube.com/watch?v=npw4s1QTmPg) for ideas.",documentation-file | documentation-file | other-file | source-file | source-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Evolving database models After a starting implementation that applies some nice basic concepts, we need to find the right way for improving the models. ## Temporary models segregation I segregated the models for properties (`AbstractPropery` and `Property`) but I don't exclude that in the future they will be in the same table as records that inherits from the same base model. A similar thing can be designed for records in the `Graph` relation, we may have three different ""kinds"" of triples that inherits from the same ""Triple"" class and are then stored in the same table. ## How to implement Graph For `Graph` that is really sparse a this moment. At first I came out with a solution like: > Add an Entity() class to build up every type of triple (instantiated, abstracted, terminated). To have for every record something like a triple: >> (Entity(Instance('A')), Entity(Property('B')), Entity(Terminal('C'. > Or split the triple into tuples: >> (Entity(Instance('A')), Entity(Property('B' , (Entity(Property('B')), Entity(Terminal('C'. > These solutions can lead to difficulties in querying by joining though. Check this interesting [video about optimizing hashmaps](https://www.youtube.com/watch?v=npw4s1QTmPg) for ideas. documentation-file documentation-file other-file source-file source-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
11,hydrus,https://github.com/HTTP-APIs/hydrus/issues/11,Define a procedure to declare/generate ApiDocumentation,"Now that we have basic models and some kind of structuring of data, we need to define the `ApiDocument` endpoint.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Define a procedure to declare/generate ApiDocumentation Now that we have basic models and some kind of structuring of data, we need to define the `ApiDocument` endpoint. source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
182,hydrus,https://github.com/HTTP-APIs/hydrus/issues/182,Port number is not specified for server endpoint URL, I'm submitting a - [x] bug report.  Current Behaviour: The port number is not specified for the API endpoint URL the server is exposed to. It may lead to a scenario where the client is unable to find the server or try to access a different program in the host machine.  Expected Behaviour: The port number of the server endpoint should be specified in the server URL so that client is able to connect to the server without any errors.  Steps to reproduce: - Run an instance of the hydrus server any port (the default `8080` also works) - Access it using a hydra enabled client with specifying the port number (e.g `http:127.0.0.1:8080/localhost` - It will not be able to find the rest of the resources apart from that which is present at `http:127.0.0.1:8080/localhost`  Do you want to work on this issue? yes,source-file | source-file,Port number is not specified for server endpoint URL  I'm submitting a - [x] bug report.  Current Behaviour: The port number is not specified for the API endpoint URL the server is exposed to. It may lead to a scenario where the client is unable to find the server or try to access a different program in the host machine.  Expected Behaviour: The port number of the server endpoint should be specified in the server URL so that client is able to connect to the server without any errors.  Steps to reproduce: - Run an instance of the hydrus server any port (the default `8080` also works) - Access it using a hydra enabled client with specifying the port number (e.g `http:127.0.0.1:8080/localhost` - It will not be able to find the rest of the resources apart from that which is present at `http:127.0.0.1:8080/localhost`  Do you want to work on this issue? yes source-file source-file,bug,0.85
324,hydrus,https://github.com/HTTP-APIs/hydrus/issues/324,Remove .DS_Store files (and others) and add them to gitignore,"There are some `.DS_Store` files in the repository, any non-used file shall be removed.",other-file | other-file,"Remove .DS_Store files (and others) and add them to gitignore There are some `.DS_Store` files in the repository, any non-used file shall be removed. other-file other-file",no-bug,1.0
2,hydrus,https://github.com/HTTP-APIs/hydrus/issues/2,General Starting Introduction To The Project,"As the first students expressed interest in the project, I write here some more insights about the things at this very early stage. The objective for this project is to create a demo Web API implementing the [HYDRA draft](http://www.hydra-cg.com/spec/latest/core/), that is an RDF-based framework. The entities defined in the specs are meant to describe the structure and usage of a generic Web API, to let an HYDRA-enabled (""intelligent"" or ""smart"") client to connect to the API's entrypoint and automatically find out where and how to find the needed data. In this scenario the layers involved are: A. HYDRA **server** that can serve data and metadata to a client (this layer can be split into a traditional lower level server relying on a graph database plus a ""HYDRA middleware""), B. **client** that can ""understand"" HYDRA metadata and connect to HYDRA-enabled services, and possibly ""learn and remember"" about past interactions with other services to store its own set of concepts to be used in the usage's domain. The objective is generally to let different HYDRA-enabled clients to exchange data each other. These clients can be running on any kind of machine, but the focus for this automation are IoT (connected) devices (industrial or consumer or research). Usage scenario: * the IoT client X needs to know at which TIME the OPERATION Y was performed by the DEVICE Z. Its starting knowledge it is only about the API entrypoint's URI. * the client X fetches the metadata from the entrypoint, it finds out that to get TIME FOR Y ON Z it needs to request the endpoint http://entrypoint/gettime with method GET and passing Y, Z as parameters * the client makes the request to pull the data Different concepts and classes are involved. An RDF domain has to be defined for the metadata exchange to work. To make the demo interesting I suggested we should leverage space exploration and astronomy, so the graph can be based on these vocabularies: https://github.com/chronos-pramantha/RDFvocab/blob/master/ld%2Bjson/Spacecraft.json I can suggest possible operations to be requested to the API. Resources are well connected to popular repositories, so we can reach a great amount of knowledge without storing too much. A very good starting design for the server is https://github.com/antoniogarrote/levanzo A Python implementation for the <s>server</s> client: https://github.com/pchampin/hydra-py Please enlist questions and comments below. Some resources: * a [blog post](http://blog.theamazingrando.com/in-band-vs-out-of-band.html) about documenting an Web API and programming a client PS. the stack to be used has to be decided yet. We should tend to use a full-Python implementation, except for the lower layer where a graph database is required, we are free to experiment so we can suggest anything in the beginning. At first impression I would avoid Triple Stores and try to use a Graph Database or try to prototype something with Apache TinkerPop or also Spark GraphX, to gain in flexibility to switch to different solutions. At first I would prefer to not get concerned into stability and scalability but just try to reach the first working tool, to let the things to be iterated. UPDATE: To have a better insight, one of the proposed design is described at #3 UPDATE: There are different possible designs that I am proposing. I would like to discuss with you all students and mentors which one is the most interesting and viable: 1. (Astronomy-based) the one you have written about is an idea coming form the quite recent development brought by planetary science about exoplanets. If you have a list of star systems with some planets observed, you can have your REST API to create the observed star and the observed planets orbiting that star. This implementation uses the Astronomy vocabulary. 2. (Engineering-based) the one described in #3 is instead the first idea I had and it is about designing simulated spacecraft spare parts (Cubesat's COTS) and serve these parts using a REST API. In this case the user could create his/her own parts and put them together (with physical constraints applied) to build its own spacecraft. This implementation uses the Spacecraft and SubSystems vocabulary. 3. (NLP based) an idea about a semantic engine that can translate human questions about the Solar System into query for the no.1 above and reply consistently; i.e. ""How bigger is Jupiter compared to Earth?"" from the user, and the server/client able to reply ""Earth has a mass of 5.97  10^24 kg. Jupiter has a mass of 1.898610^27 kg"". UPDATE: Gitter chat available [here](https://gitter.im/HTTP-APIs/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link) UPDATE: Check also this [architectural proposal](https://github.com/RubenVerborgh/Hydra-Architecture-Diagram)",source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | documentation-file | database-file,"General Starting Introduction To The Project As the first students expressed interest in the project, I write here some more insights about the things at this very early stage. The objective for this project is to create a demo Web API implementing the [HYDRA draft](http://www.hydra-cg.com/spec/latest/core/), that is an RDF-based framework. The entities defined in the specs are meant to describe the structure and usage of a generic Web API, to let an HYDRA-enabled (""intelligent"" or ""smart"") client to connect to the API's entrypoint and automatically find out where and how to find the needed data. In this scenario the layers involved are: A. HYDRA **server** that can serve data and metadata to a client (this layer can be split into a traditional lower level server relying on a graph database plus a ""HYDRA middleware""), B. **client** that can ""understand"" HYDRA metadata and connect to HYDRA-enabled services, and possibly ""learn and remember"" about past interactions with other services to store its own set of concepts to be used in the usage's domain. The objective is generally to let different HYDRA-enabled clients to exchange data each other. These clients can be running on any kind of machine, but the focus for this automation are IoT (connected) devices (industrial or consumer or research). Usage scenario: * the IoT client X needs to know at which TIME the OPERATION Y was performed by the DEVICE Z. Its starting knowledge it is only about the API entrypoint's URI. * the client X fetches the metadata from the entrypoint, it finds out that to get TIME FOR Y ON Z it needs to request the endpoint http://entrypoint/gettime with method GET and passing Y, Z as parameters * the client makes the request to pull the data Different concepts and classes are involved. An RDF domain has to be defined for the metadata exchange to work. To make the demo interesting I suggested we should leverage space exploration and astronomy, so the graph can be based on these vocabularies: https://github.com/chronos-pramantha/RDFvocab/blob/master/ld%2Bjson/Spacecraft.json I can suggest possible operations to be requested to the API. Resources are well connected to popular repositories, so we can reach a great amount of knowledge without storing too much. A very good starting design for the server is https://github.com/antoniogarrote/levanzo A Python implementation for the <s>server</s> client: https://github.com/pchampin/hydra-py Please enlist questions and comments below. Some resources: * a [blog post](http://blog.theamazingrando.com/in-band-vs-out-of-band.html) about documenting an Web API and programming a client PS. the stack to be used has to be decided yet. We should tend to use a full-Python implementation, except for the lower layer where a graph database is required, we are free to experiment so we can suggest anything in the beginning. At first impression I would avoid Triple Stores and try to use a Graph Database or try to prototype something with Apache TinkerPop or also Spark GraphX, to gain in flexibility to switch to different solutions. At first I would prefer to not get concerned into stability and scalability but just try to reach the first working tool, to let the things to be iterated. UPDATE: To have a better insight, one of the proposed design is described at #3 UPDATE: There are different possible designs that I am proposing. I would like to discuss with you all students and mentors which one is the most interesting and viable: 1. (Astronomy-based) the one you have written about is an idea coming form the quite recent development brought by planetary science about exoplanets. If you have a list of star systems with some planets observed, you can have your REST API to create the observed star and the observed planets orbiting that star. This implementation uses the Astronomy vocabulary. 2. (Engineering-based) the one described in #3 is instead the first idea I had and it is about designing simulated spacecraft spare parts (Cubesat's COTS) and serve these parts using a REST API. In this case the user could create his/her own parts and put them together (with physical constraints applied) to build its own spacecraft. This implementation uses the Spacecraft and SubSystems vocabulary. 3. (NLP based) an idea about a semantic engine that can translate human questions about the Solar System into query for the no.1 above and reply consistently; i.e. ""How bigger is Jupiter compared to Earth?"" from the user, and the server/client able to reply ""Earth has a mass of 5.97  10^24 kg. Jupiter has a mass of 1.898610^27 kg"". UPDATE: Gitter chat available [here](https://gitter.im/HTTP-APIs/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link) UPDATE: Check also this [architectural proposal](https://github.com/RubenVerborgh/Hydra-Architecture-Diagram) source-file documentation-file source-file source-file source-file source-file source-file source-file source-file test-file test-file documentation-file database-file",no-bug,0.95
60,hydrus,https://github.com/HTTP-APIs/hydrus/issues/60,Implement type annotations using mypy,Try to refactor the codebase by implementing type annotations and type checking before runtime using `mypy`,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Implement type annotations using mypy Try to refactor the codebase by implementing type annotations and type checking before runtime using `mypy` source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file test-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file test-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file test-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file test-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
128,hydrus,https://github.com/HTTP-APIs/hydrus/issues/128,Missing mypy type annotations, I'm submitting a - [X] bug report.  Current Behaviour: <!-- Describe about the bug --> Mypy type annotations in some files are gone after merging #117  Expected Behaviour: <!-- Describe what will happen if bug is removed --> All files should have mypy type annotations  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug --> See app.py and several other files,source-file | source-file,Missing mypy type annotations  I'm submitting a - [X] bug report.  Current Behaviour: <!-- Describe about the bug --> Mypy type annotations in some files are gone after merging #117  Expected Behaviour: <!-- Describe what will happen if bug is removed --> All files should have mypy type annotations  Steps to reproduce: <!-- If you can then please provide the steps to reproduce the bug --> See app.py and several other files source-file source-file,no-bug,0.9
