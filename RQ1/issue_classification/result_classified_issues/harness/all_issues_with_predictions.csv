issue_no,repo,issue_url,title,description,patched_file_types,text_for_topic_modeling,prediction,confidence
3453,harness,https://github.com/harness/harness/issues/3453,[docs] set GITNESS_PRINCIPAL_ADMIN_EMAIL,"with docker image `harness/gitness:latest` after the [remove default Admin account /environment variables](https://github.com/harness/gitness/commit/4c90cec3e59d9218a606c4b533688ff96569503f), the [doc page](https://docs.gitness.com/installation/settings) should be update to include the newly required `GITNESS_PRINCIPAL_ADMIN_EMAIL` env var bash docker run -d \ -e GITNESS_PRINCIPAL_ADMIN_EMAIL=mail@example.com \ -e GITNESS_PRINCIPAL_ADMIN_PASSWORD=correct-horse-battery-staple \ -e GITNESS_USER_SIGNUP_ENABLED=false \ -p 3000:3000 \ -v /var/run/docker.sock:/var/run/docker.sock \ -v /tmp/gitness:/data \ --name gitness \ --restart always \ harness/gitness  Otherwise: > gitness: error: encountered an error while bootstrapping the system: failed to setup admin user: failed to set up admin user: config.Principal.Admin.Email is required, try --help",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file,"[docs] set GITNESS_PRINCIPAL_ADMIN_EMAIL with docker image `harness/gitness:latest` after the [remove default Admin account /environment variables](https://github.com/harness/gitness/commit/4c90cec3e59d9218a606c4b533688ff96569503f), the [doc page](https://docs.gitness.com/installation/settings) should be update to include the newly required `GITNESS_PRINCIPAL_ADMIN_EMAIL` env var bash docker run -d \ -e GITNESS_PRINCIPAL_ADMIN_EMAIL=mail@example.com \ -e GITNESS_PRINCIPAL_ADMIN_PASSWORD=correct-horse-battery-staple \ -e GITNESS_USER_SIGNUP_ENABLED=false \ -p 3000:3000 \ -v /var/run/docker.sock:/var/run/docker.sock \ -v /tmp/gitness:/data \ --name gitness \ --restart always \ harness/gitness  Otherwise: > gitness: error: encountered an error while bootstrapping the system: failed to setup admin user: failed to set up admin user: config.Principal.Admin.Email is required, try --help other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file",no-bug,0.9
3422,harness,https://github.com/harness/harness/issues/3422,Docker-in-Docker sample don't works,"pipeline: yml kind: pipeline spec: stages: - type: ci spec: volumes: - name: dockersock spec: {} type: temp steps: - name: dind type: background spec: container: image: docker:dind privileged: true mount: - name: dockersock path: /var/run - name: test type: run spec: container: docker:dind mount: - name: dockersock path: /var/run script: |- sleep 5 docker ps -a  compose.yml yml version: '3.3' services: gitness: volumes: - '/var/run/docker.sock:/var/run/docker.sock' cap_add: - SYS_ADMIN - NET_ADMIN privileged: true image: harness/gitness  dind logs:  Certificate request self-signature ok subject=CN = docker:dind server /certs/server/cert.pem: OK Certificate request self-signature ok subject=CN = docker:dind client /certs/client/cert.pem: OK ip: can't find device 'ip_tables' ip_tables 32768 11 iptable_mangle,iptable_nat,iptable_filter x_tables 40960 26 xt_state,xt_REDIRECT,xt_ipvs,xt_policy,xt_bpf,iptable_mangle,xt_u32,xt_multiport,xt_nat,xt_MASQUERADE,xt_mark,ip6t_REJECT,xt_hl,ip6t_rt,ipt_REJECT,xt_LOG,xt_comment,xt_limit,xt_addrtype,xt_tcpudp,ip6table_filter,ip6_tables,xt_recent,xt_conntrack,iptable_filter,ip_tables modprobe: can't change directory to '/lib/modules': No such file or directory mount: permission denied (are you root?) Could not mount /sys/kernel/security. AppArmor detection and --privileged mode might break. mount: permission denied (are you root?) ",source-file | source-file | test-file | source-file | source-file,"Docker-in-Docker sample don't works pipeline: yml kind: pipeline spec: stages: - type: ci spec: volumes: - name: dockersock spec: {} type: temp steps: - name: dind type: background spec: container: image: docker:dind privileged: true mount: - name: dockersock path: /var/run - name: test type: run spec: container: docker:dind mount: - name: dockersock path: /var/run script: |- sleep 5 docker ps -a  compose.yml yml version: '3.3' services: gitness: volumes: - '/var/run/docker.sock:/var/run/docker.sock' cap_add: - SYS_ADMIN - NET_ADMIN privileged: true image: harness/gitness  dind logs:  Certificate request self-signature ok subject=CN = docker:dind server /certs/server/cert.pem: OK Certificate request self-signature ok subject=CN = docker:dind client /certs/client/cert.pem: OK ip: can't find device 'ip_tables' ip_tables 32768 11 iptable_mangle,iptable_nat,iptable_filter x_tables 40960 26 xt_state,xt_REDIRECT,xt_ipvs,xt_policy,xt_bpf,iptable_mangle,xt_u32,xt_multiport,xt_nat,xt_MASQUERADE,xt_mark,ip6t_REJECT,xt_hl,ip6t_rt,ipt_REJECT,xt_LOG,xt_comment,xt_limit,xt_addrtype,xt_tcpudp,ip6table_filter,ip6_tables,xt_recent,xt_conntrack,iptable_filter,ip_tables modprobe: can't change directory to '/lib/modules': No such file or directory mount: permission denied (are you root?) Could not mount /sys/kernel/security. AppArmor detection and --privileged mode might break. mount: permission denied (are you root?)  source-file source-file test-file source-file source-file",no-bug,0.9
2730,harness,https://github.com/harness/harness/issues/2730,Trigger section is missing in jsonnet output if it only contains cron filter,"Here's my drone.jsonnet  [ { kind: ""pipeline"", name: ""main"", steps: [ { name: ""test"", image: ""alpine"", command: [""uname"",""-a""] } ], trigger: { cron: [""weekly""] }, } ]  Output from `drone jsonnet --stream --stdout`:   kind: pipeline name: main platform: os: linux arch: amd64 steps: - name: test image: alpine command: - uname - -a   The whole `trigger` section is missing. After changing `trigger` to:  trigger: { event: [""push""], cron: [""weekly""] }  section shows up with both filters:  trigger: cron: - weekly event: - push  **drone version 1.1.0**",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Trigger section is missing in jsonnet output if it only contains cron filter Here's my drone.jsonnet  [ { kind: ""pipeline"", name: ""main"", steps: [ { name: ""test"", image: ""alpine"", command: [""uname"",""-a""] } ], trigger: { cron: [""weekly""] }, } ]  Output from `drone jsonnet --stream --stdout`:   kind: pipeline name: main platform: os: linux arch: amd64 steps: - name: test image: alpine command: - uname - -a   The whole `trigger` section is missing. After changing `trigger` to:  trigger: { event: [""push""], cron: [""weekly""] }  section shows up with both filters:  trigger: cron: - weekly event: - push  **drone version 1.1.0** source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
784,harness,https://github.com/harness/harness/issues/784,Drone CLI don't exit container,"This was a question that came up on gitter that I wanted to open an issue for. cc @maxim > is there a way for me to start an image by hand and get a checkout in it, so i can debug some stuff? If i just enter a docker image I don't get the repo checkout. > so something like > 1. launch image with /bin/bash entry point (i can do this) > 2. run drone pre-script stuff in it <- need a way to do this > 3. play around in the container Today we can use the `drone build` command to run a build locally, however, it exits as soon as the build completes. It would be nice if there were an option to drop you in a bash prompt inside the container after the build is complete for further troubleshooting. I believe this is something we can achieve with the `bash --init-file` option. We would run the build script as an init file, dropping you to the prompt once complete. For more details: http://serverfault.com/questions/368054/run-an-interactive-bash-subshell-with-initial-commands-without-returning-to-the Note that issue #749 is a definite pre-requesite to this request",source-file | documentation-file | other-file | other-file | source-file | other-file,"Drone CLI don't exit container This was a question that came up on gitter that I wanted to open an issue for. cc @maxim > is there a way for me to start an image by hand and get a checkout in it, so i can debug some stuff? If i just enter a docker image I don't get the repo checkout. > so something like > 1. launch image with /bin/bash entry point (i can do this) > 2. run drone pre-script stuff in it <- need a way to do this > 3. play around in the container Today we can use the `drone build` command to run a build locally, however, it exits as soon as the build completes. It would be nice if there were an option to drop you in a bash prompt inside the container after the build is complete for further troubleshooting. I believe this is something we can achieve with the `bash --init-file` option. We would run the build script as an init file, dropping you to the prompt once complete. For more details: http://serverfault.com/questions/368054/run-an-interactive-bash-subshell-with-initial-commands-without-returning-to-the Note that issue #749 is a definite pre-requesite to this request source-file documentation-file other-file other-file source-file other-file",no-bug,0.9
427,harness,https://github.com/harness/harness/issues/427,Can't make drone itself,"I'm using CentOS 6.5, go version go1.2.2 linux/amd64 Steps: 0. git clone https://github.com/drone/drone/; cd drone 1. make And it failed: cd cmd/droned/assets && find js -name ""_.js"" ! -name '._' ! -name ""main.js"" -exec cat {} \; > js/main.js cd cmd/droned && rice embed cd pkg/template && rice embed go build -o bin/drone -ldflags ""-X main.version 0.2dev-3e3367c"" github.com/drone/drone/cmd/drone can't load package: package github.com/drone/drone/cmd/drone: cannot find package ""github.com/drone/drone/cmd/drone"" in any of: /usr/lib/golang/src/pkg/github.com/drone/drone/cmd/drone (from $GOROOT) ($GOPATH not set) make: **\* [build] Error 1 How should I fix it? Thank you.",source-file | source-file | source-file | source-file,"Can't make drone itself I'm using CentOS 6.5, go version go1.2.2 linux/amd64 Steps: 0. git clone https://github.com/drone/drone/; cd drone 1. make And it failed: cd cmd/droned/assets && find js -name ""_.js"" ! -name '._' ! -name ""main.js"" -exec cat {} \; > js/main.js cd cmd/droned && rice embed cd pkg/template && rice embed go build -o bin/drone -ldflags ""-X main.version 0.2dev-3e3367c"" github.com/drone/drone/cmd/drone can't load package: package github.com/drone/drone/cmd/drone: cannot find package ""github.com/drone/drone/cmd/drone"" in any of: /usr/lib/golang/src/pkg/github.com/drone/drone/cmd/drone (from $GOROOT) ($GOPATH not set) make: **\* [build] Error 1 How should I fix it? Thank you. source-file source-file source-file source-file",no-bug,0.95
106,harness,https://github.com/harness/harness/issues/106,Allow multiple repo connections,"If I have repos on bitbucket, github, and github enterprise, it would be nice to be allowed the option to link a repo from any/all locations.",source-file | documentation-file | other-file | source-file | other-file | other-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Allow multiple repo connections If I have repos on bitbucket, github, and github enterprise, it would be nice to be allowed the option to link a repo from any/all locations. source-file documentation-file other-file source-file other-file other-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3454,harness,https://github.com/harness/harness/issues/3454,[docs] missing env variables,"First, I'm loving gitness and would like to thank all for your work. There are a lot of possible configuration via ENV vars defined in [types/config.go](https://github.com/harness/gitness/blob/main/types/config.go) but most are not [documented](https://docs.gitness.com/installation/settings) at all. Would be great if all are listed and documented accordingly or if you accept PR for documentation Thanks",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[docs] missing env variables First, I'm loving gitness and would like to thank all for your work. There are a lot of possible configuration via ENV vars defined in [types/config.go](https://github.com/harness/gitness/blob/main/types/config.go) but most are not [documented](https://docs.gitness.com/installation/settings) at all. Would be great if all are listed and documented accordingly or if you accept PR for documentation Thanks source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
852,harness,https://github.com/harness/harness/issues/852,RFC - Embed Docker/Machine,"I would like to create a new type of plugin for automatically adding servers (workers) to Drone via the user interface. We should use the [docker/machine](https://github.com/docker/machine) project as much as possible, since it already integrates with a bunch of providers, and handles installing and configuring Docker and generating SSL keys for secure communication over TCP. I'm not 100% what this would look like, but here are some thoughts:  toml [amazon] access_key = """" secret_key = """" session_token = """" ami = """" region = """" vpc_id = """" subnet_id = """" zone = """" security_group = """" instance_type = """" root_size = """"  The above toml description pretty much mirrors the flags defined for the amazon module in Docker machine. See the following: https://github.com/docker/machine/blob/master/drivers/amazonec2/amazonec2.go#L75 We could then create a plugin in Drone at `/plugin/hosting/amazon`, initialize the plugin similar to GitHub and others, and this plugin could import the `docker/machine/amazon` package directly to create, start and stop servers. The interface for a `Host` could look like this:  func Create() (Server, error) func Destroy(Server) error  We should register each server with the worker pool on creation, and unregister when destroyed. We should persist the list of servers in the Drone database. We should register all servers with the worker pool when Drone first starts (by fetching the list from the database). It would be great if we could start with a Digital Ocean implementation as a proof of concept to get things started.",other-file,"RFC - Embed Docker/Machine I would like to create a new type of plugin for automatically adding servers (workers) to Drone via the user interface. We should use the [docker/machine](https://github.com/docker/machine) project as much as possible, since it already integrates with a bunch of providers, and handles installing and configuring Docker and generating SSL keys for secure communication over TCP. I'm not 100% what this would look like, but here are some thoughts:  toml [amazon] access_key = """" secret_key = """" session_token = """" ami = """" region = """" vpc_id = """" subnet_id = """" zone = """" security_group = """" instance_type = """" root_size = """"  The above toml description pretty much mirrors the flags defined for the amazon module in Docker machine. See the following: https://github.com/docker/machine/blob/master/drivers/amazonec2/amazonec2.go#L75 We could then create a plugin in Drone at `/plugin/hosting/amazon`, initialize the plugin similar to GitHub and others, and this plugin could import the `docker/machine/amazon` package directly to create, start and stop servers. The interface for a `Host` could look like this:  func Create() (Server, error) func Destroy(Server) error  We should register each server with the worker pool on creation, and unregister when destroyed. We should persist the list of servers in the Drone database. We should register all servers with the worker pool when Drone first starts (by fetching the list from the database). It would be great if we could start with a Digital Ocean implementation as a proof of concept to get things started. other-file",no-bug,0.95
3427,harness,https://github.com/harness/harness/issues/3427,Is there a way to protect .drone.yml from editing?,"I mean what if I don't wanna my developers to edit this because this is potentially dangerous (disabling tests, for example)..",source-file | source-file | source-file,"Is there a way to protect .drone.yml from editing? I mean what if I don't wanna my developers to edit this because this is potentially dangerous (disabling tests, for example).. source-file source-file source-file",no-bug,0.9
1765,harness,https://github.com/harness/harness/issues/1765,Static go builds broken on Ubuntu Wily and Xenial,"Ok, I think I got to the bottom of this: https://github.com/drone/drone/issues/1759 This affects all platforms, not only arm64. We're hitting the following: https://github.com/golang/go/issues/13470 when doing static builds on ubuntu wily and xenial, due to this glibc issue: https://sourceware.org/bugzilla/show_bug.cgi?id=19341 Potential workarounds are to link against musl, like this dude does: https://github.com/tamird/cockroach/commit/a50a6d7fc0b8bdf438bd9a5e6e24acadfa9be7a7 I like his comment on the commit though.",other-file,"Static go builds broken on Ubuntu Wily and Xenial Ok, I think I got to the bottom of this: https://github.com/drone/drone/issues/1759 This affects all platforms, not only arm64. We're hitting the following: https://github.com/golang/go/issues/13470 when doing static builds on ubuntu wily and xenial, due to this glibc issue: https://sourceware.org/bugzilla/show_bug.cgi?id=19341 Potential workarounds are to link against musl, like this dude does: https://github.com/tamird/cockroach/commit/a50a6d7fc0b8bdf438bd9a5e6e24acadfa9be7a7 I like his comment on the commit though. other-file",no-bug,0.95
3244,harness,https://github.com/harness/harness/issues/3244,downstream plugin step client error 404,"Hi All, we were using this step to trigger other project. I have used admin token as secret - name: run-automation-framework image: plugins/downstream type: plugin settings: server: http://droneci.dev.demo.com token: from_secret: DOWNSTREAM_TOKEN fork: true repositories: - demo/demo-project@demo_master when: branch: - testpipeline Getting the below error and we are using dockerized drone-server version 2.12  latest: Pulling from plugins/downstream Digest: sha256:b7924a1048636fbcf7ce9f0e706017c9b5ed705aa440ee8a76b387575f8b33e8 Status: Image is up to date for plugins/downstream:latest time=""2022-07-29T15:55:50Z"" level=error msg=""execution failed: unable to get latest build for demo/demoproject@demo_master: client error 404: {\""message\"":\""sql: no rows in result set\""}\n""  @bradrydzewski please advise.",source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file,"downstream plugin step client error 404 Hi All, we were using this step to trigger other project. I have used admin token as secret - name: run-automation-framework image: plugins/downstream type: plugin settings: server: http://droneci.dev.demo.com token: from_secret: DOWNSTREAM_TOKEN fork: true repositories: - demo/demo-project@demo_master when: branch: - testpipeline Getting the below error and we are using dockerized drone-server version 2.12  latest: Pulling from plugins/downstream Digest: sha256:b7924a1048636fbcf7ce9f0e706017c9b5ed705aa440ee8a76b387575f8b33e8 Status: Image is up to date for plugins/downstream:latest time=""2022-07-29T15:55:50Z"" level=error msg=""execution failed: unable to get latest build for demo/demoproject@demo_master: client error 404: {\""message\"":\""sql: no rows in result set\""}\n""  @bradrydzewski please advise. source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file",no-bug,0.8
2506,harness,https://github.com/harness/harness/issues/2506,Error: Cannot match pipeline name with stage,"## Summary I am trying to run the example `.drone.yml` just to verify my drone setup is correctly working. Regardless of what I put in this file I get an error saying: `Cannot match pipeline name with stage`. In the logs I see the same error  {""level"":""error"",""repo"":""dom/drone"",""build"":2,""stage"":1,""time"":""2018-10-10T09:50:48Z"",""message"":""cannot match pipeline name with stage""}  I've grepped through the code base to try and work out what this error means but cannot find where it is defined. I am unsure if it is a bug or if it is a genuine error in my configuration but I am using the example `.drone.yml` file.  pipeline: build: image: golang commands: - go get - go build - go test  Start command:  docker run --volume=/var/run/docker.sock:/var/run/docker.sock --volume=/var/lib/drone:/data --env=DRONE_TLS_AUTOCERT=false --env=DRONE_GITEA_SERVER=http://XXXXX:3000 --env=DRONE_GITEA_SKIP_VERIFY=true --env=DRONE_SERVER_HOST=XXXXX --env=DRONE_SERVER_PROTO=http --env=DRONE_RUNNER_CAPACITY=2 --env=DRONE_PRIVATE_MODE=false --env=DRONE_LOGS_DEBUG=true --publish=80:80 --name=drone drone/drone:0.9.0-alpha.2  ![screenshot from 2018-10-10 10-49-44](https://user-images.githubusercontent.com/10864294/46728245-47f33e00-cc7a-11e8-8815-299ca1b1dfd5.png)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | source-file | source-file | documentation-file | other-file | documentation-file,"Error: Cannot match pipeline name with stage ## Summary I am trying to run the example `.drone.yml` just to verify my drone setup is correctly working. Regardless of what I put in this file I get an error saying: `Cannot match pipeline name with stage`. In the logs I see the same error  {""level"":""error"",""repo"":""dom/drone"",""build"":2,""stage"":1,""time"":""2018-10-10T09:50:48Z"",""message"":""cannot match pipeline name with stage""}  I've grepped through the code base to try and work out what this error means but cannot find where it is defined. I am unsure if it is a bug or if it is a genuine error in my configuration but I am using the example `.drone.yml` file.  pipeline: build: image: golang commands: - go get - go build - go test  Start command:  docker run --volume=/var/run/docker.sock:/var/run/docker.sock --volume=/var/lib/drone:/data --env=DRONE_TLS_AUTOCERT=false --env=DRONE_GITEA_SERVER=http://XXXXX:3000 --env=DRONE_GITEA_SKIP_VERIFY=true --env=DRONE_SERVER_HOST=XXXXX --env=DRONE_SERVER_PROTO=http --env=DRONE_RUNNER_CAPACITY=2 --env=DRONE_PRIVATE_MODE=false --env=DRONE_LOGS_DEBUG=true --publish=80:80 --name=drone drone/drone:0.9.0-alpha.2  ![screenshot from 2018-10-10 10-49-44](https://user-images.githubusercontent.com/10864294/46728245-47f33e00-cc7a-11e8-8815-299ca1b1dfd5.png) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file source-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file source-file other-file source-file other-file source-file other-file source-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file source-file other-file other-file other-file source-file source-file documentation-file other-file documentation-file",no-bug,0.9
388,harness,https://github.com/harness/harness/issues/388,SSL Intermediate/chain certificate,Is there a way to configure an intermediate/chain certificate? Love Drone :heart:,source-file,SSL Intermediate/chain certificate Is there a way to configure an intermediate/chain certificate? Love Drone :heart: source-file,no-bug,0.9
2744,harness,https://github.com/harness/harness/issues/2744,Feature: ability to rearrange the order of pending jobs,"Enabling users to drag & drop the pending jobs would be nice. Currently, it has to be done by cancel & restart. Use scenario: Say, prioritizing release builds over casual development CI builds in the long queue.",source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file,"Feature: ability to rearrange the order of pending jobs Enabling users to drag & drop the pending jobs would be nice. Currently, it has to be done by cancel & restart. Use scenario: Say, prioritizing release builds over casual development CI builds in the long queue. source-file source-file source-file source-file database-file database-file database-file database-file source-file",no-bug,0.9
376,harness,https://github.com/harness/harness/issues/376,Badges do not set headers that respect cache mechanisms,"If one wants to display the status of a drone-driven project, she'll use the badge integration, for example un the README.md file of her project. Unfortunately this does not work on Github, according to the following thread: https://github.com/github/markup/issues/224 For example, if I query one of my badge, here are the received headers:  Status Code: 200 Date: Wed, 16 Jul 2014 22:54:37 GMT Server: nginx/1.2.3 Connection: keep-alive Content-Length: 1410 Content-Type: image/png  Github documentation states that the caching mechanism is handled by the `Cache-Control: no-cache` header, and `Expires`, `Last-Modified` or `Etag`.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | source-file | source-file | source-file | source-file,"Badges do not set headers that respect cache mechanisms If one wants to display the status of a drone-driven project, she'll use the badge integration, for example un the README.md file of her project. Unfortunately this does not work on Github, according to the following thread: https://github.com/github/markup/issues/224 For example, if I query one of my badge, here are the received headers:  Status Code: 200 Date: Wed, 16 Jul 2014 22:54:37 GMT Server: nginx/1.2.3 Connection: keep-alive Content-Length: 1410 Content-Type: image/png  Github documentation states that the caching mechanism is handled by the `Cache-Control: no-cache` header, and `Expires`, `Last-Modified` or `Etag`. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file source-file source-file source-file source-file",no-bug,0.7
854,harness,https://github.com/harness/harness/issues/854,Become Official Slack Service,It would be great to become an official Slack plugin: ![slack_integration_message](https://cloud.githubusercontent.com/assets/817538/5914025/b467b906-a5a2-11e4-8249-60e42549a0a3.png) I've gotten a lot of feedback about this as well. I was hoping for some help from our Slack enthusiasts out there. If anyone is interested let me know. I'll be contacting the Slack team to see what we need to do to make things official.,source-file,Become Official Slack Service It would be great to become an official Slack plugin: ![slack_integration_message](https://cloud.githubusercontent.com/assets/817538/5914025/b467b906-a5a2-11e4-8249-60e42549a0a3.png) I've gotten a lot of feedback about this as well. I was hoping for some help from our Slack enthusiasts out there. If anyone is interested let me know. I'll be contacting the Slack team to see what we need to do to make things official. source-file,no-bug,0.95
2502,harness,https://github.com/harness/harness/issues/2502,[Feature Proposal] New Github Checks API support,"Github introduced Checks API few months ago https://blog.github.com/2018-05-07-introducing-checks-api/ . It looks like it supports features like direct code annotation and kicking-off re-run without leaving Github.com . I haven't looked in detail and don't know what would take for Drone to use this API (especially direct code annotation), but looks like worth investigating.",other-file,"[Feature Proposal] New Github Checks API support Github introduced Checks API few months ago https://blog.github.com/2018-05-07-introducing-checks-api/ . It looks like it supports features like direct code annotation and kicking-off re-run without leaving Github.com . I haven't looked in detail and don't know what would take for Drone to use this API (especially direct code annotation), but looks like worth investigating. other-file",no-bug,0.9
144,harness,https://github.com/harness/harness/issues/144,Specifying -lxc-conf parameters to 'docker run',"In my build I have to be able to use the loop devices and therefore need to specify arguments to 'docker run'. I need to specify the following: -lxc-conf=""lxc.cgroup.devices.allow = b 7:\* rwm"" -lxc-conf=""lxc.cgroup.devices.allow = c 10:237 rwm""",config-file | other-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Specifying -lxc-conf parameters to 'docker run' In my build I have to be able to use the loop devices and therefore need to specify arguments to 'docker run'. I need to specify the following: -lxc-conf=""lxc.cgroup.devices.allow = b 7:\* rwm"" -lxc-conf=""lxc.cgroup.devices.allow = c 10:237 rwm"" config-file other-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2052,harness,https://github.com/harness/harness/issues/2052,Separate server and agent binaries and images,Now that the CLI is moved to a separate repository I will propose separating the server and agent into separate binaries and publishing separate images for each. The binaries will follow the standard multi-binary layout:  cmd/drone-server cmd/drone-agent  We will then publish images for each  drone/drone drone/agent  The `drone/agent` does not have any CGO dependencies so we can cross-compile for armhf and arm64 and therefore distribute official images for each:  drone/agent:linux-arm drone/agent:linux-arm64  Versioned tags would look like this:  linux-arm 0.6.0-linux-arm 0.6-linux-arm  We can probably remove `codegangsta/cli` in a subsequent release since there is really no reason to include such a heavy dependency now that the CLI is moved to a separate repository. But this is something we'll take at a later time.,database-file | database-file | source-file | source-file | source-file | source-file | documentation-file,Separate server and agent binaries and images Now that the CLI is moved to a separate repository I will propose separating the server and agent into separate binaries and publishing separate images for each. The binaries will follow the standard multi-binary layout:  cmd/drone-server cmd/drone-agent  We will then publish images for each  drone/drone drone/agent  The `drone/agent` does not have any CGO dependencies so we can cross-compile for armhf and arm64 and therefore distribute official images for each:  drone/agent:linux-arm drone/agent:linux-arm64  Versioned tags would look like this:  linux-arm 0.6.0-linux-arm 0.6-linux-arm  We can probably remove `codegangsta/cli` in a subsequent release since there is really no reason to include such a heavy dependency now that the CLI is moved to a separate repository. But this is something we'll take at a later time. database-file database-file source-file source-file source-file source-file documentation-file,no-bug,0.9
256,harness,https://github.com/harness/harness/issues/256,Not able to build with gradlew,"Trying to build a Java project with the gradle wrapper. My build script is simply: ./gradlew build Error I get is: OpenJDK Runtime Environment (IcedTea 2.3.10) (7u25-2.3.10-1ubuntu0.12.04.2) OpenJDK 64-Bit Server VM (build 23.7-b01, mixed mode) $ ./gradlew build Error: Could not find or load main class org.gradle.wrapper.GradleWrapperMain",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Not able to build with gradlew Trying to build a Java project with the gradle wrapper. My build script is simply: ./gradlew build Error I get is: OpenJDK Runtime Environment (IcedTea 2.3.10) (7u25-2.3.10-1ubuntu0.12.04.2) OpenJDK 64-Bit Server VM (build 23.7-b01, mixed mode) $ ./gradlew build Error: Could not find or load main class org.gradle.wrapper.GradleWrapperMain source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
2618,harness,https://github.com/harness/harness/issues/2618,Major and minor version tags in Dockerhub,Please publish Drone images in Dockerhub with major (`1`) and minor version (`1.1`) tags so that users don't have to risk using the `latest` tag (Which may introduce breaking changes) or specific tags `1.0.0-rc.5` which do not receive updates.,database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Major and minor version tags in Dockerhub Please publish Drone images in Dockerhub with major (`1`) and minor version (`1.1`) tags so that users don't have to risk using the `latest` tag (Which may introduce breaking changes) or specific tags `1.0.0-rc.5` which do not receive updates. database-file database-file database-file database-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
2868,harness,https://github.com/harness/harness/issues/2868,fluxctl,"Hi, we are running the Drone server component on Kubernetes, with a GitOps strategy managed by Fluxctl: https://github.com/fluxcd/flux Flux is having trouble with the drone docker repo: ts=2019-11-04T13:52:51.932875392Z caller=repocachemanager.go:223 component=warmer canonical_name=index.docker.io/drone/drone auth={map[]} warn=""manifest for tag 1.0.0-rc.6 missing in repository drone/drone"" impact=""flux will fail to auto-release workloads with matching images, ask the repository administrator to fix the inconsistency"" Log messages were piling up so high, I had to replace the official image with a copy for the time being. Can you please check your docker repository and clean the above? Thanks in advance for a great product. Using it for 95% of all our builds (goal 100%) here at SupplyStack.com",source-file | other-file | other-file | other-file | documentation-file | source-file,"fluxctl Hi, we are running the Drone server component on Kubernetes, with a GitOps strategy managed by Fluxctl: https://github.com/fluxcd/flux Flux is having trouble with the drone docker repo: ts=2019-11-04T13:52:51.932875392Z caller=repocachemanager.go:223 component=warmer canonical_name=index.docker.io/drone/drone auth={map[]} warn=""manifest for tag 1.0.0-rc.6 missing in repository drone/drone"" impact=""flux will fail to auto-release workloads with matching images, ask the repository administrator to fix the inconsistency"" Log messages were piling up so high, I had to replace the official image with a copy for the time being. Can you please check your docker repository and clean the above? Thanks in advance for a great product. Using it for 95% of all our builds (goal 100%) here at SupplyStack.com source-file other-file other-file other-file documentation-file source-file",no-bug,0.9
1057,harness,https://github.com/harness/harness/issues/1057,UI should handle long commit messages,Can we just have the one line shortlog? Example: ![2015-06-13-105702_268x670_scrot](https://cloud.githubusercontent.com/assets/290429/8143890/fb4bd9e0-11ba-11e5-874e-7175ac19cee1.png),source-file | documentation-file | other-file,UI should handle long commit messages Can we just have the one line shortlog? Example: ![2015-06-13-105702_268x670_scrot](https://cloud.githubusercontent.com/assets/290429/8143890/fb4bd9e0-11ba-11e5-874e-7175ac19cee1.png) source-file documentation-file other-file,no-bug,0.9
3212,harness,https://github.com/harness/harness/issues/3212,[UI] Show runner name/architecture next to the build stage,"I'd suggest to add the name and architecture of the runner executing a build stage to the log view, so you dont have to switch to graph view to see where your job is running. There is currently a lot of white space in the sidebar anyway, so it would fit nicely. Here you can see how it would look like: ![image](https://user-images.githubusercontent.com/19636565/167794640-21c49708-a91a-4ed0-9ecc-485b451c4d0f.png)",source-file | source-file | source-file | source-file | source-file,"[UI] Show runner name/architecture next to the build stage I'd suggest to add the name and architecture of the runner executing a build stage to the log view, so you dont have to switch to graph view to see where your job is running. There is currently a lot of white space in the sidebar anyway, so it would fit nicely. Here you can see how it would look like: ![image](https://user-images.githubusercontent.com/19636565/167794640-21c49708-a91a-4ed0-9ecc-485b451c4d0f.png) source-file source-file source-file source-file source-file",no-bug,0.95
1046,harness,https://github.com/harness/harness/issues/1046,more options to privileged mode,"I would like to run some docker images with escalated privileges on a few devices (e.g. GPU), but not everything (e.g. the hard drive!). It is possible to be this fine-grained with docker on the command line but there is currently no option to enter the commands via drone.",source-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | source-file | documentation-file | other-file | other-file | source-file | other-file | source-file,"more options to privileged mode I would like to run some docker images with escalated privileges on a few devices (e.g. GPU), but not everything (e.g. the hard drive!). It is possible to be this fine-grained with docker on the command line but there is currently no option to enter the commands via drone. source-file source-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file source-file source-file source-file documentation-file other-file other-file source-file other-file source-file",no-bug,0.8
3253,harness,https://github.com/harness/harness/issues/3253,java client for drone api,"I implemented a simple java client for Drone Server Api, anyone in need can use it at will. :grinning: https://github.com/yahaha-yes/drone-api-java.git",source-file,"java client for drone api I implemented a simple java client for Drone Server Api, anyone in need can use it at will. :grinning: https://github.com/yahaha-yes/drone-api-java.git source-file",no-bug,0.9
2167,harness,https://github.com/harness/harness/issues/2167,[Feature Request] Ability to change the name of a current project/repo,"Allow changing the name of an org or repo name. This seems like a good candidate for the cli. Something allow the lines of  drone repo update --full-repo-name=newproj/supercat1 proj/supercat  would move the repo to the new name. @bradrydzewski I'm not sure if this is really feasible but I'm willing to give it a go. from what I can tell critical things would include in the repo table - repo_owner, repo_name, repo_full_name *unknowns- repo_link, repo_clone in the builds table - * unknowns if it even matters but build_link, build_remote (I doubt these would matter nearly as much as the ones in the repo table)",source-file | documentation-file | other-file,"[Feature Request] Ability to change the name of a current project/repo Allow changing the name of an org or repo name. This seems like a good candidate for the cli. Something allow the lines of  drone repo update --full-repo-name=newproj/supercat1 proj/supercat  would move the repo to the new name. @bradrydzewski I'm not sure if this is really feasible but I'm willing to give it a go. from what I can tell critical things would include in the repo table - repo_owner, repo_name, repo_full_name *unknowns- repo_link, repo_clone in the builds table - * unknowns if it even matters but build_link, build_remote (I doubt these would matter nearly as much as the ones in the repo table) source-file documentation-file other-file",no-bug,0.9
396,harness,https://github.com/harness/harness/issues/396,Successful test without any output,"Drone dont show any output and dont run any docker containers. ![drone](https://cloud.githubusercontent.com/assets/705840/3745805/aa1d2080-17b3-11e4-9d0e-9b2e3f3b9760.png) .drone.yml output  image: asjustas/php5 services: - localhost/videoclass-selenium cache: - /root/.composer/cache - /root/tmp script: - scp -q {{configDir}}build.sh build.sh - chmod +x build.sh - ./build.sh  docker version: Docker version 1.1.1, build bd609d2 drone version: 0.2-4f0585b",source-file | source-file,"Successful test without any output Drone dont show any output and dont run any docker containers. ![drone](https://cloud.githubusercontent.com/assets/705840/3745805/aa1d2080-17b3-11e4-9d0e-9b2e3f3b9760.png) .drone.yml output  image: asjustas/php5 services: - localhost/videoclass-selenium cache: - /root/.composer/cache - /root/tmp script: - scp -q {{configDir}}build.sh build.sh - chmod +x build.sh - ./build.sh  docker version: Docker version 1.1.1, build bd609d2 drone version: 0.2-4f0585b source-file source-file",no-bug,0.9
3573,harness,https://github.com/harness/harness/issues/3573,how to manage gitstate with traefik,"Hello, I would like to see how to manage URL, ports ans TLS certificate with traefik. Is it possible? Gitstate is awesome, but the default port used each Time I launch a new vs code session changes. It is complicated to manage that with traefik. Is it possible to add traefik labels or to fix a port and the number of sessions? Or to create URL dynamicly with the help of traefik? Or to choose URL? A workaround for me is to use it locally and not with the reverse proxy. Thanks you for your help",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"how to manage gitstate with traefik Hello, I would like to see how to manage URL, ports ans TLS certificate with traefik. Is it possible? Gitstate is awesome, but the default port used each Time I launch a new vs code session changes. It is complicated to manage that with traefik. Is it possible to add traefik labels or to fix a port and the number of sessions? Or to create URL dynamicly with the help of traefik? Or to choose URL? A workaround for me is to use it locally and not with the reverse proxy. Thanks you for your help source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
181,harness,https://github.com/harness/harness/issues/181,Trouble authenticating with Github Enterprise (unknown authority),"I am running into this issue when trying to authenticate:  Post https://git.local/login/oauth/access_token: x509: certificate signed by unknown authority  I think it's probably because internally we use self-signed certificates. I'd love to dig in to the source to try and fix this, but I'm not sure where to begin. Any pointers would be appreciated. Perhaps a configuration param could be set on the settings page, or a checkbox for ""trust invalid certificates"" could be added. Michael",source-file | source-file | source-file | source-file | source-file,"Trouble authenticating with Github Enterprise (unknown authority) I am running into this issue when trying to authenticate:  Post https://git.local/login/oauth/access_token: x509: certificate signed by unknown authority  I think it's probably because internally we use self-signed certificates. I'd love to dig in to the source to try and fix this, but I'm not sure where to begin. Any pointers would be appreciated. Perhaps a configuration param could be set on the settings page, or a checkbox for ""trust invalid certificates"" could be added. Michael source-file source-file source-file source-file source-file",no-bug,0.9
592,harness,https://github.com/harness/harness/issues/592,Builds succeeding with errors,In the latest 0.3 (now on master) The docker publish plugin fails but the build is still reported as success. $ git checkout -qf 6fa908e5832a6722e6b3c5621de4e8abf40946f8 Docker Plugin: Missing argument(s)  docker_port not defined in yaml  $ exit 0,other-file,Builds succeeding with errors In the latest 0.3 (now on master) The docker publish plugin fails but the build is still reported as success. $ git checkout -qf 6fa908e5832a6722e6b3c5621de4e8abf40946f8 Docker Plugin: Missing argument(s)  docker_port not defined in yaml  $ exit 0 other-file,no-bug,0.9
2020,harness,https://github.com/harness/harness/issues/2020,databases like rethink db can't be used as a service,"Drone version: .6 Repro steps: Add rethink db to the services like services: database: image: rethinkdb:2.3.5 command: [ rethinkdb, --bind, all ] and try to connect to ""database"". It will error with ECONNREFUSED from @bradrydzewski ""the rethink issue could be a chicken and egg problem. If it binds to available interface IPs (via --all), but is created before all the pipeline containers, it will never be able to bind to their networks this doesn't impact mysql / postgres/ etc because they don't try to bind to specific addresses a fix could be to create all containers (pipeline and service) up front, and then start them sequentially. Today we start and run them sequentially.""",source-file,"databases like rethink db can't be used as a service Drone version: .6 Repro steps: Add rethink db to the services like services: database: image: rethinkdb:2.3.5 command: [ rethinkdb, --bind, all ] and try to connect to ""database"". It will error with ECONNREFUSED from @bradrydzewski ""the rethink issue could be a chicken and egg problem. If it binds to available interface IPs (via --all), but is created before all the pipeline containers, it will never be able to bind to their networks this doesn't impact mysql / postgres/ etc because they don't try to bind to specific addresses a fix could be to create all containers (pipeline and service) up front, and then start them sequentially. Today we start and run them sequentially."" source-file",no-bug,0.9
713,harness,https://github.com/harness/harness/issues/713,Use regex for branch white-list in yaml,Currently the include exclude for branches is an all or nothing scenario. It would be nice to be able to do something like  branches: include: - master - release* ,source-file | test-file | source-file | test-file | source-file | other-file | other-file,Use regex for branch white-list in yaml Currently the include exclude for branches is an all or nothing scenario. It would be nice to be able to do something like  branches: include: - master - release*  source-file test-file source-file test-file source-file other-file other-file,no-bug,0.8
3581,harness,https://github.com/harness/harness/issues/3581,pipline bug : dind mount: permission denied (are you root?),dind example fail  kind: pipeline spec: stages: - type: ci spec: volumes: - name: dockersock spec: {} type: temp steps: - name: dind type: background spec: container: image: docker:dind privileged: true mount: - name: dockersock path: /var/run - name: test type: run spec: container: docker:dind mount: - name: dockersock path: /var/run script: |- sleep 5 docker ps -a  ![1731142552327](https://github.com/user-attachments/assets/583c582b-98da-4cf6-b928-b5ea94a5ae41),other-file,pipline bug : dind mount: permission denied (are you root?) dind example fail  kind: pipeline spec: stages: - type: ci spec: volumes: - name: dockersock spec: {} type: temp steps: - name: dind type: background spec: container: image: docker:dind privileged: true mount: - name: dockersock path: /var/run - name: test type: run spec: container: docker:dind mount: - name: dockersock path: /var/run script: |- sleep 5 docker ps -a  ![1731142552327](https://github.com/user-attachments/assets/583c582b-98da-4cf6-b928-b5ea94a5ae41) other-file,no-bug,0.95
122,harness,https://github.com/harness/harness/issues/122,DRONE_BRANCH and DRONE_PR env variables,"My build script handles branches differently based on their name. drone.io has the env variable DRONE_BRANCH that tells my script what branch it is building, but I am unable to find anything like that in drone/drone. What should I do to determine current branch?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"DRONE_BRANCH and DRONE_PR env variables My build script handles branches differently based on their name. drone.io has the env variable DRONE_BRANCH that tells my script what branch it is building, but I am unable to find anything like that in drone/drone. What should I do to determine current branch? source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3419,harness,https://github.com/harness/harness/issues/3419,[Feature Request] Code Syntax Color for csharp,,source-file,[Feature Request] Code Syntax Color for csharp  source-file,no-bug,0.95
2230,harness,https://github.com/harness/harness/issues/2230,optimize repository synchronization process,"When syncing a large number of repositories it can take many seconds. During this time period additional http requests from the same user could result in duplicate synchronizations. This can be resolved by immediately setting the user synchronization date. The change to the relevant [sections of code](https://github.com/drone/drone/blob/ec6016062bd1d7d702c5edf383eb0728df33dbdd/server/user.go#L69:L83) would roughly look like this: diff + user.Synced = time.Now().Unix() + store.FromContext(c).UpdateUser(user) sync := syncer{ remote: remote.FromContext(c), store: store.FromContext(c), perms: store.FromContext(c), } if err := sync.Sync(user); err != nil { logrus.Debugf(""sync error: %s: %s"", user.Login, err) - } else { - logrus.Debugf(""sync complete: %s"", user.Login) - user.Synced = time.Now().Unix() - }  In addition we should optimize the automatic synchronization process to immediately return the repository list prior to synchronization (this means the list could be slightly stale) and then perform the synchronization async in the background.",other-file | source-file | source-file,"optimize repository synchronization process When syncing a large number of repositories it can take many seconds. During this time period additional http requests from the same user could result in duplicate synchronizations. This can be resolved by immediately setting the user synchronization date. The change to the relevant [sections of code](https://github.com/drone/drone/blob/ec6016062bd1d7d702c5edf383eb0728df33dbdd/server/user.go#L69:L83) would roughly look like this: diff + user.Synced = time.Now().Unix() + store.FromContext(c).UpdateUser(user) sync := syncer{ remote: remote.FromContext(c), store: store.FromContext(c), perms: store.FromContext(c), } if err := sync.Sync(user); err != nil { logrus.Debugf(""sync error: %s: %s"", user.Login, err) - } else { - logrus.Debugf(""sync complete: %s"", user.Login) - user.Synced = time.Now().Unix() - }  In addition we should optimize the automatic synchronization process to immediately return the repository list prior to synchronization (this means the list could be slightly stale) and then perform the synchronization async in the background. other-file source-file source-file",no-bug,0.9
780,harness,https://github.com/harness/harness/issues/780,Checkout branches other than master?,"How does one go about checking out branches other than master? I see the .drone.yml in this directory has a `git` field in the yaml, but I haven't found the documentation for it. Trying out  yaml git: branch: source  doesn't seem to do the trick.",source-file,"Checkout branches other than master? How does one go about checking out branches other than master? I see the .drone.yml in this directory has a `git` field in the yaml, but I haven't found the documentation for it. Trying out  yaml git: branch: source  doesn't seem to do the trick. source-file",no-bug,0.9
612,harness,https://github.com/harness/harness/issues/612,Update Slack notifications,Slack updated their Incoming WebHooks integration. They now provide a webhook url vs `https://%s.slack.com/services/hooks/incoming-webhook?token=%s` url format they were using before.,source-file,Update Slack notifications Slack updated their Incoming WebHooks integration. They now provide a webhook url vs `https://%s.slack.com/services/hooks/incoming-webhook?token=%s` url format they were using before. source-file,no-bug,0.8
3623,harness,https://github.com/harness/harness/issues/3623,[harness/harness:unstable-uiv2] Artifacts registry moved to Harness Enterprise?,"First, thanks for this great open source product: its [landing page](https://www.harness.io/open-source) and the [roadmap](https://developer.harness.io/roadmap/#platform) made me test your product :) However, I wonder about the future of **Harness Open Source** by looking at your [Docker Hub](https://hub.docker.com/r/harness/harness/tags) activities: - `harness:latest` and `harness:test-unstable` have not been updated for 3 months. - `harness/harness:unstable-uiv2` is actively updated, and when I tested, I was surprised by this message when trying to use `Artifacts` or any other module than `Repositories`: _**Upgrade to Harness Enterprise** to access Artifacts_. ![Image](https://github.com/user-attachments/assets/61d63a36-bbf5-4a34-ab91-d2c1e39aba2e) Could you confirm that the current features of Harness Open Source like `Artifacts` and `Gitspaces` will be included in the future stable versions ? Hopefully you temporarily removed all the features except `Repositories` because `harness/harness:unstable-uiv2` is still unstable",other-file,"[harness/harness:unstable-uiv2] Artifacts registry moved to Harness Enterprise? First, thanks for this great open source product: its [landing page](https://www.harness.io/open-source) and the [roadmap](https://developer.harness.io/roadmap/#platform) made me test your product :) However, I wonder about the future of **Harness Open Source** by looking at your [Docker Hub](https://hub.docker.com/r/harness/harness/tags) activities: - `harness:latest` and `harness:test-unstable` have not been updated for 3 months. - `harness/harness:unstable-uiv2` is actively updated, and when I tested, I was surprised by this message when trying to use `Artifacts` or any other module than `Repositories`: _**Upgrade to Harness Enterprise** to access Artifacts_. ![Image](https://github.com/user-attachments/assets/61d63a36-bbf5-4a34-ab91-d2c1e39aba2e) Could you confirm that the current features of Harness Open Source like `Artifacts` and `Gitspaces` will be included in the future stable versions ? Hopefully you temporarily removed all the features except `Repositories` because `harness/harness:unstable-uiv2` is still unstable other-file",no-bug,0.9
3227,harness,https://github.com/harness/harness/issues/3227,Docker-compose + Mariadb init db ERROR: Can't initialize batch_readline,"Hi, I have a strange problem when launching a mariadb container from a docker / compose service image via drone. **Scaffolding** SQL -init.sql .drone.yml docker-compose.yml **.drone.yml**  name: ERP Services kind: pipeline type: docker  Stage Develop steps: - name: Run Services image: docker/compose:latest volumes: - name: dockersock path: /var/run/docker.sock commands: - docker-compose down - docker-compose rm - docker-compose up --detach environment: MYSQL_ROOT_PASSWORD: from_secret: MYSQL_ROOT_PASSWORD MYSQL_USER: from_secret: MYSQL_USER MYSQL_PASSWORD: from_secret: MYSQL_PASSWORD MYSQL_DATABASE: from_secret: MYSQL_DATABASE MYSQL_PORT: from_secret: MYSQL_PORT PMA_PORT: from_secret: PMA_PORT CLOUD_SERVER_PORT: from_secret: CLOUD_SERVER_PORT AWS_S3_ACCESS_KEY_ID: from_secret: AWS_S3_ACCESS_KEY_ID AWS_S3_SECRET_ACCESS_KEY: from_secret: AWS_S3_SECRET_ACCESS_KEY volumes: - name: dockersock host: path: /var/run/docker.sock trigger: branch: - master event: - push - tag  **docker-compose.yml**  version: ""3.8"" services: database: image: mariadb:latest container_name: Mariadb_ERP networks: - proxynet environment: MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD} MYSQL_USER: ${MYSQL_USER} MYSQL_TCP_PORT: ${MYSQL_PORT} MYSQL_UNIX_PORT: ${MYSQL_PORT} volumes: - ./SQL/init.sql:/docker-entrypoint-initdb.d/init.sql - /ERP/mariadb/:/var/lib/mysql restart: unless-stopped ports: - ${MYSQL_PORT}:3306 healthcheck: test: '/usr/bin/mysql --user=root --password=${MYSQL_ROOT_PASSWORD} --execute ""SHOW DATABASES;""' interval: 3s timeout: 1s retries: 5  Init.sql does not initialize the database and gives me the following error [Note] [Entrypoint]: /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init.sql ERROR: Can't initialize batch_readline - may be the input source is a directory or a block device. I noticed that it is created under the ./drone/src folder of folders: SQL / init.sql / I can't find the solution, if I launch it directly from localhost everything works perfectly. Do I have to go and create a build from the mysql image and do an ADD ./SQL?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Docker-compose + Mariadb init db ERROR: Can't initialize batch_readline Hi, I have a strange problem when launching a mariadb container from a docker / compose service image via drone. **Scaffolding** SQL -init.sql .drone.yml docker-compose.yml **.drone.yml**  name: ERP Services kind: pipeline type: docker  Stage Develop steps: - name: Run Services image: docker/compose:latest volumes: - name: dockersock path: /var/run/docker.sock commands: - docker-compose down - docker-compose rm - docker-compose up --detach environment: MYSQL_ROOT_PASSWORD: from_secret: MYSQL_ROOT_PASSWORD MYSQL_USER: from_secret: MYSQL_USER MYSQL_PASSWORD: from_secret: MYSQL_PASSWORD MYSQL_DATABASE: from_secret: MYSQL_DATABASE MYSQL_PORT: from_secret: MYSQL_PORT PMA_PORT: from_secret: PMA_PORT CLOUD_SERVER_PORT: from_secret: CLOUD_SERVER_PORT AWS_S3_ACCESS_KEY_ID: from_secret: AWS_S3_ACCESS_KEY_ID AWS_S3_SECRET_ACCESS_KEY: from_secret: AWS_S3_SECRET_ACCESS_KEY volumes: - name: dockersock host: path: /var/run/docker.sock trigger: branch: - master event: - push - tag  **docker-compose.yml**  version: ""3.8"" services: database: image: mariadb:latest container_name: Mariadb_ERP networks: - proxynet environment: MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD} MYSQL_USER: ${MYSQL_USER} MYSQL_TCP_PORT: ${MYSQL_PORT} MYSQL_UNIX_PORT: ${MYSQL_PORT} volumes: - ./SQL/init.sql:/docker-entrypoint-initdb.d/init.sql - /ERP/mariadb/:/var/lib/mysql restart: unless-stopped ports: - ${MYSQL_PORT}:3306 healthcheck: test: '/usr/bin/mysql --user=root --password=${MYSQL_ROOT_PASSWORD} --execute ""SHOW DATABASES;""' interval: 3s timeout: 1s retries: 5  Init.sql does not initialize the database and gives me the following error [Note] [Entrypoint]: /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init.sql ERROR: Can't initialize batch_readline - may be the input source is a directory or a block device. I noticed that it is created under the ./drone/src folder of folders: SQL / init.sql / I can't find the solution, if I launch it directly from localhost everything works perfectly. Do I have to go and create a build from the mysql image and do an ADD ./SQL? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
193,harness,https://github.com/harness/harness/issues/193,Deploy Plugin - CloudFoundry,It would be nice to have a deployment option for CloudFoundry. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/cloudfoundry.go,source-file | test-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | documentation-file | other-file | other-file,Deploy Plugin - CloudFoundry It would be nice to have a deployment option for CloudFoundry. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/cloudfoundry.go source-file test-file other-file source-file other-file other-file source-file other-file other-file other-file source-file documentation-file other-file other-file,no-bug,0.9
2475,harness,https://github.com/harness/harness/issues/2475,BUG: Gitea integration sending wrong URLs to Gitea,"First of all this is a copy of my bug report which got automaticly closed (https://github.com/drone/drone/issues/2470). Secondly @bradrydzewski said I should report this on https://discourse.drone.io/ - Since then my account didn't get approved so I'm opening this issue a second time. I am running a drone ci instance using the following docker-compose.yml  version: '2' networks: drone: external: false proxy: external: name: proxy services: drone-server: image: drone/drone:0.8 expose: - 8000 - 9000 volumes: - ./drone:/var/lib/drone/ restart: always networks: - proxy - drone environment: - DRONE_OPEN=true - DRONE_HOST={{REMOVED}} - DRONE_SECRET={{REMOVED}}D - DRONE_GITEA=true - DRONE_GITEA_URL={{REMOVED}} - DRONE_GITEA_GIT_USERNAME=Drone - DRONE_GITEA_GIT_PASSWORD={{REMOVED}} - DRONE_GITEA_PRIVATE_MODE=true drone-agent: image: drone/agent:0.8 command: agent restart: always networks: - drone depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=drone-server:9000 - DRONE_SECRET={{REMOVED}}  After pushing into a activated repository Gitea shows the build status. ![Example image](https://user-images.githubusercontent.com/11004008/44058996-32bb097a-9f50-11e8-9d06-65a1e2cc26cb.png ""Example image"") If the build succeeded the URL is working as expected (Redirecting to the defined DRONE_HOST) But if a build is still pending or fails the URL redirects to http://drone-server:8000/ I don't think this is an intended behavior. If you need any other details or configuration, let me know.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"BUG: Gitea integration sending wrong URLs to Gitea First of all this is a copy of my bug report which got automaticly closed (https://github.com/drone/drone/issues/2470). Secondly @bradrydzewski said I should report this on https://discourse.drone.io/ - Since then my account didn't get approved so I'm opening this issue a second time. I am running a drone ci instance using the following docker-compose.yml  version: '2' networks: drone: external: false proxy: external: name: proxy services: drone-server: image: drone/drone:0.8 expose: - 8000 - 9000 volumes: - ./drone:/var/lib/drone/ restart: always networks: - proxy - drone environment: - DRONE_OPEN=true - DRONE_HOST={{REMOVED}} - DRONE_SECRET={{REMOVED}}D - DRONE_GITEA=true - DRONE_GITEA_URL={{REMOVED}} - DRONE_GITEA_GIT_USERNAME=Drone - DRONE_GITEA_GIT_PASSWORD={{REMOVED}} - DRONE_GITEA_PRIVATE_MODE=true drone-agent: image: drone/agent:0.8 command: agent restart: always networks: - drone depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=drone-server:9000 - DRONE_SECRET={{REMOVED}}  After pushing into a activated repository Gitea shows the build status. ![Example image](https://user-images.githubusercontent.com/11004008/44058996-32bb097a-9f50-11e8-9d06-65a1e2cc26cb.png ""Example image"") If the build succeeded the URL is working as expected (Redirecting to the defined DRONE_HOST) But if a build is still pending or fails the URL redirects to http://drone-server:8000/ I don't think this is an intended behavior. If you need any other details or configuration, let me know. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.85
2180,harness,https://github.com/harness/harness/issues/2180,Caddy needs to have disabled compression for /stream,"Hi, Documentation might need a small update for caddy reverse proxy configuration. I had to disable gzip compression for /stream/, otherwise live updates wouldn't get through to browser. (caddy is probably trying to cache a bit of output and waits for the GET to finish) This configuration seems to be working correctly:  drone.mycomopany.com { + gzip { + not /stream/ + } proxy / localhost:8000 { websocket transparent } } ",source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | source-file,"Caddy needs to have disabled compression for /stream Hi, Documentation might need a small update for caddy reverse proxy configuration. I had to disable gzip compression for /stream/, otherwise live updates wouldn't get through to browser. (caddy is probably trying to cache a bit of output and waits for the GET to finish) This configuration seems to be working correctly:  drone.mycomopany.com { + gzip { + not /stream/ + } proxy / localhost:8000 { websocket transparent } }  source-file documentation-file other-file other-file other-file other-file source-file source-file",no-bug,0.9
1157,harness,https://github.com/harness/harness/issues/1157,Improve conditional step logic in Yaml,"We currently have a `Condition` structure that let's us conditionally execute steps in the `.drone.yml` file represented by the `where` attribute.  Go type Condition struct { Owner string // Indicates the step should run only for this repo (useful for forks) Branch string // Indicates the step should run only for this branch // Indicates the step should only run when the following // matrix values are present for the sub-build. Matrix map[string]string }  The above is represented in the yaml as:  yaml publish: heroku: when: branch: master   When Repo Probably less confusing to specify `repo` instead of `owner` to prevent steps from running for forks. For example, specify `repo: drone/drone` to prevent `bradrydzewski/drone` fork from executing a build step:  diff type Condition struct { - Owner string + Repo string }   When Success, Failure, Change The ability to filter steps by status exists in 0.3, however, has not been implemented in 0.4. This is one proposal to do so:  diff type Condition struct { + Success bool + Failure bool }  which could be represented in the yaml as:  yaml publish: heroku: when: success: on|off|on_change failure: on|off|on_change  or an alternative:  yaml publish: heroku: when: success: false failure: false change: true  In order to facilitate `on_change` we need to fetch and send the last build as part of the current build's payload. This filtering should happen external to the plugin, in the `drone-build` controller, so that each plugin doesn't have to duplicate the same filtering logic.  When Event Is We should give the ability to limit steps based on the hook event type. For example, we may want to execute some steps only for `pull_request` events, and others only for `tag` events. This will also help us support the GitHub `deployment` API flow:  yaml publish: heroku: when: push: on|off pull_request: on|off tag: on|off deploy: on|off  or an alternative:  yaml publish: heroku: when: event: push|pull_request|tag|deployment ",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Improve conditional step logic in Yaml We currently have a `Condition` structure that let's us conditionally execute steps in the `.drone.yml` file represented by the `where` attribute.  Go type Condition struct { Owner string // Indicates the step should run only for this repo (useful for forks) Branch string // Indicates the step should run only for this branch // Indicates the step should only run when the following // matrix values are present for the sub-build. Matrix map[string]string }  The above is represented in the yaml as:  yaml publish: heroku: when: branch: master   When Repo Probably less confusing to specify `repo` instead of `owner` to prevent steps from running for forks. For example, specify `repo: drone/drone` to prevent `bradrydzewski/drone` fork from executing a build step:  diff type Condition struct { - Owner string + Repo string }   When Success, Failure, Change The ability to filter steps by status exists in 0.3, however, has not been implemented in 0.4. This is one proposal to do so:  diff type Condition struct { + Success bool + Failure bool }  which could be represented in the yaml as:  yaml publish: heroku: when: success: on|off|on_change failure: on|off|on_change  or an alternative:  yaml publish: heroku: when: success: false failure: false change: true  In order to facilitate `on_change` we need to fetch and send the last build as part of the current build's payload. This filtering should happen external to the plugin, in the `drone-build` controller, so that each plugin doesn't have to duplicate the same filtering logic.  When Event Is We should give the ability to limit steps based on the hook event type. For example, we may want to execute some steps only for `pull_request` events, and others only for `tag` events. This will also help us support the GitHub `deployment` API flow:  yaml publish: heroku: when: push: on|off pull_request: on|off tag: on|off deploy: on|off  or an alternative:  yaml publish: heroku: when: event: push|pull_request|tag|deployment  source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
669,harness,https://github.com/harness/harness/issues/669,no repositories,"perhaps I'm doing something wrong (!) but when I log into drone (0.3) the screen says ""syncing"" and it finishes, but there are no repositories in the list. Is there a config option somewhere that I'm missing ? Using 0,3 with bitbucket thanks ![image](https://cloud.githubusercontent.com/assets/929523/4933554/6324e5b8-6598-11e4-87ec-b2627e684b5c.png)",other-file,"no repositories perhaps I'm doing something wrong (!) but when I log into drone (0.3) the screen says ""syncing"" and it finishes, but there are no repositories in the list. Is there a config option somewhere that I'm missing ? Using 0,3 with bitbucket thanks ![image](https://cloud.githubusercontent.com/assets/929523/4933554/6324e5b8-6598-11e4-87ec-b2627e684b5c.png) other-file",no-bug,0.9
2894,harness,https://github.com/harness/harness/issues/2894,"Configure Allowed-List of platforms, pipelines and nodes","We should have a global option to provide an allowed list of platforms (os, arch), kinds of pipelines (docker, kubernetes, etc) and the node labels. If a manifest tries and uses values not in the allowed-list the pipeline can fail. This prevents a situation where a user defines criteria in a manifest that we know will never have a matching runner, and will therefore sit in a pending state indefinitely.",other-file,"Configure Allowed-List of platforms, pipelines and nodes We should have a global option to provide an allowed list of platforms (os, arch), kinds of pipelines (docker, kubernetes, etc) and the node labels. If a manifest tries and uses values not in the allowed-list the pipeline can fail. This prevents a situation where a user defines criteria in a manifest that we know will never have a matching runner, and will therefore sit in a pending state indefinitely. other-file",no-bug,0.9
1087,harness,https://github.com/harness/harness/issues/1087,build limit size to be configurable,"Hi, please make the build buffer size configurable (env. variable etc). https://github.com/drone/drone/blob/master/shared/build/writer.go#L17 Sure, it's pointless to have such big outputs for CI, however if it happen (due debug enabled etc) than rather be able to keep them. Alternative approach would be to allow keep the size of buffer, but use it as a pipe, so if overloaded, than the first entries will be dropped. As you probably are more interested how the build ends.",other-file | other-file | other-file | other-file | source-file | other-file | source-file | documentation-file | other-file | other-file | source-file,"build limit size to be configurable Hi, please make the build buffer size configurable (env. variable etc). https://github.com/drone/drone/blob/master/shared/build/writer.go#L17 Sure, it's pointless to have such big outputs for CI, however if it happen (due debug enabled etc) than rather be able to keep them. Alternative approach would be to allow keep the size of buffer, but use it as a pipe, so if overloaded, than the first entries will be dropped. As you probably are more interested how the build ends. other-file other-file other-file other-file source-file other-file source-file documentation-file other-file other-file source-file",no-bug,0.9
948,harness,https://github.com/harness/harness/issues/948,Bash dependency inside containers,"I've noticed some bash scripting going on inside Drone which expects `bash` to be present in a container. With the ""minimal containers"" approach, this can become a problem. See for example: https://github.com/blendle/docker-ruby/pull/3 Any thoughts on refactoring the scripts to only use bourne-shell compatible scripts?",source-file | source-file,"Bash dependency inside containers I've noticed some bash scripting going on inside Drone which expects `bash` to be present in a container. With the ""minimal containers"" approach, this can become a problem. See for example: https://github.com/blendle/docker-ruby/pull/3 Any thoughts on refactoring the scripts to only use bourne-shell compatible scripts? source-file source-file",no-bug,0.9
3363,harness,https://github.com/harness/harness/issues/3363,Build status has always been Loading,"Drone versiondrone/drone:2 Drone runner versiondrone/drone-runner-docker:1.8.3 Service runs on kubernetes This is my drone.yaml config  kind: pipeline type: kubernetes name: build workspace: path: /home/docker/drone/drone steps: - name: maven-build image: maven:3.6.3-openjdk-8-slim volumes: - name: maven-cache path: /root/.m2 commands: - mvn install volumes: - name: maven-cache host: path: /data/app/maven/cache  Build status has always been Loading ![image](https://github.com/harness/drone/assets/33045888/c82ebf1a-1711-499d-bf02-ea7e52a26cfc) This my drone runner kubernetes yaml config  apiVersion: apps/v1 kind: DaemonSet metadata: annotations: deprecated.daemonset.template.generation: ""2"" creationTimestamp: ""2023-04-11T17:45:41Z"" generation: 2 managedFields: - apiVersion: apps/v1 fieldsType: FieldsV1 fieldsV1: f:metadata: f:annotations: .: {} f:deprecated.daemonset.template.generation: {} f:spec: f:revisionHistoryLimit: {} f:selector: {} f:template: f:metadata: f:annotations: .: {} f:pod.alpha.kubernetes.io/initialized: {} f:labels: .: {} f:app: {} f:spec: f:containers: k:{""name"":""drone-runner-docker""}: .: {} f:env: .: {} k:{""name"":""DRONE_RPC_HOST""}: .: {} f:name: {} f:value: {} k:{""name"":""DRONE_RPC_PROTO""}: .: {} f:name: {} f:value: {} k:{""name"":""DRONE_RPC_SECRET""}: .: {} f:name: {} f:value: {} k:{""name"":""DRONE_RUNNER_CAPACITY""}: .: {} f:name: {} f:value: {} k:{""name"":""DRONE_RUNNER_NAME""}: .: {} f:name: {} f:value: {} f:image: {} f:imagePullPolicy: {} f:name: {} f:resources: {} f:terminationMessagePath: {} f:terminationMessagePolicy: {} f:volumeMounts: .: {} k:{""mountPath"":""/var/run/docker.sock""}: .: {} f:mountPath: {} f:name: {} f:dnsPolicy: {} f:restartPolicy: {} f:schedulerName: {} f:securityContext: {} f:terminationGracePeriodSeconds: {} f:volumes: .: {} k:{""name"":""docker-socket""}: .: {} f:hostPath: .: {} f:path: {} f:type: {} f:name: {} f:updateStrategy: f:rollingUpdate: .: {} f:maxUnavailable: {} f:type: {} manager: kubectl-create operation: Update time: ""2023-04-11T17:45:41Z"" - apiVersion: apps/v1 fieldsType: FieldsV1 fieldsV1: f:spec: f:template: f:metadata: f:annotations: f:cattle.io/timestamp: {} f:field.cattle.io/ports: {} f:spec: f:containers: k:{""name"":""drone-runner-docker""}: f:securityContext: .: {} f:allowPrivilegeEscalation: {} f:capabilities: {} f:privileged: {} manager: Go-http-client operation: Update time: ""2023-09-19T02:39:15Z"" - apiVersion: apps/v1 fieldsType: FieldsV1 fieldsV1: f:status: f:currentNumberScheduled: {} f:desiredNumberScheduled: {} f:numberAvailable: {} f:numberMisscheduled: {} f:numberReady: {} f:observedGeneration: {} f:updatedNumberScheduled: {} manager: kube-controller-manager operation: Update time: ""2023-09-19T02:42:05Z"" name: drone-runner-docker namespace: base resourceVersion: ""59172769"" uid: 3151b2ae-4b84-42fa-9a9b-49ac78cc5b8d spec: revisionHistoryLimit: 10 selector: matchLabels: app: drone-runner-docker template: metadata: annotations: cattle.io/timestamp: ""2023-09-19T02:39:15Z"" field.cattle.io/ports: '[[]]' pod.alpha.kubernetes.io/initialized: ""true"" creationTimestamp: null labels: app: drone-runner-docker spec: containers: - env: - name: DRONE_RPC_HOST value: drone-headless - name: DRONE_RPC_PROTO value: http - name: DRONE_RPC_SECRET value: 325d602f273c2fa9f20c5bd2c4a9abf9 - name: DRONE_RUNNER_CAPACITY value: ""10"" - name: DRONE_RUNNER_NAME value: drone-runner-docker image: drone/drone-runner-docker:1.8.3 imagePullPolicy: IfNotPresent name: drone-runner-docker resources: {} securityContext: allowPrivilegeEscalation: true capabilities: {} privileged: true terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/docker.sock name: docker-socket dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30 volumes: - hostPath: path: /var/run/docker.sock type: Socket name: docker-socket updateStrategy: rollingUpdate: maxUnavailable: 1 type: RollingUpdate status: currentNumberScheduled: 3 desiredNumberScheduled: 3 numberAvailable: 3 numberMisscheduled: 0 numberReady: 3 observedGeneration: 2 updatedNumberScheduled: 3 ",source-file | source-file | source-file | source-file | source-file | source-file,"Build status has always been Loading Drone versiondrone/drone:2 Drone runner versiondrone/drone-runner-docker:1.8.3 Service runs on kubernetes This is my drone.yaml config  kind: pipeline type: kubernetes name: build workspace: path: /home/docker/drone/drone steps: - name: maven-build image: maven:3.6.3-openjdk-8-slim volumes: - name: maven-cache path: /root/.m2 commands: - mvn install volumes: - name: maven-cache host: path: /data/app/maven/cache  Build status has always been Loading ![image](https://github.com/harness/drone/assets/33045888/c82ebf1a-1711-499d-bf02-ea7e52a26cfc) This my drone runner kubernetes yaml config  apiVersion: apps/v1 kind: DaemonSet metadata: annotations: deprecated.daemonset.template.generation: ""2"" creationTimestamp: ""2023-04-11T17:45:41Z"" generation: 2 managedFields: - apiVersion: apps/v1 fieldsType: FieldsV1 fieldsV1: f:metadata: f:annotations: .: {} f:deprecated.daemonset.template.generation: {} f:spec: f:revisionHistoryLimit: {} f:selector: {} f:template: f:metadata: f:annotations: .: {} f:pod.alpha.kubernetes.io/initialized: {} f:labels: .: {} f:app: {} f:spec: f:containers: k:{""name"":""drone-runner-docker""}: .: {} f:env: .: {} k:{""name"":""DRONE_RPC_HOST""}: .: {} f:name: {} f:value: {} k:{""name"":""DRONE_RPC_PROTO""}: .: {} f:name: {} f:value: {} k:{""name"":""DRONE_RPC_SECRET""}: .: {} f:name: {} f:value: {} k:{""name"":""DRONE_RUNNER_CAPACITY""}: .: {} f:name: {} f:value: {} k:{""name"":""DRONE_RUNNER_NAME""}: .: {} f:name: {} f:value: {} f:image: {} f:imagePullPolicy: {} f:name: {} f:resources: {} f:terminationMessagePath: {} f:terminationMessagePolicy: {} f:volumeMounts: .: {} k:{""mountPath"":""/var/run/docker.sock""}: .: {} f:mountPath: {} f:name: {} f:dnsPolicy: {} f:restartPolicy: {} f:schedulerName: {} f:securityContext: {} f:terminationGracePeriodSeconds: {} f:volumes: .: {} k:{""name"":""docker-socket""}: .: {} f:hostPath: .: {} f:path: {} f:type: {} f:name: {} f:updateStrategy: f:rollingUpdate: .: {} f:maxUnavailable: {} f:type: {} manager: kubectl-create operation: Update time: ""2023-04-11T17:45:41Z"" - apiVersion: apps/v1 fieldsType: FieldsV1 fieldsV1: f:spec: f:template: f:metadata: f:annotations: f:cattle.io/timestamp: {} f:field.cattle.io/ports: {} f:spec: f:containers: k:{""name"":""drone-runner-docker""}: f:securityContext: .: {} f:allowPrivilegeEscalation: {} f:capabilities: {} f:privileged: {} manager: Go-http-client operation: Update time: ""2023-09-19T02:39:15Z"" - apiVersion: apps/v1 fieldsType: FieldsV1 fieldsV1: f:status: f:currentNumberScheduled: {} f:desiredNumberScheduled: {} f:numberAvailable: {} f:numberMisscheduled: {} f:numberReady: {} f:observedGeneration: {} f:updatedNumberScheduled: {} manager: kube-controller-manager operation: Update time: ""2023-09-19T02:42:05Z"" name: drone-runner-docker namespace: base resourceVersion: ""59172769"" uid: 3151b2ae-4b84-42fa-9a9b-49ac78cc5b8d spec: revisionHistoryLimit: 10 selector: matchLabels: app: drone-runner-docker template: metadata: annotations: cattle.io/timestamp: ""2023-09-19T02:39:15Z"" field.cattle.io/ports: '[[]]' pod.alpha.kubernetes.io/initialized: ""true"" creationTimestamp: null labels: app: drone-runner-docker spec: containers: - env: - name: DRONE_RPC_HOST value: drone-headless - name: DRONE_RPC_PROTO value: http - name: DRONE_RPC_SECRET value: 325d602f273c2fa9f20c5bd2c4a9abf9 - name: DRONE_RUNNER_CAPACITY value: ""10"" - name: DRONE_RUNNER_NAME value: drone-runner-docker image: drone/drone-runner-docker:1.8.3 imagePullPolicy: IfNotPresent name: drone-runner-docker resources: {} securityContext: allowPrivilegeEscalation: true capabilities: {} privileged: true terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/docker.sock name: docker-socket dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30 volumes: - hostPath: path: /var/run/docker.sock type: Socket name: docker-socket updateStrategy: rollingUpdate: maxUnavailable: 1 type: RollingUpdate status: currentNumberScheduled: 3 desiredNumberScheduled: 3 numberAvailable: 3 numberMisscheduled: 0 numberReady: 3 observedGeneration: 2 updatedNumberScheduled: 3  source-file source-file source-file source-file source-file source-file",no-bug,0.9
255,harness,https://github.com/harness/harness/issues/255,Commits and builds from deleted branches staying around forever,"(Probably a low priority item) It looks like the `Commits` and `Builds` for deleted feature branches hangs around indefinitely in the database and the UI. I think this can be resolved by either one of : - Detect deleted branches and delete the related `Commits` and `Builds` - Allow branches to be deleted via user action from the Drone UI, which would do the above^.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file,"Commits and builds from deleted branches staying around forever (Probably a low priority item) It looks like the `Commits` and `Builds` for deleted feature branches hangs around indefinitely in the database and the UI. I think this can be resolved by either one of : - Detect deleted branches and delete the related `Commits` and `Builds` - Allow branches to be deleted via user action from the Drone UI, which would do the above^. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file other-file other-file other-file",no-bug,0.9
3220,harness,https://github.com/harness/harness/issues/3220,"go mod tidy: go.mod file indicates go 1.18, but maximum supported version is 1.17",<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> 1.18: Pulling from library/golang default: Error response from daemon: No such image: golang:1.18,config-file | source-file | source-file | source-file | source-file,"go mod tidy: go.mod file indicates go 1.18, but maximum supported version is 1.17 <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> 1.18: Pulling from library/golang default: Error response from daemon: No such image: golang:1.18 config-file source-file source-file source-file source-file",no-bug,0.9
2778,harness,https://github.com/harness/harness/issues/2778,drone.yml parsing fails when starting by ,"I am running v1.0.0 and I noticed that when my drone.yml file starts with a `` before my first pipeline definition, the parsing fails. I tried the CLI linter but it doesn't return any error. for example a file starting by yaml kind: pipeline name: unit steps: - name: unit  Will work but this will not: yaml  kind: pipeline name: unit steps: - name: unit ",database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"drone.yml parsing fails when starting by  I am running v1.0.0 and I noticed that when my drone.yml file starts with a `` before my first pipeline definition, the parsing fails. I tried the CLI linter but it doesn't return any error. for example a file starting by yaml kind: pipeline name: unit steps: - name: unit  Will work but this will not: yaml  kind: pipeline name: unit steps: - name: unit  database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3351,harness,https://github.com/harness/harness/issues/3351,Cancellation signal,"Hi. Question is ""What signal Drone sends to launched scripts for its cancellation?"" I need to cancel my scripts when i click ""cancel"" button. But i don't know how to handle this action. Thanks!",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Cancellation signal Hi. Question is ""What signal Drone sends to launched scripts for its cancellation?"" I need to cancel my scripts when i click ""cancel"" button. But i don't know how to handle this action. Thanks! source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3591,harness,https://github.com/harness/harness/issues/3591,How to connect to MySQL in the source code and start harness debugging in Goland?,How to connect to MySQL in the source code and start harness debugging in Goland IDEA?,other-file | source-file | documentation-file | other-file | other-file,How to connect to MySQL in the source code and start harness debugging in Goland? How to connect to MySQL in the source code and start harness debugging in Goland IDEA? other-file source-file documentation-file other-file other-file,no-bug,0.95
3240,harness,https://github.com/harness/harness/issues/3240,Do you have a plan to support jihulab,https://jihulab.com She is actually a localized gitlab.com think,source-file,Do you have a plan to support jihulab https://jihulab.com She is actually a localized gitlab.com think source-file,no-bug,0.9
240,harness,https://github.com/harness/harness/issues/240,I cannot start mysql container,"Hi this project is awesome!, However I have some problems for use the mysql service. I tried to use bradrydzewski/mysql:5.5 image as a service on .drone.yml, but always get this error in Docker logs: -job start(5c2b647855af9a3ec29bdc68b6cbaf74b17fa298707e4005f89f1a30d4b0006f) = ERR (1) [error] server.go:951 Error: Cannot start container 5c2b647855af9a3ec29bdc68b6cbaf74b17fa298707e4005f89f1a30d4b0006f: Cannot link to a non running container: /determined_galileo AS /sick_darwin/mysql [error] server.go:86 HTTP Error: statusCode=500 Cannot start container 5c2b647855af9a3ec29bdc68b6cbaf74b17fa298707e4005f89f1a30d4b0006f: Cannot link to a non running container: /determined_galileo AS /sick_darwin/mysql When I tried to run just the image with this command: docker run -d -p 3306:3306 bradrydzewski/mysql:5.5 I got it this message error: /usr/sbin/mysqld: error while loading shared libraries: libz.so.1: cannot open shared object file: Permission denied How can setup properly this service? I use: Ubuntu 12.04 Docker 0.9.0",database-file | database-file | source-file | source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file,"I cannot start mysql container Hi this project is awesome!, However I have some problems for use the mysql service. I tried to use bradrydzewski/mysql:5.5 image as a service on .drone.yml, but always get this error in Docker logs: -job start(5c2b647855af9a3ec29bdc68b6cbaf74b17fa298707e4005f89f1a30d4b0006f) = ERR (1) [error] server.go:951 Error: Cannot start container 5c2b647855af9a3ec29bdc68b6cbaf74b17fa298707e4005f89f1a30d4b0006f: Cannot link to a non running container: /determined_galileo AS /sick_darwin/mysql [error] server.go:86 HTTP Error: statusCode=500 Cannot start container 5c2b647855af9a3ec29bdc68b6cbaf74b17fa298707e4005f89f1a30d4b0006f: Cannot link to a non running container: /determined_galileo AS /sick_darwin/mysql When I tried to run just the image with this command: docker run -d -p 3306:3306 bradrydzewski/mysql:5.5 I got it this message error: /usr/sbin/mysqld: error while loading shared libraries: libz.so.1: cannot open shared object file: Permission denied How can setup properly this service? I use: Ubuntu 12.04 Docker 0.9.0 database-file database-file source-file source-file source-file documentation-file other-file other-file other-file other-file other-file other-file",no-bug,0.95
2173,harness,https://github.com/harness/harness/issues/2173,add ping message to event secret and log stream,"We should add ping messages to the event stream and log stream. This will ensure a 200 response code is written with the correct content-type. This in turn _should_ ensure the browser automatically re-connects in the event of a gateway timeout. diff flusher, ok := rw.(http.Flusher) if !ok { c.String(500, ""Streaming not supported"") return } + io.WriteString(rw, "": ping\n\n"") + flusher.Flush()  We may also consider periodically pinging the client to keep the connection alive. This might be helpful when running drone behind a load balancer or reverse proxy, which may decide to close connections after periods of inactivity. diff for { select { case <-rw.CloseNotify(): return case <-ctx.Done(): return + case <-time.After(30*time.Second): + io.WriteString(rw, "": ping\n\n"") + flusher.Flush() case buf, ok := <-eventc: if ok { io.WriteString(rw, ""data: "") rw.Write(buf) io.WriteString(rw, ""\n\n"") flusher.Flush() } } } ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"add ping message to event secret and log stream We should add ping messages to the event stream and log stream. This will ensure a 200 response code is written with the correct content-type. This in turn _should_ ensure the browser automatically re-connects in the event of a gateway timeout. diff flusher, ok := rw.(http.Flusher) if !ok { c.String(500, ""Streaming not supported"") return } + io.WriteString(rw, "": ping\n\n"") + flusher.Flush()  We may also consider periodically pinging the client to keep the connection alive. This might be helpful when running drone behind a load balancer or reverse proxy, which may decide to close connections after periods of inactivity. diff for { select { case <-rw.CloseNotify(): return case <-ctx.Done(): return + case <-time.After(30*time.Second): + io.WriteString(rw, "": ping\n\n"") + flusher.Flush() case buf, ok := <-eventc: if ok { io.WriteString(rw, ""data: "") rw.Write(buf) io.WriteString(rw, ""\n\n"") flusher.Flush() } } }  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.85
2806,harness,https://github.com/harness/harness/issues/2806,Running drone-agent error through kubernetes," Environment variable setting  drone-server - name: DRONE_KUBERNETES_ENABLED value: ""true"" - name: DRONE_KUBERNETES_NAMESPACE value: default - name: DRONE_KUBERNETES_SERVICE_ACCOUNT value: drone-pipeline - name: DRONE_GIT_ALWAYS_AUTH value: ""false"" - name: DRONE_RPC_SERVER value: ""http://drone"" - name: DRONE_SERVER_HOST value: ""drone"" - name: DRONE_RPC_PROTO value: ""http"" - name: DRONE_RPC_HOST value: drone.devops:80 - name: DRONE_SERVER_PROTO value: http - name: DRONE_RPC_SECRET valueFrom: secretKeyRef: name: drone-secret key: secret - name: DRONE_DATABASE_DATASOURCE value: ""/var/lib/drone/drone.sqlite"" - name: DRONE_DATABASE_DRIVER value: ""sqlite3"" - name: DRONE_LOGS_DEBUG value: ""true"" - name: DRONE_GITEA_SERVER value: http://gitea.devops:3000  agent   - name: DRONE_RPC_HOST value: http://drone:80 - name: DRONE_SERVER_HOST value: http://drone:80 - name: DRONE_RPC_SERVER value: http://drone:80 - name: DRONE_RPC_SECRET - name: DOCKER_HOST value: tcp://localhost:2375 - name: DRONE_LOGS_DEBUG value: ""true""    ERROR  {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Running drone-agent error through kubernetes  Environment variable setting  drone-server - name: DRONE_KUBERNETES_ENABLED value: ""true"" - name: DRONE_KUBERNETES_NAMESPACE value: default - name: DRONE_KUBERNETES_SERVICE_ACCOUNT value: drone-pipeline - name: DRONE_GIT_ALWAYS_AUTH value: ""false"" - name: DRONE_RPC_SERVER value: ""http://drone"" - name: DRONE_SERVER_HOST value: ""drone"" - name: DRONE_RPC_PROTO value: ""http"" - name: DRONE_RPC_HOST value: drone.devops:80 - name: DRONE_SERVER_PROTO value: http - name: DRONE_RPC_SECRET valueFrom: secretKeyRef: name: drone-secret key: secret - name: DRONE_DATABASE_DATASOURCE value: ""/var/lib/drone/drone.sqlite"" - name: DRONE_DATABASE_DRIVER value: ""sqlite3"" - name: DRONE_LOGS_DEBUG value: ""true"" - name: DRONE_GITEA_SERVER value: http://gitea.devops:3000  agent   - name: DRONE_RPC_HOST value: http://drone:80 - name: DRONE_SERVER_HOST value: http://drone:80 - name: DRONE_RPC_SERVER value: http://drone:80 - name: DRONE_RPC_SECRET - name: DOCKER_HOST value: tcp://localhost:2375 - name: DRONE_LOGS_DEBUG value: ""true""    ERROR  {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""} {""arch"":""amd64"",""error"":""not implemented"",""level"":""warning"",""machine"":""drone-debug"",""msg"":""runner: cannot get queue item"",""os"":""linux"",""time"":""2019-08-29T12:26:15Z""}  source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
726,harness,https://github.com/harness/harness/issues/726,port is dropped during gitlab auth,"I'm trying to run gitlab and drone on same host but different ports. Problem is the auth to gitlab on port (8888) is being dropped for the port that drone is using (8000) func (r *Gitlab) GetHost() string { uri, _ := url.Parse(r.url) return uri.Host } http://10.0.0.242:8000/api/auth/gitlab.com",container-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file,"port is dropped during gitlab auth I'm trying to run gitlab and drone on same host but different ports. Problem is the auth to gitlab on port (8888) is being dropped for the port that drone is using (8000) func (r *Gitlab) GetHost() string { uri, _ := url.Parse(r.url) return uri.Host } http://10.0.0.242:8000/api/auth/gitlab.com container-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file",no-bug,0.8
923,harness,https://github.com/harness/harness/issues/923,gitlab skip_verify don't work,i have a problem with gitlab. our server has a self signed certificate. so i set `skip_verify=true` but get this message: `2015/03/18 13:27:33 Error exchanging token. Post https://our.gitlab-server.de/oauth/token: x509: certificate signed by unknown authority` @Bugagazavr said it is a problem with oauth.,other-file,gitlab skip_verify don't work i have a problem with gitlab. our server has a self signed certificate. so i set `skip_verify=true` but get this message: `2015/03/18 13:27:33 Error exchanging token. Post https://our.gitlab-server.de/oauth/token: x509: certificate signed by unknown authority` @Bugagazavr said it is a problem with oauth. other-file,no-bug,0.8
422,harness,https://github.com/harness/harness/issues/422,Analytics,"Analytics to show how many builds have occurred, the time taken to complete them, etc..",source-file,"Analytics Analytics to show how many builds have occurred, the time taken to complete them, etc.. source-file",no-bug,0.9
2007,harness,https://github.com/harness/harness/issues/2007,Disable environment variables for plugins in yaml,"Proposal to return a lint error when the user attempts to declare environment variables for plugin steps in the yaml. For example, the following would fail with lint errors:  pipeline: slack: image: plugins/slack environment: - DEBUG=true  Instead the plugin author should create input parameters that in turn set the appropriate environment variables when the plugin initializes. diff pipeline: slack: image: plugins/slack + debug: true - environment: - - DEBUG=true ",other-file,"Disable environment variables for plugins in yaml Proposal to return a lint error when the user attempts to declare environment variables for plugin steps in the yaml. For example, the following would fail with lint errors:  pipeline: slack: image: plugins/slack environment: - DEBUG=true  Instead the plugin author should create input parameters that in turn set the appropriate environment variables when the plugin initializes. diff pipeline: slack: image: plugins/slack + debug: true - environment: - - DEBUG=true  other-file",no-bug,0.9
2634,harness,https://github.com/harness/harness/issues/2634,trigger should handle skipped dependencies,"Scenario: Multiple pipelines with dependencies:   kind: pipeline name: testing steps: - name: test  kind: pipeline name: build steps: - name: build depends_on: testing  kind: pipeline name: notification steps: - name: notify depends_on: build trigger: status: - success - failure  This pipeline will run forever (till manual killing) if testing pipeline failed. As result, of failing testing pipeline build pipeline will be skipped and notifications will stay in `waiting on dependencies`. I try to add `- skipped` or `- skip` to the pipeline trigger, but this seems not to work. Sometimes e.g. for notification tasks it would be nice to have an option to always run a pipeline/task maybe something like  trigger: status: always  Here is a currently running demo: https://cloud.drone.io/xoxys/drone-webhook/5",other-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | config-file | source-file | source-file | config-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file,"trigger should handle skipped dependencies Scenario: Multiple pipelines with dependencies:   kind: pipeline name: testing steps: - name: test  kind: pipeline name: build steps: - name: build depends_on: testing  kind: pipeline name: notification steps: - name: notify depends_on: build trigger: status: - success - failure  This pipeline will run forever (till manual killing) if testing pipeline failed. As result, of failing testing pipeline build pipeline will be skipped and notifications will stay in `waiting on dependencies`. I try to add `- skipped` or `- skip` to the pipeline trigger, but this seems not to work. Sometimes e.g. for notification tasks it would be nice to have an option to always run a pipeline/task maybe something like  trigger: status: always  Here is a currently running demo: https://cloud.drone.io/xoxys/drone-webhook/5 other-file source-file source-file test-file source-file source-file source-file source-file source-file config-file source-file source-file config-file config-file config-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
188,harness,https://github.com/harness/harness/issues/188,#186 resulted in regression for #51,"refs. #186 , #51 Any thoughts about using http://www.gorillatoolkit.org/pkg/pat instead? Haven't check it yet, but it seems it will allows us to match slashes with some regex.",other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"#186 resulted in regression for #51 refs. #186 , #51 Any thoughts about using http://www.gorillatoolkit.org/pkg/pat instead? Haven't check it yet, but it seems it will allows us to match slashes with some regex. other-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.3
680,harness,https://github.com/harness/harness/issues/680,.drone.yml confusion,"Is `.drone.yml` only a Drone open-source thing? I'm trying to use it on drone.io, and it's not seeming to be picked up at all. Is there some way to enable it? If so, can I also use a custom docker image on the hosted drone.io version? Is there an article somewhere explaining what the differences are between the hosted and open-source versions, which features are only in one or the other, and if there are planned timelines for synchronizing the two? Thanks.",source-file,".drone.yml confusion Is `.drone.yml` only a Drone open-source thing? I'm trying to use it on drone.io, and it's not seeming to be picked up at all. Is there some way to enable it? If so, can I also use a custom docker image on the hosted drone.io version? Is there an article somewhere explaining what the differences are between the hosted and open-source versions, which features are only in one or the other, and if there are planned timelines for synchronizing the two? Thanks. source-file",no-bug,0.95
1125,harness,https://github.com/harness/harness/issues/1125,Push docker image to multiple locations,"We are building a platform that uses Drone for CI and building Docker images. We would like to push some docker images to more than one repository on bintray. As it stands right now, we can only push to one location, limiting our functionality. It would be great to be able to specify more than one docker push destination",other-file,"Push docker image to multiple locations We are building a platform that uses Drone for CI and building Docker images. We would like to push some docker images to more than one repository on bintray. As it stands right now, we can only push to one location, limiting our functionality. It would be great to be able to specify more than one docker push destination other-file",no-bug,0.95
515,harness,https://github.com/harness/harness/issues/515,SQLite varchar max length issue,In your SQLite database schema the max length for `repos.private_key` is 1024. There exists a problem where SQLite does not actually enforce the max. You can freely put more than 1024 characters in this field and SQLite will store all the values. Most values found in `repos.private_key` end up being about 1679 characters in length. I discovered this problem attempting to migrate our existing SQLite data to MySQL. In MySQL the schema for `repos.private_key` is 1024 as wellbut MySQL enforces the max value truncating the input to fit. The max length for `repos.private_key` (and possibly other fields) needs to be adjusted in the scripts that create the MySQL database.,documentation-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file,SQLite varchar max length issue In your SQLite database schema the max length for `repos.private_key` is 1024. There exists a problem where SQLite does not actually enforce the max. You can freely put more than 1024 characters in this field and SQLite will store all the values. Most values found in `repos.private_key` end up being about 1679 characters in length. I discovered this problem attempting to migrate our existing SQLite data to MySQL. In MySQL the schema for `repos.private_key` is 1024 as wellbut MySQL enforces the max value truncating the input to fit. The max length for `repos.private_key` (and possibly other fields) needs to be adjusted in the scripts that create the MySQL database. documentation-file other-file other-file source-file other-file other-file other-file source-file other-file source-file other-file other-file other-file,no-bug,0.9
3312,harness,https://github.com/harness/harness/issues/3312,Dose it support coding.net? Thanks,<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io -->,source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file,Dose it support coding.net? Thanks <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> source-file source-file source-file documentation-file source-file source-file source-file source-file,no-bug,0.9
903,harness,https://github.com/harness/harness/issues/903,Drone using outdated docker images,"It looks like Drone isn't pulling in new versions of docker images when one is available. I haven't inspected the code yet, but I suspect that Drone simply runs `docker run`, which does download the image if missing, but doesn't download a new image if one is already available. Instead, it should first `docker pull` before running the container.",source-file | source-file,"Drone using outdated docker images It looks like Drone isn't pulling in new versions of docker images when one is available. I haven't inspected the code yet, but I suspect that Drone simply runs `docker run`, which does download the image if missing, but doesn't download a new image if one is already available. Instead, it should first `docker pull` before running the container. source-file source-file",no-bug,0.9
551,harness,https://github.com/harness/harness/issues/551,Makefile install error,"While trying to build dron, I got this error:  root@6f815a6b46e3:/gopath/src/github.com/drone/drone# make deps build test embed install  install -t /usr/local/bin debian/drone/usr/local/bin/drone install: cannot stat `debian/drone/usr/local/bin/drone': No such file or directory make:  [install] Error 1  the Makefile install seems have a wrong source dir?",source-file | documentation-file | other-file | source-file | other-file,"Makefile install error While trying to build dron, I got this error:  root@6f815a6b46e3:/gopath/src/github.com/drone/drone# make deps build test embed install  install -t /usr/local/bin debian/drone/usr/local/bin/drone install: cannot stat `debian/drone/usr/local/bin/drone': No such file or directory make:  [install] Error 1  the Makefile install seems have a wrong source dir? source-file documentation-file other-file source-file other-file",no-bug,0.95
2525,harness,https://github.com/harness/harness/issues/2525,1.0.0.-rc.1 agent - invalid character '<' looking for beginning of value,"Running agent rc.1 throws the following error in logs {""level"":""error"",""error"":""invalid character '<' looking for beginning of value"",""platform"":""linux/amd64"",""time"":""2018-11-11T20:07:46Z"",""message"":""cannot get queue item""} the agent call the rpc service ""POST /rpc/v1/request"" response ""<!DOCTYPE html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content=""IE=edge""><meta name=viewport content=""width=device-width,initial-scale=1""><link rel=icon href=/favicon.png><title>Drone | Continuous Integration</title><link href=/css/app.b667b0e1.css rel=preload as=style><link href=/js/app.28abcb1f.js rel=preload as=script><link href=/js/chunk-vendors.6bc2aeab.js rel=preload as=script><link href=/css/app.b667b0e1.css rel=stylesheet></head><body><noscript><strong>We're sorry but Drone does not work properly without JavaScript enabled. Please enable it to continue.</strong></noscript><div id=app></div><script src=/js/chunk-vendors.6bc2aeab.js></script><script src=/js/app.28abcb1f.js></script></body></html>""",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"1.0.0.-rc.1 agent - invalid character '<' looking for beginning of value Running agent rc.1 throws the following error in logs {""level"":""error"",""error"":""invalid character '<' looking for beginning of value"",""platform"":""linux/amd64"",""time"":""2018-11-11T20:07:46Z"",""message"":""cannot get queue item""} the agent call the rpc service ""POST /rpc/v1/request"" response ""<!DOCTYPE html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content=""IE=edge""><meta name=viewport content=""width=device-width,initial-scale=1""><link rel=icon href=/favicon.png><title>Drone | Continuous Integration</title><link href=/css/app.b667b0e1.css rel=preload as=style><link href=/js/app.28abcb1f.js rel=preload as=script><link href=/js/chunk-vendors.6bc2aeab.js rel=preload as=script><link href=/css/app.b667b0e1.css rel=stylesheet></head><body><noscript><strong>We're sorry but Drone does not work properly without JavaScript enabled. Please enable it to continue.</strong></noscript><div id=app></div><script src=/js/chunk-vendors.6bc2aeab.js></script><script src=/js/app.28abcb1f.js></script></body></html>"" source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.95
3426,harness,https://github.com/harness/harness/issues/3426,Gitness itself supports deployment to kubernetes ?,"It seems to share the sock file when running in docker, how do I deploy it if my kubernetes cluster uses containerd.",source-file | source-file | source-file | source-file | source-file | source-file,"Gitness itself supports deployment to kubernetes ? It seems to share the sock file when running in docker, how do I deploy it if my kubernetes cluster uses containerd. source-file source-file source-file source-file source-file source-file",no-bug,0.9
137,harness,https://github.com/harness/harness/issues/137,Global settings,Can we have global settings so we only have to set global settings once for all the projects?,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Global settings Can we have global settings so we only have to set global settings once for all the projects? source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
2869,harness,https://github.com/harness/harness/issues/2869,nil pointer dereference on linter,"**log** bash {""arch"":""amd64"",""build"":46,""level"":""error"",""machine"":""ip-192-168-123-142.ap-northeast-1.compute.internal"",""msg"":""runner: unexpected panic: runtime error: invalid memory address or nil pointer dereference"",""os"":""linux"",""pipeline"":""api-gateway-k8s"",""repo"":""iftechio/api-gateway-k8s"",""stage"":1,""stage-id"":6438,""time"":""2019-11-05T09:15:03Z""} goroutine 1 [running]: runtime/debug.Stack(0x1, 0x1, 0x1) /usr/local/go/src/runtime/debug/stack.go:24 +0x9d runtime/debug.PrintStack() /usr/local/go/src/runtime/debug/stack.go:16 +0x22 github.com/drone/drone/operator/runner.(*Runner).Run.func1(0xc0006d67a0) /drone/src/operator/runner/runner.go:134 +0xa1 panic(0x11e3740, 0x1da0110) /usr/local/go/src/runtime/panic.go:679 +0x1b2 github.com/drone/drone-yaml/yaml/linter.checkPipeline(0xc0004bea80, 0x0, 0x0, 0xc0008cd9c0) /go/pkg/mod/github.com/drone/drone-yaml@v1.2.3-0.20190902155851-ad8ad9816fbf/yaml/linter/linter.go:80 +0x1ac github.com/drone/drone-yaml/yaml/linter.Lint(0x1521dc0, 0xc0004bea80, 0xc00040e400, 0x8, 0xc0006d7260) /go/pkg/mod/github.com/drone/drone-yaml@v1.2.3-0.20190902155851-ad8ad9816fbf/yaml/linter/linter.go:54 +0x337 github.com/drone/drone/operator/runner.(*Runner).Run(0xc0004b4600, 0x154ec40, 0xc00030ba80, 0x1926, 0x0, 0x0) /drone/src/operator/runner/runner.go:234 +0x185a main.main()  **recurrent** When using starlark, during the step creation phase, a function returns null incorrectly. py def make_pipeline(ctx): return { 'kind': 'pipeline', 'name': 'xxx', 'steps': [ get_null(),  ] }  In the web page, the build has been in the Pending state, so I looked at the log and found this problem. fix in [drone-yaml#55](https://github.com/drone/drone-yaml/pull/55)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"nil pointer dereference on linter **log** bash {""arch"":""amd64"",""build"":46,""level"":""error"",""machine"":""ip-192-168-123-142.ap-northeast-1.compute.internal"",""msg"":""runner: unexpected panic: runtime error: invalid memory address or nil pointer dereference"",""os"":""linux"",""pipeline"":""api-gateway-k8s"",""repo"":""iftechio/api-gateway-k8s"",""stage"":1,""stage-id"":6438,""time"":""2019-11-05T09:15:03Z""} goroutine 1 [running]: runtime/debug.Stack(0x1, 0x1, 0x1) /usr/local/go/src/runtime/debug/stack.go:24 +0x9d runtime/debug.PrintStack() /usr/local/go/src/runtime/debug/stack.go:16 +0x22 github.com/drone/drone/operator/runner.(*Runner).Run.func1(0xc0006d67a0) /drone/src/operator/runner/runner.go:134 +0xa1 panic(0x11e3740, 0x1da0110) /usr/local/go/src/runtime/panic.go:679 +0x1b2 github.com/drone/drone-yaml/yaml/linter.checkPipeline(0xc0004bea80, 0x0, 0x0, 0xc0008cd9c0) /go/pkg/mod/github.com/drone/drone-yaml@v1.2.3-0.20190902155851-ad8ad9816fbf/yaml/linter/linter.go:80 +0x1ac github.com/drone/drone-yaml/yaml/linter.Lint(0x1521dc0, 0xc0004bea80, 0xc00040e400, 0x8, 0xc0006d7260) /go/pkg/mod/github.com/drone/drone-yaml@v1.2.3-0.20190902155851-ad8ad9816fbf/yaml/linter/linter.go:54 +0x337 github.com/drone/drone/operator/runner.(*Runner).Run(0xc0004b4600, 0x154ec40, 0xc00030ba80, 0x1926, 0x0, 0x0) /drone/src/operator/runner/runner.go:234 +0x185a main.main()  **recurrent** When using starlark, during the step creation phase, a function returns null incorrectly. py def make_pipeline(ctx): return { 'kind': 'pipeline', 'name': 'xxx', 'steps': [ get_null(),  ] }  In the web page, the build has been in the Pending state, so I looked at the log and found this problem. fix in [drone-yaml#55](https://github.com/drone/drone-yaml/pull/55) source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3043,harness,https://github.com/harness/harness/issues/3043,Drone server 0.10.0 was not versioned properly,See https://github.com/drone/drone/blob/v1.10.0/version/version.go,source-file | source-file,Drone server 0.10.0 was not versioned properly See https://github.com/drone/drone/blob/v1.10.0/version/version.go source-file source-file,no-bug,0.8
1059,harness,https://github.com/harness/harness/issues/1059,Error 1050: Table 'migration_version' already exists,"I'm running Drone in a Docker container and I've got it linked to a MySQL container. If I try to re-run the image, I get the following error and the container stops:  2015-06-13T19:49:44.903647213Z panic: Could not get DB version: Error 1050: Table 'migration_version' already exists 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 16 [running]: 2015-06-13T19:49:44.903647213Z runtime.panic(0xaac3c0, 0xc208170440) 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 2015-06-13T19:49:44.903647213Z github.com/drone/drone/server/datastore/database.MustConnect(0xc208135fd8, 0x5, 0xc208161520, 0x1e, 0x0) 2015-06-13T19:49:44.903647213Z /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:52 +0x8a 2015-06-13T19:49:44.903647213Z main.main() 2015-06-13T19:49:44.903647213Z /var/cache/drone/src/github.com/drone/drone/server/main.go:104 +0x274 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 19 [finalizer wait]: 2015-06-13T19:49:44.903647213Z runtime.park(0x4a8630, 0x11bcf58, 0x11a79a9) 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 2015-06-13T19:49:44.903647213Z runtime.parkunlock(0x11bcf58, 0x11a79a9) 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b 2015-06-13T19:49:44.903647213Z runfinq() 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf 2015-06-13T19:49:44.903647213Z runtime.goexit() 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/proc.c:1445 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 22 [syscall]: 2015-06-13T19:49:44.903647213Z os/signal.loop() 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e 2015-06-13T19:49:44.903647213Z created by os/signal.init1 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 24 [chan receive]: 2015-06-13T19:49:44.903647213Z database/sql.(*DB).connectionOpener(0xc208050600) 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 2015-06-13T19:49:44.903647213Z created by database/sql.Open 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 17 [syscall]: 2015-06-13T19:49:44.903647213Z runtime.goexit() 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/proc.c:1445  This might be more of an issue with the migration library not being able to handle this case, but it's the last issue I'm having with what is otherwise an awesome CI setup. Thank you.",source-file | source-file | source-file | source-file,"Error 1050: Table 'migration_version' already exists I'm running Drone in a Docker container and I've got it linked to a MySQL container. If I try to re-run the image, I get the following error and the container stops:  2015-06-13T19:49:44.903647213Z panic: Could not get DB version: Error 1050: Table 'migration_version' already exists 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 16 [running]: 2015-06-13T19:49:44.903647213Z runtime.panic(0xaac3c0, 0xc208170440) 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 2015-06-13T19:49:44.903647213Z github.com/drone/drone/server/datastore/database.MustConnect(0xc208135fd8, 0x5, 0xc208161520, 0x1e, 0x0) 2015-06-13T19:49:44.903647213Z /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:52 +0x8a 2015-06-13T19:49:44.903647213Z main.main() 2015-06-13T19:49:44.903647213Z /var/cache/drone/src/github.com/drone/drone/server/main.go:104 +0x274 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 19 [finalizer wait]: 2015-06-13T19:49:44.903647213Z runtime.park(0x4a8630, 0x11bcf58, 0x11a79a9) 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 2015-06-13T19:49:44.903647213Z runtime.parkunlock(0x11bcf58, 0x11a79a9) 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b 2015-06-13T19:49:44.903647213Z runfinq() 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf 2015-06-13T19:49:44.903647213Z runtime.goexit() 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/proc.c:1445 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 22 [syscall]: 2015-06-13T19:49:44.903647213Z os/signal.loop() 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e 2015-06-13T19:49:44.903647213Z created by os/signal.init1 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 24 [chan receive]: 2015-06-13T19:49:44.903647213Z database/sql.(*DB).connectionOpener(0xc208050600) 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 2015-06-13T19:49:44.903647213Z created by database/sql.Open 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c 2015-06-13T19:49:44.903647213Z 2015-06-13T19:49:44.903647213Z goroutine 17 [syscall]: 2015-06-13T19:49:44.903647213Z runtime.goexit() 2015-06-13T19:49:44.903647213Z /usr/local/go/src/pkg/runtime/proc.c:1445  This might be more of an issue with the migration library not being able to handle this case, but it's the last issue I'm having with what is otherwise an awesome CI setup. Thank you. source-file source-file source-file source-file",no-bug,0.95
2171,harness,https://github.com/harness/harness/issues/2171,Add Drone Agent build filtering,"Particularly in cloud environments with instance-based IAM systems, it's important to make sure that builds run on the instance with the most appropriate IAM profiles relative to the build. For example: * If repo1 requires pushing artifacts to an S3 or GS bucket, it'll need to run on an instance that has the correct IAM profile. * If repo2 does not require elevated privs, it should not run on an instance with IAM privs that it does not need. While this could be managed with .drone.yaml labels, doing this at the agent level for critical/sensitive builds would lessen the likelihood of external change. For example: * I set some labels in my .drone.yaml, pointing at a particular subset of my cluster that is only for this build. * Someone sneaks a label change into one of my hundreds of other repos, thus giving the malicious party an open avenue for messing with whatever privs my IAM profile grants. I won't be very prescriptive about implementation details, but here are the things that would be great to be able to do: * Glob org and/or repo names: `myorg/some*`, `my*/someprefix-*`. This can be potentially dangerous in environments without strict control over repo creation, so we may consider including a note warning as such. * Set multiple patterns to match: `myorg/repo1,myorg/repo2`",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Add Drone Agent build filtering Particularly in cloud environments with instance-based IAM systems, it's important to make sure that builds run on the instance with the most appropriate IAM profiles relative to the build. For example: * If repo1 requires pushing artifacts to an S3 or GS bucket, it'll need to run on an instance that has the correct IAM profile. * If repo2 does not require elevated privs, it should not run on an instance with IAM privs that it does not need. While this could be managed with .drone.yaml labels, doing this at the agent level for critical/sensitive builds would lessen the likelihood of external change. For example: * I set some labels in my .drone.yaml, pointing at a particular subset of my cluster that is only for this build. * Someone sneaks a label change into one of my hundreds of other repos, thus giving the malicious party an open avenue for messing with whatever privs my IAM profile grants. I won't be very prescriptive about implementation details, but here are the things that would be great to be able to do: * Glob org and/or repo names: `myorg/some*`, `my*/someprefix-*`. This can be potentially dangerous in environments without strict control over repo creation, so we may consider including a note warning as such. * Set multiple patterns to match: `myorg/repo1,myorg/repo2` source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
1041,harness,https://github.com/harness/harness/issues/1041,White Page with logging in via Github oauth,"After setting up Github oauth, I'm redirected to a white page when Github redirects my login to the Drone Callback URL. Any one having this same issue?",other-file | source-file | other-file | source-file | documentation-file | other-file | other-file | other-file,"White Page with logging in via Github oauth After setting up Github oauth, I'm redirected to a white page when Github redirects my login to the Drone Callback URL. Any one having this same issue? other-file source-file other-file source-file documentation-file other-file other-file other-file",no-bug,0.8
3336,harness,https://github.com/harness/harness/issues/3336,Use Org. Templates and Secrets by Admins of Project/s in BitBucket DataCenter (On-premise),"Hello all!, We are running Drone, with license, for some time (3-4 years), everyone is happy with the platform and the possibilities, and now the users start becoming more enterprise-focused. They want to use the Organization templates and/or secrets and standardize some of their pipelines, but here we face an issue that we cannot solve, they must be admins of drone, although they are Admins of the Project in Bitbucket DataCenter (on-premise). But, we don't want them to manage the users of drone. Perhaps you don't know it, a Project in Bitbucket is a set of repositories, that can have a centralized RBAC. Our goal, as CI/CD platform provider, is to delegate to them the creation and maintenance of these Organization's templates and secrets. Did I miss any configuration in drone's deployment? If not, Could you review if it is feasible in your architecture? Cheers, Miguel",source-file,"Use Org. Templates and Secrets by Admins of Project/s in BitBucket DataCenter (On-premise) Hello all!, We are running Drone, with license, for some time (3-4 years), everyone is happy with the platform and the possibilities, and now the users start becoming more enterprise-focused. They want to use the Organization templates and/or secrets and standardize some of their pipelines, but here we face an issue that we cannot solve, they must be admins of drone, although they are Admins of the Project in Bitbucket DataCenter (on-premise). But, we don't want them to manage the users of drone. Perhaps you don't know it, a Project in Bitbucket is a set of repositories, that can have a centralized RBAC. Our goal, as CI/CD platform provider, is to delegate to them the creation and maintenance of these Organization's templates and secrets. Did I miss any configuration in drone's deployment? If not, Could you review if it is feasible in your architecture? Cheers, Miguel source-file",no-bug,0.9
2947,harness,https://github.com/harness/harness/issues/2947,Windows exec runner,"Hi, I'm getting `Host key verification failed.` when trying to clone a repository through ssh protocol. In cmd and PS it clones it without any problem. First I thought maybe it's the user, and I went and changed it on Computer Management -> Services -> drone-runner-exec to be run as local user not `SYSTEM` user. Same thing. Then I went and ran drone-runner-exec.exe (btw it does not have `.exe` at the end when one downloads it) directly on cmd.exe; but same thing. Interestingly runner gives `msg=""cannot accept stage"" error=""Optimistic Lock Error""` and on server output is: `Host key verification failed.` from git command. Please help, Regards",database-file | database-file | database-file | database-file,"Windows exec runner Hi, I'm getting `Host key verification failed.` when trying to clone a repository through ssh protocol. In cmd and PS it clones it without any problem. First I thought maybe it's the user, and I went and changed it on Computer Management -> Services -> drone-runner-exec to be run as local user not `SYSTEM` user. Same thing. Then I went and ran drone-runner-exec.exe (btw it does not have `.exe` at the end when one downloads it) directly on cmd.exe; but same thing. Interestingly runner gives `msg=""cannot accept stage"" error=""Optimistic Lock Error""` and on server output is: `Host key verification failed.` from git command. Please help, Regards database-file database-file database-file database-file",no-bug,0.9
2762,harness,https://github.com/harness/harness/issues/2762,Unable to deploy using the drone cli,"Our application's drone.yaml file is currently in drone v0.8.0 and has yet to be migrated to v1.0.0. My drone cli is version 1.1.0. Do I need to downgrade my drone cli to v0.8.0 or is this backwards compatible? Both `drone deploy` and `drone build promote` dont work, I get this error: `invalid character '<' looking for beginning of value`. Can anyone provide some support on this?",source-file | source-file,"Unable to deploy using the drone cli Our application's drone.yaml file is currently in drone v0.8.0 and has yet to be migrated to v1.0.0. My drone cli is version 1.1.0. Do I need to downgrade my drone cli to v0.8.0 or is this backwards compatible? Both `drone deploy` and `drone build promote` dont work, I get this error: `invalid character '<' looking for beginning of value`. Can anyone provide some support on this? source-file source-file",no-bug,0.9
767,harness,https://github.com/harness/harness/issues/767,websocket problem when deployed behind nginx,"When drone is deployed behind nginx, the websocket support is broken even if nginx is configured as per http://readme.drone.io/setup/misc/nginx/ After some debugging, I found the problem is that gorilla/websocket library by default checks whether the Host header matches the Origin header, and return a 403 Forbidden when they don't match. When using nginx, the `Origin` header is the external url, and the `Host` header is the address drone is listening on, so they differ and the browser get a 403 for websocket requests. The correspondent code is [here](https://github.com/gorilla/websocket/blob/9007e29/server.go#L62) . A temporary hack is to set the origin header to an empty string in nginx configration, e.g:  nginx location /api/stream { proxy_pass http://127.0.0.1:8000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_set_header Origin ''; }  The above hack works for me, but I hope we can find a more elegant solution for this.",source-file,"websocket problem when deployed behind nginx When drone is deployed behind nginx, the websocket support is broken even if nginx is configured as per http://readme.drone.io/setup/misc/nginx/ After some debugging, I found the problem is that gorilla/websocket library by default checks whether the Host header matches the Origin header, and return a 403 Forbidden when they don't match. When using nginx, the `Origin` header is the external url, and the `Host` header is the address drone is listening on, so they differ and the browser get a 403 for websocket requests. The correspondent code is [here](https://github.com/gorilla/websocket/blob/9007e29/server.go#L62) . A temporary hack is to set the origin header to an empty string in nginx configration, e.g:  nginx location /api/stream { proxy_pass http://127.0.0.1:8000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_set_header Origin ''; }  The above hack works for me, but I hope we can find a more elegant solution for this. source-file",no-bug,0.9
386,harness,https://github.com/harness/harness/issues/386,No way to run database migrations in heroku,At the moment there's no real way to run database migrations for heroku. I guess the heroku app would have to be installed.,other-file,No way to run database migrations in heroku At the moment there's no real way to run database migrations for heroku. I guess the heroku app would have to be installed. other-file,no-bug,0.9
3019,harness,https://github.com/harness/harness/issues/3019,Gitlab Groups/SubGroups Roadmap,"Hello all, Just a simple question, is there a roadmap to solve the problem with groups/subgroups when using gitlab? Thanks!",source-file,"Gitlab Groups/SubGroups Roadmap Hello all, Just a simple question, is there a roadmap to solve the problem with groups/subgroups when using gitlab? Thanks! source-file",no-bug,0.9
3320,harness,https://github.com/harness/harness/issues/3320,Can drone support --pid=host when type = k8s,"Currently, it seems that Drone does not support adding the --pid=host option during container startup. We have encountered situations where certain tasks need to be executed within the container, and these tasks require mapping of specific drivers or components into the container. In the process of running the program, it is necessary to fetch the PID information of these drivers, and it is required to maintain consistency between the PIDs inside and outside the container, similar to Docker's --pid=host option. Can this feature be added in future versions?",source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file,"Can drone support --pid=host when type = k8s Currently, it seems that Drone does not support adding the --pid=host option during container startup. We have encountered situations where certain tasks need to be executed within the container, and these tasks require mapping of specific drivers or components into the container. In the process of running the program, it is necessary to fetch the PID information of these drivers, and it is required to maintain consistency between the PIDs inside and outside the container, similar to Docker's --pid=host option. Can this feature be added in future versions? source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file",no-bug,0.9
413,harness,https://github.com/harness/harness/issues/413,docker/utils/utils.go Upstream changes due,"I was just working on some code and noted that, with the current master branch of `dotcloud/docker`, they've relocated all the parsing functions as part of [this merge](https://github.com/docker/docker/pull/7286). Not sure what the projects policy is on development (whether you dev against master from upstream packages, or pinning them), so I thought I'd just make note of it.",other-file | other-file | other-file | other-file | other-file | other-file,"docker/utils/utils.go Upstream changes due I was just working on some code and noted that, with the current master branch of `dotcloud/docker`, they've relocated all the parsing functions as part of [this merge](https://github.com/docker/docker/pull/7286). Not sure what the projects policy is on development (whether you dev against master from upstream packages, or pinning them), so I thought I'd just make note of it. other-file other-file other-file other-file other-file other-file",no-bug,0.9
89,harness,https://github.com/harness/harness/issues/89,Build doesn't run anything,"It seems like I have everything hooked up properly but somehow, my tests don't run. Here's my `.drone.yml`:  image: ruby2.0.0 script: - bundle install - bundle exec rake db:create db:schema:load spec services: - mysql - elasticsearch - redis - memcached  And a screenshot: ![2014-02-17 at 2 34 pm](https://f.cloud.github.com/assets/412/2188723/92ca323e-980a-11e3-9a53-f48431c10f9c.png) Any idea?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Build doesn't run anything It seems like I have everything hooked up properly but somehow, my tests don't run. Here's my `.drone.yml`:  image: ruby2.0.0 script: - bundle install - bundle exec rake db:create db:schema:load spec services: - mysql - elasticsearch - redis - memcached  And a screenshot: ![2014-02-17 at 2 34 pm](https://f.cloud.github.com/assets/412/2188723/92ca323e-980a-11e3-9a53-f48431c10f9c.png) Any idea? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
815,harness,https://github.com/harness/harness/issues/815,gnu awk missing,"My ./configure script is failing, as it doesn't find gawk:  Checking 'gawk' failed. Build dependency: Please install GNU awk.  Can you include it in the build drone images?",source-file | source-file | source-file | source-file | source-file | source-file,"gnu awk missing My ./configure script is failing, as it doesn't find gawk:  Checking 'gawk' failed. Build dependency: Please install GNU awk.  Can you include it in the build drone images? source-file source-file source-file source-file source-file source-file",no-bug,0.9
2781,harness,https://github.com/harness/harness/issues/2781,Manually Triggering a Cron Job,"Currently the [cron-api](https://docs.drone.io/api/cron/) does not allow to manually trigger a cron job. <img width=""257"" alt=""Screen Shot 2019-08-08 at 10 42 42 AM"" src=""https://user-images.githubusercontent.com/29871004/62725083-4cd36c00-b9c9-11e9-876d-6587fea0261d.png""> As suggested by @bradrydzewski : > something like `POST /api/repos/{namespace}/{name}/crons/{cron}/run` If time permits, a button to trigger on the UI would be great as well :) Thanks and keep doing great work!",documentation-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | documentation-file | source-file | other-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | documentation-file | other-file | source-file | other-file,"Manually Triggering a Cron Job Currently the [cron-api](https://docs.drone.io/api/cron/) does not allow to manually trigger a cron job. <img width=""257"" alt=""Screen Shot 2019-08-08 at 10 42 42 AM"" src=""https://user-images.githubusercontent.com/29871004/62725083-4cd36c00-b9c9-11e9-876d-6587fea0261d.png""> As suggested by @bradrydzewski : > something like `POST /api/repos/{namespace}/{name}/crons/{cron}/run` If time permits, a button to trigger on the UI would be great as well :) Thanks and keep doing great work! documentation-file source-file source-file test-file source-file source-file test-file source-file documentation-file source-file other-file source-file source-file other-file other-file source-file source-file source-file other-file other-file other-file source-file other-file other-file other-file source-file documentation-file other-file source-file other-file",no-bug,0.9
734,harness,https://github.com/harness/harness/issues/734,Docker publish won't trigger if script: [] is empty or exits quickly,"I managed to figure out why docker publish does not trigger. Reproduce:  yaml image: <any image with git> publish: docker: image_name: foobar <>  As a workaround, I added `sleep 5` to `script: []`.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | test-file,"Docker publish won't trigger if script: [] is empty or exits quickly I managed to figure out why docker publish does not trigger. Reproduce:  yaml image: <any image with git> publish: docker: image_name: foobar <>  As a workaround, I added `sleep 5` to `script: []`. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file test-file source-file test-file",no-bug,0.9
2898,harness,https://github.com/harness/harness/issues/2898,[feature] ytt templating of .drone.yml,"From my perspective, [ytt](https://get-ytt.io/) is more approachable than jsonnet and even starlark. It has many of the same benefits of the other two but doesn't require completely switching to a new DSL for basic language features. Being able to have drone render yaml with ytt would be a welcome improvement.",source-file,"[feature] ytt templating of .drone.yml From my perspective, [ytt](https://get-ytt.io/) is more approachable than jsonnet and even starlark. It has many of the same benefits of the other two but doesn't require completely switching to a new DSL for basic language features. Being able to have drone render yaml with ytt would be a welcome improvement. source-file",no-bug,0.9
2606,harness,https://github.com/harness/harness/issues/2606,"Ability to filter logs (for example, to mask passwords)","Hello, I see that #2308 introduced a way of purging logs via an HTTP request, in case you exposed passwords by mistake in the logs. As mentioned in #1584, other CI systems such as Travis or Jenkins provide features for filtering out logs to ensure no secrets are displayed. Is there a mechanism that would allow one to filter logs displayed in the user interface, otherwise is there a way one can write a plugin to do so ? Thanks a lot !",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Ability to filter logs (for example, to mask passwords) Hello, I see that #2308 introduced a way of purging logs via an HTTP request, in case you exposed passwords by mistake in the logs. As mentioned in #1584, other CI systems such as Travis or Jenkins provide features for filtering out logs to ensure no secrets are displayed. Is there a mechanism that would allow one to filter logs displayed in the user interface, otherwise is there a way one can write a plugin to do so ? Thanks a lot ! source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
105,harness,https://github.com/harness/harness/issues/105,Allow account creation/authentication with github,"If github is linked to drone, it would be nice to just use the authentication built into github to allow users to sign up and log into drone.",source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file,"Allow account creation/authentication with github If github is linked to drone, it would be nice to just use the authentication built into github to allow users to sign up and log into drone. source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file",no-bug,0.9
3334,harness,https://github.com/harness/harness/issues/3334,"Vulnerability of dependency ""golang.org/x/net""","Hello, we are a team researching the dependency management mechanism of Golang. During our analysis, we came across your project and noticed that it contains a vulnerability ([[CVE-2022-41723](https://github.com/advisories/GHSA-vvpx-j8f3-3w6h)](https://github.com/advisories/GHSA-vvpx-j8f3-3w6h)). In your project, the golang.org/x/net package is being used at version v0.0.0-20201202161906-c7110b5ffcbb, but the patched version is v0.7.0. To fix the vulnerability, we recommend modifying the go.mod file to update the version to v0.7.0. Thank you for your attention to this matter.",other-file,"Vulnerability of dependency ""golang.org/x/net"" Hello, we are a team researching the dependency management mechanism of Golang. During our analysis, we came across your project and noticed that it contains a vulnerability ([[CVE-2022-41723](https://github.com/advisories/GHSA-vvpx-j8f3-3w6h)](https://github.com/advisories/GHSA-vvpx-j8f3-3w6h)). In your project, the golang.org/x/net package is being used at version v0.0.0-20201202161906-c7110b5ffcbb, but the patched version is v0.7.0. To fix the vulnerability, we recommend modifying the go.mod file to update the version to v0.7.0. Thank you for your attention to this matter. other-file",no-bug,0.95
860,harness,https://github.com/harness/harness/issues/860,Gogs Private Repos,"The current Gogs implementation works for public (open source) repositories only. We need a way to upload ssh keys to the repository in order to clone. Ideally we would also have a way to see if the key already exists, and either update or delete and re-upload. We'll need the Gogs team to expose this functionality. For reference, this is the code we use for GitHub: https://github.com/drone/drone/blob/master/plugin/remote/github/helper.go#L233:L255 @compressed thoughts?",source-file | source-file,"Gogs Private Repos The current Gogs implementation works for public (open source) repositories only. We need a way to upload ssh keys to the repository in order to clone. Ideally we would also have a way to see if the key already exists, and either update or delete and re-upload. We'll need the Gogs team to expose this functionality. For reference, this is the code we use for GitHub: https://github.com/drone/drone/blob/master/plugin/remote/github/helper.go#L233:L255 @compressed thoughts? source-file source-file",no-bug,0.8
2776,harness,https://github.com/harness/harness/issues/2776,Gitlab 'merged' webhook is ignored,"Assessing the new `action` added in this issue [issue](https://github.com/drone/drone/issues/2685) condition, it seems like `merged` webhooks (hooks firing from gitlab when the repository is merged ) are ignored in drone. That means: - The repository is properly integrated with drone - Hooks are fired and a 200 response is received from drone. - Drone logs show no recollection of handling the `merged` hook (as opposed to `opened` hooks, which are properly evaluated) - Using debug logging, I get this message:  {""fields.time"":""2019-08-05T14:37:51Z"",""latency"":625401,""level"":""debug"",""method"":""POST"",""msg"":"""",""remote"":""172.18.0.1:37804"",""request"":""/hook"",""request-id"":""1P0fKgKxws4QTAmMxVIWV23bHJY"",""time"":""2019-08-05T14:37:51Z""}  I have specific interest to act on this merged event, rather then use the push event fired on the target branch. Any help will be much advised.",source-file | source-file | source-file | source-file,"Gitlab 'merged' webhook is ignored Assessing the new `action` added in this issue [issue](https://github.com/drone/drone/issues/2685) condition, it seems like `merged` webhooks (hooks firing from gitlab when the repository is merged ) are ignored in drone. That means: - The repository is properly integrated with drone - Hooks are fired and a 200 response is received from drone. - Drone logs show no recollection of handling the `merged` hook (as opposed to `opened` hooks, which are properly evaluated) - Using debug logging, I get this message:  {""fields.time"":""2019-08-05T14:37:51Z"",""latency"":625401,""level"":""debug"",""method"":""POST"",""msg"":"""",""remote"":""172.18.0.1:37804"",""request"":""/hook"",""request-id"":""1P0fKgKxws4QTAmMxVIWV23bHJY"",""time"":""2019-08-05T14:37:51Z""}  I have specific interest to act on this merged event, rather then use the push event fired on the target branch. Any help will be much advised. source-file source-file source-file source-file",bug,0.9
2693,harness,https://github.com/harness/harness/issues/2693,Drone for Kubernetes not deleting local volume when finished,"This issue is discussed here: https://discourse.drone.io/t/drone-leaving-directories-behind-in-kubernetes/4395 To summarize: the code exists for the controller drone-job to remove the `/tmp/drone/<namespace>` directory after a build is finished, but the drone job isn't created with a volume mount for the `/tmp/drone` directory, so it is ineffective. I'm mostly creating this issue to track a branch and link a PR. PR is here: https://github.com/drone/drone/pull/2694",source-file,"Drone for Kubernetes not deleting local volume when finished This issue is discussed here: https://discourse.drone.io/t/drone-leaving-directories-behind-in-kubernetes/4395 To summarize: the code exists for the controller drone-job to remove the `/tmp/drone/<namespace>` directory after a build is finished, but the drone job isn't created with a volume mount for the `/tmp/drone` directory, so it is ineffective. I'm mostly creating this issue to track a branch and link a PR. PR is here: https://github.com/drone/drone/pull/2694 source-file",no-bug,0.9
503,harness,https://github.com/harness/harness/issues/503,Clone branch master on build,I set another branch primary on github repo (github.com/opps/opps). If set run build in branch master in drone.io run command: git clone git://github.com/opps/opps.git /home/ubuntu/src/github.com/opps/opps not force be the master branch!,source-file | source-file | source-file | source-file | source-file | source-file | source-file,Clone branch master on build I set another branch primary on github repo (github.com/opps/opps). If set run build in branch master in drone.io run command: git clone git://github.com/opps/opps.git /home/ubuntu/src/github.com/opps/opps not force be the master branch! source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
345,harness,https://github.com/harness/harness/issues/345,Refactor Publish and Deploy Code,Currently the code which publishes and deploys application to external services relies heavily on the container having certain dependencies like python and a posix compatible shell installed. You can see an example of this failing due to the lack of dependencies in #344. I would like to refactor this part of the codebase. This can be fixed by moving all of the publishing and deployment code to go instead of [writing silent commands to the buildfile](/drone/drone/blob/master/pkg/plugin/publish/swift.go#L57). My idea is to have the code which deploys the application have access to a `docker.Client` instance which it can use to send commands the container and access the file system. Any thoughts or ideas are welcome.,database-file | source-file | documentation-file | other-file,Refactor Publish and Deploy Code Currently the code which publishes and deploys application to external services relies heavily on the container having certain dependencies like python and a posix compatible shell installed. You can see an example of this failing due to the lack of dependencies in #344. I would like to refactor this part of the codebase. This can be fixed by moving all of the publishing and deployment code to go instead of [writing silent commands to the buildfile](/drone/drone/blob/master/pkg/plugin/publish/swift.go#L57). My idea is to have the code which deploys the application have access to a `docker.Client` instance which it can use to send commands the container and access the file system. Any thoughts or ideas are welcome. database-file source-file documentation-file other-file,no-bug,0.9
417,harness,https://github.com/harness/harness/issues/417,ABE Conflict,"When I was trying to set this up, I kept getting errors from ABE: http://noscript.net/abe/ I ended up just turning it off temporarily, but it would be helpful to know what the proper values for this would be. This is clearly an edge case, so I don't expect it to take priority, but it is something you should be aware of currently.",documentation-file | other-file | other-file | other-file | other-file | other-file,"ABE Conflict When I was trying to set this up, I kept getting errors from ABE: http://noscript.net/abe/ I ended up just turning it off temporarily, but it would be helpful to know what the proper values for this would be. This is clearly an edge case, so I don't expect it to take priority, but it is something you should be aware of currently. documentation-file other-file other-file other-file other-file other-file",no-bug,0.9
314,harness,https://github.com/harness/harness/issues/314,No build force option; was: list of commits is not shown after adding the repository,"I did a clean install on Ubuntu as instructed at https://github.com/drone/drone#setup, added my github and bitbucket applications tokens/secrets and linked my accounts. After this I added a public repository from both these providers add is succesful, but the list of commits remains empty. Looking at the page, there seems to be a websocket that is made (upgrades and 200s) but the refresh button still has the 'hide' css class. I also pulled most of the images, such as base, and build engines, to no avail. What could it be missing? No error messages are given. Correction: no build can be triggered from the admin. It seems a forced-update or change to the repo is needed before a build starts.",source-file | source-file | source-file | source-file,"No build force option; was: list of commits is not shown after adding the repository I did a clean install on Ubuntu as instructed at https://github.com/drone/drone#setup, added my github and bitbucket applications tokens/secrets and linked my accounts. After this I added a public repository from both these providers add is succesful, but the list of commits remains empty. Looking at the page, there seems to be a websocket that is made (upgrades and 200s) but the refresh button still has the 'hide' css class. I also pulled most of the images, such as base, and build engines, to no avail. What could it be missing? No error messages are given. Correction: no build can be triggered from the admin. It seems a forced-update or change to the repo is needed before a build starts. source-file source-file source-file source-file",no-bug,0.9
1190,harness,https://github.com/harness/harness/issues/1190,0.3 series stack traces when attempting to add a repository,"The following is output when attempting to Add a repository from a fresh Drone-CI installation (via the .deb package) for the 0.3 series. This happens on any repository, so it doesn't appear to be triggered by existing configuration. 2015/09/05 23:48:06 http: panic serving 192.30.252.34:32556: runtime error: invalid memory address or nil pointer dereference goroutine 171 [running]: net/http.func011() /usr/local/go/src/pkg/net/http/server.go:1100 +0xb7 runtime.panic(0xb42de0, 0x11b98d3) /usr/local/go/src/pkg/runtime/panic.c:248 +0x18d github.com/drone/drone/server/handler.PostHook(0xc20894d9e0, 0xc20894d830, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/handler/hook.go:46 +0xfdb github.com/zenazn/goji/web.handlerFuncWrap.ServeHTTPC(0xd5d430, 0xc20894d9e0, 0xc20894d830, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/handler.go:25 +0x54 github.com/zenazn/goji/web.(_router).route(0xc208026348, 0xc2089bd260, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/router.go:119 +0x143 github.com/zenazn/goji/web.func002(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:88 +0x5f net/http.HandlerFunc.ServeHTTP(0xc2089912c0, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func006(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/middleware/user.go:21 +0x1a6 net/http.HandlerFunc.ServeHTTP(0xc2089912e0, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func001(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/middleware/header.go:28 +0x4e9 net/http.HandlerFunc.ServeHTTP(0xc2081fb6a0, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 main.func002(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/main.go:176 +0x721 net/http.HandlerFunc.ServeHTTP(0xc208991300, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func002(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/middleware/options.go:22 +0x261 net/http.HandlerFunc.ServeHTTP(0xc2081fb6d0, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/zenazn/goji/web.(_cStack).ServeHTTP(0xc2089bd260, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:46 +0x7f github.com/zenazn/goji/web.(_Mux).ServeHTTP(0xc208026310, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/mux.go:45 +0x5f net/http.(_ServeMux).ServeHTTP(0xc208022930, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1511 +0x1a3 net/http.serverHandler.ServeHTTP(0xc208005a40, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1673 +0x19f net/http.(_conn).serve(0xc2089fad00) /usr/local/go/src/pkg/net/http/server.go:1174 +0xa7e created by net/http.(_Server).Serve /usr/local/go/src/pkg/net/http/server.go:1721 +0x313",source-file | source-file | source-file | source-file | source-file,"0.3 series stack traces when attempting to add a repository The following is output when attempting to Add a repository from a fresh Drone-CI installation (via the .deb package) for the 0.3 series. This happens on any repository, so it doesn't appear to be triggered by existing configuration. 2015/09/05 23:48:06 http: panic serving 192.30.252.34:32556: runtime error: invalid memory address or nil pointer dereference goroutine 171 [running]: net/http.func011() /usr/local/go/src/pkg/net/http/server.go:1100 +0xb7 runtime.panic(0xb42de0, 0x11b98d3) /usr/local/go/src/pkg/runtime/panic.c:248 +0x18d github.com/drone/drone/server/handler.PostHook(0xc20894d9e0, 0xc20894d830, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/handler/hook.go:46 +0xfdb github.com/zenazn/goji/web.handlerFuncWrap.ServeHTTPC(0xd5d430, 0xc20894d9e0, 0xc20894d830, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/handler.go:25 +0x54 github.com/zenazn/goji/web.(_router).route(0xc208026348, 0xc2089bd260, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/router.go:119 +0x143 github.com/zenazn/goji/web.func002(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:88 +0x5f net/http.HandlerFunc.ServeHTTP(0xc2089912c0, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func006(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/middleware/user.go:21 +0x1a6 net/http.HandlerFunc.ServeHTTP(0xc2089912e0, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func001(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/middleware/header.go:28 +0x4e9 net/http.HandlerFunc.ServeHTTP(0xc2081fb6a0, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 main.func002(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/main.go:176 +0x721 net/http.HandlerFunc.ServeHTTP(0xc208991300, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func002(0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/drone/drone/server/middleware/options.go:22 +0x261 net/http.HandlerFunc.ServeHTTP(0xc2081fb6d0, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/zenazn/goji/web.(_cStack).ServeHTTP(0xc2089bd260, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:46 +0x7f github.com/zenazn/goji/web.(_Mux).ServeHTTP(0xc208026310, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /var/cache/drone/src/github.com/zenazn/goji/web/mux.go:45 +0x5f net/http.(_ServeMux).ServeHTTP(0xc208022930, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1511 +0x1a3 net/http.serverHandler.ServeHTTP(0xc208005a40, 0x7f65f2564928, 0xc20863d4a0, 0xc2083d68f0) /usr/local/go/src/pkg/net/http/server.go:1673 +0x19f net/http.(_conn).serve(0xc2089fad00) /usr/local/go/src/pkg/net/http/server.go:1174 +0xa7e created by net/http.(_Server).Serve /usr/local/go/src/pkg/net/http/server.go:1721 +0x313 source-file source-file source-file source-file source-file",bug,0.9
3299,harness,https://github.com/harness/harness/issues/3299,Share data between workflows without privileged mode,"We start from this example workflow composed of two pipelines, the second one depending on the first one. yaml  kind: pipeline name: simulate build steps: - name: build image: alpine commands: - echo ""Line 1"" > file.txt - cat file.txt  kind: pipeline name: simulate package steps: - name: deploy image: alpine commands: - echo ""Line 2"" >> file.txt - cat file.txt depends_on: - simulate build  If we run it as is in the first `cat file.txt` it will show `Line 1` and in the second `cat file.txt` it will show `Line 2`. That is, the pipelines are independent and data is not shared between them. Right now if I wanted to share data between both pipelines I would have to do something like the following. yaml  kind: pipeline name: simulate build steps: - name: build image: alpine volumes: - name: data path: /data commands: - echo ""Line 1"" > /data/file.txt - cat /data/file.txt volumes: - name: data host: path: /tmp  kind: pipeline name: simulate package steps: - name: deploy image: alpine volumes: - name: data path: /data commands: - echo ""Line 2"" >> /data/file.txt - cat /data/file.txt volumes: - name: data host: path: /tmp depends_on: - simulate build  While this works correctly it has the problem that it requires the repository to be trusted in Drone in order to mount a host volume for use as temporary volume. Also, since it is a standard host mount and not a temporary mount, the volume is not deleted when the workflow is finished running. It would be very interesting to have some way to share files between different pipelines without the need for the repository to be marked as trusted, without the need to use a volume on the host and using only temporary volumes.",source-file,"Share data between workflows without privileged mode We start from this example workflow composed of two pipelines, the second one depending on the first one. yaml  kind: pipeline name: simulate build steps: - name: build image: alpine commands: - echo ""Line 1"" > file.txt - cat file.txt  kind: pipeline name: simulate package steps: - name: deploy image: alpine commands: - echo ""Line 2"" >> file.txt - cat file.txt depends_on: - simulate build  If we run it as is in the first `cat file.txt` it will show `Line 1` and in the second `cat file.txt` it will show `Line 2`. That is, the pipelines are independent and data is not shared between them. Right now if I wanted to share data between both pipelines I would have to do something like the following. yaml  kind: pipeline name: simulate build steps: - name: build image: alpine volumes: - name: data path: /data commands: - echo ""Line 1"" > /data/file.txt - cat /data/file.txt volumes: - name: data host: path: /tmp  kind: pipeline name: simulate package steps: - name: deploy image: alpine volumes: - name: data path: /data commands: - echo ""Line 2"" >> /data/file.txt - cat /data/file.txt volumes: - name: data host: path: /tmp depends_on: - simulate build  While this works correctly it has the problem that it requires the repository to be trusted in Drone in order to mount a host volume for use as temporary volume. Also, since it is a standard host mount and not a temporary mount, the volume is not deleted when the workflow is finished running. It would be very interesting to have some way to share files between different pipelines without the need for the repository to be marked as trusted, without the need to use a volume on the host and using only temporary volumes. source-file",no-bug,0.9
44,harness,https://github.com/harness/harness/issues/44,Build CLI Idea,"One thing that bothers me with lots of cloud based build systems is that you cannot easily (to my knowledge) test the yml file before you commit. With Drone being based on docker, I don't see why you couldn't be able to do:  bash $ drone build  And locally run all of the scripts to make sure your configuration is what you want before you push your commits. Would this be possible? Any thoughts? Does this exist with other platforms?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Build CLI Idea One thing that bothers me with lots of cloud based build systems is that you cannot easily (to my knowledge) test the yml file before you commit. With Drone being based on docker, I don't see why you couldn't be able to do:  bash $ drone build  And locally run all of the scripts to make sure your configuration is what you want before you push your commits. Would this be possible? Any thoughts? Does this exist with other platforms? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
2076,harness,https://github.com/harness/harness/issues/2076,RFC replace websockets to support http2 and quic,"http2 does not provide support to negotiate connection upgrades and therefore does not support websockets [1]. Furthermore reverse proxies suck and are a common cause for false positive ""drone is broken"" issues due to improper websocket configuration, and in some case (Amazon ELB) don't work at all. I plan to kill two birds with one stone here. The recommended solution is to use server sent events (SSE) [2]. Early versions of drone used SSE which I personally preferred to websockets. There were however some issues at the time that made SSE unreliable which is why I replaced the implementation with websockets. __What has changed with SSE?__ The issue with SSE is that connections frequently timeout after a minute or so due to reverse proxy and load balancer configurations. This required custom configurations (similar to websockets) but in practice had poor support from nginx, caddy and others. The fact that nginx killed a SSE connection normally would not be an issue because SSE will automatically reconnect AND provide the last message ID received so the server can resume. The problem was, at the time, Drone was unable to seek to a specific location in the stream and resume. This limitation has been removed. This means nginx (et al) can kill connections and the browser will auto-reconnect, and drone can resume with no extra overhead or complexity. __What about http2 push?__ This would force everyone to use http2 which is not feasible at this time. It would also require generating keys and configuring tls for local development. Bottom line, this would increase the barrier to entry for installing and developing Drone, and would negatively impact my personal development workflow. Server push is also quite new (just landed in Go 1.8). We can therefore re-evaluate http2 server push at a later time. __What is the end user impact here?__ Absolutely none. This change will take place in the website and server and should not impact usage at all. If you are running Drone on AWS with ELB we probably just made your life way easier. If you are running Drone behind nginx or something else, no changes should be required. Nginx (et al) will certainly timeout connections, but the browser and server will coordinate re-connects and resume streams. If anything you can expect a performance improvement since we will be able to enable http2 protocol by default if supported by your environment. [1] https://daniel.haxx.se/blog/2016/06/15/no-websockets-over-http2/ [2] https://www.infoq.com/articles/websocket-and-http2-coexist",source-file,"RFC replace websockets to support http2 and quic http2 does not provide support to negotiate connection upgrades and therefore does not support websockets [1]. Furthermore reverse proxies suck and are a common cause for false positive ""drone is broken"" issues due to improper websocket configuration, and in some case (Amazon ELB) don't work at all. I plan to kill two birds with one stone here. The recommended solution is to use server sent events (SSE) [2]. Early versions of drone used SSE which I personally preferred to websockets. There were however some issues at the time that made SSE unreliable which is why I replaced the implementation with websockets. __What has changed with SSE?__ The issue with SSE is that connections frequently timeout after a minute or so due to reverse proxy and load balancer configurations. This required custom configurations (similar to websockets) but in practice had poor support from nginx, caddy and others. The fact that nginx killed a SSE connection normally would not be an issue because SSE will automatically reconnect AND provide the last message ID received so the server can resume. The problem was, at the time, Drone was unable to seek to a specific location in the stream and resume. This limitation has been removed. This means nginx (et al) can kill connections and the browser will auto-reconnect, and drone can resume with no extra overhead or complexity. __What about http2 push?__ This would force everyone to use http2 which is not feasible at this time. It would also require generating keys and configuring tls for local development. Bottom line, this would increase the barrier to entry for installing and developing Drone, and would negatively impact my personal development workflow. Server push is also quite new (just landed in Go 1.8). We can therefore re-evaluate http2 server push at a later time. __What is the end user impact here?__ Absolutely none. This change will take place in the website and server and should not impact usage at all. If you are running Drone on AWS with ELB we probably just made your life way easier. If you are running Drone behind nginx or something else, no changes should be required. Nginx (et al) will certainly timeout connections, but the browser and server will coordinate re-connects and resume streams. If anything you can expect a performance improvement since we will be able to enable http2 protocol by default if supported by your environment. [1] https://daniel.haxx.se/blog/2016/06/15/no-websockets-over-http2/ [2] https://www.infoq.com/articles/websocket-and-http2-coexist source-file",no-bug,0.9
467,harness,https://github.com/harness/harness/issues/467,Scheduled builds,I think for many continius delivery tasks like ( build docker images) needed scheduled build. Im try to find ready solution: - https://godoc.org/github.com/robfig/cron - https://github.com/gorhill/cronexpr,other-file,Scheduled builds I think for many continius delivery tasks like ( build docker images) needed scheduled build. Im try to find ready solution: - https://godoc.org/github.com/robfig/cron - https://github.com/gorhill/cronexpr other-file,no-bug,0.95
3530,harness,https://github.com/harness/harness/issues/3530,"Bug: browse the files within the ""search"" directory.","![image](https://github.com/harness/gitness/assets/8605565/0ed6af76-f6ac-4d47-80a9-1fcda94ce2cf) ![image](https://github.com/harness/gitness/assets/8605565/39401a7d-f3c0-4ac9-9a7f-e27987c10ac2) When there is a ""search"" directory in the repository, it is not possible to browse the files within the ""search"" directory.",source-file,"Bug: browse the files within the ""search"" directory. ![image](https://github.com/harness/gitness/assets/8605565/0ed6af76-f6ac-4d47-80a9-1fcda94ce2cf) ![image](https://github.com/harness/gitness/assets/8605565/39401a7d-f3c0-4ac9-9a7f-e27987c10ac2) When there is a ""search"" directory in the repository, it is not possible to browse the files within the ""search"" directory. source-file",no-bug,0.8
3382,harness,https://github.com/harness/harness/issues/3382,harness/gitness,,config-file | other-file,harness/gitness  config-file other-file,no-bug,0.9
3493,harness,https://github.com/harness/harness/issues/3493,Increase character limit for storing secrets,"Currently, the character limit for storing secrets in Gitness repositories is 1024 characters. This limit is proving to be quite restrictive for projects that require secure storage of sensitive information such as API keys, passwords, and tokens. Currently, I am splitting one long secret into multiple secrets and then merging them into one inside the pipeline, this is not the optimal solution and there should be a straightforward way of using long secrets. So can we increase this limit using some configs? Or is there an existing way to add a long string? If not I would like to submit a PR for this change.",other-file | source-file | other-file | other-file | source-file,"Increase character limit for storing secrets Currently, the character limit for storing secrets in Gitness repositories is 1024 characters. This limit is proving to be quite restrictive for projects that require secure storage of sensitive information such as API keys, passwords, and tokens. Currently, I am splitting one long secret into multiple secrets and then merging them into one inside the pipeline, this is not the optimal solution and there should be a straightforward way of using long secrets. So can we increase this limit using some configs? Or is there an existing way to add a long string? If not I would like to submit a PR for this change. other-file source-file other-file other-file source-file",no-bug,0.8
2858,harness,https://github.com/harness/harness/issues/2858,What's going on with the discourse?,"Hello. Today I've found out that my account was blocked for spam for a year. However, there was no spam at all (show me and others then, if you think there was spam). I was helping others, asking others for the help as well. Could you please explain what has happened and fix this mistake? You've also deleted some of my comments and posts, I don't understand what was the point behind all of this. Don't you just feel like answering people's questions, helping them? Thank you. Also, from [this comment](https://discourse.drone.io/t/drone-agent-port/5914/4): > the runner ports referenced in the documentation are for the new runners, which are developed and maintained in separate repositories. Does that mean that the documentation has already been partially updated for new runners and so we shouldn't pay much attention to it right now? Because there are installation instructions for ""drone/agent"" docker image but the documentation has already been partially written for new ""drone runnners"", is this correct? Thank you.",source-file,"What's going on with the discourse? Hello. Today I've found out that my account was blocked for spam for a year. However, there was no spam at all (show me and others then, if you think there was spam). I was helping others, asking others for the help as well. Could you please explain what has happened and fix this mistake? You've also deleted some of my comments and posts, I don't understand what was the point behind all of this. Don't you just feel like answering people's questions, helping them? Thank you. Also, from [this comment](https://discourse.drone.io/t/drone-agent-port/5914/4): > the runner ports referenced in the documentation are for the new runners, which are developed and maintained in separate repositories. Does that mean that the documentation has already been partially updated for new runners and so we shouldn't pay much attention to it right now? Because there are installation instructions for ""drone/agent"" docker image but the documentation has already been partially written for new ""drone runnners"", is this correct? Thank you. source-file",no-bug,0.95
712,harness,https://github.com/harness/harness/issues/712,Provide a way to delete a repo from drone,Currently there is no way to disconnect a repository from drone. It would be great to have a way for drone to cleanup its hooks and remove it from the database.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Provide a way to delete a repo from drone Currently there is no way to disconnect a repository from drone. It would be great to have a way for drone to cleanup its hooks and remove it from the database. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.8
1219,harness,https://github.com/harness/harness/issues/1219,css problems,"Hi, I just installed drone through the .deb-Package. Everything seems to work except for the interface UI. ![screenshot 2015-10-01 12 30 29](https://cloud.githubusercontent.com/assets/5519491/10218871/98d9be40-683a-11e5-8e48-425fdbdfdded.png) I looked in the chrome developer tools and any resources seems to be loaded correctly. Any ideas on how to fix it?",source-file | source-file | source-file | source-file | source-file | test-file | source-file,"css problems Hi, I just installed drone through the .deb-Package. Everything seems to work except for the interface UI. ![screenshot 2015-10-01 12 30 29](https://cloud.githubusercontent.com/assets/5519491/10218871/98d9be40-683a-11e5-8e48-425fdbdfdded.png) I looked in the chrome developer tools and any resources seems to be loaded correctly. Any ideas on how to fix it? source-file source-file source-file source-file source-file test-file source-file",no-bug,0.9
2969,harness,https://github.com/harness/harness/issues/2969,oauth: cannot exchange code,<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> drone: Gitea ERRO[0087] oauth: cannot exchange code: xH8HnmCk5D__3dEmVT70bxXBqlqdrDB-DQJhxMm0W0Q=: unauthorized_client: client is not authorized DEBU[0087] cannot authenticate user: unauthorized_client: client is not authorized,source-file | source-file,oauth: cannot exchange code <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> drone: Gitea ERRO[0087] oauth: cannot exchange code: xH8HnmCk5D__3dEmVT70bxXBqlqdrDB-DQJhxMm0W0Q=: unauthorized_client: client is not authorized DEBU[0087] cannot authenticate user: unauthorized_client: client is not authorized source-file source-file,no-bug,0.8
3,harness,https://github.com/harness/harness/issues/3,Error in image bradrydzewski/php:5.*,"In /etc/drone.d/phpenv.sh you add home variable '/home/ubuntu/phpenv/bin'. I think that should be '/home/ubuntu/.phpenv/bin' (note the . in phpenv), as I'm always getting the following error: /etc/drone.d/phpenv.sh: line 21: phpenv: command not found",other-file | source-file | source-file | test-file,"Error in image bradrydzewski/php:5.* In /etc/drone.d/phpenv.sh you add home variable '/home/ubuntu/phpenv/bin'. I think that should be '/home/ubuntu/.phpenv/bin' (note the . in phpenv), as I'm always getting the following error: /etc/drone.d/phpenv.sh: line 21: phpenv: command not found other-file source-file source-file test-file",no-bug,0.95
2335,harness,https://github.com/harness/harness/issues/2335,"Flag for global vs local secret, registry","Add some sort of metadata to the registry and secret so that we know its source (e.g. local, global, vault, etc)",source-file | source-file | source-file | source-file | source-file,"Flag for global vs local secret, registry Add some sort of metadata to the registry and secret so that we know its source (e.g. local, global, vault, etc) source-file source-file source-file source-file source-file",no-bug,0.9
414,harness,https://github.com/harness/harness/issues/414,"0.3, Repo List link, GitHub Enterprise",the repo list display `enterprise.github.com/:ower/:name` instead of using `:hostname/:owner/:name`. Need to fix,other-file | other-file,"0.3, Repo List link, GitHub Enterprise the repo list display `enterprise.github.com/:ower/:name` instead of using `:hostname/:owner/:name`. Need to fix other-file other-file",no-bug,0.7
3555,harness,https://github.com/harness/harness/issues/3555,Drone Helm chart left abandoned.,"there has been a few issues with drone for the past year when deploying with a helm chart. if you have an existing helm deployment and want to update it/redeploy it for some reason, either a configuration change or some other reason, the helm chart will never redeploy successfully. the pod will hang forever as it dosent know how to handle the service existing before the pod. this causes errors and the pod will forever loop, never deploying. this has been an issue for over a year, and due to the supposed razor focus on developing gitness, the drone chart has been left to rot.",other-file | test-file | other-file | test-file,"Drone Helm chart left abandoned. there has been a few issues with drone for the past year when deploying with a helm chart. if you have an existing helm deployment and want to update it/redeploy it for some reason, either a configuration change or some other reason, the helm chart will never redeploy successfully. the pod will hang forever as it dosent know how to handle the service existing before the pod. this causes errors and the pod will forever loop, never deploying. this has been an issue for over a year, and due to the supposed razor focus on developing gitness, the drone chart has been left to rot. other-file test-file other-file test-file",no-bug,0.9
2943,harness,https://github.com/harness/harness/issues/2943,drone orgsecret rm 404,"I use `drone orgsecret add daocloud.io docker_password my_password` successfully. But when rm orgsecret, it said 404. ![image](https://user-images.githubusercontent.com/1883728/77022090-a1a97d00-69c3-11ea-9298-a22a07e3a29b.png)",source-file | source-file | source-file | source-file | source-file | source-file,"drone orgsecret rm 404 I use `drone orgsecret add daocloud.io docker_password my_password` successfully. But when rm orgsecret, it said 404. ![image](https://user-images.githubusercontent.com/1883728/77022090-a1a97d00-69c3-11ea-9298-a22a07e3a29b.png) source-file source-file source-file source-file source-file source-file",bug,0.9
446,harness,https://github.com/harness/harness/issues/446,GitHub Service Hook,"Travis CI has a custom GitHub Service hook, which allows it to do this: ![](http://i.imgur.com/qvkAdmg.png) Is this feature coming to Drone.io? (or is it there and I can't find it?)",other-file,"GitHub Service Hook Travis CI has a custom GitHub Service hook, which allows it to do this: ![](http://i.imgur.com/qvkAdmg.png) Is this feature coming to Drone.io? (or is it there and I can't find it?) other-file",no-bug,0.9
2107,harness,https://github.com/harness/harness/issues/2107,`printenv` prints the secrets in plaintext,Drone version : `0.7.3` **Reproduce**: Run `printenv` in a drone step **Actual**: global secrets are printed with their values in plaintext **Expected**: global secrets are printed with the values concealed (*),source-file | source-file | source-file,`printenv` prints the secrets in plaintext Drone version : `0.7.3` **Reproduce**: Run `printenv` in a drone step **Actual**: global secrets are printed with their values in plaintext **Expected**: global secrets are printed with the values concealed (*) source-file source-file source-file,no-bug,0.9
2771,harness,https://github.com/harness/harness/issues/2771,Failed to create migrations tables in MySQL Group Replication,Add PK in `migrations` for GR.,documentation-file | other-file | other-file | other-file | source-file | other-file | source-file | documentation-file | source-file | source-file | other-file,Failed to create migrations tables in MySQL Group Replication Add PK in `migrations` for GR. documentation-file other-file other-file other-file source-file other-file source-file documentation-file source-file source-file other-file,no-bug,0.9
2665,harness,https://github.com/harness/harness/issues/2665,"documentation example leads to ""duplicate step names""",I'm following .drone.yml example from here (trying to make my own clone step) https://docs.drone.io/user-guide/pipeline/cloning/  kind: pipeline name: default clone: disable: true steps: - name: clone image: docker:git commands: - git clone https://github.com/octocat/hello-world.git - git checkout $DRONE_COMMIT - name: build image: golang commands: - go build - go test  but it gives an error : > linter: duplicate step names,source-file | source-file | source-file | test-file | source-file | source-file,"documentation example leads to ""duplicate step names"" I'm following .drone.yml example from here (trying to make my own clone step) https://docs.drone.io/user-guide/pipeline/cloning/  kind: pipeline name: default clone: disable: true steps: - name: clone image: docker:git commands: - git clone https://github.com/octocat/hello-world.git - git checkout $DRONE_COMMIT - name: build image: golang commands: - go build - go test  but it gives an error : > linter: duplicate step names source-file source-file source-file test-file source-file source-file",no-bug,0.9
739,harness,https://github.com/harness/harness/issues/739,Heroku plugin to use token instead of ssh key,"Documenting a request to switch to token-based authorization for Heroku: > Heroku now has both a Build API and support for HTTP GIt. Both of these authenticate with simple API keys and OAuth tokens. So you could have users do a one-time OAuth flow and then use that to HTTP-git-push or operate the Build API to build and deploy to Heroku. Or (less great) ask users for their Heroku API token. We'll need to go with the second approach (users provide their API token), which includes the following changes to the Heroku plugin code: - the `.drone.yml` should accept a Heroku token - the Heroku plugin should write the token to a `.netrc` file - the Heroku plugin should push to the http url Details for setting up http git: https://devcenter.heroku.com/articles/http-git Heroku plugin code can be found here: https://github.com/drone/drone/tree/master/plugin/deploy/heroku",source-file | source-file | source-file,"Heroku plugin to use token instead of ssh key Documenting a request to switch to token-based authorization for Heroku: > Heroku now has both a Build API and support for HTTP GIt. Both of these authenticate with simple API keys and OAuth tokens. So you could have users do a one-time OAuth flow and then use that to HTTP-git-push or operate the Build API to build and deploy to Heroku. Or (less great) ask users for their Heroku API token. We'll need to go with the second approach (users provide their API token), which includes the following changes to the Heroku plugin code: - the `.drone.yml` should accept a Heroku token - the Heroku plugin should write the token to a `.netrc` file - the Heroku plugin should push to the http url Details for setting up http git: https://devcenter.heroku.com/articles/http-git Heroku plugin code can be found here: https://github.com/drone/drone/tree/master/plugin/deploy/heroku source-file source-file source-file",no-bug,0.9
2835,harness,https://github.com/harness/harness/issues/2835,Pipeline Cron schedule skipped if HEAD commit contains [ci skip],"**Summary** A pipeline Cron schedule for a branch is not executed if the HEAD commit of that branch contains [ci skip] in its commit message. **Steps to reproduce** Create a nightly pipeline schedule for the master branch Make a commit on master with [ci skip] in the commit message, and push that commit to GitLab **Current behavior?** The nightly schedule will not be executed. **Expected behavior?** The nightly schedule should be executed. The commit message instructs GitLab to not create a pipeline for the push, but the nightly schedule should still be executed. Similarly, Drone ignore CI SKIP for tag events. **Consider the following situation:** - Have a nightly pipeline schedule for the master branch. As part of your CI process, you check used dependencies for security issues (e.g. using nsp). The idea is that you will get a ""failed pipeline"" email when a security issue is found in one of your javascript libraries. - Make a small fix to a readme file and add [ci skip] to the commit message - Don't do any commits for a few days - No pipeline schedules for the master branch will be running, and hence you won't be notified on security issues anymore One could argue that we do not want to run scheduled pipelines for [ci skip] commits, but then we have to run a scheduled pipeline for the last commit of that branch that is not [ci skip].  _[Example taken from S. Schweizer as it clearly explains the issue applicable to Drone CI](https://gitlab.com/gitlab-org/gitlab-foss/issues/34618)_",documentation-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file,"Pipeline Cron schedule skipped if HEAD commit contains [ci skip] **Summary** A pipeline Cron schedule for a branch is not executed if the HEAD commit of that branch contains [ci skip] in its commit message. **Steps to reproduce** Create a nightly pipeline schedule for the master branch Make a commit on master with [ci skip] in the commit message, and push that commit to GitLab **Current behavior?** The nightly schedule will not be executed. **Expected behavior?** The nightly schedule should be executed. The commit message instructs GitLab to not create a pipeline for the push, but the nightly schedule should still be executed. Similarly, Drone ignore CI SKIP for tag events. **Consider the following situation:** - Have a nightly pipeline schedule for the master branch. As part of your CI process, you check used dependencies for security issues (e.g. using nsp). The idea is that you will get a ""failed pipeline"" email when a security issue is found in one of your javascript libraries. - Make a small fix to a readme file and add [ci skip] to the commit message - Don't do any commits for a few days - No pipeline schedules for the master branch will be running, and hence you won't be notified on security issues anymore One could argue that we do not want to run scheduled pipelines for [ci skip] commits, but then we have to run a scheduled pipeline for the last commit of that branch that is not [ci skip].  _[Example taken from S. Schweizer as it clearly explains the issue applicable to Drone CI](https://gitlab.com/gitlab-org/gitlab-foss/issues/34618)_ documentation-file source-file source-file test-file source-file source-file test-file source-file source-file",no-bug,0.9
367,harness,https://github.com/harness/harness/issues/367,Everything in the UI should be a link,"Navigating the web UI is currently a little unwieldy. It would be very helpful if the various headers on each page, for example the name of the team when you view a team's repository, were clickable links. These should both be clickable: ![image](https://cloud.githubusercontent.com/assets/1414305/3437132/e24351e8-00aa-11e4-8369-dfe3612cfb24.png) And the branch name here should be clickable and take me to the branch's tests page: ![image](https://cloud.githubusercontent.com/assets/1414305/3437139/fcf26a9c-00aa-11e4-8dbc-f5473c5d322b.png)",other-file,"Everything in the UI should be a link Navigating the web UI is currently a little unwieldy. It would be very helpful if the various headers on each page, for example the name of the team when you view a team's repository, were clickable links. These should both be clickable: ![image](https://cloud.githubusercontent.com/assets/1414305/3437132/e24351e8-00aa-11e4-8369-dfe3612cfb24.png) And the branch name here should be clickable and take me to the branch's tests page: ![image](https://cloud.githubusercontent.com/assets/1414305/3437139/fcf26a9c-00aa-11e4-8dbc-f5473c5d322b.png) other-file",no-bug,0.95
3478,harness,https://github.com/harness/harness/issues/3478,Libsql Support for HA SQLite Database,https://github.com/tursodatabase/libsql,source-file,Libsql Support for HA SQLite Database https://github.com/tursodatabase/libsql source-file,no-bug,0.8
950,harness,https://github.com/harness/harness/issues/950,Feature request - Private hipchat support,It would be nice to be able to specify a hipchat server in the configuration for those of us with private self-hosted hipchat enterprise servers.,source-file,Feature request - Private hipchat support It would be nice to be able to specify a hipchat server in the configuration for those of us with private self-hosted hipchat enterprise servers. source-file,no-bug,0.95
2796,harness,https://github.com/harness/harness/issues/2796,How can specified the k8s jobs namespace and serviceaccount with drone ?,"When a pipeline run ,the drone server will create a job in k8s.But the job always create in the default namespace ,and the job will create namespace to execute pipeline steps by the user system:serviceaccount:default:default. ![image](https://user-images.githubusercontent.com/41962159/63311823-fa337180-c331-11e9-8f37-913f3a667d5d.png) So,I have to give the permission about create namespace to system:serviceaccount:default:default. For isolation I want create a namespace ,such as ""devops"" ,then put the drone server and all of the drone job in this namespace.If the drone can do this? I would be very grateful if you have good opinions.",source-file,"How can specified the k8s jobs namespace and serviceaccount with drone ? When a pipeline run ,the drone server will create a job in k8s.But the job always create in the default namespace ,and the job will create namespace to execute pipeline steps by the user system:serviceaccount:default:default. ![image](https://user-images.githubusercontent.com/41962159/63311823-fa337180-c331-11e9-8f37-913f3a667d5d.png) So,I have to give the permission about create namespace to system:serviceaccount:default:default. For isolation I want create a namespace ,such as ""devops"" ,then put the drone server and all of the drone job in this namespace.If the drone can do this? I would be very grateful if you have good opinions. source-file",no-bug,0.9
3286,harness,https://github.com/harness/harness/issues/3286,Multiple CVE and End of life technology,"There are multiple vulnerabilities within drone images (drone, drone-runniner-kube, drone-vault-extension) as mentioned below. Is there any plan to address this in future release? <html xmlns:v=""urn:schemas-microsoft-com:vml"" xmlns:o=""urn:schemas-microsoft-com:office:office"" xmlns:x=""urn:schemas-microsoft-com:office:excel"" xmlns=""http://www.w3.org/TR/REC-html40""> <head> <meta name=ProgId content=Excel.Sheet> <meta name=Generator content=""Microsoft Excel 15""> <link id=Main-File rel=Main-File href=""file:C:/Users/saj00003/AppData/Local/Temp/msohtmlclip1/01/clip.htm""> <link rel=File-List href=""file:C:/Users/saj00003/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml""> <style> <!--table {mso-displayed-decimal-separator:""\.""; mso-displayed-thousand-separator:""\,"";} @page {margin:.75in .7in .75in .7in; mso-header-margin:.3in; mso-footer-margin:.3in;} tr {mso-height-source:auto;} col {mso-width-source:auto;} br {mso-data-placement:same-cell;} td {padding-top:1px; padding-right:1px; padding-left:1px; mso-ignore:padding; color:black; font-size:11.0pt; font-weight:400; font-style:normal; text-decoration:none; font-family:Calibri, sans-serif; mso-font-charset:0; mso-number-format:General; text-align:general; vertical-align:bottom; border:none; mso-background-source:auto; mso-pattern:auto; mso-protection:locked visible; white-space:nowrap; mso-rotate:0;} .xl65 {border:.5pt solid windowtext;} .xl66 {font-weight:700; border:.5pt solid windowtext;} --> </style> </head> <body link=""#0563C1"" vlink=""#954F72""> CVE Name | Asset Name | Vulnerability Description | Remediation | Current Version | Recommended Version | DetailedName -- | -- | -- | -- | -- | -- | -- CVE-2022-28391 | docker.io/drone/drone-runner-kube | The package `busybox` version `1.32.1-r7` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-28391`, which exists in versions `< 1.32.1-r8`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-28391) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-28391) severity: `High`). The vulnerability can be remediated by updating the package to version `1.32.1-r8` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade busybox`. | apk upgrade busybox | 1.32.1-r7 | 1.32.1-r8 | busybox CVE-2022-0778 | docker.io/drone/drone-runner-kube | The package `libcrypto1.1` version `1.1.1l-r0` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-0778`, which exists in versions `< 1.1.1n-r0`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-0778) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-0778) severity: `High`). This vulnerability has a known exploit available. Source: [Packetstorm](https://packetstormsecurity.com/files/167344/OpenSSL-1.0.2-1.1.1-3.0-BN_mod_sqrt-Infinite-Loop.html). The vulnerability can be remediated by updating the package to version `1.1.1n-r0` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade libcrypto1.1`. | apk upgrade libcrypto1.1 | 1.1.1l-r0 | 1.1.1n-r0 | libcrypto1.1 End-of-Life Version of Technology | docker.io/drone/drone-runner-kube | The OS `Linux Alpine` version `3.13.7` has been End-of-Life since `2022-11-01` as indicated in [Alpine Releases](https://alpinelinux.org/releases/). End-of-Life versions of operating systems have no further official support by the vendor and thus no security patches. Furthermore, newly discovered vulnerabilities are not reported. Thus, such technologies pose a threat that is both unknown and will not be fixed. | | 3.13.7 | 3.14.8 | Linux Alpine End-of-Life Version of Technology | docker.io/drone/drone | The OS `Linux Alpine` version `3.11.13` has been End-of-Life since `2021-11-01` as indicated in [Alpine Releases](https://alpinelinux.org/releases/). End-of-Life versions of operating systems have no further official support by the vendor and thus no security patches. Furthermore, newly discovered vulnerabilities are not reported. Thus, such technologies pose a threat that is both unknown and will not be fixed. | | 3.11.13 | 3.14.8 | Linux Alpine CVE-2022-30065 | docker.io/drone/drone-runner-kube | The package `busybox` version `1.32.1-r7` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-30065`, which exists in versions `< 1.32.1-r9`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-30065) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-30065) severity: `High`). The vulnerability can be remediated by updating the package to version `1.32.1-r9` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade busybox`. | apk upgrade busybox | 1.32.1-r7 | 1.32.1-r9 | busybox CVE-2022-37434 | docker.io/drone/drone-runner-kube | The package `zlib` version `1.2.11-r3` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-37434`, which exists in versions `< 1.2.12-r2`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-37434) with vendor severity: `Critical` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-37434) severity: `Critical`). This vulnerability has a known exploit available. Source: Github [[1](https://github.com/ivd38/zlib_overflow), [2](https://github.com/madler/zlib/blob/21767c654d31d2dccdde4330529775c6c5fd5389/zlib.h#L1062-L1063), [3](https://github.com/nodejs/node/blob/75b68c6e4db515f76df73af476eccf382bbcb00a/deps/zlib/inflate.c#L762-L764)]. The vulnerability can be remediated by updating the package to version `1.2.12-r2` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade zlib`. | apk upgrade zlib | 1.2.11-r3 | 1.2.12-r2 | zlib CVE-2022-37434 | docker.io/drone/drone | The package `zlib` version `1.2.11-r3` was detected in `APK package manager` on a container image running `Alpine 3.11.13` is vulnerable to `CVE-2022-37434`, which exists in versions `< 1.2.11-r4`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-37434) with vendor severity: `Critical` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-37434) severity: `Critical`). This vulnerability has a known exploit available. Source: Github [[1](https://github.com/ivd38/zlib_overflow), [2](https://github.com/madler/zlib/blob/21767c654d31d2dccdde4330529775c6c5fd5389/zlib.h#L1062-L1063), [3](https://github.com/nodejs/node/blob/75b68c6e4db515f76df73af476eccf382bbcb00a/deps/zlib/inflate.c#L762-L764)]. The vulnerability can be remediated by updating the package to version `1.2.11-r4` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade zlib`. | apk upgrade zlib | 1.2.11-r3 | 1.2.11-r4 | zlib CVE-2018-25032 | docker.io/drone/drone-runner-kube | The package `zlib` version `1.2.11-r3` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2018-25032`, which exists in versions `< 1.2.12-r0`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2018-25032) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2018-25032) severity: `High`). The vulnerability can be remediated by updating the package to version `1.2.12-r0` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade zlib`. | apk upgrade zlib | 1.2.11-r3 | 1.2.12-r0 | zlib CVE-2022-28391 | docker.io/drone/drone-runner-kube | The package `ssl_client` version `1.32.1-r7` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-28391`, which exists in versions `< 1.32.1-r8`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-28391) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-28391) severity: `High`). The vulnerability can be remediated by updating the package to version `1.32.1-r8` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade ssl_client`. | apk upgrade ssl_client | 1.32.1-r7 | 1.32.1-r8 | ssl_client End-of-Life Version of Technology | docker.io/drone/vault | The OS `Linux Alpine` version `3.6.5` has been End-of-Life since `2019-05-01` as indicated in [Alpine Releases](https://alpinelinux.org/releases/). End-of-Life versions of operating systems have no further official support by the vendor and thus no security patches. Furthermore, newly discovered vulnerabilities are not reported. Thus, such technologies pose a threat that is both unknown and will not be fixed. | | 3.6.5 | 3.14.8 | Linux Alpine CVE-2022-0778 | docker.io/drone/drone-runner-kube | The package `libssl1.1` version `1.1.1l-r0` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-0778`, which exists in versions `< 1.1.1n-r0`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-0778) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-0778) severity: `High`). This vulnerability has a known exploit available. Source: [Packetstorm](https://packetstormsecurity.com/files/167344/OpenSSL-1.0.2-1.1.1-3.0-BN_mod_sqrt-Infinite-Loop.html). The vulnerability can be remediated by updating the package to version `1.1.1n-r0` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade libssl1.1`. | apk upgrade libssl1.1 | 1.1.1l-r0 | 1.1.1n-r0 | libssl1.1 CVE-2022-30065 | docker.io/drone/drone-runner-kube | The package `ssl_client` version `1.32.1-r7` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-30065`, which exists in versions `< 1.32.1-r9`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-30065) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-30065) severity: `High`). The vulnerability can be remediated by updating the package to version `1.32.1-r9` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade ssl_client`. | apk upgrade ssl_client | 1.32.1-r7 | 1.32.1-r9 | ssl_client </body> </html>",source-file,"Multiple CVE and End of life technology There are multiple vulnerabilities within drone images (drone, drone-runniner-kube, drone-vault-extension) as mentioned below. Is there any plan to address this in future release? <html xmlns:v=""urn:schemas-microsoft-com:vml"" xmlns:o=""urn:schemas-microsoft-com:office:office"" xmlns:x=""urn:schemas-microsoft-com:office:excel"" xmlns=""http://www.w3.org/TR/REC-html40""> <head> <meta name=ProgId content=Excel.Sheet> <meta name=Generator content=""Microsoft Excel 15""> <link id=Main-File rel=Main-File href=""file:C:/Users/saj00003/AppData/Local/Temp/msohtmlclip1/01/clip.htm""> <link rel=File-List href=""file:C:/Users/saj00003/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml""> <style> <!--table {mso-displayed-decimal-separator:""\.""; mso-displayed-thousand-separator:""\,"";} @page {margin:.75in .7in .75in .7in; mso-header-margin:.3in; mso-footer-margin:.3in;} tr {mso-height-source:auto;} col {mso-width-source:auto;} br {mso-data-placement:same-cell;} td {padding-top:1px; padding-right:1px; padding-left:1px; mso-ignore:padding; color:black; font-size:11.0pt; font-weight:400; font-style:normal; text-decoration:none; font-family:Calibri, sans-serif; mso-font-charset:0; mso-number-format:General; text-align:general; vertical-align:bottom; border:none; mso-background-source:auto; mso-pattern:auto; mso-protection:locked visible; white-space:nowrap; mso-rotate:0;} .xl65 {border:.5pt solid windowtext;} .xl66 {font-weight:700; border:.5pt solid windowtext;} --> </style> </head> <body link=""#0563C1"" vlink=""#954F72""> CVE Name | Asset Name | Vulnerability Description | Remediation | Current Version | Recommended Version | DetailedName -- | -- | -- | -- | -- | -- | -- CVE-2022-28391 | docker.io/drone/drone-runner-kube | The package `busybox` version `1.32.1-r7` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-28391`, which exists in versions `< 1.32.1-r8`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-28391) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-28391) severity: `High`). The vulnerability can be remediated by updating the package to version `1.32.1-r8` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade busybox`. | apk upgrade busybox | 1.32.1-r7 | 1.32.1-r8 | busybox CVE-2022-0778 | docker.io/drone/drone-runner-kube | The package `libcrypto1.1` version `1.1.1l-r0` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-0778`, which exists in versions `< 1.1.1n-r0`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-0778) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-0778) severity: `High`). This vulnerability has a known exploit available. Source: [Packetstorm](https://packetstormsecurity.com/files/167344/OpenSSL-1.0.2-1.1.1-3.0-BN_mod_sqrt-Infinite-Loop.html). The vulnerability can be remediated by updating the package to version `1.1.1n-r0` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade libcrypto1.1`. | apk upgrade libcrypto1.1 | 1.1.1l-r0 | 1.1.1n-r0 | libcrypto1.1 End-of-Life Version of Technology | docker.io/drone/drone-runner-kube | The OS `Linux Alpine` version `3.13.7` has been End-of-Life since `2022-11-01` as indicated in [Alpine Releases](https://alpinelinux.org/releases/). End-of-Life versions of operating systems have no further official support by the vendor and thus no security patches. Furthermore, newly discovered vulnerabilities are not reported. Thus, such technologies pose a threat that is both unknown and will not be fixed. | | 3.13.7 | 3.14.8 | Linux Alpine End-of-Life Version of Technology | docker.io/drone/drone | The OS `Linux Alpine` version `3.11.13` has been End-of-Life since `2021-11-01` as indicated in [Alpine Releases](https://alpinelinux.org/releases/). End-of-Life versions of operating systems have no further official support by the vendor and thus no security patches. Furthermore, newly discovered vulnerabilities are not reported. Thus, such technologies pose a threat that is both unknown and will not be fixed. | | 3.11.13 | 3.14.8 | Linux Alpine CVE-2022-30065 | docker.io/drone/drone-runner-kube | The package `busybox` version `1.32.1-r7` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-30065`, which exists in versions `< 1.32.1-r9`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-30065) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-30065) severity: `High`). The vulnerability can be remediated by updating the package to version `1.32.1-r9` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade busybox`. | apk upgrade busybox | 1.32.1-r7 | 1.32.1-r9 | busybox CVE-2022-37434 | docker.io/drone/drone-runner-kube | The package `zlib` version `1.2.11-r3` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-37434`, which exists in versions `< 1.2.12-r2`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-37434) with vendor severity: `Critical` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-37434) severity: `Critical`). This vulnerability has a known exploit available. Source: Github [[1](https://github.com/ivd38/zlib_overflow), [2](https://github.com/madler/zlib/blob/21767c654d31d2dccdde4330529775c6c5fd5389/zlib.h#L1062-L1063), [3](https://github.com/nodejs/node/blob/75b68c6e4db515f76df73af476eccf382bbcb00a/deps/zlib/inflate.c#L762-L764)]. The vulnerability can be remediated by updating the package to version `1.2.12-r2` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade zlib`. | apk upgrade zlib | 1.2.11-r3 | 1.2.12-r2 | zlib CVE-2022-37434 | docker.io/drone/drone | The package `zlib` version `1.2.11-r3` was detected in `APK package manager` on a container image running `Alpine 3.11.13` is vulnerable to `CVE-2022-37434`, which exists in versions `< 1.2.11-r4`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-37434) with vendor severity: `Critical` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-37434) severity: `Critical`). This vulnerability has a known exploit available. Source: Github [[1](https://github.com/ivd38/zlib_overflow), [2](https://github.com/madler/zlib/blob/21767c654d31d2dccdde4330529775c6c5fd5389/zlib.h#L1062-L1063), [3](https://github.com/nodejs/node/blob/75b68c6e4db515f76df73af476eccf382bbcb00a/deps/zlib/inflate.c#L762-L764)]. The vulnerability can be remediated by updating the package to version `1.2.11-r4` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade zlib`. | apk upgrade zlib | 1.2.11-r3 | 1.2.11-r4 | zlib CVE-2018-25032 | docker.io/drone/drone-runner-kube | The package `zlib` version `1.2.11-r3` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2018-25032`, which exists in versions `< 1.2.12-r0`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2018-25032) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2018-25032) severity: `High`). The vulnerability can be remediated by updating the package to version `1.2.12-r0` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade zlib`. | apk upgrade zlib | 1.2.11-r3 | 1.2.12-r0 | zlib CVE-2022-28391 | docker.io/drone/drone-runner-kube | The package `ssl_client` version `1.32.1-r7` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-28391`, which exists in versions `< 1.32.1-r8`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-28391) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-28391) severity: `High`). The vulnerability can be remediated by updating the package to version `1.32.1-r8` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade ssl_client`. | apk upgrade ssl_client | 1.32.1-r7 | 1.32.1-r8 | ssl_client End-of-Life Version of Technology | docker.io/drone/vault | The OS `Linux Alpine` version `3.6.5` has been End-of-Life since `2019-05-01` as indicated in [Alpine Releases](https://alpinelinux.org/releases/). End-of-Life versions of operating systems have no further official support by the vendor and thus no security patches. Furthermore, newly discovered vulnerabilities are not reported. Thus, such technologies pose a threat that is both unknown and will not be fixed. | | 3.6.5 | 3.14.8 | Linux Alpine CVE-2022-0778 | docker.io/drone/drone-runner-kube | The package `libssl1.1` version `1.1.1l-r0` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-0778`, which exists in versions `< 1.1.1n-r0`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-0778) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-0778) severity: `High`). This vulnerability has a known exploit available. Source: [Packetstorm](https://packetstormsecurity.com/files/167344/OpenSSL-1.0.2-1.1.1-3.0-BN_mod_sqrt-Infinite-Loop.html). The vulnerability can be remediated by updating the package to version `1.1.1n-r0` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade libssl1.1`. | apk upgrade libssl1.1 | 1.1.1l-r0 | 1.1.1n-r0 | libssl1.1 CVE-2022-30065 | docker.io/drone/drone-runner-kube | The package `ssl_client` version `1.32.1-r7` was detected in `APK package manager` on a container image running `Alpine 3.13.7` is vulnerable to `CVE-2022-30065`, which exists in versions `< 1.32.1-r9`. The vulnerability was found in the [Official Alpine Security Advisories](https://security.alpinelinux.org/vuln/CVE-2022-30065) with vendor severity: `High` ([NVD](https://nvd.nist.gov/vuln/detail/CVE-2022-30065) severity: `High`). The vulnerability can be remediated by updating the package to version `1.32.1-r9` or higher, by adding the following command to the Dockerfile: `RUN apk upgrade ssl_client`. | apk upgrade ssl_client | 1.32.1-r7 | 1.32.1-r9 | ssl_client </body> </html> source-file",no-bug,0.95
2929,harness,https://github.com/harness/harness/issues/2929,docker-runner: DRONE_RUNNER_MAX_PROCS changes behaviour of job execution,"when DRONE_RUNNER_MAX_PROCS is set queued jobs parallel jobs get canceled if a previous step fails, IMO the remaining jobs should continue to be executed just like if DRONE_RUNNER_MAX_PROCS was never set in the first place.",other-file,"docker-runner: DRONE_RUNNER_MAX_PROCS changes behaviour of job execution when DRONE_RUNNER_MAX_PROCS is set queued jobs parallel jobs get canceled if a previous step fails, IMO the remaining jobs should continue to be executed just like if DRONE_RUNNER_MAX_PROCS was never set in the first place. other-file",no-bug,0.9
499,harness,https://github.com/harness/harness/issues/499,Custom Docker containers,"e.g. we have our own container for node.js (much smaller than the official one for drone!), however it uses `/srv/app` mount. I don't see this in the documentation, how is it possible configure the mounting points, ports and `links` for services like `mongodb`? I am assuming that the mongodb & redis ports will be bridged to the build container, is that correct? PS: As of writing, i am half way through the download of the node image (1.7GB). <- does that contain the npm registry or what?",source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file,"Custom Docker containers e.g. we have our own container for node.js (much smaller than the official one for drone!), however it uses `/srv/app` mount. I don't see this in the documentation, how is it possible configure the mounting points, ports and `links` for services like `mongodb`? I am assuming that the mongodb & redis ports will be bridged to the build container, is that correct? PS: As of writing, i am half way through the download of the node image (1.7GB). <- does that contain the npm registry or what? source-file documentation-file other-file other-file other-file other-file source-file other-file source-file",no-bug,0.9
1233,harness,https://github.com/harness/harness/issues/1233,Timeline grouping and incorrect rendering,"The build timeline has a few minor rendering issues when appending builds received by the websocket. So in other words, the page is rendered correctly when first loaded, but may have trouble appending builds to the list. Right now new builds are appended to the latest group in the timeline. There are two known issues with this approach: 1. websocket receives the very first build, and no existing group exists 2. websocket receives a build, but the last group does not match the build date. The build is therefore appended to the wrong group **note** this is a known bug that I will probably defer because it is considered relatively minor compared to some of the other issues out there. I would love a volunteer to not only resolve these issues, but to also help improve our front-end code as a whole. If you are interested please get in touch in our [gitter room](https://gitter.im/drone/drone).",source-file | source-file,"Timeline grouping and incorrect rendering The build timeline has a few minor rendering issues when appending builds received by the websocket. So in other words, the page is rendered correctly when first loaded, but may have trouble appending builds to the list. Right now new builds are appended to the latest group in the timeline. There are two known issues with this approach: 1. websocket receives the very first build, and no existing group exists 2. websocket receives a build, but the last group does not match the build date. The build is therefore appended to the wrong group **note** this is a known bug that I will probably defer because it is considered relatively minor compared to some of the other issues out there. I would love a volunteer to not only resolve these issues, but to also help improve our front-end code as a whole. If you are interested please get in touch in our [gitter room](https://gitter.im/drone/drone). source-file source-file",no-bug,0.9
297,harness,https://github.com/harness/harness/issues/297,Ability to trigger upstream tests,"We have many repos that have upstream dependencies, e.g. an ORM library that many different applications depend on. It'd be great to be able to trigger tests in upstream dependencies upon completion of testing a repo. Sidenote: I think it might be possible to hack this with a bash deploy hook that hits the drone webhook endpoint, but it'd have to recreate the last payload somehow",other-file | container-file | container-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file | other-file,"Ability to trigger upstream tests We have many repos that have upstream dependencies, e.g. an ORM library that many different applications depend on. It'd be great to be able to trigger tests in upstream dependencies upon completion of testing a repo. Sidenote: I think it might be possible to hack this with a bash deploy hook that hits the drone webhook endpoint, but it'd have to recreate the last payload somehow other-file container-file container-file source-file other-file other-file other-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file source-file other-file",no-bug,0.9
2544,harness,https://github.com/harness/harness/issues/2544,instructions how to start contributing?,"I have tried to find good instructions to how to start contributing drone. It seems that there is not really good instructions to this? I am currently trying to build drone-server that I could test my new code features, but I cannot find how to do that. I tried to follow this https://github.com/drone/drone/blob/master/BUILDING but it does not build any binaries? Then I tried to understand what is happening in this file https://github.com/drone/drone/blob/master/.drone.sh#L22 However, I do not have access to drone-enterprise repositories, so I cannot build drone-server at all? So my question is: could someone make clear instructions how to build drone-server that we could verify code changes?",source-file | source-file | source-file,"instructions how to start contributing? I have tried to find good instructions to how to start contributing drone. It seems that there is not really good instructions to this? I am currently trying to build drone-server that I could test my new code features, but I cannot find how to do that. I tried to follow this https://github.com/drone/drone/blob/master/BUILDING but it does not build any binaries? Then I tried to understand what is happening in this file https://github.com/drone/drone/blob/master/.drone.sh#L22 However, I do not have access to drone-enterprise repositories, so I cannot build drone-server at all? So my question is: could someone make clear instructions how to build drone-server that we could verify code changes? source-file source-file source-file",no-bug,0.95
145,harness,https://github.com/harness/harness/issues/145,Investigate shields.io for badges,http://shields.io/ You can read about the projects approach and rationale here :) https://github.com/badges/shields#shields,source-file | source-file | source-file | source-file | source-file | source-file | other-file | documentation-file | source-file | source-file | source-file,Investigate shields.io for badges http://shields.io/ You can read about the projects approach and rationale here :) https://github.com/badges/shields#shields source-file source-file source-file source-file source-file source-file other-file documentation-file source-file source-file source-file,no-bug,0.9
1115,harness,https://github.com/harness/harness/issues/1115,Create dashing.io widget,i.e. https://gist.github.com/petehamilton/5494978,other-file | other-file | source-file,Create dashing.io widget i.e. https://gist.github.com/petehamilton/5494978 other-file other-file source-file,no-bug,0.9
394,harness,https://github.com/harness/harness/issues/394,"Building from src, deb pkg upstart script fails","droned is called without a path. After building from source, the deb package that is created installed drone in /usr/local/bin (as well as in $GOPATH/bin), neither of which may necessarily be searched on a system's boot. Thus, initctl doesn't launch the job.  droned $DRONED_OPTS  I changed this to /usr/local/bin/droned and it started correctly.",config-file | config-file,"Building from src, deb pkg upstart script fails droned is called without a path. After building from source, the deb package that is created installed drone in /usr/local/bin (as well as in $GOPATH/bin), neither of which may necessarily be searched on a system's boot. Thus, initctl doesn't launch the job.  droned $DRONED_OPTS  I changed this to /usr/local/bin/droned and it started correctly. config-file config-file",no-bug,0.9
142,harness,https://github.com/harness/harness/issues/142,Error pulling MongoDB,"What can be the reason for this? I have drone and docker daemons running. I have successfully pulled images from the docker registry but it seems drone can't find them.  bash user@ci-server:~$ docker run -i -t ubuntu /bin/bash root@5b831ad6b38f:/#  `/etc/init/docker.conf` contains this line as it solved another error ""no dial 0.0.0.0:4243"":  bash DOCKER_OPTS=""-H 0.0.0.0:4243 -H unix:var/run/docker.sock -d"" ",other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Error pulling MongoDB What can be the reason for this? I have drone and docker daemons running. I have successfully pulled images from the docker registry but it seems drone can't find them.  bash user@ci-server:~$ docker run -i -t ubuntu /bin/bash root@5b831ad6b38f:/#  `/etc/init/docker.conf` contains this line as it solved another error ""no dial 0.0.0.0:4243"":  bash DOCKER_OPTS=""-H 0.0.0.0:4243 -H unix:var/run/docker.sock -d""  other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
1234,harness,https://github.com/harness/harness/issues/1234,"Improve Dashboard, Repo List, Feed","One major change that comes with 0.4 is that we no longer sync your complete repository list in the database (for reasons described in #776). Instead we use the GitHub API to fetch your repository list and your repository permissions live. One disadvantage to this approach is that we don't have a simple way (like a database join) to tell Drone to quickly give me a list of all repositories I have access to, or a build feed for all repositories I have access to. I believe the solution is to fetch the list of all repositories from GitHub and then to create a really big `IN` statement. The `IN` operator will get passed the list of all repository names from GitHub as demonstrated in the following example:  sql select * from repos where repo_full_name IN (?,?,?,?,?,?,?,?,?,?)  I even have a function already stubbed out in the code:  Go func GetRepoListOf(db meddler.DB, listof []string) ([]*Repo, error) { var repos = []*Repo{} var length = len(listof) var qs = make([]string, length, length) var in = make([]interface{}, length, length) for i, repo := range listof { qs[i] = ""?"" in[i] = repo } var stmt = ""SELECT * FROM repos WHERE repo_id IN ("" + strings.Join(qs, "","") + "")"" var err = meddler.QueryAll(db, &repos, database.Rebind(stmt), in) return repos, err }  According to the documentation sqlite can hold a maximum of 999 parameters in the `IN` statement, and mysql and postgres [1] can hold tens of thousands of parameters. I remember doing this about 10 years ago to query an Oracle database with a few million rows and it worked quite well. So I'm pretty confident this approach is technically feasible, however, I still want to understand the performance implications on large datasets for the database vendors that we support. Until I have benchmarks that support the above design, we implement the following workarounds: 1. The `/user/repos` endpoint returns a list of all repositories to which the user has authored a commit, based on data in the `builds` table 2. The `/user/feed` endpoint returns a list of all builds the user has authored I am proactively logging this issue to explain why the behavior is currently different and might appear broken, to assure everyone this is just a temporary workaround, and that I hope to have the proposed changes in place prior to the final 0.4 release.  [1] consider described optimization for postgres https://www.datadoghq.com/blog/100x-faster-postgres-performance-by-changing-1-line/",source-file | source-file | other-file,"Improve Dashboard, Repo List, Feed One major change that comes with 0.4 is that we no longer sync your complete repository list in the database (for reasons described in #776). Instead we use the GitHub API to fetch your repository list and your repository permissions live. One disadvantage to this approach is that we don't have a simple way (like a database join) to tell Drone to quickly give me a list of all repositories I have access to, or a build feed for all repositories I have access to. I believe the solution is to fetch the list of all repositories from GitHub and then to create a really big `IN` statement. The `IN` operator will get passed the list of all repository names from GitHub as demonstrated in the following example:  sql select * from repos where repo_full_name IN (?,?,?,?,?,?,?,?,?,?)  I even have a function already stubbed out in the code:  Go func GetRepoListOf(db meddler.DB, listof []string) ([]*Repo, error) { var repos = []*Repo{} var length = len(listof) var qs = make([]string, length, length) var in = make([]interface{}, length, length) for i, repo := range listof { qs[i] = ""?"" in[i] = repo } var stmt = ""SELECT * FROM repos WHERE repo_id IN ("" + strings.Join(qs, "","") + "")"" var err = meddler.QueryAll(db, &repos, database.Rebind(stmt), in) return repos, err }  According to the documentation sqlite can hold a maximum of 999 parameters in the `IN` statement, and mysql and postgres [1] can hold tens of thousands of parameters. I remember doing this about 10 years ago to query an Oracle database with a few million rows and it worked quite well. So I'm pretty confident this approach is technically feasible, however, I still want to understand the performance implications on large datasets for the database vendors that we support. Until I have benchmarks that support the above design, we implement the following workarounds: 1. The `/user/repos` endpoint returns a list of all repositories to which the user has authored a commit, based on data in the `builds` table 2. The `/user/feed` endpoint returns a list of all builds the user has authored I am proactively logging this issue to explain why the behavior is currently different and might appear broken, to assure everyone this is just a temporary workaround, and that I hope to have the proposed changes in place prior to the final 0.4 release.  [1] consider described optimization for postgres https://www.datadoghq.com/blog/100x-faster-postgres-performance-by-changing-1-line/ source-file source-file other-file",no-bug,0.9
2144,harness,https://github.com/harness/harness/issues/2144,default some columns to utf8mb4,"We often see mysql databases created with the latin1 character set which fail to handle certain languages and special character sequences like emojis. Instead of relying on this to be configure correctly, we should probably just force a subset of drone fields to use the correct character set. We should probably set a default for the commit title and message, at a minimum. sql build_message VARCHAR(2000) CHARACTER SET utf8mb4 COLLATE utf8mb4_ci ",other-file | other-file,"default some columns to utf8mb4 We often see mysql databases created with the latin1 character set which fail to handle certain languages and special character sequences like emojis. Instead of relying on this to be configure correctly, we should probably just force a subset of drone fields to use the correct character set. We should probably set a default for the commit title and message, at a minimum. sql build_message VARCHAR(2000) CHARACTER SET utf8mb4 COLLATE utf8mb4_ci  other-file other-file",no-bug,0.9
21,harness,https://github.com/harness/harness/issues/21,Page constantly refreshes during build,"If a build is still in progress and I visit the status page, my browser continually refreshes every second until the build is done.",source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | other-file | other-file,"Page constantly refreshes during build If a build is still in progress and I visit the status page, my browser continually refreshes every second until the build is done. source-file source-file source-file source-file source-file source-file test-file source-file other-file other-file",no-bug,0.9
644,harness,https://github.com/harness/harness/issues/644,"Accept error: accept tcp: too many open files, retrying in 1s","This seems to be hanging the build. Could this be related to worker threads? 2014/10/28 18:09:05 Error building c5eae93df0e62688296e7354592bba0f67fc333a, Err: Post http:var/run/docker.sock/v1.9/build?q=1&rm=1&t=drone-36a74061cc: dial unix /var/run/docker.sock: too many open files 2014/10/28 18:09:05 dial tcp :0: too many open files 2014/10/28 18:09:05 subscription's close channel received message 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 5ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 10ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 20ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 40ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 80ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 160ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 320ms 2014/10/28 18:09:29 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 640ms 2014/10/28 18:09:29 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 1s 2014/10/28 18:09:30 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 1s 2014/10/28 18:09:31 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 1s",other-file | other-file | source-file,"Accept error: accept tcp: too many open files, retrying in 1s This seems to be hanging the build. Could this be related to worker threads? 2014/10/28 18:09:05 Error building c5eae93df0e62688296e7354592bba0f67fc333a, Err: Post http:var/run/docker.sock/v1.9/build?q=1&rm=1&t=drone-36a74061cc: dial unix /var/run/docker.sock: too many open files 2014/10/28 18:09:05 dial tcp :0: too many open files 2014/10/28 18:09:05 subscription's close channel received message 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 5ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 10ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 20ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 40ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 80ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 160ms 2014/10/28 18:09:28 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 320ms 2014/10/28 18:09:29 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 640ms 2014/10/28 18:09:29 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 1s 2014/10/28 18:09:30 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 1s 2014/10/28 18:09:31 http: Accept error: accept tcp [::]:8282: too many open files; retrying in 1s other-file other-file source-file",no-bug,0.9
2640,harness,https://github.com/harness/harness/issues/2640,"Drone connect to my github , but cannot activate",my docker-compose.yml version: '2' services: drone-server: image: drone/drone:1.0.0 ports: - 8082:80 volumes: - ./:/data - /var/run/docker.sock:/var/run/docker.sock restart: always environment: - DRONE_SERVER_HOST=${DRONE_SERVER_HOST} - DRONE_SERVER_PROTO=${DRONE_SERVER_PROTO} - DRONE_TLS_AUTOCERT=false - DRONE_RUNNER_CAPACITY=3 # GitHub Config - DRONE_GITHUB_SERVER=https://github.com - DRONE_GITHUB_CLIENT_ID=ccf51708f5d3bf22009f - DRONE_GITHUB_CLIENT_SECRET=18f79a52f02762a7dd3207140908885d09348966 - DRONE_LOGS_PRETTY=true - DRONE_LOGS_COLOR=true it stay activating . ![ 2019-04-02 8 07 30](https://user-images.githubusercontent.com/22629976/55367250-b2e14b80-551e-11e9-8f1b-750447a5206e.png),source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file,"Drone connect to my github , but cannot activate my docker-compose.yml version: '2' services: drone-server: image: drone/drone:1.0.0 ports: - 8082:80 volumes: - ./:/data - /var/run/docker.sock:/var/run/docker.sock restart: always environment: - DRONE_SERVER_HOST=${DRONE_SERVER_HOST} - DRONE_SERVER_PROTO=${DRONE_SERVER_PROTO} - DRONE_TLS_AUTOCERT=false - DRONE_RUNNER_CAPACITY=3 # GitHub Config - DRONE_GITHUB_SERVER=https://github.com - DRONE_GITHUB_CLIENT_ID=ccf51708f5d3bf22009f - DRONE_GITHUB_CLIENT_SECRET=18f79a52f02762a7dd3207140908885d09348966 - DRONE_LOGS_PRETTY=true - DRONE_LOGS_COLOR=true it stay activating . ![ 2019-04-02 8 07 30](https://user-images.githubusercontent.com/22629976/55367250-b2e14b80-551e-11e9-8f1b-750447a5206e.png) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file test-file source-file source-file",no-bug,0.7
1224,harness,https://github.com/harness/harness/issues/1224,UI links to repo,In drone 0.3 was link to repo. Like go to commit and other Now not have links in ui You want to add to it 0.4?,other-file | config-file | other-file | other-file | other-file | source-file | source-file | source-file | documentation-file | other-file,UI links to repo In drone 0.3 was link to repo. Like go to commit and other Now not have links in ui You want to add to it 0.4? other-file config-file other-file other-file other-file source-file source-file source-file documentation-file other-file,no-bug,0.8
918,harness,https://github.com/harness/harness/issues/918,Display download of images in build log,"the build log is empty for several minutes. reason is that the image gets downloaded for the first time:  928b8f4c06ba: Pulling metadata 928b8f4c06ba: Pulling fs layer 928b8f4c06ba: Download complete  the user should to know that, like with `downloading image`",source-file,"Display download of images in build log the build log is empty for several minutes. reason is that the image gets downloaded for the first time:  928b8f4c06ba: Pulling metadata 928b8f4c06ba: Pulling fs layer 928b8f4c06ba: Download complete  the user should to know that, like with `downloading image` source-file",no-bug,0.9
967,harness,https://github.com/harness/harness/issues/967,Run one build on two CPUs,"I don't know if it's currently possible but I want to use the full potential of my server by running a build on two CPUs. With my actual config I can run two builds simultaneously but when I have only one build running (and it is what happens most of the time) it can use only half of the power of my instance. Can we configure Drone to launch docker container with the good configuration for that ? Maybe something like the docker config `CpuSet` ? We have an heavy build that take 30 minutes to run, to divide it by 2 would be very great to improve the feedback loop of continuous integration.",other-file,"Run one build on two CPUs I don't know if it's currently possible but I want to use the full potential of my server by running a build on two CPUs. With my actual config I can run two builds simultaneously but when I have only one build running (and it is what happens most of the time) it can use only half of the power of my instance. Can we configure Drone to launch docker container with the good configuration for that ? Maybe something like the docker config `CpuSet` ? We have an heavy build that take 30 minutes to run, to divide it by 2 would be very great to improve the feedback loop of continuous integration. other-file",no-bug,0.95
842,harness,https://github.com/harness/harness/issues/842,How to deploy the committed application in the drone if the drone is running as a docker container,"Recently, i have learned a lot about the drone, now on my digitalocean server I install the drone as a docker container followed by this article https://www.digitalocean.com/community/tutorials/how-to-perform-continuous-integration-testing-with-drone-io-on-coreos-and-docker , and the drone can get my node.js code commits from github and run the tests successfully. However, when the tests is running over, I want to use the committed code to build a image, run this image into a app container which links to other database containers. However, as I mentioned, my drone is running in a docker container, so the issues come as. 1. in the yml document has several docker commands to start the containers in the host environment. - docker ps -a - docker start ce9e 7b84 9a9f a755 firstly docker command could not be found, secondly I think the docker in the container could not control the docker process in the host environment. 1. the committed code is in /var/cache/drone/src/github.com/helxsz/food in the container environment, and in the host environment there is no code found, given these issues, I am wondering what is the purpose of running the drone in the docker container apart from doing the tests. is it a bad practice to run the drone in the docker container, should it be to run the drone directly in the host environment.",source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file,"How to deploy the committed application in the drone if the drone is running as a docker container Recently, i have learned a lot about the drone, now on my digitalocean server I install the drone as a docker container followed by this article https://www.digitalocean.com/community/tutorials/how-to-perform-continuous-integration-testing-with-drone-io-on-coreos-and-docker , and the drone can get my node.js code commits from github and run the tests successfully. However, when the tests is running over, I want to use the committed code to build a image, run this image into a app container which links to other database containers. However, as I mentioned, my drone is running in a docker container, so the issues come as. 1. in the yml document has several docker commands to start the containers in the host environment. - docker ps -a - docker start ce9e 7b84 9a9f a755 firstly docker command could not be found, secondly I think the docker in the container could not control the docker process in the host environment. 1. the committed code is in /var/cache/drone/src/github.com/helxsz/food in the container environment, and in the host environment there is no code found, given these issues, I am wondering what is the purpose of running the drone in the docker container apart from doing the tests. is it a bad practice to run the drone in the docker container, should it be to run the drone directly in the host environment. source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file",no-bug,0.95
881,harness,https://github.com/harness/harness/issues/881,Automated Docker Hub Builds,Could someone at drone setup an automated build on the docker hub registry against master branch to avoid the need for clones (i.e. https://registry.hub.docker.com/u/davidwindell/drone/)?,source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,Automated Docker Hub Builds Could someone at drone setup an automated build on the docker hub registry against master branch to avoid the need for clones (i.e. https://registry.hub.docker.com/u/davidwindell/drone/)? source-file source-file source-file source-file source-file source-file source-file other-file,no-bug,0.9
1151,harness,https://github.com/harness/harness/issues/1151,Document building from source,Added some initial documentation here: https://github.com/drone/drone/tree/0.4.0/#cloning-building-running Some missing items include: - Installing Docker (1.7 or above?) - Creating Docker images -  anything else?,other-file,Document building from source Added some initial documentation here: https://github.com/drone/drone/tree/0.4.0/#cloning-building-running Some missing items include: - Installing Docker (1.7 or above?) - Creating Docker images -  anything else? other-file,no-bug,0.95
1039,harness,https://github.com/harness/harness/issues/1039,OAuth does not send DefaultScope variable,"The DefaultScope variable in the github.go file is never sent via OAuth to github. When a user authorizes for the first time it does not send the user:email scope and the login process will fail. To Recreate: Log into github, go to settings-Applications and revoke any old Drone applications. Start drone and try to log in. You will get a user email not found error, because Drone doesn't have permission to access emails. Workaround: Add a ""scope"" variable to your config.toml file. For example: [auth] client = ""CLIENTID"" secret = ""SECRET"" authorize = ""https://github.com/login/oauth/authorize"" access_token = ""https://github.com/login/oauth/access_token"" request_token = """" scope= [""repo"",""repo:status"",""user:email""] Thanks, Phil Winder",other-file,"OAuth does not send DefaultScope variable The DefaultScope variable in the github.go file is never sent via OAuth to github. When a user authorizes for the first time it does not send the user:email scope and the login process will fail. To Recreate: Log into github, go to settings-Applications and revoke any old Drone applications. Start drone and try to log in. You will get a user email not found error, because Drone doesn't have permission to access emails. Workaround: Add a ""scope"" variable to your config.toml file. For example: [auth] client = ""CLIENTID"" secret = ""SECRET"" authorize = ""https://github.com/login/oauth/authorize"" access_token = ""https://github.com/login/oauth/access_token"" request_token = """" scope= [""repo"",""repo:status"",""user:email""] Thanks, Phil Winder other-file",no-bug,0.8
3533,harness,https://github.com/harness/harness/issues/3533,Feature Request: Support for Displaying the Webhook Execution List,"requesting support for displaying a list of webhook executions within our application. Currently, users can manage webhooks by adding or removing them from their accounts. However, there is no feature to view which specific webhooks have been triggered, when they were triggered, and any associated metadata such as the request payload.",documentation-file | source-file | source-file | source-file | other-file | other-file | other-file | source-file | documentation-file | source-file | source-file | other-file,"Feature Request: Support for Displaying the Webhook Execution List requesting support for displaying a list of webhook executions within our application. Currently, users can manage webhooks by adding or removing them from their accounts. However, there is no feature to view which specific webhooks have been triggered, when they were triggered, and any associated metadata such as the request payload. documentation-file source-file source-file source-file other-file other-file other-file source-file documentation-file source-file source-file other-file",no-bug,0.9
2451,harness,https://github.com/harness/harness/issues/2451,Is secret logging using correct logic?,https://github.com/drone/drone/blob/a85f89a3c188ea9eba0991c483bb2a2b9e855377/cmd/drone-agent/agent.go#L270 It looks like secrets with Mask true shouldn't have their value added here. Am I missing something?,source-file | source-file | source-file,Is secret logging using correct logic? https://github.com/drone/drone/blob/a85f89a3c188ea9eba0991c483bb2a2b9e855377/cmd/drone-agent/agent.go#L270 It looks like secrets with Mask true shouldn't have their value added here. Am I missing something? source-file source-file source-file,no-bug,0.7
830,harness,https://github.com/harness/harness/issues/830,the commit get stuck in running for some reason and can't manually stop building the commit.,"I have installed the drone on the digital ocean, my app is very simple express node.js app.  javascript var express = require('express'); console.log(""hello log""); var app = express(); app.get('/', function(req, res){ res.send('hello world'); }); app.listen(3300);  my yml is like  javascript image: dockerfile/nodejs env: - GOPATH=/var/cache/drone script: - echo hello world 222 - pwd - ls - npm install express redis mqtt - node app.js - /bin/bash services: - mongodb - rabbitmq - redis  when the drone server is updating on the commit, it will get stuck in running the  node app.js, keep running forever Firstly, I don't know why it will get stuck in running  node app.js, in particular in app.listen(3300), if I commented the line  app.listen(3300), the commit update will be successful. The port 3300 is always open. Secondly, because the update is running forever, and there is no way for me to stop the current commit, even I push a new commit, this new commit will fail to execute since the previous commit is still running. Anybody help me with these two issues ?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"the commit get stuck in running for some reason and can't manually stop building the commit. I have installed the drone on the digital ocean, my app is very simple express node.js app.  javascript var express = require('express'); console.log(""hello log""); var app = express(); app.get('/', function(req, res){ res.send('hello world'); }); app.listen(3300);  my yml is like  javascript image: dockerfile/nodejs env: - GOPATH=/var/cache/drone script: - echo hello world 222 - pwd - ls - npm install express redis mqtt - node app.js - /bin/bash services: - mongodb - rabbitmq - redis  when the drone server is updating on the commit, it will get stuck in running the  node app.js, keep running forever Firstly, I don't know why it will get stuck in running  node app.js, in particular in app.listen(3300), if I commented the line  app.listen(3300), the commit update will be successful. The port 3300 is always open. Secondly, because the update is running forever, and there is no way for me to stop the current commit, even I push a new commit, this new commit will fail to execute since the previous commit is still running. Anybody help me with these two issues ? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3339,harness,https://github.com/harness/harness/issues/3339,Enable to NOT store in the database some build parameter,Idea is to either use a convention (`UNSAFE_*`?) or let it be configurable in the UI but the overall goal is to NOT store in the database - and therefore not enable to retrieve it with the API or direct access - the parameters used to trigger a job. It is likely a filter to implement in https://github.com/harness/drone/blob/master/store/build/scan.go#L102.,source-file | source-file | source-file | source-file | source-file | source-file,Enable to NOT store in the database some build parameter Idea is to either use a convention (`UNSAFE_*`?) or let it be configurable in the UI but the overall goal is to NOT store in the database - and therefore not enable to retrieve it with the API or direct access - the parameters used to trigger a job. It is likely a filter to implement in https://github.com/harness/drone/blob/master/store/build/scan.go#L102. source-file source-file source-file source-file source-file source-file,no-bug,0.8
1225,harness,https://github.com/harness/harness/issues/1225,drone 0.4 publish to docker,"<img width=""1249"" alt=""2015-10-07 15 26 32"" src=""https://cloud.githubusercontent.com/assets/1614346/10337458/736248ee-6d08-11e5-92d9-2e24bb55a18a.png""> not runnig task for pusblish my .drone.yml  build: image: golang:1.5.1 environment: - MP_DOCKER_CHANNEL=TEST-DRONE commands: - go get golang.org/x/tools/cmd/cover - go get gopkg.in/check.v1 - make deps - make test - make build compose: elastic: image: elasticsearch mongodb: image: mongo nsq: image: antonikonovalov/dockerfile-nsq pubish: docker: registry: http://ci.als.local:5000/v2/ repo: ci.als.local:5000/mp/backend tag: from-drone-4 file: Dockerfile when: branch: drone-4 notify: slack: webhook_url: https://hooks.slack.com/services/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 channel: marketplace username: drone ",source-file | source-file,"drone 0.4 publish to docker <img width=""1249"" alt=""2015-10-07 15 26 32"" src=""https://cloud.githubusercontent.com/assets/1614346/10337458/736248ee-6d08-11e5-92d9-2e24bb55a18a.png""> not runnig task for pusblish my .drone.yml  build: image: golang:1.5.1 environment: - MP_DOCKER_CHANNEL=TEST-DRONE commands: - go get golang.org/x/tools/cmd/cover - go get gopkg.in/check.v1 - make deps - make test - make build compose: elastic: image: elasticsearch mongodb: image: mongo nsq: image: antonikonovalov/dockerfile-nsq pubish: docker: registry: http://ci.als.local:5000/v2/ repo: ci.als.local:5000/mp/backend tag: from-drone-4 file: Dockerfile when: branch: drone-4 notify: slack: webhook_url: https://hooks.slack.com/services/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 channel: marketplace username: drone  source-file source-file",no-bug,0.9
569,harness,https://github.com/harness/harness/issues/569,Enhanced Gitter Support,Looks like we can establish deeper integration with Gitter by adding Drone as an official service: https://github.com/gitterHQ/services JavaScript isn't my forte so I'm hoping someone is willing to pitch in,other-file,Enhanced Gitter Support Looks like we can establish deeper integration with Gitter by adding Drone as an official service: https://github.com/gitterHQ/services JavaScript isn't my forte so I'm hoping someone is willing to pitch in other-file,no-bug,0.95
3515,harness,https://github.com/harness/harness/issues/3515,Git HTTPS Protocol - New Branch Creation Rule Not Blocking Push from CLI but Works via UI,"## Description: When using the Git HTTPS protocol, I have set a rule to prohibit the creation of new branches. After cloning the repository locally and checking out a new branch, I am able to push the new branch without any restrictions from the command line. However, the UI correctly enforces this rule. Additionally, key scanning exhibits similar behavior; enabling or disabling it has no effect. This inconsistency is affecting our workflow. ## Steps to Reproduce: - Set up a rule to prohibit new branch creation on the repository. - Clone the repository locally using the HTTPS protocol. - Create a new branch locally. - Push the new branch to the remote repository via the command line. ## Expected Behavior: The push operation should be blocked due to the rule prohibiting the creation of new branches, consistently across both CLI and UI. ![image](https://github.com/harness/gitness/assets/8605565/e350606d-ee2a-473a-8983-14795c3a5949) ![image](https://github.com/harness/gitness/assets/8605565/888d62a1-7372-4a21-af85-a63cef38c00b)",source-file,"Git HTTPS Protocol - New Branch Creation Rule Not Blocking Push from CLI but Works via UI ## Description: When using the Git HTTPS protocol, I have set a rule to prohibit the creation of new branches. After cloning the repository locally and checking out a new branch, I am able to push the new branch without any restrictions from the command line. However, the UI correctly enforces this rule. Additionally, key scanning exhibits similar behavior; enabling or disabling it has no effect. This inconsistency is affecting our workflow. ## Steps to Reproduce: - Set up a rule to prohibit new branch creation on the repository. - Clone the repository locally using the HTTPS protocol. - Create a new branch locally. - Push the new branch to the remote repository via the command line. ## Expected Behavior: The push operation should be blocked due to the rule prohibiting the creation of new branches, consistently across both CLI and UI. ![image](https://github.com/harness/gitness/assets/8605565/e350606d-ee2a-473a-8983-14795c3a5949) ![image](https://github.com/harness/gitness/assets/8605565/888d62a1-7372-4a21-af85-a63cef38c00b) source-file",no-bug,0.9
625,harness,https://github.com/harness/harness/issues/625,Drone fails to delete build,"It appears the latest master branch is failing to delete builds, I can't work out whether this is an issue with my local docker setup or an issue with drone: From `/var/log/upstart/drone.log`:  starting build failed to completely delete build image 0015cf3ad5614eb242946bbc09d0fd8e286f3f4a7e4fc46e1ead5d342d691c9d. Not Found  Docker info:  root@docker-01:/# docker version Client version: 1.3.0 Client API version: 1.15 Go version (client): go1.3.3 Git commit (client): c78088f OS/Arch (client): linux/amd64 Server version: 1.3.0 Server API version: 1.15 Go version (server): go1.3.3 Git commit (server): c78088f root@docker-01:/#  Running on Ubuntu 14.04. Any other info I can provide?",source-file | source-file | source-file,"Drone fails to delete build It appears the latest master branch is failing to delete builds, I can't work out whether this is an issue with my local docker setup or an issue with drone: From `/var/log/upstart/drone.log`:  starting build failed to completely delete build image 0015cf3ad5614eb242946bbc09d0fd8e286f3f4a7e4fc46e1ead5d342d691c9d. Not Found  Docker info:  root@docker-01:/# docker version Client version: 1.3.0 Client API version: 1.15 Go version (client): go1.3.3 Git commit (client): c78088f OS/Arch (client): linux/amd64 Server version: 1.3.0 Server API version: 1.15 Go version (server): go1.3.3 Git commit (server): c78088f root@docker-01:/#  Running on Ubuntu 14.04. Any other info I can provide? source-file source-file source-file",no-bug,0.8
3402,harness,https://github.com/harness/harness/issues/3402,Can't import repository from GitHub,"Hi team, trying to import a Spring Petclinic repo (https://github.com/spring-projects/spring-petclinic.git) in Gitness and no luck. This query fails with HTTP 400: http://localhost:3000/api/v1/repos/import Request: `{""description"":"""",""parent_ref"":""spring-petclinic"",""uid"":""spring-petclinic.git"",""provider"":{""type"":""github"",""username"":"""",""password"":""""},""provider_repo"":""spring-projects/spring-petclinic.git""}` Video: https://www.youtube.com/watch?v=v4x6G4BwxhA",source-file | source-file | source-file | source-file | source-file,"Can't import repository from GitHub Hi team, trying to import a Spring Petclinic repo (https://github.com/spring-projects/spring-petclinic.git) in Gitness and no luck. This query fails with HTTP 400: http://localhost:3000/api/v1/repos/import Request: `{""description"":"""",""parent_ref"":""spring-petclinic"",""uid"":""spring-petclinic.git"",""provider"":{""type"":""github"",""username"":"""",""password"":""""},""provider_repo"":""spring-projects/spring-petclinic.git""}` Video: https://www.youtube.com/watch?v=v4x6G4BwxhA source-file source-file source-file source-file source-file",bug,0.9
435,harness,https://github.com/harness/harness/issues/435,Document procedure for installing SSL chain,A notice in the documentation that the chain should be appended would be helpful. The only reason I was able to get this working is because I happened to find this issue: https://github.com/drone/drone/issues/388,source-file | source-file | source-file | source-file,Document procedure for installing SSL chain A notice in the documentation that the chain should be appended would be helpful. The only reason I was able to get this working is because I happened to find this issue: https://github.com/drone/drone/issues/388 source-file source-file source-file source-file,no-bug,0.9
557,harness,https://github.com/harness/harness/issues/557,Logout functionality fails silently,"It's returning a 200 OK, but clicking logout loads this empty page (and doesn't clear session): ![image](https://cloud.githubusercontent.com/assets/2149341/4623449/2c1a6f3a-534f-11e4-94ea-02ae012c9c43.png)",other-file | other-file | other-file | source-file | other-file | other-file | other-file,"Logout functionality fails silently It's returning a 200 OK, but clicking logout loads this empty page (and doesn't clear session): ![image](https://cloud.githubusercontent.com/assets/2149341/4623449/2c1a6f3a-534f-11e4-94ea-02ae012c9c43.png) other-file other-file other-file source-file other-file other-file other-file",bug,0.9
2141,harness,https://github.com/harness/harness/issues/2141,Use Bitbucket and Github at the same time,"In my server.env I have the following:  # Service Settings DRONE_SECRET=XXX DRONE_HOST=XXX # Registration settings DRONE_OPEN=false DRONE_ADMIN=XXX # GitHub Settings DRONE_GITHUB=true DRONE_GITHUB_CLIENT=XXX DRONE_GITHUB_SECRET=XXX # Bitbucket Settings DRONE_BITBUCKET=true DRONE_BITBUCKET_CLIENT=XXX DRONE_BITBUCKET_SECRET=XXX  Now if I go to the Dashboard and login it automatically uses Github. If I comment out Github it uses Bitbucket. So my question is propably integrate both services at the same time with one instance does not work, is that correct or did I miss a configuration?",source-file | source-file | source-file | source-file,"Use Bitbucket and Github at the same time In my server.env I have the following:  # Service Settings DRONE_SECRET=XXX DRONE_HOST=XXX # Registration settings DRONE_OPEN=false DRONE_ADMIN=XXX # GitHub Settings DRONE_GITHUB=true DRONE_GITHUB_CLIENT=XXX DRONE_GITHUB_SECRET=XXX # Bitbucket Settings DRONE_BITBUCKET=true DRONE_BITBUCKET_CLIENT=XXX DRONE_BITBUCKET_SECRET=XXX  Now if I go to the Dashboard and login it automatically uses Github. If I comment out Github it uses Bitbucket. So my question is propably integrate both services at the same time with one instance does not work, is that correct or did I miss a configuration? source-file source-file source-file source-file",no-bug,0.9
3420,harness,https://github.com/harness/harness/issues/3420,Sending commits via API,"I am having problems sending commits via api I am using the following Endpoint [POST] /api/v1/repos/{repo}/commits The response i am getting is: json { ""message"": ""sha does not match for path README.md [given: 3d84e33764a95d00f5b1d4a7c8362580e4fad381, expected: 73a4f96320a42cc62d0271e62aad9213ff165ff1]"" }  If it knows the sha already why do we have to send it? Would it be possible to remove the necessity of sending sha in the request?",source-file,"Sending commits via API I am having problems sending commits via api I am using the following Endpoint [POST] /api/v1/repos/{repo}/commits The response i am getting is: json { ""message"": ""sha does not match for path README.md [given: 3d84e33764a95d00f5b1d4a7c8362580e4fad381, expected: 73a4f96320a42cc62d0271e62aad9213ff165ff1]"" }  If it knows the sha already why do we have to send it? Would it be possible to remove the necessity of sending sha in the request? source-file",bug,0.85
879,harness,https://github.com/harness/harness/issues/879,Slack plugin should have a change setting like the email plugin,The email plugin allows you to send notifications on the build status change. This would be useful for the slack plugin as well so the notifications don't get too noisey.,source-file | source-file | source-file,Slack plugin should have a change setting like the email plugin The email plugin allows you to send notifications on the build status change. This would be useful for the slack plugin as well so the notifications don't get too noisey. source-file source-file source-file,no-bug,0.9
2089,harness,https://github.com/harness/harness/issues/2089,Unable to access web UI,"I am unable to access the Drone Web UI after the set up. It would not response and eventually timeout. I have tried to `curl 127.0.0.1:10010` from my server console but, getting connection timeout `docker ps` shows that, both drone server and drone agent started up and there were no error in the both services. the status of drone agent even shows that `pipeline: request next execution`.  CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES afe78e042c14 drone/drone:0.7 ""/drone agent"" 30 minutes ago Up 30 minutes 80/tcp, 443/tcp, 8000/tcp droneci_drone-agent_1 16865ecff0bf drone/drone:0.7 ""/drone server"" 30 minutes ago Up 30 minutes 80/tcp, 443/tcp, 127.0.0.1:10010->8000/tcp droneci_drone-server_1  This is the docker-compose.yml  version: '3' services: drone-server: image: drone/drone:0.7 ports: - 127.0.0.1:10010:8000 volumes: - /var/lib/drone:/var/lib/drone restart: always env_file: - /etc/drone-ci/server.env drone-agent: image: drone/drone:0.7 command: agent depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock restart: always env_file: - /etc/drone-ci/agent.env  Server.env  # Service settings DRONE_SECRET=<SECRET> DRONE_HOST=https://drone.example.com # Registration settings DRONE_OPEN=true DRONE_ADMIN=<BitBucket USERNAME> DRONE_ORGS=<BitBucket TEAM> # VCS Settings DRONE_BITBUCKET=true DRONE_BITBUCKET_CLIENT=<BitBucket-CLIENT> DRONE_BITBUCKET_SECRET=<BitBucket-SECRET>  agent.env  DRONE_SECRET=<SECRET> DRONE_SERVER=ws://drone-server:8000/ws/broker ",other-file,"Unable to access web UI I am unable to access the Drone Web UI after the set up. It would not response and eventually timeout. I have tried to `curl 127.0.0.1:10010` from my server console but, getting connection timeout `docker ps` shows that, both drone server and drone agent started up and there were no error in the both services. the status of drone agent even shows that `pipeline: request next execution`.  CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES afe78e042c14 drone/drone:0.7 ""/drone agent"" 30 minutes ago Up 30 minutes 80/tcp, 443/tcp, 8000/tcp droneci_drone-agent_1 16865ecff0bf drone/drone:0.7 ""/drone server"" 30 minutes ago Up 30 minutes 80/tcp, 443/tcp, 127.0.0.1:10010->8000/tcp droneci_drone-server_1  This is the docker-compose.yml  version: '3' services: drone-server: image: drone/drone:0.7 ports: - 127.0.0.1:10010:8000 volumes: - /var/lib/drone:/var/lib/drone restart: always env_file: - /etc/drone-ci/server.env drone-agent: image: drone/drone:0.7 command: agent depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock restart: always env_file: - /etc/drone-ci/agent.env  Server.env  # Service settings DRONE_SECRET=<SECRET> DRONE_HOST=https://drone.example.com # Registration settings DRONE_OPEN=true DRONE_ADMIN=<BitBucket USERNAME> DRONE_ORGS=<BitBucket TEAM> # VCS Settings DRONE_BITBUCKET=true DRONE_BITBUCKET_CLIENT=<BitBucket-CLIENT> DRONE_BITBUCKET_SECRET=<BitBucket-SECRET>  agent.env  DRONE_SECRET=<SECRET> DRONE_SERVER=ws://drone-server:8000/ws/broker  other-file",no-bug,0.9
1212,harness,https://github.com/harness/harness/issues/1212,Rejected post commit hook but commit is built,"I have Drone running as a docker container, connected to a local GitLab instance. Every time I push a commit, `droned` logs the following messages:  2015/09/23 22:24:35 Rejected post commit hook for [repository]. Token mismatch 2015/09/23 22:24:35 Rejected post commit hook for [repository]. Token mismatch 2015/09/23 22:24:35 Rejected post commit hook for [repository]. Token mismatch starting build 2015/09/23 22:24:57 dial tcp :0: connection refused 2015/09/23 22:24:57 subscription's close channel received message  The build _runs_ just fine, but I'd like to know what's causing these messages. Reading [hook.go](https://github.com/drone/drone/blob/bdd4742171f359098953751e792d28fe2c8947ac/server/handler/hook.go#L66) it looks like if the post-commit hook is rejected the build should never even start.",source-file,"Rejected post commit hook but commit is built I have Drone running as a docker container, connected to a local GitLab instance. Every time I push a commit, `droned` logs the following messages:  2015/09/23 22:24:35 Rejected post commit hook for [repository]. Token mismatch 2015/09/23 22:24:35 Rejected post commit hook for [repository]. Token mismatch 2015/09/23 22:24:35 Rejected post commit hook for [repository]. Token mismatch starting build 2015/09/23 22:24:57 dial tcp :0: connection refused 2015/09/23 22:24:57 subscription's close channel received message  The build _runs_ just fine, but I'd like to know what's causing these messages. Reading [hook.go](https://github.com/drone/drone/blob/bdd4742171f359098953751e792d28fe2c8947ac/server/handler/hook.go#L66) it looks like if the post-commit hook is rejected the build should never even start. source-file",no-bug,0.9
3394,harness,https://github.com/harness/harness/issues/3394,Build arm64 images,Right now all the Gitness images on Docker Hub are only built for amd64. It would be cool if we could get arm64 images as well so that the application can be easily deployed on other devices such as Raspberry Pis.,config-file | other-file | other-file,Build arm64 images Right now all the Gitness images on Docker Hub are only built for amd64. It would be cool if we could get arm64 images as well so that the application can be easily deployed on other devices such as Raspberry Pis. config-file other-file other-file,no-bug,0.9
743,harness,https://github.com/harness/harness/issues/743,Run builds with --rm flag on the container,"I have been looking around and haven't found anything on this, but it doesn't look like Drone is running the builds with the `docker run --rm` flag enabled. This becomes an issue with images that have docker volumes used during the build. They fill up the ../vfs/.. directory. Has this been considered? Are there workarounds that people have used to mitigate? I think this could be coded as the default, or opted in, like privileged. Looking at the code, a similar pattern as the privileged flag could be followed and bubbled up in the UI under repository settings. It seems like running with this flag would prevent cleanup scripts etc. to maintain the host. I don't think it would interfere with caching directories since bind mounts are not impacted.",source-file | test-file | source-file,"Run builds with --rm flag on the container I have been looking around and haven't found anything on this, but it doesn't look like Drone is running the builds with the `docker run --rm` flag enabled. This becomes an issue with images that have docker volumes used during the build. They fill up the ../vfs/.. directory. Has this been considered? Are there workarounds that people have used to mitigate? I think this could be coded as the default, or opted in, like privileged. Looking at the code, a similar pattern as the privileged flag could be followed and bubbled up in the UI under repository settings. It seems like running with this flag would prevent cleanup scripts etc. to maintain the host. I don't think it would interfere with caching directories since bind mounts are not impacted. source-file test-file source-file",no-bug,0.95
790,harness,https://github.com/harness/harness/issues/790,Security issue where user sessions are conflated,"Hi, We're running an evaluation Drone based on `master` (as of 0a6227930). During our testing with multiple (~5) users, we noticed an issue whereby one user, having refreshed the page, was suddenly logged in as another user (that had just registered). This was using the GitHub Enterprise remote plugin. I've had a look through the codebase and can't find what might have caused it, but it feels like a race condition. I'm going to add some debug logging to our local repo so that we have more information should the issue happen again. Has anyone noticed this issue before or have a hunch about what may be causing it? Thanks, Matt",source-file | source-file | test-file | other-file | source-file | other-file | other-file | other-file | source-file | documentation-file | other-file | source-file,"Security issue where user sessions are conflated Hi, We're running an evaluation Drone based on `master` (as of 0a6227930). During our testing with multiple (~5) users, we noticed an issue whereby one user, having refreshed the page, was suddenly logged in as another user (that had just registered). This was using the GitHub Enterprise remote plugin. I've had a look through the codebase and can't find what might have caused it, but it feels like a race condition. I'm going to add some debug logging to our local repo so that we have more information should the issue happen again. Has anyone noticed this issue before or have a hunch about what may be causing it? Thanks, Matt source-file source-file test-file other-file source-file other-file other-file other-file source-file documentation-file other-file source-file",no-bug,0.8
929,harness,https://github.com/harness/harness/issues/929,Encrypted values / variables - and Shared values,"Currently (I believe) there is no way to inject information securely into the build. Use case: I'm using Drone.io (open source) to run tests against chef cookbooks. With an internal berkshelf server, I need to deploy a key into the container so it can communicate with the internal berkshelf server. If I configure this through the web ui there are 2 problems: 1. The value is plain text / can be read by anyone? 2. I have to set this value on every repository - An organisation level, or user level setting would be more desirable to apply to all builds.",source-file | source-file,"Encrypted values / variables - and Shared values Currently (I believe) there is no way to inject information securely into the build. Use case: I'm using Drone.io (open source) to run tests against chef cookbooks. With an internal berkshelf server, I need to deploy a key into the container so it can communicate with the internal berkshelf server. If I configure this through the web ui there are 2 problems: 1. The value is plain text / can be read by anyone? 2. I have to set this value on every repository - An organisation level, or user level setting would be more desirable to apply to all builds. source-file source-file",no-bug,0.9
3544,harness,https://github.com/harness/harness/issues/3544,Multi repo trigger with drone,"My build is stacking the build environment with clones from multiple repository. Other repos are fetched with shell script. I am using gogs as repo container. I would like to trigger the build, if any of these repositories got a change. Is there a way to implement this with drone (2.24) ? I tried the repo trigger documented here: https://docs.drone.io/pipeline/triggers/#by-repository but i was not able to trigger the build with it. Maby it works only for pull requests?",other-file | other-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file,"Multi repo trigger with drone My build is stacking the build environment with clones from multiple repository. Other repos are fetched with shell script. I am using gogs as repo container. I would like to trigger the build, if any of these repositories got a change. Is there a way to implement this with drone (2.24) ? I tried the repo trigger documented here: https://docs.drone.io/pipeline/triggers/#by-repository but i was not able to trigger the build with it. Maby it works only for pull requests? other-file other-file source-file source-file test-file source-file source-file test-file source-file source-file test-file source-file test-file source-file source-file",no-bug,0.9
601,harness,https://github.com/harness/harness/issues/601,Networking restart problem on CentOS with SystemD,"Running under Centos7, systemd via service drone start. I've been experiencing an ongoing issue of droned starting up but failing to acquire its network port (thus, netstat -an | grep LIST shows the port isn't up). This is especially prevalent when trying to restart the daemon. A rule was added to firewalld to allow all traffic to and from port 8282 (where my drone server is configured). I've tried these things: 1. stopping firewalld before starting drone 2. Stopping docker then restarting drone 3. Waiting for all ports using 8282 to complete their TIME_WAIT Edit: last output I pasted here was a red-herring, I had a bad logging option in the toml. The networking restart problem is still an intermittent issue.",documentation-file | other-file | other-file,"Networking restart problem on CentOS with SystemD Running under Centos7, systemd via service drone start. I've been experiencing an ongoing issue of droned starting up but failing to acquire its network port (thus, netstat -an | grep LIST shows the port isn't up). This is especially prevalent when trying to restart the daemon. A rule was added to firewalld to allow all traffic to and from port 8282 (where my drone server is configured). I've tried these things: 1. stopping firewalld before starting drone 2. Stopping docker then restarting drone 3. Waiting for all ports using 8282 to complete their TIME_WAIT Edit: last output I pasted here was a red-herring, I had a bad logging option in the toml. The networking restart problem is still an intermittent issue. documentation-file other-file other-file",no-bug,0.9
2586,harness,https://github.com/harness/harness/issues/2586,Proposal: Add env var for the step that caused a build failure,"Hi all, I was wondering whether an environment variable could be provided to plugins on the step that caused a build to fail. The suggested use case would be to give more detail to notification plugins. I would love to know at a glance in Slack whether the build failed during the testing step, or something mundane to do with linting. At the minute its either a pass or fail message, and then a dig through the logs to see what the issue was. Maybe something like this?  - name: slack image: plugins/slack when: status: [ success, failure ] settings: webhook: https://hooks.slack.com/services/ template: > {{#success build.status}} CI passed! Commit `{{truncate build.commit 8}}` on branch {{build.branch}}. <{{build.link}}|Link to build log> {{else}} CI Failed on step {{build.failedStep}} Commit `{{truncate build.commit 8}}` (by {{build.author}}) on branch {{build.branch}}. <{{build.link}}|Link to build log> {{/success}}  There was a similar suggestion a year and a half ago - https://github.com/drone/drone/issues/1740#issuecomment-329984464 Thanks.",source-file,"Proposal: Add env var for the step that caused a build failure Hi all, I was wondering whether an environment variable could be provided to plugins on the step that caused a build to fail. The suggested use case would be to give more detail to notification plugins. I would love to know at a glance in Slack whether the build failed during the testing step, or something mundane to do with linting. At the minute its either a pass or fail message, and then a dig through the logs to see what the issue was. Maybe something like this?  - name: slack image: plugins/slack when: status: [ success, failure ] settings: webhook: https://hooks.slack.com/services/ template: > {{#success build.status}} CI passed! Commit `{{truncate build.commit 8}}` on branch {{build.branch}}. <{{build.link}}|Link to build log> {{else}} CI Failed on step {{build.failedStep}} Commit `{{truncate build.commit 8}}` (by {{build.author}}) on branch {{build.branch}}. <{{build.link}}|Link to build log> {{/success}}  There was a similar suggestion a year and a half ago - https://github.com/drone/drone/issues/1740#issuecomment-329984464 Thanks. source-file",no-bug,0.9
468,harness,https://github.com/harness/harness/issues/468,Push tag event,"Gitlab and Github supports push tag event, also this can be used to create release https://github.com/drone/drone/issues/439  yml publish: rubygems: tag_only: true token: $RUBYGEMS_TOKEN scripts: - gem build ./supergem.gemspec artifacts: - supergem-$DRONE_TAG.gem github: tag_only: true token: $GITHUB_TOKEN name: 'supergem' artifacts: - supergem-$DRONE_TAG.gem ",other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | documentation-file | other-file | other-file | documentation-file,"Push tag event Gitlab and Github supports push tag event, also this can be used to create release https://github.com/drone/drone/issues/439  yml publish: rubygems: tag_only: true token: $RUBYGEMS_TOKEN scripts: - gem build ./supergem.gemspec artifacts: - supergem-$DRONE_TAG.gem github: tag_only: true token: $GITHUB_TOKEN name: 'supergem' artifacts: - supergem-$DRONE_TAG.gem  other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file source-file documentation-file other-file other-file documentation-file",no-bug,0.8
807,harness,https://github.com/harness/harness/issues/807,Disabling a repo should remove hooks and SSH keys; reactivating it should re-instate hooks and SSH keys,"Currently, disabling a repository (using the CLI) removes the SSH key stored in GitHub against that repo, but it doesn't remove the Drone web hook. Conversely, re-activating a repo after it has been disabled does not add back the SSH key. I would expect that hooks and the SSH key would be removed and added back when repositories are disabled or reactivated.",source-file | source-file,"Disabling a repo should remove hooks and SSH keys; reactivating it should re-instate hooks and SSH keys Currently, disabling a repository (using the CLI) removes the SSH key stored in GitHub against that repo, but it doesn't remove the Drone web hook. Conversely, re-activating a repo after it has been disabled does not add back the SSH key. I would expect that hooks and the SSH key would be removed and added back when repositories are disabled or reactivated. source-file source-file",no-bug,0.9
763,harness,https://github.com/harness/harness/issues/763,time limit exceeded for build,One of my projects is taking a while to build and test. I get a build failure and a note in the drone log saying: `time limit exceeded for build` Is there a way to increase the build time limit? I'm running from the 0.3 deb.,other-file | other-file | other-file | source-file,time limit exceeded for build One of my projects is taking a while to build and test. I get a build failure and a note in the drone log saying: `time limit exceeded for build` Is there a way to increase the build time limit? I'm running from the 0.3 deb. other-file other-file other-file source-file,no-bug,0.95
385,harness,https://github.com/harness/harness/issues/385,"Heroku ""force"" option is a bit strange","Just noticed that you recommit any changes and do a push when ""force"" is set. This is a bit strange and I would only really expect the addition of --force. Perhaps ""recommit_artifacts_before_push"" is a bit better. https://github.com/drone/drone/blob/6ef506c1d17ebfc4c5ee808170a0bf3b94ded7e9/pkg/plugin/deploy/heroku.go#L31",source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file,"Heroku ""force"" option is a bit strange Just noticed that you recommit any changes and do a push when ""force"" is set. This is a bit strange and I would only really expect the addition of --force. Perhaps ""recommit_artifacts_before_push"" is a bit better. https://github.com/drone/drone/blob/6ef506c1d17ebfc4c5ee808170a0bf3b94ded7e9/pkg/plugin/deploy/heroku.go#L31 source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file",no-bug,0.9
609,harness,https://github.com/harness/harness/issues/609,Sessions & Login,"It seems like everytime I open a browser I have to relogin to drone. Do you save sessions/cookies at all? Maybe for the time being if this is a big fix, after login, instead of redirecting to the dash, can you redirect to the page I was on/had requested? Thanks!",config-file | container-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,"Sessions & Login It seems like everytime I open a browser I have to relogin to drone. Do you save sessions/cookies at all? Maybe for the time being if this is a big fix, after login, instead of redirecting to the dash, can you redirect to the page I was on/had requested? Thanks! config-file container-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file other-file",no-bug,0.8
352,harness,https://github.com/harness/harness/issues/352,Ability to use multiple images,"It would be really interesting to be able to run tests on multiple images, for example one for Python 2 and one for Python 3, a possible syntax could be  image: - python2.7 - python3.4 script: - nosetest ",other-file | other-file | other-file | other-file | other-file | other-file,"Ability to use multiple images It would be really interesting to be able to run tests on multiple images, for example one for Python 2 and one for Python 3, a possible syntax could be  image: - python2.7 - python3.4 script: - nosetest  other-file other-file other-file other-file other-file other-file",no-bug,0.9
2133,harness,https://github.com/harness/harness/issues/2133,Ability to use pod network for pipeline network,"In older versions of drone we emulated pod networking which is a shitty hack that lets every container share the same network (with restrictions) so that everything is accessible via localhost (sometimes called pod networking). This was changed in 0.6 to use docker hostnames, in an effort to increase compliance with docker compose, of which the drone yaml is a superset. There are still some scenarios where pod network may be needed, or where localhost may simply be easier to work with. We should therefore give the ability to override the default configuration and enable pod networking. The syntax would conform to docker-compose. In the yaml file you would create a default network with custom drone-specific driver options enabling pod networking:  pipeline:  networks: default: driver: bridge driver_opts: io.drone.network.pod=true ",other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | documentation-file | other-file | documentation-file,"Ability to use pod network for pipeline network In older versions of drone we emulated pod networking which is a shitty hack that lets every container share the same network (with restrictions) so that everything is accessible via localhost (sometimes called pod networking). This was changed in 0.6 to use docker hostnames, in an effort to increase compliance with docker compose, of which the drone yaml is a superset. There are still some scenarios where pod network may be needed, or where localhost may simply be easier to work with. We should therefore give the ability to override the default configuration and enable pod networking. The syntax would conform to docker-compose. In the yaml file you would create a default network with custom drone-specific driver options enabling pod networking:  pipeline:  networks: default: driver: bridge driver_opts: io.drone.network.pod=true  other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file source-file other-file other-file source-file other-file other-file other-file source-file documentation-file other-file documentation-file",no-bug,0.9
2847,harness,https://github.com/harness/harness/issues/2847,How to execute tasks in sequence to avoid conflicts,"![image](https://user-images.githubusercontent.com/3961388/65825374-b6287a80-e2a8-11e9-8b5d-c04fafbdd8ac.png) As the picture shows, when the task #24 is completed, it will be deployed an old version. How to avoid this situation?",source-file | source-file | other-file | other-file,"How to execute tasks in sequence to avoid conflicts ![image](https://user-images.githubusercontent.com/3961388/65825374-b6287a80-e2a8-11e9-8b5d-c04fafbdd8ac.png) As the picture shows, when the task #24 is completed, it will be deployed an old version. How to avoid this situation? source-file source-file other-file other-file",no-bug,0.9
2311,harness,https://github.com/harness/harness/issues/2311,Drone event system,"I have a docker container I need to spin up in parallel after it is built. I can't do this using groups because the container runs indefinitely, and the group gets stuck. Yes, I can use a timeout to force shutdown the container after a certain amount of time, but it is a hacky solution and forces me to override the default command inside the container. There are two possible ways to accomplish this, but they would both be dependant on some sort of primitive event system. 1. Services could be dependant on a certain step in the pipeline. 2. Drone groups could shut down when a certain container in the group is finished.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Drone event system I have a docker container I need to spin up in parallel after it is built. I can't do this using groups because the container runs indefinitely, and the group gets stuck. Yes, I can use a timeout to force shutdown the container after a certain amount of time, but it is a hacky solution and forces me to override the default command inside the container. There are two possible ways to accomplish this, but they would both be dependant on some sort of primitive event system. 1. Services could be dependant on a certain step in the pipeline. 2. Drone groups could shut down when a certain container in the group is finished. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2111,harness,https://github.com/harness/harness/issues/2111,Allow Drone to scheduled builds,I would like to have the opportunity to schedule a build let's say every night to build a canary version a release it. This feature should be something like cron job with timezone and target a branch. I would like also to be able to have severals schedule builds.,source-file | source-file | source-file,Allow Drone to scheduled builds I would like to have the opportunity to schedule a build let's say every night to build a canary version a release it. This feature should be something like cron job with timezone and target a branch. I would like also to be able to have severals schedule builds. source-file source-file source-file,no-bug,0.9
3380,harness,https://github.com/harness/harness/issues/3380,Jupyter Notebook preview?,Congrats on launch! I wonder will gitness support Jupyter Notebook preview in the near future like [Gitea](https://blog.gitea.com/render-jupyter-notebooks/) does?,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Jupyter Notebook preview? Congrats on launch! I wonder will gitness support Jupyter Notebook preview in the near future like [Gitea](https://blog.gitea.com/render-jupyter-notebooks/) does? source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
3595,harness,https://github.com/harness/harness/issues/3595,"Is the front-end visual UI similar to the one shown in the figure, which replaces the.drone.yml code, open source?","<img width=""1514"" alt=""image"" src=""https://github.com/user-attachments/assets/340c08bf-87db-440c-8779-a59917dd076d"">",documentation-file | other-file,"Is the front-end visual UI similar to the one shown in the figure, which replaces the.drone.yml code, open source? <img width=""1514"" alt=""image"" src=""https://github.com/user-attachments/assets/340c08bf-87db-440c-8779-a59917dd076d""> documentation-file other-file",no-bug,0.9
96,harness,https://github.com/harness/harness/issues/96,Detect if running pull request.,"Hi, Is there any configuration so I can detect if I'm running pull requests or commits from master branch ? I can see that deployment commands are not run if there is a pull request, but currently I cannot run capistrano deployment (I can't see any plugin for that). Also, any chance to introduce IRC notifications ?",other-file | other-file | source-file | source-file | source-file | source-file | source-file,"Detect if running pull request. Hi, Is there any configuration so I can detect if I'm running pull requests or commits from master branch ? I can see that deployment commands are not run if there is a pull request, but currently I cannot run capistrano deployment (I can't see any plugin for that). Also, any chance to introduce IRC notifications ? other-file other-file source-file source-file source-file source-file source-file",no-bug,0.9
195,harness,https://github.com/harness/harness/issues/195,Deploy Plugin - OpenShift,Provide a deployment option for OpenShift. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/openshift.go,other-file | other-file | source-file,Deploy Plugin - OpenShift Provide a deployment option for OpenShift. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/openshift.go other-file other-file source-file,no-bug,0.9
874,harness,https://github.com/harness/harness/issues/874,Allow multiple targets in notify plugins,"Currently we have the slack plugin up and running on our internal drone server. Because of the amount of chatter from drone some teams have decided to relegate the build notifications to a separate channel from the main dev channel. An issue becomes that they can miss a failed build from a release branches because they're not paying attention. For normal workflow they'd want something like  yaml notify: slack: webhook_url: 'https://hooks.slack.com/services/' username: 'drone' channel: '#project-builds' on_started: false on_success: false on_failure: true  But on release or master they'd want something like  yaml slack: webhook_url: 'https://hooks.slack.com/services/' username: 'drone' channel: '#project' on_started: false on_success: true on_failure: true when: branch: - master - release*  So maybe having something like  yaml notify: slack: - channel: ""#project-builds"" on_failure: true on_started: false on_success: true username: drone webhook_url: ""https://hooks.slack.com/services/"" - channel: ""#project"" on_failure: true on_started: false on_success: true username: drone webhook_url: ""https://hooks.slack.com/services/"" when: branch: - master - release*  This could probably be applied to other sorts of plugins. For example on a release branch you might want to run run a full suite of tests for a release branch but not on develop as the full suite takes a significant amount of time.",other-file,"Allow multiple targets in notify plugins Currently we have the slack plugin up and running on our internal drone server. Because of the amount of chatter from drone some teams have decided to relegate the build notifications to a separate channel from the main dev channel. An issue becomes that they can miss a failed build from a release branches because they're not paying attention. For normal workflow they'd want something like  yaml notify: slack: webhook_url: 'https://hooks.slack.com/services/' username: 'drone' channel: '#project-builds' on_started: false on_success: false on_failure: true  But on release or master they'd want something like  yaml slack: webhook_url: 'https://hooks.slack.com/services/' username: 'drone' channel: '#project' on_started: false on_success: true on_failure: true when: branch: - master - release*  So maybe having something like  yaml notify: slack: - channel: ""#project-builds"" on_failure: true on_started: false on_success: true username: drone webhook_url: ""https://hooks.slack.com/services/"" - channel: ""#project"" on_failure: true on_started: false on_success: true username: drone webhook_url: ""https://hooks.slack.com/services/"" when: branch: - master - release*  This could probably be applied to other sorts of plugins. For example on a release branch you might want to run run a full suite of tests for a release branch but not on develop as the full suite takes a significant amount of time. other-file",no-bug,0.9
20,harness,https://github.com/harness/harness/issues/20,Colours not available in build output,"See the example below. This works as expected on drone.io and shows green text.  [4mRunning ""vows:all"" (vows) task[24m [32m[39m[32m[39m[32m[39m[32m[39m [32m[39m[32m[39m[32m[39m[32m[39m  [32m[1mOK[22m[39m  [1m8[22m honored[90m (0.129s)[39m ",source-file | other-file | other-file | source-file | other-file | documentation-file | source-file,"Colours not available in build output See the example below. This works as expected on drone.io and shows green text.  [4mRunning ""vows:all"" (vows) task[24m [32m[39m[32m[39m[32m[39m[32m[39m [32m[39m[32m[39m[32m[39m[32m[39m  [32m[1mOK[22m[39m  [1m8[22m honored[90m (0.129s)[39m  source-file other-file other-file source-file other-file documentation-file source-file",no-bug,0.9
983,harness,https://github.com/harness/harness/issues/983,HTTP 400 Error While GitHub Authentication,"I'm getting error while trying to auth with GitHub. Actually this error same with Telmo's [problem](https://github.com/drone/drone/issues/679#issuecomment-68703200). But that issue closed without resolving problem.  [server] port="":8001""  [github] client=""xxx"" secret=""yyy"" orgs=[] open=true  ![image](https://cloud.githubusercontent.com/assets/782514/7216251/4bb27d2a-e601-11e4-971b-7da2973d0e1d.png) (of course using my real domain instead of _domain.com_) I'm following these steps and getting error : 1. Browsing to http://domain.com:8001/ 2. Clicking to GitHub button and redirected to Github.com 3. Allowing application and redirecting back to this url: `http://domain.com:8001/api/auth/github.com?code=62e5cb142fb19ad657b0&state=I6MYHH2YJVHZWXWW44WNWM4DPOZPWCEKHH4BQHCIBQDG64ZX3AOQ%3D%3D%3D%3D` 4. But it's just a blank page. Here Chrome Console logs : ![image](https://cloud.githubusercontent.com/assets/782514/7216277/677c0c46-e602-11e4-8172-64663e915415.png)",other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | documentation-file,"HTTP 400 Error While GitHub Authentication I'm getting error while trying to auth with GitHub. Actually this error same with Telmo's [problem](https://github.com/drone/drone/issues/679#issuecomment-68703200). But that issue closed without resolving problem.  [server] port="":8001""  [github] client=""xxx"" secret=""yyy"" orgs=[] open=true  ![image](https://cloud.githubusercontent.com/assets/782514/7216251/4bb27d2a-e601-11e4-971b-7da2973d0e1d.png) (of course using my real domain instead of _domain.com_) I'm following these steps and getting error : 1. Browsing to http://domain.com:8001/ 2. Clicking to GitHub button and redirected to Github.com 3. Allowing application and redirecting back to this url: `http://domain.com:8001/api/auth/github.com?code=62e5cb142fb19ad657b0&state=I6MYHH2YJVHZWXWW44WNWM4DPOZPWCEKHH4BQHCIBQDG64ZX3AOQ%3D%3D%3D%3D` 4. But it's just a blank page. Here Chrome Console logs : ![image](https://cloud.githubusercontent.com/assets/782514/7216277/677c0c46-e602-11e4-8172-64663e915415.png) other-file source-file documentation-file other-file other-file other-file other-file other-file documentation-file",bug,0.85
3527,harness,https://github.com/harness/harness/issues/3527,Error: Changes blocked by files exceeding the file size limit,"We are getting the following error: Changes blocked by files exceeding the file size limit  remote: Resolving deltas: 100% (492/492), done. remote: remote: Push contains files exceeding the size limit: remote: remote: 31c3dd7f2bf911dc68461ec6cbff002d9cce017d remote: Size: 179064597B remote: remote: 1 file found exceeding the size limit of 100000000B remote: remote: pre-receive: error: Changes blocked by files exceeding the file size limit, try --help  And interesting the file thats exceeding the size limit is within the .git folder `\.git\objects\31\c3dd7f2bf911dc68461ec6cbff002d9cce017d` Could you please advice how we can increase the file size limit or resolve this problem? Thanks in advance, cheers!",other-file | other-file | other-file,"Error: Changes blocked by files exceeding the file size limit We are getting the following error: Changes blocked by files exceeding the file size limit  remote: Resolving deltas: 100% (492/492), done. remote: remote: Push contains files exceeding the size limit: remote: remote: 31c3dd7f2bf911dc68461ec6cbff002d9cce017d remote: Size: 179064597B remote: remote: 1 file found exceeding the size limit of 100000000B remote: remote: pre-receive: error: Changes blocked by files exceeding the file size limit, try --help  And interesting the file thats exceeding the size limit is within the .git folder `\.git\objects\31\c3dd7f2bf911dc68461ec6cbff002d9cce017d` Could you please advice how we can increase the file size limit or resolve this problem? Thanks in advance, cheers! other-file other-file other-file",no-bug,0.95
2568,harness,https://github.com/harness/harness/issues/2568,nested yaml plugin options not parsing to expected json,"Original issue here: https://github.com/drone-plugins/drone-s3-sync/issues/51 Using Drone image: `drone/drone:1.0.0-rc.3` with `plugins/s3-sync`. When configuring acl values like so, it does not work:  settings: acl: ""*"": public-read  Bug when configuring it as a JSON string, it seems to work:  settings: acl: '{ ""*"": ""public-read"" }' ",database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | other-file | source-file | source-file | source-file | source-file,"nested yaml plugin options not parsing to expected json Original issue here: https://github.com/drone-plugins/drone-s3-sync/issues/51 Using Drone image: `drone/drone:1.0.0-rc.3` with `plugins/s3-sync`. When configuring acl values like so, it does not work:  settings: acl: ""*"": public-read  Bug when configuring it as a JSON string, it seems to work:  settings: acl: '{ ""*"": ""public-read"" }'  database-file database-file database-file database-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file other-file source-file source-file source-file source-file",no-bug,0.8
910,harness,https://github.com/harness/harness/issues/910,Build timeout in yaml,The build timeout should be able to be set in the yaml. The settings area isn't available to most users so its not common knowledge that there is a build time out. Additionally if a build fails due to a timeout this should be reflected in the UI so you know whether you should increase the timeout.,container-file,Build timeout in yaml The build timeout should be able to be set in the yaml. The settings area isn't available to most users so its not common knowledge that there is a build time out. Additionally if a build fails due to a timeout this should be reflected in the UI so you know whether you should increase the timeout. container-file,no-bug,0.9
3452,harness,https://github.com/harness/harness/issues/3452,How to DELETE Import in progress Repositories,"How to DELETE Import in progress Repositories <img width=""1233"" alt=""image"" src=""https://github.com/harness/gitness/assets/6457312/fdd6b669-57ac-41f0-b22f-99c6ddad7afa""> Translation status lasted two days",source-file,"How to DELETE Import in progress Repositories How to DELETE Import in progress Repositories <img width=""1233"" alt=""image"" src=""https://github.com/harness/gitness/assets/6457312/fdd6b669-57ac-41f0-b22f-99c6ddad7afa""> Translation status lasted two days source-file",no-bug,0.7
2708,harness,https://github.com/harness/harness/issues/2708,Copy Fork values when re-started build,"There is a bug in the code that re-starts a build where the `Fork` value is not copied to the new build object. As a result, the build is rejected when Forks are disabled. diff hook := &core.Hook{ Trigger: user.Login, Event: prev.Event, Action: prev.Action, Link: prev.Link, Timestamp: prev.Timestamp, Title: prev.Title, Message: prev.Message, Before: prev.Before, After: prev.After, Ref: prev.Ref, + Fork: prev.Fork, Source: prev.Source, Target: prev.Target, Author: prev.Author, AuthorName: prev.AuthorName, AuthorEmail: prev.AuthorEmail, AuthorAvatar: prev.AuthorAvatar, Sender: prev.Sender, Params: map[string]string{}, }  [1] https://github.com/drone/drone/blob/master/handler/api/repos/builds/retry.go#L66",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | other-file | other-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | source-file | documentation-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | other-file | source-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | documentation-file | source-file | other-file,"Copy Fork values when re-started build There is a bug in the code that re-starts a build where the `Fork` value is not copied to the new build object. As a result, the build is rejected when Forks are disabled. diff hook := &core.Hook{ Trigger: user.Login, Event: prev.Event, Action: prev.Action, Link: prev.Link, Timestamp: prev.Timestamp, Title: prev.Title, Message: prev.Message, Before: prev.Before, After: prev.After, Ref: prev.Ref, + Fork: prev.Fork, Source: prev.Source, Target: prev.Target, Author: prev.Author, AuthorName: prev.AuthorName, AuthorEmail: prev.AuthorEmail, AuthorAvatar: prev.AuthorAvatar, Sender: prev.Sender, Params: map[string]string{}, }  [1] https://github.com/drone/drone/blob/master/handler/api/repos/builds/retry.go#L66 other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file other-file other-file source-file source-file source-file other-file source-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file other-file source-file other-file source-file other-file other-file source-file source-file documentation-file source-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file test-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file source-file other-file source-file other-file other-file test-file other-file other-file source-file other-file other-file other-file documentation-file other-file other-file other-file documentation-file source-file other-file",no-bug,0.9
709,harness,https://github.com/harness/harness/issues/709,droned and 'app' box,"Is it possible to tell `droned` where to find the Angular assets manually? For example, I'm building a custom Dockerfile. I copy `droned` inside but when I run it I get error `panic: could not locate box ""app""`. To get around that I can embed the assets to the binary as per the `rice` [doco](https://github.com/GeertJohan/go.rice/blob/master/README.md):  sh $ cd server $ go build -o droned $ rice append --exec droned  Using that binary inside my container works. I'd prefer not to have to append the assets in that way. It would be better if I could simply tell droned where to find these assets at startup e.g. via command line flag.",other-file | source-file | other-file | other-file,"droned and 'app' box Is it possible to tell `droned` where to find the Angular assets manually? For example, I'm building a custom Dockerfile. I copy `droned` inside but when I run it I get error `panic: could not locate box ""app""`. To get around that I can embed the assets to the binary as per the `rice` [doco](https://github.com/GeertJohan/go.rice/blob/master/README.md):  sh $ cd server $ go build -o droned $ rice append --exec droned  Using that binary inside my container works. I'd prefer not to have to append the assets in that way. It would be better if I could simply tell droned where to find these assets at startup e.g. via command line flag. other-file source-file other-file other-file",no-bug,0.9
3474,harness,https://github.com/harness/harness/issues/3474,[BUG] Unable to import repository from GitHub when branch name is not 'main',"I encountered an issue where importing a repository from GitHub fails when the branch name is not 'main'. The import process consistently displays Import in progress Additionally, when I commit locally with a branch name other than 'main', the committed code appears empty after submission. <img width=""897"" alt=""2024-02-11 22 22 36"" src=""https://github.com/harness/gitness/assets/46970005/81ddaa75-e757-4791-bca5-2127169dfe60"">",source-file,"[BUG] Unable to import repository from GitHub when branch name is not 'main' I encountered an issue where importing a repository from GitHub fails when the branch name is not 'main'. The import process consistently displays Import in progress Additionally, when I commit locally with a branch name other than 'main', the committed code appears empty after submission. <img width=""897"" alt=""2024-02-11 22 22 36"" src=""https://github.com/harness/gitness/assets/46970005/81ddaa75-e757-4791-bca5-2127169dfe60""> source-file",no-bug,0.9
1538,harness,https://github.com/harness/harness/issues/1538,Delegated secrets management,"First off we're willing to do the work proposed, I wanted to share the approach and general idea first. ## Current state of affairs Drone allows for encryption of secrets but it works locally and so the secrets yaml file needs to be shared amongst ""blessed"" team members who gate changes to .drone.yml. ## Expected behavior Decouple and delegate managing secrets yaml content from the ability to encrypt drone.yml. Every maintainer should be able to encrypt the .drone.yml file. But the ability to add or change secrets should still be gated through a set of ""blessed"" individuals. ## Proposed approach To achieve this we can introduce a secure secrets store like hashicorps vault, dockers notary,  The backend might actually be pluggable, for a first pass I think hashicorps vault is most appropriate. The drone-cli will submit the .drone.yml file to the drone API server and gets the encryption string back. This then gets stored in .drone.sec. This can be a flag that allows people the choice but by default we stick to the current behavior of needing a local file. The drone-api server needs to get a new endpoint to accommodate this new workflow. There will also be a config necessary so that the drone api server knows how to connect to the secure store backend. The secrets are now provided through vault, so the people who can write or even read that are highly privileged accounts but this is decoupled from the build system.",source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | source-file | test-file | source-file,"Delegated secrets management First off we're willing to do the work proposed, I wanted to share the approach and general idea first. ## Current state of affairs Drone allows for encryption of secrets but it works locally and so the secrets yaml file needs to be shared amongst ""blessed"" team members who gate changes to .drone.yml. ## Expected behavior Decouple and delegate managing secrets yaml content from the ability to encrypt drone.yml. Every maintainer should be able to encrypt the .drone.yml file. But the ability to add or change secrets should still be gated through a set of ""blessed"" individuals. ## Proposed approach To achieve this we can introduce a secure secrets store like hashicorps vault, dockers notary,  The backend might actually be pluggable, for a first pass I think hashicorps vault is most appropriate. The drone-cli will submit the .drone.yml file to the drone API server and gets the encryption string back. This then gets stored in .drone.sec. This can be a flag that allows people the choice but by default we stick to the current behavior of needing a local file. The drone-api server needs to get a new endpoint to accommodate this new workflow. There will also be a config necessary so that the drone api server knows how to connect to the secure store backend. The secrets are now provided through vault, so the people who can write or even read that are highly privileged accounts but this is decoupled from the build system. source-file source-file source-file source-file source-file database-file database-file database-file source-file test-file source-file",no-bug,0.9
1075,harness,https://github.com/harness/harness/issues/1075,Blank page after logging into gogs,"Hello, I've just installed drone and configured it to use a locally-installed gogs service via the following environment variables: `DRONE_GOGS_URL=https://mygogsdomain.com` `DRONE_GOGS_SECRET=[oath key]` `DRONE_GOGS_OPEN=true` When I visit the drone URL, I see a gogs button which prompts me for login credentials when clicked. Upon entering my **gogs login** I'm redirected to a blank page at `https://mygogsdomain.com/api/auth/gogs`. I'd appreciate any advice, as I'm at a complete loss. Thanks!",other-file,"Blank page after logging into gogs Hello, I've just installed drone and configured it to use a locally-installed gogs service via the following environment variables: `DRONE_GOGS_URL=https://mygogsdomain.com` `DRONE_GOGS_SECRET=[oath key]` `DRONE_GOGS_OPEN=true` When I visit the drone URL, I see a gogs button which prompts me for login credentials when clicked. Upon entering my **gogs login** I'm redirected to a blank page at `https://mygogsdomain.com/api/auth/gogs`. I'd appreciate any advice, as I'm at a complete loss. Thanks! other-file",no-bug,0.8
2672,harness,https://github.com/harness/harness/issues/2672,Disable Pull requests and forks by default,I think enabling pipelines for pull requests and forks by default is not good: - You need to disable them in the UI every time you add a repo OR you must disable them in pipeline configuration if you don't want to see failed builds because pull requests and forks cannot access secrets by default (Which is good) - Since any user can create a pull request or a fork it might be a possible security risk if some party starts creating these rapidly to increase load in the Drone server (DDOS),source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Disable Pull requests and forks by default I think enabling pipelines for pull requests and forks by default is not good: - You need to disable them in the UI every time you add a repo OR you must disable them in pipeline configuration if you don't want to see failed builds because pull requests and forks cannot access secrets by default (Which is good) - Since any user can create a pull request or a fork it might be a possible security risk if some party starts creating these rapidly to increase load in the Drone server (DDOS) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
555,harness,https://github.com/harness/harness/issues/555,Builds immediately fail,I have an issue where all builds fail with the following error: `failed to completely delete build image e746d9a14594869f7aed56398628ec42c126c33a2464408719de6721bf65cc7a. invalid character 'C' looking for beginning of value`,other-file,Builds immediately fail I have an issue where all builds fail with the following error: `failed to completely delete build image e746d9a14594869f7aed56398628ec42c126c33a2464408719de6721bf65cc7a. invalid character 'C' looking for beginning of value` other-file,no-bug,0.9
2519,harness,https://github.com/harness/harness/issues/2519,Drone is not recognizing gitea release creation,"Hi, if i create a release from the gitea ui (creates also a tag in background), drone does not recognize it and is not running the pipeline. If i instead push a tag from command line to remote repo, drone will run twice. One run for the push and one run for the tag That duplicates the runtime. Any chance to fix this?",source-file,"Drone is not recognizing gitea release creation Hi, if i create a release from the gitea ui (creates also a tag in background), drone does not recognize it and is not running the pipeline. If i instead push a tag from command line to remote repo, drone will run twice. One run for the push and one run for the tag That duplicates the runtime. Any chance to fix this? source-file",no-bug,0.8
2547,harness,https://github.com/harness/harness/issues/2547,"Getting error in gogs ""There was a problem enabling your repository.""","Getting error in gogs ""There was a problem enabling your repository."" My Docker Config  docker run \ --volume=/var/run/docker.sock:/var/run/docker.sock \ --volume=/root/drone:/data \ --env=DRONE_GIT_ALWAYS_AUTH=false \ --env=DRONE_GOGS_SERVER=https://gitote.in \ --env=DRONE_RUNNER_CAPACITY=2 \ --env=DRONE_SERVER_HOST=ci.gitote.in \ --env=DRONE_SERVER_PROTO=https \ --env=DRONE_TLS_AUTOCERT=true \ --publish=80:80 \ --publish=443:443 \ --restart=always \ --detach=true \ --name=drone \ drone/drone:1.0.0-rc.1  ![screenshot](https://user-images.githubusercontent.com/45569460/49735785-3f38db80-fcae-11e8-8279-92d827b4720d.png)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Getting error in gogs ""There was a problem enabling your repository."" Getting error in gogs ""There was a problem enabling your repository."" My Docker Config  docker run \ --volume=/var/run/docker.sock:/var/run/docker.sock \ --volume=/root/drone:/data \ --env=DRONE_GIT_ALWAYS_AUTH=false \ --env=DRONE_GOGS_SERVER=https://gitote.in \ --env=DRONE_RUNNER_CAPACITY=2 \ --env=DRONE_SERVER_HOST=ci.gitote.in \ --env=DRONE_SERVER_PROTO=https \ --env=DRONE_TLS_AUTOCERT=true \ --publish=80:80 \ --publish=443:443 \ --restart=always \ --detach=true \ --name=drone \ drone/drone:1.0.0-rc.1  ![screenshot](https://user-images.githubusercontent.com/45569460/49735785-3f38db80-fcae-11e8-8279-92d827b4720d.png) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.3
1172,harness,https://github.com/harness/harness/issues/1172,listen on port 80 and redirect to https,optionally drone should be able to listen on port 80 and redirect to https:// maybe that can be better achieved with a reverse-proxy setup with nginx in production for example? example nginx vhost:  server { listen 80; server_name drone.example.com; return 301 https://$server_name$request_uri; } ,documentation-file | other-file,listen on port 80 and redirect to https optionally drone should be able to listen on port 80 and redirect to https:// maybe that can be better achieved with a reverse-proxy setup with nginx in production for example? example nginx vhost:  server { listen 80; server_name drone.example.com; return 301 https://$server_name$request_uri; }  documentation-file other-file,no-bug,0.9
5,harness,https://github.com/harness/harness/issues/5,Dockerfile for drone itself,"Would be insanely useful. I'm working on one, would you merge?",source-file | source-file | source-file | source-file,"Dockerfile for drone itself Would be insanely useful. I'm working on one, would you merge? source-file source-file source-file source-file",no-bug,0.95
2769,harness,https://github.com/harness/harness/issues/2769,trigger: cannot find yaml,"I deployed drone in kubernetes(use helm chart). I configed gitlab and sync project is ok. But when I use drone in project and trigger to do ci, an error appear. drone server log(no more log in debug mode): json {""commit"":""db51b7a2d88aabc8db74d7379d230a0368a24a25"",""error"":"""",""event"":""push"",""level"":""warning"",""msg"":""trigger: cannot find yaml"",""ref"":""refs/heads/master"",""repo"":""xianyang.li/drone-demo"",""time"":""2019-08-01T03:47:31Z""}  project file:  .drone.yml .gitattributes README.md main.go  .drone.yml: yaml  kind: pipeline name: default steps: - name: test image: golang:1.12.6-stretch commands: - go version ",source-file,"trigger: cannot find yaml I deployed drone in kubernetes(use helm chart). I configed gitlab and sync project is ok. But when I use drone in project and trigger to do ci, an error appear. drone server log(no more log in debug mode): json {""commit"":""db51b7a2d88aabc8db74d7379d230a0368a24a25"",""error"":"""",""event"":""push"",""level"":""warning"",""msg"":""trigger: cannot find yaml"",""ref"":""refs/heads/master"",""repo"":""xianyang.li/drone-demo"",""time"":""2019-08-01T03:47:31Z""}  project file:  .drone.yml .gitattributes README.md main.go  .drone.yml: yaml  kind: pipeline name: default steps: - name: test image: golang:1.12.6-stretch commands: - go version  source-file",no-bug,0.9
3209,harness,https://github.com/harness/harness/issues/3209,DRONE_RUNNER_LABELS for kube-runner,Based upon the docs this doesn't seem to be possible. It would be nice to route to specific kube runners the same as a [docker runner.](https://docs.drone.io/pipeline/docker/syntax/routing/) Great stuff btw! Cheers,other-file | other-file,DRONE_RUNNER_LABELS for kube-runner Based upon the docs this doesn't seem to be possible. It would be nice to route to specific kube runners the same as a [docker runner.](https://docs.drone.io/pipeline/docker/syntax/routing/) Great stuff btw! Cheers other-file other-file,no-bug,0.8
2041,harness,https://github.com/harness/harness/issues/2041,Account show token is not working in Firefox,"Show token is not working in Firefox, but Chromium is fine. Console error: TypeError: p.findDOMNode().showModal is not a function[Learn More] app.js:1984:719 Drone: 0.6 Firefox: 53 Ubuntu 17.04",documentation-file | other-file | other-file,"Account show token is not working in Firefox Show token is not working in Firefox, but Chromium is fine. Console error: TypeError: p.findDOMNode().showModal is not a function[Learn More] app.js:1984:719 Drone: 0.6 Firefox: 53 Ubuntu 17.04 documentation-file other-file other-file",no-bug,0.9
2592,harness,https://github.com/harness/harness/issues/2592,Docker Plugin Client Certificate Authentication (TLS)?,The docs only mention username/password auth on private docker registries. Is there a possibility to authenticate with tls?,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file,Docker Plugin Client Certificate Authentication (TLS)? The docs only mention username/password auth on private docker registries. Is there a possibility to authenticate with tls? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file,no-bug,0.9
485,harness,https://github.com/harness/harness/issues/485,follow button on 0.3?,"I'm sure it's one of the minor things on the todo list for merging exp into master, but is there going to be a ""follow"" button for the 0.3 release? I know issue #382 asks for a slight tweak to the 0.2 behavior but I'm not sure what the status is for 0.3. I'd be happy to contribute it if it hasn't been done yet. I think it would basically be (in app.js): - insert follow button with JS variable `follow` (probably as a sibling to `#output`) - whenever websocket gets data scroll to bottom if follow is true (probably in the stdout.subscribe callback) - some css/less (position: fixed; right: 240px; bottom: 10px)",source-file,"follow button on 0.3? I'm sure it's one of the minor things on the todo list for merging exp into master, but is there going to be a ""follow"" button for the 0.3 release? I know issue #382 asks for a slight tweak to the 0.2 behavior but I'm not sure what the status is for 0.3. I'd be happy to contribute it if it hasn't been done yet. I think it would basically be (in app.js): - insert follow button with JS variable `follow` (probably as a sibling to `#output`) - whenever websocket gets data scroll to bottom if follow is true (probably in the stdout.subscribe callback) - some css/less (position: fixed; right: 240px; bottom: 10px) source-file",no-bug,0.9
2944,harness,https://github.com/harness/harness/issues/2944,Issues with grep syntax,"Hello, I am having some issues with drone parsing a `grep` command in my pipeline. Essentially, I am using grep to pull a version number of one of my container images in order to promote the image from dev -> stage and eventually stage->prod. I am doing this through `gcloud`. My command to grab the image using `gcloud` syntax is: ` gcloud container images list-tags <my-image-repository> --filter=""tags:latest"" --format=""table[noheading](tags)"" | grep -o '\bv\w*.*'` This command parses the correct information when I log directly into the docker container that I am using to execute this step, however, when I run it with Drone it appears to yank the `\b` from my grep command completely. I tested this with a pipeline by just running `grep -o '\bv\w*.*'` against a `test.txt` file that included a string `v1.0.30841303` and the pipeline fails out with the last step showing the following: `+ grep -o 'v\w*.*' test.txt` Is there something I am doing wrong or is there something in Drone that would cause it to incorrectly parse the `\b` in my grep syntax? Thank you!",source-file | other-file | test-file | test-file | other-file,"Issues with grep syntax Hello, I am having some issues with drone parsing a `grep` command in my pipeline. Essentially, I am using grep to pull a version number of one of my container images in order to promote the image from dev -> stage and eventually stage->prod. I am doing this through `gcloud`. My command to grab the image using `gcloud` syntax is: ` gcloud container images list-tags <my-image-repository> --filter=""tags:latest"" --format=""table[noheading](tags)"" | grep -o '\bv\w*.*'` This command parses the correct information when I log directly into the docker container that I am using to execute this step, however, when I run it with Drone it appears to yank the `\b` from my grep command completely. I tested this with a pipeline by just running `grep -o '\bv\w*.*'` against a `test.txt` file that included a string `v1.0.30841303` and the pipeline fails out with the last step showing the following: `+ grep -o 'v\w*.*' test.txt` Is there something I am doing wrong or is there something in Drone that would cause it to incorrectly parse the `\b` in my grep syntax? Thank you! source-file other-file test-file test-file other-file",no-bug,0.95
2154,harness,https://github.com/harness/harness/issues/2154,Drone server failed to unmarshal webhook payload from Gogs (labels are present),"Steps to reproduce: 1. Create PR with labels. 2. See drone-server logs. These errors are found there in my case:  drone-server_1 | time=""2017-08-07T06:00:10Z"" level=error msg=""failure to parse hook. json: cannot unmarshal object into Go struct field .labels of type string"" drone-server_1 | time=""2017-08-07T06:00:10Z"" level=error msg=""Error #01: json: cannot unmarshal object into Go struct field .labels of type string\n"" ip=89.188.125.8 latency=16.784072ms method=POST path=""/hook"" status=400 time=""2017-08-07T06:00:10Z"" user-agent=GogsServer  3. See ""labels"" section of payload (can be found in webhook edit page in Gogs). In my case: json ""labels"": [ { ""id"": 268, ""name"": ""component/library"", ""color"": ""7614de"", ""url"": """" } ],  It seems like drone webhook processing function works incorrectly, somewhere around [this](https://github.com/drone/drone/blob/c8313f8cd8b398becaa46563121a4c5526b1081a/server/hook.go#L324) line. Gitter discussion is [here](https://gitter.im/drone/drone?at=59887a8845fc670746015e41).",source-file | source-file | database-file | database-file | database-file | database-file,"Drone server failed to unmarshal webhook payload from Gogs (labels are present) Steps to reproduce: 1. Create PR with labels. 2. See drone-server logs. These errors are found there in my case:  drone-server_1 | time=""2017-08-07T06:00:10Z"" level=error msg=""failure to parse hook. json: cannot unmarshal object into Go struct field .labels of type string"" drone-server_1 | time=""2017-08-07T06:00:10Z"" level=error msg=""Error #01: json: cannot unmarshal object into Go struct field .labels of type string\n"" ip=89.188.125.8 latency=16.784072ms method=POST path=""/hook"" status=400 time=""2017-08-07T06:00:10Z"" user-agent=GogsServer  3. See ""labels"" section of payload (can be found in webhook edit page in Gogs). In my case: json ""labels"": [ { ""id"": 268, ""name"": ""component/library"", ""color"": ""7614de"", ""url"": """" } ],  It seems like drone webhook processing function works incorrectly, somewhere around [this](https://github.com/drone/drone/blob/c8313f8cd8b398becaa46563121a4c5526b1081a/server/hook.go#L324) line. Gitter discussion is [here](https://gitter.im/drone/drone?at=59887a8845fc670746015e41). source-file source-file database-file database-file database-file database-file",bug,0.95
54,harness,https://github.com/harness/harness/issues/54,Webhooks not working from GitHub,"When I push to GitHub, nothing happens. If I go to debug the webhook on GitHub, it says there was a timeout. However, if I capture the request by adding a hook to another server and submit it directly to my Drone instance, it works just fine. Any idea what this could be? My first thought is firewall issues, but I haven't had a problem accessing my server from other locations before.",config-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | other-file,"Webhooks not working from GitHub When I push to GitHub, nothing happens. If I go to debug the webhook on GitHub, it says there was a timeout. However, if I capture the request by adding a hook to another server and submit it directly to my Drone instance, it works just fine. Any idea what this could be? My first thought is firewall issues, but I haven't had a problem accessing my server from other locations before. config-file source-file other-file other-file other-file other-file other-file source-file source-file source-file source-file source-file source-file documentation-file other-file other-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file source-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file source-file source-file other-file",no-bug,0.9
2304,harness,https://github.com/harness/harness/issues/2304,drone not build stage when i push code to gitlab,"<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> i use drone 0.8 version and gitlab 8.x version i want to ci use drone + gitlab but my project's `.drone.yml` file is  pipeline: build: image: 10.10.30.38:5000/alpine-java-maven commands: - mvn -DskipTests=true clean package -U branches: [ master ]  and i push to gitlab, but not found drone execute build stage ![image](https://user-images.githubusercontent.com/1763935/34970302-99830262-faae-11e7-8a9d-177cb4fa84d4.png) what steps i miss? i need gitlab ci add hooks? ![image](https://user-images.githubusercontent.com/1763935/34970331-c6d823aa-faae-11e7-9059-4b066b480983.png) what is the url and Secret Token ?",source-file | source-file | config-file | config-file | source-file | source-file | source-file,"drone not build stage when i push code to gitlab <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> i use drone 0.8 version and gitlab 8.x version i want to ci use drone + gitlab but my project's `.drone.yml` file is  pipeline: build: image: 10.10.30.38:5000/alpine-java-maven commands: - mvn -DskipTests=true clean package -U branches: [ master ]  and i push to gitlab, but not found drone execute build stage ![image](https://user-images.githubusercontent.com/1763935/34970302-99830262-faae-11e7-8a9d-177cb4fa84d4.png) what steps i miss? i need gitlab ci add hooks? ![image](https://user-images.githubusercontent.com/1763935/34970331-c6d823aa-faae-11e7-9059-4b066b480983.png) what is the url and Secret Token ? source-file source-file config-file config-file source-file source-file source-file",no-bug,0.9
340,harness,https://github.com/harness/harness/issues/340,Drone cache is stored in /tmp/drone by default,"This should respect the system $TMPDIR rather than being hard coded to /tmp/drone. We are currently using the undocumented $DRONE_TMP variable to override this, but it feels like it should default to $TMPDIR. ioutil.TempDir should return the proper temporary directory.",source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | documentation-file,"Drone cache is stored in /tmp/drone by default This should respect the system $TMPDIR rather than being hard coded to /tmp/drone. We are currently using the undocumented $DRONE_TMP variable to override this, but it feels like it should default to $TMPDIR. ioutil.TempDir should return the proper temporary directory. source-file other-file other-file source-file other-file other-file other-file other-file other-file documentation-file",no-bug,0.9
2758,harness,https://github.com/harness/harness/issues/2758,[bitbucket] Tag builds not executing,# Expected behaviour Tag builds triggered on pushing tags to remote # Actual behaviour Need to push the tag twice for it to be picked up. 1. create tag and push it to remote 2. delete tag on local and remote 3. create and push it again -- build triggers # Version latest,source-file | source-file | source-file | source-file | source-file | source-file,[bitbucket] Tag builds not executing # Expected behaviour Tag builds triggered on pushing tags to remote # Actual behaviour Need to push the tag twice for it to be picked up. 1. create tag and push it to remote 2. delete tag on local and remote 3. create and push it again -- build triggers # Version latest source-file source-file source-file source-file source-file source-file,no-bug,0.8
2734,harness,https://github.com/harness/harness/issues/2734,Feature Request - Implement Catlight.io protocol,"Heya, I recently discovered a CI monitor called Catlight that is really cool and allows communication amongst the team. It implements a new protocol that aims to replace the cc.xml from cruise control. It would be quite nice if this protocol would be implemented in Drone. More information is https://blog.catlight.io/post/158337666873/open-protocol-for-integration-with-continuous",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Feature Request - Implement Catlight.io protocol Heya, I recently discovered a CI monitor called Catlight that is really cool and allows communication amongst the team. It implements a new protocol that aims to replace the cc.xml from cruise control. It would be quite nice if this protocol would be implemented in Drone. More information is https://blog.catlight.io/post/158337666873/open-protocol-for-integration-with-continuous source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
267,harness,https://github.com/harness/harness/issues/267,"Clarify ""Unable to setup the Repository"" when adding a repository","The real error message is available in the response from the AJAX request to ""/new/github.com"" This helps understand what is actually wrong. So far two things have been discovered: 1. The github user needs to be admin of the repository, not only have write (push/pull) access 2. Each repository can only be added once, so if another drone user has added a repository, it can't be added again by another drone user",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | other-file | other-file | documentation-file | source-file | documentation-file | other-file | other-file | other-file,"Clarify ""Unable to setup the Repository"" when adding a repository The real error message is available in the response from the AJAX request to ""/new/github.com"" This helps understand what is actually wrong. So far two things have been discovered: 1. The github user needs to be admin of the repository, not only have write (push/pull) access 2. Each repository can only be added once, so if another drone user has added a repository, it can't be added again by another drone user source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file other-file other-file documentation-file source-file documentation-file other-file other-file other-file",no-bug,0.8
2811,harness,https://github.com/harness/harness/issues/2811,Current build stage target variable,"It would be useful to have access to the current deploy promotion target within a step. This is to avoid potential duplicate step commands for differing targets. E.g. instead of:  name: deployTest image:  commands: - ./deploy.sh test when: event: [ promote ] target: [test] name: deployProd image:  commands: - ./deploy.sh prod when: event: [ promote ] target: [prod]  Have:  name: deploy image:  commands: - ./deploy.sh $DRONE_BUILD_STAGE when: event: [ promote ]  Or, if the stage is an empty string when not promoted:  name: deploy image:  commands: - ./deploy.sh $DRONE_BUILD_STAGE ",source-file,"Current build stage target variable It would be useful to have access to the current deploy promotion target within a step. This is to avoid potential duplicate step commands for differing targets. E.g. instead of:  name: deployTest image:  commands: - ./deploy.sh test when: event: [ promote ] target: [test] name: deployProd image:  commands: - ./deploy.sh prod when: event: [ promote ] target: [prod]  Have:  name: deploy image:  commands: - ./deploy.sh $DRONE_BUILD_STAGE when: event: [ promote ]  Or, if the stage is an empty string when not promoted:  name: deploy image:  commands: - ./deploy.sh $DRONE_BUILD_STAGE  source-file",no-bug,0.9
3466,harness,https://github.com/harness/harness/issues/3466,Cannot create repository when using an external drive,"## Context I am using a machine with little space only to run programs via Docker, I save the data on an external disk using volumes. Trying to do this with Gitness I get an error when creating a repository. Using the internal storage, there is no problem, but linking the volume to a directory on the external disk is a problem. **This should not be a permissions issue**, as some files and directories have been generated by Gitness. ## Current behavior When I try to create a repository, I get the following error: UI: ![image](https://github.com/harness/gitness/assets/25767185/212d9c07-d47b-4647-80b9-145dc55ae2f8) Container logs:  gitness | {""level"":""warn"",""time"":""2024-01-21T21:18:02.925943609Z"",""message"":""operation resulted in user facing error. Internal details: error creating repository on git: failed to create repo on: failed to setup symlink for hook 'pre-receive' ('/data/repos/k0/ln/is9pe61py0t4119hm2setelm3knohdtie2t5rw.git/hooks/pre-receive' -> '/app/gitness'): %!s(MISSING)""}  ## Expected behavior The repository is created normally. ## Additional info **Gitness version:** v2.22.0 **Docker version:** 20.10.12",source-file | source-file | source-file | source-file,"Cannot create repository when using an external drive ## Context I am using a machine with little space only to run programs via Docker, I save the data on an external disk using volumes. Trying to do this with Gitness I get an error when creating a repository. Using the internal storage, there is no problem, but linking the volume to a directory on the external disk is a problem. **This should not be a permissions issue**, as some files and directories have been generated by Gitness. ## Current behavior When I try to create a repository, I get the following error: UI: ![image](https://github.com/harness/gitness/assets/25767185/212d9c07-d47b-4647-80b9-145dc55ae2f8) Container logs:  gitness | {""level"":""warn"",""time"":""2024-01-21T21:18:02.925943609Z"",""message"":""operation resulted in user facing error. Internal details: error creating repository on git: failed to create repo on: failed to setup symlink for hook 'pre-receive' ('/data/repos/k0/ln/is9pe61py0t4119hm2setelm3knohdtie2t5rw.git/hooks/pre-receive' -> '/app/gitness'): %!s(MISSING)""}  ## Expected behavior The repository is created normally. ## Additional info **Gitness version:** v2.22.0 **Docker version:** 20.10.12 source-file source-file source-file source-file",no-bug,0.9
733,harness,https://github.com/harness/harness/issues/733,"stdout'ing causing high memory, cpu and blocks browser","While downloading a ZIP file I accidentally didn't save it to a file but had `curl` print it to stdout. The result is now a big `drone.sqlite` file and a browser that breaks down every time I visit the commit build status. - Does drone automatically prune old commit logs? - Is there a way to force something like that - Can we implement a countermeasure for occasions like these (this is also a security threat as people could just cat `/dev/urandom` into stdout, filling the Drone database with junk)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file,"stdout'ing causing high memory, cpu and blocks browser While downloading a ZIP file I accidentally didn't save it to a file but had `curl` print it to stdout. The result is now a big `drone.sqlite` file and a browser that breaks down every time I visit the commit build status. - Does drone automatically prune old commit logs? - Is there a way to force something like that - Can we implement a countermeasure for occasions like these (this is also a security threat as people could just cat `/dev/urandom` into stdout, filling the Drone database with junk) source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file",no-bug,0.9
2604,harness,https://github.com/harness/harness/issues/2604,},,source-file,}  source-file,no-bug,0.7
2700,harness,https://github.com/harness/harness/issues/2700,"[Feature] Autoscaler ""fleet upgrade"" on configuration changes","We have been evaluating the drone 1.x autoscaler on AWS. One feature we would like to see is the ability to safely replace all agent instances when relevant configuration changes. This ensures that all running agents have the latest configuration. I imagine this would be an opt-in feature, and not the default behavior. Looking at the autoscaler variables, it seems every `DRONE_AMAZON_*` variable change would trigger the ""fleet upgrade"".",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[Feature] Autoscaler ""fleet upgrade"" on configuration changes We have been evaluating the drone 1.x autoscaler on AWS. One feature we would like to see is the ability to safely replace all agent instances when relevant configuration changes. This ensures that all running agents have the latest configuration. I imagine this would be an opt-in feature, and not the default behavior. Looking at the autoscaler variables, it seems every `DRONE_AMAZON_*` variable change would trigger the ""fleet upgrade"". source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
639,harness,https://github.com/harness/harness/issues/639,Params cannot contain the equals sign,"Because of https://github.com/drone/drone/blob/master/shared/build/script/script.go#L106 , seems you'll only get the portion of a param up until the = sign. Maybe something as simple as `strings.SplitN(env, ""="", 2)` ?",source-file | test-file | source-file | test-file | test-file | test-file | source-file | test-file | source-file | container-file,"Params cannot contain the equals sign Because of https://github.com/drone/drone/blob/master/shared/build/script/script.go#L106 , seems you'll only get the portion of a param up until the = sign. Maybe something as simple as `strings.SplitN(env, ""="", 2)` ? source-file test-file source-file test-file test-file test-file source-file test-file source-file container-file",bug,0.85
3421,harness,https://github.com/harness/harness/issues/3421,Cloudflare Pages deploy issue,"When adding the cloudflare-pages plugin to a build pipeline, an error occurs upon execution. Take the basic pipeline: version: 1 kind: pipeline spec: stages: - name: build type: ci spec: steps: - type: plugin spec: name: cloudflare-pages inputs: branch: deploy cloudflare_account_id: ${{ secrets.get(""CLOUDFLARE_ACCOUNT_ID"") }} cloudflare_api_token: ${{ secrets.get(""CLOUDFLARE_API_TOKEN"") }} path: public/ project_name: pname  I get the following error in the WebUI when trying to run the pipeline:  Error response from daemon: manifest for mgzamharness/cf-pages-drone-plugin:latest not found: manifest unknown: manifest unknown  Checking out that image on DockerHub, there is no latest tag: https://hub.docker.com/r/mgzamharness/cf-pages-drone-plugin/tags",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Cloudflare Pages deploy issue When adding the cloudflare-pages plugin to a build pipeline, an error occurs upon execution. Take the basic pipeline: version: 1 kind: pipeline spec: stages: - name: build type: ci spec: steps: - type: plugin spec: name: cloudflare-pages inputs: branch: deploy cloudflare_account_id: ${{ secrets.get(""CLOUDFLARE_ACCOUNT_ID"") }} cloudflare_api_token: ${{ secrets.get(""CLOUDFLARE_API_TOKEN"") }} path: public/ project_name: pname  I get the following error in the WebUI when trying to run the pipeline:  Error response from daemon: manifest for mgzamharness/cf-pages-drone-plugin:latest not found: manifest unknown: manifest unknown  Checking out that image on DockerHub, there is no latest tag: https://hub.docker.com/r/mgzamharness/cf-pages-drone-plugin/tags source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
552,harness,https://github.com/harness/harness/issues/552,README.md correction," # custom database settings export DRONE_SERVER_PORT="""" export DRONE_SERVER_SSL_KEY="""" export DRONE_SERVER_SSL_CERT=""""  should be:  # custom server settings  ",documentation-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | source-file | source-file | source-file,"README.md correction  # custom database settings export DRONE_SERVER_PORT="""" export DRONE_SERVER_SSL_KEY="""" export DRONE_SERVER_SSL_CERT=""""  should be:  # custom server settings   documentation-file other-file other-file other-file documentation-file other-file other-file other-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file database-file database-file source-file source-file source-file",no-bug,0.95
2813,harness,https://github.com/harness/harness/issues/2813,skipping automated docker,"the config is :  - name: Docker( image: plugins/docker settings: username: from_secret: docker-hub-user password: from_secret: docker-hub-pswd repo: docker.abc.cn/mimihui registry: docker.abc.cn auto_tag: true mirror: http://f1361db2.m.daocloud.io  use branch master is ok ,when I use other branch,only plugins/docker can't work  time=""2019-09-03T11:48:51Z"" level=info msg=""skipping automated docker build for refs/heads/develop"" ",other-file | other-file | other-file | other-file,"skipping automated docker the config is :  - name: Docker( image: plugins/docker settings: username: from_secret: docker-hub-user password: from_secret: docker-hub-pswd repo: docker.abc.cn/mimihui registry: docker.abc.cn auto_tag: true mirror: http://f1361db2.m.daocloud.io  use branch master is ok ,when I use other branch,only plugins/docker can't work  time=""2019-09-03T11:48:51Z"" level=info msg=""skipping automated docker build for refs/heads/develop""  other-file other-file other-file other-file",no-bug,0.9
2985,harness,https://github.com/harness/harness/issues/2985,Multiple Application Links on Bitbucket Server override one another,"Hello, We've got multiple drone deployments pointing to the same Bitbucket Server. The issue is that these application links seem to override one another. Creating / Updating one seems to alter/squash the other. Is there a workaround here? Can we change the name of the Application Link and the name of the Service Provider maybe?",source-file,"Multiple Application Links on Bitbucket Server override one another Hello, We've got multiple drone deployments pointing to the same Bitbucket Server. The issue is that these application links seem to override one another. Creating / Updating one seems to alter/squash the other. Is there a workaround here? Can we change the name of the Application Link and the name of the Service Provider maybe? source-file",no-bug,0.7
3303,harness,https://github.com/harness/harness/issues/3303,Add Version Info to API (and later CLI),I currently automate the updating of all my applications. Nearly every software I know has some way of outputting version information via either CLI or API. Drone currently has no way of getting the version information via API or CLI. This feature should be added as it helps many people. Devs like me could automate updating Drone based on a check if the installed version is the current version and users who have issues could output version information in their Bug reports. This should be added to the API and later to the CLI which uses the API.,other-file,Add Version Info to API (and later CLI) I currently automate the updating of all my applications. Nearly every software I know has some way of outputting version information via either CLI or API. Drone currently has no way of getting the version information via API or CLI. This feature should be added as it helps many people. Devs like me could automate updating Drone based on a check if the installed version is the current version and users who have issues could output version information in their Bug reports. This should be added to the API and later to the CLI which uses the API. other-file,no-bug,0.9
2970,harness,https://github.com/harness/harness/issues/2970,Tesekkurler,<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io -->,other-file | other-file | other-file | other-file | source-file | other-file | other-file | documentation-file | source-file,Tesekkurler <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> other-file other-file other-file other-file source-file other-file other-file documentation-file source-file,no-bug,0.9
742,harness,https://github.com/harness/harness/issues/742,Set the maximum number of parallel build,"Hi, I running drone on a 2 core, 2GB RAM server on DigitalOcean. My app needs about 1.2/1.5GB for each run. Becouse I have 2 processors it starts 2 parallel builds. Is any setting so I can allow only 1 parallel build due to memory constrains ?",source-file,"Set the maximum number of parallel build Hi, I running drone on a 2 core, 2GB RAM server on DigitalOcean. My app needs about 1.2/1.5GB for each run. Becouse I have 2 processors it starts 2 parallel builds. Is any setting so I can allow only 1 parallel build due to memory constrains ? source-file",no-bug,0.9
109,harness,https://github.com/harness/harness/issues/109,Set the default SMTP port to 25,"If a port from SMTP is not provided, 0 is used, but 25 would be a safer default.",source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file,"Set the default SMTP port to 25 If a port from SMTP is not provided, 0 is used, but 25 would be a safer default. source-file source-file test-file source-file test-file source-file source-file source-file source-file",no-bug,0.9
66,harness,https://github.com/harness/harness/issues/66,Missing status badge in README.md,"well, for the demo purposes would make sense (if you build on some public instance like drone.io).",documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Missing status badge in README.md well, for the demo purposes would make sense (if you build on some public instance like drone.io). documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
667,harness,https://github.com/harness/harness/issues/667,Author/gravatar inconsistancy,"Drone will report the opening of a pull request by putting the pull request author's github alias in the `author` field. When drone reports the MERGING of a pull request, or generally just any direct commit to master, it puts the committer's email address in the `author` field, rather than their github alias. When the email address is used for the `author` field, the gravatar hash will indeed point to the gravatar for that email address. When the github alias is used for the `author` field, a different gravatar hash will appear, one that invariably displays the system default gravatar. Presumably this is a gravatar generated from that alias, rather than an email address. What this means is that a single user opening pull requests and merging others will appear in Drone results as two people, sometimes with their email address and correct gravatar, and other times with their github alias and a system default gravatar. This is problematic when attempting to track activity in a user-centric fashion. I'm not sure if this is something that can be changed on the drone side, or if it's a fundamental github issue, but hopefully there's a resolution here that will allow consistent email-address usage for all drone builds, so people can be tracked and gravatars can be relied upon.",other-file | other-file,"Author/gravatar inconsistancy Drone will report the opening of a pull request by putting the pull request author's github alias in the `author` field. When drone reports the MERGING of a pull request, or generally just any direct commit to master, it puts the committer's email address in the `author` field, rather than their github alias. When the email address is used for the `author` field, the gravatar hash will indeed point to the gravatar for that email address. When the github alias is used for the `author` field, a different gravatar hash will appear, one that invariably displays the system default gravatar. Presumably this is a gravatar generated from that alias, rather than an email address. What this means is that a single user opening pull requests and merging others will appear in Drone results as two people, sometimes with their email address and correct gravatar, and other times with their github alias and a system default gravatar. This is problematic when attempting to track activity in a user-centric fashion. I'm not sure if this is something that can be changed on the drone side, or if it's a fundamental github issue, but hopefully there's a resolution here that will allow consistent email-address usage for all drone builds, so people can be tracked and gravatars can be relied upon. other-file other-file",no-bug,0.85
2006,harness,https://github.com/harness/harness/issues/2006,Support for CLI plugins,Support for command line plugins similar to Heroku https://github.com/heroku/cli https://devcenter.heroku.com/articles/developing-cli-plugins,source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file,Support for CLI plugins Support for command line plugins similar to Heroku https://github.com/heroku/cli https://devcenter.heroku.com/articles/developing-cli-plugins source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file test-file source-file test-file source-file test-file source-file test-file source-file source-file source-file source-file,no-bug,0.9
2838,harness,https://github.com/harness/harness/issues/2838,allow organization admins to create org secrets,"currently only administrators can manage organization secrets. This should be extended to organization administrators. Use the organization membership endpoint for this: https://developer.github.com/v3/orgs/members/#get-your-organization-membership not all providers support organization or organization membership endpoints. In this case, the system should still allow system admins to manage all organization secrets.",source-file | source-file | source-file | source-file | source-file,"allow organization admins to create org secrets currently only administrators can manage organization secrets. This should be extended to organization administrators. Use the organization membership endpoint for this: https://developer.github.com/v3/orgs/members/#get-your-organization-membership not all providers support organization or organization membership endpoints. In this case, the system should still allow system admins to manage all organization secrets. source-file source-file source-file source-file source-file",no-bug,0.8
714,harness,https://github.com/harness/harness/issues/714,Unable to build python project with LDAP,"I'm wondering what would be the best way to handle this case. I've been using drone (0.3 via apt package) for a few weeks. When a build succeeds, it pushes the code to a server we have on-site running dokku. If you're not familiar with Dokku, it's basically like Heroku. I have a `.env` file:  export BUILDPACK_URL=https://github.com/ddollar/heroku-buildpack-multi.git  and a `.buildpacks` file:  https://github.com/heroku/heroku-buildpack-nodejs.git https://github.com/darkpixel/heroku-buildpack-bower.git https://github.com/heroku/heroku-buildpack-python.git https://github.com/damgad/heroku-buildpack-python-ldap.git  We recently started to depend on python-ldap. If I `git push` directly to the box, everything builds and deploys correctly. When I push to the main repo and drone gets a hold of it, it blows up.  gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fPIC -DHAVE_SASL -DHAVE_TLS -DHAVE_LIBLDAP_R -DHAVE_LIBLDAP_R -DLDAPMODULE_VERSION=2.4.18 -IModules -I/opt/openldap/include -I/usr/include/sasl -I/usr/include -I/usr/include/python2.7 -c Modules/LDAPObject.c -o build/temp.linux-x86_64-2.7/Modules/LDAPObject.o Modules/LDAPObject.c:18:18: fatal error: sasl.h: No such file or directory compilation terminated. error: command 'gcc' failed with exit status 1  Is there a way to make the drone build process more closely mimic dokku/heroku?",container-file,"Unable to build python project with LDAP I'm wondering what would be the best way to handle this case. I've been using drone (0.3 via apt package) for a few weeks. When a build succeeds, it pushes the code to a server we have on-site running dokku. If you're not familiar with Dokku, it's basically like Heroku. I have a `.env` file:  export BUILDPACK_URL=https://github.com/ddollar/heroku-buildpack-multi.git  and a `.buildpacks` file:  https://github.com/heroku/heroku-buildpack-nodejs.git https://github.com/darkpixel/heroku-buildpack-bower.git https://github.com/heroku/heroku-buildpack-python.git https://github.com/damgad/heroku-buildpack-python-ldap.git  We recently started to depend on python-ldap. If I `git push` directly to the box, everything builds and deploys correctly. When I push to the main repo and drone gets a hold of it, it blows up.  gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fPIC -DHAVE_SASL -DHAVE_TLS -DHAVE_LIBLDAP_R -DHAVE_LIBLDAP_R -DLDAPMODULE_VERSION=2.4.18 -IModules -I/opt/openldap/include -I/usr/include/sasl -I/usr/include -I/usr/include/python2.7 -c Modules/LDAPObject.c -o build/temp.linux-x86_64-2.7/Modules/LDAPObject.o Modules/LDAPObject.c:18:18: fatal error: sasl.h: No such file or directory compilation terminated. error: command 'gcc' failed with exit status 1  Is there a way to make the drone build process more closely mimic dokku/heroku? container-file",no-bug,0.95
1012,harness,https://github.com/harness/harness/issues/1012,github URL format,"Not sure why, but one of my added repos is trying to use git://github.com/meanpath/json2csv where it should be using git@github.com:meanpath/json2csv. All my other repos use it without issue. I tried running ""drone delete github.com/meanpath/json2csv"" so i could delete and re-add, but it tells me ""Unauthorized"". Any ideas?",other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file,"github URL format Not sure why, but one of my added repos is trying to use git://github.com/meanpath/json2csv where it should be using git@github.com:meanpath/json2csv. All my other repos use it without issue. I tried running ""drone delete github.com/meanpath/json2csv"" so i could delete and re-add, but it tells me ""Unauthorized"". Any ideas? other-file source-file other-file other-file other-file source-file other-file other-file",no-bug,0.9
2623,harness,https://github.com/harness/harness/issues/2623,Cannot run the drone outside the docker,"system: Archlinux I clone drone master branch, and build `drone-server` with : shell cd cmd/drone-server go build -tags netgo -ldflags '-extldflags ""-static"" -s' -o drone-server  And create a shell script `server.sh` to run `drone-server` with local `gitea`(running at `localhost:3000`): shell #! /bin/bash # # runner # export DRONE_RUNNER_LOCAL=true export DRONE_RUNNER_OS=linux export DRONE_RUNNER_ARCH=arm64 export DRONE_RUNNER_CAPACITY=2 # # server # export DRONE_SERVER_HOST=localhost:8000 export DRONE_SERVER_PORT=:8000 export DRONE_SERVER_PROTO=http export DRONE_TLS_AUTOCERT=false # # database # export DRONE_DATABASE_DRIVER=postgres export DRONE_DATABASE_DATASOURCE=postgres://postgres:password@127.0.0.1:5432/drone?sslmode=disable # # datadog # export DRONE_DATADOG_ENABLED=true export DRONE_DATADOG_ENDPOINT=https://stats.drone.ci/api/v1/series # # other # export GODEBUG=netdns=go export XDG_CACHE_HOME=data # # logging # export DRONE_LOGS_DEBUG=true export DRONE_LOGS_TRACE=true export DRONE_LOGS_COLOR=true export DRONE_LOGS_PRETTY=true export DRONE_LOGS_TEXT=true # # Gitea # # NOTICE: The ip or domain should be accessible in docker container export DRONE_GITEA_SERVER=http://127.0.0.1:3000 export DRONE_GIT_ALWAYS_AUTH=false ./drone-server  Then, run `server.sh` with: shell sudo ./server.sh  drone can sync and active repo, gitea webhook also work, but building jobs will stuck at `default: Pending`: ![ASBTiV.png](https://s2.ax1x.com/2019/03/09/ASBTiV.png) I noticed that the code for starting build jobs maybe is `trigger/trigger.go`, but I can't find how it to drive the docker work.",other-file | other-file | other-file,"Cannot run the drone outside the docker system: Archlinux I clone drone master branch, and build `drone-server` with : shell cd cmd/drone-server go build -tags netgo -ldflags '-extldflags ""-static"" -s' -o drone-server  And create a shell script `server.sh` to run `drone-server` with local `gitea`(running at `localhost:3000`): shell #! /bin/bash # # runner # export DRONE_RUNNER_LOCAL=true export DRONE_RUNNER_OS=linux export DRONE_RUNNER_ARCH=arm64 export DRONE_RUNNER_CAPACITY=2 # # server # export DRONE_SERVER_HOST=localhost:8000 export DRONE_SERVER_PORT=:8000 export DRONE_SERVER_PROTO=http export DRONE_TLS_AUTOCERT=false # # database # export DRONE_DATABASE_DRIVER=postgres export DRONE_DATABASE_DATASOURCE=postgres://postgres:password@127.0.0.1:5432/drone?sslmode=disable # # datadog # export DRONE_DATADOG_ENABLED=true export DRONE_DATADOG_ENDPOINT=https://stats.drone.ci/api/v1/series # # other # export GODEBUG=netdns=go export XDG_CACHE_HOME=data # # logging # export DRONE_LOGS_DEBUG=true export DRONE_LOGS_TRACE=true export DRONE_LOGS_COLOR=true export DRONE_LOGS_PRETTY=true export DRONE_LOGS_TEXT=true # # Gitea # # NOTICE: The ip or domain should be accessible in docker container export DRONE_GITEA_SERVER=http://127.0.0.1:3000 export DRONE_GIT_ALWAYS_AUTH=false ./drone-server  Then, run `server.sh` with: shell sudo ./server.sh  drone can sync and active repo, gitea webhook also work, but building jobs will stuck at `default: Pending`: ![ASBTiV.png](https://s2.ax1x.com/2019/03/09/ASBTiV.png) I noticed that the code for starting build jobs maybe is `trigger/trigger.go`, but I can't find how it to drive the docker work. other-file other-file other-file",no-bug,0.9
893,harness,https://github.com/harness/harness/issues/893,Plugin for Mercurial,"To my dismay I realised whilst Bitbucket _is_ supported, it's only for Git repos, so I can't use Drone without converting entire repos. :( There even seems to be [a TODO for HG/SVN support](https://github.com/drone/drone/blob/8d493b393c8a03ca1eda5d4574875770cfd3a1dd/shared/build/repo/repo.go#L102), and a [note about Git-only support for Bitbucket](https://github.com/drone/drone/blob/38379992bf1c82aae0e7eed94f640bc630bc9eef/plugin/remote/bitbucket/bitbucket.go#L145). Any idea when this will be available (or even: clues about hacking this in (for a non-Go dev))?",other-file,"Plugin for Mercurial To my dismay I realised whilst Bitbucket _is_ supported, it's only for Git repos, so I can't use Drone without converting entire repos. :( There even seems to be [a TODO for HG/SVN support](https://github.com/drone/drone/blob/8d493b393c8a03ca1eda5d4574875770cfd3a1dd/shared/build/repo/repo.go#L102), and a [note about Git-only support for Bitbucket](https://github.com/drone/drone/blob/38379992bf1c82aae0e7eed94f640bc630bc9eef/plugin/remote/bitbucket/bitbucket.go#L145). Any idea when this will be available (or even: clues about hacking this in (for a non-Go dev))? other-file",no-bug,0.9
502,harness,https://github.com/harness/harness/issues/502,docker too many levels of symlink,"Hi Guys, I have been experiencing this issue with my drone and docker where i am unable build a built due too many levels of symlink. have any of you seen this error? if you have how did you fix it?",other-file | other-file | other-file | other-file | other-file | other-file,"docker too many levels of symlink Hi Guys, I have been experiencing this issue with my drone and docker where i am unable build a built due too many levels of symlink. have any of you seen this error? if you have how did you fix it? other-file other-file other-file other-file other-file other-file",no-bug,0.9
2458,harness,https://github.com/harness/harness/issues/2458,drone always suddenly in pending state,"<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> As shown in the question,at first it was normal,after a few times,it alway suddenly in pending state,just like that ![image](https://user-images.githubusercontent.com/23305845/43196007-38290540-9039-11e8-9ea3-eff9baba010a.png) Deploy with Docker Stack yml version: ""3"" services: drone-server: image: drone/drone ports: - 8999:8000 - 9000 volumes: - drone:/var/lib/drone deploy: replicas: 1 restart_policy: condition: on-failure environment: - DRONE_OPEN=true - DRONE_HOST=http://localhost:8999 - DRONE_GITLAB=true - DRONE_GITLAB_CLIENT=24fbdfd9978f6XXXXXX49f55b51316d3d7684d0b00b195884c08781 - DRONE_GITLAB_SECRET=59XXXXXe28cd8f0c858fb3afecf52342 - DRONE_GITLAB_URL=http://localhost - DRONE_SECRET=mytest2018 drone-agent: image: drone/agent deploy: replicas: 1 restart_policy: condition: on-failure depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=drone-server:9000 - DRONE_SECRET=mytest2018 volumes: drone: driver: local  Who has met such a problem, and how do you solve it? Best wishes to you!",database-file | database-file | database-file | database-file,"drone always suddenly in pending state <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> As shown in the question,at first it was normal,after a few times,it alway suddenly in pending state,just like that ![image](https://user-images.githubusercontent.com/23305845/43196007-38290540-9039-11e8-9ea3-eff9baba010a.png) Deploy with Docker Stack yml version: ""3"" services: drone-server: image: drone/drone ports: - 8999:8000 - 9000 volumes: - drone:/var/lib/drone deploy: replicas: 1 restart_policy: condition: on-failure environment: - DRONE_OPEN=true - DRONE_HOST=http://localhost:8999 - DRONE_GITLAB=true - DRONE_GITLAB_CLIENT=24fbdfd9978f6XXXXXX49f55b51316d3d7684d0b00b195884c08781 - DRONE_GITLAB_SECRET=59XXXXXe28cd8f0c858fb3afecf52342 - DRONE_GITLAB_URL=http://localhost - DRONE_SECRET=mytest2018 drone-agent: image: drone/agent deploy: replicas: 1 restart_policy: condition: on-failure depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=drone-server:9000 - DRONE_SECRET=mytest2018 volumes: drone: driver: local  Who has met such a problem, and how do you solve it? Best wishes to you! database-file database-file database-file database-file",no-bug,0.9
390,harness,https://github.com/harness/harness/issues/390,"Docker build fails with ""pkg/template: signal: killed""","Running `docker build github.com/drone/drone` on a fresh Digital Ocean Ubuntu (14.04) Docker droplet fails with the following error:  Step 11 : RUN make > Running in cd98568980a1 cd cmd/droned/assets && find js -name ""*.js"" ! -name '.*' ! -name ""main.js"" -exec cat {} \; > js/main.js go get github.com/GeertJohan/go.rice/rice go build github.com/GeertJohan/go.rice/rice cd cmd/droned && rice embed cd pkg/template && rice embed go build -o bin/drone -ldflags ""-X main.version 0.2dev-4f0585b"" github.com/drone/drone/cmd/drone go build github.com/drone/drone/pkg/template: signal: killed make:  [build] Error 1 2014/07/25 18:00:59 The command [/bin/sh -c make] returned a non-zero code: 2 ",source-file | source-file | database-file | database-file | database-file | database-file | source-file,"Docker build fails with ""pkg/template: signal: killed"" Running `docker build github.com/drone/drone` on a fresh Digital Ocean Ubuntu (14.04) Docker droplet fails with the following error:  Step 11 : RUN make > Running in cd98568980a1 cd cmd/droned/assets && find js -name ""*.js"" ! -name '.*' ! -name ""main.js"" -exec cat {} \; > js/main.js go get github.com/GeertJohan/go.rice/rice go build github.com/GeertJohan/go.rice/rice cd cmd/droned && rice embed cd pkg/template && rice embed go build -o bin/drone -ldflags ""-X main.version 0.2dev-4f0585b"" github.com/drone/drone/cmd/drone go build github.com/drone/drone/pkg/template: signal: killed make:  [build] Error 1 2014/07/25 18:00:59 The command [/bin/sh -c make] returned a non-zero code: 2  source-file source-file database-file database-file database-file database-file source-file",no-bug,0.9
2522,harness,https://github.com/harness/harness/issues/2522,"1.0.0-rc.1: GitLab, cannot find repository error=""sql: no rows in result set""","Hi! I'm trying to upgrade to the 1.0.0-rc.1. While I was able to (re-)configure GitLab and everything seems to work, whenever a trigger arrives at Drone it prints the following to stdout:  drone-server_1 | 2018-11-10T20:01:04Z |ERROR| cannot find repository error=""sql: no rows in result set"" ip=11.0.0.110 method=POST name=[project_name] namespace=[namespace_name] path=/hook request_id=bfjji04etrt0l997jv60  I suspect the ""project_name"" part of this, since it should be the repository name it searches for. That differs in GitLab.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"1.0.0-rc.1: GitLab, cannot find repository error=""sql: no rows in result set"" Hi! I'm trying to upgrade to the 1.0.0-rc.1. While I was able to (re-)configure GitLab and everything seems to work, whenever a trigger arrives at Drone it prints the following to stdout:  drone-server_1 | 2018-11-10T20:01:04Z |ERROR| cannot find repository error=""sql: no rows in result set"" ip=11.0.0.110 method=POST name=[project_name] namespace=[namespace_name] path=/hook request_id=bfjji04etrt0l997jv60  I suspect the ""project_name"" part of this, since it should be the repository name it searches for. That differs in GitLab. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.7
141,harness,https://github.com/harness/harness/issues/141,Custom badges text,This is more like feature request - is it handy to pass text to `badge` handle and generate images like ![](http://img.shields.io/badge/deploy-success-brightgreen.png) or ![](http://img.shields.io/badge/tests-failing-red.png) instead of standart ![](https://raw.github.com/drone/drone/master/cmd/droned/assets/img/build_failing.png)?,other-file | other-file,Custom badges text This is more like feature request - is it handy to pass text to `badge` handle and generate images like ![](http://img.shields.io/badge/deploy-success-brightgreen.png) or ![](http://img.shields.io/badge/tests-failing-red.png) instead of standart ![](https://raw.github.com/drone/drone/master/cmd/droned/assets/img/build_failing.png)? other-file other-file,no-bug,0.95
936,harness,https://github.com/harness/harness/issues/936,[DOCS] Using nginx config from the docs causes drone to redirect to wrong page,"Hey, I've set up a bitbucket configuration for drone. I currently forward all data from the encrypted port 443 on my subdomain to an unencrypted port used by drone internally. Unfortunately, this means that I'm getting forwarded to ""/api/auth/bitbucket.org"" on port 80 of my subdomain instead of to port 443. I'm using nginx for auth and other checks so it has to go through nginx unfortunately. I hope that makes sense As mentioned by @bradrydzewski below, the docs should include `X-Forwarded-Proto`. The docs where I got my config from are located here: http://readme.drone.io/setup/misc/nginx/",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | database-file | database-file | database-file | database-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[DOCS] Using nginx config from the docs causes drone to redirect to wrong page Hey, I've set up a bitbucket configuration for drone. I currently forward all data from the encrypted port 443 on my subdomain to an unencrypted port used by drone internally. Unfortunately, this means that I'm getting forwarded to ""/api/auth/bitbucket.org"" on port 80 of my subdomain instead of to port 443. I'm using nginx for auth and other checks so it has to go through nginx unfortunately. I hope that makes sense As mentioned by @bradrydzewski below, the docs should include `X-Forwarded-Proto`. The docs where I got my config from are located here: http://readme.drone.io/setup/misc/nginx/ source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file database-file database-file database-file database-file test-file test-file test-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
851,harness,https://github.com/harness/harness/issues/851,oauth with existing gitlab fails since drone 0.3.0-alpha,"After the drone login page the url is redirected to to gitlab web to renew ""authentication"". While the gitlab says 404.  Started GET ""/oauth/authorize?client_id=&redirect_uri=https%3A%2F%2Fdrone.vums.blueit%2Fapi%2Fauth%2Fgitlab.com&response_type=code&scope=api&state=ESXHFAQCELJYH6LKTTT3MO2VVYXNWXMDENGK7RCFW44Y6ZVM3GRQ%3D%3D%3D%3D"" for 127.0.0.1 at 2015-01-26 19:59:20 +0100 Processing by ProjectsController#show as HTML Parameters: {""client_id""=>"""", ""redirect_uri""=>""https://drone.vums.blueit/api/auth/gitlab.com"", ""response_type""=>""code"", ""scope""=>""api"", ""state""=>""ESXHFAQCELJYH6LKTTT3MO2VVYXNWXMDENGK7RCFW44Y6ZVM3GRQ"", ""id""=>""oauth/authorize""} Filter chain halted as :project rendered or redirected Completed 404 Not Found in 4ms (Views: 0.4ms | ActiveRecord: 0.3ms)  no logs in drone.log (what is a way to enable more verbose or debug logging?) obviously recent drone update in gitlab oauth do not fit older gitlab (6.8.2 in my case).",other-file | other-file,"oauth with existing gitlab fails since drone 0.3.0-alpha After the drone login page the url is redirected to to gitlab web to renew ""authentication"". While the gitlab says 404.  Started GET ""/oauth/authorize?client_id=&redirect_uri=https%3A%2F%2Fdrone.vums.blueit%2Fapi%2Fauth%2Fgitlab.com&response_type=code&scope=api&state=ESXHFAQCELJYH6LKTTT3MO2VVYXNWXMDENGK7RCFW44Y6ZVM3GRQ%3D%3D%3D%3D"" for 127.0.0.1 at 2015-01-26 19:59:20 +0100 Processing by ProjectsController#show as HTML Parameters: {""client_id""=>"""", ""redirect_uri""=>""https://drone.vums.blueit/api/auth/gitlab.com"", ""response_type""=>""code"", ""scope""=>""api"", ""state""=>""ESXHFAQCELJYH6LKTTT3MO2VVYXNWXMDENGK7RCFW44Y6ZVM3GRQ"", ""id""=>""oauth/authorize""} Filter chain halted as :project rendered or redirected Completed 404 Not Found in 4ms (Views: 0.4ms | ActiveRecord: 0.3ms)  no logs in drone.log (what is a way to enable more verbose or debug logging?) obviously recent drone update in gitlab oauth do not fit older gitlab (6.8.2 in my case). other-file other-file",no-bug,0.8
2777,harness,https://github.com/harness/harness/issues/2777,re-enable github deployment in 1.0,"We removed github deployments from 1.0 because we thought nobody was using them. We were very wrong. I re-enabled github deployment events, and mapped deployment events to the new promotion events. However, we are still not correctly setting the deployment status. We need to explicitly invoke the github deployment status endpoint. For the initial implementation (and because this is GitHub specific) we can probably just modify the go-scm library to include a `Deploy` field indicating this is a deployment. In the future we may want to have separate methods to find, create, update and list deployment status, but for now we can probably just share since we only need to create. diff type ( StatusInput struct { State State Label string Desc string Target string + Deploy string } )  The only gotcha is that we need to extract the deployment ID and pass to the status. I _think_ we can get the deployment ID from the build link, but this needs to be verified. If this is possible, we can use a regular expression to extract:  var reDeploy = regexp.MustCompile("".+/deployments/(\\d+)"")  Reference code from 0.8 https://github.com/drone/drone/blob/v0.8.8/remote/github/github.go#L408:L423",source-file | source-file | source-file,"re-enable github deployment in 1.0 We removed github deployments from 1.0 because we thought nobody was using them. We were very wrong. I re-enabled github deployment events, and mapped deployment events to the new promotion events. However, we are still not correctly setting the deployment status. We need to explicitly invoke the github deployment status endpoint. For the initial implementation (and because this is GitHub specific) we can probably just modify the go-scm library to include a `Deploy` field indicating this is a deployment. In the future we may want to have separate methods to find, create, update and list deployment status, but for now we can probably just share since we only need to create. diff type ( StatusInput struct { State State Label string Desc string Target string + Deploy string } )  The only gotcha is that we need to extract the deployment ID and pass to the status. I _think_ we can get the deployment ID from the build link, but this needs to be verified. If this is possible, we can use a regular expression to extract:  var reDeploy = regexp.MustCompile("".+/deployments/(\\d+)"")  Reference code from 0.8 https://github.com/drone/drone/blob/v0.8.8/remote/github/github.go#L408:L423 source-file source-file source-file",no-bug,0.9
411,harness,https://github.com/harness/harness/issues/411,persistent connection closed?,The build stdout show `persistent connection closed` error ? screenshot: ![screenshot from 2014-08-05 17 23 35](https://cloud.githubusercontent.com/assets/612381/3809313/385ea576-1c82-11e4-9822-9be035fb35ee.png) I use `docker 0.9.1` and `bradrydzewski/ruby 2.0.0` image  root@iZ23ann35stZ:~# drone version 0.2-43a0a46 ,other-file | source-file,persistent connection closed? The build stdout show `persistent connection closed` error ? screenshot: ![screenshot from 2014-08-05 17 23 35](https://cloud.githubusercontent.com/assets/612381/3809313/385ea576-1c82-11e4-9822-9be035fb35ee.png) I use `docker 0.9.1` and `bradrydzewski/ruby 2.0.0` image  root@iZ23ann35stZ:~# drone version 0.2-43a0a46  other-file source-file,no-bug,0.9
2797,harness,https://github.com/harness/harness/issues/2797,Stage name is limited to 50 characters,"As soon as I put 51 characters in a name, then drone does not start from my GitHub PR. IMO this is because a lot of the database fields are limited to `VARCHAR(50)` e.g. https://github.com/drone/drone/blob/master/store/shared/migrate/mysql/files/005_create_table_stages.sql Is there a reason for that limit? Can we make it longer? (100, 128, 256?) e.g. I am generating the drone matrix from a starlark script. I end up with names like:  kind: pipeline type: docker name: webUIActivitySharingInternal-firefox-master-mariadb10.2-php7.0  I am generating a unique name that describes all the variable pieces of the environment that are used in the stage: - test suite `webUIActivitySharingInternal` - browser `firefox` - SW version `master` - database `mariadb10.2` - PHP version `php7.0` That makes a long name! But the generated names need to be unique so that they can be mentioned in `depends_on`",source-file,"Stage name is limited to 50 characters As soon as I put 51 characters in a name, then drone does not start from my GitHub PR. IMO this is because a lot of the database fields are limited to `VARCHAR(50)` e.g. https://github.com/drone/drone/blob/master/store/shared/migrate/mysql/files/005_create_table_stages.sql Is there a reason for that limit? Can we make it longer? (100, 128, 256?) e.g. I am generating the drone matrix from a starlark script. I end up with names like:  kind: pipeline type: docker name: webUIActivitySharingInternal-firefox-master-mariadb10.2-php7.0  I am generating a unique name that describes all the variable pieces of the environment that are used in the stage: - test suite `webUIActivitySharingInternal` - browser `firefox` - SW version `master` - database `mariadb10.2` - PHP version `php7.0` That makes a long name! But the generated names need to be unique so that they can be mentioned in `depends_on` source-file",no-bug,0.9
960,harness,https://github.com/harness/harness/issues/960,Database Foreign Keys,"Deleting a user should also result in user tokens, and user subscriptions (`user_repos` bucket) being purged as well: https://github.com/drone/drone/blob/bolt/datastore/bolt/user.go#L131",source-file | source-file | other-file | other-file,"Database Foreign Keys Deleting a user should also result in user tokens, and user subscriptions (`user_repos` bucket) being purged as well: https://github.com/drone/drone/blob/bolt/datastore/bolt/user.go#L131 source-file source-file other-file other-file",no-bug,0.9
3552,harness,https://github.com/harness/harness/issues/3552,docker registry-mirrors can be customized?,,database-file | database-file,docker registry-mirrors can be customized?  database-file database-file,no-bug,0.9
2710,harness,https://github.com/harness/harness/issues/2710,Sync Gitlab project in subgroups KO,"When you try to access on Gitlab sub-group project, the Ui respond 404 and the API respond: ",other-file | other-file | other-file | source-file | documentation-file | other-file | other-file | source-file,"Sync Gitlab project in subgroups KO When you try to access on Gitlab sub-group project, the Ui respond 404 and the API respond:  other-file other-file other-file source-file documentation-file other-file other-file source-file",bug,0.85
425,harness,https://github.com/harness/harness/issues/425,SAML 2.0 Single Sign On,"I'd like to be able manage authentication via SAML. This would allow us to login using SSO services like Okta or OneLogin As an example, here's a plugin I wrote to do it in Jenkins https://github.com/jenkinsci/saml-plugin",documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | other-file,"SAML 2.0 Single Sign On I'd like to be able manage authentication via SAML. This would allow us to login using SSO services like Okta or OneLogin As an example, here's a plugin I wrote to do it in Jenkins https://github.com/jenkinsci/saml-plugin documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file other-file",no-bug,0.9
724,harness,https://github.com/harness/harness/issues/724,"""Service Timeout"" with GitHub Enterprise","Hi, All my GitHub Enterprise web hook calls get a ""Service Timeout"": ![screen shot 2014-11-21 at 17 09 33](https://cloud.githubusercontent.com/assets/2472064/5145252/84775010-71a1-11e4-9b16-d12d95ea0b0a.png) There is no error in `/var/log/upstart/drone.log` Our internal GitHub Enterprise's SSL certificate is btw signed by an internal root certificate, not by a public one. Can this be an issue? I've added the root certificate of the GitHub Enterprise instance to the Ubuntu key store of the Drone.io server. Is that enough? Does the Go application recognize the certificate? Thanks, Michael",source-file,"""Service Timeout"" with GitHub Enterprise Hi, All my GitHub Enterprise web hook calls get a ""Service Timeout"": ![screen shot 2014-11-21 at 17 09 33](https://cloud.githubusercontent.com/assets/2472064/5145252/84775010-71a1-11e4-9b16-d12d95ea0b0a.png) There is no error in `/var/log/upstart/drone.log` Our internal GitHub Enterprise's SSL certificate is btw signed by an internal root certificate, not by a public one. Can this be an issue? I've added the root certificate of the GitHub Enterprise instance to the Ubuntu key store of the Drone.io server. Is that enough? Does the Go application recognize the certificate? Thanks, Michael source-file",no-bug,0.9
2460,harness,https://github.com/harness/harness/issues/2460,Option to configure a service account when enabling repos/webhooks,The current way repo webhooks are enabled (http://docs.drone.io/hooks/) has bit us a few times. We've had a few situations: - The user on the team hasn't been given admin permissions on their git repo yet - The team is getting help setting up their Drone configs and the person helping enables the repo instead - The user who enabled the repo in Drone left the company. So when their account was disabled and permissions removed from the git repo it broke the webook. It would be really useful if we were able to configure a service account to be used when enabling the repo in Drone.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | config-file,Option to configure a service account when enabling repos/webhooks The current way repo webhooks are enabled (http://docs.drone.io/hooks/) has bit us a few times. We've had a few situations: - The user on the team hasn't been given admin permissions on their git repo yet - The team is getting help setting up their Drone configs and the person helping enables the repo instead - The user who enabled the repo in Drone left the company. So when their account was disabled and permissions removed from the git repo it broke the webook. It would be really useful if we were able to configure a service account to be used when enabling the repo in Drone. source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file config-file,no-bug,0.9
1584,harness,https://github.com/harness/harness/issues/1584,Ability to delete logs (in case you accidentally expose a password in your logs),"Drone should implement some basic log parsing for the web UI so secret exposure can be fail-safed. This would be implemented by treating specified secrets as an array of ""do not print"" words, and scrubbing them from the log output. While there is an obvious vector here of weak-passwords being highlighted by emitted text, this is marginal compared to the benefits of ""failing safe"" for the common case, and could be mitigated by assigning secrets as ""fail if appears in logs"" by default (which you should never really need to turn off).",source-file | source-file,"Ability to delete logs (in case you accidentally expose a password in your logs) Drone should implement some basic log parsing for the web UI so secret exposure can be fail-safed. This would be implemented by treating specified secrets as an array of ""do not print"" words, and scrubbing them from the log output. While there is an obvious vector here of weak-passwords being highlighted by emitted text, this is marginal compared to the benefits of ""failing safe"" for the common case, and could be mitigated by assigning secrets as ""fail if appears in logs"" by default (which you should never really need to turn off). source-file source-file",no-bug,0.9
1195,harness,https://github.com/harness/harness/issues/1195,Recreate Queue on Restart,"I'm stress test drone 0.4.0 and docker. If i forcebly restart docker and drone, build container may not be destroyed, and restart build does not work, because docker says that container with this name already exists. I think drone needs check for container existance before creating, and destroy it when rebuild.",source-file | other-file | other-file,"Recreate Queue on Restart I'm stress test drone 0.4.0 and docker. If i forcebly restart docker and drone, build container may not be destroyed, and restart build does not work, because docker says that container with this name already exists. I think drone needs check for container existance before creating, and destroy it when rebuild. source-file other-file other-file",no-bug,0.9
738,harness,https://github.com/harness/harness/issues/738,delete account - http 400,"I've setup Drone to sync against Bitbucket. When I click the main menu (top left) and select 'Users' I see a single user which is my Bitbucket account. When I click on that, I see on the user edit screen a button labelled 'Delete Account'. Clicking that results in a DELETE request to http://mydrone/api/users/bitbucket.org/<user> which returns HTTP 400 response. I'm guessing this is left-over code from when Drone supported local user accounts?",source-file,"delete account - http 400 I've setup Drone to sync against Bitbucket. When I click the main menu (top left) and select 'Users' I see a single user which is my Bitbucket account. When I click on that, I see on the user edit screen a button labelled 'Delete Account'. Clicking that results in a DELETE request to http://mydrone/api/users/bitbucket.org/<user> which returns HTTP 400 response. I'm guessing this is left-over code from when Drone supported local user accounts? source-file",bug,0.9
471,harness,https://github.com/harness/harness/issues/471,Building docker image from exp branch fails,`make deps` fails on exp branch with  github.com/gorilla/mux github.com/gorilla/pat github.com/gorilla/websocket github.com/mattn/go-sqlite3 github.com/drone/drone/shared/sshutil github.com/drone/drone/server/handler github.com/drone/drone/server/database/testdatabase make:  [deps] Error 123 2014/09/19 09:08:19 The command [/bin/sh -c make deps build embed install] returned a non-zero code: 2 ,source-file,Building docker image from exp branch fails `make deps` fails on exp branch with  github.com/gorilla/mux github.com/gorilla/pat github.com/gorilla/websocket github.com/mattn/go-sqlite3 github.com/drone/drone/shared/sshutil github.com/drone/drone/server/handler github.com/drone/drone/server/database/testdatabase make:  [deps] Error 123 2014/09/19 09:08:19 The command [/bin/sh -c make deps build embed install] returned a non-zero code: 2  source-file,no-bug,0.9
2513,harness,https://github.com/harness/harness/issues/2513,Drone agent restarting,"From [Discourse](https://discourse.drone.io/t/drone-agent-restarting/2641) : Hello, I have encountered a bug with the Drone Agent where it restarts when facing a particular .drone.yml pipeline : I have checked the Agent logs and found this:  {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""repo"":""CaliOpen/Caliopen"",""build"":""90"",""id"":""4557"",""error"":"""",""exit_code"":0,""message"":""updating pipeline status""} {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""repo"":""CaliOpen/Caliopen"",""build"":""90"",""id"":""4557"",""message"":""stop listening for cancel signal""} {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""repo"":""CaliOpen/Caliopen"",""build"":""90"",""id"":""4557"",""message"":""updating pipeline status complete""} {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""message"":""request next execution""} {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""repo"":""CaliOpen/Caliopen"",""build"":""90"",""id"":""4557"",""message"":""pipeline done""} panic: runtime error: index out of range goroutine 24 [running]: main.(*runner).run(0xc420486280, 0xbf1e40, 0xc420207780, 0x0, 0x0) /go/src/github.com/drone/drone/cmd/drone-agent/agent.go:182 +0x170d main.loop.func2(0xc4202af010, 0xc4202aee9c, 0xbf43a0, 0xc42027cee0, 0xc4201d1a40, 0x0, 0x0, 0xc4202aef70, 0xc4202aefd0) /go/src/github.com/drone/drone/cmd/drone-agent/agent.go:132 +0x193 created by main.loop /go/src/github.com/drone/drone/cmd/drone-agent/agent.go:137 +0x910 {""time"":""2018-09-19T09:30:24Z"",""level"":""debug"",""message"":""request next execution""} panic: runtime error: index out of range  The drone.yml can be found [here](https://github.com/CaliOpen/Caliopen/blob/develop/.drone.yml) . Another report includes where the error occurs during a deploy hook : During deployment : Works :  clone: git: image: plugins/git:next when: event: [ push, pull_request, tag ] git: image: fpfis/true when: event: [ deployment ]  fails :  clone: git: image: plugins/git:next when: event: [ push, pull_request, tag ]  Some debugging lead me to https://github.com/drone/drone/blob/master/cmd/drone-agent/agent.go#L478 , where stages seems to be unset. I thought the source was the usage of a custom clone logic but another user reports he's just using matrices. Thank you for your help!",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | source-file | source-file | documentation-file | other-file | documentation-file,"Drone agent restarting From [Discourse](https://discourse.drone.io/t/drone-agent-restarting/2641) : Hello, I have encountered a bug with the Drone Agent where it restarts when facing a particular .drone.yml pipeline : I have checked the Agent logs and found this:  {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""repo"":""CaliOpen/Caliopen"",""build"":""90"",""id"":""4557"",""error"":"""",""exit_code"":0,""message"":""updating pipeline status""} {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""repo"":""CaliOpen/Caliopen"",""build"":""90"",""id"":""4557"",""message"":""stop listening for cancel signal""} {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""repo"":""CaliOpen/Caliopen"",""build"":""90"",""id"":""4557"",""message"":""updating pipeline status complete""} {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""message"":""request next execution""} {""time"":""2018-09-19T09:30:23Z"",""level"":""debug"",""repo"":""CaliOpen/Caliopen"",""build"":""90"",""id"":""4557"",""message"":""pipeline done""} panic: runtime error: index out of range goroutine 24 [running]: main.(*runner).run(0xc420486280, 0xbf1e40, 0xc420207780, 0x0, 0x0) /go/src/github.com/drone/drone/cmd/drone-agent/agent.go:182 +0x170d main.loop.func2(0xc4202af010, 0xc4202aee9c, 0xbf43a0, 0xc42027cee0, 0xc4201d1a40, 0x0, 0x0, 0xc4202aef70, 0xc4202aefd0) /go/src/github.com/drone/drone/cmd/drone-agent/agent.go:132 +0x193 created by main.loop /go/src/github.com/drone/drone/cmd/drone-agent/agent.go:137 +0x910 {""time"":""2018-09-19T09:30:24Z"",""level"":""debug"",""message"":""request next execution""} panic: runtime error: index out of range  The drone.yml can be found [here](https://github.com/CaliOpen/Caliopen/blob/develop/.drone.yml) . Another report includes where the error occurs during a deploy hook : During deployment : Works :  clone: git: image: plugins/git:next when: event: [ push, pull_request, tag ] git: image: fpfis/true when: event: [ deployment ]  fails :  clone: git: image: plugins/git:next when: event: [ push, pull_request, tag ]  Some debugging lead me to https://github.com/drone/drone/blob/master/cmd/drone-agent/agent.go#L478 , where stages seems to be unset. I thought the source was the usage of a custom clone logic but another user reports he's just using matrices. Thank you for your help! source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file source-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file source-file other-file source-file other-file source-file other-file source-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file source-file other-file other-file other-file source-file source-file documentation-file other-file documentation-file",no-bug,0.9
947,harness,https://github.com/harness/harness/issues/947,Add support for CCMenu,Is it possible to implements XML support for [CCMenu](http://ccmenu.org) ?,other-file,Add support for CCMenu Is it possible to implements XML support for [CCMenu](http://ccmenu.org) ? other-file,no-bug,0.9
330,harness,https://github.com/harness/harness/issues/330,Custom container yields error rbenv: version `2.0.0-p353' not installed,"I created a new custom image using the `Dockerfile`  FROM bradrydzewski/python:2.7 # install scipy RUN sudo apt-get update && sudo apt-get install python-numpy python-scipy python-pandas libsndfile1 libsndfile1-dev python-nose python-matplotlib  I thought that should be enough since all the settings and the virtualenv are already there. Just to make sure I made a more complex one  FROM bradrydzewski/python:2.7 WORKDIR /home/ubuntu USER ubuntu ADD python.sh /etc/drone.d/ # install scipy RUN sudo apt-get update && sudo apt-get install python-numpy python-scipy python-pandas libsndfile1 libsndfile1-dev python-nose python-matplotlib RUN rm -rf /home/ubuntu/virtualenv/python2.7 # setup default virtualenv for python 2.7 RUN virtualenv --python=/usr/bin/python2.7 /home/ubuntu/virtualenv/python2.7 --system-site-packages && \ . /home/ubuntu/virtualenv/python2.7/bin/activate && \ pip install --use-mirrors nose && \ pip install -U pytest  the creation of both containers runs through fine and I can load them manually too. However when trying to run tests on them I get the very pecuilar message  rbenv: version `2.0.0-p353' not installed  Just to make sure, I ran `rbenv` on both containers and `2.0.0-p353` was in fact there.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,"Custom container yields error rbenv: version `2.0.0-p353' not installed I created a new custom image using the `Dockerfile`  FROM bradrydzewski/python:2.7 # install scipy RUN sudo apt-get update && sudo apt-get install python-numpy python-scipy python-pandas libsndfile1 libsndfile1-dev python-nose python-matplotlib  I thought that should be enough since all the settings and the virtualenv are already there. Just to make sure I made a more complex one  FROM bradrydzewski/python:2.7 WORKDIR /home/ubuntu USER ubuntu ADD python.sh /etc/drone.d/ # install scipy RUN sudo apt-get update && sudo apt-get install python-numpy python-scipy python-pandas libsndfile1 libsndfile1-dev python-nose python-matplotlib RUN rm -rf /home/ubuntu/virtualenv/python2.7 # setup default virtualenv for python 2.7 RUN virtualenv --python=/usr/bin/python2.7 /home/ubuntu/virtualenv/python2.7 --system-site-packages && \ . /home/ubuntu/virtualenv/python2.7/bin/activate && \ pip install --use-mirrors nose && \ pip install -U pytest  the creation of both containers runs through fine and I can load them manually too. However when trying to run tests on them I get the very pecuilar message  rbenv: version `2.0.0-p353' not installed  Just to make sure, I ran `rbenv` on both containers and `2.0.0-p353` was in fact there. source-file source-file source-file source-file source-file source-file source-file source-file other-file",no-bug,0.95
961,harness,https://github.com/harness/harness/issues/961,Database: User Repo Index,"We need to be able to get a list of repositories for a user: https://github.com/drone/drone/blob/bolt/datastore/bolt/user.go#L53 This means we need to manually maintain an index that associates repositories to a user. So we store a key/value where the key is the username and the value is an array of keys (`[][]byte`): There is code in place that expects this index to exist:  Go key := []byte(login) raw := t.Bucket(bucketUserRepos).Get(key) keys := [][]byte{} err = decode(raw, &keys) if err != nil { return repos, err }  The problem is that we are not currently maintaining this index when creating a repository: https://github.com/drone/drone/blob/bolt/datastore/bolt/repo.go#L45 We should also maintain a reverse index. A list of user keys that have access to a particular repository (in the `bucketRepoUsers` bucket).",other-file | other-file | other-file | other-file | source-file,"Database: User Repo Index We need to be able to get a list of repositories for a user: https://github.com/drone/drone/blob/bolt/datastore/bolt/user.go#L53 This means we need to manually maintain an index that associates repositories to a user. So we store a key/value where the key is the username and the value is an array of keys (`[][]byte`): There is code in place that expects this index to exist:  Go key := []byte(login) raw := t.Bucket(bucketUserRepos).Get(key) keys := [][]byte{} err = decode(raw, &keys) if err != nil { return repos, err }  The problem is that we are not currently maintaining this index when creating a repository: https://github.com/drone/drone/blob/bolt/datastore/bolt/repo.go#L45 We should also maintain a reverse index. A list of user keys that have access to a particular repository (in the `bucketRepoUsers` bucket). other-file other-file other-file other-file source-file",no-bug,0.9
3428,harness,https://github.com/harness/harness/issues/3428,Add configuration values for the Pipelines created containers,"I've tried to use my docker file template to deploy Gitness. In that docker file, I define specific networks for the stack, and usually, I run everything without exposing ports by exposing the services with a tunnel (Cloudflare) or a proxy (Traefik) Following this approach I have found that it is not possible to run pipelines, as they create the Drone container expecting to have access to Gitness using the 'http://host.docker.internal:3000/' address, instead of 'http://container_name:3000', accessible from the same docker network. This results in an error on the first step of the pipeline that says 'unable to access 'http://host.docker.internal:3000/' Changing the docker file by exposing the port makes it work. It should be possible to specify the network for the newly created containers + where to find Gitness, as docker environment variables that can be passed on the container creation or as part of any docker file",other-file | test-file | test-file | test-file | test-file | test-file | test-file | other-file | other-file | test-file | test-file | test-file | test-file | test-file | test-file | other-file | other-file | other-file | test-file | other-file | test-file,"Add configuration values for the Pipelines created containers I've tried to use my docker file template to deploy Gitness. In that docker file, I define specific networks for the stack, and usually, I run everything without exposing ports by exposing the services with a tunnel (Cloudflare) or a proxy (Traefik) Following this approach I have found that it is not possible to run pipelines, as they create the Drone container expecting to have access to Gitness using the 'http://host.docker.internal:3000/' address, instead of 'http://container_name:3000', accessible from the same docker network. This results in an error on the first step of the pipeline that says 'unable to access 'http://host.docker.internal:3000/' Changing the docker file by exposing the port makes it work. It should be possible to specify the network for the newly created containers + where to find Gitness, as docker environment variables that can be passed on the container creation or as part of any docker file other-file test-file test-file test-file test-file test-file test-file other-file other-file test-file test-file test-file test-file test-file test-file other-file other-file other-file test-file other-file test-file",no-bug,0.9
2743,harness,https://github.com/harness/harness/issues/2743,Drone installed successfully but will not trigger the build,docker run --volume=/var/run/docker.sock:/var/run/docker.sock --volume=/var/lib/drone:/data --env=DRONE_GITEA_SERVER=https://xxxxx:3000 --env=DRONE_GIT_ALWAYS_AUTH=false --env=DRONE_SERVER_HOST=xxx.xxx.xxx.xx:8000 --env=DRONE_RUNNER_CAPACITY=2 --env=DRONE_SERVER_PROTO=http --env=DRONE_TLS_AUTOCERT=false --publish=8000:80 --publish=4430:443 --restart=always --detach=true --name=drone drone/drone:1 .drone.yml  kind: pipeline name: chasing-test steps: - name: install image: composer commands: - composer install - name: test image: php:7.1 commands: - ls -al - vendor/bin/codecept run when: branch: - dev_unit event: - push ,other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file,Drone installed successfully but will not trigger the build docker run --volume=/var/run/docker.sock:/var/run/docker.sock --volume=/var/lib/drone:/data --env=DRONE_GITEA_SERVER=https://xxxxx:3000 --env=DRONE_GIT_ALWAYS_AUTH=false --env=DRONE_SERVER_HOST=xxx.xxx.xxx.xx:8000 --env=DRONE_RUNNER_CAPACITY=2 --env=DRONE_SERVER_PROTO=http --env=DRONE_TLS_AUTOCERT=false --publish=8000:80 --publish=4430:443 --restart=always --detach=true --name=drone drone/drone:1 .drone.yml  kind: pipeline name: chasing-test steps: - name: install image: composer commands: - composer install - name: test image: php:7.1 commands: - ls -al - vendor/bin/codecept run when: branch: - dev_unit event: - push  other-file source-file other-file other-file other-file other-file other-file other-file other-file documentation-file source-file,no-bug,0.9
819,harness,https://github.com/harness/harness/issues/819,Handling PR and commit webhooks for the same Commit,"I work in a team where we all have access to the private github repo, and develop directly against it (as opposed to forking it to our personal GitHub accounts). All our changes are submitted as Pull Requests though (we push the feature branch to the shared private repo on GitHub, and then create a PR from there). The issue is that because the branch and the PR are part of the repository linked to drone, github will send a webhook for both the commit on the branch and the PR. This then continues for each subsequent change to that branch after a PR has been created. Drone seems to just respond to 1 and ignore the other (I'm guessing it just responds to the first one it receives 'cause sometimes it is the PR one and sometimes it's the commit one). This results in the following issues: - If it handles the PR one and ignores the commit one, the commit message is the PR title and not the actual commit message. - If it handles the PR one after the initial PR was created, it then results in a duplicate block for the same PR under the Pull Requests section - If it handles the commit one, it doesn't update the PR block at the bottom. For example, if I submit a PR and the build fails, and I then push a fix which builds successfully, if drone runs the commit webhook (rather than the PR one), the PR block will still reflect a failure even though the commit from that PR has built successfully. I realise that this may be slightly unusual workflow (especially compared to open source repositories), but I'm assuming it should still handle it. Possibly, if a PR webhook is received after the commit webhook for the same SHA, it should update the record in the commits table (updating the commit_pr column, and probably replacing the value of the commit_message column to rather be the PR title too).",source-file | source-file,"Handling PR and commit webhooks for the same Commit I work in a team where we all have access to the private github repo, and develop directly against it (as opposed to forking it to our personal GitHub accounts). All our changes are submitted as Pull Requests though (we push the feature branch to the shared private repo on GitHub, and then create a PR from there). The issue is that because the branch and the PR are part of the repository linked to drone, github will send a webhook for both the commit on the branch and the PR. This then continues for each subsequent change to that branch after a PR has been created. Drone seems to just respond to 1 and ignore the other (I'm guessing it just responds to the first one it receives 'cause sometimes it is the PR one and sometimes it's the commit one). This results in the following issues: - If it handles the PR one and ignores the commit one, the commit message is the PR title and not the actual commit message. - If it handles the PR one after the initial PR was created, it then results in a duplicate block for the same PR under the Pull Requests section - If it handles the commit one, it doesn't update the PR block at the bottom. For example, if I submit a PR and the build fails, and I then push a fix which builds successfully, if drone runs the commit webhook (rather than the PR one), the PR block will still reflect a failure even though the commit from that PR has built successfully. I realise that this may be slightly unusual workflow (especially compared to open source repositories), but I'm assuming it should still handle it. Possibly, if a PR webhook is received after the commit webhook for the same SHA, it should update the record in the commits table (updating the commit_pr column, and probably replacing the value of the commit_message column to rather be the PR title too). source-file source-file",no-bug,0.8
3424,harness,https://github.com/harness/harness/issues/3424,Repository names cannot start with '.',When importing/creating a repo the repo cannot start with a '.' Example: `.dotfiles` It would be great to mirror Github in this aspect so that when cloning down to my machines it clones to a hidden file with only the default clone command. RE: all my dotfiles.,source-file | source-file | source-file | source-file | source-file,Repository names cannot start with '.' When importing/creating a repo the repo cannot start with a '.' Example: `.dotfiles` It would be great to mirror Github in this aspect so that when cloning down to my machines it clones to a hidden file with only the default clone command. RE: all my dotfiles. source-file source-file source-file source-file source-file,no-bug,0.8
2961,harness,https://github.com/harness/harness/issues/2961,drone exec --include more than one step does not work,"Trying to run multiple steps and exec does not do anything while single individual steps are fine.  drone exec --include=build,test ",other-file,"drone exec --include more than one step does not work Trying to run multiple steps and exec does not do anything while single individual steps are fine.  drone exec --include=build,test  other-file",no-bug,0.7
3245,harness,https://github.com/harness/harness/issues/3245,Adding Power (ppc64le) support to Drone Server,"It looks like we do not have ppc64le support for the drone server. I am working on adding ppc64le support to it. If you don't have ppc64le resource for test this pipeline, then we can provide that resource as well.",source-file | source-file | source-file,"Adding Power (ppc64le) support to Drone Server It looks like we do not have ppc64le support for the drone server. I am working on adding ppc64le support to it. If you don't have ppc64le resource for test this pipeline, then we can provide that resource as well. source-file source-file source-file",no-bug,0.9
2635,harness,https://github.com/harness/harness/issues/2635,Running Drone agent on Windows Server 2016,"Hi, Support for Drone Agent on Windows was added in #1330 , however, it is based on an 1803/1809 image. Windows Server 2016 cannot run a Windows docker container that is based on a newer OS image. https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/version-compatibility There was a Windows binary release in https://github.com/drone/drone/issues/1330#issuecomment-251129732 but it seems to no longer be updated. Is it possible to publish updated Windows binaries, or (preferably) Docker tags based on Server 2016 as well as the current 1803/1809 tags? So that Drone Agent can run on a Server 2016 PC? Thanks",source-file | source-file | source-file | source-file | source-file | source-file,"Running Drone agent on Windows Server 2016 Hi, Support for Drone Agent on Windows was added in #1330 , however, it is based on an 1803/1809 image. Windows Server 2016 cannot run a Windows docker container that is based on a newer OS image. https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/version-compatibility There was a Windows binary release in https://github.com/drone/drone/issues/1330#issuecomment-251129732 but it seems to no longer be updated. Is it possible to publish updated Windows binaries, or (preferably) Docker tags based on Server 2016 as well as the current 1803/1809 tags? So that Drone Agent can run on a Server 2016 PC? Thanks source-file source-file source-file source-file source-file source-file",no-bug,0.9
859,harness,https://github.com/harness/harness/issues/859,Jenkins Env Variable Compatibility,"Per https://github.com/drone/drone/pull/858#issuecomment-71968729 we should consider adding environment variables to match other CI systems (specifically Jenkins). Below is what the old version of Drone used, which I think is a good starting point. We intentionally omitted some environment variables (like `SVN_REVISION`) since they aren't as relevant today as when Jenkins was created. - `JOB_NAME`: the name of your project (github.com/:user/:repo) - `WORKSPACE`: the location of your code and working directory of your build script - `BUILD_URL`: the url of your build (drone.io/github.com/:user/:repo/:build) - `BUILD_DIR`: the location of your code and working directory of your build script - `BUILD_ID`: the current build number - `GIT_COMMIT`: the commit hash currently being built - `GIT_BRANCH`: the branch currently being built cc @craigtracey",other-file | other-file | other-file | other-file,"Jenkins Env Variable Compatibility Per https://github.com/drone/drone/pull/858#issuecomment-71968729 we should consider adding environment variables to match other CI systems (specifically Jenkins). Below is what the old version of Drone used, which I think is a good starting point. We intentionally omitted some environment variables (like `SVN_REVISION`) since they aren't as relevant today as when Jenkins was created. - `JOB_NAME`: the name of your project (github.com/:user/:repo) - `WORKSPACE`: the location of your code and working directory of your build script - `BUILD_URL`: the url of your build (drone.io/github.com/:user/:repo/:build) - `BUILD_DIR`: the location of your code and working directory of your build script - `BUILD_ID`: the current build number - `GIT_COMMIT`: the commit hash currently being built - `GIT_BRANCH`: the branch currently being built cc @craigtracey other-file other-file other-file other-file",no-bug,0.9
1220,harness,https://github.com/harness/harness/issues/1220,base64 not found in container,![2015-10-06 17 16 55](https://cloud.githubusercontent.com/assets/1614346/10311592/170aba62-6c50-11e5-8edf-50fca525749b.png) You using base64 for decode variable? it's need add to container? I am used  build: image: antonikonovalov/drone-image-go:latest insecure: true environment: - PATH=$GOPATH/bin:/usr/local/bin:$PATH - MP_DOCKER_CHANNEL=TEST-DRONE commands: - go get -u github.com/antonikonovalov/money - make local_deps - make test - make build compose: elastic: image: elasticsearch mongodb: image: mongo nsq: image: antonikonovalov/dockerfile-nsq ,source-file | source-file | source-file | source-file | documentation-file | other-file,base64 not found in container ![2015-10-06 17 16 55](https://cloud.githubusercontent.com/assets/1614346/10311592/170aba62-6c50-11e5-8edf-50fca525749b.png) You using base64 for decode variable? it's need add to container? I am used  build: image: antonikonovalov/drone-image-go:latest insecure: true environment: - PATH=$GOPATH/bin:/usr/local/bin:$PATH - MP_DOCKER_CHANNEL=TEST-DRONE commands: - go get -u github.com/antonikonovalov/money - make local_deps - make test - make build compose: elastic: image: elasticsearch mongodb: image: mongo nsq: image: antonikonovalov/dockerfile-nsq  source-file source-file source-file source-file documentation-file other-file,no-bug,0.9
126,harness,https://github.com/harness/harness/issues/126,Manually force new builds,Most of the other CI services support this feature.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Manually force new builds Most of the other CI services support this feature. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
2849,harness,https://github.com/harness/harness/issues/2849,What version am I running?,"There doesn't seem to be an indication anywhere that I am able to find that shows me exactly what version of Drone I'm running. I don't see anything in the web interface, the CLI doesn't seem to query or show this information nor am I able to find it in the database. I use `image: drone/drone:1` in my docker-compose file to make it easier for upgrades (`docker-compose pull`, `docker-compose up -d`), so I know I'm on the 1.x series, but I have no idea which version at a glance. I just did a `pull` and `up` this morning so I'm assuming I'm on 1.5 now, but I can't confirm. Please consider this a feature request to display the version of Drone somewhere - footer, CLI, etc. If there is a way to determine this that I'm missing, please let me know and I'll happily close this issue.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file,"What version am I running? There doesn't seem to be an indication anywhere that I am able to find that shows me exactly what version of Drone I'm running. I don't see anything in the web interface, the CLI doesn't seem to query or show this information nor am I able to find it in the database. I use `image: drone/drone:1` in my docker-compose file to make it easier for upgrades (`docker-compose pull`, `docker-compose up -d`), so I know I'm on the 1.x series, but I have no idea which version at a glance. I just did a `pull` and `up` this morning so I'm assuming I'm on 1.5 now, but I can't confirm. Please consider this a feature request to display the version of Drone somewhere - footer, CLI, etc. If there is a way to determine this that I'm missing, please let me know and I'll happily close this issue. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file",no-bug,0.95
3323,harness,https://github.com/harness/harness/issues/3323,Filter builds by branch name,"The feature will allow us visualize build timeline for a specific branch more easily. Other CI tools like CircleCI have this and it is good for usability. I imagine it something like this. No filter selected: ![No filter selected](https://github.com/harness/drone/assets/41040569/6c6d0d85-991a-49db-86d9-f0230c4ef270) Filter selected for branch ""master"": ![Filter selected](https://github.com/harness/drone/assets/41040569/24f85bde-48af-4f6d-a6f0-c7788185563f)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Filter builds by branch name The feature will allow us visualize build timeline for a specific branch more easily. Other CI tools like CircleCI have this and it is good for usability. I imagine it something like this. No filter selected: ![No filter selected](https://github.com/harness/drone/assets/41040569/6c6d0d85-991a-49db-86d9-f0230c4ef270) Filter selected for branch ""master"": ![Filter selected](https://github.com/harness/drone/assets/41040569/24f85bde-48af-4f6d-a6f0-c7788185563f) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
112,harness,https://github.com/harness/harness/issues/112,"Add a ""test now"" button for SMTP","When entering SMTP server values, it would be nice to have a button to validate/test settings.",other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file,"Add a ""test now"" button for SMTP When entering SMTP server values, it would be nice to have a button to validate/test settings. other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file",no-bug,0.9
2782,harness,https://github.com/harness/harness/issues/2782,Log Downloads don't work in firefox,"You can't download the log by clicking the download log button in firefox, works fine in chrome. See also: https://discourse.drone.io/t/firefox-download-button-does-not-work/4730/2",source-file,"Log Downloads don't work in firefox You can't download the log by clicking the download log button in firefox, works fine in chrome. See also: https://discourse.drone.io/t/firefox-download-button-does-not-work/4730/2 source-file",no-bug,0.9
266,harness,https://github.com/harness/harness/issues/266,Dev environment initialization with Vagrant issues,I have followed this steps : https://github.com/drone/drone/tree/master#local-development but the Vagrant VM doesn't work. I have the following messages :  # cd /opt/go/src/github.com/drone/drone; git pull --ff-only Host key verification failed. fatal: The remote end hung up unexpectedly package github.com/drone/drone/cmd/drone: exit status 1   make:  [deps] Error 1   Stderr from the command: stdin: is not a tty dpkg-preconfigure: unable to re-open stdin: No such file or directory  I work on Mac OS. The complete logs are available here : https://gist.github.com/alexandre-butynski/10600296 I'm new to Go but Drone is a great tool and I would be happy to contribute. What is the best way to initialize a dev environment ?,documentation-file | other-file | source-file | other-file | source-file,Dev environment initialization with Vagrant issues I have followed this steps : https://github.com/drone/drone/tree/master#local-development but the Vagrant VM doesn't work. I have the following messages :  # cd /opt/go/src/github.com/drone/drone; git pull --ff-only Host key verification failed. fatal: The remote end hung up unexpectedly package github.com/drone/drone/cmd/drone: exit status 1   make:  [deps] Error 1   Stderr from the command: stdin: is not a tty dpkg-preconfigure: unable to re-open stdin: No such file or directory  I work on Mac OS. The complete logs are available here : https://gist.github.com/alexandre-butynski/10600296 I'm new to Go but Drone is a great tool and I would be happy to contribute. What is the best way to initialize a dev environment ? documentation-file other-file source-file other-file source-file,no-bug,0.9
1105,harness,https://github.com/harness/harness/issues/1105,Reverse proxy configuration?,"I'm using drone inside a docker container, drone itself is hidden behind nginx. I get 400 response for ws://mydrone.io/api/stream/stdout/98?access_token=  And the main problem I can not see the live stdout ( My site configuration.  upstream drone { server localhost:8080; } server { listen 80; set_by_lua $drone_hostname 'return os.getenv(""DRONE_HOSTNAME"")'; server_name $drone_hostname; location / { proxy_pass http://drone; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # Proxy for websockets location = /feed { proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $http_host; proxy_pass http://drone; proxy_redirect off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection ""upgrade""; } } ",other-file | source-file | other-file,"Reverse proxy configuration? I'm using drone inside a docker container, drone itself is hidden behind nginx. I get 400 response for ws://mydrone.io/api/stream/stdout/98?access_token=  And the main problem I can not see the live stdout ( My site configuration.  upstream drone { server localhost:8080; } server { listen 80; set_by_lua $drone_hostname 'return os.getenv(""DRONE_HOSTNAME"")'; server_name $drone_hostname; location / { proxy_pass http://drone; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # Proxy for websockets location = /feed { proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header Host $http_host; proxy_pass http://drone; proxy_redirect off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection ""upgrade""; } }  other-file source-file other-file",no-bug,0.8
1070,harness,https://github.com/harness/harness/issues/1070,Question about build matrix,"Hi, I have a question about the build matrix new feature, but I don't think it's possible using the current format. What is the best solution for this use case: I have an application which I want to be able to run on x86/x64 but also on arm architecture. I can add 2 build workers for this (1 for x64 and one for arm), but I have the following questions: 1. Can drone worker run on arm architecture ? 2. How can I make sure that one build will go on arm server and one on x64 server ? 3. I need different services images, for example `redis` for x64 and `arm-redis` for arm. Is this supported by build matrix ?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Question about build matrix Hi, I have a question about the build matrix new feature, but I don't think it's possible using the current format. What is the best solution for this use case: I have an application which I want to be able to run on x86/x64 but also on arm architecture. I can add 2 build workers for this (1 for x64 and one for arm), but I have the following questions: 1. Can drone worker run on arm architecture ? 2. How can I make sure that one build will go on arm server and one on x64 server ? 3. I need different services images, for example `redis` for x64 and `arm-redis` for arm. Is this supported by build matrix ? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
285,harness,https://github.com/harness/harness/issues/285,More descriptive fail build messages.,"Hello. I'm using private drone deployment and started to test it a little. When my app is failing to build I only get message: ""HTTP code: 404"" Which is not descriptive enough to track this problem. Is there possibility to get whole building logs? Are they saved somewhere on server? Anyway, I think this message should tell more about problem. At least URL should be included, right?",source-file | other-file | other-file,"More descriptive fail build messages. Hello. I'm using private drone deployment and started to test it a little. When my app is failing to build I only get message: ""HTTP code: 404"" Which is not descriptive enough to track this problem. Is there possibility to get whole building logs? Are they saved somewhere on server? Anyway, I think this message should tell more about problem. At least URL should be included, right? source-file other-file other-file",no-bug,0.9
731,harness,https://github.com/harness/harness/issues/731,Cert error after 'git push',"I just set up a second project. When I do `git push` the github hook fires, and I get the following error in my drone log: `2014/11/25 19:48:28 http: TLS handshake error from 192.30.252.34:54931: remote error: unknown certificate authority` I don't receive the error on my other project when I push.",other-file | other-file | other-file,"Cert error after 'git push' I just set up a second project. When I do `git push` the github hook fires, and I get the following error in my drone log: `2014/11/25 19:48:28 http: TLS handshake error from 192.30.252.34:54931: remote error: unknown certificate authority` I don't receive the error on my other project when I push. other-file other-file other-file",no-bug,0.9
2158,harness,https://github.com/harness/harness/issues/2158,Logs refuse to load for some builds,The following error message appears in console:  Uncaught (in promise) TypeError: Cannot read property 'map' of null at client.getLogs.then (drone-app.html:20975) at <anonymous>  Drone 0.8.0-rc.3 on GKE Chrome 60 on OS X Sierra,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file,Logs refuse to load for some builds The following error message appears in console:  Uncaught (in promise) TypeError: Cannot read property 'map' of null at client.getLogs.then (drone-app.html:20975) at <anonymous>  Drone 0.8.0-rc.3 on GKE Chrome 60 on OS X Sierra source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file,no-bug,0.8
238,harness,https://github.com/harness/harness/issues/238,Build fails because of new NPM dependencies version format,"Hi guys! We use drone.io for CI, and have a trouble with a dependency, which uses new versions format in its dependencies. Looks like: `npm ERR! Error: No compatible version found: underscore.string@'^2.3.3'` Seems that the NPM version is too old. Is there any way to workaround it?",other-file | container-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | documentation-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file,"Build fails because of new NPM dependencies version format Hi guys! We use drone.io for CI, and have a trouble with a dependency, which uses new versions format in its dependencies. Looks like: `npm ERR! Error: No compatible version found: underscore.string@'^2.3.3'` Seems that the NPM version is too old. Is there any way to workaround it? other-file container-file source-file other-file other-file source-file other-file other-file source-file other-file source-file documentation-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file source-file",no-bug,0.9
2644,harness,https://github.com/harness/harness/issues/2644,the build logs is not colorful for log level,the build logs is not colorful for log level. example: info: black warn: orange error: red ,documentation-file,the build logs is not colorful for log level the build logs is not colorful for log level. example: info: black warn: orange error: red  documentation-file,no-bug,0.9
562,harness,https://github.com/harness/harness/issues/562,Changing pwd in `script` breaks `deploy`,For example a `.drone.yml` file like  image: base script: - cd proj - make deploy: ssh: target: machine artifacts: - proj/a.out  will not successfully deploy `proj/a.out` as `deploy` is executed after `script` without changing back to the root dir and the `artifact` it would be looking for is `proj/proj/a.out`  script: - cd proj - make - cd ..  Fixes this. I would expect all instructions to run with respect to the root directory: Changing dir in one does not affect any of the others.,other-file | test-file | test-file | test-file | other-file | source-file | other-file,Changing pwd in `script` breaks `deploy` For example a `.drone.yml` file like  image: base script: - cd proj - make deploy: ssh: target: machine artifacts: - proj/a.out  will not successfully deploy `proj/a.out` as `deploy` is executed after `script` without changing back to the root dir and the `artifact` it would be looking for is `proj/proj/a.out`  script: - cd proj - make - cd ..  Fixes this. I would expect all instructions to run with respect to the root directory: Changing dir in one does not affect any of the others. other-file test-file test-file test-file other-file source-file other-file,no-bug,0.9
2617,harness,https://github.com/harness/harness/issues/2617,Build breaks with Githubs new Draft PR feature.,1. Push a branch 2. Create a Draft PR (see https://github.blog/2019-02-14-introducing-draft-pull-requests/) 3. Expect tests to run. Actually it fails: https://drone.nextcloud.com/nextcloud/spreed/1683/29  git fetch --no-tags origin +refs/pull/1591/merge: fatal: Couldn't find remote ref refs/pull/1591/merge ,other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | documentation-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file,Build breaks with Githubs new Draft PR feature. 1. Push a branch 2. Create a Draft PR (see https://github.blog/2019-02-14-introducing-draft-pull-requests/) 3. Expect tests to run. Actually it fails: https://drone.nextcloud.com/nextcloud/spreed/1683/29  git fetch --no-tags origin +refs/pull/1591/merge: fatal: Couldn't find remote ref refs/pull/1591/merge  other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file source-file documentation-file other-file source-file other-file other-file other-file other-file other-file source-file,no-bug,0.9
637,harness,https://github.com/harness/harness/issues/637,"Team Settings, forbidden access?","I just set up a fresh Drone.io instance and added a new team. At some point, when I clicked on ""Team Settings"" from the team-specific dashboard, I get a ""Forbidden"" message and a ""400: Bad Request"" response. This seemed to happen out of the blue. I installed Drone.io using a Docker container which I believe installs the latest version of Drone. Is there something that might cause this? Is there a way for me to delete the team given I no longer have access?",source-file,"Team Settings, forbidden access? I just set up a fresh Drone.io instance and added a new team. At some point, when I clicked on ""Team Settings"" from the team-specific dashboard, I get a ""Forbidden"" message and a ""400: Bad Request"" response. This seemed to happen out of the blue. I installed Drone.io using a Docker container which I believe installs the latest version of Drone. Is there something that might cause this? Is there a way for me to delete the team given I no longer have access? source-file",bug,0.85
196,harness,https://github.com/harness/harness/issues/196,Deploy Plugin - EngineYard,Provide a deployment option for EngineYard. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/engineyard.go,source-file | documentation-file | other-file | other-file | source-file | source-file | other-file | other-file | other-file,Deploy Plugin - EngineYard Provide a deployment option for EngineYard. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/engineyard.go source-file documentation-file other-file other-file source-file source-file other-file other-file other-file,no-bug,0.9
610,harness,https://github.com/harness/harness/issues/610,Git deployment target not working,"Using the following git deployment target doesn't work:  git: target: dokku@myserver.mydomain.tld:mysite branch: master force: false  I get the following output from Drone after my tests pass:  usage: git config [options] Config file location --global use global config file --system use system config file --local use repository config file -f, --file <file> use given config file Action --get get value: name [value-regex] --get-all get all values: key [value-regex] --get-regexp get values for regexp: name-regex [value-regex] --replace-all replace all matching variables: name value [value_regex] --add adds a new variable: name value --unset removes a variable: name [value-regex] --unset-all removes all matches: name [value-regex] --rename-section rename section: old-name new-name --remove-section remove a section: name -l, --list list all -e, --edit opens an editor --get-color <slot> find the color configured: [default] --get-colorbool <slot> find the color setting: [stdout-is-tty] Type --bool value is ""true"" or ""false"" --int value is decimal number --bool-or-int value is --bool or --int --path value is a path (file or directory name) Other -z, --null terminate values with NUL byte  If I change it to:  bash: script: - git remote add production dokku@myserver.mydomain.tld:mysite - git push production master  it deploys just fine.",other-file | documentation-file | config-file | other-file,"Git deployment target not working Using the following git deployment target doesn't work:  git: target: dokku@myserver.mydomain.tld:mysite branch: master force: false  I get the following output from Drone after my tests pass:  usage: git config [options] Config file location --global use global config file --system use system config file --local use repository config file -f, --file <file> use given config file Action --get get value: name [value-regex] --get-all get all values: key [value-regex] --get-regexp get values for regexp: name-regex [value-regex] --replace-all replace all matching variables: name value [value_regex] --add adds a new variable: name value --unset removes a variable: name [value-regex] --unset-all removes all matches: name [value-regex] --rename-section rename section: old-name new-name --remove-section remove a section: name -l, --list list all -e, --edit opens an editor --get-color <slot> find the color configured: [default] --get-colorbool <slot> find the color setting: [stdout-is-tty] Type --bool value is ""true"" or ""false"" --int value is decimal number --bool-or-int value is --bool or --int --path value is a path (file or directory name) Other -z, --null terminate values with NUL byte  If I change it to:  bash: script: - git remote add production dokku@myserver.mydomain.tld:mysite - git push production master  it deploys just fine. other-file documentation-file config-file other-file",no-bug,0.9
3274,harness,https://github.com/harness/harness/issues/3274,gitea oauth: cannot exchange code,"gitea: version [1.17.2] drone log:  {""level"":""error"",""msg"":""oauth: cannot exchange code: gta_xxxxxx: : ""  gitea log:  GET /login/oauth/access_token for 111.22.248.4:0, 405 Method Not Allowed  look [gitea oauth2-provider.md](https://github.com/go-gitea/gitea/blob/711cbcce8d6a193f5738c45861d11cb86b412ec7/docs/content/doc/developers/oauth2-provider.md) Need to change GET to POST",source-file | source-file,"gitea oauth: cannot exchange code gitea: version [1.17.2] drone log:  {""level"":""error"",""msg"":""oauth: cannot exchange code: gta_xxxxxx: : ""  gitea log:  GET /login/oauth/access_token for 111.22.248.4:0, 405 Method Not Allowed  look [gitea oauth2-provider.md](https://github.com/go-gitea/gitea/blob/711cbcce8d6a193f5738c45861d11cb86b412ec7/docs/content/doc/developers/oauth2-provider.md) Need to change GET to POST source-file source-file",bug,0.9
2607,harness,https://github.com/harness/harness/issues/2607,DRONE_* Environment Variables,"What built-in variables can I reference from a bash script *drone plugin*? I have seen `DRONE_COMMIT` [in the docu](https://docs.drone.io/user-guide/pipeline/cloning/) but I would love to have the directory where the repository is linked to available in my bash script. Also: If there is more than the above mentioned variable, could we add a list of available variables to the documentation?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"DRONE_* Environment Variables What built-in variables can I reference from a bash script *drone plugin*? I have seen `DRONE_COMMIT` [in the docu](https://docs.drone.io/user-guide/pipeline/cloning/) but I would love to have the directory where the repository is linked to available in my bash script. Also: If there is more than the above mentioned variable, could we add a list of available variables to the documentation? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2042,harness,https://github.com/harness/harness/issues/2042,Add repository visibility field,I would like to add a new attribute to the repository called visibility. This will give us more control over which repositories are visible to users and under which circumstances. This idea is inspired by gitlab. The visibility field will have the following values: - `public` visible by anyone - `private` visible by anyone with access - `internal` visible by any authenticated user The visibility field will have the following default value: - `public` if repository is public - `private` if repository is private The use case for this is that some organizations are running github in private mode (meaning the repository is private) but don't want users to have to login to see the build results. This will replace the undocumented `PUBLIC_MODE` hack that we added a while back.,other-file | source-file,Add repository visibility field I would like to add a new attribute to the repository called visibility. This will give us more control over which repositories are visible to users and under which circumstances. This idea is inspired by gitlab. The visibility field will have the following values: - `public` visible by anyone - `private` visible by anyone with access - `internal` visible by any authenticated user The visibility field will have the following default value: - `public` if repository is public - `private` if repository is private The use case for this is that some organizations are running github in private mode (meaning the repository is private) but don't want users to have to login to see the build results. This will replace the undocumented `PUBLIC_MODE` hack that we added a while back. other-file source-file,no-bug,0.9
1122,harness,https://github.com/harness/harness/issues/1122,"How about add volume ""/var/run/docker.sock:/var/run/docker.sock"" to the runner container","Hi there, I'm looking at master HEAD and see that `docker` publish plugin does support to build & publish docker image for project. Two required options are: - docker_host - image From a end-user point of view, I think it's good if `docker_host` is optional because as a end-user, I'm not interested in where my image will to be built, should I? As I think, the drone CI/CD service should provides all equipment I want, rather than bring my own docker host to it. So to make user life easier, I think it's good if we make `docker_host` optional, by default, we'll use the default docker socket(`/var/run/docker.sock`) to build user docker image. To do that, drone must mounts `docker.sock` to runner container, in addition, is it doable to add another option to .drone.yml which let user specify what volumes mounted to runner container? Something like below:  docker: - /host/dir:/container/dir:RO - /host/dir2:/container/dir2  How do you think?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file,"How about add volume ""/var/run/docker.sock:/var/run/docker.sock"" to the runner container Hi there, I'm looking at master HEAD and see that `docker` publish plugin does support to build & publish docker image for project. Two required options are: - docker_host - image From a end-user point of view, I think it's good if `docker_host` is optional because as a end-user, I'm not interested in where my image will to be built, should I? As I think, the drone CI/CD service should provides all equipment I want, rather than bring my own docker host to it. So to make user life easier, I think it's good if we make `docker_host` optional, by default, we'll use the default docker socket(`/var/run/docker.sock`) to build user docker image. To do that, drone must mounts `docker.sock` to runner container, in addition, is it doable to add another option to .drone.yml which let user specify what volumes mounted to runner container? Something like below:  docker: - /host/dir:/container/dir:RO - /host/dir2:/container/dir2  How do you think? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file",no-bug,0.9
2162,harness,https://github.com/harness/harness/issues/2162,Issues with Bitbucket Server/Stash usersnames containing '@', with option closed registration this is the output for admins when trying to add new users:  $ drone user add ida Successfully added user ida $ drone user add first.last@company.com client error 400: Invalid User Login   with option open registration usernames with '@' works fine. but users with '@' can't access drone through the cli.  drone version used: 0.8-rc3 Question posted in drone gitter channel earlier today.,other-file | other-file | other-file | documentation-file,Issues with Bitbucket Server/Stash usersnames containing '@'  with option closed registration this is the output for admins when trying to add new users:  $ drone user add ida Successfully added user ida $ drone user add first.last@company.com client error 400: Invalid User Login   with option open registration usernames with '@' works fine. but users with '@' can't access drone through the cli.  drone version used: 0.8-rc3 Question posted in drone gitter channel earlier today. other-file other-file other-file documentation-file,no-bug,0.7
514,harness,https://github.com/harness/harness/issues/514,drone/pkg/plugin/notify errors on dependency build,When running a 'make deps' before building drone I Attempting to build and compile drone from source on my CentOS 6.5 VM and get the following:  go get -u -t -v ./ drone (download) bitbucket.org/kardianos/osext (download) code.google.com/p/go.crypto (download) code.google.com/p/go.text (download) code.google.com/p/gomock (download) github.com/GeertJohan/go.rice (download) github.com/daaku/go.zipexe (download) github.com/andybons/hipchat (download) github.com/dchest/uniuri (download) github.com/docker/docker (download) github.com/drone/drone (download) github.com/go-sql-driver/mysql (download) github.com/mattn/go-sqlite3 (download) github.com/russross/meddler (download) github.com/fluffle/goirc (download) github.com/stvp/flowdock (download) launchpad.net/goyaml (download) code.google.com/p/go.net (download) github.com/bmizerany/pat (download) github.com/dchest/authcookie (download) github.com/dchest/passwordreset (download) github.com/drone/go-github (download) github.com/drone/go-bitbucket (download) github.com/plouc/go-gitlab-client (download) github.com/smartystreets/goconvey (download) gopkg.in/v1/yaml (download) github.com/drone/drone/pkg/plugin/notify drone/pkg/plugin/notify # github.com/drone/drone/pkg/plugin/notify ../github.com/drone/drone/pkg/plugin/notify/irc.go:29: c.SSL undefined (type *client.Conn has no field or method SSL) ../github.com/drone/drone/pkg/plugin/notify/irc.go:31: c.AddHandler undefined (type *client.Conn has no field or method AddHandler) ../github.com/drone/drone/pkg/plugin/notify/irc.go:36: too many arguments in call to c.Connect # drone/pkg/plugin/notify pkg/plugin/notify/irc.go:80: i.Connect undefined (type *IRC has no field or method Connect) make:  [deps] Error 2 ,other-file | other-file,drone/pkg/plugin/notify errors on dependency build When running a 'make deps' before building drone I Attempting to build and compile drone from source on my CentOS 6.5 VM and get the following:  go get -u -t -v ./ drone (download) bitbucket.org/kardianos/osext (download) code.google.com/p/go.crypto (download) code.google.com/p/go.text (download) code.google.com/p/gomock (download) github.com/GeertJohan/go.rice (download) github.com/daaku/go.zipexe (download) github.com/andybons/hipchat (download) github.com/dchest/uniuri (download) github.com/docker/docker (download) github.com/drone/drone (download) github.com/go-sql-driver/mysql (download) github.com/mattn/go-sqlite3 (download) github.com/russross/meddler (download) github.com/fluffle/goirc (download) github.com/stvp/flowdock (download) launchpad.net/goyaml (download) code.google.com/p/go.net (download) github.com/bmizerany/pat (download) github.com/dchest/authcookie (download) github.com/dchest/passwordreset (download) github.com/drone/go-github (download) github.com/drone/go-bitbucket (download) github.com/plouc/go-gitlab-client (download) github.com/smartystreets/goconvey (download) gopkg.in/v1/yaml (download) github.com/drone/drone/pkg/plugin/notify drone/pkg/plugin/notify # github.com/drone/drone/pkg/plugin/notify ../github.com/drone/drone/pkg/plugin/notify/irc.go:29: c.SSL undefined (type *client.Conn has no field or method SSL) ../github.com/drone/drone/pkg/plugin/notify/irc.go:31: c.AddHandler undefined (type *client.Conn has no field or method AddHandler) ../github.com/drone/drone/pkg/plugin/notify/irc.go:36: too many arguments in call to c.Connect # drone/pkg/plugin/notify pkg/plugin/notify/irc.go:80: i.Connect undefined (type *IRC has no field or method Connect) make:  [deps] Error 2  other-file other-file,no-bug,0.95
517,harness,https://github.com/harness/harness/issues/517,"Can't make drone: imports github.com/docker/docker/archive: cannot find package ""github.com/docker/docker/archive""","I cloned the drone repository, trying to run ""make deps"" command and getting this error: imports github.com/docker/docker/archive: cannot find package ""github.com/docker/docker/archive"" in any of: /usr/local/go/src/pkg/github.com/docker/docker/archive (from $GOROOT) /home/slava/go/src/github.com/docker/docker/archive (from $GOPATH)",other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file,"Can't make drone: imports github.com/docker/docker/archive: cannot find package ""github.com/docker/docker/archive"" I cloned the drone repository, trying to run ""make deps"" command and getting this error: imports github.com/docker/docker/archive: cannot find package ""github.com/docker/docker/archive"" in any of: /usr/local/go/src/pkg/github.com/docker/docker/archive (from $GOROOT) /home/slava/go/src/github.com/docker/docker/archive (from $GOPATH) other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file",no-bug,0.9
3239,harness,https://github.com/harness/harness/issues/3239,CockroachDB query of dashboard repos is relatively slow,"The following query statement is very slow to query in the crdb database ![image](https://user-images.githubusercontent.com/1785778/178662505-44ba6bed-f478-4f01-8aef-9bf8f23c2be6.png)  SELECT repo_id, repo_uid, repo_user_id, repo_namespace, repo_name, repo_slug, repo_scm, repo_clone_url, repo_ssh_url, repo_html_url, repo_active, repo_private, repo_visibility, repo_branch, repo_counter, repo_config, repo_timeout, repo_throttle, repo_trusted, repo_protected, repo_no_forks, repo_no_pulls, repo_cancel_pulls, repo_cancel_push, repo_cancel_running, repo_synced, repo_created, repo_updated, repo_version, repo_signer, repo_secret, build_id, build_repo_id, build_trigger, build_number, build_parent, build_status, build_error, build_event, build_action, build_link, build_timestamp, build_title, build_message, build_before, build_after, build_ref, build_source_repo, build_source, build_target, build_author, build_author_name, build_author_email, build_author_avatar, build_sender, build_params, build_cron, build_deploy, build_deploy_id, build_debug, build_started, build_finished, build_created, build_updated, build_version FROM repos LEFT JOIN builds ON build_id = ( SELECT DISTINCT ON (build_repo_id) build_id FROM builds WHERE builds.build_repo_id = repos.repo_id ORDER BY build_repo_id, build_id DESC ) INNER JOIN perms ON perms.perm_repo_uid = repos.repo_uid WHERE perms.perm_user_id = _ ORDER BY repo_slug ASC ",source-file | source-file | source-file | source-file,"CockroachDB query of dashboard repos is relatively slow The following query statement is very slow to query in the crdb database ![image](https://user-images.githubusercontent.com/1785778/178662505-44ba6bed-f478-4f01-8aef-9bf8f23c2be6.png)  SELECT repo_id, repo_uid, repo_user_id, repo_namespace, repo_name, repo_slug, repo_scm, repo_clone_url, repo_ssh_url, repo_html_url, repo_active, repo_private, repo_visibility, repo_branch, repo_counter, repo_config, repo_timeout, repo_throttle, repo_trusted, repo_protected, repo_no_forks, repo_no_pulls, repo_cancel_pulls, repo_cancel_push, repo_cancel_running, repo_synced, repo_created, repo_updated, repo_version, repo_signer, repo_secret, build_id, build_repo_id, build_trigger, build_number, build_parent, build_status, build_error, build_event, build_action, build_link, build_timestamp, build_title, build_message, build_before, build_after, build_ref, build_source_repo, build_source, build_target, build_author, build_author_name, build_author_email, build_author_avatar, build_sender, build_params, build_cron, build_deploy, build_deploy_id, build_debug, build_started, build_finished, build_created, build_updated, build_version FROM repos LEFT JOIN builds ON build_id = ( SELECT DISTINCT ON (build_repo_id) build_id FROM builds WHERE builds.build_repo_id = repos.repo_id ORDER BY build_repo_id, build_id DESC ) INNER JOIN perms ON perms.perm_repo_uid = repos.repo_uid WHERE perms.perm_user_id = _ ORDER BY repo_slug ASC  source-file source-file source-file source-file",no-bug,0.95
173,harness,https://github.com/harness/harness/issues/173,How to change the port of drone,"I would like to have drone run behind nginx, which is listening to port 80. My server also runs seafile, so i would like to change the port of drone, sothat I can proxypass correctly. How can I do this or is there a nice way to configure it with nginx? My config currently looks like this: https://paste.welcloud.de/show/SNukexZewNX5eAlcwM9f/",source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file,"How to change the port of drone I would like to have drone run behind nginx, which is listening to port 80. My server also runs seafile, so i would like to change the port of drone, sothat I can proxypass correctly. How can I do this or is there a nice way to configure it with nginx? My config currently looks like this: https://paste.welcloud.de/show/SNukexZewNX5eAlcwM9f/ source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file other-file other-file",no-bug,0.9
2962,harness,https://github.com/harness/harness/issues/2962,"missing property ""commands"" in .drone.yml file",<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io -->,source-file | source-file | source-file | source-file | source-file,"missing property ""commands"" in .drone.yml file <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> source-file source-file source-file source-file source-file",no-bug,0.9
2047,harness,https://github.com/harness/harness/issues/2047,Restarted build doesn't get correct {{build.link}},"The build only gets correct {{build.link}} when first run, after which {{build.link}} will use `localhost` instead the correct host url",source-file | test-file | test-file,"Restarted build doesn't get correct {{build.link}} The build only gets correct {{build.link}} when first run, after which {{build.link}} will use `localhost` instead the correct host url source-file test-file test-file",bug,0.85
2099,harness,https://github.com/harness/harness/issues/2099,Cant start drone with docker-compose.yml,"Hey, i want to integrate drone to my gogs instance. This is my docker-compose.yml:  version: '2' services: drone-server: image: drone/drone:0.7 ports: - 80:8000 volumes: - /var/lib/drone:/var/lib/drone/ restart: always environment: - DRONE_OPEN=true - DRONE_HOST=https://[SECRET] - DRONE_GOGS=true - DRONE_GOGS_URL=https://[SECRET] - DRONE_GOGS_GIT_USERNAME=[SECRET] - DRONE_GOGS_GIT_PASSWORD=[SECRET] - DRONE_SECRET=[SECRET] drone-agent: image: drone/drone:0.7 command: agent restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=ws://drone-server:8000/ws/broker - DRONE_SECRET=[SECRET]  But im recieving the following error when i run `sudo docker-compose up` ![unbenannt](https://user-images.githubusercontent.com/18403881/27763789-a7842c58-5e8a-11e7-89a9-54f65e6f4660.PNG) This repeats about 30 times Is my docker-compose wrong in some ways? or is something missing? Thank you guys",source-file,"Cant start drone with docker-compose.yml Hey, i want to integrate drone to my gogs instance. This is my docker-compose.yml:  version: '2' services: drone-server: image: drone/drone:0.7 ports: - 80:8000 volumes: - /var/lib/drone:/var/lib/drone/ restart: always environment: - DRONE_OPEN=true - DRONE_HOST=https://[SECRET] - DRONE_GOGS=true - DRONE_GOGS_URL=https://[SECRET] - DRONE_GOGS_GIT_USERNAME=[SECRET] - DRONE_GOGS_GIT_PASSWORD=[SECRET] - DRONE_SECRET=[SECRET] drone-agent: image: drone/drone:0.7 command: agent restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=ws://drone-server:8000/ws/broker - DRONE_SECRET=[SECRET]  But im recieving the following error when i run `sudo docker-compose up` ![unbenannt](https://user-images.githubusercontent.com/18403881/27763789-a7842c58-5e8a-11e7-89a9-54f65e6f4660.PNG) This repeats about 30 times Is my docker-compose wrong in some ways? or is something missing? Thank you guys source-file",no-bug,0.9
602,harness,https://github.com/harness/harness/issues/602,Gravatar for commit author - BitBucket,"There's no gravatar in commits for BitBucket. It seems to be assumed that `author` from BitBucket post-commit hook is email of author. It's not, it's just username. Email could be obtained by parsing `raw_author` field. [1] There's also no `RawAuthor` field in `Commit` struct in drone/go-bitbucket [2], which would be needed to get access to `raw_author` field from BitBucket. Are there any disadvantages of this solution? If not I'll gladly make the PR :) [1] https://confluence.atlassian.com/display/BITBUCKET/POST+hook+management [2] https://github.com/drone/go-bitbucket/blob/master/bitbucket/brokers.go#L221",other-file | other-file | source-file | other-file,"Gravatar for commit author - BitBucket There's no gravatar in commits for BitBucket. It seems to be assumed that `author` from BitBucket post-commit hook is email of author. It's not, it's just username. Email could be obtained by parsing `raw_author` field. [1] There's also no `RawAuthor` field in `Commit` struct in drone/go-bitbucket [2], which would be needed to get access to `raw_author` field from BitBucket. Are there any disadvantages of this solution? If not I'll gladly make the PR :) [1] https://confluence.atlassian.com/display/BITBUCKET/POST+hook+management [2] https://github.com/drone/go-bitbucket/blob/master/bitbucket/brokers.go#L221 other-file other-file source-file other-file",no-bug,0.8
495,harness,https://github.com/harness/harness/issues/495,[exp] Gitlab Auth issue,"since last commits, i can't auth via gitlab, got NotFound Ok, go to `server/main.go` and add handler:  go goji.Post(""/api/auth/:host"", handler.GetLogin)  Launch drone, and test: Internal Error  @iMac  drone rvm:(ruby-2.1.3) git:(exp)  ./debian/drone/usr/local/bin/droned --config=./drone.conf 2014/10/01 19:38:16.206024 Starting Goji on [::]:8000 2014/10/01 19:40:23.911282 [iMac-Kirill/224rnGM5Au-000001] Started POST ""/api/auth/git.teobit.ru"" from 127.0.0.1:58796 2014/10/01 19:40:24.265804 [iMac-Kirill/224rnGM5Au-000001] Returning 400 in 354.500938ms 2014/10/01 19:40:24.635285 [iMac-Kirill/224rnGM5Au-000002] Started GET ""/favicon.ico"" from 127.0.0.1:58796 2014/10/01 19:40:24.635454 [iMac-Kirill/224rnGM5Au-000002] Returning 200 in 142.609us 2014/10/01 19:45:25.809654 [iMac-Kirill/224rnGM5Au-000003] Started POST ""/api/auth/git.teobit.ru"" from 127.0.0.1:58796 2014/10/01 19:45:26.090742 [iMac-Kirill/224rnGM5Au-000003] Returning 400 in 281.071105ms 2014/10/01 19:45:26.497144 [iMac-Kirill/224rnGM5Au-000004] Started GET ""/favicon.ico"" from 127.0.0.1:58796 2014/10/01 19:45:26.497312 [iMac-Kirill/224rnGM5Au-000004] Returning 200 in 145.985us 2014/10/01 19:45:28.678011 [iMac-Kirill/224rnGM5Au-000005] Started GET ""/gitlab"" from 127.0.0.1:58796 2014/10/01 19:45:28.678176 [iMac-Kirill/224rnGM5Au-000005] Returning 200 in 139.485us 2014/10/01 19:45:28.861238 [iMac-Kirill/224rnGM5Au-000006] Started GET ""/api/user"" from 127.0.0.1:58796 invalid token 2014/10/01 19:45:28.861321 [iMac-Kirill/224rnGM5Au-000006] Returning 401 in 64.215us 2014/10/01 19:45:29.041267 [iMac-Kirill/224rnGM5Au-000007] Started GET ""/api/stream/user"" from 127.0.0.1:63467 2014/10/01 19:45:29.137947 [iMac-Kirill/224rnGM5Au-000008] Started GET ""/favicon.ico"" from 127.0.0.1:58796 2014/10/01 19:45:29.138098 [iMac-Kirill/224rnGM5Au-000008] Returning 200 in 124.012us 2014/10/01 19:45:30.498867 [iMac-Kirill/224rnGM5Au-000009] Started POST ""/api/auth/gitlab.com"" from 127.0.0.1:58796 2014/10/01 19:45:31.000913 [iMac-Kirill/224rnGM5Au-000009] panic: interface conversion: interface is nil, not capability.Capability /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/recoverer.go:24 (0x42cd86b) func.006: debug.PrintStack() /usr/local/Cellar/go/1.3.2/libexec/src/pkg/runtime/panic.c:248 (0x40cbdfd) panic: runtimenewstackcall(d->fn, (byte*)d->args, d->siz); /usr/local/Cellar/go/1.3.2/libexec/src/pkg/runtime/iface.goc:292 (0x40dea10) assertE2Tret: runtimepanic(err); /usr/local/Cellar/go/1.3.2/libexec/src/pkg/runtime/iface.goc:280 (0x40de990) assertE2T: assertE2Tret(t, e, (byte*)&retbase); /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/capability/context.go:31 (0x42af94c) FromContext: return c.Value(reqkey).(Capability) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/capability/capability.go:22 (0x42af871) Enabled: return FromContext(c).Get(key) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/handler/login.go:51 (0x415295d) GetLogin: if capability.Enabled(ctx, capability.Registration) == false { /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/web.go:127 (0x416e894) HandlerFunc.ServeHTTPC: h(c, w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/router.go:210 (0x416d5a9) routeMachine.route: rm.routes[si].handler.ServeHTTPC(*c, w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/router.go:250 (0x416d91a) (*router).route: methods, ok := rm.route(c, w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware.go:94 (0x416e96f) func.002: router.route(&cs.C, w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/middleware/user.go:21 (0x415c819) func.005: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/middleware/header.go:25 (0x415b9bf) func.001: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/main.go:190 (0x40bd6d5) func.002: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/options.go:70 (0x42cd7ab) func.004: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/recoverer.go:29 (0x42cda29) func.007: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/logger.go:28 (0x42cd4a0) func.002: h.ServeHTTP(lw, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/request_id.go:68 (0x42cdd5f) func.008: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware.go:51 (0x4169b9f) (*cStack).ServeHTTP: s.m.ServeHTTP(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/mux.go:77 (0x416ad1f) (*Mux).ServeHTTP: stack.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1511 (0x412ca83) (*ServeMux).ServeHTTP: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1673 (0x412d3af) serverHandler.ServeHTTP: handler.ServeHTTP(rw, req) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1174 (0x412ae2e) (*conn).serve: serverHandler{c.server}.ServeHTTP(w, w.req) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/runtime/proc.c:1445 (0x40d0620) goexit: runtimegoexit(void) ",other-file | other-file | other-file | source-file | documentation-file | other-file | other-file,"[exp] Gitlab Auth issue since last commits, i can't auth via gitlab, got NotFound Ok, go to `server/main.go` and add handler:  go goji.Post(""/api/auth/:host"", handler.GetLogin)  Launch drone, and test: Internal Error  @iMac  drone rvm:(ruby-2.1.3) git:(exp)  ./debian/drone/usr/local/bin/droned --config=./drone.conf 2014/10/01 19:38:16.206024 Starting Goji on [::]:8000 2014/10/01 19:40:23.911282 [iMac-Kirill/224rnGM5Au-000001] Started POST ""/api/auth/git.teobit.ru"" from 127.0.0.1:58796 2014/10/01 19:40:24.265804 [iMac-Kirill/224rnGM5Au-000001] Returning 400 in 354.500938ms 2014/10/01 19:40:24.635285 [iMac-Kirill/224rnGM5Au-000002] Started GET ""/favicon.ico"" from 127.0.0.1:58796 2014/10/01 19:40:24.635454 [iMac-Kirill/224rnGM5Au-000002] Returning 200 in 142.609us 2014/10/01 19:45:25.809654 [iMac-Kirill/224rnGM5Au-000003] Started POST ""/api/auth/git.teobit.ru"" from 127.0.0.1:58796 2014/10/01 19:45:26.090742 [iMac-Kirill/224rnGM5Au-000003] Returning 400 in 281.071105ms 2014/10/01 19:45:26.497144 [iMac-Kirill/224rnGM5Au-000004] Started GET ""/favicon.ico"" from 127.0.0.1:58796 2014/10/01 19:45:26.497312 [iMac-Kirill/224rnGM5Au-000004] Returning 200 in 145.985us 2014/10/01 19:45:28.678011 [iMac-Kirill/224rnGM5Au-000005] Started GET ""/gitlab"" from 127.0.0.1:58796 2014/10/01 19:45:28.678176 [iMac-Kirill/224rnGM5Au-000005] Returning 200 in 139.485us 2014/10/01 19:45:28.861238 [iMac-Kirill/224rnGM5Au-000006] Started GET ""/api/user"" from 127.0.0.1:58796 invalid token 2014/10/01 19:45:28.861321 [iMac-Kirill/224rnGM5Au-000006] Returning 401 in 64.215us 2014/10/01 19:45:29.041267 [iMac-Kirill/224rnGM5Au-000007] Started GET ""/api/stream/user"" from 127.0.0.1:63467 2014/10/01 19:45:29.137947 [iMac-Kirill/224rnGM5Au-000008] Started GET ""/favicon.ico"" from 127.0.0.1:58796 2014/10/01 19:45:29.138098 [iMac-Kirill/224rnGM5Au-000008] Returning 200 in 124.012us 2014/10/01 19:45:30.498867 [iMac-Kirill/224rnGM5Au-000009] Started POST ""/api/auth/gitlab.com"" from 127.0.0.1:58796 2014/10/01 19:45:31.000913 [iMac-Kirill/224rnGM5Au-000009] panic: interface conversion: interface is nil, not capability.Capability /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/recoverer.go:24 (0x42cd86b) func.006: debug.PrintStack() /usr/local/Cellar/go/1.3.2/libexec/src/pkg/runtime/panic.c:248 (0x40cbdfd) panic: runtimenewstackcall(d->fn, (byte*)d->args, d->siz); /usr/local/Cellar/go/1.3.2/libexec/src/pkg/runtime/iface.goc:292 (0x40dea10) assertE2Tret: runtimepanic(err); /usr/local/Cellar/go/1.3.2/libexec/src/pkg/runtime/iface.goc:280 (0x40de990) assertE2T: assertE2Tret(t, e, (byte*)&retbase); /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/capability/context.go:31 (0x42af94c) FromContext: return c.Value(reqkey).(Capability) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/capability/capability.go:22 (0x42af871) Enabled: return FromContext(c).Get(key) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/handler/login.go:51 (0x415295d) GetLogin: if capability.Enabled(ctx, capability.Registration) == false { /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/web.go:127 (0x416e894) HandlerFunc.ServeHTTPC: h(c, w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/router.go:210 (0x416d5a9) routeMachine.route: rm.routes[si].handler.ServeHTTPC(*c, w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/router.go:250 (0x416d91a) (*router).route: methods, ok := rm.route(c, w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware.go:94 (0x416e96f) func.002: router.route(&cs.C, w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/middleware/user.go:21 (0x415c819) func.005: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/middleware/header.go:25 (0x415b9bf) func.001: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/drone/drone/server/main.go:190 (0x40bd6d5) func.002: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/options.go:70 (0x42cd7ab) func.004: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/recoverer.go:29 (0x42cda29) func.007: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/logger.go:28 (0x42cd4a0) func.002: h.ServeHTTP(lw, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware/request_id.go:68 (0x42cdd5f) func.008: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1235 (0x412b2b0) HandlerFunc.ServeHTTP: f(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/middleware.go:51 (0x4169b9f) (*cStack).ServeHTTP: s.m.ServeHTTP(w, r) /Users/bugagazavr/Documents/Go/src/github.com/zenazn/goji/web/mux.go:77 (0x416ad1f) (*Mux).ServeHTTP: stack.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1511 (0x412ca83) (*ServeMux).ServeHTTP: h.ServeHTTP(w, r) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1673 (0x412d3af) serverHandler.ServeHTTP: handler.ServeHTTP(rw, req) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/net/http/server.go:1174 (0x412ae2e) (*conn).serve: serverHandler{c.server}.ServeHTTP(w, w.req) /usr/local/Cellar/go/1.3.2/libexec/src/pkg/runtime/proc.c:1445 (0x40d0620) goexit: runtimegoexit(void)  other-file other-file other-file source-file documentation-file other-file other-file",bug,0.95
462,harness,https://github.com/harness/harness/issues/462,GitHub Client setting not saved,"Having cloned yesterday, I have it running from a vagrant up. The first admin user does not correspond to my github id, so I go to admin settings and save my actual github client id, then it says the setting has been saved, but when I return the github client id is still the drone login user id. To avoid this, I set up a new drone user corresponding to my github client id and gov it admin. This time I set the github password & wonder whether that has been saved (because of the former & because of password concealment). When I try to create a new drone repository and link to my github account, I see a 404 from github.com . Perhaps a 404 is not an indication that drone has the wrong password for my github account, perhaps it is instead a result of running from localhost. How do I start to debug this?",other-file | other-file | source-file | documentation-file,"GitHub Client setting not saved Having cloned yesterday, I have it running from a vagrant up. The first admin user does not correspond to my github id, so I go to admin settings and save my actual github client id, then it says the setting has been saved, but when I return the github client id is still the drone login user id. To avoid this, I set up a new drone user corresponding to my github client id and gov it admin. This time I set the github password & wonder whether that has been saved (because of the former & because of password concealment). When I try to create a new drone repository and link to my github account, I see a 404 from github.com . Perhaps a 404 is not an indication that drone has the wrong password for my github account, perhaps it is instead a result of running from localhost. How do I start to debug this? other-file other-file source-file documentation-file",no-bug,0.9
919,harness,https://github.com/harness/harness/issues/919,drone start before mysql,"i have drone configured with mysql. maybe upstart starts drone before mysql. the upstart scripts needs to wait for mysql BUT ONLY if it's used. it works with `service drone start` after the server started.  panic: Could not get DB version: dial tcp 127.0.0.1:3306: connection refused goroutine 16 [running]: runtime.panic(0xab3d40, 0xc2081275e0) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 github.com/drone/drone/server/datastore/database.MustConnect(0xc2081272c0, 0x5, 0xc2081284e0, 0x1e, 0x0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:52 +0x8a main.main() /var/cache/drone/src/github.com/drone/drone/server/main.go:104 +0x274 goroutine 19 [finalizer wait]: runtime.park(0x4a8570, 0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 runtime.parkunlock(0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 22 [syscall]: os/signal.loop() /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e created by os/signal.init1 /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 goroutine 24 [chan receive]: database/sql.(*DB).connectionOpener(0xc208060480) /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 created by database/sql.Open /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c starting build 2015/03/16 18:08:55 x509: certificate is valid for grml, not localhost 2015/03/16 18:08:56 subscription's close channel received message panic: Could not get DB version: dial tcp 127.0.0.1:3306: connection refused goroutine 16 [running]: runtime.panic(0xab3d40, 0xc208127540) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 github.com/drone/drone/server/datastore/database.MustConnect(0xc208127220, 0x5, 0xc208128400, 0x1e, 0x0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:52 +0x8a main.main() /var/cache/drone/src/github.com/drone/drone/server/main.go:104 +0x274 goroutine 19 [finalizer wait]: runtime.park(0x4a8570, 0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 runtime.parkunlock(0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 22 [syscall]: os/signal.loop() /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e created by os/signal.init1 /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 goroutine 24 [chan receive]: database/sql.(*DB).connectionOpener(0xc208060480) /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 created by database/sql.Open /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c ",source-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file,"drone start before mysql i have drone configured with mysql. maybe upstart starts drone before mysql. the upstart scripts needs to wait for mysql BUT ONLY if it's used. it works with `service drone start` after the server started.  panic: Could not get DB version: dial tcp 127.0.0.1:3306: connection refused goroutine 16 [running]: runtime.panic(0xab3d40, 0xc2081275e0) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 github.com/drone/drone/server/datastore/database.MustConnect(0xc2081272c0, 0x5, 0xc2081284e0, 0x1e, 0x0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:52 +0x8a main.main() /var/cache/drone/src/github.com/drone/drone/server/main.go:104 +0x274 goroutine 19 [finalizer wait]: runtime.park(0x4a8570, 0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 runtime.parkunlock(0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 22 [syscall]: os/signal.loop() /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e created by os/signal.init1 /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 goroutine 24 [chan receive]: database/sql.(*DB).connectionOpener(0xc208060480) /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 created by database/sql.Open /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c starting build 2015/03/16 18:08:55 x509: certificate is valid for grml, not localhost 2015/03/16 18:08:56 subscription's close channel received message panic: Could not get DB version: dial tcp 127.0.0.1:3306: connection refused goroutine 16 [running]: runtime.panic(0xab3d40, 0xc208127540) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 github.com/drone/drone/server/datastore/database.MustConnect(0xc208127220, 0x5, 0xc208128400, 0x1e, 0x0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:52 +0x8a main.main() /var/cache/drone/src/github.com/drone/drone/server/main.go:104 +0x274 goroutine 19 [finalizer wait]: runtime.park(0x4a8570, 0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 runtime.parkunlock(0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 22 [syscall]: os/signal.loop() /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e created by os/signal.init1 /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 goroutine 24 [chan receive]: database/sql.(*DB).connectionOpener(0xc208060480) /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 created by database/sql.Open /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c  source-file source-file other-file source-file other-file other-file other-file other-file",no-bug,0.9
822,harness,https://github.com/harness/harness/issues/822,Drone project Dockerfile currently does not build,"It returns the following error during make build:  > Running in 8e1e34b89ff6 fatal: Not a git repository (or any of the parent directories): .git mkdir -p packaging/output mkdir -p packaging/root/usr/local/bin go build -o packaging/root/usr/local/bin/drone -ldflags ""-X main.revision -X main.version 0.3.0-alpha"" github.com/drone/drone/cli # github.com/drone/drone/cli usage: 6l [options] main.6 -1 use alternate profiling code -8 assume 64-bit addresses -B info define ELF NT_GNU_BUILD_ID note -D addr  make:  [build] Error 2 ",other-file | container-file | other-file | container-file | other-file,"Drone project Dockerfile currently does not build It returns the following error during make build:  > Running in 8e1e34b89ff6 fatal: Not a git repository (or any of the parent directories): .git mkdir -p packaging/output mkdir -p packaging/root/usr/local/bin go build -o packaging/root/usr/local/bin/drone -ldflags ""-X main.revision -X main.version 0.3.0-alpha"" github.com/drone/drone/cli # github.com/drone/drone/cli usage: 6l [options] main.6 -1 use alternate profiling code -8 assume 64-bit addresses -B info define ELF NT_GNU_BUILD_ID note -D addr  make:  [build] Error 2  other-file container-file other-file container-file other-file",no-bug,0.9
699,harness,https://github.com/harness/harness/issues/699,Deploy to multiple targets of the same,We're deploying via git using the new when: branch:master but would like to deploy via git to other endpoints for other branches. I could not find any documentation and looking at the code it seems like there could be only one deploy target per service. We're using the following code:  deploy: git: target: OMITTED branch: master force: false when: branch: master  and would like something like:  deploy: git: target: A DIFFERENT OMITTED branch: develop force: false when: branch: develop  for the same project. Is this possible?,other-file,Deploy to multiple targets of the same We're deploying via git using the new when: branch:master but would like to deploy via git to other endpoints for other branches. I could not find any documentation and looking at the code it seems like there could be only one deploy target per service. We're using the following code:  deploy: git: target: OMITTED branch: master force: false when: branch: master  and would like something like:  deploy: git: target: A DIFFERENT OMITTED branch: develop force: false when: branch: develop  for the same project. Is this possible? other-file,no-bug,0.9
2057,harness,https://github.com/harness/harness/issues/2057,[Feature Request] Be able to set a starting build number,"It would be great to be able to set the starting build number. Use case: When you migrate from another build system or even upgrade drone sometimes you want to set the build number to the last of the other system. Seems like in the settings or enable location we could add a starting build number. @bradrydzewski If you have any ideas around what's the best way to handle this, I'm down to take a stab at it.",source-file,"[Feature Request] Be able to set a starting build number It would be great to be able to set the starting build number. Use case: When you migrate from another build system or even upgrade drone sometimes you want to set the build number to the last of the other system. Seems like in the settings or enable location we could add a starting build number. @bradrydzewski If you have any ideas around what's the best way to handle this, I'm down to take a stab at it. source-file",no-bug,0.95
246,harness,https://github.com/harness/harness/issues/246,random errors,"Drone latest ( 0c9a765956fa7a42de5fa704b555b5af26928643 ) Sometimes i got random success, without any output in build log. Via standalone gitlab ![2014-04-06 20-11-55 git teobit ruteobitteobit 7161b8](https://cloud.githubusercontent.com/assets/683590/2625718/7528c346-bda6-11e3-9d38-13b117b4410b.png)",source-file | other-file | test-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | source-file | other-file | source-file | documentation-file | other-file,"random errors Drone latest ( 0c9a765956fa7a42de5fa704b555b5af26928643 ) Sometimes i got random success, without any output in build log. Via standalone gitlab ![2014-04-06 20-11-55 git teobit ruteobitteobit 7161b8](https://cloud.githubusercontent.com/assets/683590/2625718/7528c346-bda6-11e3-9d38-13b117b4410b.png) source-file other-file test-file other-file other-file other-file source-file other-file other-file other-file documentation-file source-file other-file source-file documentation-file other-file",no-bug,0.7
2974,harness,https://github.com/harness/harness/issues/2974,cannot get secret if my k8s runner is not deployed in the specific namespace other than 'default',"I deploy k8s not in the namespace 'default', how can i configure secrets to get the secrets. the command i use is :  drone plugins secret get --repo infrastructure/queue docker-key username  the output is:  kubernetes api: Failure 403 secrets ""docker-key"" is forbidden: User ""system:serviceaccount:cicd:default"" cannot get resource ""secrets"" in API group """" in the namespace ""default"" ",source-file | source-file | source-file,"cannot get secret if my k8s runner is not deployed in the specific namespace other than 'default' I deploy k8s not in the namespace 'default', how can i configure secrets to get the secrets. the command i use is :  drone plugins secret get --repo infrastructure/queue docker-key username  the output is:  kubernetes api: Failure 403 secrets ""docker-key"" is forbidden: User ""system:serviceaccount:cicd:default"" cannot get resource ""secrets"" in API group """" in the namespace ""default""  source-file source-file source-file",no-bug,0.9
310,harness,https://github.com/harness/harness/issues/310,"Where to post feature requests: GitHub, Uservoice or Google Groups?","Is the Uservoice http://drone.uservoice.com official? Where to put the feature requests / PR proposals? I propose: - every single issue (bug, feature request / PR proposal) be gathered here on GitHub and tagged accordingly. Easier to search for things on a single place. - the CONTRIBUTING be made clearer. Currently it says: > We recommend discussing your plans on the mailing list before starting to code [links to Google code] But also: > Any significant improvement should be documented as a GitHub issue before anybody starts working on it. What is the difference between both places?",other-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file,"Where to post feature requests: GitHub, Uservoice or Google Groups? Is the Uservoice http://drone.uservoice.com official? Where to put the feature requests / PR proposals? I propose: - every single issue (bug, feature request / PR proposal) be gathered here on GitHub and tagged accordingly. Easier to search for things on a single place. - the CONTRIBUTING be made clearer. Currently it says: > We recommend discussing your plans on the mailing list before starting to code [links to Google code] But also: > Any significant improvement should be documented as a GitHub issue before anybody starts working on it. What is the difference between both places? other-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file other-file other-file source-file documentation-file other-file other-file other-file other-file other-file",no-bug,0.95
3501,harness,https://github.com/harness/harness/issues/3501,Drone use PAT owner account for git commit,"Hi @bradrydzewski, I followed your documentation to set up a machine user on Github https://docs.drone.io/pipeline/docker/syntax/cloning/auth/ If I understood it correctly it should clone the repository and allow also for `git commit` and `git push` using the same bot account within the pipelines. So I set up both variables, cloning is probably done through PAT (I can see the activity on this token) but pushing (in my case I want to push a commit and create a tag) is still done by other account - **the one that did the commit before**. Any way to force git user on pipeline runtime? I can't use plugin here - I need to do this directly from the CLI.",source-file | source-file | source-file | source-file | source-file,"Drone use PAT owner account for git commit Hi @bradrydzewski, I followed your documentation to set up a machine user on Github https://docs.drone.io/pipeline/docker/syntax/cloning/auth/ If I understood it correctly it should clone the repository and allow also for `git commit` and `git push` using the same bot account within the pipelines. So I set up both variables, cloning is probably done through PAT (I can see the activity on this token) but pushing (in my case I want to push a commit and create a tag) is still done by other account - **the one that did the commit before**. Any way to force git user on pipeline runtime? I can't use plugin here - I need to do this directly from the CLI. source-file source-file source-file source-file source-file",no-bug,0.9
1147,harness,https://github.com/harness/harness/issues/1147,Bitbucket Oauth2 integration,"Bitbucket now supports oauth2 (including cloning a repository with an access_token) which is really good news. These tokens expire after just 1 hour before needing to be refreshed, which is probably also good news from a security perspective, however, we need to figure out how this impacts our overall system design. First, and most importantly, we need to verify that multiple valid access tokens can exist at the same time for a single user. Or stated another way, refreshing an access token doesn't revoke all existing, un-expired access token. **EDIT** I have verified that this won't be an issue! Creating a new token **does not** invalidate existing tokens Second, we need to figure out what happens if we dispatch a job and the token expires before the job is started. Our workers don't have access to the database to refresh and persist a new access token. Ideally Bitbucket would have offline tokens that don't require refresh (like Google, GitHub, etc), but I didn't see an option in their docs. If multiple access tokens can exist simultaneously, however, this is much less of an issue since we can just force refresh before scheduling a job. If a job takes longer than an hour, this is probably still an issue  so we'll need to find a way around it.",source-file | source-file | source-file | source-file | source-file | test-file | other-file | documentation-file | other-file | other-file | documentation-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file,"Bitbucket Oauth2 integration Bitbucket now supports oauth2 (including cloning a repository with an access_token) which is really good news. These tokens expire after just 1 hour before needing to be refreshed, which is probably also good news from a security perspective, however, we need to figure out how this impacts our overall system design. First, and most importantly, we need to verify that multiple valid access tokens can exist at the same time for a single user. Or stated another way, refreshing an access token doesn't revoke all existing, un-expired access token. **EDIT** I have verified that this won't be an issue! Creating a new token **does not** invalidate existing tokens Second, we need to figure out what happens if we dispatch a job and the token expires before the job is started. Our workers don't have access to the database to refresh and persist a new access token. Ideally Bitbucket would have offline tokens that don't require refresh (like Google, GitHub, etc), but I didn't see an option in their docs. If multiple access tokens can exist simultaneously, however, this is much less of an issue since we can just force refresh before scheduling a job. If a job takes longer than an hour, this is probably still an issue  so we'll need to find a way around it. source-file source-file source-file source-file source-file test-file other-file documentation-file other-file other-file documentation-file source-file source-file source-file test-file test-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file test-file source-file test-file source-file test-file source-file source-file test-file source-file test-file source-file source-file test-file source-file source-file source-file test-file source-file test-file source-file",no-bug,0.9
2651,harness,https://github.com/harness/harness/issues/2651,Allow user to run a image with a specific user at a certain step.,"I use Drone CI Service to start gradle image to build software. But gradle image run as gradle user insted of root user by default. However, only the root user has write access in the /drone/src directory. I spent an afternoon trying to solve this problem, finally I switched to openjdk:latest image. Is there a way to run as specific user with a image in some step, like this:  steps: - name: build user: root #specific user image: gradle:latest commands: - ./gradle assemble  [This link](https://github.com/keeganwitt/docker-gradle/issues/93) has more information if you need it.",documentation-file | other-file | other-file | source-file,"Allow user to run a image with a specific user at a certain step. I use Drone CI Service to start gradle image to build software. But gradle image run as gradle user insted of root user by default. However, only the root user has write access in the /drone/src directory. I spent an afternoon trying to solve this problem, finally I switched to openjdk:latest image. Is there a way to run as specific user with a image in some step, like this:  steps: - name: build user: root #specific user image: gradle:latest commands: - ./gradle assemble  [This link](https://github.com/keeganwitt/docker-gradle/issues/93) has more information if you need it. documentation-file other-file other-file source-file",no-bug,0.9
482,harness,https://github.com/harness/harness/issues/482,A way to change the text that appears in Pull Requests,"When a build fails/succeeds there is a small piece of text that appears next to _All is well_: ![image](https://cloud.githubusercontent.com/assets/1631166/4389512/d01faf46-43f5-11e4-9167-c8bb284d8599.png) It could be great if one could change it to custom text or to the domain where it has actually build. If you want to have the name drone appear in it (which is perfectly acceptable in my opinion) it could also be something like: *build with drone on <ci.server.hostname>"". PS: This is really an awesome tool!",other-file,"A way to change the text that appears in Pull Requests When a build fails/succeeds there is a small piece of text that appears next to _All is well_: ![image](https://cloud.githubusercontent.com/assets/1631166/4389512/d01faf46-43f5-11e4-9167-c8bb284d8599.png) It could be great if one could change it to custom text or to the domain where it has actually build. If you want to have the name drone appear in it (which is perfectly acceptable in my opinion) it could also be something like: *build with drone on <ci.server.hostname>"". PS: This is really an awesome tool! other-file",no-bug,0.9
2036,harness,https://github.com/harness/harness/issues/2036,Revisit Repository Syncing,"Early versions of Drone would sync the user repositories and permissions with the database. This was slow and was problematic for certain providers (Bitbucket) which had certain API restrictions. I therefore decided in 0.5 to remove the sync and fetch the repository list and permissions and cache in ram. Most Drone users probably think this works quite well, however, there have been some unforseen issues with individuals that have access to thousands of repositories: 1. Drone is required to make many (20+) api calls for 1000+ repositories, which can be slow 2. In addition to being slow it can cause users to max out their API limits 3. The implementation requires the IN clause which is limited to the number of input parameters There have also been some technology improvements that can simplify syncing. Namely the fact that Postgres (as well as other vendors) now all support the `INSERT IGNORE` syntax. Bitbucket and Bitbucket server are still a problem. I believe we can solve this by storing a TTL for the individual repository permissions. When the TTL expires we make an API call. This prevents us from having to update thousands of rows of permissions on sync. This should also address some UX issues like https://github.com/drone/drone-ui/issues/79",source-file | test-file,"Revisit Repository Syncing Early versions of Drone would sync the user repositories and permissions with the database. This was slow and was problematic for certain providers (Bitbucket) which had certain API restrictions. I therefore decided in 0.5 to remove the sync and fetch the repository list and permissions and cache in ram. Most Drone users probably think this works quite well, however, there have been some unforseen issues with individuals that have access to thousands of repositories: 1. Drone is required to make many (20+) api calls for 1000+ repositories, which can be slow 2. In addition to being slow it can cause users to max out their API limits 3. The implementation requires the IN clause which is limited to the number of input parameters There have also been some technology improvements that can simplify syncing. Namely the fact that Postgres (as well as other vendors) now all support the `INSERT IGNORE` syntax. Bitbucket and Bitbucket server are still a problem. I believe we can solve this by storing a TTL for the individual repository permissions. When the TTL expires we make an API call. This prevents us from having to update thousands of rows of permissions on sync. This should also address some UX issues like https://github.com/drone/drone-ui/issues/79 source-file test-file",no-bug,0.9
479,harness,https://github.com/harness/harness/issues/479,Docker publish failing (0.2),"When attempting to use the docker publish plugin drone errors out before it even installs docker into the build container (logs below). Is there a known work-around for this? I tried upgrading to the exp branch but it appears that the docker publish functionality has not yet made it there.  $ sudo apt-get install apt-transport-https Reading package lists Building dependency tree Reading state information The following extra packages will be installed: libapt-pkg4.12 The following packages will be upgraded: apt-transport-https libapt-pkg4.12 2 upgraded, 0 newly installed, 0 to remove and 9 not upgraded. Need to get 953 kB of archives. After this operation, 0 B of additional disk space will be used. Err http://archive.ubuntu.com/ubuntu/ precise-updates/main libapt-pkg4.12 amd64 0.8.16~exp12ubuntu10.16 404 Not Found [IP: 91.189.91.15 80] Err http://archive.ubuntu.com/ubuntu/ precise-updates/main apt-transport-https amd64 0.8.16~exp12ubuntu10.16 404 Not Found [IP: 91.189.91.15 80] Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/a/apt/libapt-pkg4.12_0.8.16~exp12ubuntu10.16_amd64.deb 404 Not Found [IP: 91.189.91.15 80]   ",other-file | source-file | other-file | documentation-file | other-file | source-file | documentation-file | other-file | other-file,"Docker publish failing (0.2) When attempting to use the docker publish plugin drone errors out before it even installs docker into the build container (logs below). Is there a known work-around for this? I tried upgrading to the exp branch but it appears that the docker publish functionality has not yet made it there.  $ sudo apt-get install apt-transport-https Reading package lists Building dependency tree Reading state information The following extra packages will be installed: libapt-pkg4.12 The following packages will be upgraded: apt-transport-https libapt-pkg4.12 2 upgraded, 0 newly installed, 0 to remove and 9 not upgraded. Need to get 953 kB of archives. After this operation, 0 B of additional disk space will be used. Err http://archive.ubuntu.com/ubuntu/ precise-updates/main libapt-pkg4.12 amd64 0.8.16~exp12ubuntu10.16 404 Not Found [IP: 91.189.91.15 80] Err http://archive.ubuntu.com/ubuntu/ precise-updates/main apt-transport-https amd64 0.8.16~exp12ubuntu10.16 404 Not Found [IP: 91.189.91.15 80] Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/a/apt/libapt-pkg4.12_0.8.16~exp12ubuntu10.16_amd64.deb 404 Not Found [IP: 91.189.91.15 80]    other-file source-file other-file documentation-file other-file source-file documentation-file other-file other-file",no-bug,0.95
346,harness,https://github.com/harness/harness/issues/346,connection from php to mysql failed,"Hey, i have builded the docker images from source directly - bradrydzewski/php:5.3 - bradrydzewski/mysql:5.5 the php could not connect to the mysql. i added ""DEBIAN_FRONTEND=noninteractive apt-get install -y socat"" to both dockerfiles and rebuild them (the documentation suggested installing _socat_ in the container to make sure they can expose the ports but it also cannot connect. additional: i could build the mysql container after i added  rm /sbin/initctl  before the _ln -s_ i also had to remove the _drop database_ command because the db was missing. is there any way to test this and get it up and running? br Dominik",source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,"connection from php to mysql failed Hey, i have builded the docker images from source directly - bradrydzewski/php:5.3 - bradrydzewski/mysql:5.5 the php could not connect to the mysql. i added ""DEBIAN_FRONTEND=noninteractive apt-get install -y socat"" to both dockerfiles and rebuild them (the documentation suggested installing _socat_ in the container to make sure they can expose the ports but it also cannot connect. additional: i could build the mysql container after i added  rm /sbin/initctl  before the _ln -s_ i also had to remove the _drop database_ command because the db was missing. is there any way to test this and get it up and running? br Dominik source-file source-file source-file source-file test-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file",no-bug,0.9
2671,harness,https://github.com/harness/harness/issues/2671,Session cookie Secure flag and lifetime,"I noticed that the `_session_` cookie is not protected with the `Secure` flag. This happens even when `DRONE_SERVER_PROTO=https` is set. I would like to propose checking this environment variable and setting the `Secure` flag when appropriate. :smiley: Besides, the lifetime of the cookie is several decades long. Maybe this could be reduced a bit :wink:",documentation-file | source-file | source-file | source-file | source-file | test-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | other-file | other-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | source-file | documentation-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | other-file | source-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | documentation-file | source-file | other-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Session cookie Secure flag and lifetime I noticed that the `_session_` cookie is not protected with the `Secure` flag. This happens even when `DRONE_SERVER_PROTO=https` is set. I would like to propose checking this environment variable and setting the `Secure` flag when appropriate. :smiley: Besides, the lifetime of the cookie is several decades long. Maybe this could be reduced a bit :wink: documentation-file source-file source-file source-file source-file test-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file other-file other-file source-file source-file source-file other-file source-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file other-file source-file other-file source-file other-file other-file source-file source-file documentation-file source-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file test-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file source-file other-file source-file other-file other-file test-file other-file other-file source-file other-file other-file other-file documentation-file other-file other-file other-file documentation-file source-file other-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
942,harness,https://github.com/harness/harness/issues/942,Drone doesn't work with Gitlab 7.9+,"As @kowalczykp and others have noted on Gitter, Drone does not appear to work with the latest versions of Gitlab. Drone will issue a 400 Bad Request for all incoming webhooks. Manually verified with tcpflow on ubuntu. `tcpflow -p -c -i eth0 port 80` Seems to stem from the gitlab go library. https://github.com/Bugagazavr/go-gitlab-client/blob/master/hook_payload.go#L93 Indirectly the message reads. _""Invalid hook received, payload format not recognized.""_",other-file | other-file,"Drone doesn't work with Gitlab 7.9+ As @kowalczykp and others have noted on Gitter, Drone does not appear to work with the latest versions of Gitlab. Drone will issue a 400 Bad Request for all incoming webhooks. Manually verified with tcpflow on ubuntu. `tcpflow -p -c -i eth0 port 80` Seems to stem from the gitlab go library. https://github.com/Bugagazavr/go-gitlab-client/blob/master/hook_payload.go#L93 Indirectly the message reads. _""Invalid hook received, payload format not recognized.""_ other-file other-file",bug,0.9
2585,harness,https://github.com/harness/harness/issues/2585,Support for Starlark,"Experiment with support for Starlark as a configuration language. This could be integrated in the CLI like jsonnet or it could be integrated natively into Drone, depending on how useful it is. * https://docs.bazel.build/versions/master/skylark/language.html * https://github.com/bazelbuild/examples/blob/master/android/firebase-cloud-messaging/app/BUILD#L9 * https://github.com/stripe/skycfg  load(""//config/common/pipeline.sky"", ""pipeline"") def main(ctx): return [ pipeline(ctx, os = 'linux', arch='amd64', name='amd64'), pipeline(ctx, os = 'linux', arch='arm64', name='arm64), pipeline(ctx, os = 'linux', arch='arm', name='arm32'), ] ",other-file | other-file | source-file | other-file | other-file | other-file,"Support for Starlark Experiment with support for Starlark as a configuration language. This could be integrated in the CLI like jsonnet or it could be integrated natively into Drone, depending on how useful it is. * https://docs.bazel.build/versions/master/skylark/language.html * https://github.com/bazelbuild/examples/blob/master/android/firebase-cloud-messaging/app/BUILD#L9 * https://github.com/stripe/skycfg  load(""//config/common/pipeline.sky"", ""pipeline"") def main(ctx): return [ pipeline(ctx, os = 'linux', arch='amd64', name='amd64'), pipeline(ctx, os = 'linux', arch='arm64', name='arm64), pipeline(ctx, os = 'linux', arch='arm', name='arm32'), ]  other-file other-file source-file other-file other-file other-file",no-bug,0.95
111,harness,https://github.com/harness/harness/issues/111,"If a repo is public, list build jobs publicly","When logged in and viewing the main dashboard, it would be nice to see all users (that you follow?) building jobs.",source-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | test-file | other-file | other-file | other-file | source-file | source-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | other-file,"If a repo is public, list build jobs publicly When logged in and viewing the main dashboard, it would be nice to see all users (that you follow?) building jobs. source-file source-file other-file other-file other-file source-file other-file other-file source-file other-file test-file other-file other-file other-file source-file source-file documentation-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file source-file other-file",no-bug,0.9
3285,harness,https://github.com/harness/harness/issues/3285,Drone build without ipv6 interface error,"i set the docker daemon.json, its means i enable ipv6 at docker.  { ""ipv6"": true, ""fixed-cidr-v6"": ""2001:db8:1::/64"" }  also i can run alpine on host with ipv6 successful. but let drone runner docker do it, i don't know how it works, because host docker network bridge not have any 172.19.x.x ip.  ""b86e3bed93598cf767afd89fd3de8cc500d6630c952656ee44a6ac8228396619"": { ""Name"": ""drone-runner"", ""EndpointID"": ""37feadaa4f6dfff551d8c5f84eaca478498755c4b2a00642c935f9ca052e434e"", ""MacAddress"": ""02:42:ac:11:00:05"", ""IPv4Address"": ""172.17.0.5/16"", ""IPv6Address"": ""2001:db8:1::242:ac11:5/64"" }  so I'm trying to figure out what it's doing with /var/run/docker.sock, and it looks like it's creating a completely different docker network and without ipv6.  latest: Pulling from library/alpine Digest: sha256:bc41182d7ef5ffc53a40b044e725193bc10142a1243f395ee852a8d9730fc2ad Status: Image is up to date for alpine:latest + ip addr 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 28: eth0@if29: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:13:00:02 brd ff:ff:ff:ff:ff:ff inet 172.19.0.2/16 brd 172.19.255.255 scope global eth0 valid_lft forever preferred_lft forever + ping * PING * (*): 56 data bytes ping: sendto: Address not available  and i set --env DRONE_RUNNER_NETWORKS=bridge \, but its not working. and i use dind to test my guess, i find that runner will create random docker network, so can i control it behavior? Forgive me for my English proficiency in machine translation.",source-file | source-file | documentation-file | source-file | source-file,"Drone build without ipv6 interface error i set the docker daemon.json, its means i enable ipv6 at docker.  { ""ipv6"": true, ""fixed-cidr-v6"": ""2001:db8:1::/64"" }  also i can run alpine on host with ipv6 successful. but let drone runner docker do it, i don't know how it works, because host docker network bridge not have any 172.19.x.x ip.  ""b86e3bed93598cf767afd89fd3de8cc500d6630c952656ee44a6ac8228396619"": { ""Name"": ""drone-runner"", ""EndpointID"": ""37feadaa4f6dfff551d8c5f84eaca478498755c4b2a00642c935f9ca052e434e"", ""MacAddress"": ""02:42:ac:11:00:05"", ""IPv4Address"": ""172.17.0.5/16"", ""IPv6Address"": ""2001:db8:1::242:ac11:5/64"" }  so I'm trying to figure out what it's doing with /var/run/docker.sock, and it looks like it's creating a completely different docker network and without ipv6.  latest: Pulling from library/alpine Digest: sha256:bc41182d7ef5ffc53a40b044e725193bc10142a1243f395ee852a8d9730fc2ad Status: Image is up to date for alpine:latest + ip addr 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 28: eth0@if29: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:13:00:02 brd ff:ff:ff:ff:ff:ff inet 172.19.0.2/16 brd 172.19.255.255 scope global eth0 valid_lft forever preferred_lft forever + ping * PING * (*): 56 data bytes ping: sendto: Address not available  and i set --env DRONE_RUNNER_NETWORKS=bridge \, but its not working. and i use dind to test my guess, i find that runner will create random docker network, so can i control it behavior? Forgive me for my English proficiency in machine translation. source-file source-file documentation-file source-file source-file",no-bug,0.9
2648,harness,https://github.com/harness/harness/issues/2648,Suggestion: Use project directory name for workspace: base directory,Using `src` as the default base path seems arbitrary. Would it not make more sense to use the projects directory name as the base as that is what the developer who created the project decided already? And I only say this because some tools do expect the project directory to be the same across builds. Just a suggestion. Perhaps it's too much of a breaking change - feel free to close.,source-file | source-file | source-file | source-file,Suggestion: Use project directory name for workspace: base directory Using `src` as the default base path seems arbitrary. Would it not make more sense to use the projects directory name as the base as that is what the developer who created the project decided already? And I only say this because some tools do expect the project directory to be the same across builds. Just a suggestion. Perhaps it's too much of a breaking change - feel free to close. source-file source-file source-file source-file,no-bug,0.95
2216,harness,https://github.com/harness/harness/issues/2216,Can we get DRONE_WORKER env var added as well known env var?,It would be useful to use to have hostname and/or host ip address pushed into the worker container as an environment variable so that our builds can know which worker they are running on.,source-file | source-file | source-file,Can we get DRONE_WORKER env var added as well known env var? It would be useful to use to have hostname and/or host ip address pushed into the worker container as an environment variable so that our builds can know which worker they are running on. source-file source-file source-file,no-bug,0.9
962,harness,https://github.com/harness/harness/issues/962,RethinkDB support,Please add support for [RethinkDB](http://rethinkdb.com/) for the hosted version of drone https://registry.hub.docker.com/u/library/rethinkdb/,source-file | source-file,RethinkDB support Please add support for [RethinkDB](http://rethinkdb.com/) for the hosted version of drone https://registry.hub.docker.com/u/library/rethinkdb/ source-file source-file,no-bug,0.9
1236,harness,https://github.com/harness/harness/issues/1236,CPU load on the client is significant,"When I run a build and watch the build process from firefox, it tends to consume one CPU core (one total CPU core, i7 3rd gen, 4700 or so). I think that is quite significant. I am using the latest rpm being provided as of today.",other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file,"CPU load on the client is significant When I run a build and watch the build process from firefox, it tends to consume one CPU core (one total CPU core, i7 3rd gen, 4700 or so). I think that is quite significant. I am using the latest rpm being provided as of today. other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file",no-bug,0.9
2692,harness,https://github.com/harness/harness/issues/2692,How to add ssh key to drone plugin,"I need to use the ssh key clone library in the drone plugin.For example php project, I need to use the composer command to clone a private warehouse. My current solution is to use a script to parse the parameters passed in the env parameter and generate the ssh_key file.  ssh key phpssh key docker env ssh key ssh key  FROM composer:latest ENV PHPREDIS_VERSION 4.2.0 #RUN  ADD ./drone-php /bin/ ENTRYPOINT [""/bin/drone-php""]  drone-php: go  .drone.yml:  - name: add key image: bbking/composer:latest settings: private_key: from_secret: ssh_key public_key: from_secret: pub_ssh_key commands: - ls -lah /root/.ssh  But I did not see the expected results: drone  + ls -lah /root/.ssh -- 2 | total 8 3 | drwxr-xr-x 2 root root 4.0K May 2 14:10 . 4 | drwx 1 root root 4.0K May 3 05:20 ..  My understanding of docker is not good enough. I want to know how I should safely put the ssh key into the image. dockerssh key ? When I tested it locally, it was the normal generation of ssh key. ssh key ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"How to add ssh key to drone plugin I need to use the ssh key clone library in the drone plugin.For example php project, I need to use the composer command to clone a private warehouse. My current solution is to use a script to parse the parameters passed in the env parameter and generate the ssh_key file.  ssh key phpssh key docker env ssh key ssh key  FROM composer:latest ENV PHPREDIS_VERSION 4.2.0 #RUN  ADD ./drone-php /bin/ ENTRYPOINT [""/bin/drone-php""]  drone-php: go  .drone.yml:  - name: add key image: bbking/composer:latest settings: private_key: from_secret: ssh_key public_key: from_secret: pub_ssh_key commands: - ls -lah /root/.ssh  But I did not see the expected results: drone  + ls -lah /root/.ssh -- 2 | total 8 3 | drwxr-xr-x 2 root root 4.0K May 2 14:10 . 4 | drwx 1 root root 4.0K May 3 05:20 ..  My understanding of docker is not good enough. I want to know how I should safely put the ssh key into the image. dockerssh key ? When I tested it locally, it was the normal generation of ssh key. ssh key  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
1199,harness,https://github.com/harness/harness/issues/1199,Manually kick off a build,"I'd like to use 0.4 at my company, but I can't (and wouldn't want to) open up a public port on my machine to receive callbacks. Is it possible to get a button or shell command that kicks off a build against the latest revision of a repo?",other-file | other-file | source-file | documentation-file | source-file,"Manually kick off a build I'd like to use 0.4 at my company, but I can't (and wouldn't want to) open up a public port on my machine to receive callbacks. Is it possible to get a button or shell command that kicks off a build against the latest revision of a repo? other-file other-file source-file documentation-file source-file",no-bug,0.9
185,harness,https://github.com/harness/harness/issues/185,Versioning + changelog,Having versions with changelogs make it much easier to keep up with a project. Context for me is that I'd like to have some idea of what I'm in for upgrading a drone server I set up a month ago.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | documentation-file,Versioning + changelog Having versions with changelogs make it much easier to keep up with a project. Context for me is that I'd like to have some idea of what I'm in for upgrading a drone server I set up a month ago. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file documentation-file,no-bug,0.9
432,harness,https://github.com/harness/harness/issues/432,SSL warning from not using secure urls on Repository Setup pages,"Just started to use drone for the first time and noticed this once I enabled https  The page at 'https://foo.bar.com/new/bitbucket.org' was loaded over HTTPS, but displayed insecure content from 'http://i0.wp.com/identicon': this content should also be loaded over HTTPS. bitbucket.org:1 GET http://i0.wp.com/identicon 400 (Bad Request) bitbucket.org:102  This happens for github as well. I didn't test gitlab.  $ drone version 0.2-43a0a46 ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"SSL warning from not using secure urls on Repository Setup pages Just started to use drone for the first time and noticed this once I enabled https  The page at 'https://foo.bar.com/new/bitbucket.org' was loaded over HTTPS, but displayed insecure content from 'http://i0.wp.com/identicon': this content should also be loaded over HTTPS. bitbucket.org:1 GET http://i0.wp.com/identicon 400 (Bad Request) bitbucket.org:102  This happens for github as well. I didn't test gitlab.  $ drone version 0.2-43a0a46  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
523,harness,https://github.com/harness/harness/issues/523,re-activate repo via UI,"I have had issues before where I wanted to remove/re-activate a repo in order to fix an issue with the deploy key or web hook, but there doesn't seem to be a good way of doing that, so I have just been removing the `drone.sqlite` file and starting fresh. Would be nice to have a button to re-add webhook and deploy key for a repo, or to even ""deactivate"" a repo.",source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file,"re-activate repo via UI I have had issues before where I wanted to remove/re-activate a repo in order to fix an issue with the deploy key or web hook, but there doesn't seem to be a good way of doing that, so I have just been removing the `drone.sqlite` file and starting fresh. Would be nice to have a button to re-add webhook and deploy key for a repo, or to even ""deactivate"" a repo. source-file source-file source-file source-file other-file source-file source-file source-file other-file other-file source-file source-file source-file",no-bug,0.9
2490,harness,https://github.com/harness/harness/issues/2490,[Feature] Drone jobs for individual subdirectories in a repo,"Hi all, I was wondering if a feature to have multiple Drone jobs for a single repository was possible at some point in the future. We have a large repo with multiple infrastructure related Jenkins jobs, and ideally we would like to move them to Drone. Right now with Jenkins we trigger them off of a push to the repo and Jenkins has a plugin to check if a specific subdirectory/specific files had changed at all in that commit. I could see this working as having one main .drone.yml file in the root of the directory, and in that file having some sort of syntax like: yaml pipeline: mydir-job: image: plugins/run-another-file file-to-run: mydir/.drone.yml when: changed-files: - mydir/* - thisdir/myfile  I have considered writing a plugin for looking for changed files in a commit, but as far as I have found, drone does not have any sort of call to execute a specific drone file. I have read that this wasn't included originally because of how drone is triggered based off of repo-level events, but I could see this being a useful addition to the platform. Interested to hear your thoughts. Thanks.",database-file,"[Feature] Drone jobs for individual subdirectories in a repo Hi all, I was wondering if a feature to have multiple Drone jobs for a single repository was possible at some point in the future. We have a large repo with multiple infrastructure related Jenkins jobs, and ideally we would like to move them to Drone. Right now with Jenkins we trigger them off of a push to the repo and Jenkins has a plugin to check if a specific subdirectory/specific files had changed at all in that commit. I could see this working as having one main .drone.yml file in the root of the directory, and in that file having some sort of syntax like: yaml pipeline: mydir-job: image: plugins/run-another-file file-to-run: mydir/.drone.yml when: changed-files: - mydir/* - thisdir/myfile  I have considered writing a plugin for looking for changed files in a commit, but as far as I have found, drone does not have any sort of call to execute a specific drone file. I have read that this wasn't included originally because of how drone is triggered based off of repo-level events, but I could see this being a useful addition to the platform. Interested to hear your thoughts. Thanks. database-file",no-bug,0.95
2725,harness,https://github.com/harness/harness/issues/2725,"invalid mount config for type ""bind""",Fix issues where bind mount fails if path does not exist on the host machine. This is related to how drone-runtime changed how it configured docker volumes when invoking the Docker API.,other-file | other-file,"invalid mount config for type ""bind"" Fix issues where bind mount fails if path does not exist on the host machine. This is related to how drone-runtime changed how it configured docker volumes when invoking the Docker API. other-file other-file",no-bug,0.9
676,harness,https://github.com/harness/harness/issues/676,A way to login without external identity provider,"Hello, I've been trying to give drone.io a run locally, but it seems it is impossible to actually register using just username/email and password?",other-file,"A way to login without external identity provider Hello, I've been trying to give drone.io a run locally, but it seems it is impossible to actually register using just username/email and password? other-file",no-bug,0.8
406,harness,https://github.com/harness/harness/issues/406,"After running tests, rice executable remains in the source tree","As a developer, I'd like to be able to `git add . && git commit -m 'Frobbed the twizzlestick'` after running `make test`. At the moment, I can't do this because there's an executable created by rice that's left in the working directory. Should this be added to the .gitignore file like other generated files (e.g. bin/drone, bin/droned etc)? I can follow up with a quick PR if so.",source-file | source-file | source-file | source-file | other-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file,"After running tests, rice executable remains in the source tree As a developer, I'd like to be able to `git add . && git commit -m 'Frobbed the twizzlestick'` after running `make test`. At the moment, I can't do this because there's an executable created by rice that's left in the working directory. Should this be added to the .gitignore file like other generated files (e.g. bin/drone, bin/droned etc)? I can follow up with a quick PR if so. source-file source-file source-file source-file other-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file",no-bug,0.95
1086,harness,https://github.com/harness/harness/issues/1086,"[Drone, Gitlab] ""Activate Now"" returns 500 Internal Server Error","Gitlab version: 7.12.2 Steps: - Setup Drone in gitlab under applications  Name: Drone Callback URL: http://drone.[myserver].com/api/auth/gitlab.com  - Setup drone.yml with client and secret keys to talk to gitlab  [gitlab] url = ""http://gitlab.[myserver].com"" client = ""exampleclientkey"" secret = ""examplesecretkey"" skip_verify=false open=false  - Activate returns:  POST http://drone.[myserver].com/api/repos/gitlab.[myserver].com/user/test 500 (Internal Server Error)  Logs: - Nothing in the apache log for gitlab - Not sure where else to look Cheers",other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | other-file | documentation-file | other-file | other-file | other-file | source-file | source-file | source-file,"[Drone, Gitlab] ""Activate Now"" returns 500 Internal Server Error Gitlab version: 7.12.2 Steps: - Setup Drone in gitlab under applications  Name: Drone Callback URL: http://drone.[myserver].com/api/auth/gitlab.com  - Setup drone.yml with client and secret keys to talk to gitlab  [gitlab] url = ""http://gitlab.[myserver].com"" client = ""exampleclientkey"" secret = ""examplesecretkey"" skip_verify=false open=false  - Activate returns:  POST http://drone.[myserver].com/api/repos/gitlab.[myserver].com/user/test 500 (Internal Server Error)  Logs: - Nothing in the apache log for gitlab - Not sure where else to look Cheers other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file source-file other-file documentation-file other-file other-file other-file source-file source-file source-file",bug,0.9
3235,harness,https://github.com/harness/harness/issues/3235,SQLite warning will be prompted during server build,"Build commands: bash REPO=""github.com/drone/drone"" go build -ldflags ""-extldflags \""-static\"""" ${REPO}/cmd/drone-server  Warning:  > Running in 470f8f7a7a5d # github.com/mattn/go-sqlite3 sqlite3-binding.c: In function 'sqlite3SelectNew': sqlite3-binding.c:121469:10: warning: function may return address of local variable [-Wreturn-local-addr] 121469 | return pNew; | ^ sqlite3-binding.c:121431:10: note: declared here 121431 | Select standin; | ^ ",source-file,"SQLite warning will be prompted during server build Build commands: bash REPO=""github.com/drone/drone"" go build -ldflags ""-extldflags \""-static\"""" ${REPO}/cmd/drone-server  Warning:  > Running in 470f8f7a7a5d # github.com/mattn/go-sqlite3 sqlite3-binding.c: In function 'sqlite3SelectNew': sqlite3-binding.c:121469:10: warning: function may return address of local variable [-Wreturn-local-addr] 121469 | return pNew; | ^ sqlite3-binding.c:121431:10: note: declared here 121431 | Select standin; | ^  source-file",no-bug,0.95
3066,harness,https://github.com/harness/harness/issues/3066,"My project needs to use vs2019 to compile my c++ program, how do I edit the yml file?","My project was developed using vs2019, using the C++ language, but I found a lot of information about drone, but I didn't see how to use drone to continuously integrate and deploy my project. Mainly the preparation of the yml of the project",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"My project needs to use vs2019 to compile my c++ program, how do I edit the yml file? My project was developed using vs2019, using the C++ language, but I found a lot of information about drone, but I didn't see how to use drone to continuously integrate and deploy my project. Mainly the preparation of the yml of the project source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
2480,harness,https://github.com/harness/harness/issues/2480,panic: send on closed channel,"Getting this panic in the server when a build outputs large logs:  panic: send on closed channel goroutine 168623 [running]: github.com/drone/drone/server.LogStreamSSE.func2.1(0xc428365a38, 0x1, 0x1) /go/src/github.com/drone/drone/server/stream.go:196 +0xc4 created by github.com/drone/drone/vendor/github.com/cncd/logging.(*log).Write /go/src/github.com/drone/drone/vendor/github.com/cncd/logging/log.go:74 +0x1cd  Possibly related error on the agent just before the panic:  grpc error: upload(): code: ResourceExhausted: rpc error: code = ResourceExhausted desc = grpc: trying to send message larger than max (6135644 vs. 4194304) ",config-file | source-file | source-file | source-file | source-file | source-file | source-file,"panic: send on closed channel Getting this panic in the server when a build outputs large logs:  panic: send on closed channel goroutine 168623 [running]: github.com/drone/drone/server.LogStreamSSE.func2.1(0xc428365a38, 0x1, 0x1) /go/src/github.com/drone/drone/server/stream.go:196 +0xc4 created by github.com/drone/drone/vendor/github.com/cncd/logging.(*log).Write /go/src/github.com/drone/drone/vendor/github.com/cncd/logging/log.go:74 +0x1cd  Possibly related error on the agent just before the panic:  grpc error: upload(): code: ResourceExhausted: rpc error: code = ResourceExhausted desc = grpc: trying to send message larger than max (6135644 vs. 4194304)  config-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
420,harness,https://github.com/harness/harness/issues/420,0.3 Private variables not set on PR build,"Hey, I was testing the 0.3 build and found that, when building a PR the private variables are not set. I configured them in the project settings:  ONE=bar TWO=foo  Any ideas what can be wrong? Greetings, Ralf",other-file | other-file,"0.3 Private variables not set on PR build Hey, I was testing the 0.3 build and found that, when building a PR the private variables are not set. I configured them in the project settings:  ONE=bar TWO=foo  Any ideas what can be wrong? Greetings, Ralf other-file other-file",no-bug,0.9
2053,harness,https://github.com/harness/harness/issues/2053,ability to specify platform requirement in matrix builds,"I need to build apps one per platform (arm,x86). Right now even if I run agents on multiple platforms I cannot override platform requirement using matrix variable (as well as plugin image names) I am migrating from TeamCity where I can create separate build configurations with corresponding arch requirements. I understand that TeamCity is java and all the plugins just work so it is a bit simpler.",source-file,"ability to specify platform requirement in matrix builds I need to build apps one per platform (arm,x86). Right now even if I run agents on multiple platforms I cannot override platform requirement using matrix variable (as well as plugin image names) I am migrating from TeamCity where I can create separate build configurations with corresponding arch requirements. I understand that TeamCity is java and all the plugins just work so it is a bit simpler. source-file",no-bug,0.9
2515,harness,https://github.com/harness/harness/issues/2515,now that Github has disabled webhooks for more than 24h - force a new drone build?,"Hello! First of all, I ignore if there is another way to do it, and I have tried with the cli with no success. Is there any way to force a *new* build without a webhook? I mean Github is down now, and many of us would like to have a way to do a new build with whatever there is on a specific branch, a new build, not a rebuild of a past build, something like: drone build start etaleinc/etale-java-main again guys, is there any way to actually accomplish this?",config-file | config-file,"now that Github has disabled webhooks for more than 24h - force a new drone build? Hello! First of all, I ignore if there is another way to do it, and I have tried with the cli with no success. Is there any way to force a *new* build without a webhook? I mean Github is down now, and many of us would like to have a way to do a new build with whatever there is on a specific branch, a new build, not a rebuild of a past build, something like: drone build start etaleinc/etale-java-main again guys, is there any way to actually accomplish this? config-file config-file",no-bug,0.9
3304,harness,https://github.com/harness/harness/issues/3304,Feature request: HTTP Proxy Support,<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> I googled and didn't find a way to config HTTP Proxy for Drone. Is there any way to do that? I need this to make drone able to access corporate network content.,source-file | source-file | source-file,Feature request: HTTP Proxy Support <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> I googled and didn't find a way to config HTTP Proxy for Drone. Is there any way to do that? I need this to make drone able to access corporate network content. source-file source-file source-file,no-bug,0.95
759,harness,https://github.com/harness/harness/issues/759,Docker 1.4 requires `--force` when using existing tag,"See https://github.com/docker/docker/pull/8511. When the Docker image is built it's tagged with the first tag (https://github.com/drone/drone/blob/fb254e3f2c675ed65b78551224e3ed1115739f5c/plugin/publish/docker.go#L92), then later all tags are applied (https://github.com/drone/drone/blob/fb254e3f2c675ed65b78551224e3ed1115739f5c/plugin/publish/docker.go#L102). This should either use `--force` for all tags, or not retag the first one.",source-file | source-file | source-file,"Docker 1.4 requires `--force` when using existing tag See https://github.com/docker/docker/pull/8511. When the Docker image is built it's tagged with the first tag (https://github.com/drone/drone/blob/fb254e3f2c675ed65b78551224e3ed1115739f5c/plugin/publish/docker.go#L92), then later all tags are applied (https://github.com/drone/drone/blob/fb254e3f2c675ed65b78551224e3ed1115739f5c/plugin/publish/docker.go#L102). This should either use `--force` for all tags, or not retag the first one. source-file source-file source-file",no-bug,0.9
1073,harness,https://github.com/harness/harness/issues/1073,Drone development and directions,"Hi, We're considering using drone in our organisation. We have a basic setup working integrated with gitlab, and it works great. Our needs, however, go beyond what drone currently supports. We're thinking of using some of our time to seriously contribute do drone. In order to make a decision, we would like to understand what is the current development plans. I guess the first question would be: Whats you plan for the 0.4 release? It seems the two branches named after ""0.4"" have greatly diverged from master, with some big changes regarding builds and the database. Is 0.4 going to be released with all the work from those branches merged into master?",other-file | other-file | source-file | other-file | other-file | source-file | source-file | documentation-file | other-file | other-file | source-file | other-file | source-file,"Drone development and directions Hi, We're considering using drone in our organisation. We have a basic setup working integrated with gitlab, and it works great. Our needs, however, go beyond what drone currently supports. We're thinking of using some of our time to seriously contribute do drone. In order to make a decision, we would like to understand what is the current development plans. I guess the first question would be: Whats you plan for the 0.4 release? It seems the two branches named after ""0.4"" have greatly diverged from master, with some big changes regarding builds and the database. Is 0.4 going to be released with all the work from those branches merged into master? other-file other-file source-file other-file other-file source-file source-file documentation-file other-file other-file source-file other-file source-file",no-bug,0.95
549,harness,https://github.com/harness/harness/issues/549,Prevent Hanging Builds,"We need to put code in place to prevent inadvertently hanging a build. There are some things we can't prevent, like someone executing a blocking command. The timeout will handle this. I'm more concerned with background jobs (a web server, selenium server, etc) that might be started and run in the background, or disowned from the parent process. This is a simple test script that will hang even if `exit 0` is reached:  sh #!/bin/bash python -m SimpleHTTPServer 8888 & exit 0  This will hang a Drone build as well, until it times out, resulting in a failure status even when the build should be successful. This is something that, unless addressed, is going to frequently trip people up. We could implement a trap that gets included in each generated build script:  sh exit_trap() { # TODO kill processes } trap exit_trap SIGINT SIGTERM EXIT  And in the trap, we could try to kill and background jobs. It would look something like this:  sh for pid in $(jobs -pr); do [ -d /proc/$pid ] && disown $pid && kill -9 $pid &> /dev/null; done  I've seen examples where the above code isn't adequate. So we could just kill all processes `> 1`. The reason I say `> 1` is because `pid 1` is the build script being executed by Docker. This code could look something like this:  sh for pid in $(ps -A --no-headers -o pid); do [ $pid -gt 1 ] && [ -d /proc/$pid ] && kill -9 $pid &> /dev/null; done  There may be a better, more reliable way to address this issue. Heck, maybe there is a flag I can pass to bash to do this automatically. If so, let me know",other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file,"Prevent Hanging Builds We need to put code in place to prevent inadvertently hanging a build. There are some things we can't prevent, like someone executing a blocking command. The timeout will handle this. I'm more concerned with background jobs (a web server, selenium server, etc) that might be started and run in the background, or disowned from the parent process. This is a simple test script that will hang even if `exit 0` is reached:  sh #!/bin/bash python -m SimpleHTTPServer 8888 & exit 0  This will hang a Drone build as well, until it times out, resulting in a failure status even when the build should be successful. This is something that, unless addressed, is going to frequently trip people up. We could implement a trap that gets included in each generated build script:  sh exit_trap() { # TODO kill processes } trap exit_trap SIGINT SIGTERM EXIT  And in the trap, we could try to kill and background jobs. It would look something like this:  sh for pid in $(jobs -pr); do [ -d /proc/$pid ] && disown $pid && kill -9 $pid &> /dev/null; done  I've seen examples where the above code isn't adequate. So we could just kill all processes `> 1`. The reason I say `> 1` is because `pid 1` is the build script being executed by Docker. This code could look something like this:  sh for pid in $(ps -A --no-headers -o pid); do [ $pid -gt 1 ] && [ -d /proc/$pid ] && kill -9 $pid &> /dev/null; done  There may be a better, more reliable way to address this issue. Heck, maybe there is a flag I can pass to bash to do this automatically. If so, let me know other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file",no-bug,0.95
85,harness,https://github.com/harness/harness/issues/85,Ability for an admin to permit a repo's builds to be privileged,"I need this for testing one of my projects that's much like Docker. For now I've just forked Drone and switched it to run everything privileged, but I'm wondering what this would look like as a polished feature, so I can start putting together a PR. For example, I'd expect pull-request-triggered builds to _not_ run privileged, but I'm not sure what that means for the build. Perhaps it should set an environment variable so that the tests know to skip the ones that require it? Any other things to worry about?",config-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file,"Ability for an admin to permit a repo's builds to be privileged I need this for testing one of my projects that's much like Docker. For now I've just forked Drone and switched it to run everything privileged, but I'm wondering what this would look like as a polished feature, so I can start putting together a PR. For example, I'd expect pull-request-triggered builds to _not_ run privileged, but I'm not sure what that means for the build. Perhaps it should set an environment variable so that the tests know to skip the ones that require it? Any other things to worry about? config-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file",no-bug,0.9
2952,harness,https://github.com/harness/harness/issues/2952,"Active Gogs Repo Failed, github.com/drone/drone/service/hook.deleteHook",There is a bug when I Active gogs repo. ![image](https://user-images.githubusercontent.com/15363011/79181058-14c8d680-7e3e-11ea-88e9-735781d0193e.png),source-file,"Active Gogs Repo Failed, github.com/drone/drone/service/hook.deleteHook There is a bug when I Active gogs repo. ![image](https://user-images.githubusercontent.com/15363011/79181058-14c8d680-7e3e-11ea-88e9-735781d0193e.png) source-file",no-bug,0.7
809,harness,https://github.com/harness/harness/issues/809,invalid character '<' looking for beginning of value,"While trying to login using gitlab.com in drone, i get the following error  2015/01/13 14:32:18 invalid character '<' looking for beginning of value  I launched drone this way  DRONE_SERVER_PORT=localhost:9876 DRONE_GITLAB_URL=""http://gitlab.com"" droned  i tried using the Dockerfile and also using the debian package on ubuntu14.04 . Btw i also tried to authenticate manually against https://gitlab.com/api/v3/session and it works, so it does not seems to be related to wrong credentials. Any ideas?",source-file | test-file | source-file | test-file | test-file,"invalid character '<' looking for beginning of value While trying to login using gitlab.com in drone, i get the following error  2015/01/13 14:32:18 invalid character '<' looking for beginning of value  I launched drone this way  DRONE_SERVER_PORT=localhost:9876 DRONE_GITLAB_URL=""http://gitlab.com"" droned  i tried using the Dockerfile and also using the debian package on ubuntu14.04 . Btw i also tried to authenticate manually against https://gitlab.com/api/v3/session and it works, so it does not seems to be related to wrong credentials. Any ideas? source-file test-file source-file test-file test-file",bug,0.85
2852,harness,https://github.com/harness/harness/issues/2852,Add more trigger events,Would be awesome if we had the following trigger events: - cron - webapi,source-file,Add more trigger events Would be awesome if we had the following trigger events: - cron - webapi source-file,no-bug,0.9
1185,harness,https://github.com/harness/harness/issues/1185,Build broken at master@dbdad86: gogs.go:167: undefined: gogs.ParseHook,"See title; `make deps` isn't working from current head of `master`, dbdad86:  henrik@ip-10-0-42-21 ~/src $ git clone https://github.com/drone/drone.git henrik@ip-10-0-42-21 ~/src $ cd drone henrik@ip-10-0-42-21 ~/src/drone $ git log --oneline | head -n 1 dbdad86 fix SSL error when wget docker henrik@ip-10-0-42-21 ~/src/drone $ docker build . Sending build context to Docker daemon 18.93 MB Sending build context to Docker daemon Step 0 : FROM google/golang # Executing 1 build triggers Trigger 0, RUN echo ""This image is now deprecated. If you are not using Managed VMs, you should use the official Go Docker image located at: https://hub.docker.com/_/golang/"" [..] Step 6 : RUN make deps build embed install > Running in c12dc240b66a go get github.com/GeertJohan/go.rice/rice go get -t -v ./ code.google.com/p/goauth2 (download) github.com/Bugagazavr/go-gitlab-client (download) [] github.com/drone/drone/plugin/remote/gogs # github.com/drone/drone/plugin/remote/gogs plugin/remote/gogs/gogs.go:167: undefined: gogs.ParseHook [] make:  [deps] Error 2 The command '/bin/sh -c make deps build embed install' returned a non-zero code: 2 ",source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file,"Build broken at master@dbdad86: gogs.go:167: undefined: gogs.ParseHook See title; `make deps` isn't working from current head of `master`, dbdad86:  henrik@ip-10-0-42-21 ~/src $ git clone https://github.com/drone/drone.git henrik@ip-10-0-42-21 ~/src $ cd drone henrik@ip-10-0-42-21 ~/src/drone $ git log --oneline | head -n 1 dbdad86 fix SSL error when wget docker henrik@ip-10-0-42-21 ~/src/drone $ docker build . Sending build context to Docker daemon 18.93 MB Sending build context to Docker daemon Step 0 : FROM google/golang # Executing 1 build triggers Trigger 0, RUN echo ""This image is now deprecated. If you are not using Managed VMs, you should use the official Go Docker image located at: https://hub.docker.com/_/golang/"" [..] Step 6 : RUN make deps build embed install > Running in c12dc240b66a go get github.com/GeertJohan/go.rice/rice go get -t -v ./ code.google.com/p/goauth2 (download) github.com/Bugagazavr/go-gitlab-client (download) [] github.com/drone/drone/plugin/remote/gogs # github.com/drone/drone/plugin/remote/gogs plugin/remote/gogs/gogs.go:167: undefined: gogs.ParseHook [] make:  [deps] Error 2 The command '/bin/sh -c make deps build embed install' returned a non-zero code: 2  source-file source-file source-file source-file test-file source-file source-file source-file",no-bug,0.95
2988,harness,https://github.com/harness/harness/issues/2988,Discussion of usage scenarios of drone CD,"Wanted a drone to focus on the CD part of the assembly line. I hope to discuss it with the big boys. How do you use drone to specify a mirrored library instead of a code base, or use API calls to implement the continuous deployment phase ?",source-file,"Discussion of usage scenarios of drone CD Wanted a drone to focus on the CD part of the assembly line. I hope to discuss it with the big boys. How do you use drone to specify a mirrored library instead of a code base, or use API calls to implement the continuous deployment phase ? source-file",no-bug,0.9
855,harness,https://github.com/harness/harness/issues/855,GitLab Refresh Tokens & Concurrency,"When the `access_token` is refreshed GitLab also sends a new `refresh_token`. This is a perfectly valid (but optional) implementation detail: > the authorization server MAY issue a new refresh token, in which case the client MUST discard the old refresh token and replace it with the new refresh token. When GitLab sends back a new `refresh_token` it also immediately expires the old `refresh_token`. This is also a perfectly valid (but optional) implementation detail: > The authorization server MAY revoke the old refresh token after issuing a new refresh token to the client. This becomes problematic for systems that are making concurrent requests to the API. It is possible for two threads (or in our case goroutines) to successfully refresh an access_token around the same time. This means one thread will have an expired set of tokens that it cannot refresh. This gets more complicated because we are making these requests offline. This means if we achieve the above race condition, we could get locked out of the API forever until the user physically goes to the website and re-authenticates. There really isn't a good way to handle this in a concurrent, offline environment. We could try to implement mutexes, but even this is subject to edge cases (ie program quits un-unexpectedly) and breaks down if you have clustered servers. I believe we need to engage GitLab for this. One example of a middle ground could be providing `access_type=offline` (similar to Google) that would prevent sending a new `refresh_token` when refreshing an `access_token`. Another option would be to more closely mirror GitHub and never expire an access token. It looks like this is possible (see https://github.com/doorkeeper-gem/doorkeeper/pull/76) but I'm not sure they would be willing to make such a drastic policy change.",other-file | other-file | source-file,"GitLab Refresh Tokens & Concurrency When the `access_token` is refreshed GitLab also sends a new `refresh_token`. This is a perfectly valid (but optional) implementation detail: > the authorization server MAY issue a new refresh token, in which case the client MUST discard the old refresh token and replace it with the new refresh token. When GitLab sends back a new `refresh_token` it also immediately expires the old `refresh_token`. This is also a perfectly valid (but optional) implementation detail: > The authorization server MAY revoke the old refresh token after issuing a new refresh token to the client. This becomes problematic for systems that are making concurrent requests to the API. It is possible for two threads (or in our case goroutines) to successfully refresh an access_token around the same time. This means one thread will have an expired set of tokens that it cannot refresh. This gets more complicated because we are making these requests offline. This means if we achieve the above race condition, we could get locked out of the API forever until the user physically goes to the website and re-authenticates. There really isn't a good way to handle this in a concurrent, offline environment. We could try to implement mutexes, but even this is subject to edge cases (ie program quits un-unexpectedly) and breaks down if you have clustered servers. I believe we need to engage GitLab for this. One example of a middle ground could be providing `access_type=offline` (similar to Google) that would prevent sending a new `refresh_token` when refreshing an `access_token`. Another option would be to more closely mirror GitHub and never expire an access token. It looks like this is possible (see https://github.com/doorkeeper-gem/doorkeeper/pull/76) but I'm not sure they would be willing to make such a drastic policy change. other-file other-file source-file",no-bug,0.9
545,harness,https://github.com/harness/harness/issues/545,"Projects with pre-existing .drone.yml files still get the ""Add a .drone.yml file"" messaging","Steps to repro: 1. Find a project that hasn't been added to the Drone instance 2. Add a .drone.yml file to it 3. Add the project to the Drone instance Expected results: - The messaging should say ""make a commit to trigger a build"" or have an option to manually trigger one Actual results: - The messaging says something like ""add a .drone.yml file""",other-file | other-file | source-file,"Projects with pre-existing .drone.yml files still get the ""Add a .drone.yml file"" messaging Steps to repro: 1. Find a project that hasn't been added to the Drone instance 2. Add a .drone.yml file to it 3. Add the project to the Drone instance Expected results: - The messaging should say ""make a commit to trigger a build"" or have an option to manually trigger one Actual results: - The messaging says something like ""add a .drone.yml file"" other-file other-file source-file",no-bug,0.9
3357,harness,https://github.com/harness/harness/issues/3357,cron: cannot find commit,"Hello! Drone seems to have an issue trying to run cron jobs on deleted repositories. I'm running Drone against Gitea, both in Docker (on CapRover). I deleted two repos, then synced Drone to my repos and since then I get the following errors in my Drone docker logs: `branch=main cron=4 error=Not Found level=warning msg=cron: cannot find commit repo=org/deleted repo` I have also created cron jobs for other repos that haven't been deleted and they show the same error Cron jobs have been created with the CLI and show on the GUI. The build runs properly when a commit is done on the new repo or when manually triggered from Drone UI Thanks,",source-file,"cron: cannot find commit Hello! Drone seems to have an issue trying to run cron jobs on deleted repositories. I'm running Drone against Gitea, both in Docker (on CapRover). I deleted two repos, then synced Drone to my repos and since then I get the following errors in my Drone docker logs: `branch=main cron=4 error=Not Found level=warning msg=cron: cannot find commit repo=org/deleted repo` I have also created cron jobs for other repos that haven't been deleted and they show the same error Cron jobs have been created with the CLI and show on the GUI. The build runs properly when a commit is done on the new repo or when manually triggered from Drone UI Thanks, source-file",no-bug,0.9
560,harness,https://github.com/harness/harness/issues/560,"Builds don't run, fail with network-y issues","Two different repos (drone fork and another):  Error: Unable to pull image bradrydzewski/postgres:9.1   dial: unknown network  I'm sure it's something to do with my env, just wondering if you'd seen this before?",other-file | source-file | other-file | other-file | source-file | other-file | other-file | documentation-file | other-file | other-file,"Builds don't run, fail with network-y issues Two different repos (drone fork and another):  Error: Unable to pull image bradrydzewski/postgres:9.1   dial: unknown network  I'm sure it's something to do with my env, just wondering if you'd seen this before? other-file source-file other-file other-file source-file other-file other-file documentation-file other-file other-file",no-bug,0.9
831,harness,https://github.com/harness/harness/issues/831,"could not connect to the server in the container, is it because of the wrong port mapping between the host and container?","This is my app , a very simple express node.js app.  javascript var express = require('express'); console.log(""hello log""); var app = express(); app.get('/', function(req, res){ res.send('hello world'); }); app.listen(3300);  my yml is like  javascript image: dockerfile/nodejs env: - GOPATH=/var/cache/drone script: - echo hello world 222 - pwd - ls - npm install express redis mqtt - node app.js & - /bin/bash services: - mongodb - rabbitmq - redis  As the drone.io built up the image and run the app container successfully on my digitalocean server. I opened the url : https:digital_server_ip:3300, it was supposed to obtain the 'hello world' text, but in fact, the page could not be open. in the docker, usually the container will have to expose the port, and make a mapping with host_port: container_port, how does the drone.io handle this port mapping and exposure, is this the reason that my server in the container is open at 3300 port, but not connected from the host environment ?",source-file | source-file | source-file | source-file | source-file,"could not connect to the server in the container, is it because of the wrong port mapping between the host and container? This is my app , a very simple express node.js app.  javascript var express = require('express'); console.log(""hello log""); var app = express(); app.get('/', function(req, res){ res.send('hello world'); }); app.listen(3300);  my yml is like  javascript image: dockerfile/nodejs env: - GOPATH=/var/cache/drone script: - echo hello world 222 - pwd - ls - npm install express redis mqtt - node app.js & - /bin/bash services: - mongodb - rabbitmq - redis  As the drone.io built up the image and run the app container successfully on my digitalocean server. I opened the url : https:digital_server_ip:3300, it was supposed to obtain the 'hello world' text, but in fact, the page could not be open. in the docker, usually the container will have to expose the port, and make a mapping with host_port: container_port, how does the drone.io handle this port mapping and exposure, is this the reason that my server in the container is open at 3300 port, but not connected from the host environment ? source-file source-file source-file source-file source-file",no-bug,0.9
252,harness,https://github.com/harness/harness/issues/252,Commit-hash checking on hook handlers,"When hook triggered, drone checking the commit hash and see if it's already exists in the commits table: https://github.com/drone/drone/blob/master/pkg/handler/hooks.go#L220  Go _, err = database.GetCommitBranchHash(hook.Branch(), hook.Head.Id, repo.ID) if err != nil && err != sql.ErrNoRows { println(""commit already exists"") return RenderText(w, http.StatusText(http.StatusBadGateway), http.StatusBadGateway) }  Do the lines above really do what it supposed to do? Looks like it only checks for error, then print `commit already exists` when error is not nil and not equal to `sql.ErrNoRows`. But it wont get trapped there if the commit actually exists in the table, since the error will be `nil`. Aren't we supposed to also exit there if the error is nil (the commit is found)?",source-file | other-file,"Commit-hash checking on hook handlers When hook triggered, drone checking the commit hash and see if it's already exists in the commits table: https://github.com/drone/drone/blob/master/pkg/handler/hooks.go#L220  Go _, err = database.GetCommitBranchHash(hook.Branch(), hook.Head.Id, repo.ID) if err != nil && err != sql.ErrNoRows { println(""commit already exists"") return RenderText(w, http.StatusText(http.StatusBadGateway), http.StatusBadGateway) }  Do the lines above really do what it supposed to do? Looks like it only checks for error, then print `commit already exists` when error is not nil and not equal to `sql.ErrNoRows`. But it wont get trapped there if the commit actually exists in the table, since the error will be `nil`. Aren't we supposed to also exit there if the error is nil (the commit is found)? source-file other-file",no-bug,0.8
3034,harness,https://github.com/harness/harness/issues/3034,"Not dependant pipelines are skipped, when any pipeline fails before they are started, even when dependant pipelines are OK","Hello, I have the following situation: ![image](https://user-images.githubusercontent.com/1737722/97972322-a2f9af80-1dc4-11eb-842b-c9282a064bef.png) Here the pipelines, test1, test2 and test3 ""[depends_on](https://docs.drone.io/pipeline/configuration/)"" build. - release1 depends_on test1 - release2 depends_on test2 - release3 depends_on test3 But release2 has no dependance on test1. When test1 fails before test2 is finished, release2 is skipped. When test1 fails after test2 is successful, release2 will be executed. I think it should always execute release2 when test2 is successful, regardless of the other pipelines release2 has no dependance on, or what do you think? Thank you and best regards, Philipp",source-file | source-file,"Not dependant pipelines are skipped, when any pipeline fails before they are started, even when dependant pipelines are OK Hello, I have the following situation: ![image](https://user-images.githubusercontent.com/1737722/97972322-a2f9af80-1dc4-11eb-842b-c9282a064bef.png) Here the pipelines, test1, test2 and test3 ""[depends_on](https://docs.drone.io/pipeline/configuration/)"" build. - release1 depends_on test1 - release2 depends_on test2 - release3 depends_on test3 But release2 has no dependance on test1. When test1 fails before test2 is finished, release2 is skipped. When test1 fails after test2 is successful, release2 will be executed. I think it should always execute release2 when test2 is successful, regardless of the other pipelines release2 has no dependance on, or what do you think? Thank you and best regards, Philipp source-file source-file",no-bug,0.9
1114,harness,https://github.com/harness/harness/issues/1114,Drone set docker container MAC address,"I was wandering if it is possible to have a container with the same mac address every time. I believe there is an option in docker:  docker run -i -t --mac-address=26:99:7c:50:d8:20 --name=my-container ubuntu bash  Alternatively, is it possible to change the mac address within the container?",source-file | other-file | other-file | other-file | other-file,"Drone set docker container MAC address I was wandering if it is possible to have a container with the same mac address every time. I believe there is an option in docker:  docker run -i -t --mac-address=26:99:7c:50:d8:20 --name=my-container ubuntu bash  Alternatively, is it possible to change the mac address within the container? source-file other-file other-file other-file other-file",no-bug,0.9
2637,harness,https://github.com/harness/harness/issues/2637,DRONE_STAGE_NAME/NUMBER not passed to plugins,"If I understand it correctly, `DRONE_STAGE_NUMBER` would be the replacement for 0.8's `DRONE_JOB_NUMBER`. Apparantly this new variable isn't available to plugins though: https://github.com/Drillster/drone-volume-cache/issues/23",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"DRONE_STAGE_NAME/NUMBER not passed to plugins If I understand it correctly, `DRONE_STAGE_NUMBER` would be the replacement for 0.8's `DRONE_JOB_NUMBER`. Apparantly this new variable isn't available to plugins though: https://github.com/Drillster/drone-volume-cache/issues/23 source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.7
1188,harness,https://github.com/harness/harness/issues/1188,Re-Building doesn't trigger deploys,I noticed today that re-building an existing job does not trigger deploys. Need to figure out why,source-file | source-file | source-file | source-file | source-file | source-file | source-file,Re-Building doesn't trigger deploys I noticed today that re-building an existing job does not trigger deploys. Need to figure out why source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
1013,harness,https://github.com/harness/harness/issues/1013,drone.toml when running Drone Docker,I would like to add my `drone.toml` file to the volume. I can't really specify the custom `drone.toml` location as a command option because I'm using Kitematic which defers to using the images default command or entrypoint. Can we create an environment variable to specify the location of the drone.toml or check the volume for a drone.toml by default before falling back to `/etc/drone/drone.toml`?,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,drone.toml when running Drone Docker I would like to add my `drone.toml` file to the volume. I can't really specify the custom `drone.toml` location as a command option because I'm using Kitematic which defers to using the images default command or entrypoint. Can we create an environment variable to specify the location of the drone.toml or check the volume for a drone.toml by default before falling back to `/etc/drone/drone.toml`? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
3056,harness,https://github.com/harness/harness/issues/3056,plugin/docker ,<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io -->,source-file,plugin/docker  <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> source-file,no-bug,0.9
1148,harness,https://github.com/harness/harness/issues/1148,Move build timout to build container,"The build timeout is currently being enforced by the Drone server. It would be nice if, instead, this is enforced by the build container launched on the worker node.",source-file | source-file,"Move build timout to build container The build timeout is currently being enforced by the Drone server. It would be nice if, instead, this is enforced by the build container launched on the worker node. source-file source-file",no-bug,0.9
1145,harness,https://github.com/harness/harness/issues/1145,Secure environment variables encrypted in Yaml,"Currently we have the ability to store private environment variables in the database. I'd like to expand this capability to store encrypted environment variables in the yaml itself, similar to travis.  yaml secure: docker_user: U2FsdGVkX19g96OdOIRPtVNGzPP1CgGlxRxRVDvlVHZKYrulqPLlYFG3TfUw53Gk docker_pass: U2FsdGVkX18B3tY76uPxLe2tA6UzaBrVMMsArAUS4bo=  the secure parameters are decrypted at runtime and injected into your build yaml, similar to how we inject private variables (entered in the UI) or matrix parameters:  yaml deploy: docker: email: $$docker_user password: $$docker_pass  Unlike travis, injecting the private parameters as environment variables is not sufficient since publish, deploy and notify sections (which are typically the only sections that require such secrets) are executed outside of the build container and expect very specific parameters in the yaml. This is a result of the new 0.4 plugin model. So for now we need to inject using the same syntax as matrix and private variables. I will spend some time, however, thinking up alternate approaches ",source-file | source-file | source-file | source-file | source-file | test-file,"Secure environment variables encrypted in Yaml Currently we have the ability to store private environment variables in the database. I'd like to expand this capability to store encrypted environment variables in the yaml itself, similar to travis.  yaml secure: docker_user: U2FsdGVkX19g96OdOIRPtVNGzPP1CgGlxRxRVDvlVHZKYrulqPLlYFG3TfUw53Gk docker_pass: U2FsdGVkX18B3tY76uPxLe2tA6UzaBrVMMsArAUS4bo=  the secure parameters are decrypted at runtime and injected into your build yaml, similar to how we inject private variables (entered in the UI) or matrix parameters:  yaml deploy: docker: email: $$docker_user password: $$docker_pass  Unlike travis, injecting the private parameters as environment variables is not sufficient since publish, deploy and notify sections (which are typically the only sections that require such secrets) are executed outside of the build container and expect very specific parameters in the yaml. This is a result of the new 0.4 plugin model. So for now we need to inject using the same syntax as matrix and private variables. I will spend some time, however, thinking up alternate approaches  source-file source-file source-file source-file source-file test-file",no-bug,0.9
424,harness,https://github.com/harness/harness/issues/424,Provide HTTPs Download Link,"The docs say to get it from http://downloads.drone.io/latest/drone.deb However, it's not secure to download software from http as it opens it up to man in the middle attacks giving you a malicious version of the package. Please make a version available from https :-)",source-file | source-file,"Provide HTTPs Download Link The docs say to get it from http://downloads.drone.io/latest/drone.deb However, it's not secure to download software from http as it opens it up to man in the middle attacks giving you a malicious version of the package. Please make a version available from https :-) source-file source-file",no-bug,0.9
360,harness,https://github.com/harness/harness/issues/360,make deps error,"I'm quite new to drone, so please help me if you could, thanks! root@drone:/go/src/drone# make deps go get -u -t -v ./ drone (download) bitbucket.org/kardianos/osext (download) code.google.com/p/go.crypto (download) code.google.com/p/go.text (download) code.google.com/p/gomock (download) github.com/GeertJohan/go.rice (download) github.com/daaku/go.zipexe (download) github.com/andybons/hipchat (download) github.com/dchest/uniuri (download) github.com/dotcloud/docker (download) github.com/drone/drone (download) github.com/go-sql-driver/mysql (download) github.com/mattn/go-sqlite3 (download) github.com/russross/meddler (download) github.com/fluffle/goevent (download) # cd /go/src/github.com/fluffle/goevent; git symbolic-ref HEAD fatal: ref HEAD is not a symbolic ref /go/src/github.com/fluffle/goevent on detached head; repairing github.com/fluffle/goirc (download) # cd /go/src/github.com/fluffle/goirc; git symbolic-ref HEAD fatal: ref HEAD is not a symbolic ref /go/src/github.com/fluffle/goirc on detached head; repairing github.com/fluffle/golog (download) # cd /go/src/github.com/fluffle/golog; git symbolic-ref HEAD fatal: ref HEAD is not a symbolic ref /go/src/github.com/fluffle/golog on detached head; repairing launchpad.net/goyaml (download) code.google.com/p/go.net (download) github.com/bmizerany/pat (download) github.com/dchest/authcookie (download) github.com/dchest/passwordreset (download) github.com/drone/go-github (download) github.com/drone/go-bitbucket (download) github.com/plouc/go-gitlab-client (download) github.com/smartystreets/goconvey (download) github.com/jacobsa/oglematchers (download) github.com/fluffle/goirc/state drone/pkg/handler/testing go build drone/pkg/handler/testing: no buildable Go source files in /go/src/drone/pkg/handler/testing github.com/fluffle/goirc/client github.com/drone/drone/pkg/plugin/notify drone/pkg/plugin/notify github.com/drone/drone/pkg/build/script drone/pkg/build/script github.com/drone/drone/pkg/build drone/pkg/build drone/cmd/drone github.com/drone/drone/pkg/queue github.com/drone/drone/pkg/handler drone/cmd/droned drone/pkg/handler drone/pkg/queue make: **\* [deps] Error 1",other-file | documentation-file | other-file | source-file,"make deps error I'm quite new to drone, so please help me if you could, thanks! root@drone:/go/src/drone# make deps go get -u -t -v ./ drone (download) bitbucket.org/kardianos/osext (download) code.google.com/p/go.crypto (download) code.google.com/p/go.text (download) code.google.com/p/gomock (download) github.com/GeertJohan/go.rice (download) github.com/daaku/go.zipexe (download) github.com/andybons/hipchat (download) github.com/dchest/uniuri (download) github.com/dotcloud/docker (download) github.com/drone/drone (download) github.com/go-sql-driver/mysql (download) github.com/mattn/go-sqlite3 (download) github.com/russross/meddler (download) github.com/fluffle/goevent (download) # cd /go/src/github.com/fluffle/goevent; git symbolic-ref HEAD fatal: ref HEAD is not a symbolic ref /go/src/github.com/fluffle/goevent on detached head; repairing github.com/fluffle/goirc (download) # cd /go/src/github.com/fluffle/goirc; git symbolic-ref HEAD fatal: ref HEAD is not a symbolic ref /go/src/github.com/fluffle/goirc on detached head; repairing github.com/fluffle/golog (download) # cd /go/src/github.com/fluffle/golog; git symbolic-ref HEAD fatal: ref HEAD is not a symbolic ref /go/src/github.com/fluffle/golog on detached head; repairing launchpad.net/goyaml (download) code.google.com/p/go.net (download) github.com/bmizerany/pat (download) github.com/dchest/authcookie (download) github.com/dchest/passwordreset (download) github.com/drone/go-github (download) github.com/drone/go-bitbucket (download) github.com/plouc/go-gitlab-client (download) github.com/smartystreets/goconvey (download) github.com/jacobsa/oglematchers (download) github.com/fluffle/goirc/state drone/pkg/handler/testing go build drone/pkg/handler/testing: no buildable Go source files in /go/src/drone/pkg/handler/testing github.com/fluffle/goirc/client github.com/drone/drone/pkg/plugin/notify drone/pkg/plugin/notify github.com/drone/drone/pkg/build/script drone/pkg/build/script github.com/drone/drone/pkg/build drone/pkg/build drone/cmd/drone github.com/drone/drone/pkg/queue github.com/drone/drone/pkg/handler drone/cmd/droned drone/pkg/handler drone/pkg/queue make: **\* [deps] Error 1 other-file documentation-file other-file source-file",no-bug,0.95
2553,harness,https://github.com/harness/harness/issues/2553,E-mail plugin reports build as succesfull even though other pipelines failed,"After updating to 1.0 I've converted a matrix build to a multi-machine with a notify step which depends on the previous pipelines, similar to what is suggested here: https://docs.drone.io/user-guide/pipeline/multi-machine/ Instead of Slack, I'm using the e-mail plugin though: yaml  kind: pipeline name: notify clone: disable: true steps: - name: notify image: drillster/drone-email settings: #  depends_on: - pipeline_a - pipeline_b trigger: status: - failure  Even though all pipeline_a and pipeline_b failed, I'm getting an email with the message ""Successful build #xy"". I guess this is because the plugin gets the status of its own machine / pipeline, not the status of the whole build?",source-file | source-file | source-file | source-file | database-file | database-file | database-file | source-file | database-file | database-file,"E-mail plugin reports build as succesfull even though other pipelines failed After updating to 1.0 I've converted a matrix build to a multi-machine with a notify step which depends on the previous pipelines, similar to what is suggested here: https://docs.drone.io/user-guide/pipeline/multi-machine/ Instead of Slack, I'm using the e-mail plugin though: yaml  kind: pipeline name: notify clone: disable: true steps: - name: notify image: drillster/drone-email settings: #  depends_on: - pipeline_a - pipeline_b trigger: status: - failure  Even though all pipeline_a and pipeline_b failed, I'm getting an email with the message ""Successful build #xy"". I guess this is because the plugin gets the status of its own machine / pipeline, not the status of the whole build? source-file source-file source-file source-file database-file database-file database-file source-file database-file database-file",no-bug,0.9
1810,harness,https://github.com/harness/harness/issues/1810,drone exec panic when missing interpolation variables,"example yaml file:  pipeline: build: image: plugins/docker repo: ${DRONE_REPO} tag: ${DRONE_COMMIT}  panic output:  panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0xa0 pc=0x305368] goroutine 1 [running]: panic(0x7f8cc0, 0x820ed20c0) /usr/local/go/src/runtime/panic.go:481 +0x3e6 github.com/drone/drone/yaml/transform.argsToEnv(0x8210d6b40, 0x8210d6c60, 0x0, 0x0) /go/src/github.com/drone/drone/yaml/transform/util.go:23 +0x258 github.com/drone/drone/yaml/transform.PluginParams(0x8210e0580, 0x0, 0x0) /go/src/github.com/drone/drone/yaml/transform/plugin.go:41 +0x12e github.com/drone/drone/agent.(*Agent).prep(0x8213d5180, 0x8210e0180, 0xd9aec0, 0x0, 0x0) /go/src/github.com/drone/drone/agent/agent.go:163 +0xcd5 github.com/drone/drone/agent.(*Agent).Run(0x8213d5180, 0x8210e0180, 0x8210ac8c0, 0x0, 0x0) /go/src/github.com/drone/drone/agent/agent.go:56 +0xa9 main.exec(0x8210abd40, 0x0, 0x0) /go/src/github.com/drone/drone/drone/exec.go:420 +0x21e6 main.glob.func10(0x8210abd40) /go/src/github.com/drone/drone/drone/exec.go:27 +0x25 github.com/drone/drone/vendor/github.com/codegangsta/cli.Command.Run(0x8f0be0, 0x4, 0x0, 0x0, 0x0, 0x0, 0x0, 0x97c790, 0x15, 0x0, ) /go/src/github.com/drone/drone/vendor/github.com/codegangsta/cli/command.go:131 +0x1058 github.com/drone/drone/vendor/github.com/codegangsta/cli.(*App).Run(0x8210abb00, 0x820f4a060, 0x2, 0x2, 0x0, 0x0) /go/src/github.com/drone/drone/vendor/github.com/codegangsta/cli/app.go:175 +0xfd1 main.main() ",source-file,"drone exec panic when missing interpolation variables example yaml file:  pipeline: build: image: plugins/docker repo: ${DRONE_REPO} tag: ${DRONE_COMMIT}  panic output:  panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0xa0 pc=0x305368] goroutine 1 [running]: panic(0x7f8cc0, 0x820ed20c0) /usr/local/go/src/runtime/panic.go:481 +0x3e6 github.com/drone/drone/yaml/transform.argsToEnv(0x8210d6b40, 0x8210d6c60, 0x0, 0x0) /go/src/github.com/drone/drone/yaml/transform/util.go:23 +0x258 github.com/drone/drone/yaml/transform.PluginParams(0x8210e0580, 0x0, 0x0) /go/src/github.com/drone/drone/yaml/transform/plugin.go:41 +0x12e github.com/drone/drone/agent.(*Agent).prep(0x8213d5180, 0x8210e0180, 0xd9aec0, 0x0, 0x0) /go/src/github.com/drone/drone/agent/agent.go:163 +0xcd5 github.com/drone/drone/agent.(*Agent).Run(0x8213d5180, 0x8210e0180, 0x8210ac8c0, 0x0, 0x0) /go/src/github.com/drone/drone/agent/agent.go:56 +0xa9 main.exec(0x8210abd40, 0x0, 0x0) /go/src/github.com/drone/drone/drone/exec.go:420 +0x21e6 main.glob.func10(0x8210abd40) /go/src/github.com/drone/drone/drone/exec.go:27 +0x25 github.com/drone/drone/vendor/github.com/codegangsta/cli.Command.Run(0x8f0be0, 0x4, 0x0, 0x0, 0x0, 0x0, 0x0, 0x97c790, 0x15, 0x0, ) /go/src/github.com/drone/drone/vendor/github.com/codegangsta/cli/command.go:131 +0x1058 github.com/drone/drone/vendor/github.com/codegangsta/cli.(*App).Run(0x8210abb00, 0x820f4a060, 0x2, 0x2, 0x0, 0x0) /go/src/github.com/drone/drone/vendor/github.com/codegangsta/cli/app.go:175 +0xfd1 main.main()  source-file",no-bug,0.9
24,harness,https://github.com/harness/harness/issues/24,"Error ""dial tcp 0.0.0.0:4243: connection refused"" when running test","Thanks for opensourcing this, it is really amazing! After installing on Ubuntu 12.04 in virtualbox and setting up this repo: https://github.com/tax/testdrone I get the following error when a test is run:  dial tcp 0.0.0.0:4243: connection refused  This is my .drone.yml file:  image: python:2.7 script: - python test.py notify: email: recipients: - paultax@gmail.com  Any idea what might be the problem?",source-file | source-file | documentation-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | source-file | documentation-file | source-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file,"Error ""dial tcp 0.0.0.0:4243: connection refused"" when running test Thanks for opensourcing this, it is really amazing! After installing on Ubuntu 12.04 in virtualbox and setting up this repo: https://github.com/tax/testdrone I get the following error when a test is run:  dial tcp 0.0.0.0:4243: connection refused  This is my .drone.yml file:  image: python:2.7 script: - python test.py notify: email: recipients: - paultax@gmail.com  Any idea what might be the problem? source-file source-file documentation-file other-file other-file source-file other-file other-file other-file source-file source-file documentation-file source-file source-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file documentation-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file",no-bug,0.9
828,harness,https://github.com/harness/harness/issues/828,Selective email notifications,"Is there a way to receive selective email notifications? I am not interested in seeing ""yes, your build is still green"" stuff, yet absolutely care to know the following: 1. build failures 2. or, even better, changes in the build status This stuff is done quite well in Travis CI. Is there a way to configure at least (1) on Drone? Thanks!",other-file | other-file,"Selective email notifications Is there a way to receive selective email notifications? I am not interested in seeing ""yes, your build is still green"" stuff, yet absolutely care to know the following: 1. build failures 2. or, even better, changes in the build status This stuff is done quite well in Travis CI. Is there a way to configure at least (1) on Drone? Thanks! other-file other-file",no-bug,0.95
548,harness,https://github.com/harness/harness/issues/548,Commitstore.KillCommits is causing an init-time panic,"This is a vanilla DigitalOcean Ubuntu 14.04 + Docker 1.2 droplet (1gb)  ciarand@drone:~$ sudo tail /var/log/upstart/drone.log goroutine 17 [syscall]: runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 25 [runnable]: github.com/drone/drone/server/datastore/database.(*Commitstore).KillCommits(0xc208036cb0, 0xc208050a80, 0xc208036cb0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/commit.go:75 created by main.main /var/cache/drone/src/github.com/drone/drone/server/main.go:103 +0x27e  Any idea?",other-file | other-file | other-file | other-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file,"Commitstore.KillCommits is causing an init-time panic This is a vanilla DigitalOcean Ubuntu 14.04 + Docker 1.2 droplet (1gb)  ciarand@drone:~$ sudo tail /var/log/upstart/drone.log goroutine 17 [syscall]: runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 25 [runnable]: github.com/drone/drone/server/datastore/database.(*Commitstore).KillCommits(0xc208036cb0, 0xc208050a80, 0xc208036cb0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/commit.go:75 created by main.main /var/cache/drone/src/github.com/drone/drone/server/main.go:103 +0x27e  Any idea? other-file other-file other-file other-file documentation-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file other-file",no-bug,0.9
81,harness,https://github.com/harness/harness/issues/81,Add ability to split tests to execute in different containers,"Hi! It will be very good to have ability to split tests to N containers. For languages like ruby, it will dramatically decrease execution time. Is it possible?",source-file | documentation-file | other-file | other-file,"Add ability to split tests to execute in different containers Hi! It will be very good to have ability to split tests to N containers. For languages like ruby, it will dramatically decrease execution time. Is it possible? source-file documentation-file other-file other-file",no-bug,0.95
516,harness,https://github.com/harness/harness/issues/516,Add global config for npm publish and ability to set always-auth,"It would be great to expose the npm publish options globally so they can be set within the config file. This ensures that user accounts for private npm servers are not exposed within the drone config. Additionally for private repositories to set always-auth within the config. This is used by private npm servers like sinopia, https://www.npmjs.org/package/sinopia. The command is `npm set always-auth true` By default it is false. See https://www.npmjs.org/doc/misc/npm-config.html",source-file | source-file | test-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | documentation-file | source-file,"Add global config for npm publish and ability to set always-auth It would be great to expose the npm publish options globally so they can be set within the config file. This ensures that user accounts for private npm servers are not exposed within the drone config. Additionally for private repositories to set always-auth within the config. This is used by private npm servers like sinopia, https://www.npmjs.org/package/sinopia. The command is `npm set always-auth true` By default it is false. See https://www.npmjs.org/doc/misc/npm-config.html source-file source-file test-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file other-file other-file other-file source-file other-file other-file source-file documentation-file other-file other-file other-file other-file documentation-file source-file",no-bug,0.9
2229,harness,https://github.com/harness/harness/issues/2229,Whitelist/blacklist for plugins,I would like to have a UI to define which plugins could be executed and read the information from drone for a security consideration.,other-file | other-file,Whitelist/blacklist for plugins I would like to have a UI to define which plugins could be executed and read the information from drone for a security consideration. other-file other-file,no-bug,0.9
2078,harness,https://github.com/harness/harness/issues/2078,Commit author email is empty with gogs/gitea providers,"Gitea version: 1.1.2 Drone version: 0.7.1 Steps to reproduce: * setup a Gitea 1.1.2 instance * setup drone server/agent with following docker-compose.yml  services: drone-server: image: drone/drone:0.7.1 ports: - 80:8000 volumes: - ./drone:/var/lib/drone/ restart: always environment: - DRONE_OPEN=false - DRONE_GITEA=true - DRONE_GITEA_URL=https://git.company.com/ - DRONE_GITEA_PRIVATE_MODE:true - DRONE_SECRET=<something> drone-agent: image: drone/drone:0.7.1 command: agent restart: always depends_on: [ drone-server ] volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=ws://drone-server:8000/ws/broker - DRONE_SECRET=<something>  * create and active a repository with following .drone.yml  pipeline: debug: image: alpine:3.4 commands: - env  Expected behavior: in the build output, see `DRONE_COMMIT_AUTHOR_EMAIL`. Actual behavior: No `DRONE_COMMIT_AUTHOR_EMAIL` in build output, or any environment variable with email. Extra information: * I tried with Gogs provider, but same result. * Post hook payload with removed sensitive information  { ""secret"": ""<removed>"", ""ref"": ""refs/heads/master"", ""before"": ""9a6d4950fcd4b23593693b66281dc9737998f3c0"", ""after"": ""e1ce9a14a8c89a968de7511a389912661be93ac4"", ""compare_url"": ""https://git.company.com/ci/drone-test/compare/9a6d4950fcd4b23593693b66281dc9737998f3c0e1ce9a14a8c89a968de7511a389912661be93ac4"", ""commits"": [ { ""id"": ""e1ce9a14a8c89a968de7511a389912661be93ac4"", ""message"": ""do something\n"", ""url"": ""https://git.company.com/ci/drone-test/commit/e1ce9a14a8c89a968de7511a389912661be93ac4"", ""author"": { ""name"": ""My Real Name"", ""email"": ""me@myemail.com"", ""username"": ""my_username"" }, ""committer"": { ""name"": ""My Real Name"", ""email"": ""me@myemail.com"", ""username"": ""my_username"" }, ""timestamp"": ""2017-06-20T08:39:13Z"" } ], ""repository"": { ""id"": 7, ""owner"": { ""id"": 3, ""login"": ""ci"", ""full_name"": """", ""email"": ""ci@my_username.com"", ""avatar_url"": ""https://secure.gravatar.com/avatar/795cee0be515bbc377c8da227c0a0363"", ""username"": ""ci"" }, ""name"": ""drone-test"", ""full_name"": ""ci/drone-test"", ""description"": """", ""private"": true, ""fork"": false, ""mirror"": false, ""html_url"": ""https://git.company.com/ci/drone-test"", ""ssh_url"": ""ssh://git@git.company.com:2222/ci/drone-test.git"", ""clone_url"": ""https://git.company.com/ci/drone-test.git"", ""website"": """", ""stars_count"": 0, ""forks_count"": 0, ""watchers_count"": 1, ""open_issues_count"": 0, ""default_branch"": ""master"", ""created_at"": ""2017-04-18T07:39:22Z"", ""updated_at"": ""2017-06-20T08:08:36Z"", ""permissions"": { ""admin"": false, ""push"": false, ""pull"": false } }, ""pusher"": { ""id"": 1, ""login"": ""my_username"", ""full_name"": ""My Real Name"", ""email"": ""me@myemail.com"", ""avatar_url"": ""https://git.company.com/avatars/74170010fb38c17915d187346da8a985"", ""username"": ""my_username"" }, ""sender"": { ""id"": 1, ""login"": ""my_username"", ""full_name"": ""My Real Name"", ""email"": ""me@myemail.com"", ""avatar_url"": ""https://git.company.com/avatars/74170010fb38c17915d187346da8a985"", ""username"": ""my_username"" } } ",other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | source-file | source-file | documentation-file | other-file | documentation-file,"Commit author email is empty with gogs/gitea providers Gitea version: 1.1.2 Drone version: 0.7.1 Steps to reproduce: * setup a Gitea 1.1.2 instance * setup drone server/agent with following docker-compose.yml  services: drone-server: image: drone/drone:0.7.1 ports: - 80:8000 volumes: - ./drone:/var/lib/drone/ restart: always environment: - DRONE_OPEN=false - DRONE_GITEA=true - DRONE_GITEA_URL=https://git.company.com/ - DRONE_GITEA_PRIVATE_MODE:true - DRONE_SECRET=<something> drone-agent: image: drone/drone:0.7.1 command: agent restart: always depends_on: [ drone-server ] volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=ws://drone-server:8000/ws/broker - DRONE_SECRET=<something>  * create and active a repository with following .drone.yml  pipeline: debug: image: alpine:3.4 commands: - env  Expected behavior: in the build output, see `DRONE_COMMIT_AUTHOR_EMAIL`. Actual behavior: No `DRONE_COMMIT_AUTHOR_EMAIL` in build output, or any environment variable with email. Extra information: * I tried with Gogs provider, but same result. * Post hook payload with removed sensitive information  { ""secret"": ""<removed>"", ""ref"": ""refs/heads/master"", ""before"": ""9a6d4950fcd4b23593693b66281dc9737998f3c0"", ""after"": ""e1ce9a14a8c89a968de7511a389912661be93ac4"", ""compare_url"": ""https://git.company.com/ci/drone-test/compare/9a6d4950fcd4b23593693b66281dc9737998f3c0e1ce9a14a8c89a968de7511a389912661be93ac4"", ""commits"": [ { ""id"": ""e1ce9a14a8c89a968de7511a389912661be93ac4"", ""message"": ""do something\n"", ""url"": ""https://git.company.com/ci/drone-test/commit/e1ce9a14a8c89a968de7511a389912661be93ac4"", ""author"": { ""name"": ""My Real Name"", ""email"": ""me@myemail.com"", ""username"": ""my_username"" }, ""committer"": { ""name"": ""My Real Name"", ""email"": ""me@myemail.com"", ""username"": ""my_username"" }, ""timestamp"": ""2017-06-20T08:39:13Z"" } ], ""repository"": { ""id"": 7, ""owner"": { ""id"": 3, ""login"": ""ci"", ""full_name"": """", ""email"": ""ci@my_username.com"", ""avatar_url"": ""https://secure.gravatar.com/avatar/795cee0be515bbc377c8da227c0a0363"", ""username"": ""ci"" }, ""name"": ""drone-test"", ""full_name"": ""ci/drone-test"", ""description"": """", ""private"": true, ""fork"": false, ""mirror"": false, ""html_url"": ""https://git.company.com/ci/drone-test"", ""ssh_url"": ""ssh://git@git.company.com:2222/ci/drone-test.git"", ""clone_url"": ""https://git.company.com/ci/drone-test.git"", ""website"": """", ""stars_count"": 0, ""forks_count"": 0, ""watchers_count"": 1, ""open_issues_count"": 0, ""default_branch"": ""master"", ""created_at"": ""2017-04-18T07:39:22Z"", ""updated_at"": ""2017-06-20T08:08:36Z"", ""permissions"": { ""admin"": false, ""push"": false, ""pull"": false } }, ""pusher"": { ""id"": 1, ""login"": ""my_username"", ""full_name"": ""My Real Name"", ""email"": ""me@myemail.com"", ""avatar_url"": ""https://git.company.com/avatars/74170010fb38c17915d187346da8a985"", ""username"": ""my_username"" }, ""sender"": { ""id"": 1, ""login"": ""my_username"", ""full_name"": ""My Real Name"", ""email"": ""me@myemail.com"", ""avatar_url"": ""https://git.company.com/avatars/74170010fb38c17915d187346da8a985"", ""username"": ""my_username"" } }  other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file source-file other-file source-file other-file source-file other-file source-file other-file other-file other-file source-file source-file documentation-file other-file documentation-file",no-bug,0.8
453,harness,https://github.com/harness/harness/issues/453,Handle Token Expiration,"Scenario: 1. User sets up a private Github repository in Drone 2. Time passes 3. User's Github token expires 4. Drone builds break unexpectedly and with zero explanation The first build attempt after the token expires will result in a ""No .drone.yml was found in this repository. You need to add one."" message, which might prompt somebody to look in the repo and confirm that `.drone.yml` is indeed there, shrug, and retry the build. This time the error is even less heplful: ""Error: missing Docker image"". This again gives zero information about what the actual failure is. Looking in the Drone log does not help either; the error received from Github while trying to fetch `.drone.yml` is not logged _anywhere_. Now, let's assume that I somehow figure out that the issue is an expired token. What do I do? I'm not the user who created the repo (and that actual user no longer works at the company). I have no way to reassign a repo to myself. I have no way to refresh the token. It's not even obvious how I can get a token for my own user. Fixing this required me to try to add a new repo just to trigger the Github authentication so that my user can acquire a Github token, and then manually remap all affected repos in `drone.sqlite` to my user. I can't help but wonder if this is the right way to handle this.",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Handle Token Expiration Scenario: 1. User sets up a private Github repository in Drone 2. Time passes 3. User's Github token expires 4. Drone builds break unexpectedly and with zero explanation The first build attempt after the token expires will result in a ""No .drone.yml was found in this repository. You need to add one."" message, which might prompt somebody to look in the repo and confirm that `.drone.yml` is indeed there, shrug, and retry the build. This time the error is even less heplful: ""Error: missing Docker image"". This again gives zero information about what the actual failure is. Looking in the Drone log does not help either; the error received from Github while trying to fetch `.drone.yml` is not logged _anywhere_. Now, let's assume that I somehow figure out that the issue is an expired token. What do I do? I'm not the user who created the repo (and that actual user no longer works at the company). I have no way to reassign a repo to myself. I have no way to refresh the token. It's not even obvious how I can get a token for my own user. Fixing this required me to try to add a new repo just to trigger the Github authentication so that my user can acquire a Github token, and then manually remap all affected repos in `drone.sqlite` to my user. I can't help but wonder if this is the right way to handle this. other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
45,harness,https://github.com/harness/harness/issues/45,Include a more modern Haskell image,How can someone submit a newer Haskell build? 7.4 is very outdated. A better target would be the 2013.2.0.0 Haskell Platform (https://index.docker.io/u/zsol/haskell-platform-2013.2.0.0/) which has upgraded to GHC 7.6.3. There's also a new Haskell Platform on its way which might even include GHC 7.8.,documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | other-file | source-file | source-file | source-file,Include a more modern Haskell image How can someone submit a newer Haskell build? 7.4 is very outdated. A better target would be the 2013.2.0.0 Haskell Platform (https://index.docker.io/u/zsol/haskell-platform-2013.2.0.0/) which has upgraded to GHC 7.6.3. There's also a new Haskell Platform on its way which might even include GHC 7.8. documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file other-file source-file source-file source-file,no-bug,0.95
747,harness,https://github.com/harness/harness/issues/747,need option to disable the tick at the end of the build,It messes with display of logs in centralized logging tools  would be great to be able to toggle it off.,source-file,need option to disable the tick at the end of the build It messes with display of logs in centralized logging tools  would be great to be able to toggle it off. source-file,no-bug,0.9
917,harness,https://github.com/harness/harness/issues/917,Document MySQL database creation,"i setup a server like described, but drone don't create the database itself. http://readme.drone.io/setup/database/mysql/  panic: Could not get DB version: Error 1049: Unknown database 'drone' goroutine 16 [running]: runtime.panic(0xab3d40, 0xc2081371b0) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 github.com/drone/drone/server/datastore/database.MustConnect(0xc208136e10, 0x5, 0xc20811ed80, 0x1e, 0x0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:52 +0x8a main.main() /var/cache/drone/src/github.com/drone/drone/server/main.go:104 +0x274 goroutine 19 [finalizer wait]: runtime.park(0x4a8570, 0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 runtime.parkunlock(0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 22 [syscall]: os/signal.loop() /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e created by os/signal.init1 /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 goroutine 24 [chan receive]: database/sql.(*DB).connectionOpener(0xc208050380) /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 created by database/sql.Open /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c ",documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,"Document MySQL database creation i setup a server like described, but drone don't create the database itself. http://readme.drone.io/setup/database/mysql/  panic: Could not get DB version: Error 1049: Unknown database 'drone' goroutine 16 [running]: runtime.panic(0xab3d40, 0xc2081371b0) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 github.com/drone/drone/server/datastore/database.MustConnect(0xc208136e10, 0x5, 0xc20811ed80, 0x1e, 0x0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:52 +0x8a main.main() /var/cache/drone/src/github.com/drone/drone/server/main.go:104 +0x274 goroutine 19 [finalizer wait]: runtime.park(0x4a8570, 0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 runtime.parkunlock(0x11caf90, 0x11b59e9) /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 22 [syscall]: os/signal.loop() /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e created by os/signal.init1 /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 goroutine 24 [chan receive]: database/sql.(*DB).connectionOpener(0xc208050380) /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 created by database/sql.Open /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c  documentation-file source-file source-file source-file source-file source-file source-file source-file other-file",no-bug,0.9
2768,harness,https://github.com/harness/harness/issues/2768,"v0.8.0, Registry credentials not provided. Guest mode enabled.","![image](https://user-images.githubusercontent.com/1992933/62264475-a29c9700-b452-11e9-86fb-731759767eee.png) ![image](https://user-images.githubusercontent.com/1992933/62264507-c65fdd00-b452-11e9-99e3-e13258c876a5.png) + /usr/local/bin/dockerd -g /var/lib/docker --registry-mirror http://f1361db2.m.daocloud.io Registry credentials not provided. Guest mode enabled. + /usr/local/bin/docker version Client: Version: 17.12.0-ce API version: 1.35 Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:05:38 2017 OS/Arch: linux/amd64 Server: Engine: Version: 17.12.0-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:12:29 2017 OS/Arch: linux/amd64 Experimental: false + /usr/local/bin/docker info Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 17.12.0-ce Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 89623f28b87a6004d4b785663257362d1658a729 runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8f init version: 949e6fa Security Options: seccomp Profile: default Kernel Version: 3.10.0-862.9.1.el7.x86_64 Operating System: Alpine Linux v3.7 (containerized) OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.46GiB Name: a5f0e6b868cf ID: YMC3:WSVQ:JXWE:KJEE:7PTM:CMDM:4YM5:M2UV:BVYM:WRIP:I6FA:R6TE Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ WARNING: bridge-nf-call-iptables is disabled WARNING: bridge-nf-call-ip6tables is disabled Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Registry Mirrors: http://f1361db2.m.daocloud.io/ Live Restore Enabled: false + /usr/local/bin/docker build --rm=true -f Dockerfile -t ed70e9639c3869829ab1d26ae1c0e2b553335966 . --pull=true --label org.label-schema.schema-version=1.0 --label org.label-schema.build-date=2019-08-01T02:50:16Z --label org.label-schema.vcs-ref=ed70e9639c3869829ab1d26ae1c0e2b553335966 --label org.label-schema.vcs-url=https://git.changhong.com/hlj/industry-equipment-center-fe.git Sending build context to Docker daemon 16.17MB Step 1/10 : FROM registry.changhong.com/ssc_yb_lfl/nginx:alpine alpine: Pulling from ssc_yb_lfl/nginx e7c96db7181b: Pulling fs layer 3fb6217217ef: Pulling fs layer e7c96db7181b: Verifying Checksum e7c96db7181b: Download complete 3fb6217217ef: Verifying Checksum 3fb6217217ef: Download complete e7c96db7181b: Pull complete 3fb6217217ef: Pull complete Digest: sha256:20b62c392073deac500292d6b37c851bb4d00986edb3d73d08c0f0e65019ce6c Status: Downloaded newer image for registry.changhong.com/ssc_yb_lfl/nginx:alpine > ea1193fd3dde Step 2/10 : MAINTAINER Say.li <120011676@qq.com> > Running in 591e3dea1d5e Removing intermediate container 591e3dea1d5e > 5049aa21ca93 Step 3/10 : LABEL maintainer=""Say.li <120011676@qq.com>"" > Running in dd541d26b153 Removing intermediate container dd541d26b153 > d5693b4a7997 Step 4/10 : ENV TZ Asia/Shanghai > Running in f69e48b3bdf0 Removing intermediate container f69e48b3bdf0 > 6cad896226fd Step 5/10 : RUN apk --update add tzdata && ln -sf /usr/share/zoneinfo/${TZ} /etc/localtime && echo ${TZ} > /etc/timezone > Running in 9dbf9558203a fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/community/x86_64/APKINDEX.tar.gz OK: 27 MiB in 37 packages Removing intermediate container 9dbf9558203a > b81832e6f697 Step 6/10 : COPY ./nginx/ /etc/nginx/ > df4193ec26a9 Step 7/10 : COPY ./dist /usr/share/nginx/html/ec > 5b60aebdcb7c Step 8/10 : EXPOSE 80 > Running in ee4a3b345801 Removing intermediate container ee4a3b345801 > ca2e4dd36b44 Step 9/10 : CMD envsubst '$RCG_MGR_SERVER_URL $RCG_MGR_SERVER_LOCATION $MGR_HTML_LOCATION' < /etc/nginx/conf.d/default.conf.tpl > /etc/nginx/conf.d/default.conf && nginx -g 'daemon off;' > Running in 713ae4b5d01d Removing intermediate container 713ae4b5d01d > 3ddd0b567571 Step 10/10 : LABEL ""org.label-schema.build-date""='2019-08-01T02:50:16Z' ""org.label-schema.schema-version""='1.0' ""org.label-schema.vcs-ref""='ed70e9639c3869829ab1d26ae1c0e2b553335966' ""org.label-schema.vcs-url""='https://git.changhong.com/hlj/industry-equipment-center-fe.git' > Running in b4679ac4d10e Removing intermediate container b4679ac4d10e > ca07aae29772 Successfully built ca07aae29772 Successfully tagged ed70e9639c3869829ab1d26ae1c0e2b553335966:latest + /usr/local/bin/docker tag ed70e9639c3869829ab1d26ae1c0e2b553335966 registry.changhong.com/industry/platform-ec-html:test_136 + /usr/local/bin/docker push registry.changhong.com/industry/platform-ec-html:test_136 The push refers to repository [registry.changhong.com/industry/platform-ec-html] 34fbea13f7bb: Preparing 886d81c6454a: Preparing b949f30766a7: Preparing fbe0fc9bcf95: Preparing f1b5933fe4b5: Preparing denied: requested access to the resource is denied time=""2019-08-01T02:51:06Z"" level=fatal msg=""exit status 1""",source-file | database-file | database-file | database-file | database-file | source-file,"v0.8.0, Registry credentials not provided. Guest mode enabled. ![image](https://user-images.githubusercontent.com/1992933/62264475-a29c9700-b452-11e9-86fb-731759767eee.png) ![image](https://user-images.githubusercontent.com/1992933/62264507-c65fdd00-b452-11e9-99e3-e13258c876a5.png) + /usr/local/bin/dockerd -g /var/lib/docker --registry-mirror http://f1361db2.m.daocloud.io Registry credentials not provided. Guest mode enabled. + /usr/local/bin/docker version Client: Version: 17.12.0-ce API version: 1.35 Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:05:38 2017 OS/Arch: linux/amd64 Server: Engine: Version: 17.12.0-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:12:29 2017 OS/Arch: linux/amd64 Experimental: false + /usr/local/bin/docker info Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 17.12.0-ce Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 89623f28b87a6004d4b785663257362d1658a729 runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8f init version: 949e6fa Security Options: seccomp Profile: default Kernel Version: 3.10.0-862.9.1.el7.x86_64 Operating System: Alpine Linux v3.7 (containerized) OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.46GiB Name: a5f0e6b868cf ID: YMC3:WSVQ:JXWE:KJEE:7PTM:CMDM:4YM5:M2UV:BVYM:WRIP:I6FA:R6TE Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ WARNING: bridge-nf-call-iptables is disabled WARNING: bridge-nf-call-ip6tables is disabled Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Registry Mirrors: http://f1361db2.m.daocloud.io/ Live Restore Enabled: false + /usr/local/bin/docker build --rm=true -f Dockerfile -t ed70e9639c3869829ab1d26ae1c0e2b553335966 . --pull=true --label org.label-schema.schema-version=1.0 --label org.label-schema.build-date=2019-08-01T02:50:16Z --label org.label-schema.vcs-ref=ed70e9639c3869829ab1d26ae1c0e2b553335966 --label org.label-schema.vcs-url=https://git.changhong.com/hlj/industry-equipment-center-fe.git Sending build context to Docker daemon 16.17MB Step 1/10 : FROM registry.changhong.com/ssc_yb_lfl/nginx:alpine alpine: Pulling from ssc_yb_lfl/nginx e7c96db7181b: Pulling fs layer 3fb6217217ef: Pulling fs layer e7c96db7181b: Verifying Checksum e7c96db7181b: Download complete 3fb6217217ef: Verifying Checksum 3fb6217217ef: Download complete e7c96db7181b: Pull complete 3fb6217217ef: Pull complete Digest: sha256:20b62c392073deac500292d6b37c851bb4d00986edb3d73d08c0f0e65019ce6c Status: Downloaded newer image for registry.changhong.com/ssc_yb_lfl/nginx:alpine > ea1193fd3dde Step 2/10 : MAINTAINER Say.li <120011676@qq.com> > Running in 591e3dea1d5e Removing intermediate container 591e3dea1d5e > 5049aa21ca93 Step 3/10 : LABEL maintainer=""Say.li <120011676@qq.com>"" > Running in dd541d26b153 Removing intermediate container dd541d26b153 > d5693b4a7997 Step 4/10 : ENV TZ Asia/Shanghai > Running in f69e48b3bdf0 Removing intermediate container f69e48b3bdf0 > 6cad896226fd Step 5/10 : RUN apk --update add tzdata && ln -sf /usr/share/zoneinfo/${TZ} /etc/localtime && echo ${TZ} > /etc/timezone > Running in 9dbf9558203a fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/community/x86_64/APKINDEX.tar.gz OK: 27 MiB in 37 packages Removing intermediate container 9dbf9558203a > b81832e6f697 Step 6/10 : COPY ./nginx/ /etc/nginx/ > df4193ec26a9 Step 7/10 : COPY ./dist /usr/share/nginx/html/ec > 5b60aebdcb7c Step 8/10 : EXPOSE 80 > Running in ee4a3b345801 Removing intermediate container ee4a3b345801 > ca2e4dd36b44 Step 9/10 : CMD envsubst '$RCG_MGR_SERVER_URL $RCG_MGR_SERVER_LOCATION $MGR_HTML_LOCATION' < /etc/nginx/conf.d/default.conf.tpl > /etc/nginx/conf.d/default.conf && nginx -g 'daemon off;' > Running in 713ae4b5d01d Removing intermediate container 713ae4b5d01d > 3ddd0b567571 Step 10/10 : LABEL ""org.label-schema.build-date""='2019-08-01T02:50:16Z' ""org.label-schema.schema-version""='1.0' ""org.label-schema.vcs-ref""='ed70e9639c3869829ab1d26ae1c0e2b553335966' ""org.label-schema.vcs-url""='https://git.changhong.com/hlj/industry-equipment-center-fe.git' > Running in b4679ac4d10e Removing intermediate container b4679ac4d10e > ca07aae29772 Successfully built ca07aae29772 Successfully tagged ed70e9639c3869829ab1d26ae1c0e2b553335966:latest + /usr/local/bin/docker tag ed70e9639c3869829ab1d26ae1c0e2b553335966 registry.changhong.com/industry/platform-ec-html:test_136 + /usr/local/bin/docker push registry.changhong.com/industry/platform-ec-html:test_136 The push refers to repository [registry.changhong.com/industry/platform-ec-html] 34fbea13f7bb: Preparing 886d81c6454a: Preparing b949f30766a7: Preparing fbe0fc9bcf95: Preparing f1b5933fe4b5: Preparing denied: requested access to the resource is denied time=""2019-08-01T02:51:06Z"" level=fatal msg=""exit status 1"" source-file database-file database-file database-file database-file source-file",no-bug,0.9
3277,harness,https://github.com/harness/harness/issues/3277,Params are empty when branch is empty,When - When you do not set any branch in the Create Build Option but set params Issue - params in the build context is empty when you want to go with default branch of your repo but want to use some params Reproduce - Set a parameter value like `test : 2` and trigger the build. Log `ctx.build.params` which will be empty,other-file,Params are empty when branch is empty When - When you do not set any branch in the Create Build Option but set params Issue - params in the build context is empty when you want to go with default branch of your repo but want to use some params Reproduce - Set a parameter value like `test : 2` and trigger the build. Log `ctx.build.params` which will be empty other-file,no-bug,0.7
3601,harness,https://github.com/harness/harness/issues/3601,fatal: detected dubious ownership in repository,"When I transfer the data in the `data` to another linux system, I cannot access the repository in harness web.  harness | {""level"":""warn"",""http.router"":""api"",""http.router"":""api"",""http.url"":""/v1/repos/Moda%2FTvNotice/content?include_commit=true&git_ref=refs%2Fheads%2Fmain"",""http.method"":""GET"",""request_id"":""cte057g334hc73e2iie0"",""principal_uid"":""admin"",""principal_type"":""user"",""principal_admin"":true,""error"":""failed to read tree node: failed to find node '' in 'refs/heads/main': failed to get root tree node: exit status 128: fatal: detected dubious ownership in repository at '/data/repos/6l/2q/lghf2n2vimxibp4zfzeqz7u32dhem14syy0twf.git'\nTo add an exception for this directory, call:\n\n\tgit config --global --add safe.directory /data/repos/6l/2q/lghf2n2vimxibp4zfzeqz7u32dhem14syy0twf.git\n"",""time"":""2024-12-13T09:47:10.272573684Z"",""message"":""Unable to translate error - returning Internal Error.""}  After I execute `git config --global --add safe.directory /data/repos/6l/2q/lghf2n2vimxibp4zfzeqz7u32dhem14syy0twf.git` in the container, I can access it. However, the same error still occurs after deleting and restarting the container. How to solve this problem",other-file,"fatal: detected dubious ownership in repository When I transfer the data in the `data` to another linux system, I cannot access the repository in harness web.  harness | {""level"":""warn"",""http.router"":""api"",""http.router"":""api"",""http.url"":""/v1/repos/Moda%2FTvNotice/content?include_commit=true&git_ref=refs%2Fheads%2Fmain"",""http.method"":""GET"",""request_id"":""cte057g334hc73e2iie0"",""principal_uid"":""admin"",""principal_type"":""user"",""principal_admin"":true,""error"":""failed to read tree node: failed to find node '' in 'refs/heads/main': failed to get root tree node: exit status 128: fatal: detected dubious ownership in repository at '/data/repos/6l/2q/lghf2n2vimxibp4zfzeqz7u32dhem14syy0twf.git'\nTo add an exception for this directory, call:\n\n\tgit config --global --add safe.directory /data/repos/6l/2q/lghf2n2vimxibp4zfzeqz7u32dhem14syy0twf.git\n"",""time"":""2024-12-13T09:47:10.272573684Z"",""message"":""Unable to translate error - returning Internal Error.""}  After I execute `git config --global --add safe.directory /data/repos/6l/2q/lghf2n2vimxibp4zfzeqz7u32dhem14syy0twf.git` in the container, I can access it. However, the same error still occurs after deleting and restarting the container. How to solve this problem other-file",no-bug,0.9
766,harness,https://github.com/harness/harness/issues/766,Button to cancel a build,"Some feedback from one of our internal pilots:  () there should be a cancel button for a build, especially if a build hangs up.  We've experienced builds hanging up randomly, but can't reproduce it at the moment. Once it happens, only restarting Drone helps. We are working on reproducing it.",other-file,"Button to cancel a build Some feedback from one of our internal pilots:  () there should be a cancel button for a build, especially if a build hangs up.  We've experienced builds hanging up randomly, but can't reproduce it at the moment. Once it happens, only restarting Drone helps. We are working on reproducing it. other-file",no-bug,0.9
301,harness,https://github.com/harness/harness/issues/301,"Deploy SSH: enable ""scp -r""","Hi there, I ran into some trouble on my own drone service, I wanted to specify a directory as artifact but because there is no check on the artifact type [here](https://github.com/drone/drone/blob/f3530d76b2f599e2937ce481ddd7498a65588046/pkg/plugin/deploy/ssh.go#L76), `scp` is not called using `-r` so it cannot send a folder to remote host. Is it possible to add this feature ? (I might be able to do a feature request if you want)",other-file | other-file | other-file,"Deploy SSH: enable ""scp -r"" Hi there, I ran into some trouble on my own drone service, I wanted to specify a directory as artifact but because there is no check on the artifact type [here](https://github.com/drone/drone/blob/f3530d76b2f599e2937ce481ddd7498a65588046/pkg/plugin/deploy/ssh.go#L76), `scp` is not called using `-r` so it cannot send a folder to remote host. Is it possible to add this feature ? (I might be able to do a feature request if you want) other-file other-file other-file",no-bug,0.9
3283,harness,https://github.com/harness/harness/issues/3283,Update `lib/pq` to new(er) version,"Drone's Postgres driver, `lib/pq` is on [v1.1.0](https://github.com/lib/pq/releases/tag/v1.1.0), which was released in April 2019. https://github.com/harness/drone/blob/master/go.mod#L45 Postgres 12 was released in [October 2019](https://www.postgresql.org/docs/release/12.0/). This means the last major Postgres version that `lib/pq` v1.1.0 had official compatibility with was Postgres 11. I'm requesting `lib/pq` be updated to something newer. I read the [contributing doc](https://github.com/harness/drone/blob/master/.github/contributing.md#dependencies) about dependencies. I don't have a target version in mind, but I would like to upgrade to a newer Postgres version knowing that the driver was written after that version of Postgres came out. They're currently at [v1.10.7](https://github.com/lib/pq/releases/tag/v1.10.7), but I'm not sure if you want to jump that far forward. For example: - v1.2.0 dropped tested support for Postgres < 9.4 - v1.4.0 bumped oldest supported Go version to 1.13",source-file,"Update `lib/pq` to new(er) version Drone's Postgres driver, `lib/pq` is on [v1.1.0](https://github.com/lib/pq/releases/tag/v1.1.0), which was released in April 2019. https://github.com/harness/drone/blob/master/go.mod#L45 Postgres 12 was released in [October 2019](https://www.postgresql.org/docs/release/12.0/). This means the last major Postgres version that `lib/pq` v1.1.0 had official compatibility with was Postgres 11. I'm requesting `lib/pq` be updated to something newer. I read the [contributing doc](https://github.com/harness/drone/blob/master/.github/contributing.md#dependencies) about dependencies. I don't have a target version in mind, but I would like to upgrade to a newer Postgres version knowing that the driver was written after that version of Postgres came out. They're currently at [v1.10.7](https://github.com/lib/pq/releases/tag/v1.10.7), but I'm not sure if you want to jump that far forward. For example: - v1.2.0 dropped tested support for Postgres < 9.4 - v1.4.0 bumped oldest supported Go version to 1.13 source-file",no-bug,0.9
2159,harness,https://github.com/harness/harness/issues/2159,Builds page must be refreshed for changes to appear,"When new builds are triggered, the builds page does not display them until the page is refresh. Expected behaviour: the builds page should be responsive when events happen on the server",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Builds page must be refreshed for changes to appear When new builds are triggered, the builds page does not display them until the page is refresh. Expected behaviour: the builds page should be responsive when events happen on the server source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
583,harness,https://github.com/harness/harness/issues/583,"WebSocket connection to 'wss://drone/api/stream/stdout/"" fails handshake 404 (Centos 7)","Hi Brad, We can get repos to build, but on the screen where we expect to see output (with the follow button), it stays black and the status of the job never shows completion. If we come back to the UI later by closing the browser tab and then looking at the status, we see all the output and failed/succeeded. During the build, the Javascript console shows the following:  WebSocket connection to 'wss://drone.xxx.com:8282/api/stream/stdout/29?access_token=eyJhbGciOiTQxMzBLAAAAaaarrKGpZCI6MX0.DP3UljiLgGVDFPKFWuilAF14JXWrV8X6-F0P5ZNivxI' failed: Error during WebSocket handshake: Unexpected response code: 404 drone.nodeprime.net:8282/static/scripts/services/stdout.js:14 websocket closed at 29  Build dc1851c Centos 7 SELinux disabled Docker 1.2 (latest) /usr/bin/docker -d -H tcp://127.0.0.1:2375 -H unix:var/run/docker.sock --graph=/var/lib/docker",other-file | source-file | documentation-file,"WebSocket connection to 'wss://drone/api/stream/stdout/"" fails handshake 404 (Centos 7) Hi Brad, We can get repos to build, but on the screen where we expect to see output (with the follow button), it stays black and the status of the job never shows completion. If we come back to the UI later by closing the browser tab and then looking at the status, we see all the output and failed/succeeded. During the build, the Javascript console shows the following:  WebSocket connection to 'wss://drone.xxx.com:8282/api/stream/stdout/29?access_token=eyJhbGciOiTQxMzBLAAAAaaarrKGpZCI6MX0.DP3UljiLgGVDFPKFWuilAF14JXWrV8X6-F0P5ZNivxI' failed: Error during WebSocket handshake: Unexpected response code: 404 drone.nodeprime.net:8282/static/scripts/services/stdout.js:14 websocket closed at 29  Build dc1851c Centos 7 SELinux disabled Docker 1.2 (latest) /usr/bin/docker -d -H tcp://127.0.0.1:2375 -H unix:var/run/docker.sock --graph=/var/lib/docker other-file source-file documentation-file",no-bug,0.8
2440,harness,https://github.com/harness/harness/issues/2440,Optional Automatic Purging,"Provide the ability to retain the last N builds per-repository (e.g. last 50 builds). When a new build is created the build history is pruned and older builds are deleted from the database. This will be an optional, opt-in feature, and N will be configurable.",container-file,"Optional Automatic Purging Provide the ability to retain the last N builds per-repository (e.g. last 50 builds). When a new build is created the build history is pruned and older builds are deleted from the database. This will be an optional, opt-in feature, and N will be configurable. container-file",no-bug,0.9
850,harness,https://github.com/harness/harness/issues/850,Build priority to master branch,"I like a lot that drone builds my secondary branches, but I would like to **_prioritize the builds on master branch**_, to speed up our CI and prod deployment time. Considering we are 5 devs on the same project, it happens all the time that we have 1 or 2 commits awaiting to be built on master, while other, lesser important or WIP branches are constantly taking over the consumers and slowing down the queue. There is something that can be done, apart from disabling all the secondary branches or piling up consumers?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Build priority to master branch I like a lot that drone builds my secondary branches, but I would like to **_prioritize the builds on master branch**_, to speed up our CI and prod deployment time. Considering we are 5 devs on the same project, it happens all the time that we have 1 or 2 commits awaiting to be built on master, while other, lesser important or WIP branches are constantly taking over the consumers and slowing down the queue. There is something that can be done, apart from disabling all the secondary branches or piling up consumers? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
2889,harness,https://github.com/harness/harness/issues/2889,[Feature] Signed environment variables,"Gitlab-CI supports secret-less push to Docker repository in the pipeline. That is, there is no need to manually pass a secret to the pipeline (such as docker repository username/password) to pipeline to allow a build of my-group/my-project.git to push to my-group/my-project docker repository (whereas a build on other-group/other-project.git cannot, but can obviously push to other-group/other-project repository) I was wondering at how to implement this in my Drone workflow in the most generic possible way, and came at the conclusion that it cant be done with the features offered by Drone right now  please correct me if Im wrong  but a simple addition would allow that, and would probably allow a lot of interesting things as well. The idea would be to export all environment variables exposed to a pipeline as a JWT object (lets say an environment variable $DRONE_SIGNED_ENV, or a /.drone-signed-env file), signed by a private key known only to Drone (not exposed to pipelines so a task can't just recreate a token by itself with crafted values of DRONE_REPO/DRONE_COMMIT_BRANCH/). The pipeline would be able to communicate this to a third-party service that would itself be able to ascertain the git project/branch build pipeline the request is commit from just be verifying the signature of the token with the associated public key.",source-file | source-file,"[Feature] Signed environment variables Gitlab-CI supports secret-less push to Docker repository in the pipeline. That is, there is no need to manually pass a secret to the pipeline (such as docker repository username/password) to pipeline to allow a build of my-group/my-project.git to push to my-group/my-project docker repository (whereas a build on other-group/other-project.git cannot, but can obviously push to other-group/other-project repository) I was wondering at how to implement this in my Drone workflow in the most generic possible way, and came at the conclusion that it cant be done with the features offered by Drone right now  please correct me if Im wrong  but a simple addition would allow that, and would probably allow a lot of interesting things as well. The idea would be to export all environment variables exposed to a pipeline as a JWT object (lets say an environment variable $DRONE_SIGNED_ENV, or a /.drone-signed-env file), signed by a private key known only to Drone (not exposed to pipelines so a task can't just recreate a token by itself with crafted values of DRONE_REPO/DRONE_COMMIT_BRANCH/). The pipeline would be able to communicate this to a third-party service that would itself be able to ascertain the git project/branch build pipeline the request is commit from just be verifying the signature of the token with the associated public key. source-file source-file",no-bug,0.9
2178,harness,https://github.com/harness/harness/issues/2178,Colourful output is not rendered correctly in Firefox,"I'm using drone 0.8.0-rc3 Colourful output is not rendered correctly in Firefox while the same output is rendered fine in Chromium. I'm using latest FF 55.0.2, disabled all ad-blockers and such. I remember colourful output worked just fine in the previous releases, so perhaps some change in 0.8.0 broke it?",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Colourful output is not rendered correctly in Firefox I'm using drone 0.8.0-rc3 Colourful output is not rendered correctly in Firefox while the same output is rendered fine in Chromium. I'm using latest FF 55.0.2, disabled all ad-blockers and such. I remember colourful output worked just fine in the previous releases, so perhaps some change in 0.8.0 broke it? source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
483,harness,https://github.com/harness/harness/issues/483,"Support for docker ""official"" unprefixed images","Drone overrides Docker unprefixed ""official"" images used for services and the base image (ubuntu, node, etc.). In some cases, I would rather use the unprefixed Docker images, but I can't find a way to do it in drone.",source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file,"Support for docker ""official"" unprefixed images Drone overrides Docker unprefixed ""official"" images used for services and the base image (ubuntu, node, etc.). In some cases, I would rather use the unprefixed Docker images, but I can't find a way to do it in drone. source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file",no-bug,0.9
3054,harness,https://github.com/harness/harness/issues/3054,subgroup project,How to support subgroup project,source-file | source-file,subgroup project How to support subgroup project source-file source-file,no-bug,0.9
1502,harness,https://github.com/harness/harness/issues/1502,Separate GitHub commit statuses for PRs and pushes,"Travis-CI has separate `/pr` and `/push` commit statuses, whereas Drone does not. There is a reason these should be distinguished: A PR build is run against the result of merging the head of the merge source into the head of the merge base; a branch (""push"") build is simply run against the head of the branch. Thus, in the case of a PR, the PR build actually tests what will land on the merge base, whereas the branch build does not necessarily test this; currently Drone will run both builds, but the results will just overwrite the same commit status, so the status you end up with will randomly depend on which build ran last.",source-file | source-file | source-file,"Separate GitHub commit statuses for PRs and pushes Travis-CI has separate `/pr` and `/push` commit statuses, whereas Drone does not. There is a reason these should be distinguished: A PR build is run against the result of merging the head of the merge source into the head of the merge base; a branch (""push"") build is simply run against the head of the branch. Thus, in the case of a PR, the PR build actually tests what will land on the merge base, whereas the branch build does not necessarily test this; currently Drone will run both builds, but the results will just overwrite the same commit status, so the status you end up with will randomly depend on which build ran last. source-file source-file source-file",no-bug,0.85
1205,harness,https://github.com/harness/harness/issues/1205,Missing error message for `token_exchange`,"If I try to authenticate with gitlab I get redirected to http://example.com/login#error=token_exchange` and the error message is empty, it's missing a div block for that error. If you give me the text that should be displayed I will create a pull request.",other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file,"Missing error message for `token_exchange` If I try to authenticate with gitlab I get redirected to http://example.com/login#error=token_exchange` and the error message is empty, it's missing a div block for that error. If you give me the text that should be displayed I will create a pull request. other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file",no-bug,0.8
224,harness,https://github.com/harness/harness/issues/224,sqlite db migration fails on table already existing,"Trying to upgrade to the latest version of drone and seeing this error on startup:  $ ./bin/droned 2014/03/26 13:32:28 Failed to upgrade to Revision Number 1 2014/03/26 13:32:28 table users already exists 2014/03/26 13:32:28 starting drone version 9f43d5c on port :8080  I changed  go func (s *sqliteDriver) CreateTable(tableName string, args []string) (sql.Result, error)  to use `CREATE TABLE IF NOT EXISTS`, which seems more accurate. I'll submit a PR shortly.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"sqlite db migration fails on table already existing Trying to upgrade to the latest version of drone and seeing this error on startup:  $ ./bin/droned 2014/03/26 13:32:28 Failed to upgrade to Revision Number 1 2014/03/26 13:32:28 table users already exists 2014/03/26 13:32:28 starting drone version 9f43d5c on port :8080  I changed  go func (s *sqliteDriver) CreateTable(tableName string, args []string) (sql.Result, error)  to use `CREATE TABLE IF NOT EXISTS`, which seems more accurate. I'll submit a PR shortly. source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2761,harness,https://github.com/harness/harness/issues/2761,Ability to define a fallback image for steps,"It should be very helpful to be able to define fallback images for steps in case an image is not available. The use case I'm facing: my drone pipeline uses an image created by itself on the last build. The problem is that in the very first build there is no custom image to use so it would be useful to be able to define another image to use in case the primary one is missing. Possible syntaxes would be: (i) passing a list as `image`; or (ii) specifying it on a parameter like `fallback-image`: (i) yaml pipeline: backend: image: [ my-custom-image, golang ] commands: - go get - go build - go test  (ii) yaml pipeline: backend: image: my-custom-image fallback-image: golang commands: - go get - go build - go test ",source-file | source-file | source-file | source-file | source-file,"Ability to define a fallback image for steps It should be very helpful to be able to define fallback images for steps in case an image is not available. The use case I'm facing: my drone pipeline uses an image created by itself on the last build. The problem is that in the very first build there is no custom image to use so it would be useful to be able to define another image to use in case the primary one is missing. Possible syntaxes would be: (i) passing a list as `image`; or (ii) specifying it on a parameter like `fallback-image`: (i) yaml pipeline: backend: image: [ my-custom-image, golang ] commands: - go get - go build - go test  (ii) yaml pipeline: backend: image: my-custom-image fallback-image: golang commands: - go get - go build - go test  source-file source-file source-file source-file source-file",no-bug,0.9
2179,harness,https://github.com/harness/harness/issues/2179,Follow in Firefox doesn't follow the log output,"When I enable following in Firefox while the job is running, browser doesn't follow the log output - in fact instead of scrolling to the end of the stream, it seems so ""jump"" to the top of the page. Drone 0.8.0-rc3 Firefox 55.0.2 All works as expected in Chromium",source-file,"Follow in Firefox doesn't follow the log output When I enable following in Firefox while the job is running, browser doesn't follow the log output - in fact instead of scrolling to the end of the stream, it seems so ""jump"" to the top of the page. Drone 0.8.0-rc3 Firefox 55.0.2 All works as expected in Chromium source-file",no-bug,0.9
92,harness,https://github.com/harness/harness/issues/92,GitHub Enterprise & http://,"cc @suguru @floatdrop this was brought up in issue #75 the github url is currently hardcoded with an `https://` prefix. Let's slightly change the design so that instead of `github_domain` we store `github_url` which is the scheme+domain, and remove the hard-coded `https://` prefix. we may also need a migration script for this, to change existing records from `github.com` to `https://github.com`",source-file | documentation-file | source-file | other-file | other-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | test-file | other-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | documentation-file | source-file | source-file | other-file | other-file,"GitHub Enterprise & http:// cc @suguru @floatdrop this was brought up in issue #75 the github url is currently hardcoded with an `https://` prefix. Let's slightly change the design so that instead of `github_domain` we store `github_url` which is the scheme+domain, and remove the hard-coded `https://` prefix. we may also need a migration script for this, to change existing records from `github.com` to `https://github.com` source-file documentation-file source-file other-file other-file source-file source-file other-file other-file other-file other-file other-file test-file other-file source-file source-file source-file source-file source-file other-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file documentation-file source-file source-file other-file other-file",no-bug,0.9
518,harness,https://github.com/harness/harness/issues/518,Docker publish in 0.3,The docker publish plugin is not yet in exp. Is this just a task that is not yet done or is there a separate plan for this functionality in 0.3?,other-file | other-file | other-file | documentation-file | other-file | other-file | source-file | other-file,Docker publish in 0.3 The docker publish plugin is not yet in exp. Is this just a task that is not yet done or is there a separate plan for this functionality in 0.3? other-file other-file other-file documentation-file other-file other-file source-file other-file,no-bug,0.9
293,harness,https://github.com/harness/harness/issues/293,Error when deploying via Git using public key authentication (ssh_askpass),"When using the deploy via Git Push and using a default id_rsa key file (in the ~/.ssh/id_rsa of the Unix account used by the drone daemon within the Docker container), the logs come back with a ssh_askpass error as follows:  $ git remote add deploy root@my_ci_server.com:path_to_my_repo.git $ git push deploy $COMMIT:master Warning: Permanently added 'my_ci_server.com,192.168.1.5' (ECDSA) to the list of known hosts. ssh_askpass: exec(/usr/bin/ssh-askpass): No such file or directory Permission denied, please try again. ssh_askpass: exec(/usr/bin/ssh-askpass): No such file or directory Permission denied, please try again. ssh_askpass: exec(/usr/bin/ssh-askpass): No such file or directory Permission denied (publickey,password). fatal: The remote end hung up unexpectedly  I have confirmed that I can still perform this remote push via logging into that Docker container manually via the command-line and performing the push.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Error when deploying via Git using public key authentication (ssh_askpass) When using the deploy via Git Push and using a default id_rsa key file (in the ~/.ssh/id_rsa of the Unix account used by the drone daemon within the Docker container), the logs come back with a ssh_askpass error as follows:  $ git remote add deploy root@my_ci_server.com:path_to_my_repo.git $ git push deploy $COMMIT:master Warning: Permanently added 'my_ci_server.com,192.168.1.5' (ECDSA) to the list of known hosts. ssh_askpass: exec(/usr/bin/ssh-askpass): No such file or directory Permission denied, please try again. ssh_askpass: exec(/usr/bin/ssh-askpass): No such file or directory Permission denied, please try again. ssh_askpass: exec(/usr/bin/ssh-askpass): No such file or directory Permission denied (publickey,password). fatal: The remote end hung up unexpectedly  I have confirmed that I can still perform this remote push via logging into that Docker container manually via the command-line and performing the push. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
1062,harness,https://github.com/harness/harness/issues/1062,Use build numbers in URL path,"Hi! I found a bug in 0.3 version. I've tried to use branch with name ""#33"". Unfortunatelly, it breaks drone.io client - you can't click on test box, and it doesn't show commit message. Screenshot attached. ![zrzut ekranu 2015-06-15 o 17 53 55](https://cloud.githubusercontent.com/assets/1429660/8164240/0f712154-1388-11e5-8470-6ccc51975e33.png)",source-file | source-file | source-file | source-file | source-file | source-file,"Use build numbers in URL path Hi! I found a bug in 0.3 version. I've tried to use branch with name ""#33"". Unfortunatelly, it breaks drone.io client - you can't click on test box, and it doesn't show commit message. Screenshot attached. ![zrzut ekranu 2015-06-15 o 17 53 55](https://cloud.githubusercontent.com/assets/1429660/8164240/0f712154-1388-11e5-8470-6ccc51975e33.png) source-file source-file source-file source-file source-file source-file",no-bug,0.7
347,harness,https://github.com/harness/harness/issues/347,commit view refreshes multiple times in a second on build,"Hey, i witness multiple site refreshes on deployment on the commit page. also no ""live"" output from the build. br, Dom",documentation-file | other-file | source-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file,"commit view refreshes multiple times in a second on build Hey, i witness multiple site refreshes on deployment on the commit page. also no ""live"" output from the build. br, Dom documentation-file other-file source-file documentation-file other-file source-file other-file other-file source-file other-file source-file source-file source-file source-file source-file",no-bug,0.9
1221,harness,https://github.com/harness/harness/issues/1221,"drone login (to gitlab) returns ""The redirect URI included is not valid""","@Bugagazavr can you pls comment the following error I found on the following configuration? any idea? When I try to LogIn the Drone, I will get: ""The redirect URI included is not valid"" on an Gitlab page.  https://git.lab.ci/oauth/authorize?client_id=7a72db7cb5d74f6870c5d279a96bbf50420db9a84aa8c7d5c1525349dae138e2&redirect_uri=https%3A%2F%2Fdrone.lab.ci%2Fauthorize&response_type=code&scope=api&state=drone  drone log:  [GIN] 2015/10/06 - 15:12:38 | 200 | 231.362s | 172.16.0.214:43077 | GET /login [GIN] 2015/10/06 - 15:12:40 | 303 | 112.659s | 172.16.0.214:43077 | GET /authorize   CLIENT=""7a72db7cb5d74f6870c5d27xxxx"" SECRET=""54575e0053a1dcfa6a6916xxxx"" REMOTE_DRIVER=""gitlab"" REMOTE_CONFIG=""https://git.lab.ci?client_id=$CLIENT&client_secret=$SECRET&skip_verify=true&open=false""  Drone 0.4.0 (tested with .deb and builded from source, today) GitLab 8.0.4 GitLab Shell 2.6.5 GitLab API v3 Ruby 2.1.5p273 Rails 4.1.12",other-file | source-file | source-file | other-file,"drone login (to gitlab) returns ""The redirect URI included is not valid"" @Bugagazavr can you pls comment the following error I found on the following configuration? any idea? When I try to LogIn the Drone, I will get: ""The redirect URI included is not valid"" on an Gitlab page.  https://git.lab.ci/oauth/authorize?client_id=7a72db7cb5d74f6870c5d279a96bbf50420db9a84aa8c7d5c1525349dae138e2&redirect_uri=https%3A%2F%2Fdrone.lab.ci%2Fauthorize&response_type=code&scope=api&state=drone  drone log:  [GIN] 2015/10/06 - 15:12:38 | 200 | 231.362s | 172.16.0.214:43077 | GET /login [GIN] 2015/10/06 - 15:12:40 | 303 | 112.659s | 172.16.0.214:43077 | GET /authorize   CLIENT=""7a72db7cb5d74f6870c5d27xxxx"" SECRET=""54575e0053a1dcfa6a6916xxxx"" REMOTE_DRIVER=""gitlab"" REMOTE_CONFIG=""https://git.lab.ci?client_id=$CLIENT&client_secret=$SECRET&skip_verify=true&open=false""  Drone 0.4.0 (tested with .deb and builded from source, today) GitLab 8.0.4 GitLab Shell 2.6.5 GitLab API v3 Ruby 2.1.5p273 Rails 4.1.12 other-file source-file source-file other-file",no-bug,0.8
1124,harness,https://github.com/harness/harness/issues/1124,"build status badge always show as ""build|none"" regardless what's the real status is","Hi, I managed setup a drone service with master branch code(built from source) and the test project can build, however, I see the ""status badge"" of my test project always show ""build|none"" regardless what's the real status is, building, sucess or fail. Am I missed somthing? Thanks in advance!",source-file,"build status badge always show as ""build|none"" regardless what's the real status is Hi, I managed setup a drone service with master branch code(built from source) and the test project can build, however, I see the ""status badge"" of my test project always show ""build|none"" regardless what's the real status is, building, sucess or fail. Am I missed somthing? Thanks in advance! source-file",no-bug,0.8
2010,harness,https://github.com/harness/harness/issues/2010,Show errors on webhooks in user interface,I had a wrong indent in my .drone.yml. This resulted in a very unclear HTTP 400 response from Drone on my webhook in Bitbucket. I can figure 2 solutions: - either add the error to the HTTP 400 response - or show an attempted build in the user interface of Drone with what's going on,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Show errors on webhooks in user interface I had a wrong indent in my .drone.yml. This resulted in a very unclear HTTP 400 response from Drone on my webhook in Bitbucket. I can figure 2 solutions: - either add the error to the HTTP 400 response - or show an attempted build in the user interface of Drone with what's going on source-file source-file source-file source-file source-file source-file source-file source-file source-file,bug,0.85
199,harness,https://github.com/harness/harness/issues/199,Notification Plugin - Campfire,It would be nice to integrate with Campfire for sending build success / failure messages. It would probably look something like the Hipchat or IRC plugins,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Notification Plugin - Campfire It would be nice to integrate with Campfire for sending build success / failure messages. It would probably look something like the Hipchat or IRC plugins source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
2664,harness,https://github.com/harness/harness/issues/2664,Cache repository permissions in Feed,"the SSE feed should cache repository permissions to reduce database lookups. There are no documented issues of this being a problem, but this sort of performance improvements seems like low hanging fruit.",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | other-file | other-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | source-file | documentation-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | other-file | source-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | documentation-file | source-file | other-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Cache repository permissions in Feed the SSE feed should cache repository permissions to reduce database lookups. There are no documented issues of this being a problem, but this sort of performance improvements seems like low hanging fruit. other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file other-file other-file source-file source-file source-file other-file source-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file other-file source-file other-file source-file other-file other-file source-file source-file documentation-file source-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file test-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file source-file other-file source-file other-file other-file test-file other-file other-file source-file other-file other-file other-file documentation-file other-file other-file other-file documentation-file source-file other-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3314,harness,https://github.com/harness/harness/issues/3314,ReferenceError: useLocation is not defined,Can not view EXECUTIONS detail docker image sha256:6b0171d2d27aa1046927acc53f44cd264b94441d5c20ba6818bee2d0d37d4f0a,source-file | source-file | source-file | source-file,ReferenceError: useLocation is not defined Can not view EXECUTIONS detail docker image sha256:6b0171d2d27aa1046927acc53f44cd264b94441d5c20ba6818bee2d0d37d4f0a source-file source-file source-file source-file,no-bug,0.9
3615,harness,https://github.com/harness/harness/issues/3615,Harness internal repository as a mirror of external repository,,other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | documentation-file | other-file | source-file | test-file | source-file,Harness internal repository as a mirror of external repository  other-file source-file other-file other-file source-file other-file other-file source-file other-file documentation-file other-file source-file test-file source-file,no-bug,0.9
216,harness,https://github.com/harness/harness/issues/216,ASP.Net deployment?,Hi - Any pointers on how to go about adding the capability to perform an ASP.Net (or other custom) deployment extension?,other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,ASP.Net deployment? Hi - Any pointers on how to go about adding the capability to perform an ASP.Net (or other custom) deployment extension? other-file other-file source-file other-file other-file other-file other-file source-file source-file source-file documentation-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
391,harness,https://github.com/harness/harness/issues/391,Confusing role menu in team membership/members,I cannot find how I can add members to see running build. Adding them to a team does not seem to do it. Additionally the role menu is confusing: ![image](https://cloud.githubusercontent.com/assets/1408285/3717667/65314fe0-1629-11e4-8caf-476e88038acd.png),other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file,Confusing role menu in team membership/members I cannot find how I can add members to see running build. Adding them to a team does not seem to do it. Additionally the role menu is confusing: ![image](https://cloud.githubusercontent.com/assets/1408285/3717667/65314fe0-1629-11e4-8caf-476e88038acd.png) other-file other-file other-file other-file source-file other-file other-file source-file other-file source-file other-file documentation-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file documentation-file source-file,no-bug,0.9
2511,harness,https://github.com/harness/harness/issues/2511,"""Invalid or missing image"" when ""when:"" block is formatted incorrectly","Drone 0.85 will fail a build with the error `invalid or missing image` if a `when:` line is outdented incorrectly away from its block. The build error should relate to the incorrectly-formatted `when:` line. Repro yaml: yaml pipeline: build_always: image: alpine commands: - echo ""hello always"" build_sometimes: image: alpine commands: - echo ""hello sometimes"" # When incorrectly formatted like this, error message in 0.85 is ""Invalid or missing image"" when: status: [ success ] event: push branch: master ",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"""Invalid or missing image"" when ""when:"" block is formatted incorrectly Drone 0.85 will fail a build with the error `invalid or missing image` if a `when:` line is outdented incorrectly away from its block. The build error should relate to the incorrectly-formatted `when:` line. Repro yaml: yaml pipeline: build_always: image: alpine commands: - echo ""hello always"" build_sometimes: image: alpine commands: - echo ""hello sometimes"" # When incorrectly formatted like this, error message in 0.85 is ""Invalid or missing image"" when: status: [ success ] event: push branch: master  source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
119,harness,https://github.com/harness/harness/issues/119,Ability to either set locale in setup or default to en_US.utf8,![Localte](http://f.cl.ly/items/0a0v023t1b2V151O420G/Screen%20Shot%202014-02-24%20at%2012.30.10.png),source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Ability to either set locale in setup or default to en_US.utf8 ![Localte](http://f.cl.ly/items/0a0v023t1b2V151O420G/Screen%20Shot%202014-02-24%20at%2012.30.10.png) source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.8
492,harness,https://github.com/harness/harness/issues/492,Unit test w/ MySQL + Postgres,"The latest version in `exp` works with postgres, mysql and sqlite, however, there are not tests for postgres and mysql. Merge with #437",documentation-file,"Unit test w/ MySQL + Postgres The latest version in `exp` works with postgres, mysql and sqlite, however, there are not tests for postgres and mysql. Merge with #437 documentation-file",no-bug,0.9
2541,harness,https://github.com/harness/harness/issues/2541,Handle expired vault token generated with Kube auth,"if the vault token is generated using kubernetes auth it expires after 32 days. I propose we try to generate a new kubernetes token if the vault token refresh fails. Something like this: diff func (v *vault) renewLoop() { for { select { case <-time.After(v.renew): incr := int(v.ttl / time.Second) logrus.Debugf(""vault: refreshing token: increment %v"", v.ttl) _, err := v.client.Auth().Token().RenewSelf(incr) + if err != nil && v.auth == ""kubernetes"" { + err = v.initKubernetes() + } if err != nil { logrus.Errorf(""vault: refreshing token failed: %s"", err) } else { logrus.Debugf(""vault: refreshing token succeeded"") } case <-v.done: return } } }  cc @praxist",source-file,"Handle expired vault token generated with Kube auth if the vault token is generated using kubernetes auth it expires after 32 days. I propose we try to generate a new kubernetes token if the vault token refresh fails. Something like this: diff func (v *vault) renewLoop() { for { select { case <-time.After(v.renew): incr := int(v.ttl / time.Second) logrus.Debugf(""vault: refreshing token: increment %v"", v.ttl) _, err := v.client.Auth().Token().RenewSelf(incr) + if err != nil && v.auth == ""kubernetes"" { + err = v.initKubernetes() + } if err != nil { logrus.Errorf(""vault: refreshing token failed: %s"", err) } else { logrus.Debugf(""vault: refreshing token succeeded"") } case <-v.done: return } } }  cc @praxist source-file",no-bug,0.9
2628,harness,https://github.com/harness/harness/issues/2628,Store cron job that spawned build in Build struct and database,"this can be used to visualize which cron job started a build, and can be used to enable support for using the cron job name in the `when` and `trigger` clauses. example when configuration:  when: cron: [ nightly ]  example trigger configuration:  trigger: cron: [ nightly ] ",documentation-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | source-file | database-file | source-file | database-file | source-file | test-file | source-file | source-file | documentation-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file,"Store cron job that spawned build in Build struct and database this can be used to visualize which cron job started a build, and can be used to enable support for using the cron job name in the `when` and `trigger` clauses. example when configuration:  when: cron: [ nightly ]  example trigger configuration:  trigger: cron: [ nightly ]  documentation-file source-file source-file other-file source-file source-file source-file source-file source-file source-file database-file source-file database-file source-file database-file source-file test-file source-file source-file documentation-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file",no-bug,0.9
584,harness,https://github.com/harness/harness/issues/584,"Blank build output page when ""/"" in the Branch. Fix route declarations","On several repos, and on some build status but not others, instead of the page rendering with status and build output, we get a blank page and this error in the console: TypeError: Cannot read property '$$route' of undefined at https://drone.example.comt:5555/static/scripts/app.js:188:33 at h.$broadcast (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:104:521) at https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular-route.min.js:11:179 at C (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:92:375) at https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:94:28 at h.$eval (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:102:293) at h.$digest (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:100:50) at h.$apply (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:103:100) at HTMLHtmlElement.<anonymous> (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:82:295) at https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:27:208",source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | other-file | other-file,"Blank build output page when ""/"" in the Branch. Fix route declarations On several repos, and on some build status but not others, instead of the page rendering with status and build output, we get a blank page and this error in the console: TypeError: Cannot read property '$$route' of undefined at https://drone.example.comt:5555/static/scripts/app.js:188:33 at h.$broadcast (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:104:521) at https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular-route.min.js:11:179 at C (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:92:375) at https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:94:28 at h.$eval (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:102:293) at h.$digest (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:100:50) at h.$apply (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:103:100) at HTMLHtmlElement.<anonymous> (https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:82:295) at https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js:27:208 source-file source-file source-file source-file source-file source-file source-file other-file source-file other-file other-file",no-bug,0.9
2977,harness,https://github.com/harness/harness/issues/2977,No completed webhook sent,"Based on the [docs](https://docs.drone.io/webhooks/examples/#completed) there should be a webhook with a completed action. Saw [this](https://github.com/drone/drone/pull/2923) PR about implementing it. Am I missing something, or it is really not implemented correctly?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file,"No completed webhook sent Based on the [docs](https://docs.drone.io/webhooks/examples/#completed) there should be a webhook with a completed action. Saw [this](https://github.com/drone/drone/pull/2923) PR about implementing it. Am I missing something, or it is really not implemented correctly? source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file",bug,0.85
395,harness,https://github.com/harness/harness/issues/395,"make fails to find ""rice"" in the path and the build exits",The Makefile has a rice target:  rice: go get github.com/GeertJohan/go.rice/rice go build github.com/GeertJohan/go.rice/rice  The make failed because this wasn't in my path on the system. My solution was to add one more line to the rice dep:  go install github.com/GeertJohan/go.rice/rice  which placed the binary in my $GOPATH/bin and thus the build could continue.,other-file,"make fails to find ""rice"" in the path and the build exits The Makefile has a rice target:  rice: go get github.com/GeertJohan/go.rice/rice go build github.com/GeertJohan/go.rice/rice  The make failed because this wasn't in my path on the system. My solution was to add one more line to the rice dep:  go install github.com/GeertJohan/go.rice/rice  which placed the binary in my $GOPATH/bin and thus the build could continue. other-file",no-bug,0.95
2921,harness,https://github.com/harness/harness/issues/2921,webhooks on build complete event,"Hi, In documentation it is stated , that webhooks are emitted on following events:  User is created User is deleted Repository is activated Repository is de-activated Build is created Build is updated Build is completed  ref: https://docs.drone.io/webhooks/examples/ while in the code https://github.com/drone/drone/blob/1ddf7963feb98ae7fed7dd2834389441f2401c77/core/webhook.go#L29 there is no such type as `completed` Any plans to update documentation or implement `completed` action?",source-file | source-file | source-file,"webhooks on build complete event Hi, In documentation it is stated , that webhooks are emitted on following events:  User is created User is deleted Repository is activated Repository is de-activated Build is created Build is updated Build is completed  ref: https://docs.drone.io/webhooks/examples/ while in the code https://github.com/drone/drone/blob/1ddf7963feb98ae7fed7dd2834389441f2401c77/core/webhook.go#L29 there is no such type as `completed` Any plans to update documentation or implement `completed` action? source-file source-file source-file",no-bug,0.8
2190,harness,https://github.com/harness/harness/issues/2190,Matrix builds are stuck even though the agent finished,"This is using Drone 0.8. I have an agent running on a different machine than the server. I have matrix builds that complete (according to the agent), the logs are visible in the UI, but the ""parent"" job keeps ""spinning"". This causes all subsequent builds to be queued forever. Also, Github status is not set (this is consistent with the build being marked ""in progress""). The only suspicious thing I see in the server log is a bunch of RPC errors:  INFO: 2017/09/05 14:36:26 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 14:37:50 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 14:38:26 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 14:47:43 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 14:53:11 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:00:28 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:00:39 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:00:53 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:02:27 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:04:27 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:06:27 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:09:40 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded""  The agent logs look good, I have a bunch of innocent looking lines like this:  2017/09/05 13:16:25 pipeline: finish uploading logs: application/json+logs: step 222: build 2017/09/05 13:16:25 pipeline: finish uploading logs: 222: step build 2017/09/05 13:16:27 pipeline: execution complete: 222 2017/09/05 13:16:27 pipeline: logging complete: 222 2017/09/05 13:16:27 pipeline: cancel channel closed: 222 2017/09/05 13:16:27 pipeline: done: 222 2017/09/05 13:16:27 pipeline: request next execution 2017/09/05 13:16:27 pipeline: cancel ping loop: 222 2017/09/05 13:16:27 pipeline: received next execution: 213 2017/09/05 13:16:29 pipeline: finish uploading logs: application/json+logs: step 213: clone 2017/09/05 13:16:29 pipeline: finish uploading logs: 213: step clone 2017/09/05 13:17:27 pipeline: ping queue: 213 2017/09/05 13:17:34 pipeline: execution complete: 213 2017/09/05 13:17:35 pipeline: finish uploading logs: application/json+logs: step 213: build 2017/09/05 13:17:35 pipeline: finish uploading logs: 213: step build 2017/09/05 13:17:35 pipeline: logging complete: 213 2017/09/05 13:17:35 pipeline: done: 213 2017/09/05 13:17:35 pipeline: request next execution 2017/09/05 13:17:35 pipeline: cancel ping loop: 213  I'm configuring the agent like this (I had the script lying around since 0.4 so I just reused it instead of going to docker-compose, especially since the server and agent are on different machines):  # run Drone agent docker run \ --env DOCKER_API_VERSION=1.24 \ --env DRONE_SERVER=drone.iulidragos.com:9000 \ --env DRONE_SECRET= \ --env DRONE_MAX_PROCS=4 \ --volume /var/run/docker.sock:/var/run/docker.sock \ --restart=always \ --detach=true \ --name=drone-agent \ drone/agent:0.8  Not sure if the Docker API version has anything to do with this (the agent logs don't show any error though). At this point all builds are stuck, so I'm considering reverting to 0.7, but there I had similar issues but less consistent.",other-file | source-file | other-file | other-file | other-file,"Matrix builds are stuck even though the agent finished This is using Drone 0.8. I have an agent running on a different machine than the server. I have matrix builds that complete (according to the agent), the logs are visible in the UI, but the ""parent"" job keeps ""spinning"". This causes all subsequent builds to be queued forever. Also, Github status is not set (this is consistent with the build being marked ""in progress""). The only suspicious thing I see in the server log is a bunch of RPC errors:  INFO: 2017/09/05 14:36:26 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 14:37:50 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 14:38:26 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 14:47:43 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 14:53:11 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:00:28 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:00:39 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:00:53 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:02:27 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:04:27 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:06:27 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded"" INFO: 2017/09/05 15:09:40 grpc: Server.processUnaryRPC failed to write status stream error: code = DeadlineExceeded desc = ""context deadline exceeded""  The agent logs look good, I have a bunch of innocent looking lines like this:  2017/09/05 13:16:25 pipeline: finish uploading logs: application/json+logs: step 222: build 2017/09/05 13:16:25 pipeline: finish uploading logs: 222: step build 2017/09/05 13:16:27 pipeline: execution complete: 222 2017/09/05 13:16:27 pipeline: logging complete: 222 2017/09/05 13:16:27 pipeline: cancel channel closed: 222 2017/09/05 13:16:27 pipeline: done: 222 2017/09/05 13:16:27 pipeline: request next execution 2017/09/05 13:16:27 pipeline: cancel ping loop: 222 2017/09/05 13:16:27 pipeline: received next execution: 213 2017/09/05 13:16:29 pipeline: finish uploading logs: application/json+logs: step 213: clone 2017/09/05 13:16:29 pipeline: finish uploading logs: 213: step clone 2017/09/05 13:17:27 pipeline: ping queue: 213 2017/09/05 13:17:34 pipeline: execution complete: 213 2017/09/05 13:17:35 pipeline: finish uploading logs: application/json+logs: step 213: build 2017/09/05 13:17:35 pipeline: finish uploading logs: 213: step build 2017/09/05 13:17:35 pipeline: logging complete: 213 2017/09/05 13:17:35 pipeline: done: 213 2017/09/05 13:17:35 pipeline: request next execution 2017/09/05 13:17:35 pipeline: cancel ping loop: 213  I'm configuring the agent like this (I had the script lying around since 0.4 so I just reused it instead of going to docker-compose, especially since the server and agent are on different machines):  # run Drone agent docker run \ --env DOCKER_API_VERSION=1.24 \ --env DRONE_SERVER=drone.iulidragos.com:9000 \ --env DRONE_SECRET= \ --env DRONE_MAX_PROCS=4 \ --volume /var/run/docker.sock:/var/run/docker.sock \ --restart=always \ --detach=true \ --name=drone-agent \ drone/agent:0.8  Not sure if the Docker API version has anything to do with this (the agent logs don't show any error though). At this point all builds are stuck, so I'm considering reverting to 0.7, but there I had similar issues but less consistent. other-file source-file other-file other-file other-file",no-bug,0.9
838,harness,https://github.com/harness/harness/issues/838,Trigger Builds from Pull Request Comments (and run Privileged),"We have some tests that require the container to be run as privileged. These tests should be run on _every_ PR before it is merged. The current security model would have these test run on `master` only, which doesn't prevent us merging code that will fail the full test suite. My proposal is for Drone to listen to the [IssueCommentEvent](https://developer.github.com/v3/activity/events/types/#issuecommentevent) for a given PR and react to comments from users who have Admin permissions in Drone. For example: - `recheck` will re-run the tests - `recheck trusted` will re-run the tests and enabled Privileged and/or Private ENV Variables A logical extension to this proposal would be to maintain a whitelist of users for which builds will run trusted by default. I'd suggest that Drone Admins would be sensible starting point and then adding the the ability to add more users either via the UI or even through comments e.g `whitelist`",other-file,"Trigger Builds from Pull Request Comments (and run Privileged) We have some tests that require the container to be run as privileged. These tests should be run on _every_ PR before it is merged. The current security model would have these test run on `master` only, which doesn't prevent us merging code that will fail the full test suite. My proposal is for Drone to listen to the [IssueCommentEvent](https://developer.github.com/v3/activity/events/types/#issuecommentevent) for a given PR and react to comments from users who have Admin permissions in Drone. For example: - `recheck` will re-run the tests - `recheck trusted` will re-run the tests and enabled Privileged and/or Private ENV Variables A logical extension to this proposal would be to maintain a whitelist of users for which builds will run trusted by default. I'd suggest that Drone Admins would be sensible starting point and then adding the the ability to add more users either via the UI or even through comments e.g `whitelist` other-file",no-bug,0.9
2625,harness,https://github.com/harness/harness/issues/2625,Feature request: from_file and from_variable in plugins' settings,"Hi guys, you made an awesome product, I love it! There are some plugins that require large content to be passed in the settings, e.g. CI success message pattern. That is why the a feature I am missing is something similar to `from_secret` but `from_file` and `from_variable` in the settings of plugins. Example of what I would like to have:  steps: - name: image: plugins/telegram settings: message: from_file: .drone-telegram-message.md  I asked this on [discourse](https://discourse.drone.io/t/using-from-file-and-from-variable-in-plugins-settings/4010) but didn't get any answer, so I assume it is not implemented yet.",source-file,"Feature request: from_file and from_variable in plugins' settings Hi guys, you made an awesome product, I love it! There are some plugins that require large content to be passed in the settings, e.g. CI success message pattern. That is why the a feature I am missing is something similar to `from_secret` but `from_file` and `from_variable` in the settings of plugins. Example of what I would like to have:  steps: - name: image: plugins/telegram settings: message: from_file: .drone-telegram-message.md  I asked this on [discourse](https://discourse.drone.io/t/using-from-file-and-from-variable-in-plugins-settings/4010) but didn't get any answer, so I assume it is not implemented yet. source-file",no-bug,0.9
1035,harness,https://github.com/harness/harness/issues/1035,use travis-build to parse a YAML file,"We're considering moving to drone for our CI https://github.com/ensime/ensime-server/issues/974 But we have a few questions that I couldn't find answers to in your documentation: 1. can you take a `travis.yml` file defined in the project to define the various build stages for a simple sequential pipeline? (using the same rules for reporting and so on). 2. can remote workers be set up with a simple ssh login? What permissions does the user need to have? I believe the travis file goes too far it should not be used for setting up the system environment (that's the job of the docker image). In shippable, a new section called `docker_image` allows the definition of the docker image to use, which I think is ideal.",source-file | source-file,"use travis-build to parse a YAML file We're considering moving to drone for our CI https://github.com/ensime/ensime-server/issues/974 But we have a few questions that I couldn't find answers to in your documentation: 1. can you take a `travis.yml` file defined in the project to define the various build stages for a simple sequential pipeline? (using the same rules for reporting and so on). 2. can remote workers be set up with a simple ssh login? What permissions does the user need to have? I believe the travis file goes too far it should not be used for setting up the system environment (that's the job of the docker image). In shippable, a new section called `docker_image` allows the definition of the docker image to use, which I think is ideal. source-file source-file",no-bug,0.95
359,harness,https://github.com/harness/harness/issues/359,Session expiration,"Hi, I can see I am logged out every 2 days from drone. Is there any way I can adjust session expire time ? Thank you, Teodor",source-file | source-file | source-file | source-file | other-file | documentation-file | other-file | source-file | other-file,"Session expiration Hi, I can see I am logged out every 2 days from drone. Is there any way I can adjust session expire time ? Thank you, Teodor source-file source-file source-file source-file other-file documentation-file other-file source-file other-file",no-bug,0.9
1109,harness,https://github.com/harness/harness/issues/1109,cannot find re-activate/deactivate button on web ui,"I remove webhooks from gitlab by mistake, and i want to re-activate a project to re-create the hook intead of creating it on gitlab by myself So i have to do that though api, that's really inconvenient.. That also happends if drone host:port changes without changing DB.",other-file,"cannot find re-activate/deactivate button on web ui I remove webhooks from gitlab by mistake, and i want to re-activate a project to re-create the hook intead of creating it on gitlab by myself So i have to do that though api, that's really inconvenient.. That also happends if drone host:port changes without changing DB. other-file",no-bug,0.8
320,harness,https://github.com/harness/harness/issues/320,Publish official Docker image,It would be great to publish an official trusted Docker image to the docker index. Since there already is a Dockerfile it should not be a lot of work.,other-file | other-file | other-file | source-file | documentation-file | other-file,Publish official Docker image It would be great to publish an official trusted Docker image to the docker index. Since there already is a Dockerfile it should not be a lot of work. other-file other-file other-file source-file documentation-file other-file,no-bug,0.9
136,harness,https://github.com/harness/harness/issues/136,Build dies after 5 minutes,"My build dies after five minutes. After changing https://github.com/drone/drone/blob/master/cmd/droned/drone.go#L125 it works, but I don't know how that hard coded piece of duration relates to https://github.com/drone/drone/blob/master/pkg/build/build.go#L64  what gives?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file,"Build dies after 5 minutes My build dies after five minutes. After changing https://github.com/drone/drone/blob/master/cmd/droned/drone.go#L125 it works, but I don't know how that hard coded piece of duration relates to https://github.com/drone/drone/blob/master/pkg/build/build.go#L64  what gives? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file other-file other-file other-file other-file",no-bug,0.9
2650,harness,https://github.com/harness/harness/issues/2650,Can't activate a repository from Bitbucket private account,"**Configuration:** Private bitbucket account Host: Ubuntu 18.04.2 LTS Docker version: 18.09.4 Docker run command for drone:  docker run \ --volume=/drone/data:/data \ --env=DRONE_BITBUCKET_CLIENT_ID= \ --env=DRONE_BITBUCKET_CLIENT_SECRET= \ --env=DRONE_RPC_SECRET= \ --env=DRONE_SERVER_HOST=our.domain.io \ --env=DRONE_SERVER_PROTO=http \ --env=DRONE_TLS_AUTOCERT=false \ --publish=80:80 \ --publish=443:443 \ --restart=always \ --detach=true \ --name=drone-server \ drone/drone:1  Issue steps: 1. Go to our drone url: our.domain.io 2. See the list of repositories (good) 3. Click on one repo 4. Click on 'activate' Expected: 1. connect to the repo for configuration actual: Get GUI message: ""There was a problem enabling your repository. Not Found."" Details from Chrome console: Request URL: http://our.domain.io/api/repos/project/reponame Request Method: POST Status Code: 404 Not Found Remote Address: xx.xx.xx.xx:80 Referrer Policy: no-referrer-when-downgrade",source-file,"Can't activate a repository from Bitbucket private account **Configuration:** Private bitbucket account Host: Ubuntu 18.04.2 LTS Docker version: 18.09.4 Docker run command for drone:  docker run \ --volume=/drone/data:/data \ --env=DRONE_BITBUCKET_CLIENT_ID= \ --env=DRONE_BITBUCKET_CLIENT_SECRET= \ --env=DRONE_RPC_SECRET= \ --env=DRONE_SERVER_HOST=our.domain.io \ --env=DRONE_SERVER_PROTO=http \ --env=DRONE_TLS_AUTOCERT=false \ --publish=80:80 \ --publish=443:443 \ --restart=always \ --detach=true \ --name=drone-server \ drone/drone:1  Issue steps: 1. Go to our drone url: our.domain.io 2. See the list of repositories (good) 3. Click on one repo 4. Click on 'activate' Expected: 1. connect to the repo for configuration actual: Get GUI message: ""There was a problem enabling your repository. Not Found."" Details from Chrome console: Request URL: http://our.domain.io/api/repos/project/reponame Request Method: POST Status Code: 404 Not Found Remote Address: xx.xx.xx.xx:80 Referrer Policy: no-referrer-when-downgrade source-file",bug,0.9
1027,harness,https://github.com/harness/harness/issues/1027,"No files copied to image during drone-cli ""local build"" under Windows","I liked the feature of using ""drone build <dir-to-repo>"" to perform a local build of my git repo before pushing to the standard CI server. Unfortunately the Windows build from http://downloads.drone.io/drone-cli/drone_windows_amd64.tar.gz doesn't work in this manner - the expected directory only had an oddly named ""varcachedronesrc<dir-base>"" directory in it. After some hacking I've managed to fix this by: 1) Forcing windows file separators back to unix-style ones where intended for use inside the created docker container/Dockerfile. (filepath.join was converting to windows style in https://github.com/drone/drone/blob/master/cli/build.go#L164 and https://github.com/drone/drone/blob/master/shared/build/build.go#L440). Used `strings.Replace(str, ""\\"", ""/"", -1)` for lack of a better idea. 2) Switching from the tar-up-and-POST to build an image in ImageService.build (https://github.com/drone/drone/blob/master/shared/build/docker/image.go#L98) to `os.exec` out to a docker 1.6.0 binary. I don't know what part of the archive is failing but couldn't update to a newer docker repo than 1.5.0 in the `make docker` command without running into https://github.com/docker/docker/issues/10922.. Do you want a PR for this, as the full fix is a bit hacky with the shell out, and I suspect your 0.4.0 branch is quite well on already?",other-file | other-file | source-file | other-file,"No files copied to image during drone-cli ""local build"" under Windows I liked the feature of using ""drone build <dir-to-repo>"" to perform a local build of my git repo before pushing to the standard CI server. Unfortunately the Windows build from http://downloads.drone.io/drone-cli/drone_windows_amd64.tar.gz doesn't work in this manner - the expected directory only had an oddly named ""varcachedronesrc<dir-base>"" directory in it. After some hacking I've managed to fix this by: 1) Forcing windows file separators back to unix-style ones where intended for use inside the created docker container/Dockerfile. (filepath.join was converting to windows style in https://github.com/drone/drone/blob/master/cli/build.go#L164 and https://github.com/drone/drone/blob/master/shared/build/build.go#L440). Used `strings.Replace(str, ""\\"", ""/"", -1)` for lack of a better idea. 2) Switching from the tar-up-and-POST to build an image in ImageService.build (https://github.com/drone/drone/blob/master/shared/build/docker/image.go#L98) to `os.exec` out to a docker 1.6.0 binary. I don't know what part of the archive is failing but couldn't update to a newer docker repo than 1.5.0 in the `make docker` command without running into https://github.com/docker/docker/issues/10922.. Do you want a PR for this, as the full fix is a bit hacky with the shell out, and I suspect your 0.4.0 branch is quite well on already? other-file other-file source-file other-file",no-bug,0.9
118,harness,https://github.com/harness/harness/issues/118,SSH Deployments?,"I see this on drone.io, but not here? http://docs.drone.io/ssh.html",source-file | source-file | source-file | source-file | test-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file,"SSH Deployments? I see this on drone.io, but not here? http://docs.drone.io/ssh.html source-file source-file source-file source-file test-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file",no-bug,0.8
3389,harness,https://github.com/harness/harness/issues/3389,Feature Request: Add feedback for routing failure,It would be really nice to get feedback about things like the status of attempts to route pipelines to nodes. Right now what I see is a hung build when I assume it's not matching the labels I have in `node`. It would be really useful to at least have debug output on the server or runner to say that it's attempting or has attempted and not immediately succeeded in routing to a node.,other-file | other-file | other-file | other-file | other-file | other-file | other-file,Feature Request: Add feedback for routing failure It would be really nice to get feedback about things like the status of attempts to route pipelines to nodes. Right now what I see is a hung build when I assume it's not matching the labels I have in `node`. It would be really useful to at least have debug output on the server or runner to say that it's attempting or has attempted and not immediately succeeded in routing to a node. other-file other-file other-file other-file other-file other-file other-file,no-bug,0.9
553,harness,https://github.com/harness/harness/issues/553,Issues with GitHub auth setting up v0.3,"Following the instructions in the readme, I created a new GitHub app. I placed the ID and key in the `drone.toml` file and made sure that the authorization callback URL was set accordingly (`/api/auth/github.com`). When attempting to login for the first time the process stops in the browser with the authorization callback URL in the address bar and the page is blank. The last thing written to the `drone.log` file is `usubscribed to subscription`.",source-file | other-file | other-file | source-file | documentation-file | other-file | source-file,"Issues with GitHub auth setting up v0.3 Following the instructions in the readme, I created a new GitHub app. I placed the ID and key in the `drone.toml` file and made sure that the authorization callback URL was set accordingly (`/api/auth/github.com`). When attempting to login for the first time the process stops in the browser with the authorization callback URL in the address bar and the page is blank. The last thing written to the `drone.log` file is `usubscribed to subscription`. source-file other-file other-file source-file documentation-file other-file source-file",no-bug,0.7
343,harness,https://github.com/harness/harness/issues/343,Give choice for .drone.yml: whether in repo or given via Drone's Web UI,Isn't it possible to have the choice to provide a .drone.yml file directly in the repo or if it is not present use a drone.yml file configured from the project settings in Drone's Web UI client. (most like drone.io),other-file | documentation-file | other-file,Give choice for .drone.yml: whether in repo or given via Drone's Web UI Isn't it possible to have the choice to provide a .drone.yml file directly in the repo or if it is not present use a drone.yml file configured from the project settings in Drone's Web UI client. (most like drone.io) other-file documentation-file other-file,no-bug,0.9
401,harness,https://github.com/harness/harness/issues/401,go 1.3 official image,would be sweet!,other-file,go 1.3 official image would be sweet! other-file,no-bug,0.9
2804,harness,https://github.com/harness/harness/issues/2804,job stil active after running,"please help,my pileline is build docker and publish via helm chart , but the job is still active after running, and my disk space is full of caches.",other-file | other-file | other-file,"job stil active after running please help,my pileline is build docker and publish via helm chart , but the job is still active after running, and my disk space is full of caches. other-file other-file other-file",no-bug,0.9
817,harness,https://github.com/harness/harness/issues/817,Docker publish assumes sudo is installed,First off thanks for adding the docker publish plugin. I think it will be really useful for many people. However the docker publish plugin doesn't seem to be compatible with all base images. When using the default node image the following error is produced:  $ type -p docker || wget -qO- https://get.docker.io/builds/Linux/x86_64/docker-1.3.tgz |sudo tar zxf - -C / /usr/local/bin/drone: line 86: sudo: command not found  Here is my .drone.yml  image: node:latest script: - echo $DRONE_COMMIT - npm install gulp -g - npm install - gulp test publish: docker: dockerfile: Dockerfile docker_host: 0.0.0.0 docker_port: 2375 docker_version: 1.3 registry_host: mysite.com registry_protocol: https registry_login: true registry_login_uri: /registry/v1/ username: $$registry_user password: $$registry_pass image_name: myImage push_latest: true keep_builds: false tag: $$DRONE_COMMIT ,source-file | test-file | test-file,Docker publish assumes sudo is installed First off thanks for adding the docker publish plugin. I think it will be really useful for many people. However the docker publish plugin doesn't seem to be compatible with all base images. When using the default node image the following error is produced:  $ type -p docker || wget -qO- https://get.docker.io/builds/Linux/x86_64/docker-1.3.tgz |sudo tar zxf - -C / /usr/local/bin/drone: line 86: sudo: command not found  Here is my .drone.yml  image: node:latest script: - echo $DRONE_COMMIT - npm install gulp -g - npm install - gulp test publish: docker: dockerfile: Dockerfile docker_host: 0.0.0.0 docker_port: 2375 docker_version: 1.3 registry_host: mysite.com registry_protocol: https registry_login: true registry_login_uri: /registry/v1/ username: $$registry_user password: $$registry_pass image_name: myImage push_latest: true keep_builds: false tag: $$DRONE_COMMIT  source-file test-file test-file,no-bug,0.9
2866,harness,https://github.com/harness/harness/issues/2866,drone server doesn't support custom port,"For some reason I can not use the 80 and 443 port for the drone server, and I set the port when `docker run` > --publish=8080:80 \ > --publish=8443:443 I noticed that after some url redirection it failed. I found the `:http` and `:https` about port in the `drone/server/server.go`. It looks like the hard code and meaning not support custom port. Can you give some advice in my situation? Thanks a lot",source-file,"drone server doesn't support custom port For some reason I can not use the 80 and 443 port for the drone server, and I set the port when `docker run` > --publish=8080:80 \ > --publish=8443:443 I noticed that after some url redirection it failed. I found the `:http` and `:https` about port in the `drone/server/server.go`. It looks like the hard code and meaning not support custom port. Can you give some advice in my situation? Thanks a lot source-file",no-bug,0.8
11,harness,https://github.com/harness/harness/issues/11,Where is the log file located?,I installed Drone on Ubuntu 13.04. Where is the log file located? I'm trying to use a HipChat notification function but I can not get any notifications on HipChat. I want to check a log file to understand what is wrong.,other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file,Where is the log file located? I installed Drone on Ubuntu 13.04. Where is the log file located? I'm trying to use a HipChat notification function but I can not get any notifications on HipChat. I want to check a log file to understand what is wrong. other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file test-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file other-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file,no-bug,0.9
496,harness,https://github.com/harness/harness/issues/496,Blank install screen on version 0.3,I'm Dockerizing the `exp` branch. When I open the URL `/install` I got a blank screen but doing an inspect I can see an invisible menu: ![screen shot 2014-10-01 at 20 10 43](https://cloud.githubusercontent.com/assets/478564/4480365/af47b07e-4996-11e4-8672-fff49b2cd2bf.png),other-file | other-file | source-file | source-file | source-file | source-file | source-file,Blank install screen on version 0.3 I'm Dockerizing the `exp` branch. When I open the URL `/install` I got a blank screen but doing an inspect I can see an invisible menu: ![screen shot 2014-10-01 at 20 10 43](https://cloud.githubusercontent.com/assets/478564/4480365/af47b07e-4996-11e4-8672-fff49b2cd2bf.png) other-file other-file source-file source-file source-file source-file source-file,no-bug,0.8
2284,harness,https://github.com/harness/harness/issues/2284,Close and reopen merge request cannot trigger build task,"I wrote a build task in drone.yml and set the event as `pull_request`, when I submit a merge request, the build task is triggered but when I close the merge request and reopen it, the build task cannot be triggered, do you know why?",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | config-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Close and reopen merge request cannot trigger build task I wrote a build task in drone.yml and set the event as `pull_request`, when I submit a merge request, the build task is triggered but when I close the merge request and reopen it, the build task cannot be triggered, do you know why? other-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file other-file config-file config-file config-file source-file source-file source-file source-file source-file config-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3264,harness,https://github.com/harness/harness/issues/3264,`DRONE_RESOURCE_REQUEST_MEMORY` The setting does not take effect,I ran drone in K8s and set DRONE_RESOURCE_REQUEST_MEMORY to 1000MIB; but it didn't seem to work. This is my runner configuration: yaml # drone-runner-kube/values.yaml  env: DRONE_NAMESPACE_DEFAULT: drone DRONE_RESOURCE_REQUEST_CPU: 500 DRONE_RESOURCE_REQUEST_MEMORY: 1000MiB   It looks like its request configuration: ![image](https://user-images.githubusercontent.com/22833963/189838724-700ce82a-fa1d-4302-b306-3a90afc2a18d.png),source-file | source-file | source-file,`DRONE_RESOURCE_REQUEST_MEMORY` The setting does not take effect I ran drone in K8s and set DRONE_RESOURCE_REQUEST_MEMORY to 1000MIB; but it didn't seem to work. This is my runner configuration: yaml # drone-runner-kube/values.yaml  env: DRONE_NAMESPACE_DEFAULT: drone DRONE_RESOURCE_REQUEST_CPU: 500 DRONE_RESOURCE_REQUEST_MEMORY: 1000MiB   It looks like its request configuration: ![image](https://user-images.githubusercontent.com/22833963/189838724-700ce82a-fa1d-4302-b306-3a90afc2a18d.png) source-file source-file source-file,no-bug,0.9
1229,harness,https://github.com/harness/harness/issues/1229,"Default clone should use ""--depth 1""",For normal CI purposes it does not make sense to clone the whole history of a repo. So the default clone should be using the `--depth 1` flag in order to only retrieve the latest revision. Or at least add an option to do so.,source-file,"Default clone should use ""--depth 1"" For normal CI purposes it does not make sense to clone the whole history of a repo. So the default clone should be using the `--depth 1` flag in order to only retrieve the latest revision. Or at least add an option to do so. source-file",no-bug,0.9
194,harness,https://github.com/harness/harness/issues/194,Deploy Plugin - Nodejitsu,Provide a deployment option for Nodejitsu. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/nodejitsu.go,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file,Deploy Plugin - Nodejitsu Provide a deployment option for Nodejitsu. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/nodejitsu.go source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file,no-bug,0.9
1036,harness,https://github.com/harness/harness/issues/1036,BitBucket integration not working,"I've pretty much followed everything here: http://readme.drone.io/setup/config/bitbucket/ The process itself is (as it should be) trivial, however it's not working. After logging in to Drone through BitBucket, the returned URL is ""/api/auth/bitbucket.org?oauth_verifier"" (with a key and token), which results in a completely blank page. Additionally /var/log/upstart/drone.log also appends an empty line with a timestamp. I'm using the latest .deb build on Ubuntu.",container-file,"BitBucket integration not working I've pretty much followed everything here: http://readme.drone.io/setup/config/bitbucket/ The process itself is (as it should be) trivial, however it's not working. After logging in to Drone through BitBucket, the returned URL is ""/api/auth/bitbucket.org?oauth_verifier"" (with a key and token), which results in a completely blank page. Additionally /var/log/upstart/drone.log also appends an empty line with a timestamp. I'm using the latest .deb build on Ubuntu. container-file",no-bug,0.7
561,harness,https://github.com/harness/harness/issues/561,Dashboard only shows 4 linked repositories,"Currently the dashboard only shows four big boxes of repositories I have linked to my account (presumably sorted by the order in which I linked them). I cannot access any of the other repositories, even if I have more than four.",other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | test-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | test-file,"Dashboard only shows 4 linked repositories Currently the dashboard only shows four big boxes of repositories I have linked to my account (presumably sorted by the order in which I linked them). I cannot access any of the other repositories, even if I have more than four. other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file test-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file test-file",no-bug,0.9
2258,harness,https://github.com/harness/harness/issues/2258,Secrets don't work in Drone 0.7,"Hi, guys! I did all steps in http://readme.drone.io/usage/secret-guide/. I see all secrets in Drone UI. sign yml, but secrets not seen. Why?",source-file | other-file | other-file | other-file | other-file | other-file | other-file | config-file | config-file | config-file | source-file | config-file | source-file | source-file,"Secrets don't work in Drone 0.7 Hi, guys! I did all steps in http://readme.drone.io/usage/secret-guide/. I see all secrets in Drone UI. sign yml, but secrets not seen. Why? source-file other-file other-file other-file other-file other-file other-file config-file config-file config-file source-file config-file source-file source-file",no-bug,0.3
638,harness,https://github.com/harness/harness/issues/638,Safari 8 not rendering correctly,"I just noticed that if i open drone with safari, the sidebar is at the top instead on the right. I just did a quick crossbrowser compatibility check and it looks like also ie10 and other safari versions do have that problem: http://www.browserstack.com/screenshots/1a74b401f1bd022c21e6bc7fe9272bc694a8d55f If ie and safari is not supported by drone than this is not an issue. David",source-file,"Safari 8 not rendering correctly I just noticed that if i open drone with safari, the sidebar is at the top instead on the right. I just did a quick crossbrowser compatibility check and it looks like also ie10 and other safari versions do have that problem: http://www.browserstack.com/screenshots/1a74b401f1bd022c21e6bc7fe9272bc694a8d55f If ie and safari is not supported by drone than this is not an issue. David source-file",no-bug,0.95
335,harness,https://github.com/harness/harness/issues/335,GitLab: Deleting branch triggers build on commit 0000000,"Title says it all, really. Whenever I delete a branch drone creates a new build on the commit 000000, which naturally fails.",source-file | config-file,"GitLab: Deleting branch triggers build on commit 0000000 Title says it all, really. Whenever I delete a branch drone creates a new build on the commit 000000, which naturally fails. source-file config-file",no-bug,0.8
3439,harness,https://github.com/harness/harness/issues/3439,Gitness website Contribution,"Hi, gitness team your website is awesome and cool I would like to have the opportunity to contribute but I am finding it difficult to find the gitness.com repo. I would appreciate the assistance cloning the repo of it is open source.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Gitness website Contribution Hi, gitness team your website is awesome and cool I would like to have the opportunity to contribute but I am finding it difficult to find the gitness.com repo. I would appreciate the assistance cloning the repo of it is open source. source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
51,harness,https://github.com/harness/harness/issues/51,Branch names with slashes are not properly handled,"Examples: `feature/my-new-feature`, `hotfix/urgent-bug`, `release/1.0`",source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Branch names with slashes are not properly handled Examples: `feature/my-new-feature`, `hotfix/urgent-bug`, `release/1.0` source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file other-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.3
3406,harness,https://github.com/harness/harness/issues/3406,Updating Docker Image,Your Docker Image Seems to use and older version of NodeJs update it to a latest version which is supported by different deployment platform. as it may lead to future velnebarability issues and deployment failures. assign me this task under hacktoberfest-accepted label,container-file | source-file,Updating Docker Image Your Docker Image Seems to use and older version of NodeJs update it to a latest version which is supported by different deployment platform. as it may lead to future velnebarability issues and deployment failures. assign me this task under hacktoberfest-accepted label container-file source-file,no-bug,0.9
2736,harness,https://github.com/harness/harness/issues/2736,Add support for expr,"Please, add support for expressions via [expr](https://github.com/antonmedv/expr) evaluator.",documentation-file,"Add support for expr Please, add support for expressions via [expr](https://github.com/antonmedv/expr) evaluator. documentation-file",no-bug,0.9
405,harness,https://github.com/harness/harness/issues/405,"0.3, Management screens for GitHub, Gitlab, Bitbucket",The screens exist in the UI but are readonly. We need to allow people to update existing configurations as well as add new configurations.,source-file | source-file | source-file | source-file | source-file,"0.3, Management screens for GitHub, Gitlab, Bitbucket The screens exist in the UI but are readonly. We need to allow people to update existing configurations as well as add new configurations. source-file source-file source-file source-file source-file",no-bug,0.9
2002,harness,https://github.com/harness/harness/issues/2002,LDAP authentication,Many companies use Active Directory to manage access to different resources. Usually AD server has LDAP protocol support to work with tools like Jira/TeamCity/BitBucket/etc.. It would be great to support authentication in Drone through LDAP.,other-file | other-file | other-file | other-file | other-file | other-file,LDAP authentication Many companies use Active Directory to manage access to different resources. Usually AD server has LDAP protocol support to work with tools like Jira/TeamCity/BitBucket/etc.. It would be great to support authentication in Drone through LDAP. other-file other-file other-file other-file other-file other-file,no-bug,0.9
187,harness,https://github.com/harness/harness/issues/187,Environment variables setting,"![](http://docs.drone.io/img/build-script.png) On the screenshot, there is a ""Environment Variables"" field. I couldn't find the same feature in open source version. How can I set it?",source-file | documentation-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file,"Environment variables setting ![](http://docs.drone.io/img/build-script.png) On the screenshot, there is a ""Environment Variables"" field. I couldn't find the same feature in open source version. How can I set it? source-file documentation-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file documentation-file source-file",no-bug,0.9
2428,harness,https://github.com/harness/harness/issues/2428,Add Rebuild button to UI,I'm a little confused about the state of this issue. I would definitely need a UI button to simply trigger a build after adding a new Repo or Rebuilding a failed build. From all the discussions I see there is also a lot of demand in the community and it seems like the REST API already exists and #318 also helped with rebuilding. But all the issues regarding the topic are closed: https://github.com/drone/drone/issues/107 - Allow an option to retest without a commit https://github.com/drone/drone/issues/126 - Manually force new builds https://github.com/drone/drone/issues/148 - Should be able to retry build https://github.com/drone/drone/issues/307 - Please add 'rebuild' button to rebuild any build that has finished https://github.com/drone/drone/issues/497 - Empty page after creating repository https://github.com/drone/drone/pull/318 - already enabled rebuilding https://github.com/drone/drone/pull/158 - would need to be implemented again,database-file | database-file | database-file | database-file | source-file,Add Rebuild button to UI I'm a little confused about the state of this issue. I would definitely need a UI button to simply trigger a build after adding a new Repo or Rebuilding a failed build. From all the discussions I see there is also a lot of demand in the community and it seems like the REST API already exists and #318 also helped with rebuilding. But all the issues regarding the topic are closed: https://github.com/drone/drone/issues/107 - Allow an option to retest without a commit https://github.com/drone/drone/issues/126 - Manually force new builds https://github.com/drone/drone/issues/148 - Should be able to retry build https://github.com/drone/drone/issues/307 - Please add 'rebuild' button to rebuild any build that has finished https://github.com/drone/drone/issues/497 - Empty page after creating repository https://github.com/drone/drone/pull/318 - already enabled rebuilding https://github.com/drone/drone/pull/158 - would need to be implemented again database-file database-file database-file database-file source-file,no-bug,0.9
2688,harness,https://github.com/harness/harness/issues/2688,Yaml command multiline regression,"Hello, Multi line is not supported since version 1.1.0. In my yaml, i have this : yaml deploy: image: docker volumes: - /var/run/docker.sock:/var/run/docker.sock commands: | docker run -d \ --name foo \ foo/foo  and in my drone build i had this `run -d \\n -name foo \\n foo/foo` But with the version 1.1.0, i have this `run -d \n --name foo \n foo/foo` `\n` are not correctly escaped so i have this error: `Unable to find image 'n:latest' locally`. Tried to compare branches to see where is the mistake but i did not find. Could you fix it ? :) Thank you.",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | other-file | other-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | source-file | documentation-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | other-file | source-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | documentation-file | source-file | other-file,"Yaml command multiline regression Hello, Multi line is not supported since version 1.1.0. In my yaml, i have this : yaml deploy: image: docker volumes: - /var/run/docker.sock:/var/run/docker.sock commands: | docker run -d \ --name foo \ foo/foo  and in my drone build i had this `run -d \\n -name foo \\n foo/foo` But with the version 1.1.0, i have this `run -d \n --name foo \n foo/foo` `\n` are not correctly escaped so i have this error: `Unable to find image 'n:latest' locally`. Tried to compare branches to see where is the mistake but i did not find. Could you fix it ? :) Thank you. other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file other-file other-file source-file source-file source-file other-file source-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file other-file source-file other-file source-file other-file other-file source-file source-file documentation-file source-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file test-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file source-file other-file source-file other-file other-file test-file other-file other-file source-file other-file other-file other-file documentation-file other-file other-file other-file documentation-file source-file other-file",no-bug,0.8
2763,harness,https://github.com/harness/harness/issues/2763,Drone 1.X: Secrets per image,In drone 0.8 there was possibility to add Secrets scoped to certain images. This would allow only trusted images to use secrets. Now in Drone 1.0 when i try add secret for image i am getting following error:  flag provided but not defined: -image  This allows everyone to create a custom image and read all the secrets from it by putting them in **.drone.yml** file which can be considered as a security issue.,source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file,Drone 1.X: Secrets per image In drone 0.8 there was possibility to add Secrets scoped to certain images. This would allow only trusted images to use secrets. Now in Drone 1.0 when i try add secret for image i am getting following error:  flag provided but not defined: -image  This allows everyone to create a custom image and read all the secrets from it by putting them in **.drone.yml** file which can be considered as a security issue. source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file,bug,0.85
2505,harness,https://github.com/harness/harness/issues/2505,Add new ENV var for Let's Encrypt account e-mail,"Please add a flag to specify an e-mail address used for Let's Encrypt account registration: https://godoc.org/golang.org/x/crypto/acme/autocert#Manager Patch should be trivial, but I can make a pull request.",source-file | source-file | source-file | source-file | source-file | source-file,"Add new ENV var for Let's Encrypt account e-mail Please add a flag to specify an e-mail address used for Let's Encrypt account registration: https://godoc.org/golang.org/x/crypto/acme/autocert#Manager Patch should be trivial, but I can make a pull request. source-file source-file source-file source-file source-file source-file",no-bug,0.9
878,harness,https://github.com/harness/harness/issues/878,bump go to go-1.4 in drone.io,"hi there, not sure this is the right place to send this but it would be great to bump the go version served by drone.io to go-1.4. many of my projects require a few interfaces introduced with 1.3 (while drone.io still serves `go1.2`) thanks, -s",other-file | other-file,"bump go to go-1.4 in drone.io hi there, not sure this is the right place to send this but it would be great to bump the go version served by drone.io to go-1.4. many of my projects require a few interfaces introduced with 1.3 (while drone.io still serves `go1.2`) thanks, -s other-file other-file",no-bug,0.9
140,harness,https://github.com/harness/harness/issues/140,"Question, modify /etc/hosts within docker container","I'm using the ruby image to run my rspec tests. My issue is that I have a internal github enterprise install, setup to internal dns. The docker image isn't provisioned to use our dns, so adding a /etc/hosts entry to point our github enterprise domain to the ip address is required. Is this possible withing the drone.yml file or is there some other way to override the /etc/hosts inside of the container?",database-file | database-file | documentation-file,"Question, modify /etc/hosts within docker container I'm using the ruby image to run my rspec tests. My issue is that I have a internal github enterprise install, setup to internal dns. The docker image isn't provisioned to use our dns, so adding a /etc/hosts entry to point our github enterprise domain to the ip address is required. Is this possible withing the drone.yml file or is there some other way to override the /etc/hosts inside of the container? database-file database-file documentation-file",no-bug,0.95
585,harness,https://github.com/harness/harness/issues/585,packaging/output directory missing before RPM creation,"Run make rpm. (Work-around: mkdir packaging/output) drone@drone:..c/github.com/drone(master)*$ make rpm fpm -s dir -t rpm -n drone -v 0.3 -p packaging/output/drone.rpm \ --rpm-compression bzip2 --rpm-os linux \ --force \ --after-install packaging/scripts/postinst.rpm \ --before-remove packaging/scripts/prerm.rpm \ --after-remove packaging/scripts/postrm.rpm \ --url https://github.com/drone/drone \ --description ""Drone continuous integration server"" \ -m ""Brad Rydzewski brad@drone.io"" \ --license ""Apache License 2.0"" \ --vendor ""drone.io"" -a amd64 \ --config-files /etc/drone/drone.toml \ packaging/root/=/ no value for epoch is set, defaulting to nil {:level=>:warn} Parent directory does not exist: packaging/output - cannot write to packaging/output/drone.rpm {:level=>:fatal}",other-file,"packaging/output directory missing before RPM creation Run make rpm. (Work-around: mkdir packaging/output) drone@drone:..c/github.com/drone(master)*$ make rpm fpm -s dir -t rpm -n drone -v 0.3 -p packaging/output/drone.rpm \ --rpm-compression bzip2 --rpm-os linux \ --force \ --after-install packaging/scripts/postinst.rpm \ --before-remove packaging/scripts/prerm.rpm \ --after-remove packaging/scripts/postrm.rpm \ --url https://github.com/drone/drone \ --description ""Drone continuous integration server"" \ -m ""Brad Rydzewski brad@drone.io"" \ --license ""Apache License 2.0"" \ --vendor ""drone.io"" -a amd64 \ --config-files /etc/drone/drone.toml \ packaging/root/=/ no value for epoch is set, defaulting to nil {:level=>:warn} Parent directory does not exist: packaging/output - cannot write to packaging/output/drone.rpm {:level=>:fatal} other-file",no-bug,0.95
1080,harness,https://github.com/harness/harness/issues/1080,Broken link to font file,"0.4 uses the following font file, which returns a `404`: http://cdn.rawgit.com/zavoloklom/material-design-iconic-font/master/css/material-design-iconic-font.min.css",other-file,"Broken link to font file 0.4 uses the following font file, which returns a `404`: http://cdn.rawgit.com/zavoloklom/material-design-iconic-font/master/css/material-design-iconic-font.min.css other-file",no-bug,0.9
465,harness,https://github.com/harness/harness/issues/465,Java 1.8 version used is generating invalid byte-code,"I've been debugging an issue for quite a while where a certain code executes correctly on my machines, but always fail on drone.io. It turns out that drone.io uses an older release of the Java 1.8 SDK which contains a [code generation bug](http://bugs.java.com/view_bug.do?bug_id=8036942). In essence, if a lambda expression contains a multicatch statement, then the wrong catch clause is entered. Specifically in my case, [this is the code segment](https://github.com/project-iris/iris-java/blob/68b72fc6a5bda058e0b9f4f1a36d950d7a770b01/src/test/java/com/karalabe/iris/RequestTest.java#L287) that is executed, and the [drone.io output](https://drone.io/github.com/project-iris/iris-java/142). Code snippet:  java new Thread(() -> { try { conn.request(TestConfigs.CLUSTER_NAME, new byte[]{0x00}, 1000); } catch (IOException | RemoteException | TimeoutException ignore) { ignore.printStackTrace(); // Not what we expected, time out } catch (ClosedException ignore) { done.release(); } }).start();  Output snippet:  com.karalabe.iris.RequestTest > terminate STANDARD_ERROR com.karalabe.iris.exceptions.ClosedException: java.lang.InterruptedException at com.karalabe.iris.schemes.RequestScheme.request(RequestScheme.java:80) at com.karalabe.iris.Connection.request(Connection.java:120) at com.karalabe.iris.RequestTest.lambda$terminate$4(RequestTest.java:285) at com.karalabe.iris.RequestTest$$Lambda$14/912498451.run(Unknown Source) at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.InterruptedException at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at com.karalabe.iris.schemes.RequestScheme.request(RequestScheme.java:78)  As you can see, the first catch clause catches the ClosedException, even though only the second one should be able to.",other-file | other-file | source-file,"Java 1.8 version used is generating invalid byte-code I've been debugging an issue for quite a while where a certain code executes correctly on my machines, but always fail on drone.io. It turns out that drone.io uses an older release of the Java 1.8 SDK which contains a [code generation bug](http://bugs.java.com/view_bug.do?bug_id=8036942). In essence, if a lambda expression contains a multicatch statement, then the wrong catch clause is entered. Specifically in my case, [this is the code segment](https://github.com/project-iris/iris-java/blob/68b72fc6a5bda058e0b9f4f1a36d950d7a770b01/src/test/java/com/karalabe/iris/RequestTest.java#L287) that is executed, and the [drone.io output](https://drone.io/github.com/project-iris/iris-java/142). Code snippet:  java new Thread(() -> { try { conn.request(TestConfigs.CLUSTER_NAME, new byte[]{0x00}, 1000); } catch (IOException | RemoteException | TimeoutException ignore) { ignore.printStackTrace(); // Not what we expected, time out } catch (ClosedException ignore) { done.release(); } }).start();  Output snippet:  com.karalabe.iris.RequestTest > terminate STANDARD_ERROR com.karalabe.iris.exceptions.ClosedException: java.lang.InterruptedException at com.karalabe.iris.schemes.RequestScheme.request(RequestScheme.java:80) at com.karalabe.iris.Connection.request(Connection.java:120) at com.karalabe.iris.RequestTest.lambda$terminate$4(RequestTest.java:285) at com.karalabe.iris.RequestTest$$Lambda$14/912498451.run(Unknown Source) at java.lang.Thread.run(Thread.java:744) Caused by: java.lang.InterruptedException at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at com.karalabe.iris.schemes.RequestScheme.request(RequestScheme.java:78)  As you can see, the first catch clause catches the ClosedException, even though only the second one should be able to. other-file other-file source-file",no-bug,0.95
176,harness,https://github.com/harness/harness/issues/176,Fail Started / Pending builds when Drone is restarted,"My drone container was killed during a build. Now the build in question is in a perpetual ""running"" state. Depending on the implementation, I think there should either be a timeout in general, or in-progress jobs should be marked fail after a restart, if there is no way for them to be completed anyway.",other-file,"Fail Started / Pending builds when Drone is restarted My drone container was killed during a build. Now the build in question is in a perpetual ""running"" state. Depending on the implementation, I think there should either be a timeout in general, or in-progress jobs should be marked fail after a restart, if there is no way for them to be completed anyway. other-file",no-bug,0.9
474,harness,https://github.com/harness/harness/issues/474,"""Method Not Allowed"" after login when clicking ""Rebuild"" with expired session","When clicking ""Rebuild"" with an expired session the POST request redirects you to /login with the return_url set to the URL of post request. And after the login it does a GET request to that URL which is declined with ""Method Not Allowed"".",other-file | other-file | source-file | other-file | source-file | documentation-file | other-file | other-file,"""Method Not Allowed"" after login when clicking ""Rebuild"" with expired session When clicking ""Rebuild"" with an expired session the POST request redirects you to /login with the return_url set to the URL of post request. And after the login it does a GET request to that URL which is declined with ""Method Not Allowed"". other-file other-file source-file other-file source-file documentation-file other-file other-file",bug,0.9
3044,harness,https://github.com/harness/harness/issues/3044,"Show who ""owns"" or ""enabled"" the repo","Since the repo ""owner"" who activated the repo in Drone grants their credentials to be used (and thus embedded for things like accessing dependencies in private repos), Drone should show who added the repo to it. The problem is that when people leave organizations or revoke their access to Drone, it's not transparent why builds stopped from looking at Drone. If the owner's handle + icon was visible then it would be easy to understand ""oh this person left so I need to chown"" this repo (the shortfall of oauth apps [until GH Apps is a thing](https://github.com/drone/drone/issues/2422)).",source-file | source-file | source-file | source-file | source-file,"Show who ""owns"" or ""enabled"" the repo Since the repo ""owner"" who activated the repo in Drone grants their credentials to be used (and thus embedded for things like accessing dependencies in private repos), Drone should show who added the repo to it. The problem is that when people leave organizations or revoke their access to Drone, it's not transparent why builds stopped from looking at Drone. If the owner's handle + icon was visible then it would be easy to understand ""oh this person left so I need to chown"" this repo (the shortfall of oauth apps [until GH Apps is a thing](https://github.com/drone/drone/issues/2422)). source-file source-file source-file source-file source-file",no-bug,0.9
2129,harness,https://github.com/harness/harness/issues/2129,[Feature Request] API Access for User Account Token,"Currently we're using Drone.io to setup environments for use in building a wide array of applications using various stacks. The technology stacks we're using range from Go, Java, .NET Core, Python, JavaScript/Node.js and others. When we setup these environments, the entire ecosystem - from individual environments, user accounts, and related collateral - are spun up via an automated system created with Terraform, Bash, and some other tools. When these tools set everything up various pieces of state are passed from execution to execution to set all of these elements up. This automated part of the process has one huge feature we'd love to be able to have, to complete more automation around Drone.io. That feature is the ability at the API level to get a _user account token_ so that we can take additional steps via the API as that user the _user account token_ is assigned to. **_NOTE:_** I did review [Github Issue 1812](https://github.com/drone/drone/issues/1812), which was a somewhat similar yet tangential feature request. But I wanted to be specific that I'm looking for this capability to use Drone.io in an internal environment. It may still be in a public cloud service like AWS or GCP, but it wouldn't be accessible to Github or some of the other services. So a robot user account as referred in [issue 1812](https://github.com/drone/drone/issues/1812) wouldn't really work for this, _but_ this feature could prospective lend itself to building a robot feature as specified in [issue 1812](https://github.com/drone/drone/issues/1812). As per the other comments too it looks like that request and this feature could be implemented in conjunction. I've created this issue, not just to propose the feature but to see if it would be something that the Drone.io team would like to have added to the code base? If so, I'm happy to dive in and get code written to enable this and submit a PR, but wanted to check with the team to insure this is wanted or not. Cheers, @Adron",other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | documentation-file | other-file | documentation-file,"[Feature Request] API Access for User Account Token Currently we're using Drone.io to setup environments for use in building a wide array of applications using various stacks. The technology stacks we're using range from Go, Java, .NET Core, Python, JavaScript/Node.js and others. When we setup these environments, the entire ecosystem - from individual environments, user accounts, and related collateral - are spun up via an automated system created with Terraform, Bash, and some other tools. When these tools set everything up various pieces of state are passed from execution to execution to set all of these elements up. This automated part of the process has one huge feature we'd love to be able to have, to complete more automation around Drone.io. That feature is the ability at the API level to get a _user account token_ so that we can take additional steps via the API as that user the _user account token_ is assigned to. **_NOTE:_** I did review [Github Issue 1812](https://github.com/drone/drone/issues/1812), which was a somewhat similar yet tangential feature request. But I wanted to be specific that I'm looking for this capability to use Drone.io in an internal environment. It may still be in a public cloud service like AWS or GCP, but it wouldn't be accessible to Github or some of the other services. So a robot user account as referred in [issue 1812](https://github.com/drone/drone/issues/1812) wouldn't really work for this, _but_ this feature could prospective lend itself to building a robot feature as specified in [issue 1812](https://github.com/drone/drone/issues/1812). As per the other comments too it looks like that request and this feature could be implemented in conjunction. I've created this issue, not just to propose the feature but to see if it would be something that the Drone.io team would like to have added to the code base? If so, I'm happy to dive in and get code written to enable this and submit a PR, but wanted to check with the team to insure this is wanted or not. Cheers, @Adron other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file source-file other-file other-file other-file other-file other-file source-file other-file other-file other-file source-file documentation-file other-file documentation-file",no-bug,0.95
2325,harness,https://github.com/harness/harness/issues/2325,Set env vars on `drone exec --local`,"This is a feature request based on the thread here: > https://discourse.drone.io/t/set-env-vars-on-drone-exec-local/1689 In summary, I'm requesting that both the `-e`/`--env` & `--env-file` flags be added to Drone, in a way analogous to Docker's usage of these flags. The environment variables defined by these flags should be populated into the environment of all build steps in a pipeline when run via `drone exec --local`. With a slight bit of guidance (pointer to key files & branch to start from) I'd be happy to give implementing this a go.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Set env vars on `drone exec --local` This is a feature request based on the thread here: > https://discourse.drone.io/t/set-env-vars-on-drone-exec-local/1689 In summary, I'm requesting that both the `-e`/`--env` & `--env-file` flags be added to Drone, in a way analogous to Docker's usage of these flags. The environment variables defined by these flags should be populated into the environment of all build steps in a pipeline when run via `drone exec --local`. With a slight bit of guidance (pointer to key files & branch to start from) I'd be happy to give implementing this a go. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
1066,harness,https://github.com/harness/harness/issues/1066,"Update data model to support matrix builds, build numbers","This is a design document to finalize the data model in `0.4`. Having a solid data model is extremely important with the introduction of plugins, which require data stability. When plugins are introduced, structural changes the data model will be difficult and infrequent, since it could impact hundreds of plugin repositories. Each data structure below will map directly to a database table. Some data structures have nested objects (one-to-one relationships, such as Build.Commit.Author) which we can also include in the same table (no need for joins). Nested data does not include one-to-many data structures, which are instead broken out into separate structs and tables. The map data structures, however, will be serialized as JSON and stored in a single column. Hoping to finalize this over the weekend. **Please note** that the below code is pseudo-code. The final implementation will not use embedded anonymous structures. **User** Represents the user object  Go type User struct { ID int64 Login string Token string // access token Secret string // refresh token (optional) Email string Avatar string Active bool Admin bool }  **Repos** Represents a repository  Go type Repo struct { ID int64 UserID int64 // foreign key. associate the repo with creator's github access token Owner string Name string FullName string Link string // link to repo in remote system (ie github.com/drone/drone) Remote string // clone url Branch string // default branch Private bool Trusted bool Timeout int64 Keys struct { Public string Private string } Hooks struct { PullRequest bool // enable or disable pull request hooks Push bool // enable or disable push hooks Tags bool } Params map[string]string // private params not stored in yaml }  **Builds** Represents a build. Includes commit data and optional pull request data. The optional pull request data includes the base of the working branch, to which the pull request is being merged. This is important for testing pull requests in non-github systems  Go type Build struct { ID int64 RepoID int64 Number int Status string Started int64 Finished int64 // Head commit. This would be used to clone pushes Commit struct { Sha string Ref string Branch string Message string Timestamp string Remote string Author struct { Login string Email string } } // optional, nil if not pull request PullRequest struct { Title string Number int // Base commit (ie target of pull request). We would clone the Base commit // first, then merge the Head commit, and then run our tests. This would be // used with Bitbucket and GitLab, since they don't provide a ref for pull requests Base struct { Sha string Ref string Branch string Message string Timestamp string Remote string Author struct { Login string Email string } } } }  **Jobs (Sub-build)** Every build has at least 1 job. A matrix build will have multiple jobs.  Go type Job struct { ID int64 BuildID int64 Number int Status string ExitCode int Started int64 Finished int64 Environment map[string]string # matrix parameters } ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file,"Update data model to support matrix builds, build numbers This is a design document to finalize the data model in `0.4`. Having a solid data model is extremely important with the introduction of plugins, which require data stability. When plugins are introduced, structural changes the data model will be difficult and infrequent, since it could impact hundreds of plugin repositories. Each data structure below will map directly to a database table. Some data structures have nested objects (one-to-one relationships, such as Build.Commit.Author) which we can also include in the same table (no need for joins). Nested data does not include one-to-many data structures, which are instead broken out into separate structs and tables. The map data structures, however, will be serialized as JSON and stored in a single column. Hoping to finalize this over the weekend. **Please note** that the below code is pseudo-code. The final implementation will not use embedded anonymous structures. **User** Represents the user object  Go type User struct { ID int64 Login string Token string // access token Secret string // refresh token (optional) Email string Avatar string Active bool Admin bool }  **Repos** Represents a repository  Go type Repo struct { ID int64 UserID int64 // foreign key. associate the repo with creator's github access token Owner string Name string FullName string Link string // link to repo in remote system (ie github.com/drone/drone) Remote string // clone url Branch string // default branch Private bool Trusted bool Timeout int64 Keys struct { Public string Private string } Hooks struct { PullRequest bool // enable or disable pull request hooks Push bool // enable or disable push hooks Tags bool } Params map[string]string // private params not stored in yaml }  **Builds** Represents a build. Includes commit data and optional pull request data. The optional pull request data includes the base of the working branch, to which the pull request is being merged. This is important for testing pull requests in non-github systems  Go type Build struct { ID int64 RepoID int64 Number int Status string Started int64 Finished int64 // Head commit. This would be used to clone pushes Commit struct { Sha string Ref string Branch string Message string Timestamp string Remote string Author struct { Login string Email string } } // optional, nil if not pull request PullRequest struct { Title string Number int // Base commit (ie target of pull request). We would clone the Base commit // first, then merge the Head commit, and then run our tests. This would be // used with Bitbucket and GitLab, since they don't provide a ref for pull requests Base struct { Sha string Ref string Branch string Message string Timestamp string Remote string Author struct { Login string Email string } } } }  **Jobs (Sub-build)** Every build has at least 1 job. A matrix build will have multiple jobs.  Go type Job struct { ID int64 BuildID int64 Number int Status string ExitCode int Started int64 Finished int64 Environment map[string]string # matrix parameters }  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file",no-bug,0.9
3547,harness,https://github.com/harness/harness/issues/3547,Drone Pipeline Timed Out,I followed the default server installation instructions for gitness and I am running into the issue where the pipeline is timing out trying to clone to repository: `Failed to connect to host.docker.internal port 3000 after 134630 ms: Operation timed out `,other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Drone Pipeline Timed Out I followed the default server installation instructions for gitness and I am running into the issue where the pipeline is timing out trying to clone to repository: `Failed to connect to host.docker.internal port 3000 after 134630 ms: Operation timed out ` other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
2857,harness,https://github.com/harness/harness/issues/2857,[Proposal] support custom volume to mapping source-code when use k8s mode,"Dear all, Drone is an awesome CI/CD tool and we use it about 3 years. thanks again ! recently, we upgrade our workflow to work with Drone k8s build feature. but we found it's a little slow because when use k8s mode, drone-runner-pod always create a new volume mapping because pod and namespace name is random value.it's make sense. we should physical isolation different pod. but I think maybe we can set a volume to mapping source-code & only for source-code. all pod work on same k8s node will share same path. this can save a lot of time.",other-file | source-file,"[Proposal] support custom volume to mapping source-code when use k8s mode Dear all, Drone is an awesome CI/CD tool and we use it about 3 years. thanks again ! recently, we upgrade our workflow to work with Drone k8s build feature. but we found it's a little slow because when use k8s mode, drone-runner-pod always create a new volume mapping because pod and namespace name is random value.it's make sense. we should physical isolation different pod. but I think maybe we can set a volume to mapping source-code & only for source-code. all pod work on same k8s node will share same path. this can save a lot of time. other-file source-file",no-bug,0.95
2021,harness,https://github.com/harness/harness/issues/2021,drone exec ignores when: local: false,Drone version: .6 Repro steps: 1. create a .drone.yml file with some steps that have secrets 2. add { when: { local: false }} yml equiv to the steps with secrets 3. run drone exec if will try to still run the containers that are marked for local: false from a conversation with @bradrydzewski it looks like this may have been lost from .5 but should get brought back into .6,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,drone exec ignores when: local: false Drone version: .6 Repro steps: 1. create a .drone.yml file with some steps that have secrets 2. add { when: { local: false }} yml equiv to the steps with secrets 3. run drone exec if will try to still run the containers that are marked for local: false from a conversation with @bradrydzewski it looks like this may have been lost from .5 but should get brought back into .6 source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
690,harness,https://github.com/harness/harness/issues/690,Multiple ssh commands,"Current, you can only run one command in an SSH deployment scenario. This should be changed to allow a list of commands, similar to the `script` section. e.g.  deploy: ssh: target: foo@server.de:var/www cmd: git pull origin master; python manage.py syncdb  Instead it would be awesome to do something like  deploy: ssh: target: foo@server.de:var/www cmd: - git pull origin master - python manage.py syncdb ",source-file | test-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file,"Multiple ssh commands Current, you can only run one command in an SSH deployment scenario. This should be changed to allow a list of commands, similar to the `script` section. e.g.  deploy: ssh: target: foo@server.de:var/www cmd: git pull origin master; python manage.py syncdb  Instead it would be awesome to do something like  deploy: ssh: target: foo@server.de:var/www cmd: - git pull origin master - python manage.py syncdb  source-file test-file source-file source-file source-file source-file source-file other-file source-file source-file",no-bug,0.9
2602,harness,https://github.com/harness/harness/issues/2602,Enable Path Style for S3 integration,"this was initially discussed in https://github.com/drone/drone/pull/2600 add the following parameters: * `DRONE_S3_SKIP_VERIFY=false` * `DRONE_S3_PATH_STYLE=false` and use when setting the aws configuration in `store/logs/s3.go` diff &aws.Config{ Endpoint: aws.String(endpoint), + DisableSSL: aws.Bool(skipverify), + S3ForcePathStyle: aws.Bool(pathstyle), }  reference implementation: https://github.com/minio/cookbook/blob/master/docs/aws-sdk-for-go-with-minio.md",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file,"Enable Path Style for S3 integration this was initially discussed in https://github.com/drone/drone/pull/2600 add the following parameters: * `DRONE_S3_SKIP_VERIFY=false` * `DRONE_S3_PATH_STYLE=false` and use when setting the aws configuration in `store/logs/s3.go` diff &aws.Config{ Endpoint: aws.String(endpoint), + DisableSSL: aws.Bool(skipverify), + S3ForcePathStyle: aws.Bool(pathstyle), }  reference implementation: https://github.com/minio/cookbook/blob/master/docs/aws-sdk-for-go-with-minio.md source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file",no-bug,0.9
1426,harness,https://github.com/harness/harness/issues/1426,Docker base image up for change?,"Hi All, I wanted to ask if the community would be open to changing the base Docker image from ""scratch"" to alpine or busybox. I really like scratch, I do, but it limits extendability when the tools inside have an external dependency. For instance, if I need to wait for the existence of a configuration file that will contain all of my environment variables, I have no way to extend without making my own image because there is no shell. By creating a configuration container, that will generate the file with confd and share a new entrypoint script to source it, I could alter the behavior _WITHOUT_ modifying the upstream container and all of its goodness. By injecting configuration and alternate scripts, one does not need to worry about disturbing the core dependencies of the app. something like:  drone: image: drone/drone:0.4 entrypoint: /opt/scripts/entry volumes_from: - drone-config  drone-config: image: cloudnautique/drone-config:0.4 volumes: - /opt/scripts  with a script in `/opt/scripts/` that looks like  #!/bin/bash while [ ! -e /etc/drone/dronerc ]; do sleep 1 done source /etc/drone/dronerc exec /drone_static  Currently, something like this fails because there is no shell in drone:0.4. Alternatively, if the binary was placed in a folder instead of `/` the relationship could be flipped. So if /drone/bin/drone_static was where the binary lived, the container could be launched with `-v /drone` and picked up with volumes-from in the conf container. In general, I like the idea of having a shell for troubleshooting purposes, but I certainly see the benefits of `scratch`. Thoughts? Alternate approaches? I will be happy to put in a PR one way or another.",container-file | container-file,"Docker base image up for change? Hi All, I wanted to ask if the community would be open to changing the base Docker image from ""scratch"" to alpine or busybox. I really like scratch, I do, but it limits extendability when the tools inside have an external dependency. For instance, if I need to wait for the existence of a configuration file that will contain all of my environment variables, I have no way to extend without making my own image because there is no shell. By creating a configuration container, that will generate the file with confd and share a new entrypoint script to source it, I could alter the behavior _WITHOUT_ modifying the upstream container and all of its goodness. By injecting configuration and alternate scripts, one does not need to worry about disturbing the core dependencies of the app. something like:  drone: image: drone/drone:0.4 entrypoint: /opt/scripts/entry volumes_from: - drone-config  drone-config: image: cloudnautique/drone-config:0.4 volumes: - /opt/scripts  with a script in `/opt/scripts/` that looks like  #!/bin/bash while [ ! -e /etc/drone/dronerc ]; do sleep 1 done source /etc/drone/dronerc exec /drone_static  Currently, something like this fails because there is no shell in drone:0.4. Alternatively, if the binary was placed in a folder instead of `/` the relationship could be flipped. So if /drone/bin/drone_static was where the binary lived, the container could be launched with `-v /drone` and picked up with volumes-from in the conf container. In general, I like the idea of having a shell for troubleshooting purposes, but I certainly see the benefits of `scratch`. Thoughts? Alternate approaches? I will be happy to put in a PR one way or another. container-file container-file",no-bug,0.95
2799,harness,https://github.com/harness/harness/issues/2799,Do drone Support the SVN?,My CVS is SVN. Can I use drone?,other-file | other-file | source-file | other-file | other-file | source-file | other-file,Do drone Support the SVN? My CVS is SVN. Can I use drone? other-file other-file source-file other-file other-file source-file other-file,no-bug,0.9
525,harness,https://github.com/harness/harness/issues/525,exp not working after initial auth w/ github enterprise [0.3],"After authorizing against github enterprise I am redirected to a blank page with the following log (with actual code and state of course)  2014/10/09 00:01:59.800599 [47744fe7df1d/brZBwyUGPx-000025] Started GET ""/api/auth/enterprise.github.com?code=yyyy&state=xxxx"" from 10.0.2.2:63002 2014/10/09 00:01:59.800654 [47744fe7df1d/brZBwyUGPx-000025] Returning 400 in 37.051us  This looks like the same error I was receiving when trying to use 0.3 against github.com without a verified email. Is there something looking for specifically a verified email? /user/emails is sending back a valid email, but verified is set to false.",other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file,"exp not working after initial auth w/ github enterprise [0.3] After authorizing against github enterprise I am redirected to a blank page with the following log (with actual code and state of course)  2014/10/09 00:01:59.800599 [47744fe7df1d/brZBwyUGPx-000025] Started GET ""/api/auth/enterprise.github.com?code=yyyy&state=xxxx"" from 10.0.2.2:63002 2014/10/09 00:01:59.800654 [47744fe7df1d/brZBwyUGPx-000025] Returning 400 in 37.051us  This looks like the same error I was receiving when trying to use 0.3 against github.com without a verified email. Is there something looking for specifically a verified email? /user/emails is sending back a valid email, but verified is set to false. other-file other-file source-file other-file other-file other-file other-file other-file",bug,0.85
3416,harness,https://github.com/harness/harness/issues/3416,login error Not Found,"Gitness cannot log in again after running for a period of time, account lost  docker run -d --name gitness --restart always \ -e GITNESS_PRINCIPAL_ADMIN_PASSWORD=gitness \ -e GITNESS_USER_SIGNUP_ENABLED=false \ -p 3000:3000 \ -v /var/run/docker.sock:/var/run/docker.sock \ -v /data/gitness:/data \ harness/gitness ",source-file,"login error Not Found Gitness cannot log in again after running for a period of time, account lost  docker run -d --name gitness --restart always \ -e GITNESS_PRINCIPAL_ADMIN_PASSWORD=gitness \ -e GITNESS_USER_SIGNUP_ENABLED=false \ -p 3000:3000 \ -v /var/run/docker.sock:/var/run/docker.sock \ -v /data/gitness:/data \ harness/gitness  source-file",bug,0.8
675,harness,https://github.com/harness/harness/issues/675,GitHub webhook always returning a 303,"I have followed the instructions on setting up Drone on Ubuntu, and I have most of the things working. I can log in with my GitHub account, it sees my repos, but when I do a commit in Github the result it is always a 303. drone.log doesn't say anything about it. But the response I get from github is this:  Access-Control-Allow-Origin: * Cache-Control: no-cache, no-store, max-age=0, must-revalidate, value Content-Length: 0 Content-Type: text/plain; charset=utf-8 Date: Fri, 07 Nov 2014 09:58:45 GMT Expires: Thu, 01 Jan 1970 00:00:00 GMT Last-Modified: Fri, 07 Nov 2014 09:58:45 GMT Location:  Set-Cookie:  X-Content-Type-Options: nosniff X-Frame-Options: DENY X-Xss-Protection: 1; mode=block  I have update to the latest .deb available, and still the same issue. And I have tried with curl sending the same payload, headers etc, and the same result. the webhook url is http://my-server/api/auth/github.com",documentation-file | other-file | other-file | other-file,"GitHub webhook always returning a 303 I have followed the instructions on setting up Drone on Ubuntu, and I have most of the things working. I can log in with my GitHub account, it sees my repos, but when I do a commit in Github the result it is always a 303. drone.log doesn't say anything about it. But the response I get from github is this:  Access-Control-Allow-Origin: * Cache-Control: no-cache, no-store, max-age=0, must-revalidate, value Content-Length: 0 Content-Type: text/plain; charset=utf-8 Date: Fri, 07 Nov 2014 09:58:45 GMT Expires: Thu, 01 Jan 1970 00:00:00 GMT Last-Modified: Fri, 07 Nov 2014 09:58:45 GMT Location:  Set-Cookie:  X-Content-Type-Options: nosniff X-Frame-Options: DENY X-Xss-Protection: 1; mode=block  I have update to the latest .deb available, and still the same issue. And I have tried with curl sending the same payload, headers etc, and the same result. the webhook url is http://my-server/api/auth/github.com documentation-file other-file other-file other-file",no-bug,0.8
980,harness,https://github.com/harness/harness/issues/980,Option to specifiy the hostname/url of the drone instance,"I`ve been trying to get drone running behind an apache installation in which I only have access to .htaccess files and mod_rewrite proxy options. drone always detects the internal address (localhost) and internal port and passes it on to github/bitbucket So instead of using drone.domain.com drone passes localhost:PORT to the github api. It would be great to not only have an option to specify the port for the server, but also the domainname / ip address. (currently I use a dirty hack by hardcoding my url into /shared/httputil/httputil.go",container-file,"Option to specifiy the hostname/url of the drone instance I`ve been trying to get drone running behind an apache installation in which I only have access to .htaccess files and mod_rewrite proxy options. drone always detects the internal address (localhost) and internal port and passes it on to github/bitbucket So instead of using drone.domain.com drone passes localhost:PORT to the github api. It would be great to not only have an option to specify the port for the server, but also the domainname / ip address. (currently I use a dirty hack by hardcoding my url into /shared/httputil/httputil.go container-file",no-bug,0.8
1100,harness,https://github.com/harness/harness/issues/1100,Github Authentication Issue (build 0.4.0),"I have been having trouble getting github authentication working in the latest 0.4.0 build. Realizing this is under heavy development, I thought I'd share my results in the event its an actual bug, but it could simply be a configuration issue :) My TOML config looks like this  [server] addr = "":80"" [database] driver=""sqlite3"" datasource=""/var/lib/drone/drone.sqlite"" [docker] addr = ""unix:var/run/docker.sock"" swarm = false [remote] kind=""github"" base=""https://github.com"" orgs=[""my_org""] open=true [auth] client=""xxx"" secret=""xxxxx"" authorize=""https://github.com/login/oauth/authorize"" access_token=""https://github.com/login/oauth/access_token""  I have set up the GH Application with the following..  homepage url: http://x.x.x.x auth callback url: http://x.x.x.x/api/auth/github.com  With this configuration, I receive a URI mismatch error  http://x.x.x.x/login?error=redirect_uri_mismatch&error_description=The%20redirect_uri%20MUST%20match%20the%20registered%20callback%20URL%20for%20this%20application.&error_uri=https:%2F%2Fdeveloper.github.com%2Fv3%2Foauth%2F%23redirect-uri-mismatch&state=random  If i modify the ""auth callback url"" to match the ""homepage url"", I am redirected from Drone -> GH login, at which point I am able to authorize the application. I am then redirected back to Drone, where I receive an error ""There was an error authorizing your account""  http://x.x.x.x/login#error=user_not_found  Running this all in debug mode, I have the following in my log  [GIN] 2015/07/17 - 10:22:33 | 200 | 172.985s | x.x.x.x:52191 | GET / [GIN] 2015/07/17 - 10:22:33 | 401 | 76.747s | x.x.x.x:52202 | GET /api/user [GIN] 2015/07/17 - 10:22:33 | 401 | 41.783s | x.x.x.x:52203 | GET /api/user [GIN] 2015/07/17 - 10:22:33 | 401 | 22.659s | x.x.x.x:52202 | GET /api/user/repos [GIN] 2015/07/17 - 10:22:34 | 303 | 515.537s | x.x.x.x:52204 | GET /authorize ERRO[0074] cannot get user with access_token. GET https://api.github.com/user/emails: 404 Not Found [] [GIN] 2015/07/17 - 10:22:46 | 303 | 293.630906ms | x.x.x.x:52204 | GET /authorize [GIN] 2015/07/17 - 10:22:47 | 200 | 90.46s | x.x.x.x:52204 | GET /login [GIN] 2015/07/17 - 10:23:23 | 303 | 108.303s | x.x.x.x:52164 | GET /authorize ERRO[0111] cannot get user with access_token. GET https://api.github.com/user/emails: 404 Not Found [] [GIN] 2015/07/17 - 10:23:23 | 303 | 176.590794ms | x.x.x.x:52164 | GET /authorize [GIN] 2015/07/17 - 10:23:23 | 200 | 59.108s | x.x.x.x:52164 | GET /login  If you need any more information, please let me know! I appreciate any help you have to offer",other-file | source-file | other-file | other-file | source-file | documentation-file | other-file,"Github Authentication Issue (build 0.4.0) I have been having trouble getting github authentication working in the latest 0.4.0 build. Realizing this is under heavy development, I thought I'd share my results in the event its an actual bug, but it could simply be a configuration issue :) My TOML config looks like this  [server] addr = "":80"" [database] driver=""sqlite3"" datasource=""/var/lib/drone/drone.sqlite"" [docker] addr = ""unix:var/run/docker.sock"" swarm = false [remote] kind=""github"" base=""https://github.com"" orgs=[""my_org""] open=true [auth] client=""xxx"" secret=""xxxxx"" authorize=""https://github.com/login/oauth/authorize"" access_token=""https://github.com/login/oauth/access_token""  I have set up the GH Application with the following..  homepage url: http://x.x.x.x auth callback url: http://x.x.x.x/api/auth/github.com  With this configuration, I receive a URI mismatch error  http://x.x.x.x/login?error=redirect_uri_mismatch&error_description=The%20redirect_uri%20MUST%20match%20the%20registered%20callback%20URL%20for%20this%20application.&error_uri=https:%2F%2Fdeveloper.github.com%2Fv3%2Foauth%2F%23redirect-uri-mismatch&state=random  If i modify the ""auth callback url"" to match the ""homepage url"", I am redirected from Drone -> GH login, at which point I am able to authorize the application. I am then redirected back to Drone, where I receive an error ""There was an error authorizing your account""  http://x.x.x.x/login#error=user_not_found  Running this all in debug mode, I have the following in my log  [GIN] 2015/07/17 - 10:22:33 | 200 | 172.985s | x.x.x.x:52191 | GET / [GIN] 2015/07/17 - 10:22:33 | 401 | 76.747s | x.x.x.x:52202 | GET /api/user [GIN] 2015/07/17 - 10:22:33 | 401 | 41.783s | x.x.x.x:52203 | GET /api/user [GIN] 2015/07/17 - 10:22:33 | 401 | 22.659s | x.x.x.x:52202 | GET /api/user/repos [GIN] 2015/07/17 - 10:22:34 | 303 | 515.537s | x.x.x.x:52204 | GET /authorize ERRO[0074] cannot get user with access_token. GET https://api.github.com/user/emails: 404 Not Found [] [GIN] 2015/07/17 - 10:22:46 | 303 | 293.630906ms | x.x.x.x:52204 | GET /authorize [GIN] 2015/07/17 - 10:22:47 | 200 | 90.46s | x.x.x.x:52204 | GET /login [GIN] 2015/07/17 - 10:23:23 | 303 | 108.303s | x.x.x.x:52164 | GET /authorize ERRO[0111] cannot get user with access_token. GET https://api.github.com/user/emails: 404 Not Found [] [GIN] 2015/07/17 - 10:23:23 | 303 | 176.590794ms | x.x.x.x:52164 | GET /authorize [GIN] 2015/07/17 - 10:23:23 | 200 | 59.108s | x.x.x.x:52164 | GET /login  If you need any more information, please let me know! I appreciate any help you have to offer other-file source-file other-file other-file source-file documentation-file other-file",no-bug,0.8
2679,harness,https://github.com/harness/harness/issues/2679,"Trigger build for Branch, Commit","Currently the only way to programmatically trigger a build is by re-starting an existing build with a new build number via the API. With 1.0 we now have the ability to fetch command branch data from version control, which means we can trigger a new build without any pre-existing data. I propose adding the following endpoints:  POST /api/repos/{namespace}/{name}/builds POST /api/repos/{namespace}/{name}/builds?branch={branch} POST /api/repos/{namespace}/{name}/builds?branch={branch}&commit={commit}  You can pass additional parameters to your pipeline as url query parameters:  POST /api/repos/{namespace}/{name}/builds?branch={branch}&{key=value}  Note that if no branch is provided, the default branch (master) is used.",documentation-file | source-file | source-file | test-file,"Trigger build for Branch, Commit Currently the only way to programmatically trigger a build is by re-starting an existing build with a new build number via the API. With 1.0 we now have the ability to fetch command branch data from version control, which means we can trigger a new build without any pre-existing data. I propose adding the following endpoints:  POST /api/repos/{namespace}/{name}/builds POST /api/repos/{namespace}/{name}/builds?branch={branch} POST /api/repos/{namespace}/{name}/builds?branch={branch}&commit={commit}  You can pass additional parameters to your pipeline as url query parameters:  POST /api/repos/{namespace}/{name}/builds?branch={branch}&{key=value}  Note that if no branch is provided, the default branch (master) is used. documentation-file source-file source-file test-file",no-bug,0.9
94,harness,https://github.com/harness/harness/issues/94,Enable ListenAndServeTLS for https support,"It is currently possible to set ""http"" or ""https"" modes but where to put SSL certificate and key to make it work?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Enable ListenAndServeTLS for https support It is currently possible to set ""http"" or ""https"" modes but where to put SSL certificate and key to make it work? source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
867,harness,https://github.com/harness/harness/issues/867,Error when running drone from deb - 0.3.0-alpha-1423116857,"On drone installed via deb on an ubuntu 14.10 machine, deb version 0.3.0-alpha-1423116857, visiting the site results to:  2015/02/05 10:30:53 http: panic serving 127.0.0.1:40439: read /usr/local/bin/droned: bad file descriptor goroutine 36 [running]: net/http.func011() /usr/local/go/src/pkg/net/http/server.go:1100 +0xb7 runtime.panic(0xa997c0, 0xc20809b500) /usr/local/go/src/pkg/runtime/panic.c:248 +0x18d github.com/GeertJohan/go%2erice.(*Box).MustBytes(0xc208111a10, 0xbf7090, 0xa, 0x0, 0x0, 0x0) /var/cache/drone/src/github.com/GeertJohan/go.rice/box.go:298 +0xc0 main.func001(0x7f40b6d7ba10, 0xc208044c80, 0xc208108820) /var/cache/drone/src/github.com/drone/drone/server/main.go:133 +0x3d net/http.HandlerFunc.ServeHTTP(0xc2080362a0, 0x7f40b6d7ba10, 0xc208044c80, 0xc208108820) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 net/http.(*ServeMux).ServeHTTP(0xc208022930, 0x7f40b6d7ba10, 0xc208044c80, 0xc208108820) /usr/local/go/src/pkg/net/http/server.go:1511 +0x1a3 net/http.serverHandler.ServeHTTP(0xc208005c20, 0x7f40b6d7ba10, 0xc208044c80, 0xc208108820) /usr/local/go/src/pkg/net/http/server.go:1673 +0x19f net/http.(*conn).serve(0xc208050980) /usr/local/go/src/pkg/net/http/server.go:1174 +0xa7e created by net/http.(*Server).Serve /usr/local/go/src/pkg/net/http/server.go:1721 +0x313  The same machine used to run an older 0.3.0 alpha just fine. Also tried it on a new machine.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Error when running drone from deb - 0.3.0-alpha-1423116857 On drone installed via deb on an ubuntu 14.10 machine, deb version 0.3.0-alpha-1423116857, visiting the site results to:  2015/02/05 10:30:53 http: panic serving 127.0.0.1:40439: read /usr/local/bin/droned: bad file descriptor goroutine 36 [running]: net/http.func011() /usr/local/go/src/pkg/net/http/server.go:1100 +0xb7 runtime.panic(0xa997c0, 0xc20809b500) /usr/local/go/src/pkg/runtime/panic.c:248 +0x18d github.com/GeertJohan/go%2erice.(*Box).MustBytes(0xc208111a10, 0xbf7090, 0xa, 0x0, 0x0, 0x0) /var/cache/drone/src/github.com/GeertJohan/go.rice/box.go:298 +0xc0 main.func001(0x7f40b6d7ba10, 0xc208044c80, 0xc208108820) /var/cache/drone/src/github.com/drone/drone/server/main.go:133 +0x3d net/http.HandlerFunc.ServeHTTP(0xc2080362a0, 0x7f40b6d7ba10, 0xc208044c80, 0xc208108820) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 net/http.(*ServeMux).ServeHTTP(0xc208022930, 0x7f40b6d7ba10, 0xc208044c80, 0xc208108820) /usr/local/go/src/pkg/net/http/server.go:1511 +0x1a3 net/http.serverHandler.ServeHTTP(0xc208005c20, 0x7f40b6d7ba10, 0xc208044c80, 0xc208108820) /usr/local/go/src/pkg/net/http/server.go:1673 +0x19f net/http.(*conn).serve(0xc208050980) /usr/local/go/src/pkg/net/http/server.go:1174 +0xa7e created by net/http.(*Server).Serve /usr/local/go/src/pkg/net/http/server.go:1721 +0x313  The same machine used to run an older 0.3.0 alpha just fine. Also tried it on a new machine. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
554,harness,https://github.com/harness/harness/issues/554,Customize timeout before killing job?,"It appears that Drone is killing my very long-running tests. As a major incentive for using drone running on my own server was the ability to run CI test suites that would take more than 50 minutes to execute, it's rather disappointing to see Drone kill them anyway (if that is indeed what is going on -- the log is not very informative so I suppose other errors may be possible, all I see is `/usr/local/bin/drone: line 42: 321 Killed`) Do we / could we have some way to toggle the time a job is allowed to run before being killed?",documentation-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file,"Customize timeout before killing job? It appears that Drone is killing my very long-running tests. As a major incentive for using drone running on my own server was the ability to run CI test suites that would take more than 50 minutes to execute, it's rather disappointing to see Drone kill them anyway (if that is indeed what is going on -- the log is not very informative so I suppose other errors may be possible, all I see is `/usr/local/bin/drone: line 42: 321 Killed`) Do we / could we have some way to toggle the time a job is allowed to run before being killed? documentation-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file",no-bug,0.9
245,harness,https://github.com/harness/harness/issues/245,Support Private Docker images,"This is the error when trying to use a docker image from a private repository. Not sure if this is supported by drone. If not, please support it :) If yes, please include instructions in the wiki/readme about how to set-up authentication against private docker image repositories.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file,"Support Private Docker images This is the error when trying to use a docker image from a private repository. Not sure if this is supported by drone. If not, please support it :) If yes, please include instructions in the wiki/readme about how to set-up authentication against private docker image repositories. source-file source-file source-file source-file source-file source-file source-file source-file test-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file",no-bug,0.9
3289,harness,https://github.com/harness/harness/issues/3289,drone-docker generate invalid Card URL for self-hosted docker registry,"<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> Not sure if it is the correct place to ask, but since [drone-docker](https://github.com/drone-plugins/drone-docker) does not allow filing issues, I will post my issue here. https://github.com/drone-plugins/drone-docker/blob/7888a798b1b331bd9c5a2662e50494f907499f2c/card.go#L75-L88 The `mapRegistryToURL` function uses a simple heuristic to generate URLs for common public registries. But a self-hosted registry using [distribution](https://github.com/distribution/distribution) or [Gitea](https://github.com/gitea-go/gitea) will be mapped to invalid URLs. It's desirable to have a general config entry to allow custom mapping using regex substitution mechanism, e.g., with the following configuration bash DRONE_DOCKER_REGISTRY_MATCH=<REGEXP> # Match and capture DRONE_DOCKER_REGISTRY_REPLACEMENT=<REPLACEMENT>  similar to a simplified version of Prometheus' [relabeling](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config) config. Or a configuration entry based on template string (if general enough).",source-file | source-file,"drone-docker generate invalid Card URL for self-hosted docker registry <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> Not sure if it is the correct place to ask, but since [drone-docker](https://github.com/drone-plugins/drone-docker) does not allow filing issues, I will post my issue here. https://github.com/drone-plugins/drone-docker/blob/7888a798b1b331bd9c5a2662e50494f907499f2c/card.go#L75-L88 The `mapRegistryToURL` function uses a simple heuristic to generate URLs for common public registries. But a self-hosted registry using [distribution](https://github.com/distribution/distribution) or [Gitea](https://github.com/gitea-go/gitea) will be mapped to invalid URLs. It's desirable to have a general config entry to allow custom mapping using regex substitution mechanism, e.g., with the following configuration bash DRONE_DOCKER_REGISTRY_MATCH=<REGEXP> # Match and capture DRONE_DOCKER_REGISTRY_REPLACEMENT=<REPLACEMENT>  similar to a simplified version of Prometheus' [relabeling](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config) config. Or a configuration entry based on template string (if general enough). source-file source-file",no-bug,0.9
200,harness,https://github.com/harness/harness/issues/200,Notification Plugin - Slack,Slack looks awesome. First can someone get me an invite? https://slack.com/ We definitely need a plugin for this,source-file | source-file,Notification Plugin - Slack Slack looks awesome. First can someone get me an invite? https://slack.com/ We definitely need a plugin for this source-file source-file,no-bug,0.95
2066,harness,https://github.com/harness/harness/issues/2066,Configurable Session/Token Timeout,"We recently upgraded to Drone 0.7 and are generally happy with the improvements, but an issue still remains: The session token expiration seems to be hardcoded at 72 hours in two places: https://github.com/drone/drone/blob/240f2a8ec520003a6c7a66a7236a742d4d665a06/server/login.go#L103 https://github.com/drone/drone/blob/240f2a8ec520003a6c7a66a7236a742d4d665a06/server/login.go#L143 As a drone admin, I often get complaints from developers that they find themselves logged out when clicking on a Drone status link going to Drone in our slack etc. An acceptable way to address this would be to offer an ENV variable to specify the number of expiration hours. Apparently, such an option existed at one point, as referenced in https://github.com/drone/drone/issues/609#issuecomment-60192587",test-file | test-file | test-file | source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file,"Configurable Session/Token Timeout We recently upgraded to Drone 0.7 and are generally happy with the improvements, but an issue still remains: The session token expiration seems to be hardcoded at 72 hours in two places: https://github.com/drone/drone/blob/240f2a8ec520003a6c7a66a7236a742d4d665a06/server/login.go#L103 https://github.com/drone/drone/blob/240f2a8ec520003a6c7a66a7236a742d4d665a06/server/login.go#L143 As a drone admin, I often get complaints from developers that they find themselves logged out when clicking on a Drone status link going to Drone in our slack etc. An acceptable way to address this would be to offer an ENV variable to specify the number of expiration hours. Apparently, such an option existed at one point, as referenced in https://github.com/drone/drone/issues/609#issuecomment-60192587 test-file test-file test-file source-file documentation-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file",no-bug,0.9
2086,harness,https://github.com/harness/harness/issues/2086,"Add support for ""Cron Jobs""","Like in Travis CI, it would be a good idea that you can set periodics builds without make changes in repository.",test-file | other-file,"Add support for ""Cron Jobs"" Like in Travis CI, it would be a good idea that you can set periodics builds without make changes in repository. test-file other-file",no-bug,0.9
284,harness,https://github.com/harness/harness/issues/284,'Could not find remote branch __ to clone',"My Drone deployment (which is master `0.2-d7d4ae9`) has had the behavior from day 1 of: - User forks my package on Github - User creates topic branch `feature_x` where `feature_x` is not an existing branch on origin - User creates pull request - Drone build fails to clone the repo and fails, as in [this build](http://ci.serversaurus.com/github.com/alexzorin/libvirt-go/commit/1a87af19b55362292a1f5b91d857b221caa69c4f?branch=volume_1) Specifically:  warning: Could not find remote branch volume_1 to clone. fatal: Remote branch volume_1 not found in upstream origin  Now, if you look at [this build from beta.drone.io](http://beta.drone.io/github.com/drone/drone/commit/97bb6baf5ac9257cc0598a5d01866120e9810fb4), its output makes more sense:  warning: Remote branch privileged-builds not found in upstream origin, using HEAD instead  i.e the missing branch on the origin is not fatal. Is anybody able to account for the difference in behavior? I thought it might have been me using an outdated ~~Github~~ drone release, but building from `master` results in the same behavior.",source-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | other-file | source-file | other-file | other-file,"'Could not find remote branch __ to clone' My Drone deployment (which is master `0.2-d7d4ae9`) has had the behavior from day 1 of: - User forks my package on Github - User creates topic branch `feature_x` where `feature_x` is not an existing branch on origin - User creates pull request - Drone build fails to clone the repo and fails, as in [this build](http://ci.serversaurus.com/github.com/alexzorin/libvirt-go/commit/1a87af19b55362292a1f5b91d857b221caa69c4f?branch=volume_1) Specifically:  warning: Could not find remote branch volume_1 to clone. fatal: Remote branch volume_1 not found in upstream origin  Now, if you look at [this build from beta.drone.io](http://beta.drone.io/github.com/drone/drone/commit/97bb6baf5ac9257cc0598a5d01866120e9810fb4), its output makes more sense:  warning: Remote branch privileged-builds not found in upstream origin, using HEAD instead  i.e the missing branch on the origin is not fatal. Is anybody able to account for the difference in behavior? I thought it might have been me using an outdated ~~Github~~ drone release, but building from `master` results in the same behavior. source-file source-file source-file test-file source-file test-file source-file test-file source-file other-file source-file other-file other-file",no-bug,0.9
687,harness,https://github.com/harness/harness/issues/687,database: mariadb,"I miss mariadb in the list of supported DBS to be launched [README.md#databases](https://github.com/drone/drone/blob/v0.2.1/README.md#databases). Sounds like popular one, these days.",other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | source-file | documentation-file,"database: mariadb I miss mariadb in the list of supported DBS to be launched [README.md#databases](https://github.com/drone/drone/blob/v0.2.1/README.md#databases). Sounds like popular one, these days. other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file source-file documentation-file",no-bug,0.9
331,harness,https://github.com/harness/harness/issues/331,Does `drone build` respect the notify setting?,"I'm using Drone `v0.2-0d25dc1`. From a project directory, I did a `drone -v build`. I am not able to get a notification through any channel (tried email, Slack and webhook) although I can see the Docker container being built and my tests running (and passing).   Drone Build Results (1)  (Less than a second)  This is how my `.drone.yml` file looks:  image: ubuntu script: - bash script.sh notify: webhook: on_success: true on_failure: true urls: - http://localhost:8080  Wasn't sure if I'm doing something wrong or the CLI just does not support this for now.",source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | documentation-file | other-file | other-file | other-file | source-file,"Does `drone build` respect the notify setting? I'm using Drone `v0.2-0d25dc1`. From a project directory, I did a `drone -v build`. I am not able to get a notification through any channel (tried email, Slack and webhook) although I can see the Docker container being built and my tests running (and passing).   Drone Build Results (1)  (Less than a second)  This is how my `.drone.yml` file looks:  image: ubuntu script: - bash script.sh notify: webhook: on_success: true on_failure: true urls: - http://localhost:8080  Wasn't sure if I'm doing something wrong or the CLI just does not support this for now. source-file other-file source-file other-file other-file other-file other-file other-file source-file documentation-file other-file other-file other-file source-file other-file other-file source-file other-file other-file documentation-file other-file other-file other-file source-file",no-bug,0.8
869,harness,https://github.com/harness/harness/issues/869,Remove Socat for local access to service containers,"Ideally we could have a fallback when `socat` is not installed. My idea is to inject a perl script in the container when `socat` isn't available that is capable of proxying connections. Why choose Perl? It is the only scripting language included in the default Ubuntu and Debian containers. I found the an proxy Perl script here: https://github.com/pkrumins/perl-tcp-proxy/blob/master/tcp-proxy.pl I adjusted the below example to work with Redis:  perl #!/usr/bin/perl use warnings; use strict; use IO::Socket; use IO::Select; my $ioset = IO::Select->new; my %socket_map; my $debug = 1; sub new_conn { my ($host, $port) = @_; return IO::Socket::INET->new( PeerAddr => $host, PeerPort => $port ) || die ""Unable to connect to $host:$port: $!""; } sub new_server { my ($host, $port) = @_; my $server = IO::Socket::INET->new( LocalAddr => $host, LocalPort => $port, ReuseAddr => 1, Listen => 100 ) || die ""Unable to listen on $host:$port: $!""; } sub new_connection { my $server = shift; my $client = $server->accept; my $remote = new_conn($ENV{""REDIS_PORT_6379_TCP_ADDR""}, $ENV{REDIS_PORT_6379_TCP_PORT}); $ioset->add($client); $ioset->add($remote); $socket_map{$client} = $remote; $socket_map{$remote} = $client; } sub close_connection { my $client = shift; my $remote = $socket_map{$client}; $ioset->remove($client); $ioset->remove($remote); delete $socket_map{$client}; delete $socket_map{$remote}; $client->close; $remote->close; } my $server = new_server('0.0.0.0', $ENV{REDIS_PORT_6379_TCP_PORT}); $ioset->add($server); while (1) { for my $socket ($ioset->can_read) { if ($socket == $server) { new_connection($server); } else { next unless exists $socket_map{$socket}; my $remote = $socket_map{$socket}; my $buffer; my $read = $socket->sysread($buffer, 4096); if ($read) { $remote->syswrite($buffer); } else { close_connection($socket); } } } }  So how would this work? We would embed the perl script in our `build.sh` file and write that file from inside the container. It could look something like this:  echo IyEvdXNyL2Jpbi9wZXJsCnByaW50ICJoZWxsbyB3b3JsZCIKCg== | base64 -d > /tmp/drone-proxy  We could then invoke with `/tmp/drone-proxy $IP $PORT` as an alternative to `socat`. It may seem a bit strange to embed the file in the `build.sh` script, but this is because when #749 is implemented we won't be able to inject files into the container any other way.",config-file | other-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | test-file,"Remove Socat for local access to service containers Ideally we could have a fallback when `socat` is not installed. My idea is to inject a perl script in the container when `socat` isn't available that is capable of proxying connections. Why choose Perl? It is the only scripting language included in the default Ubuntu and Debian containers. I found the an proxy Perl script here: https://github.com/pkrumins/perl-tcp-proxy/blob/master/tcp-proxy.pl I adjusted the below example to work with Redis:  perl #!/usr/bin/perl use warnings; use strict; use IO::Socket; use IO::Select; my $ioset = IO::Select->new; my %socket_map; my $debug = 1; sub new_conn { my ($host, $port) = @_; return IO::Socket::INET->new( PeerAddr => $host, PeerPort => $port ) || die ""Unable to connect to $host:$port: $!""; } sub new_server { my ($host, $port) = @_; my $server = IO::Socket::INET->new( LocalAddr => $host, LocalPort => $port, ReuseAddr => 1, Listen => 100 ) || die ""Unable to listen on $host:$port: $!""; } sub new_connection { my $server = shift; my $client = $server->accept; my $remote = new_conn($ENV{""REDIS_PORT_6379_TCP_ADDR""}, $ENV{REDIS_PORT_6379_TCP_PORT}); $ioset->add($client); $ioset->add($remote); $socket_map{$client} = $remote; $socket_map{$remote} = $client; } sub close_connection { my $client = shift; my $remote = $socket_map{$client}; $ioset->remove($client); $ioset->remove($remote); delete $socket_map{$client}; delete $socket_map{$remote}; $client->close; $remote->close; } my $server = new_server('0.0.0.0', $ENV{REDIS_PORT_6379_TCP_PORT}); $ioset->add($server); while (1) { for my $socket ($ioset->can_read) { if ($socket == $server) { new_connection($server); } else { next unless exists $socket_map{$socket}; my $remote = $socket_map{$socket}; my $buffer; my $read = $socket->sysread($buffer, 4096); if ($read) { $remote->syswrite($buffer); } else { close_connection($socket); } } } }  So how would this work? We would embed the perl script in our `build.sh` file and write that file from inside the container. It could look something like this:  echo IyEvdXNyL2Jpbi9wZXJsCnByaW50ICJoZWxsbyB3b3JsZCIKCg== | base64 -d > /tmp/drone-proxy  We could then invoke with `/tmp/drone-proxy $IP $PORT` as an alternative to `socat`. It may seem a bit strange to embed the file in the `build.sh` script, but this is because when #749 is implemented we won't be able to inject files into the container any other way. config-file other-file source-file test-file source-file test-file source-file test-file source-file test-file",no-bug,0.9
190,harness,https://github.com/harness/harness/issues/190,Push fixed Elastic Search images to Index,Using Tire in a Rails app. It requires access to port 9200. This is my `tire.yml`.  test: url: http://127.0.0.1:9200  Am I doing anything wrong?,other-file | other-file,Push fixed Elastic Search images to Index Using Tire in a Rails app. It requires access to port 9200. This is my `tire.yml`.  test: url: http://127.0.0.1:9200  Am I doing anything wrong? other-file other-file,no-bug,0.9
1184,harness,https://github.com/harness/harness/issues/1184,github `orgs` restriction not letting people in,"After disabling self-registration, I updated to  GITHUB_ORGS=""ensime,fommil"" REMOTE_CONFIG=""https://github.com?client_id=$CLIENT&client_secret=$SECRET&orgs=$GITHUB_ORGS&open=false""  (of which one is me and I am an owner of `ensime`) but when I log in, I see this  Login is restricted to approved organization members only  so I'm guessing org restriction is currently not working.",documentation-file | documentation-file | source-file,"github `orgs` restriction not letting people in After disabling self-registration, I updated to  GITHUB_ORGS=""ensime,fommil"" REMOTE_CONFIG=""https://github.com?client_id=$CLIENT&client_secret=$SECRET&orgs=$GITHUB_ORGS&open=false""  (of which one is me and I am an owner of `ensime`) but when I log in, I see this  Login is restricted to approved organization members only  so I'm guessing org restriction is currently not working. documentation-file documentation-file source-file",bug,0.85
1128,harness,https://github.com/harness/harness/issues/1128,Retry logic if a worker is down,"When you add multiple Docker daemons from multiple hosts, if one of the hosts drop out you end up with a 1/n build failures due to time out. It would be ideal, if there were retry logic after the time out to drop the build back on the queue. Additional optimization would be to keep track of workers that are unresponsive and eject them from the pool. Just to save on build startup time.",source-file | source-file | source-file | source-file | source-file,"Retry logic if a worker is down When you add multiple Docker daemons from multiple hosts, if one of the hosts drop out you end up with a 1/n build failures due to time out. It would be ideal, if there were retry logic after the time out to drop the build back on the queue. Additional optimization would be to keep track of workers that are unresponsive and eject them from the pool. Just to save on build startup time. source-file source-file source-file source-file source-file",no-bug,0.9
393,harness,https://github.com/harness/harness/issues/393,support for environment variables in s3 publish,would be cool if you could set the target to something like: `target: builds/{{DRONE_REPO_SLUG}}/{{DRONE_COMMIT}}`,other-file,support for environment variables in s3 publish would be cool if you could set the target to something like: `target: builds/{{DRONE_REPO_SLUG}}/{{DRONE_COMMIT}}` other-file,no-bug,0.9
1127,harness,https://github.com/harness/harness/issues/1127,Cache bind mounts fail in case repo url contains a colon (e.g. url:port),"bind mounts for cache dirs currently fail to work in case the repository url contains a colon (see https://github.com/docker/docker/issues/8604) e.g. '10.0.0.1:10080/user/app' `docker inspect drone-container` gives the following output:  [] ""VolumesRW"": { ""/tmp/bundle"": true, ""10080/user/app/tmp/bundle"": false } []  This should probably be handled by docker itself, it would still be nice if one could override the default host path set by drone",other-file,"Cache bind mounts fail in case repo url contains a colon (e.g. url:port) bind mounts for cache dirs currently fail to work in case the repository url contains a colon (see https://github.com/docker/docker/issues/8604) e.g. '10.0.0.1:10080/user/app' `docker inspect drone-container` gives the following output:  [] ""VolumesRW"": { ""/tmp/bundle"": true, ""10080/user/app/tmp/bundle"": false } []  This should probably be handled by docker itself, it would still be nice if one could override the default host path set by drone other-file",no-bug,0.9
2887,harness,https://github.com/harness/harness/issues/2887,RFC: Service detach until,"Graph Execution is awesome! What about add limit for service execution? For example i need database and other infrastructure only for testing, but testing is not end of pipeline. I want to free resource immediately as it no more necessary. yaml  kind: pipeline type: docker name: default steps: - name: database image: mariadb detach: until: - unit - e2e - name: install image: node commands: - npm install - name: unit image: node commands: - npm test - name: e2e image: node commands: - npm e2e - name: build / push / deploy / notify / something else  ",source-file,"RFC: Service detach until Graph Execution is awesome! What about add limit for service execution? For example i need database and other infrastructure only for testing, but testing is not end of pipeline. I want to free resource immediately as it no more necessary. yaml  kind: pipeline type: docker name: default steps: - name: database image: mariadb detach: until: - unit - e2e - name: install image: node commands: - npm install - name: unit image: node commands: - npm test - name: e2e image: node commands: - npm e2e - name: build / push / deploy / notify / something else   source-file",no-bug,0.9
317,harness,https://github.com/harness/harness/issues/317,Plugin for Perceptual Diffing,It would be cool if drone.io had perceptual diffing support. Perceptual diffing is the act of diffing two rendered user interfaces to check if there are any differences that shouldn't be there. Here are some resources: - http://mattjibson.com/blog/2013/06/11/perceptual-diffs-at-stack-overflow/ - https://github.com/bslatkin/dpxdt,source-file | documentation-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file,Plugin for Perceptual Diffing It would be cool if drone.io had perceptual diffing support. Perceptual diffing is the act of diffing two rendered user interfaces to check if there are any differences that shouldn't be there. Here are some resources: - http://mattjibson.com/blog/2013/06/11/perceptual-diffs-at-stack-overflow/ - https://github.com/bslatkin/dpxdt source-file documentation-file other-file other-file other-file source-file other-file other-file other-file source-file,no-bug,0.9
969,harness,https://github.com/harness/harness/issues/969,Database: Refactor utility functions to leverage BoltDB wrappers,"The current utility functions could be refactored to take a `*bolt.Tx` instead of `*DB`. This would allow them to be used directly with BoltDB's convenience functions. An example implementation might look like: (from https://github.com/drone/drone/pull/968#issuecomment-91615322)  go func (db *DB) InsertBuild(repo string, build *Build) error { return db.Update(func(tx *bolt.Tx) error { err := get(t, bucket, key, v) if err != nil { return err } insert(t, bucket, key, v) if err != nil { return err } return nil }) } func insert(t *bolt.Tx, bucket, key []byte, v interface{}) error {  } ",source-file | source-file | test-file | test-file | test-file,"Database: Refactor utility functions to leverage BoltDB wrappers The current utility functions could be refactored to take a `*bolt.Tx` instead of `*DB`. This would allow them to be used directly with BoltDB's convenience functions. An example implementation might look like: (from https://github.com/drone/drone/pull/968#issuecomment-91615322)  go func (db *DB) InsertBuild(repo string, build *Build) error { return db.Update(func(tx *bolt.Tx) error { err := get(t, bucket, key, v) if err != nil { return err } insert(t, bucket, key, v) if err != nil { return err } return nil }) } func insert(t *bolt.Tx, bucket, key []byte, v interface{}) error {  }  source-file source-file test-file test-file test-file",no-bug,0.9
27,harness,https://github.com/harness/harness/issues/27,Question: What's the reason for not using a web framework?,"Simply out of curiosity, what was the reason you chose not to go with one of the golang web frameworks?",other-file | other-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | config-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,"Question: What's the reason for not using a web framework? Simply out of curiosity, what was the reason you chose not to go with one of the golang web frameworks? other-file other-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file config-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file",no-bug,0.95
274,harness,https://github.com/harness/harness/issues/274,Gmail threading of email notifications,"I don't know if anyone else is having this problem, but Gmail merges all build notifications (from all branches and for successes and failures) from drone into the same conversation thread which can make it difficult to read. I know this is an issue with gmail, but could we change the subject of the message to fix this? I've found that adding a timestamp to the end of the build notification stops gmail from merging build notifications. Something like:  go msg.Subject = ""[FAILURE] "" + repo + "" "" + Time.now().Format(time.UnixDate) ",other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file,"Gmail threading of email notifications I don't know if anyone else is having this problem, but Gmail merges all build notifications (from all branches and for successes and failures) from drone into the same conversation thread which can make it difficult to read. I know this is an issue with gmail, but could we change the subject of the message to fix this? I've found that adding a timestamp to the end of the build notification stops gmail from merging build notifications. Something like:  go msg.Subject = ""[FAILURE] "" + repo + "" "" + Time.now().Format(time.UnixDate)  other-file other-file source-file other-file other-file other-file source-file other-file other-file source-file documentation-file other-file source-file other-file other-file source-file other-file source-file",no-bug,0.9
500,harness,https://github.com/harness/harness/issues/500,Login page improvements,"When the user enters the wrong password, persisting the email address would be good UX. I am not sure how easy it is to do, since the page seems to refresh. The login could be an XHR request which would again improve UX..",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Login page improvements When the user enters the wrong password, persisting the email address would be good UX. I am not sure how easy it is to do, since the page seems to refresh. The login could be an XHR request which would again improve UX.. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
1034,harness,https://github.com/harness/harness/issues/1034,any way to get the commit message as a variable to use in build scripts ?,,source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file,any way to get the commit message as a variable to use in build scripts ?  source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file,no-bug,0.9
2128,harness,https://github.com/harness/harness/issues/2128,[Docs Request] Automation of Drone.io Environments,"A lot of the work I've been doing lately involves automating the creation and deployment of Drone.io itself, and then the deployment of apps with Drone.io. In turn, I'd like to contribute a section on ways to automate the creation and deployment of Drone.io. Specifically, deployment via tooling like Terraform or even creation of settings, users, or other elements of Drone.io once Terraform has created and environment for and with Drone.io. ## Topics Would Include: * Deploying Drone.io with Terraform in GCP/AWS/Azure (where to find details, what steps to take, various options, etc) * Deploying Drone.io User Accounts, Repositories, etc via Terraform. * Deploying Drone.io Builds for Repositories based on  X Y Z topic TBD.",source-file | source-file | source-file | source-file | source-file,"[Docs Request] Automation of Drone.io Environments A lot of the work I've been doing lately involves automating the creation and deployment of Drone.io itself, and then the deployment of apps with Drone.io. In turn, I'd like to contribute a section on ways to automate the creation and deployment of Drone.io. Specifically, deployment via tooling like Terraform or even creation of settings, users, or other elements of Drone.io once Terraform has created and environment for and with Drone.io. ## Topics Would Include: * Deploying Drone.io with Terraform in GCP/AWS/Azure (where to find details, what steps to take, various options, etc) * Deploying Drone.io User Accounts, Repositories, etc via Terraform. * Deploying Drone.io Builds for Repositories based on  X Y Z topic TBD. source-file source-file source-file source-file source-file",no-bug,0.95
2843,harness,https://github.com/harness/harness/issues/2843,Improve linking to resources in the remote repository,deep links in the user interface are unreliable and do not always link to the desired resource in the source control management system. In many cases they are github specific. the solution to this issue will be to handle the redirects server-side and generate the redirect links on the fly. We have updated the `go-scm` library to include some helper functions to generate deep links for the different providers.,source-file,Improve linking to resources in the remote repository deep links in the user interface are unreliable and do not always link to the desired resource in the source control management system. In many cases they are github specific. the solution to this issue will be to handle the redirects server-side and generate the redirect links on the fly. We have updated the `go-scm` library to include some helper functions to generate deep links for the different providers. source-file,no-bug,0.9
403,harness,https://github.com/harness/harness/issues/403,"0.3 Release, Re-add GitHub status API",this was temporarily commented out. Needs to be re-added to the `server/worker` package,source-file | source-file | source-file | source-file | documentation-file | source-file | config-file | other-file | other-file | source-file | other-file | other-file,"0.3 Release, Re-add GitHub status API this was temporarily commented out. Needs to be re-added to the `server/worker` package source-file source-file source-file source-file documentation-file source-file config-file other-file other-file source-file other-file other-file",no-bug,0.8
3460,harness,https://github.com/harness/harness/issues/3460,[BUG] Always redirect to signin page.,"I depoly a instance with docker with this:  sudo docker run -d \ -e GITNESS_HTTP_PROTO=https \ -e GITNESS_URL_BASE=https://gitness.company.com \ -e GITNESS_DATABASE_DRIVER=postgres \ -e GITNESS_DATABASE_DATASOURCE=""host=1.2.3.4 port=5678 sslmode=disable dbname=gitness user=$USER password=$PASSWORD"" \ -e GITNESS_PRINCIPAL_ADMIN_EMAIL=mail@example.com \ -e GITNESS_PRINCIPAL_ADMIN_PASSWORD=correct-horse-battery-staple \ -e GITNESS_USER_SIGNUP_ENABLED=false \ -p 3000:3000 \ -v /var/run/docker.sock:/var/run/docker.sock \ -v $HOME/gitness:/data \ --name gitness \ --restart always \ harness/gitness  I can access the deployed instance normally, but when I log in with an administrator account, I am always redirected to the signin page, which is completely unusable.",source-file | source-file,"[BUG] Always redirect to signin page. I depoly a instance with docker with this:  sudo docker run -d \ -e GITNESS_HTTP_PROTO=https \ -e GITNESS_URL_BASE=https://gitness.company.com \ -e GITNESS_DATABASE_DRIVER=postgres \ -e GITNESS_DATABASE_DATASOURCE=""host=1.2.3.4 port=5678 sslmode=disable dbname=gitness user=$USER password=$PASSWORD"" \ -e GITNESS_PRINCIPAL_ADMIN_EMAIL=mail@example.com \ -e GITNESS_PRINCIPAL_ADMIN_PASSWORD=correct-horse-battery-staple \ -e GITNESS_USER_SIGNUP_ENABLED=false \ -p 3000:3000 \ -v /var/run/docker.sock:/var/run/docker.sock \ -v $HOME/gitness:/data \ --name gitness \ --restart always \ harness/gitness  I can access the deployed instance normally, but when I log in with an administrator account, I am always redirected to the signin page, which is completely unusable. source-file source-file",no-bug,0.8
839,harness,https://github.com/harness/harness/issues/839,Services do not operate correctly when docker net host option is specified,"The addition of `--net` in #617 is awesome, I need it, but I may have found a bug - I don't have bandwidth to test this one out at the moment though The implementation of `services` looks to rely on Docker Links https://github.com/drone/drone/blob/0a6227930dce3e356667506bc950530a9d847c61/shared/build/build.go#L346 Links and `--net=host` are not supported https://github.com/docker/docker/pull/7066 A possible workaround might be to run service containers in `--net=host` but you might run in to port conflict issues if you are, for example, using postgres as the backend for your Drone install and attempting to run a postgres service.",source-file | source-file | source-file | source-file | source-file | source-file,"Services do not operate correctly when docker net host option is specified The addition of `--net` in #617 is awesome, I need it, but I may have found a bug - I don't have bandwidth to test this one out at the moment though The implementation of `services` looks to rely on Docker Links https://github.com/drone/drone/blob/0a6227930dce3e356667506bc950530a9d847c61/shared/build/build.go#L346 Links and `--net=host` are not supported https://github.com/docker/docker/pull/7066 A possible workaround might be to run service containers in `--net=host` but you might run in to port conflict issues if you are, for example, using postgres as the backend for your Drone install and attempting to run a postgres service. source-file source-file source-file source-file source-file source-file",no-bug,0.9
2764,harness,https://github.com/harness/harness/issues/2764,server agent mode always in pending,"drone 1.21 drone-server version: ""2"" services: server: image: drone/drone:latest environment: - DRONE_GITEA_SERVER=http://192.168.16.77:3000 - DRONE_GIT_ALWAYS_AUTH=false - DRONE_RUNNER_CAPACITY =2 - DRONE_SERVER_HOST=192.168.16.77 - DRONE_SERVER_PROTO=http - DRONE_TLS_AUTOCERT=false - DRONE_USER_CREATE=username:root,admin:true - DRONE_MACHINE=192.168.16.77 - DRONE_LOGS_DEBUG=true - DRONE_LOGS_PRETTY=false - DRONE_LOGS_NOCOLOR=false - DRONE_DATABASE_DRIVER=mysql - DRONE_DATABASE_DATASOURCE=root:Mm123456@tcp(192.168.25.154:3306)/drone?parseTime=true - DRONE_AGENTS_ENABLED=true - DRONE_RPC_SECRET=40c297ad6590ecf64d02313dd7b31728 restart: always network_mode: ""bridge"" volumes: - /var/run/docker.sock:/var/run/docker.sock - ./drone:/data ports: - ""80:80"" - ""443:443"" drone-agent: version: ""2"" services: drone-agent: image: drone/agent:latest environment: - DRONE_RPC_SERVER=http://192.168.16.77 - DRONE_RPC_SECRET=40c297ad6590ecf64d02313dd7b31728 - DRONE_RUNNER_CAPACITY=2 - DRONE_MACHINE=192.168.16.77 - DRONE_RUNNER_NAME=hoc154 - DRONE_RUNNER_LABELS=disk:ssd,memory:high - DRONE_LOGS_DEBUG=true - DRONE_LOGS_PRETTY=false - DRONE_LOGS_NOCOLOR=false restart: always network_mode: ""bridge"" volumes: - /var/run/docker.sock:/var/run/docker.sock drone-agent-log: drone-agent_1 | {""level"":""debug"",""msg"":""successfully pinged the docker daemon"",""time"":""2019-07-18T16:34:35Z""} drone-agent_1 | {""arch"":""amd64"",""level"":""debug"",""machine"":""hoc154"",""msg"":""runner: polling queue"",""os"":""linux"",""time"":""2019-07-18T16:34:35Z""} drone-agent_1 | {""arch"":""amd64"",""level"":""debug"",""machine"":""hoc154"",""msg"":""runner: polling queue"",""os"":""linux"",""time"":""2019-07-18T16:34:35Z""} drone-server-log: server_1 | {""arch"":""amd64"",""kernel"":"""",""kind"":""pipeline"",""level"":""debug"",""msg"":""manager: request queue item"",""os"":""linux"",""time"":""2019-07-18T16:37:51Z"",""type"":""docker"",""variant"":""""} server_1 | {""arch"":""amd64"",""kernel"":"""",""kind"":""pipeline"",""level"":""debug"",""msg"":""manager: request queue item"",""os"":""linux"",""time"":""2019-07-18T16:37:51Z"",""type"":""docker"",""variant"":""""} and I found the mysql nodes table is empty? .drone.yml kind: pipeline name: dubhe-ci/cd steps: - name: build image: node/v10.16.0 commands: - npm install - npm test node: instance: disk drone-ci always in pending,an do nothing ",other-file | source-file | other-file | other-file | other-file,"server agent mode always in pending drone 1.21 drone-server version: ""2"" services: server: image: drone/drone:latest environment: - DRONE_GITEA_SERVER=http://192.168.16.77:3000 - DRONE_GIT_ALWAYS_AUTH=false - DRONE_RUNNER_CAPACITY =2 - DRONE_SERVER_HOST=192.168.16.77 - DRONE_SERVER_PROTO=http - DRONE_TLS_AUTOCERT=false - DRONE_USER_CREATE=username:root,admin:true - DRONE_MACHINE=192.168.16.77 - DRONE_LOGS_DEBUG=true - DRONE_LOGS_PRETTY=false - DRONE_LOGS_NOCOLOR=false - DRONE_DATABASE_DRIVER=mysql - DRONE_DATABASE_DATASOURCE=root:Mm123456@tcp(192.168.25.154:3306)/drone?parseTime=true - DRONE_AGENTS_ENABLED=true - DRONE_RPC_SECRET=40c297ad6590ecf64d02313dd7b31728 restart: always network_mode: ""bridge"" volumes: - /var/run/docker.sock:/var/run/docker.sock - ./drone:/data ports: - ""80:80"" - ""443:443"" drone-agent: version: ""2"" services: drone-agent: image: drone/agent:latest environment: - DRONE_RPC_SERVER=http://192.168.16.77 - DRONE_RPC_SECRET=40c297ad6590ecf64d02313dd7b31728 - DRONE_RUNNER_CAPACITY=2 - DRONE_MACHINE=192.168.16.77 - DRONE_RUNNER_NAME=hoc154 - DRONE_RUNNER_LABELS=disk:ssd,memory:high - DRONE_LOGS_DEBUG=true - DRONE_LOGS_PRETTY=false - DRONE_LOGS_NOCOLOR=false restart: always network_mode: ""bridge"" volumes: - /var/run/docker.sock:/var/run/docker.sock drone-agent-log: drone-agent_1 | {""level"":""debug"",""msg"":""successfully pinged the docker daemon"",""time"":""2019-07-18T16:34:35Z""} drone-agent_1 | {""arch"":""amd64"",""level"":""debug"",""machine"":""hoc154"",""msg"":""runner: polling queue"",""os"":""linux"",""time"":""2019-07-18T16:34:35Z""} drone-agent_1 | {""arch"":""amd64"",""level"":""debug"",""machine"":""hoc154"",""msg"":""runner: polling queue"",""os"":""linux"",""time"":""2019-07-18T16:34:35Z""} drone-server-log: server_1 | {""arch"":""amd64"",""kernel"":"""",""kind"":""pipeline"",""level"":""debug"",""msg"":""manager: request queue item"",""os"":""linux"",""time"":""2019-07-18T16:37:51Z"",""type"":""docker"",""variant"":""""} server_1 | {""arch"":""amd64"",""kernel"":"""",""kind"":""pipeline"",""level"":""debug"",""msg"":""manager: request queue item"",""os"":""linux"",""time"":""2019-07-18T16:37:51Z"",""type"":""docker"",""variant"":""""} and I found the mysql nodes table is empty? .drone.yml kind: pipeline name: dubhe-ci/cd steps: - name: build image: node/v10.16.0 commands: - npm install - npm test node: instance: disk drone-ci always in pending,an do nothing  other-file source-file other-file other-file other-file",no-bug,0.8
576,harness,https://github.com/harness/harness/issues/576,Ability to grant admin privileges in UI,"Hi Brad, We just upgraded to the latest drone today. Looking great! I notice the Settings page is blank. I'm trying to figure out how to give other users Drone admin privs in the UI (so they can see settings and user administration). Is there a command-line method?",documentation-file,"Ability to grant admin privileges in UI Hi Brad, We just upgraded to the latest drone today. Looking great! I notice the Settings page is blank. I'm trying to figure out how to give other users Drone admin privs in the UI (so they can see settings and user administration). Is there a command-line method? documentation-file",no-bug,0.9
1649,harness,https://github.com/harness/harness/issues/1649,Error with Postgresql and Gogs,"On trying to use Drone with Gogs and Postgresql, authentication is successful but throws the error pq: syntax error at or near "")"" on logging in. This is with both latest and Drone 0.4. No error seen in logs. Gogs with Sqlite works perfectly fine. So I suspect something to do with the postgres DB driver issue",source-file | source-file | source-file | source-file | source-file | source-file,"Error with Postgresql and Gogs On trying to use Drone with Gogs and Postgresql, authentication is successful but throws the error pq: syntax error at or near "")"" on logging in. This is with both latest and Drone 0.4. No error seen in logs. Gogs with Sqlite works perfectly fine. So I suspect something to do with the postgres DB driver issue source-file source-file source-file source-file source-file source-file",no-bug,0.8
3306,harness,https://github.com/harness/harness/issues/3306,,,other-file | other-file | other-file | other-file | other-file,  other-file other-file other-file other-file other-file,no-bug,0.9
490,harness,https://github.com/harness/harness/issues/490,"Pull requests getting built after disabling ""Enable Pull Hooks"" flag","I unchecked that flag in the UI, but pull requests are still triggering builds. Is there something I'm missing? I couldn't see that flag been used anywhere in the code.",other-file | other-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | source-file | documentation-file | other-file | source-file | other-file | other-file | other-file,"Pull requests getting built after disabling ""Enable Pull Hooks"" flag I unchecked that flag in the UI, but pull requests are still triggering builds. Is there something I'm missing? I couldn't see that flag been used anywhere in the code. other-file other-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file other-file other-file other-file source-file documentation-file other-file source-file other-file other-file other-file",no-bug,0.9
2251,harness,https://github.com/harness/harness/issues/2251,/api/info/queue reports running_count > 0 when there are no running builds,"version 0.7.3+build.1139 I observe the following: /api/info/queue returns  { ""pending"": null, ""running"": [ { ""id"": ""191"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""171"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""199"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""183"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""203"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""195"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } } ], ""stats"": { ""worker_count"": 12, ""pending_count"": 0, ""running_count"": 6, ""completed_count"": 0 } }  Note `""running_count"": 6` But there are no builds, and /api/builds doesn't report any:  [] ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"/api/info/queue reports running_count > 0 when there are no running builds version 0.7.3+build.1139 I observe the following: /api/info/queue returns  { ""pending"": null, ""running"": [ { ""id"": ""191"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""171"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""199"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""183"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""203"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } }, { ""id"": ""195"", ""data"": """", ""labels"": { ""platform"": ""linux/amd64"" } } ], ""stats"": { ""worker_count"": 12, ""pending_count"": 0, ""running_count"": 6, ""completed_count"": 0 } }  Note `""running_count"": 6` But there are no builds, and /api/builds doesn't report any:  []  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.95
295,harness,https://github.com/harness/harness/issues/295,Deployment to github gh-pages branch,"I'll like to be able to deploy a branch or a subdirectory, directly to gh-pages branch on my github repository. Is it possible to add a simple mechanism in the deployment page?",source-file | documentation-file | other-file | source-file | source-file | source-file,"Deployment to github gh-pages branch I'll like to be able to deploy a branch or a subdirectory, directly to gh-pages branch on my github repository. Is it possible to add a simple mechanism in the deployment page? source-file documentation-file other-file source-file source-file source-file",no-bug,0.9
428,harness,https://github.com/harness/harness/issues/428,Can't access private github repository,"I have been fighting to create a single build the whole day. I followed all the guides vigorously without any success. I always get this message:  $ git clone --depth=50 --recursive --branch=master git@github.com:pithikos/myproject.git /var/cache/drone/src/github.com/pithikos/myproject Cloning into '/var/cache/drone/src/github.com/pithikos/myproject' Warning: Permanently added 'github.com,192.30.252.128' (RSA) to the list of known hosts. ERROR: Repository not found. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists.  From inside the server I can run the command (`git clone --depth=50 --recursive --branch=master git@github.com:pithikos/myproject.git /var/cache/drone/src/github.com/pithikos/myproject`) without problems. I assume that drone creates the container and then pulls the source from there. Thus there is no key so it can't pull. But in that case how do I solve this? Can't I set drone to get the source and mount it to the container instead?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | source-file | source-file | source-file | source-file,"Can't access private github repository I have been fighting to create a single build the whole day. I followed all the guides vigorously without any success. I always get this message:  $ git clone --depth=50 --recursive --branch=master git@github.com:pithikos/myproject.git /var/cache/drone/src/github.com/pithikos/myproject Cloning into '/var/cache/drone/src/github.com/pithikos/myproject' Warning: Permanently added 'github.com,192.30.252.128' (RSA) to the list of known hosts. ERROR: Repository not found. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists.  From inside the server I can run the command (`git clone --depth=50 --recursive --branch=master git@github.com:pithikos/myproject.git /var/cache/drone/src/github.com/pithikos/myproject`) without problems. I assume that drone creates the container and then pulls the source from there. Thus there is no key so it can't pull. But in that case how do I solve this? Can't I set drone to get the source and mount it to the container instead? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file source-file source-file source-file source-file",no-bug,0.95
977,harness,https://github.com/harness/harness/issues/977,reverse proxy nginx,The life update of the build views fails when used behind an nginx reverse proxy.,database-file | database-file | database-file | database-file,reverse proxy nginx The life update of the build views fails when used behind an nginx reverse proxy. database-file database-file database-file database-file,no-bug,0.7
3378,harness,https://github.com/harness/harness/issues/3378,Gitness on Docker with Network Macvlan,I tried to run gitness on a machine with docker and the network mode macvlan. This works with Drone 2: - Start the drone-server with: `docker run --name drone-server --net=macvlan_netname -t -d drone/drone` - Start the drone-runner-docker with: `docker run --name node01 --net=macvlan_netname -t -d -e DRONE_RUNNER_NETWORKS=macvlan_netname -v /var/run/docker.sock:/var/run/docker.sock drone/drone-runner-docker` Right now the clone failed because the clone step can not resolve http://host.docker.internal:3000. This is expected with the used network mode because macvlan allows container-to-container but not container-to-host communication. Drone allows this kind of setup via `DRONE_RUNNER_NETWORKS`. Is there a similar option within gitness to support macvlan?,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file,Gitness on Docker with Network Macvlan I tried to run gitness on a machine with docker and the network mode macvlan. This works with Drone 2: - Start the drone-server with: `docker run --name drone-server --net=macvlan_netname -t -d drone/drone` - Start the drone-runner-docker with: `docker run --name node01 --net=macvlan_netname -t -d -e DRONE_RUNNER_NETWORKS=macvlan_netname -v /var/run/docker.sock:/var/run/docker.sock drone/drone-runner-docker` Right now the clone failed because the clone step can not resolve http://host.docker.internal:3000. This is expected with the used network mode because macvlan allows container-to-container but not container-to-host communication. Drone allows this kind of setup via `DRONE_RUNNER_NETWORKS`. Is there a similar option within gitness to support macvlan? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file,no-bug,0.9
2548,harness,https://github.com/harness/harness/issues/2548,Migration script to 1.0 from 0.8,i was just checking if the migration script to 1.0 from 0.8 will be ready on November 16th of 2019 or what happened. Today is December 10th and it is not on the documentation. am i missing something?,other-file,Migration script to 1.0 from 0.8 i was just checking if the migration script to 1.0 from 0.8 will be ready on November 16th of 2019 or what happened. Today is December 10th and it is not on the documentation. am i missing something? other-file,no-bug,0.9
2202,harness,https://github.com/harness/harness/issues/2202,'workspace' section overrides base folder entirely,"Hey, I have a docker image with some folders under `/go` bash ls /go bin pkg src  If in my drone manifest I put the `workspace` section such: yml workspace: base: /go path: src/bitbucket.org/my/project  Then the `/go` folder gets overridden entirely and contains only the `/go/src` folder. bash ls /go src  Drone should not remove the folder rather put the workspace's path under the base folder. (If I remove the 'workspace' section everything work as expected) Thanks.",source-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file,"'workspace' section overrides base folder entirely Hey, I have a docker image with some folders under `/go` bash ls /go bin pkg src  If in my drone manifest I put the `workspace` section such: yml workspace: base: /go path: src/bitbucket.org/my/project  Then the `/go` folder gets overridden entirely and contains only the `/go/src` folder. bash ls /go src  Drone should not remove the folder rather put the workspace's path under the base folder. (If I remove the 'workspace' section everything work as expected) Thanks. source-file source-file source-file source-file config-file config-file source-file source-file",no-bug,0.9
438,harness,https://github.com/harness/harness/issues/438,Document private parameters & injection strategies,"Build progress output shows the command that is run after params are injected. Granted, I understand that if someone had access to your account or you left the page up and walked away from your desk a malicious person could click and view the list of params. I am talking more from the perspective when someone walks up to my desk I don't have to minimize the build status and worry they read the output and are going to cause mischief. I think it would be a good idea not to show this information. I am not familiar with Go, so I am not sure where this expansion happens in the code and how difficult it would be to show the command with {{vars}} before they are expanded. A quick/simple option would be to also make the params available as environment variables. Then a command can be written like  foo --branch-name=$DRONE_BRANCH --param1=$SAFENAMESPACE_PARAM1  and the param is not displayed while following build progress. Versus something like  foo --branch-name=$DRONE_BRANCH --param1={{PARAM1}}  which displays  foo --branch-name=$DRONE_BRANCH --param1=""ALL-YOUR-BASE-ARE-BELONG-TO-US"" ",other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | source-file | other-file | documentation-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file,"Document private parameters & injection strategies Build progress output shows the command that is run after params are injected. Granted, I understand that if someone had access to your account or you left the page up and walked away from your desk a malicious person could click and view the list of params. I am talking more from the perspective when someone walks up to my desk I don't have to minimize the build status and worry they read the output and are going to cause mischief. I think it would be a good idea not to show this information. I am not familiar with Go, so I am not sure where this expansion happens in the code and how difficult it would be to show the command with {{vars}} before they are expanded. A quick/simple option would be to also make the params available as environment variables. Then a command can be written like  foo --branch-name=$DRONE_BRANCH --param1=$SAFENAMESPACE_PARAM1  and the param is not displayed while following build progress. Versus something like  foo --branch-name=$DRONE_BRANCH --param1={{PARAM1}}  which displays  foo --branch-name=$DRONE_BRANCH --param1=""ALL-YOUR-BASE-ARE-BELONG-TO-US""  other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file source-file other-file source-file source-file other-file documentation-file other-file other-file source-file other-file other-file other-file documentation-file",no-bug,0.9
865,harness,https://github.com/harness/harness/issues/865,Extend YAML to allow Docker Parameters for Services,"Let's say you want persistence for your `postgres` service  yaml services: - postgres docker: name: project_awesome_redis volume: {{awesome_volume}}:/var/lib/pgsql/data  Or maybe you want to your services and build container to share the same network namespace (no linking)  yaml services: - davetucker/drone-ovs docker: name: project_awesome_ovs docker: - net: container:project_awesome_ovs  There are potentially a lot more use cases, but these are the two that I can think of right now.",other-file,"Extend YAML to allow Docker Parameters for Services Let's say you want persistence for your `postgres` service  yaml services: - postgres docker: name: project_awesome_redis volume: {{awesome_volume}}:/var/lib/pgsql/data  Or maybe you want to your services and build container to share the same network namespace (no linking)  yaml services: - davetucker/drone-ovs docker: name: project_awesome_ovs docker: - net: container:project_awesome_ovs  There are potentially a lot more use cases, but these are the two that I can think of right now. other-file",no-bug,0.9
311,harness,https://github.com/harness/harness/issues/311,Sending emails fails silently,"When emails are sent, it looks like there isn't any error handling. Is this intentional and something that'll be changed in the future? See: - https://github.com/drone/drone/blob/0c9a765956fa7a42de5fa704b555b5af26928643/pkg/handler/admin.go#L59 - https://github.com/drone/drone/blob/8102265475ca7ac07e6d7be93a80eac802e22ba6/pkg/handler/members.go#L197",source-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | documentation-file,"Sending emails fails silently When emails are sent, it looks like there isn't any error handling. Is this intentional and something that'll be changed in the future? See: - https://github.com/drone/drone/blob/0c9a765956fa7a42de5fa704b555b5af26928643/pkg/handler/admin.go#L59 - https://github.com/drone/drone/blob/8102265475ca7ac07e6d7be93a80eac802e22ba6/pkg/handler/members.go#L197 source-file source-file other-file other-file source-file documentation-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file documentation-file",no-bug,0.7
3525,harness,https://github.com/harness/harness/issues/3525,Gitness Integration support,I am working on project . I need to add support gitness as git provider. i am have problem fetching orgnations list via api. does gitness support orgs like github? if yes please guide my how to ?,other-file | other-file,Gitness Integration support I am working on project . I need to add support gitness as git provider. i am have problem fetching orgnations list via api. does gitness support orgs like github? if yes please guide my how to ? other-file other-file,no-bug,0.7
3008,harness,https://github.com/harness/harness/issues/3008,Drone authentication,hi Is there any option for only connecting 1 repository to Drone and don't give access to entire our version control account ? in team project everyone wants to see Pipeline so they should have my username and password for login to Drone App. and they see all of my repository. otherwise i should create account for my team and its not convenient Or is there any option to login Drone app with username and password Instead using Github authentication?,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | source-file | source-file | source-file | source-file,Drone authentication hi Is there any option for only connecting 1 repository to Drone and don't give access to entire our version control account ? in team project everyone wants to see Pipeline so they should have my username and password for login to Drone App. and they see all of my repository. otherwise i should create account for my team and its not convenient Or is there any option to login Drone app with username and password Instead using Github authentication? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file source-file source-file source-file source-file,no-bug,0.9
3237,harness,https://github.com/harness/harness/issues/3237,template converter: template name given not found," I cannot use template configuration  I created the template, but I will report an error when I build it  I created a template called notify.yaml, and I quoted it in my project. As shown in the figure  I found the same problem as me. [Click Here](https://stackoverflow.com/questions/70622564/drone-template-not-triggering-build) ![_20220704223044](https://user-images.githubusercontent.com/44392078/177175894-837ae27f-e279-4244-b415-579492db558a.png)  The drone-server is latest from docker hub When I ask this question ## This is `.drone.yaml` yaml kind: pipeline type: exec name: wind steps: - name: build commands: - docker-compose -p wind_generator build - name: start commands: - docker-compose -p wind_generator up -d - name: test_live commands: - /bin/sh -c ""sleep 2;if [ $(curl --noproxy ""*"" -o /dev/null -s -w %{http_code} -m 5 http://127.0.0.1:5200/liveprobe) = ""200"" ]; then echo """"; else echo """" && exit 1 ; fi"" trigger: branch: - master event: - push - custom  kind: template load: notify.yaml data: depends_on: wind  ## And this is `notify.yaml` yaml kind: pipeline type: docker name: default clone: disable: true steps: - name: email image: drillster/drone-email settings: recipients: from_secret: email_recipients subject: ""Drone build: [{{ build.status }}] {{ repo.name }} ({{ repo.branch }}) #{{ build.number }}"" host: smtp.qq.com port: 465 from: from_secret: email_user username: from_secret: email_user password: from_secret: email_password trigger: status: [success, failure] depends_on: - {{ .input.depends_on }}   You can see from the webpage that my template was successfully created. ![_20220704223149](https://user-images.githubusercontent.com/44392078/177176926-7565ba4a-d5d0-4111-b8c4-caf995ec9a78.png) ## I don't know why. My drone is started through docker.  I come from China, and the description language may not be so accurate. But I think I should still understand the problem I want to express.   The next day, I found a phenomenon. When I put `.drone.yaml` After the content of yaml is deleted, only one template is retained, like this yaml kind: template load: notify.yaml data: depends_on: wind   Then he can read the template I set  I think I can only find the answer by reading the source code of drone",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"template converter: template name given not found  I cannot use template configuration  I created the template, but I will report an error when I build it  I created a template called notify.yaml, and I quoted it in my project. As shown in the figure  I found the same problem as me. [Click Here](https://stackoverflow.com/questions/70622564/drone-template-not-triggering-build) ![_20220704223044](https://user-images.githubusercontent.com/44392078/177175894-837ae27f-e279-4244-b415-579492db558a.png)  The drone-server is latest from docker hub When I ask this question ## This is `.drone.yaml` yaml kind: pipeline type: exec name: wind steps: - name: build commands: - docker-compose -p wind_generator build - name: start commands: - docker-compose -p wind_generator up -d - name: test_live commands: - /bin/sh -c ""sleep 2;if [ $(curl --noproxy ""*"" -o /dev/null -s -w %{http_code} -m 5 http://127.0.0.1:5200/liveprobe) = ""200"" ]; then echo """"; else echo """" && exit 1 ; fi"" trigger: branch: - master event: - push - custom  kind: template load: notify.yaml data: depends_on: wind  ## And this is `notify.yaml` yaml kind: pipeline type: docker name: default clone: disable: true steps: - name: email image: drillster/drone-email settings: recipients: from_secret: email_recipients subject: ""Drone build: [{{ build.status }}] {{ repo.name }} ({{ repo.branch }}) #{{ build.number }}"" host: smtp.qq.com port: 465 from: from_secret: email_user username: from_secret: email_user password: from_secret: email_password trigger: status: [success, failure] depends_on: - {{ .input.depends_on }}   You can see from the webpage that my template was successfully created. ![_20220704223149](https://user-images.githubusercontent.com/44392078/177176926-7565ba4a-d5d0-4111-b8c4-caf995ec9a78.png) ## I don't know why. My drone is started through docker.  I come from China, and the description language may not be so accurate. But I think I should still understand the problem I want to express.   The next day, I found a phenomenon. When I put `.drone.yaml` After the content of yaml is deleted, only one template is retained, like this yaml kind: template load: notify.yaml data: depends_on: wind   Then he can read the template I set  I think I can only find the answer by reading the source code of drone source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
288,harness,https://github.com/harness/harness/issues/288,on_success: after_failure,"In some other CI systems it's possible to set up notifications to only go out in the event of failure, or after a failure has been resolved. So `on_success: after_failure` would look at the previous build, see if it was a failure, and if so send a notification.",other-file | source-file,"on_success: after_failure In some other CI systems it's possible to set up notifications to only go out in the event of failure, or after a failure has been resolved. So `on_success: after_failure` would look at the previous build, see if it was a failure, and if so send a notification. other-file source-file",no-bug,0.9
1,harness,https://github.com/harness/harness/issues/1,Dockerfile support,"Is it possible to configure drone so that if your project already has a `Dockerfile`, you can omit the `script` part of `.drone.yml` and rely on the `Dockerfile` to build the image?",source-file | source-file | test-file | source-file,"Dockerfile support Is it possible to configure drone so that if your project already has a `Dockerfile`, you can omit the `script` part of `.drone.yml` and rely on the `Dockerfile` to build the image? source-file source-file test-file source-file",no-bug,0.9
2695,harness,https://github.com/harness/harness/issues/2695,Rollback disabled,"Holaa, It looks like Rollback is disabled: https://github.com/drone/drone/blame/1c6d751d50dded95fa6c28e9842bb9bf36c89440/handler/api/api.go#L191-L193 It's not clear why, though. Commit just says ""squash and merge a local branch"". Is it supposed to be?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file,"Rollback disabled Holaa, It looks like Rollback is disabled: https://github.com/drone/drone/blame/1c6d751d50dded95fa6c28e9842bb9bf36c89440/handler/api/api.go#L191-L193 It's not clear why, though. Commit just says ""squash and merge a local branch"". Is it supposed to be? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file",no-bug,0.7
2249,harness,https://github.com/harness/harness/issues/2249,Build status not refresh on GitHub,"Hi, It seems like build status indicator on GitHUb is not refreshing when build succeed. <img width=""1004"" alt=""zrzut ekranu 2017-10-24 o 01 12 26"" src=""https://user-images.githubusercontent.com/12626874/31917616-ae49c304-b858-11e7-9191-b17de244c618.png""> <img width=""1080"" alt=""zrzut ekranu 2017-10-24 o 01 11 35"" src=""https://user-images.githubusercontent.com/12626874/31917623-b4db3fea-b858-11e7-85e3-ca577aa098fd.png""> It only works on failure builds <img width=""998"" alt=""zrzut ekranu 2017-10-24 o 01 15 25"" src=""https://user-images.githubusercontent.com/12626874/31917670-fe656636-b858-11e7-82ab-29aa169ba0d1.png"">",source-file,"Build status not refresh on GitHub Hi, It seems like build status indicator on GitHUb is not refreshing when build succeed. <img width=""1004"" alt=""zrzut ekranu 2017-10-24 o 01 12 26"" src=""https://user-images.githubusercontent.com/12626874/31917616-ae49c304-b858-11e7-9191-b17de244c618.png""> <img width=""1080"" alt=""zrzut ekranu 2017-10-24 o 01 11 35"" src=""https://user-images.githubusercontent.com/12626874/31917623-b4db3fea-b858-11e7-85e3-ca577aa098fd.png""> It only works on failure builds <img width=""998"" alt=""zrzut ekranu 2017-10-24 o 01 15 25"" src=""https://user-images.githubusercontent.com/12626874/31917670-fe656636-b858-11e7-82ab-29aa169ba0d1.png""> source-file",no-bug,0.8
3362,harness,https://github.com/harness/harness/issues/3362,About java springboot multiple module project,"**such as this project** ![image](https://github.com/harness/drone/assets/57866641/3a11ba8c-1472-4b2b-83f4-0eb4ec187fd3) **I want to deploy only modules with code updates, not the entire project, so I wrote a git command to get the updated module namesuch as ""module-1""** ![image](https://github.com/harness/drone/assets/57866641/576d4340-ae72-48e1-8c35-43d7a8578807) **But I cannot pass the entire variable to other steps in the pipeline. Neither the ""export"" method nor the ""environment"" method works. How can I pass the name of this module variable to other steps in the pipeline?**",documentation-file | test-file | other-file | other-file | other-file | other-file | other-file,"About java springboot multiple module project **such as this project** ![image](https://github.com/harness/drone/assets/57866641/3a11ba8c-1472-4b2b-83f4-0eb4ec187fd3) **I want to deploy only modules with code updates, not the entire project, so I wrote a git command to get the updated module namesuch as ""module-1""** ![image](https://github.com/harness/drone/assets/57866641/576d4340-ae72-48e1-8c35-43d7a8578807) **But I cannot pass the entire variable to other steps in the pipeline. Neither the ""export"" method nor the ""environment"" method works. How can I pass the name of this module variable to other steps in the pipeline?** documentation-file test-file other-file other-file other-file other-file other-file",no-bug,0.95
2976,harness,https://github.com/harness/harness/issues/2976,"My service is on the internal network, and the webhook of GitHub cannot be recalled. What should I do",,source-file | source-file,"My service is on the internal network, and the webhook of GitHub cannot be recalled. What should I do  source-file source-file",no-bug,0.8
984,harness,https://github.com/harness/harness/issues/984,Remove deprecated Task APIs,"Per @bradrydzewski, in the [`bolt` branch](https://github.com/drone/drone/tree/bolt), the `Task`, `TaskList` and `SetTask` methods in the datastore are deprecated and can be probably be removed. We need to make sure we aren't still using those functions anywhere else in the code.",test-file | source-file | test-file | source-file | source-file | test-file | source-file | other-file,"Remove deprecated Task APIs Per @bradrydzewski, in the [`bolt` branch](https://github.com/drone/drone/tree/bolt), the `Task`, `TaskList` and `SetTask` methods in the datastore are deprecated and can be probably be removed. We need to make sure we aren't still using those functions anywhere else in the code. test-file source-file test-file source-file source-file test-file source-file other-file",no-bug,0.9
691,harness,https://github.com/harness/harness/issues/691,Add install section to drone.yml,"Currently, installation and execution of tests is mixed in the `script` section of `drone.yml`. This should be split up in `installation` and `script` for two reasons: 1. By separation of installation from tests it documents better what is going on. People can see your test procedure by just looking at the correct part of the file 2. It allows for **Docker caching**. Drone could leverage Dockers builtin caching for its installation instructions, minimising the traffic and time needed to set up the build image. Only the `script` part should always be un-cached and thus run every time.",source-file,"Add install section to drone.yml Currently, installation and execution of tests is mixed in the `script` section of `drone.yml`. This should be split up in `installation` and `script` for two reasons: 1. By separation of installation from tests it documents better what is going on. People can see your test procedure by just looking at the correct part of the file 2. It allows for **Docker caching**. Drone could leverage Dockers builtin caching for its installation instructions, minimising the traffic and time needed to set up the build image. Only the `script` part should always be un-cached and thus run every time. source-file",no-bug,0.95
2881,harness,https://github.com/harness/harness/issues/2881,Improve kubernetes runner documentation,"current drone documentation contains only how to start drone runner as pod. However, that is not quite good for production use. First in production drone runner should be deployed as deployment. Secondly the instructions is missing rbac rules. Here you have rbac rules (hopefully this contains everything I went through the engine code):  kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: default name: drone rules: - apiGroups: - """" resources: - secrets verbs: - create - delete - apiGroups: - """" resources: - pods - pods/log verbs: - get - create - delete - list - watch - update  kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: drone namespace: default subjects: - kind: ServiceAccount name: default namespace: default roleRef: kind: Role name: drone apiGroup: rbac.authorization.k8s.io  And Here the deployment:  apiVersion: apps/v1 kind: Deployment metadata: name: drone labels: app.kubernetes.io/name: drone spec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: drone template: metadata: labels: app.kubernetes.io/name: drone spec: containers: - name: runner image: drone/drone-runner-kube:latest ports: - containerPort: 3000 env: - name: DRONE_RPC_HOST value: foobar.com - name: DRONE_RPC_PROTO value: https - name: DRONE_RPC_SECRET value: yyy  no idea which is correct place to report these?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Improve kubernetes runner documentation current drone documentation contains only how to start drone runner as pod. However, that is not quite good for production use. First in production drone runner should be deployed as deployment. Secondly the instructions is missing rbac rules. Here you have rbac rules (hopefully this contains everything I went through the engine code):  kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: default name: drone rules: - apiGroups: - """" resources: - secrets verbs: - create - delete - apiGroups: - """" resources: - pods - pods/log verbs: - get - create - delete - list - watch - update  kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: drone namespace: default subjects: - kind: ServiceAccount name: default namespace: default roleRef: kind: Role name: drone apiGroup: rbac.authorization.k8s.io  And Here the deployment:  apiVersion: apps/v1 kind: Deployment metadata: name: drone labels: app.kubernetes.io/name: drone spec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: drone template: metadata: labels: app.kubernetes.io/name: drone spec: containers: - name: runner image: drone/drone-runner-kube:latest ports: - containerPort: 3000 env: - name: DRONE_RPC_HOST value: foobar.com - name: DRONE_RPC_PROTO value: https - name: DRONE_RPC_SECRET value: yyy  no idea which is correct place to report these? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
1006,harness,https://github.com/harness/harness/issues/1006,"Can ""drone"" run under a non-root user?","Can ""drone"" run under a non-root user?",source-file | source-file,"Can ""drone"" run under a non-root user? Can ""drone"" run under a non-root user? source-file source-file",no-bug,0.9
1037,harness,https://github.com/harness/harness/issues/1037,Add support for report files,"There is actually no support for report file resulting of running tests. It would be interesting to be able to have a reports section in the .drone.yml to be able to specify the report file generated by the test suites, so that drone can serve them via http for example.",source-file | other-file,"Add support for report files There is actually no support for report file resulting of running tests. It would be interesting to be able to have a reports section in the .drone.yml to be able to specify the report file generated by the test suites, so that drone can serve them via http for example. source-file other-file",no-bug,0.9
1550,harness,https://github.com/harness/harness/issues/1550,send deployment status updates,The github remote should support sending status updates for deployments. Discussed a plan with @bradrydzewski on how to implement.,source-file,send deployment status updates The github remote should support sending status updates for deployments. Discussed a plan with @bradrydzewski on how to implement. source-file,no-bug,0.9
3556,harness,https://github.com/harness/harness/issues/3556,api for Projects missing?,REST apis for 'Projects' not available in swagger. Is it intentionally left or any plan to add in near future?,other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | other-file | documentation-file | source-file,api for Projects missing? REST apis for 'Projects' not available in swagger. Is it intentionally left or any plan to add in near future? other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file source-file other-file documentation-file source-file,no-bug,0.8
64,harness,https://github.com/harness/harness/issues/64,More ways to register in drone.io,"Hey. I really want to get drone.io into stress environment and see how it's going, but current registration scheme gets in the way. Would you accept settings for enabling open registration in drone.io? Invites working great, but I feel like people just move along, when seeing login page without any hints, how get access. Thank you for sharing this project again. It's wonderful!",source-file | source-file | database-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | source-file | source-file | source-file | database-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"More ways to register in drone.io Hey. I really want to get drone.io into stress environment and see how it's going, but current registration scheme gets in the way. Would you accept settings for enabling open registration in drone.io? Invites working great, but I feel like people just move along, when seeing login page without any hints, how get access. Thank you for sharing this project again. It's wonderful! source-file source-file database-file source-file source-file source-file source-file other-file other-file other-file source-file source-file source-file database-file source-file source-file source-file source-file other-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
971,harness,https://github.com/harness/harness/issues/971,Support personal API tokens,"We could improve user tokens. Today the user has a single token and no way to revoke or refresh. The database structure now supports a way for the user to store multiple tokens. The user could, for example, create a different token for each service they provide access to and even choose an expiration date. This can be similar to GitHub's user account tokens. You have the ability to choose which scopes are assigned to the token. This could be further improved, however, by also giving the ability to grant access to specific repositories for a given token. Proposed data structure: https://github.com/drone/drone/blob/bolt/common/token.go  type Token struct { Label string `json:""label""` Login string `json:""-""` Repos []string `json:""repos,omitempty""` Scopes []string `json:""scopes,omitempty""` Expiry int64 `json:""expiry,omitempty""` }  - `Expiry` could be an optional expiration date (unix seconds) for the token. If 0, no expiration - `Repos` could be a list of repositories to which the token is granted access. If `len == 0` the token is granted access to all repositories - `Scopes` similar to oauth scopes. This needs more definition - `Label` is used by the UI to identify the type of token. Useful for user management - `Login` is used to associate the token with the user account. Primarily required for database lookups I think for the initial implementation we could get away with just the `Label` field, and add all other functionality (expiry, scopes, etc) in a follow-up release to `0.4`. Getting `0.4` out quickly is more important than implementing all these features today. ## Generating a Token The proposal is to generate a `jwt` token, similar to the way we generate our auth tokens. This logic is found in the `server/login.go` file and the `server/session` package:  token := &common.Token{ Login: user.Login, Expiry: time.Now().UTC().Add(72*time.Hour), } tokenstr, err := session.GenerateToken(c.Request, token)  This means we can have a single approach to authorization. The con is that the `jwt` token is singed by a secret value that is optional. If not specified in the `drone.toml` configuration file, a random value is used. This means session tokens are invalidated when the application restarts, which is fine for session tokens, but bad for persistent user tokens. ## Generating When the user requests to create a new token we will generate the `jwt` string and return back to the browser (or whatever invokes the rest endpoint). The `jwt` value itself is never persisted in the database. The user needs to immediately copy the `jwt` string since it will never be shown again. I think that creating a user token should fail (with a specific error message) if the `drone.toml` has not been configured with a session secret. The error message could read something like > Could not generate a user token. This feature is currently disabled. Please contact your system administrator ## Persisting We want to allow the user to manage existing tokens and revoke them. This means that we will need to lookup and verify a token in the datastore. Note that we don't want to lookup session tokens, which have expirations and should not be persisted anyway. I'm proposing we store the user token in the `tokens` bucket. The key could be comprised of the user's login and token label (`token.Login + token.Label`). We could persist the token value, but this would of course be readonly, since we would have already generated the JWT string",source-file | source-file,"Support personal API tokens We could improve user tokens. Today the user has a single token and no way to revoke or refresh. The database structure now supports a way for the user to store multiple tokens. The user could, for example, create a different token for each service they provide access to and even choose an expiration date. This can be similar to GitHub's user account tokens. You have the ability to choose which scopes are assigned to the token. This could be further improved, however, by also giving the ability to grant access to specific repositories for a given token. Proposed data structure: https://github.com/drone/drone/blob/bolt/common/token.go  type Token struct { Label string `json:""label""` Login string `json:""-""` Repos []string `json:""repos,omitempty""` Scopes []string `json:""scopes,omitempty""` Expiry int64 `json:""expiry,omitempty""` }  - `Expiry` could be an optional expiration date (unix seconds) for the token. If 0, no expiration - `Repos` could be a list of repositories to which the token is granted access. If `len == 0` the token is granted access to all repositories - `Scopes` similar to oauth scopes. This needs more definition - `Label` is used by the UI to identify the type of token. Useful for user management - `Login` is used to associate the token with the user account. Primarily required for database lookups I think for the initial implementation we could get away with just the `Label` field, and add all other functionality (expiry, scopes, etc) in a follow-up release to `0.4`. Getting `0.4` out quickly is more important than implementing all these features today. ## Generating a Token The proposal is to generate a `jwt` token, similar to the way we generate our auth tokens. This logic is found in the `server/login.go` file and the `server/session` package:  token := &common.Token{ Login: user.Login, Expiry: time.Now().UTC().Add(72*time.Hour), } tokenstr, err := session.GenerateToken(c.Request, token)  This means we can have a single approach to authorization. The con is that the `jwt` token is singed by a secret value that is optional. If not specified in the `drone.toml` configuration file, a random value is used. This means session tokens are invalidated when the application restarts, which is fine for session tokens, but bad for persistent user tokens. ## Generating When the user requests to create a new token we will generate the `jwt` string and return back to the browser (or whatever invokes the rest endpoint). The `jwt` value itself is never persisted in the database. The user needs to immediately copy the `jwt` string since it will never be shown again. I think that creating a user token should fail (with a specific error message) if the `drone.toml` has not been configured with a session secret. The error message could read something like > Could not generate a user token. This feature is currently disabled. Please contact your system administrator ## Persisting We want to allow the user to manage existing tokens and revoke them. This means that we will need to lookup and verify a token in the datastore. Note that we don't want to lookup session tokens, which have expirations and should not be persisted anyway. I'm proposing we store the user token in the `tokens` bucket. The key could be comprised of the user's login and token label (`token.Login + token.Label`). We could persist the token value, but this would of course be readonly, since we would have already generated the JWT string source-file source-file",no-bug,0.9
2955,harness,https://github.com/harness/harness/issues/2955,Illegal instruction (core dumped) in Docker drone server images (armv7),"Env: Raspberry pi running Docker (see version output below) Latest image that works for me is `1.6.5`  pi@pi2:~ $ docker run -it --rm --entrypoint=sh drone/drone:latest / # drone-server Illegal instruction (core dumped) / # pi@pi2:docker run -it --rm --entrypoint=sh drone/drone:1.7.0 / # drone-server Segmentation fault (core dumped) / # pi@pi2:~ $ docker run -it --rm --entrypoint=sh drone/drone:1.7 Unable to find image 'drone/drone:1.7' locally 1.7: Pulling from drone/drone Digest: sha256:78af08dc38ec1dc3dad7047be799d2cde14e1888ed1e29316695d7cb53bfca07 Status: Downloaded newer image for drone/drone:1.7 / # drone-server Segmentation fault (core dumped) / # pi@pi2:docker run -it --rm --entrypoint=sh drone/drone:1.7.0-linux-arm Unable to find image 'drone/drone:1.7.0-linux-arm' locally 1.7.0-linux-arm: Pulling from drone/drone Digest: sha256:2b6437bcadb4615c6ae8b19dffc2b8a58ab1ea9253907fd5f396c52d0f9e5327 Status: Downloaded newer image for drone/drone:1.7.0-linux-arm / # drone-server Segmentation fault (core dumped) / # pi@pi2:~ $ docker run -it --rm --entrypoint=sh drone/drone:1.6.5 Unable to find image 'drone/drone:1.6.5' locally 1.6.5: Pulling from drone/drone 832e07764099: Pull complete 9bb17fa08116: Pull complete 40b659b65992: Pull complete e9521b7a1e0e: Pull complete Digest: sha256:f15247fb65d404491fa85b99dbc6e41ee6ee7eb37916b0e32c73a750bccc8579 Status: Downloaded newer image for drone/drone:1.6.5 / # drone-server {""level"":""fatal"",""msg"":""main: source code management system not configured"",""time"":""2020-04-23T11:55:19Z""}   pi@pi2:~ $ docker version Client: Docker Engine - Community Version: 19.03.8 API version: 1.40 Go version: go1.12.17 Git commit: afacb8b Built: Wed Mar 11 01:35:24 2020 OS/Arch: linux/arm Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.8 API version: 1.40 (minimum version 1.12) Go version: go1.12.17 Git commit: afacb8b Built: Wed Mar 11 01:29:22 2020 OS/Arch: linux/arm Experimental: false containerd: Version: 1.2.13 GitCommit: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc: Version: 1.0.0-rc10 GitCommit: dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init: Version: 0.18.0 GitCommit: fec3683 ",other-file | source-file,"Illegal instruction (core dumped) in Docker drone server images (armv7) Env: Raspberry pi running Docker (see version output below) Latest image that works for me is `1.6.5`  pi@pi2:~ $ docker run -it --rm --entrypoint=sh drone/drone:latest / # drone-server Illegal instruction (core dumped) / # pi@pi2:docker run -it --rm --entrypoint=sh drone/drone:1.7.0 / # drone-server Segmentation fault (core dumped) / # pi@pi2:~ $ docker run -it --rm --entrypoint=sh drone/drone:1.7 Unable to find image 'drone/drone:1.7' locally 1.7: Pulling from drone/drone Digest: sha256:78af08dc38ec1dc3dad7047be799d2cde14e1888ed1e29316695d7cb53bfca07 Status: Downloaded newer image for drone/drone:1.7 / # drone-server Segmentation fault (core dumped) / # pi@pi2:docker run -it --rm --entrypoint=sh drone/drone:1.7.0-linux-arm Unable to find image 'drone/drone:1.7.0-linux-arm' locally 1.7.0-linux-arm: Pulling from drone/drone Digest: sha256:2b6437bcadb4615c6ae8b19dffc2b8a58ab1ea9253907fd5f396c52d0f9e5327 Status: Downloaded newer image for drone/drone:1.7.0-linux-arm / # drone-server Segmentation fault (core dumped) / # pi@pi2:~ $ docker run -it --rm --entrypoint=sh drone/drone:1.6.5 Unable to find image 'drone/drone:1.6.5' locally 1.6.5: Pulling from drone/drone 832e07764099: Pull complete 9bb17fa08116: Pull complete 40b659b65992: Pull complete e9521b7a1e0e: Pull complete Digest: sha256:f15247fb65d404491fa85b99dbc6e41ee6ee7eb37916b0e32c73a750bccc8579 Status: Downloaded newer image for drone/drone:1.6.5 / # drone-server {""level"":""fatal"",""msg"":""main: source code management system not configured"",""time"":""2020-04-23T11:55:19Z""}   pi@pi2:~ $ docker version Client: Docker Engine - Community Version: 19.03.8 API version: 1.40 Go version: go1.12.17 Git commit: afacb8b Built: Wed Mar 11 01:35:24 2020 OS/Arch: linux/arm Experimental: false Server: Docker Engine - Community Engine: Version: 19.03.8 API version: 1.40 (minimum version 1.12) Go version: go1.12.17 Git commit: afacb8b Built: Wed Mar 11 01:29:22 2020 OS/Arch: linux/arm Experimental: false containerd: Version: 1.2.13 GitCommit: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc: Version: 1.0.0-rc10 GitCommit: dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init: Version: 0.18.0 GitCommit: fec3683  other-file source-file",no-bug,0.95
528,harness,https://github.com/harness/harness/issues/528,re-add SSL,"this was removed when we switched to `goji` which doesn't provide `ListenAndServeTLS`, so we'll need to just alter our code to not use `goji.Server()`",other-file | other-file | other-file,"re-add SSL this was removed when we switched to `goji` which doesn't provide `ListenAndServeTLS`, so we'll need to just alter our code to not use `goji.Server()` other-file other-file other-file",no-bug,0.9
730,harness,https://github.com/harness/harness/issues/730,long time before build starts,"Hello, Help on this would be appreciated. It takes around 15 (sometimes more) minutes to see status being changed from STARTED (into building) and to see build logs in a browser screen. There is nothing in between showing what is going on (cannot see anything in logs neither). If rebuild is triggered, it takes as much long. Did pull all images needed for build  also could notice image being build at very beginning but not having tag yet. if I would stop drone process, image would get a tag name. It is running on amazon m1.small. Docker info: Images: 150 Storage Driver: btrfs Execution Driver: native-0.2 Kernel Version: 3.13.0-36-generic Operating System: Ubuntu 14.04.1 LTS WARNING: No swap limit support ubuntu@ip-172-31-36-122:~$ thank you in advance",source-file | source-file,"long time before build starts Hello, Help on this would be appreciated. It takes around 15 (sometimes more) minutes to see status being changed from STARTED (into building) and to see build logs in a browser screen. There is nothing in between showing what is going on (cannot see anything in logs neither). If rebuild is triggered, it takes as much long. Did pull all images needed for build  also could notice image being build at very beginning but not having tag yet. if I would stop drone process, image would get a tag name. It is running on amazon m1.small. Docker info: Images: 150 Storage Driver: btrfs Execution Driver: native-0.2 Kernel Version: 3.13.0-36-generic Operating System: Ubuntu 14.04.1 LTS WARNING: No swap limit support ubuntu@ip-172-31-36-122:~$ thank you in advance source-file source-file",no-bug,0.9
41,harness,https://github.com/harness/harness/issues/41,Cache-Control for Badges,Need to understand how this impacts our badge implementation: https://github.com/github/markup/issues/224 Any changes required?,other-file | other-file | other-file | other-file,Cache-Control for Badges Need to understand how this impacts our badge implementation: https://github.com/github/markup/issues/224 Any changes required? other-file other-file other-file other-file,no-bug,0.9
821,harness,https://github.com/harness/harness/issues/821,Dart: Add pub bin dir to PATH,"For dart builds if you want to call any [pub global activated executables](https://www.dartlang.org/tools/pub/cmd/pub-global.html#running-a-script-from-your-path) you have to add the following to your drone script: export PATH=""$PATH"":""~/.pub-cache/bin"" It would be nice if this were done automatically.",other-file | other-file | other-file | other-file | other-file | documentation-file | other-file | source-file | other-file | source-file,"Dart: Add pub bin dir to PATH For dart builds if you want to call any [pub global activated executables](https://www.dartlang.org/tools/pub/cmd/pub-global.html#running-a-script-from-your-path) you have to add the following to your drone script: export PATH=""$PATH"":""~/.pub-cache/bin"" It would be nice if this were done automatically. other-file other-file other-file other-file other-file documentation-file other-file source-file other-file source-file",no-bug,0.95
2484,harness,https://github.com/harness/harness/issues/2484,Cancel button for matrix builds,"I have a pipeline which has 4 matrix builds, I can individually cancel the jobs by going to their individual pages and hitting cancel, but I'd like button to cancel all of them from the matrix view.",other-file | container-file | source-file,"Cancel button for matrix builds I have a pipeline which has 4 matrix builds, I can individually cancel the jobs by going to their individual pages and hitting cancel, but I'd like button to cancel all of them from the matrix view. other-file container-file source-file",no-bug,0.9
1133,harness,https://github.com/harness/harness/issues/1133,Build logs scroll left on Firefox,"If you have a build log that has one very long line, on firefox the whole text pane slides to the left. This means most messages that are shorter can't be seen because they are off screen. This works fine on Chrome though.",source-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file,"Build logs scroll left on Firefox If you have a build log that has one very long line, on firefox the whole text pane slides to the left. This means most messages that are shorter can't be seen because they are off screen. This works fine on Chrome though. source-file other-file other-file source-file other-file other-file source-file documentation-file other-file other-file",no-bug,0.95
572,harness,https://github.com/harness/harness/issues/572,WS connection fails for live output, ws://server:80/api/stream/stdout/4' failed: Error during WebSocket handshake: Unexpected response code: 404  No proxy is used at all,source-file | source-file | source-file | source-file,WS connection fails for live output  ws://server:80/api/stream/stdout/4' failed: Error during WebSocket handshake: Unexpected response code: 404  No proxy is used at all source-file source-file source-file source-file,no-bug,0.7
511,harness,https://github.com/harness/harness/issues/511,Enableing DualStack transport,"This is workaround for enabling [DualStack](https://golang.org/src/pkg/net/dial.go#L41) flag for IPv6 only hosts. If you have IPv6 (without IPv4 routes) host and `github.enterprise.com` that have IPv4 **and** IPv6 adresses - go will pick IPv4 by default. This will cause next error: `Error exchanging token. Post https://github.enterprise.com/login/oauth/access_token: dial tcp x.x.x.x:443: no route to host` You will need pass `Transport` to `oauth.Transport` calls. For github you should modify [github.go](https://github.com/drone/drone/blob/5f950d21c494c48ffae6e32cf9e381ea3ee6125a/plugin/remote/github/github.go#L81):  go // Do not forget to import `net` in the head of file var trans = &oauth.Transport{Config: config, Transport: &http.Transport{Dial: (&net.Dialer{DualStack: true}).Dial}}  Also [helper.go](https://github.com/drone/drone/blob/5f950d21c494c48ffae6e32cf9e381ea3ee6125a/plugin/remote/github/helper.go#L20) should be modified in the same way. Seems like `Transport` should be refactored in one place and be configurable (`dualstack` in config would be nice).",source-file | source-file,"Enableing DualStack transport This is workaround for enabling [DualStack](https://golang.org/src/pkg/net/dial.go#L41) flag for IPv6 only hosts. If you have IPv6 (without IPv4 routes) host and `github.enterprise.com` that have IPv4 **and** IPv6 adresses - go will pick IPv4 by default. This will cause next error: `Error exchanging token. Post https://github.enterprise.com/login/oauth/access_token: dial tcp x.x.x.x:443: no route to host` You will need pass `Transport` to `oauth.Transport` calls. For github you should modify [github.go](https://github.com/drone/drone/blob/5f950d21c494c48ffae6e32cf9e381ea3ee6125a/plugin/remote/github/github.go#L81):  go // Do not forget to import `net` in the head of file var trans = &oauth.Transport{Config: config, Transport: &http.Transport{Dial: (&net.Dialer{DualStack: true}).Dial}}  Also [helper.go](https://github.com/drone/drone/blob/5f950d21c494c48ffae6e32cf9e381ea3ee6125a/plugin/remote/github/helper.go#L20) should be modified in the same way. Seems like `Transport` should be refactored in one place and be configurable (`dualstack` in config would be nice). source-file source-file",no-bug,0.9
2860,harness,https://github.com/harness/harness/issues/2860,"Templating, shared YAML","Drone should support templating so we can keep things DRY. I'm finding repositories essentially have nearly identical `.drone.yml` files. Adding support for basic templating such as [GitLab's include directive](https://docs.gitlab.com/ee/ci/yaml/#include) would help keep pipelines more reusable. At the very least, Drone should support running a script to generate its full `.drone.yml` file before the run. There is an old 2 year old issue about supporting templating but it was closed without resolution.",other-file,"Templating, shared YAML Drone should support templating so we can keep things DRY. I'm finding repositories essentially have nearly identical `.drone.yml` files. Adding support for basic templating such as [GitLab's include directive](https://docs.gitlab.com/ee/ci/yaml/#include) would help keep pipelines more reusable. At the very least, Drone should support running a script to generate its full `.drone.yml` file before the run. There is an old 2 year old issue about supporting templating but it was closed without resolution. other-file",no-bug,0.9
1022,harness,https://github.com/harness/harness/issues/1022,Update private repo params as structure JSON (not yaml string),"Content of params (private variable) during update is expected yaml string format . It would be easier if params KVP can be accepted in json format. Below returns : 500 Internal Server Error  curl -v -X PUT ""http://droneio.xyz.com/api/repos/github.com/npateriya/godemo?access_token=XYZ"" -d `{params: { hello: world } }`  Yaml param for single variable works but not sure how to embed multiple KVP yaml in json.  curl -v -X PUT ""http://droneio.xyz.com/api/repos/github.com/npateriya/godemo?access_token=XYZ"" -d `{params: hello: world }` ",test-file,"Update private repo params as structure JSON (not yaml string) Content of params (private variable) during update is expected yaml string format . It would be easier if params KVP can be accepted in json format. Below returns : 500 Internal Server Error  curl -v -X PUT ""http://droneio.xyz.com/api/repos/github.com/npateriya/godemo?access_token=XYZ"" -d `{params: { hello: world } }`  Yaml param for single variable works but not sure how to embed multiple KVP yaml in json.  curl -v -X PUT ""http://droneio.xyz.com/api/repos/github.com/npateriya/godemo?access_token=XYZ"" -d `{params: hello: world }`  test-file",bug,0.85
2836,harness,https://github.com/harness/harness/issues/2836,scratch plugin does not work,"<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> i've a scratch based binary image, but when i configure drone's command of this plugin, it fails of no /bin/sh found, i think it may be that drone call `sh -c` for each command. has any settings can i set it for only run my own command not `sh -c`",database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file,"scratch plugin does not work <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> i've a scratch based binary image, but when i configure drone's command of this plugin, it fails of no /bin/sh found, i think it may be that drone call `sh -c` for each command. has any settings can i set it for only run my own command not `sh -c` database-file database-file database-file database-file database-file database-file database-file database-file",no-bug,0.9
2717,harness,https://github.com/harness/harness/issues/2717,Feature/Kubernetes: Allow overriding randomly generated namespaces,"Hi there, it would be great to override Drone creating randomly generated namespaces, thus running all builds in the same namespace as drone agents (`DRONE_KUBERNETES_NAMESPACE`) or using a custom namespace (`DRONE_KUBERNETES_BUILD_STAGE_NAMESPACE` ?) to address this. What do you think?",other-file | source-file | documentation-file | other-file | other-file | documentation-file,"Feature/Kubernetes: Allow overriding randomly generated namespaces Hi there, it would be great to override Drone creating randomly generated namespaces, thus running all builds in the same namespace as drone agents (`DRONE_KUBERNETES_NAMESPACE`) or using a custom namespace (`DRONE_KUBERNETES_BUILD_STAGE_NAMESPACE` ?) to address this. What do you think? other-file source-file documentation-file other-file other-file documentation-file",no-bug,0.9
2214,harness,https://github.com/harness/harness/issues/2214,How make the tests run faster?,"![screen shot 2017-09-14 at 12 15 01 pm](https://user-images.githubusercontent.com/3416976/30429336-9cf5186e-9946-11e7-9445-6603c342d20b.png) I'm using Drone to run `rspec` and everything is okay so far. But, I think it's slow. On average, it took around 5 minutes, 20 seconds to finish. My `.drone.yml`:  pipeline: build: image: zulhfreelancer/ruby_nodejs:latest commands: - gem update bundler - bundle install --path vendor/bundle - bundle exec rake db:create db:migrate - bundle exec rspec environment: - RAILS_ENV=test - SECRET_TOKEN=abc - DB_HOST=postgres - DB_USER=pg_user - DB_PASSWORD=pg_pass services: postgres: image: postgres:9.4.5 environment: POSTGRES_PASSWORD: pg_pass POSTGRES_USER: pg_user PGDATA: /var/lib/postgresql/data POSTGRES_DB: useradmin_test redis: image: redis:2.8.22 cache: - vendor/bundle - .git  Any idea or suggestion how to make the tests finish faster? FYI, I'm running DroneCI on 1GB VPS. I only have Drone service inside that VPS. No other processes running except Drone.",source-file | source-file | source-file | source-file | documentation-file | source-file | other-file,"How make the tests run faster? ![screen shot 2017-09-14 at 12 15 01 pm](https://user-images.githubusercontent.com/3416976/30429336-9cf5186e-9946-11e7-9445-6603c342d20b.png) I'm using Drone to run `rspec` and everything is okay so far. But, I think it's slow. On average, it took around 5 minutes, 20 seconds to finish. My `.drone.yml`:  pipeline: build: image: zulhfreelancer/ruby_nodejs:latest commands: - gem update bundler - bundle install --path vendor/bundle - bundle exec rake db:create db:migrate - bundle exec rspec environment: - RAILS_ENV=test - SECRET_TOKEN=abc - DB_HOST=postgres - DB_USER=pg_user - DB_PASSWORD=pg_pass services: postgres: image: postgres:9.4.5 environment: POSTGRES_PASSWORD: pg_pass POSTGRES_USER: pg_user PGDATA: /var/lib/postgresql/data POSTGRES_DB: useradmin_test redis: image: redis:2.8.22 cache: - vendor/bundle - .git  Any idea or suggestion how to make the tests finish faster? FYI, I'm running DroneCI on 1GB VPS. I only have Drone service inside that VPS. No other processes running except Drone. source-file source-file source-file source-file documentation-file source-file other-file",no-bug,0.95
2745,harness,https://github.com/harness/harness/issues/2745,Documentation is missing DRONE_RUNNER_NETWORKS,Since I discussed the issue about drone runner not able to connect to network of the drone itself (or other docker network) I was approached by few people asking if it was solved. So I guess the DRONE_RUNNER_NETWORKS should be added to documentation reference,source-file | source-file | source-file | source-file | source-file | source-file | source-file,Documentation is missing DRONE_RUNNER_NETWORKS Since I discussed the issue about drone runner not able to connect to network of the drone itself (or other docker network) I was approached by few people asking if it was solved. So I guess the DRONE_RUNNER_NETWORKS should be added to documentation reference source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
3247,harness,https://github.com/harness/harness/issues/3247,Registry of active runners,"Sometimes I do not know how many active runners I have. It would be nice to have API endpoint or/and UI element to list active runners (with auto generated names/UUIDs or IPs, or some other way of differentiating them)",source-file | source-file,"Registry of active runners Sometimes I do not know how many active runners I have. It would be nice to have API endpoint or/and UI element to list active runners (with auto generated names/UUIDs or IPs, or some other way of differentiating them) source-file source-file",no-bug,0.9
4,harness,https://github.com/harness/harness/issues/4,Help Page not found,"When clicking on the Help link in the main navigation you get redirected to /help that returns a ""404 page not found"".",other-file | source-file | test-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file,"Help Page not found When clicking on the Help link in the main navigation you get redirected to /help that returns a ""404 page not found"". other-file source-file test-file other-file source-file other-file other-file other-file other-file source-file",no-bug,0.9
2323,harness,https://github.com/harness/harness/issues/2323,Anchors doesn't work in yaml,"Yaml anchors used to work with earlier versions. With the 0.8 line it doesn't work anymore Here is a snippet that would be nice to see working. More details are in this discourse thread: https://discourse.drone.io/t/solved-conditional-builds-multiple-when-clauses/316/4  run_tests: &run_tests image: node:7.6.0 commands: - npm install --no-optional --silent > /dev/null - npm run ci pipeline: pr: <<: *run_tests when: event: pull_request branch: excludes: master push: <<: *run_tests when: event: push branch: master  Running this snippet results in ""Invalid or missing image""",source-file,"Anchors doesn't work in yaml Yaml anchors used to work with earlier versions. With the 0.8 line it doesn't work anymore Here is a snippet that would be nice to see working. More details are in this discourse thread: https://discourse.drone.io/t/solved-conditional-builds-multiple-when-clauses/316/4  run_tests: &run_tests image: node:7.6.0 commands: - npm install --no-optional --silent > /dev/null - npm run ci pipeline: pr: <<: *run_tests when: event: pull_request branch: excludes: master push: <<: *run_tests when: event: push branch: master  Running this snippet results in ""Invalid or missing image"" source-file",no-bug,0.9
741,harness,https://github.com/harness/harness/issues/741,Drone/Slack: Corporate Proxy,"Hi! We currently use Drone in our company and it works just awesome. We also use Slack in our team and would like to notify a slack channel of the build status. Currently, nothing happens with slack. We have set it up this way:  notify: slack: username: $$SLACK_USER token: $$SLACK_TOKEN team: $$SLACK_TEAM channel: $$SLACK_CHANNEL on_started: true on_success: true on_failure: true  And the environment variables are set in the repository settings on Drone. There is no output of the slack plugin. How can we have a more verbose logging output of Drone or the Plugin? Does Drone/The Plugin System/The Slack plugin support a corporate proxy? Our proxy is set via `HTTP_PROXY/HTTPS_PROXY`on the machine.",source-file,"Drone/Slack: Corporate Proxy Hi! We currently use Drone in our company and it works just awesome. We also use Slack in our team and would like to notify a slack channel of the build status. Currently, nothing happens with slack. We have set it up this way:  notify: slack: username: $$SLACK_USER token: $$SLACK_TOKEN team: $$SLACK_TEAM channel: $$SLACK_CHANNEL on_started: true on_success: true on_failure: true  And the environment variables are set in the repository settings on Drone. There is no output of the slack plugin. How can we have a more verbose logging output of Drone or the Plugin? Does Drone/The Plugin System/The Slack plugin support a corporate proxy? Our proxy is set via `HTTP_PROXY/HTTPS_PROXY`on the machine. source-file",no-bug,0.9
481,harness,https://github.com/harness/harness/issues/481,"0.3 Release, POST to /v1/remotes is not found","On latest build I have error, when trying to configure Github/Github enterprise:  Request URL:http://drone-dev.yandex.net/v1/remotes Request Method:POST Status Code:404 Not Found  May be it caused by wrong URL (without concrete remote plugin) passed to client.",source-file,"0.3 Release, POST to /v1/remotes is not found On latest build I have error, when trying to configure Github/Github enterprise:  Request URL:http://drone-dev.yandex.net/v1/remotes Request Method:POST Status Code:404 Not Found  May be it caused by wrong URL (without concrete remote plugin) passed to client. source-file",bug,0.9
3528,harness,https://github.com/harness/harness/issues/3528,"using pipelines with Docker-in-Docker samples, Error: mount: permission denied","Using pipelines with Docker-in-Docker samples Error: mount: permission denied, Could not mount /sys/kernel/security. Error Log:  Certificate request self-signature ok subject=CN=docker:dind server /certs/server/cert.pem: OK Certificate request self-signature ok subject=CN=docker:dind client /certs/client/cert.pem: OK iptables v1.8.10 (legacy) mount: permission denied (are you root?) Could not mount /sys/kernel/security. AppArmor detection and --privileged mode might break. mount: permission denied (are you root?)   Steps To Reproduce OS: Ubuntu aarch64 GNU/Linux pipeline:  kind: pipeline spec: stages: - type: ci spec: volumes: - name: dockersock spec: {} type: temp steps: - name: dind type: background spec: container: image: docker:dind privileged: true mount: - name: dockersock path: /var/run - name: test type: run spec: container: docker:dind mount: - name: dockersock path: /var/run script: |- sleep 5 docker ps -a ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file,"using pipelines with Docker-in-Docker samples, Error: mount: permission denied Using pipelines with Docker-in-Docker samples Error: mount: permission denied, Could not mount /sys/kernel/security. Error Log:  Certificate request self-signature ok subject=CN=docker:dind server /certs/server/cert.pem: OK Certificate request self-signature ok subject=CN=docker:dind client /certs/client/cert.pem: OK iptables v1.8.10 (legacy) mount: permission denied (are you root?) Could not mount /sys/kernel/security. AppArmor detection and --privileged mode might break. mount: permission denied (are you root?)   Steps To Reproduce OS: Ubuntu aarch64 GNU/Linux pipeline:  kind: pipeline spec: stages: - type: ci spec: volumes: - name: dockersock spec: {} type: temp steps: - name: dind type: background spec: container: image: docker:dind privileged: true mount: - name: dockersock path: /var/run - name: test type: run spec: container: docker:dind mount: - name: dockersock path: /var/run script: |- sleep 5 docker ps -a  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file",no-bug,0.9
2466,harness,https://github.com/harness/harness/issues/2466,DRONE_WORKSPACE and CI_WORKSPACE env variable behaves weird,"Hi. I am using the latest drone docker image `0.8.6` and experience some weird behaviour with the `DRONE_WORKSPACE`/`CI_WORKSPACE` variables. They seem to be only injected as environment variables when running the image, but are not in the ""metadata"" (so cannot be used for string operations as explained [here](http://readme.drone.io/0.5/usage/environment-reference/)). Here a quick test case to reproduce: yaml pipeline: test1: image: busybox:latest environment: - DRONE_WORKSPACE2=${DRONE_WORKSPACE} commands: # works - echo $DRONE_WORKSPACE # is empty, but I would expected it to be filled, too - echo $DRONE_WORKSPACE2 # is empty, but I would expected it to be filled, too - echo ${DRONE_WORKSPACE} test2: image: busybox:latest environment: - CI_WORKSPACE2=${CI_WORKSPACE} commands: # works - echo $CI_WORKSPACE # is empty, but I would expected it to be filled, too - echo $CI_WORKSPACE2 # is empty, but I would expected it to be filled, too - echo ${CI_WORKSPACE}  Is this intentional?",other-file,"DRONE_WORKSPACE and CI_WORKSPACE env variable behaves weird Hi. I am using the latest drone docker image `0.8.6` and experience some weird behaviour with the `DRONE_WORKSPACE`/`CI_WORKSPACE` variables. They seem to be only injected as environment variables when running the image, but are not in the ""metadata"" (so cannot be used for string operations as explained [here](http://readme.drone.io/0.5/usage/environment-reference/)). Here a quick test case to reproduce: yaml pipeline: test1: image: busybox:latest environment: - DRONE_WORKSPACE2=${DRONE_WORKSPACE} commands: # works - echo $DRONE_WORKSPACE # is empty, but I would expected it to be filled, too - echo $DRONE_WORKSPACE2 # is empty, but I would expected it to be filled, too - echo ${DRONE_WORKSPACE} test2: image: busybox:latest environment: - CI_WORKSPACE2=${CI_WORKSPACE} commands: # works - echo $CI_WORKSPACE # is empty, but I would expected it to be filled, too - echo $CI_WORKSPACE2 # is empty, but I would expected it to be filled, too - echo ${CI_WORKSPACE}  Is this intentional? other-file",no-bug,0.9
286,harness,https://github.com/harness/harness/issues/286,Error building on raspberry pi,"I want to install drone on raspberry pi. The device has a arch linux and installed docker from the project http://resin.io I cloned https://github.com/drone/drone/issues/new, added changes to `Dockerfile` and tried to build an image.  FROM resin/rpi-raspbian  In the logs I have not seen the error cause.  cmd/go go tool dist: FAILED: /go/pkg/tool/linux_arm/5g -o $WORK/_go_.5 -p main /go/src/cmd/go/bootstrap.go /go/src/cmd/go/build.go /go/src/cmd/go/clean.go /go/src/cmd/go/env.go /go/src/cm d/go/fix.go /go/src/cmd/go/fmt.go /go/src/cmd/go/get.go /go/src/cmd/go/go11.go /go/src/cmd/go/help.go /go/src/cmd/go/list.go /go/src/cmd/go/main.go /go/src/cmd/go/pkg.go /go/src/cm d/go/run.go /go/src/cmd/go/signal.go /go/src/cmd/go/signal_unix.go /go/src/cmd/go/test.go /go/src/cmd/go/testflag.go /go/src/cmd/go/tool.go /go/src/cmd/go/vcs.go /go/src/cmd/go/version.go /go/src/cmd/go/vet.go /go/src/cmd/go/zdefaultcc.go  Please help me to understand and build drone under raspberry pi. In advance, thank you.",source-file | source-file,"Error building on raspberry pi I want to install drone on raspberry pi. The device has a arch linux and installed docker from the project http://resin.io I cloned https://github.com/drone/drone/issues/new, added changes to `Dockerfile` and tried to build an image.  FROM resin/rpi-raspbian  In the logs I have not seen the error cause.  cmd/go go tool dist: FAILED: /go/pkg/tool/linux_arm/5g -o $WORK/_go_.5 -p main /go/src/cmd/go/bootstrap.go /go/src/cmd/go/build.go /go/src/cmd/go/clean.go /go/src/cmd/go/env.go /go/src/cm d/go/fix.go /go/src/cmd/go/fmt.go /go/src/cmd/go/get.go /go/src/cmd/go/go11.go /go/src/cmd/go/help.go /go/src/cmd/go/list.go /go/src/cmd/go/main.go /go/src/cmd/go/pkg.go /go/src/cm d/go/run.go /go/src/cmd/go/signal.go /go/src/cmd/go/signal_unix.go /go/src/cmd/go/test.go /go/src/cmd/go/testflag.go /go/src/cmd/go/tool.go /go/src/cmd/go/vcs.go /go/src/cmd/go/version.go /go/src/cmd/go/vet.go /go/src/cmd/go/zdefaultcc.go  Please help me to understand and build drone under raspberry pi. In advance, thank you. source-file source-file",no-bug,0.95
1173,harness,https://github.com/harness/harness/issues/1173,Inconsistent use of `*_url` in JSON,"We currently have an inconsistent use of `_url` prefix in our JSON data. For example, we use `link_url` and `clone_url` in some cases, and use `avatar` instead of `avatar_url` in other cases. Avatar may be the only example, but we need to audit and fix so that we can finalize the REST api",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Inconsistent use of `*_url` in JSON We currently have an inconsistent use of `_url` prefix in our JSON data. For example, we use `link_url` and `clone_url` in some cases, and use `avatar` instead of `avatar_url` in other cases. Avatar may be the only example, but we need to audit and fix so that we can finalize the REST api source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.9
812,harness,https://github.com/harness/harness/issues/812,Report any error when parsing private variables,"If the YAML parser cannot parse the private variables in the settings, it fails silently, and the build continues. The build needs to fail and report the parsing error instead.",source-file | source-file,"Report any error when parsing private variables If the YAML parser cannot parse the private variables in the settings, it fails silently, and the build continues. The build needs to fail and report the parsing error instead. source-file source-file",no-bug,0.8
3369,harness,https://github.com/harness/harness/issues/3369,Drone Templates aren't working with signed .drone.yaml,"I've searched far and wide where to report bugs, etc. but after 20 minutes searching through your repositories, I can't find a better place. Sorry. I tried setting up templates in drone and it fails when signing what is left over of the .drone.yaml. I moved everything from the .drone.yaml to a jsonnet template, added that to the organization, only referenced the template in the .drone.yaml and called `drone sign <organization>/<repo> --save`. It updated the hash, but drone itself does not accept it and requires me to manually approve the build. What do I have to do?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Drone Templates aren't working with signed .drone.yaml I've searched far and wide where to report bugs, etc. but after 20 minutes searching through your repositories, I can't find a better place. Sorry. I tried setting up templates in drone and it fails when signing what is left over of the .drone.yaml. I moved everything from the .drone.yaml to a jsonnet template, added that to the organization, only referenced the template in the .drone.yaml and called `drone sign <organization>/<repo> --save`. It updated the hash, but drone itself does not accept it and requires me to manually approve the build. What do I have to do? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
408,harness,https://github.com/harness/harness/issues/408,Failure to build deps on fresh vagrant environment,Building the vagrant environment from scratch on the `exp` branch results in the following error:-  # which npm && npm -g install uglify-js less go get github.com/GeertJohan/go.rice/rice go list github.com/drone/drone/ | xargs go get -t -v github.com/drone/drone/cmd/droned # github.com/drone/drone/cmd/droned runtime.main: call to external function main.main runtime.main: undefined: main.main make:  [deps] Error 123  It looks like something is expecting to find droned.main which appears to have been removed. Any idea what the background is here?,other-file | other-file | other-file,Failure to build deps on fresh vagrant environment Building the vagrant environment from scratch on the `exp` branch results in the following error:-  # which npm && npm -g install uglify-js less go get github.com/GeertJohan/go.rice/rice go list github.com/drone/drone/ | xargs go get -t -v github.com/drone/drone/cmd/droned # github.com/drone/drone/cmd/droned runtime.main: call to external function main.main runtime.main: undefined: main.main make:  [deps] Error 123  It looks like something is expecting to find droned.main which appears to have been removed. Any idea what the background is here? other-file other-file other-file,no-bug,0.95
3335,harness,https://github.com/harness/harness/issues/3335,"Vulnerability of dependency ""golang.org/x/net""","Hello, we are a team researching the dependency management mechanism of Golang. During our analysis, we came across your project and noticed that it contains a vulnerability (CVE-2022-41723). In your project, the golang.org/x/net package is being used at version v0.0.0-20201202161906-c7110b5ffcbb, but the patched version is v0.7.0. To fix the vulnerability, we recommend modifying the go.mod file to update the version to v0.7.0. Thank you for your attention to this matter.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Vulnerability of dependency ""golang.org/x/net"" Hello, we are a team researching the dependency management mechanism of Golang. During our analysis, we came across your project and noticed that it contains a vulnerability (CVE-2022-41723). In your project, the golang.org/x/net package is being used at version v0.0.0-20201202161906-c7110b5ffcbb, but the patched version is v0.7.0. To fix the vulnerability, we recommend modifying the go.mod file to update the version to v0.7.0. Thank you for your attention to this matter. source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
491,harness,https://github.com/harness/harness/issues/491,Add loading / spinners,Currently when a button is clicked to launch an async event there is no loading bar or spinner that indicates the request was made and the client is waiting for a response.,source-file,Add loading / spinners Currently when a button is clicked to launch an async event there is no loading bar or spinner that indicates the request was made and the client is waiting for a response. source-file,no-bug,0.9
684,harness,https://github.com/harness/harness/issues/684,Drone crashes when it tries to send build output to non-existing websocket,"I am running drone behing an AWS ELB in http mode, which means that websocket traffic is not supported. I do see `bad request` when I click on `follow` link in the build web console (which is expected). However, drone crashes when it tries to send build output back to a non-existing subscribed websocket client.  Nov 10 18:19:11 ip-10-0-0-62.ec2.internal docker[29236]: 2014/11/10 18:19:11 http: multiple response.WriteHeader calls Nov 10 18:20:19 ip-10-0-0-62.ec2.internal docker[29236]: starting build Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: 2014/11/10 18:20:27 http: multiple response.WriteHeader calls Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: panic: runtime error: send on closed channel Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 560 [running]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.panic(0xad8880, 0x111c49e) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.replay(0xc2082daee0, 0xc20814ed80, 0x45, 0x45) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/channel.go:115 +0xb2 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Channel).start Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/channel.go:79 +0x2c8 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 16 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb61a0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815ff00, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815ff00, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).accept(0xc20815fea0, 0xcdc1d8, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:409 +0x343 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*TCPListener).AcceptTCP(0xc208038250, 0x4ef463, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/tcpsock_posix.go:234 +0x5d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.tcpKeepAliveListener.Accept(0xc208038250, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1947 +0x4b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Server).Serve(0xc208005920, 0x7f902deb6798, 0xc208038250, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1698 +0x91 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Server).ListenAndServe(0xc208005920, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1688 +0x14d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.ListenAndServe(0x7fffab5eafc2, 0x3, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1778 +0x79 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: main.main() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/main.go:142 +0x92e Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 19 [finalizer wait, 7 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.park(0x491980, 0x1138d70, 0x11237e9) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.parkunlock(0x1138d70, 0x11237e9) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runfinq() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.goexit() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/proc.c:1445 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 22 [syscall, 7 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: os/signal.loop() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by os/signal.init1 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 24 [chan receive, 7 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: database/sql.(*DB).connectionOpener(0xc208050580) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by database/sql.Open Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 17 [syscall, 7 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.goexit() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/proc.c:1445 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 129 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.(*Channel).start(0xc20824fb30) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/channel.go:64 +0x6f3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*PubSub).RegisterOpts Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/pubsub.go:59 +0x26b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 466 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5750, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208222450, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208222450, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc2082223f0, 0xc208312000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038240, 0xc208312000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038240, 0xc20833e1b8, 0xc208312000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc208308200, 0xc208312000, 0x1000, 0x1000, 0xc20836c050, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820c180) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820c180, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e160) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 218 [chan send, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 203 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5f90, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208355f00, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208355f00, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208355ea0, 0xc208410000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038d10, 0xc208410000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038d10, 0xc20833e5d8, 0xc208410000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc20817c2a0, 0xc208410000, 0x1000, 0x1000, 0xc20836c830, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820c6c0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820c6c0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e580) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 424 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.(*Channel).start(0xc2082ea640) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/channel.go:64 +0x6f3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*PubSub).RegisterOpts Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/pubsub.go:59 +0x26b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 467 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e160) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 142 [select, 4 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc208042160) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 141 [IO wait, 4 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5d80, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208171bf0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208171bf0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208171b90, 0xc20831c000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038880, 0xc20831c000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038880, 0xc2080421b8, 0xc20831c000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082da140, 0xc20831c000, 0x1000, 0x1000, 0xc208381130, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20831b3e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20831b3e0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc208042160) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 204 [select, 4 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e580) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal systemd[1]: drone@1.service: main process exited, code=exited, status=2/INVALIDARGUMENT Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 184 [chan send, 4 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 242 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb60f0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208354b50, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208354b50, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208354af0, 0xc20832e000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038400, 0xc20832e000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038400, 0xc20833f238, 0xc20832e000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082ca5e0, 0xc20832e000, 0x1000, 0x1000, 0xc20836da30, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc208376d80) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc208376d80, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f1e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 240 [chan send, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 243 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f1e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 388 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5e30, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc2081719c0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc2081719c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208171960, 0xc208313000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038c78, 0xc208313000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038c78, 0xc20833f708, 0xc208313000, 0x1000, 0x1000, 0xc2083a23c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082a6420, 0xc208313000, 0x1000, 0x1000, 0xc208380680, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2480) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2480, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f6b0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 246 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5ee0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208355170, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208355170, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208355110, 0xc208198000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080385d0, 0xc208198000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080385d0, 0xc20833f398, 0xc208198000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082cb7c0, 0xc208198000, 0x1000, 0x1000, 0xc2083800e0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc208377080) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc208377080, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f340) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 247 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f340) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 389 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f6b0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 250 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5cd0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208355950, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208355950, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc2083558f0, 0xc2081e8000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038750, 0xc2081e8000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038750, 0xc20833f4f8, 0xc2081e8000, 0x1000, 0x1000, 0xc2083772c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal systemd[1]: drone@1.service: control process exited, code=exited status=1 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal systemd[1]: Unit drone@1.service entered failed state. Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082cbf20, 0xc2081e8000, 0x1000, 0x1000, 0xc208380290, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc208377380) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc208377380, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f4a0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 251 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f4a0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 253 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5c20, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208355e90, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208355e90, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208355e30, 0xc208204000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080387a0, 0xc208204000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080387a0, 0xc20833f658, 0xc208204000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082bc160, 0xc208204000, 0x1000, 0x1000, 0xc2083804d0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083779e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083779e0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f600) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 254 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f600) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 395 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f810) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 394 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5ac0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815e6f0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815e6f0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc20815e690, 0xc208335000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038d28, 0xc208335000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038d28, 0xc20833f868, 0xc208335000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082a67c0, 0xc208335000, 0x1000, 0x1000, 0xc2083808c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2900) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2900, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f810) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 468 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).roundTrip(0xc20833e6e0, 0xc208428a30, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1015 +0x6db Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Transport).RoundTrip(0xc208430480, 0xc2083929c0, 0xd6, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:208 +0x49a Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.send(0xc2083929c0, 0x7f902deb46c8, 0xc208430480, 0xc208226e00, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/client.go:195 +0x43d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Client).send(0xc2083efa40, 0xc2083929c0, 0x6b, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/client.go:118 +0x15b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Client).doFollowingRedirects(0xc2083efa40, 0xc2083929c0, 0xcdc250, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/client.go:343 +0x97f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Client).Do(0xc2083efa40, 0xc2083929c0, 0xc, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/client.go:153 +0x193 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.(*Client).do(0xc2081240f0, 0xb6b3d0, 0x4, 0xc20820c900, 0x51, 0x0, 0x0, 0x9539a0, 0xc2084289a8, 0x0, ) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/client.go:215 +0x45c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.(*ContainerService).Wait(0xc208038100, 0xc20838e700, 0x40, 0xc208430180, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/container.go:74 +0x19d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build.(*Builder).run(0xc208217300, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:415 +0x108f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build.func001() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:113 +0x32 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/shared/build.(*Builder).Run Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:114 +0x1fc Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 422 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build.(*Builder).Run(0xc208217300, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:117 +0x480 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/worker/docker.(*Docker).Do(0xc2080ee150, 0x7f902debb070, 0xc2082f2760, 0xc20837e060) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/worker/docker/docker.go:130 +0xb3c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/worker/director.(*Director).do(0xc208118240, 0x7f902debb070, 0xc2082f2760, 0xc20837e060) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/worker/director/director.go:55 +0xed Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/worker/director.(*Director).Do(0xc208118240, 0x7f902debb070, 0xc2082f2760, 0xc20837e060) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/worker/director/director.go:32 +0x59 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/worker.Do(0x7f902debb070, 0xc2082f2760, 0xc20837e060) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/worker/worker.go:14 +0x6d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/handler.PostHook Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/handler/hook.go:125 +0x8ce Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 431 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5960, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815ebc0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815ebc0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc20815eb60, 0xc20837b000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080388e0, 0xc20837b000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080388e0, 0xc20833ef78, 0xc20837b000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc20829e040, 0xc20837b000, 0x1000, 0x1000, 0xc2083729e0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2ae0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2ae0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833ef20) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 392 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f760) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 391 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5b70, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815e140, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815e140, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc20815e0e0, 0xc208333000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038cd0, 0xc208333000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038cd0, 0xc20833f7b8, 0xc208333000, 0x1000, 0x1000, 0xc2083a2660, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082a65c0, 0xc208333000, 0x1000, 0x1000, 0xc2083807a0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2720) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2720, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f760) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 432 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833ef20) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 450 [chan send]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 435 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb58b0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815f3a0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815f3a0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc20815f340, 0xc20841d000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038980, 0xc20841d000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038980, 0xc20833f028, 0xc20841d000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc20829f140, 0xc20841d000, 0x1000, 0x1000, 0xc208372e60, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2d80) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2d80, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833efd0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 436 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833efd0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 472 [chan receive]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.(*Client).hijack(0xc2081240f0, 0xb6b3d0, 0x4, 0xc208222e00, 0x6f, 0xc208222e00, 0x7f902dec53a8, 0xc208308ea0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/client.go:287 +0x594 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.(*ContainerService).Attach(0xc208038100, 0xc20838e700, 0x40, 0x7f902dec53a8, 0xc208308ea0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/container.go:81 +0x15c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build.func002() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:404 +0xd0 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/shared/build.(*Builder).run Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:405 +0xf74 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 470 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5a10, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208222990, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208222990, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208222930, 0xc2083b6000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080382e8, 0xc2083b6000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080382e8, 0xc20833e318, 0xc2083b6000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc208308d00, 0xc2083b6000, 0x1000, 0x1000, 0xc20836c680, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820c480) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820c480, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e2c0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 471 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e2c0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 476 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5800, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208222f40, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208222f40, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208222ee0, 0xc208432000, 0x8009, 0x8009, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038348, 0xc208432000, 0x8009, 0x8009, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Read(0xc20820c7e0, 0xc208432000, 0x8009, 0x8009, 0x8009, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:165 +0x13b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/docker/docker/pkg/stdcopy.StdCopy(0x7f902dec53a8, 0xc208308ea0, 0x7f902dec53a8, 0xc208308ea0, 0x7f902deb4e60, 0xc20820c7e0, 0x611, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/docker/docker/pkg/stdcopy/stdcopy.go:94 +0x16b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.func002() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/client.go:280 +0x172 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/shared/build/docker.(*Client).hijack Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/client.go:284 +0x550 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 474 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb56a0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208222fb0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208222fb0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208222f50, 0xc20835f000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038350, 0xc20835f000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038350, 0xc20833e688, 0xc20835f000, 0x1000, 0x1000, 0xc20820c780, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc208308fc0, 0xc20835f000, 0x1000, 0x1000, 0xc20836c8c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820c8a0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820c8a0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e630) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 475 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e630) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 557 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5490, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208354610, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208354610, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc2083545b0, 0xc20817f000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038810, 0xc20817f000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*liveSwitchReader).Read(0xc208216ca8, 0xc20817f000, 0x1000, 0x1000, 0x7f902deb6508, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:206 +0xaf Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: io.(*LimitedReader).Read(0xc2082ed940, 0xc20817f000, 0x1000, 0x1000, 0xc2083388c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/io/io.go:399 +0xd0 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc208005a40) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).ReadSlice(0xc208005a40, 0xc208118f0a, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:298 +0x22c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).ReadLine(0xc208005a40, 0x0, 0x0, 0x0, 0x4a0000, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:326 +0x69 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/textproto.(*Reader).readLineSlice(0xc20838d200, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/textproto/reader.go:55 +0x9d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/textproto.(*Reader).ReadLine(0xc20838d200, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/textproto/reader.go:36 +0x4e Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.ReadRequest(0xc208005a40, 0xc2083d16c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/request.go:556 +0xc7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*conn).readRequest(0xc208216c80, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:577 +0x276 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*conn).serve(0xc208216c80) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1132 +0x61e Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Server).Serve Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1721 +0x313 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 479 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb55f0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208223640, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208223640, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc2082235e0, 0xc208364000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080383b8, 0xc208364000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080383b8, 0xc20833e738, 0xc208364000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2083091c0, 0xc208364000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820cb40) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820cb40, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e6e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 480 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e6e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 559 [chan send]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 ",source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file,"Drone crashes when it tries to send build output to non-existing websocket I am running drone behing an AWS ELB in http mode, which means that websocket traffic is not supported. I do see `bad request` when I click on `follow` link in the build web console (which is expected). However, drone crashes when it tries to send build output back to a non-existing subscribed websocket client.  Nov 10 18:19:11 ip-10-0-0-62.ec2.internal docker[29236]: 2014/11/10 18:19:11 http: multiple response.WriteHeader calls Nov 10 18:20:19 ip-10-0-0-62.ec2.internal docker[29236]: starting build Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: 2014/11/10 18:20:27 http: multiple response.WriteHeader calls Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: panic: runtime error: send on closed channel Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 560 [running]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.panic(0xad8880, 0x111c49e) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.replay(0xc2082daee0, 0xc20814ed80, 0x45, 0x45) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/channel.go:115 +0xb2 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Channel).start Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/channel.go:79 +0x2c8 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 16 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb61a0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815ff00, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815ff00, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).accept(0xc20815fea0, 0xcdc1d8, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:409 +0x343 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*TCPListener).AcceptTCP(0xc208038250, 0x4ef463, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/tcpsock_posix.go:234 +0x5d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.tcpKeepAliveListener.Accept(0xc208038250, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1947 +0x4b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Server).Serve(0xc208005920, 0x7f902deb6798, 0xc208038250, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1698 +0x91 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Server).ListenAndServe(0xc208005920, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1688 +0x14d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.ListenAndServe(0x7fffab5eafc2, 0x3, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1778 +0x79 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: main.main() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/main.go:142 +0x92e Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 19 [finalizer wait, 7 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.park(0x491980, 0x1138d70, 0x11237e9) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.parkunlock(0x1138d70, 0x11237e9) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runfinq() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.goexit() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/proc.c:1445 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 22 [syscall, 7 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: os/signal.loop() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by os/signal.init1 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 24 [chan receive, 7 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: database/sql.(*DB).connectionOpener(0xc208050580) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/database/sql/sql.go:583 +0x48 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by database/sql.Open Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 17 [syscall, 7 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: runtime.goexit() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/proc.c:1445 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 129 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.(*Channel).start(0xc20824fb30) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/channel.go:64 +0x6f3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*PubSub).RegisterOpts Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/pubsub.go:59 +0x26b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 466 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5750, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208222450, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208222450, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc2082223f0, 0xc208312000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038240, 0xc208312000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038240, 0xc20833e1b8, 0xc208312000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc208308200, 0xc208312000, 0x1000, 0x1000, 0xc20836c050, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820c180) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820c180, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e160) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 218 [chan send, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 203 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5f90, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208355f00, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208355f00, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208355ea0, 0xc208410000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038d10, 0xc208410000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038d10, 0xc20833e5d8, 0xc208410000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc20817c2a0, 0xc208410000, 0x1000, 0x1000, 0xc20836c830, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820c6c0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820c6c0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e580) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 424 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.(*Channel).start(0xc2082ea640) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/channel.go:64 +0x6f3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*PubSub).RegisterOpts Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/pubsub.go:59 +0x26b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 467 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e160) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 142 [select, 4 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc208042160) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 141 [IO wait, 4 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5d80, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208171bf0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208171bf0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208171b90, 0xc20831c000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038880, 0xc20831c000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038880, 0xc2080421b8, 0xc20831c000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082da140, 0xc20831c000, 0x1000, 0x1000, 0xc208381130, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20831b3e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20831b3e0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc208042160) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 204 [select, 4 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e580) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal systemd[1]: drone@1.service: main process exited, code=exited, status=2/INVALIDARGUMENT Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 184 [chan send, 4 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 242 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb60f0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208354b50, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208354b50, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208354af0, 0xc20832e000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038400, 0xc20832e000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038400, 0xc20833f238, 0xc20832e000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082ca5e0, 0xc20832e000, 0x1000, 0x1000, 0xc20836da30, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc208376d80) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc208376d80, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f1e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 240 [chan send, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 243 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f1e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 388 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5e30, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc2081719c0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc2081719c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208171960, 0xc208313000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038c78, 0xc208313000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038c78, 0xc20833f708, 0xc208313000, 0x1000, 0x1000, 0xc2083a23c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082a6420, 0xc208313000, 0x1000, 0x1000, 0xc208380680, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2480) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2480, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f6b0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 246 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5ee0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208355170, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208355170, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208355110, 0xc208198000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080385d0, 0xc208198000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080385d0, 0xc20833f398, 0xc208198000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082cb7c0, 0xc208198000, 0x1000, 0x1000, 0xc2083800e0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc208377080) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc208377080, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f340) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 247 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f340) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 389 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f6b0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 250 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5cd0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208355950, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208355950, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc2083558f0, 0xc2081e8000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038750, 0xc2081e8000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038750, 0xc20833f4f8, 0xc2081e8000, 0x1000, 0x1000, 0xc2083772c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal systemd[1]: drone@1.service: control process exited, code=exited status=1 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal systemd[1]: Unit drone@1.service entered failed state. Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082cbf20, 0xc2081e8000, 0x1000, 0x1000, 0xc208380290, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc208377380) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc208377380, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f4a0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 251 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f4a0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 253 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5c20, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208355e90, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208355e90, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208355e30, 0xc208204000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080387a0, 0xc208204000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080387a0, 0xc20833f658, 0xc208204000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082bc160, 0xc208204000, 0x1000, 0x1000, 0xc2083804d0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083779e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083779e0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f600) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 254 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f600) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 395 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f810) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 394 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5ac0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815e6f0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815e6f0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc20815e690, 0xc208335000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038d28, 0xc208335000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038d28, 0xc20833f868, 0xc208335000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082a67c0, 0xc208335000, 0x1000, 0x1000, 0xc2083808c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2900) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2900, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f810) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 468 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).roundTrip(0xc20833e6e0, 0xc208428a30, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1015 +0x6db Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Transport).RoundTrip(0xc208430480, 0xc2083929c0, 0xd6, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:208 +0x49a Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.send(0xc2083929c0, 0x7f902deb46c8, 0xc208430480, 0xc208226e00, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/client.go:195 +0x43d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Client).send(0xc2083efa40, 0xc2083929c0, 0x6b, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/client.go:118 +0x15b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Client).doFollowingRedirects(0xc2083efa40, 0xc2083929c0, 0xcdc250, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/client.go:343 +0x97f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*Client).Do(0xc2083efa40, 0xc2083929c0, 0xc, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/client.go:153 +0x193 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.(*Client).do(0xc2081240f0, 0xb6b3d0, 0x4, 0xc20820c900, 0x51, 0x0, 0x0, 0x9539a0, 0xc2084289a8, 0x0, ) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/client.go:215 +0x45c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.(*ContainerService).Wait(0xc208038100, 0xc20838e700, 0x40, 0xc208430180, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/container.go:74 +0x19d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build.(*Builder).run(0xc208217300, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:415 +0x108f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build.func001() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:113 +0x32 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/shared/build.(*Builder).Run Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:114 +0x1fc Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 422 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build.(*Builder).Run(0xc208217300, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:117 +0x480 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/worker/docker.(*Docker).Do(0xc2080ee150, 0x7f902debb070, 0xc2082f2760, 0xc20837e060) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/worker/docker/docker.go:130 +0xb3c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/worker/director.(*Director).do(0xc208118240, 0x7f902debb070, 0xc2082f2760, 0xc20837e060) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/worker/director/director.go:55 +0xed Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/worker/director.(*Director).Do(0xc208118240, 0x7f902debb070, 0xc2082f2760, 0xc20837e060) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/worker/director/director.go:32 +0x59 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/worker.Do(0x7f902debb070, 0xc2082f2760, 0xc20837e060) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/worker/worker.go:14 +0x6d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/handler.PostHook Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/handler/hook.go:125 +0x8ce Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 431 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5960, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815ebc0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815ebc0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc20815eb60, 0xc20837b000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080388e0, 0xc20837b000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080388e0, 0xc20833ef78, 0xc20837b000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc20829e040, 0xc20837b000, 0x1000, 0x1000, 0xc2083729e0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2ae0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2ae0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833ef20) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 392 [select, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833f760) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 391 [IO wait, 2 minutes]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5b70, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815e140, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815e140, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc20815e0e0, 0xc208333000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038cd0, 0xc208333000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038cd0, 0xc20833f7b8, 0xc208333000, 0x1000, 0x1000, 0xc2083a2660, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2082a65c0, 0xc208333000, 0x1000, 0x1000, 0xc2083807a0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2720) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2720, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833f760) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 432 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833ef20) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 450 [chan send]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 435 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb58b0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc20815f3a0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc20815f3a0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc20815f340, 0xc20841d000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038980, 0xc20841d000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038980, 0xc20833f028, 0xc20841d000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc20829f140, 0xc20841d000, 0x1000, 0x1000, 0xc208372e60, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc2083a2d80) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc2083a2d80, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833efd0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 436 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833efd0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 472 [chan receive]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.(*Client).hijack(0xc2081240f0, 0xb6b3d0, 0x4, 0xc208222e00, 0x6f, 0xc208222e00, 0x7f902dec53a8, 0xc208308ea0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/client.go:287 +0x594 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.(*ContainerService).Attach(0xc208038100, 0xc20838e700, 0x40, 0x7f902dec53a8, 0xc208308ea0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/container.go:81 +0x15c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build.func002() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:404 +0xd0 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/shared/build.(*Builder).run Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/build.go:405 +0xf74 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 470 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5a10, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208222990, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208222990, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208222930, 0xc2083b6000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080382e8, 0xc2083b6000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080382e8, 0xc20833e318, 0xc2083b6000, 0x1000, 0x1000, 0x114ce80, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc208308d00, 0xc2083b6000, 0x1000, 0x1000, 0xc20836c680, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820c480) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820c480, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e2c0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 471 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e2c0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 476 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5800, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208222f40, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208222f40, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208222ee0, 0xc208432000, 0x8009, 0x8009, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038348, 0xc208432000, 0x8009, 0x8009, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Read(0xc20820c7e0, 0xc208432000, 0x8009, 0x8009, 0x8009, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:165 +0x13b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/docker/docker/pkg/stdcopy.StdCopy(0x7f902dec53a8, 0xc208308ea0, 0x7f902dec53a8, 0xc208308ea0, 0x7f902deb4e60, 0xc20820c7e0, 0x611, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/docker/docker/pkg/stdcopy/stdcopy.go:94 +0x16b Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/shared/build/docker.func002() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/client.go:280 +0x172 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/shared/build/docker.(*Client).hijack Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/shared/build/docker/client.go:284 +0x550 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 474 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb56a0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208222fb0, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208222fb0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc208222f50, 0xc20835f000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038350, 0xc20835f000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc208038350, 0xc20833e688, 0xc20835f000, 0x1000, 0x1000, 0xc20820c780, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc208308fc0, 0xc20835f000, 0x1000, 0x1000, 0xc20836c8c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820c8a0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820c8a0, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e630) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 475 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e630) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 557 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb5490, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208354610, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208354610, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc2083545b0, 0xc20817f000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc208038810, 0xc20817f000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*liveSwitchReader).Read(0xc208216ca8, 0xc20817f000, 0x1000, 0x1000, 0x7f902deb6508, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:206 +0xaf Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: io.(*LimitedReader).Read(0xc2082ed940, 0xc20817f000, 0x1000, 0x1000, 0xc2083388c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/io/io.go:399 +0xd0 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc208005a40) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).ReadSlice(0xc208005a40, 0xc208118f0a, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:298 +0x22c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).ReadLine(0xc208005a40, 0x0, 0x0, 0x0, 0x4a0000, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:326 +0x69 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/textproto.(*Reader).readLineSlice(0xc20838d200, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/textproto/reader.go:55 +0x9d Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/textproto.(*Reader).ReadLine(0xc20838d200, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/textproto/reader.go:36 +0x4e Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.ReadRequest(0xc208005a40, 0xc2083d16c0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/request.go:556 +0xc7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*conn).readRequest(0xc208216c80, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:577 +0x276 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*conn).serve(0xc208216c80) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1132 +0x61e Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Server).Serve Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/server.go:1721 +0x313 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 479 [IO wait]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.runtime_pollWait(0x7f902deb55f0, 0x72, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/runtime/netpoll.goc:146 +0x66 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).Wait(0xc208223640, 0x72, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:84 +0x46 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*pollDesc).WaitRead(0xc208223640, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_poll_runtime.go:89 +0x42 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*netFD).Read(0xc2082235e0, 0xc208364000, 0x1000, 0x1000, 0x0, 0x7f902deb44f8, 0xb) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/fd_unix.go:232 +0x34c Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net.(*conn).Read(0xc2080383b8, 0xc208364000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/net.go:122 +0xe7 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.noteEOFReader.Read(0x7f902deb6328, 0xc2080383b8, 0xc20833e738, 0xc208364000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:1203 +0x72 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*noteEOFReader).Read(0xc2083091c0, 0xc208364000, 0x1000, 0x1000, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: <autogenerated>:124 +0xca Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).fill(0xc20820cb40) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:97 +0x1b3 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: bufio.(*Reader).Peek(0xc20820cb40, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/bufio/bufio.go:132 +0x101 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).readLoop(0xc20833e6e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:782 +0x95 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:600 +0x93f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 480 [select]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: net/http.(*persistConn).writeLoop(0xc20833e6e0) Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:885 +0x38f Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by net/http.(*Transport).dialConn Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /usr/local/go/src/pkg/net/http/transport.go:601 +0x957 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: goroutine 559 [chan send]: Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: github.com/drone/drone/server/pubsub.func005() Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x45 Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: created by github.com/drone/drone/server/pubsub.(*Subscription).Close Nov 10 18:20:27 ip-10-0-0-62.ec2.internal docker[29236]: /var/cache/drone/src/github.com/drone/drone/server/pubsub/subscribe.go:23 +0x90  source-file source-file source-file test-file source-file source-file source-file source-file source-file",no-bug,0.9
178,harness,https://github.com/harness/harness/issues/178,Prevent accepting invite if already a team member,"Hi there, I somehow missed the point on how the User/Team feature worked on the OS version of Drone while deploying it at my company. Briefly, I was expecting that the initial admin account would be able to configure teams, and associate repositories to teams, (similar to what GitHub does). Here are the steps to reproduce the bug: 1. Invite user 2. User signs up though link 3. Delete user account 4. Create team 5. Invite user (same email used in step 1) 6. Following the link the user doesn't se the sign up form, only the login screen. Same thing occurred when using an incognito window in step 6.",source-file | documentation-file | other-file | other-file,"Prevent accepting invite if already a team member Hi there, I somehow missed the point on how the User/Team feature worked on the OS version of Drone while deploying it at my company. Briefly, I was expecting that the initial admin account would be able to configure teams, and associate repositories to teams, (similar to what GitHub does). Here are the steps to reproduce the bug: 1. Invite user 2. User signs up though link 3. Delete user account 4. Create team 5. Invite user (same email used in step 1) 6. Following the link the user doesn't se the sign up form, only the login screen. Same thing occurred when using an incognito window in step 6. source-file documentation-file other-file other-file",no-bug,0.8
2931,harness,https://github.com/harness/harness/issues/2931,Disabled repository still run cron jobs,"If you configure a cron job in a repository and next you disable it, the cron job still runs. Steps to reproduce: 1. Enable a repository 2. Make the first build 3. Enable an hourly cron job 4. Disable repository 5. Wait for next cron schedule 6. Voila! cron execute the job I think that if a repository is disabled, Drone should be disable cron jobs too.",source-file | source-file | source-file | source-file | source-file,"Disabled repository still run cron jobs If you configure a cron job in a repository and next you disable it, the cron job still runs. Steps to reproduce: 1. Enable a repository 2. Make the first build 3. Enable an hourly cron job 4. Disable repository 5. Wait for next cron schedule 6. Voila! cron execute the job I think that if a repository is disabled, Drone should be disable cron jobs too. source-file source-file source-file source-file source-file",no-bug,0.9
3414,harness,https://github.com/harness/harness/issues/3414,Does anyone know how to disable signing commits statuses for gitea?,I am searching the solution for disabling statuses. Sometimes I need to see clean commit without any signs in my Gitea branch. Thanks.,other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file,Does anyone know how to disable signing commits statuses for gitea? I am searching the solution for disabling statuses. Sometimes I need to see clean commit without any signs in my Gitea branch. Thanks. other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file,no-bug,0.9
159,harness,https://github.com/harness/harness/issues/159,Drone should support multiple projects per git repository,It'd be nice if I could have an arbitrary set of build targets that were tested individually by Drone. Some git repositories are large and contain many different components. It's helpful to know the specific component that is broken.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file,Drone should support multiple projects per git repository It'd be nice if I could have an arbitrary set of build targets that were tested individually by Drone. Some git repositories are large and contain many different components. It's helpful to know the specific component that is broken. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file,no-bug,0.9
220,harness,https://github.com/harness/harness/issues/220,Containers hang at random,"I've tested with 2 drone servers and at random, containers will hang and some point in a build and I'm forced to restart drone or kill the container. Anyone having this issue as well?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Containers hang at random I've tested with 2 drone servers and at random, containers will hang and some point in a build and I'm forced to restart drone or kill the container. Anyone having this issue as well? source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
594,harness,https://github.com/harness/harness/issues/594,Config parsing is failing,"config.Parse called in main.go during startup often fails with an no such flag error. `no such flag -github-secret` The exact flag it fails on varies by run, but this causes the env variables to be ignored and the app to often not start up at all.",other-file,"Config parsing is failing config.Parse called in main.go during startup often fails with an no such flag error. `no such flag -github-secret` The exact flag it fails on varies by run, but this causes the env variables to be ignored and the app to often not start up at all. other-file",no-bug,0.9
2742,harness,https://github.com/harness/harness/issues/2742,Error if port starts with tcp://,We should error and exit if DRONE_SERVER_PORT starts with `tcp://`. Kubernetes automatically injects environment variables that can sometimes conflict or override Drone environment variables. We should detect when this happens and provide an error message to help people debug and resolve the issue. further reading: https://discourse.drone.io/t/drone-server-changing-ports-protocol/4144,source-file | source-file | database-file | database-file | database-file | database-file | source-file,Error if port starts with tcp:// We should error and exit if DRONE_SERVER_PORT starts with `tcp://`. Kubernetes automatically injects environment variables that can sometimes conflict or override Drone environment variables. We should detect when this happens and provide an error message to help people debug and resolve the issue. further reading: https://discourse.drone.io/t/drone-server-changing-ports-protocol/4144 source-file source-file database-file database-file database-file database-file source-file,no-bug,0.8
2084,harness,https://github.com/harness/harness/issues/2084,Add version info in Drone webpage,Is possible add a page footer (or in account section under of sync list) that shows Drone version? Something like in [Gogs](https://try.gogs.io/) that says ` 2017 Gogs Versin: 0.11.22.0621`,source-file | other-file | other-file | source-file | database-file,Add version info in Drone webpage Is possible add a page footer (or in account section under of sync list) that shows Drone version? Something like in [Gogs](https://try.gogs.io/) that says ` 2017 Gogs Versin: 0.11.22.0621` source-file other-file other-file source-file database-file,no-bug,0.9
2775,harness,https://github.com/harness/harness/issues/2775,Update screenshots to drone 1.0 UI,screenshots in https://github.com/drone/brand/tree/master/screenshots which are referenced in README are from old UI. Would be nice to update to latest UI but not sure where to access the octocat/hello world examples to take screenshots of. Alternatively maybe take screenshots of the drone build itself?,source-file | source-file | source-file | source-file,Update screenshots to drone 1.0 UI screenshots in https://github.com/drone/brand/tree/master/screenshots which are referenced in README are from old UI. Would be nice to update to latest UI but not sure where to access the octocat/hello world examples to take screenshots of. Alternatively maybe take screenshots of the drone build itself? source-file source-file source-file source-file,no-bug,0.95
373,harness,https://github.com/harness/harness/issues/373,Unable to build on just pull requests,"Is there a way to build just on pull requests and not on commits? When I go on the GitHub side and uncheck Pus from the webhook, when it the webhook posts from a PR, GitHub gets a 400 error from Drone.",other-file,"Unable to build on just pull requests Is there a way to build just on pull requests and not on commits? When I go on the GitHub side and uncheck Pus from the webhook, when it the webhook posts from a PR, GitHub gets a 400 error from Drone. other-file",no-bug,0.9
3602,harness,https://github.com/harness/harness/issues/3602,Gitspace Container Network missing,"I get an error, when I try to create an gitspace. `177 13.12.2024 13:36:22 fatal: unable to access 'http://harness:3000/git/Test/Test.git/': Could not resolve host: harness` I set GITNESS_URL_CONTAINER and GITNESS_CI_CONTAINER_NETWORKS which works for the pipeline. So I suspect, that the container network isn't added to the gitspace container.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Gitspace Container Network missing I get an error, when I try to create an gitspace. `177 13.12.2024 13:36:22 fatal: unable to access 'http://harness:3000/git/Test/Test.git/': Could not resolve host: harness` I set GITNESS_URL_CONTAINER and GITNESS_CI_CONTAINER_NETWORKS which works for the pipeline. So I suspect, that the container network isn't added to the gitspace container. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
1174,harness,https://github.com/harness/harness/issues/1174,Hook up multi-Docker daemons,"Re-enable multiple docker daemons. Right now, for testing purposes, only a single daemon was enabled. Some initial implementation details documented here: http://readme.drone.io/docs/setup/#/docker.md",source-file | source-file,"Hook up multi-Docker daemons Re-enable multiple docker daemons. Right now, for testing purposes, only a single daemon was enabled. Some initial implementation details documented here: http://readme.drone.io/docs/setup/#/docker.md source-file source-file",no-bug,0.8
2372,harness,https://github.com/harness/harness/issues/2372,[Feature] Proposal: sub-directory projects,"Hi there! A lot of people lately have switched to using monolithic repositories, especially for microservice-based architectures. I developed a build / script runner that is fairly similar to a drone-agent. I'd love to move the functionality into Drone, and this would definitely bring something unique for Drone to the table. Here's what I propose: Let's say I have a single repository with multiple projects:  .  admin  errors.go  identity.go  internal  multicheck.go  models.go  sites  users  vendor  Where `users` and `admin` are totally separate projects. They are kept in the same repository, though, because changes to one will almost always include changes to the other. If they were separate, multiple PRs would be involved. There's also some shared code in `.` and `internal`, which needs to be tested. Example `.drone.yml`: yaml workspace: base: /go path: src/github.com/kminehart/drone services: database: image: cockroachdb/cockroach:v1.1.2 commands: - /cockroach/cockroach start --insecure pipeline: test: image: golang:1.10 commands: - make test publish: image: plugins/docker # These projects are individual directories in the source tree which will be tested by the pipeline # Any information like ""commands"", ""image"", ""environment"", etc. overrides what's defined by the pipeline. # If left blank, then it assumes whatever information was provided by the original pipeline definition. projects: root: path: ""."" pipeline: test: commands: - go test . admin: path: ""./admin"" pipeline: test: image: node:9.8 commands: - yarn install - yarn test publish: image: node:9.8 secrets: [ ssh_key, deploy_target ] commands: - yarn deploy internal: path: ""./internal"" users: path: ""./users""  What does everyone think of this? Some potential issues I see: * Artifacts * Caching",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[Feature] Proposal: sub-directory projects Hi there! A lot of people lately have switched to using monolithic repositories, especially for microservice-based architectures. I developed a build / script runner that is fairly similar to a drone-agent. I'd love to move the functionality into Drone, and this would definitely bring something unique for Drone to the table. Here's what I propose: Let's say I have a single repository with multiple projects:  .  admin  errors.go  identity.go  internal  multicheck.go  models.go  sites  users  vendor  Where `users` and `admin` are totally separate projects. They are kept in the same repository, though, because changes to one will almost always include changes to the other. If they were separate, multiple PRs would be involved. There's also some shared code in `.` and `internal`, which needs to be tested. Example `.drone.yml`: yaml workspace: base: /go path: src/github.com/kminehart/drone services: database: image: cockroachdb/cockroach:v1.1.2 commands: - /cockroach/cockroach start --insecure pipeline: test: image: golang:1.10 commands: - make test publish: image: plugins/docker # These projects are individual directories in the source tree which will be tested by the pipeline # Any information like ""commands"", ""image"", ""environment"", etc. overrides what's defined by the pipeline. # If left blank, then it assumes whatever information was provided by the original pipeline definition. projects: root: path: ""."" pipeline: test: commands: - go test . admin: path: ""./admin"" pipeline: test: image: node:9.8 commands: - yarn install - yarn test publish: image: node:9.8 secrets: [ ssh_key, deploy_target ] commands: - yarn deploy internal: path: ""./internal"" users: path: ""./users""  What does everyone think of this? Some potential issues I see: * Artifacts * Caching source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
2494,harness,https://github.com/harness/harness/issues/2494,Drone agent without volume,"I don't have permission to make host bind mounts so I need another way to connect to the docker daemon from within the drone-agent container as mounting `/var/run/docker.sock` is not possible:  failed to update service drone-ci_drone-agent: Error response from daemon: access denied: no access to Service Create with [Host Bind Mounts], Service Update, on collection xxxxxxxx-xxx-xxx-xxx-xxxxxxxxxxxx  I have tried to add environment variables `DOCKER_TLS_VERIFY`, `DOCKER_CERT_PATH` and most importantly `DOCKER_HOST` but it doesn't seem like this is supported. Is it possible to avoid using `/var/run/docker.sock` and use the `DOCKER_HOST` directly? I've searched half the day and couldn't find a satisfying answer. If this is a feature you want to add I might be able to provide a PR with some pointers.",database-file | database-file,"Drone agent without volume I don't have permission to make host bind mounts so I need another way to connect to the docker daemon from within the drone-agent container as mounting `/var/run/docker.sock` is not possible:  failed to update service drone-ci_drone-agent: Error response from daemon: access denied: no access to Service Create with [Host Bind Mounts], Service Update, on collection xxxxxxxx-xxx-xxx-xxx-xxxxxxxxxxxx  I have tried to add environment variables `DOCKER_TLS_VERIFY`, `DOCKER_CERT_PATH` and most importantly `DOCKER_HOST` but it doesn't seem like this is supported. Is it possible to avoid using `/var/run/docker.sock` and use the `DOCKER_HOST` directly? I've searched half the day and couldn't find a satisfying answer. If this is a feature you want to add I might be able to provide a PR with some pointers. database-file database-file",no-bug,0.9
2064,harness,https://github.com/harness/harness/issues/2064,RFC ignore branch whitelist for pull requests,"The yaml file has a branch filter: yaml pipeline: {} branches: - master - develop  I would like to consider ignoring this filter for pull request events. diff // verify the branches can be built vs skipped branches, err := yaml.ParseString(conf.Data) if err == nil { - if !branches.Branches.Match(build.Branch) { + if !branches.Branches.Match(build.Branch) && build.Event == model.EventPush { c.String(200, ""Branch does not match restrictions defined in yaml"") return } }  The reason is that teams _not_ using the github workflow (fork pull-request) will push to a branch with an open pull request, triggering two builds. This change in logic would allow a team to whitelist branches (e.g. master) and push to feature branches with an open pull request, while only triggering a single build for the pull request, and not a second for the push. _Note that merging the pull request would still trigger a build assuming it matches the branch whitelist_. I'm open to other solutions here as well  @jmccann @donny-dont @benschumacher hoping to get some thoughts. Does this make sense?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"RFC ignore branch whitelist for pull requests The yaml file has a branch filter: yaml pipeline: {} branches: - master - develop  I would like to consider ignoring this filter for pull request events. diff // verify the branches can be built vs skipped branches, err := yaml.ParseString(conf.Data) if err == nil { - if !branches.Branches.Match(build.Branch) { + if !branches.Branches.Match(build.Branch) && build.Event == model.EventPush { c.String(200, ""Branch does not match restrictions defined in yaml"") return } }  The reason is that teams _not_ using the github workflow (fork pull-request) will push to a branch with an open pull request, triggering two builds. This change in logic would allow a team to whitelist branches (e.g. master) and push to feature branches with an open pull request, while only triggering a single build for the pull request, and not a second for the push. _Note that merging the pull request would still trigger a build assuming it matches the branch whitelist_. I'm open to other solutions here as well  @jmccann @donny-dont @benschumacher hoping to get some thoughts. Does this make sense? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3565,harness,https://github.com/harness/harness/issues/3565,Rename GITNESS_URL_BASE to HARNESS_URL_BASE,In order to pass a custom dns name and other config you need to pass environment variables  they are here https://github.com/harness/harness/blob/077256b69c16ebe26ae7c85284ef6b3101bd3c80/types/config.go#L57 and they still refer to GITNESS instead of HARNESS I suggest to correct that ;),other-file,Rename GITNESS_URL_BASE to HARNESS_URL_BASE In order to pass a custom dns name and other config you need to pass environment variables  they are here https://github.com/harness/harness/blob/077256b69c16ebe26ae7c85284ef6b3101bd3c80/types/config.go#L57 and they still refer to GITNESS instead of HARNESS I suggest to correct that ;) other-file,no-bug,0.9
445,harness,https://github.com/harness/harness/issues/445,/usr/local/bin/drone: line 47: unexpected EOF while looking for matching `'',"I think this may be related to https://github.com/drone/drone/issues/370 I uploaded an incorrectly formated .drone.yml file. I corrected it. I verified it with PyYaml. I've even removed it down to the basic  image: bradrydzewski/python:2.7 script: - echo passed.  because I thought my issues were caused by the file. I've deleted all docker images on the system and rebooted. Every build fails with some variation of the following output:  $ git clone --depth=50 --recursive --branch=master git@bitbucket.org:foo/bar.git /var/cache/drone/src/bitbucket.org/foo/bar Cloning into '/var/cache/drone/src/bitbucket.org/foo/bar' Warning: Permanently added 'bitbucket.org,131.103.20.168' (RSA) to the list of known hosts. $ git checkout -qf somecommit /usr/local/bin/drone: line 47: unexpected EOF while looking for matching `''  or  $ git clone --depth=50 --recursive --branch=master git@bitbucket.org:foo/bar.git /var/cache/drone/src/bitbucket.org/foo/bar Cloning into '/var/cache/drone/src/bitbucket.org/foo/bar' Warning: Permanently added 'bitbucket.org,131.103.20.167' (RSA) to the list of known hosts. $ git checkout -qf anothercommit /usr/local/bin/drone: line 56: unexpected EOF while looking for matching `""'  I am lost with the error message.",source-file | source-file | source-file | source-file | source-file | source-file,"/usr/local/bin/drone: line 47: unexpected EOF while looking for matching `'' I think this may be related to https://github.com/drone/drone/issues/370 I uploaded an incorrectly formated .drone.yml file. I corrected it. I verified it with PyYaml. I've even removed it down to the basic  image: bradrydzewski/python:2.7 script: - echo passed.  because I thought my issues were caused by the file. I've deleted all docker images on the system and rebooted. Every build fails with some variation of the following output:  $ git clone --depth=50 --recursive --branch=master git@bitbucket.org:foo/bar.git /var/cache/drone/src/bitbucket.org/foo/bar Cloning into '/var/cache/drone/src/bitbucket.org/foo/bar' Warning: Permanently added 'bitbucket.org,131.103.20.168' (RSA) to the list of known hosts. $ git checkout -qf somecommit /usr/local/bin/drone: line 47: unexpected EOF while looking for matching `''  or  $ git clone --depth=50 --recursive --branch=master git@bitbucket.org:foo/bar.git /var/cache/drone/src/bitbucket.org/foo/bar Cloning into '/var/cache/drone/src/bitbucket.org/foo/bar' Warning: Permanently added 'bitbucket.org,131.103.20.167' (RSA) to the list of known hosts. $ git checkout -qf anothercommit /usr/local/bin/drone: line 56: unexpected EOF while looking for matching `""'  I am lost with the error message. source-file source-file source-file source-file source-file source-file",no-bug,0.95
55,harness,https://github.com/harness/harness/issues/55,Local repository cache,"Cloning a large repository can take a long (build) time, we should do something like:  if [ -d $repository_path ] cd $repository_path && git fetch $remote && git reset --hard $branch else git clone $repo $repository_path ",other-file | test-file | test-file | other-file | other-file | source-file | source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file,"Local repository cache Cloning a large repository can take a long (build) time, we should do something like:  if [ -d $repository_path ] cd $repository_path && git fetch $remote && git reset --hard $branch else git clone $repo $repository_path  other-file test-file test-file other-file other-file source-file source-file source-file documentation-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file source-file other-file source-file other-file source-file source-file other-file source-file other-file other-file source-file other-file",no-bug,0.95
920,harness,https://github.com/harness/harness/issues/920,Wrong build status in readme,"Hi, Especially in Maven multi-module projects (not sure, if that's a reason) I constantly see the status badge like https://drone.io/github.com/unitsofmeasurement/uom-tools/admin/badges failing in the Readme: https://github.com/unitsofmeasurement/uom-tools/blob/master/README.md although the build is passing. TIA, Werner",other-file | other-file | other-file,"Wrong build status in readme Hi, Especially in Maven multi-module projects (not sure, if that's a reason) I constantly see the status badge like https://drone.io/github.com/unitsofmeasurement/uom-tools/admin/badges failing in the Readme: https://github.com/unitsofmeasurement/uom-tools/blob/master/README.md although the build is passing. TIA, Werner other-file other-file other-file",no-bug,0.9
2922,harness,https://github.com/harness/harness/issues/2922,Does Drone's Postgres client library support scram-sha-256?,"I setup Drone successfully on Docker using the built-in SQLite database. I then tried to setup Drone again (deleting all old volumes), but changed the database to use Postgres. Nothing else changed except the database connection. When starting the Drone docker container, I get this in the logs over and over.  {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:04:47Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:05:19Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:05:50Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:06:22Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:06:54Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:07:26Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:07:57Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:08:29Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:09:01Z""},  A quick Google shows this is due to my use of [scram-sha-256 in Postgres](https://www.postgresql.org/docs/11/auth-password.html) instead of MD5. I can confirm this because when I switched my Drone database user in Postgres to MD5, Drone started without issue. I see that you're using [pq](https://github.com/lib/pq), and it looks like pq added support for scram-sha-256 in [v1.1.0](https://github.com/lib/pq/releases/tag/v1.1.0). I don't know anything about the Go language, but does [this file](https://github.com/drone/drone/blob/ad6be2073b8f8bd935a4dda9aaf9a449f3d2d000/go.mod) mean you're using v1.0.0? If so, can you update to v.1.1.0?",source-file | source-file,"Does Drone's Postgres client library support scram-sha-256? I setup Drone successfully on Docker using the built-in SQLite database. I then tried to setup Drone again (deleting all old volumes), but changed the database to use Postgres. Nothing else changed except the database connection. When starting the Drone docker container, I get this in the logs over and over.  {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:04:47Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:05:19Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:05:50Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:06:22Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:06:54Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:07:26Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:07:57Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:08:29Z""}, {""error"":""pq: unknown authentication response: 10"",""level"":""fatal"",""msg"":""main: cannot initialize server"",""time"":""2020-02-18T14:09:01Z""},  A quick Google shows this is due to my use of [scram-sha-256 in Postgres](https://www.postgresql.org/docs/11/auth-password.html) instead of MD5. I can confirm this because when I switched my Drone database user in Postgres to MD5, Drone started without issue. I see that you're using [pq](https://github.com/lib/pq), and it looks like pq added support for scram-sha-256 in [v1.1.0](https://github.com/lib/pq/releases/tag/v1.1.0). I don't know anything about the Go language, but does [this file](https://github.com/drone/drone/blob/ad6be2073b8f8bd935a4dda9aaf9a449f3d2d000/go.mod) mean you're using v1.0.0? If so, can you update to v.1.1.0? source-file source-file",no-bug,0.9
434,harness,https://github.com/harness/harness/issues/434,No commits appearing?,"On a digitalocean droplet, I run the setup,  wget http://downloads.drone.io/latest/drone.deb sudo dpkg -i drone.deb sudo start drone  go to http://<my-ip>:80/install and do the install, adding a new Github OAuth app with client and secret key, and with the homepage URL to http://$YOUR_IP_ADDRESS/ and the callback URL to http://$YOUR_IP_ADDRESS/auth/login/github So far so good. I go to add a Github repo, everything looks okay, but I don't see any commits. What have I missed and how can I debug? (I can confirm that the `.drone.yml` is working with `drone -v build .`, and it seems to run fine.)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | documentation-file,"No commits appearing? On a digitalocean droplet, I run the setup,  wget http://downloads.drone.io/latest/drone.deb sudo dpkg -i drone.deb sudo start drone  go to http://<my-ip>:80/install and do the install, adding a new Github OAuth app with client and secret key, and with the homepage URL to http://$YOUR_IP_ADDRESS/ and the callback URL to http://$YOUR_IP_ADDRESS/auth/login/github So far so good. I go to add a Github repo, everything looks okay, but I don't see any commits. What have I missed and how can I debug? (I can confirm that the `.drone.yml` is working with `drone -v build .`, and it seems to run fine.) source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file documentation-file",no-bug,0.8
2729,harness,https://github.com/harness/harness/issues/2729,"In a pull_request event, DRONE_COMMIT_MESSAGE is using the description instead of the title","I am using GitHub with Drone 1.1 and I have some logic similar to [CI SKIP] bound to the pull request title. As far as I understand, drone uses the pull request title for `DRONE_COMMIT_MESSAGE` in case of `pull_request` events. Everything works well when the pull request description is empty, but as soon as I add a description, it gets set to `DRONE_COMMIT_MESSAGE`. Interestingly, the pull request title is still shown in the drone UI. `env` doesn't show any variable which would still contain the pull request title.",other-file | other-file,"In a pull_request event, DRONE_COMMIT_MESSAGE is using the description instead of the title I am using GitHub with Drone 1.1 and I have some logic similar to [CI SKIP] bound to the pull request title. As far as I understand, drone uses the pull request title for `DRONE_COMMIT_MESSAGE` in case of `pull_request` events. Everything works well when the pull request description is empty, but as soon as I add a description, it gets set to `DRONE_COMMIT_MESSAGE`. Interestingly, the pull request title is still shown in the drone UI. `env` doesn't show any variable which would still contain the pull request title. other-file other-file",no-bug,0.9
940,harness,https://github.com/harness/harness/issues/940,Drone - Build failed -Maximum Build time exceeded..,Drone build failed with the message 'Maximum build time exceeded' after 15minutes. How can i increase the build time in drone? I could not find any setting in drone to set the build time. Please help.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file,Drone - Build failed -Maximum Build time exceeded.. Drone build failed with the message 'Maximum build time exceeded' after 15minutes. How can i increase the build time in drone? I could not find any setting in drone to set the build time. Please help. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file,no-bug,0.95
2702,harness,https://github.com/harness/harness/issues/2702,non-interactive metrics access,"I'm playing with autoscaling drone agents. Everything I need is available from the API at `api/system/stats`. The trouble is, in order to access this information, I need to log into drone to collect my oauth token so that I can paste it into a script and make the request. That's a manual step that I want to avoid. I could use the new `DRONE_PROMETHEUS_ANONYMOUS_ACCESS` which also has the info I need, but I'd rather not expose that publicly. Here are some ideas I've had: 1. Use `DRONE_USER_CREATE` to specify the token of a new user so that I know it in advance what the token is. I tried this, but it turns out the token actually does not set the `user_oauth_token` field, but the `user_hash` field instead. Is that intentional? Either way it would be nice to be able to do this somehow. 2. Dig a token directly out of the database. I was thinking of doing this, but it seems if I'm going to go that far, I may as well skip that step and dig the stats I need directly out of the database instead. I can do this but it isn't awesome. 3. Add a new HTTP listener to the drone server which serves some bits of the app (maybe parts of the API) on a separate port without requiring authentication so that I can expose it only privately.",source-file | source-file | source-file | source-file | other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | documentation-file,"non-interactive metrics access I'm playing with autoscaling drone agents. Everything I need is available from the API at `api/system/stats`. The trouble is, in order to access this information, I need to log into drone to collect my oauth token so that I can paste it into a script and make the request. That's a manual step that I want to avoid. I could use the new `DRONE_PROMETHEUS_ANONYMOUS_ACCESS` which also has the info I need, but I'd rather not expose that publicly. Here are some ideas I've had: 1. Use `DRONE_USER_CREATE` to specify the token of a new user so that I know it in advance what the token is. I tried this, but it turns out the token actually does not set the `user_oauth_token` field, but the `user_hash` field instead. Is that intentional? Either way it would be nice to be able to do this somehow. 2. Dig a token directly out of the database. I was thinking of doing this, but it seems if I'm going to go that far, I may as well skip that step and dig the stats I need directly out of the database instead. I can do this but it isn't awesome. 3. Add a new HTTP listener to the drone server which serves some bits of the app (maybe parts of the API) on a separate port without requiring authentication so that I can expose it only privately. source-file source-file source-file source-file other-file source-file documentation-file other-file other-file other-file other-file other-file documentation-file",no-bug,0.85
1091,harness,https://github.com/harness/harness/issues/1091,Cannot connect to services image,"Hi, I am writing .drone.yml as:  image: ""bradrydzewski/ruby:2.0.0"" env: - RAILS_ENV=test script: - pwd - whoami - rbenv versions - lsof -P | grep TCP - ps -ef | grep socat - mysql -uroot -h127.0.0.1 -P3306 -e 'show databases' services: - mysql - redis  but mysql connection fails. The output of drone console is as follows:  $ whoami ubuntu $ rbenv versions * 2.0.0-p353 (set by RBENV_VERSION environment variable) $ lsof -P | grep TCP socat 42 ubuntu 3u IPv4 458517 0t0 TCP *:3306 (LISTEN) socat 43 ubuntu 3u IPv4 458519 0t0 TCP *:6379 (LISTEN) $ ps -ef | grep socat ubuntu 42 40 0 02:36 ? 00:00:00 socat TCP-LISTEN:6379,fork TCP:192.168.5.107:6379 ubuntu 43 39 0 02:36 ? 00:00:00 socat TCP-LISTEN:3306,fork TCP:192.168.5.106:3306 $ mysql -uroot -h127.0.0.1 -P3306 -e 'show databases' 2015/07/10 02:16:39 socat[221] E connect(3, AF=2 192.168.5.106:3306, 16): No route to host ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0  Can you tell me how to troubleshoot this? On host OS, iptables -L tell like this:  $ iptables -t nat -L -n Chain PREROUTING (policy ACCEPT) target prot opt source destination DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCAL Chain INPUT (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination DOCKER all -- 0.0.0.0/0 !127.0.0.0/8 ADDRTYPE match dst-type LOCAL Chain POSTROUTING (policy ACCEPT) target prot opt source destination MASQUERADE all -- 192.168.5.0/24 0.0.0.0/0 MASQUERADE tcp -- 192.168.5.106 192.168.5.106 tcp dpt:3306 MASQUERADE tcp -- 192.168.5.107 192.168.5.107 tcp dpt:6379 Chain DOCKER (2 references) target prot opt source destination DNAT tcp -- 0.0.0.0/0 127.0.0.1 tcp dpt:32810 to:192.168.5.106:3306 DNAT tcp -- 0.0.0.0/0 127.0.0.1 tcp dpt:32811 to:192.168.5.107:6379   $ ps -ef | grep docker root 13552 14675 0 10:37 ? 00:00:00 docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32800 -container-ip 192.168.5.106 -container-port 3306 root 13650 14675 0 10:37 ? 00:00:00 docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32801 -container-ip 192.168.5.107 -container-port 6379  The information of host os is as follows:  $ cat /etc/redhat-release CentOS Linux release 7.1.1503 (Core) $ uname -a Linux xxxxxx 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux $ rpm -qa | grep drone drone-0.3.0_alpha-1435875221.x86_64 $ docker --version Docker version 1.7.0, build 0baf609  If you need some more information, please let me know. thanks",other-file,"Cannot connect to services image Hi, I am writing .drone.yml as:  image: ""bradrydzewski/ruby:2.0.0"" env: - RAILS_ENV=test script: - pwd - whoami - rbenv versions - lsof -P | grep TCP - ps -ef | grep socat - mysql -uroot -h127.0.0.1 -P3306 -e 'show databases' services: - mysql - redis  but mysql connection fails. The output of drone console is as follows:  $ whoami ubuntu $ rbenv versions * 2.0.0-p353 (set by RBENV_VERSION environment variable) $ lsof -P | grep TCP socat 42 ubuntu 3u IPv4 458517 0t0 TCP *:3306 (LISTEN) socat 43 ubuntu 3u IPv4 458519 0t0 TCP *:6379 (LISTEN) $ ps -ef | grep socat ubuntu 42 40 0 02:36 ? 00:00:00 socat TCP-LISTEN:6379,fork TCP:192.168.5.107:6379 ubuntu 43 39 0 02:36 ? 00:00:00 socat TCP-LISTEN:3306,fork TCP:192.168.5.106:3306 $ mysql -uroot -h127.0.0.1 -P3306 -e 'show databases' 2015/07/10 02:16:39 socat[221] E connect(3, AF=2 192.168.5.106:3306, 16): No route to host ERROR 2013 (HY000): Lost connection to MySQL server at 'reading initial communication packet', system error: 0  Can you tell me how to troubleshoot this? On host OS, iptables -L tell like this:  $ iptables -t nat -L -n Chain PREROUTING (policy ACCEPT) target prot opt source destination DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCAL Chain INPUT (policy ACCEPT) target prot opt source destination Chain OUTPUT (policy ACCEPT) target prot opt source destination DOCKER all -- 0.0.0.0/0 !127.0.0.0/8 ADDRTYPE match dst-type LOCAL Chain POSTROUTING (policy ACCEPT) target prot opt source destination MASQUERADE all -- 192.168.5.0/24 0.0.0.0/0 MASQUERADE tcp -- 192.168.5.106 192.168.5.106 tcp dpt:3306 MASQUERADE tcp -- 192.168.5.107 192.168.5.107 tcp dpt:6379 Chain DOCKER (2 references) target prot opt source destination DNAT tcp -- 0.0.0.0/0 127.0.0.1 tcp dpt:32810 to:192.168.5.106:3306 DNAT tcp -- 0.0.0.0/0 127.0.0.1 tcp dpt:32811 to:192.168.5.107:6379   $ ps -ef | grep docker root 13552 14675 0 10:37 ? 00:00:00 docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32800 -container-ip 192.168.5.106 -container-port 3306 root 13650 14675 0 10:37 ? 00:00:00 docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32801 -container-ip 192.168.5.107 -container-port 6379  The information of host os is as follows:  $ cat /etc/redhat-release CentOS Linux release 7.1.1503 (Core) $ uname -a Linux xxxxxx 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux $ rpm -qa | grep drone drone-0.3.0_alpha-1435875221.x86_64 $ docker --version Docker version 1.7.0, build 0baf609  If you need some more information, please let me know. thanks other-file",no-bug,0.95
2534,harness,https://github.com/harness/harness/issues/2534,404 on README get-help link,The last link on the README leads to a 404. Just thought you'd want to know.,documentation-file,404 on README get-help link The last link on the README leads to a 404. Just thought you'd want to know. documentation-file,no-bug,0.9
3611,harness,https://github.com/harness/harness/issues/3611,Stage '' not found in build file : resource not found when drone exec type exec?,"Hi, Use only drone-cli in local from doc https://docs.drone.io/quickstart/cli/ install drone-cli  brew install drone-cli  Use the following .drone.yml:  kind: pipeline type: docker name: default steps: - name: test image: alpine commands: - echo hello - echo world  run is ok  drone exec  But got failed when update type: exec  kind: pipeline type: exec # just update name: default steps: - name: test image: alpine commands: - echo hello - echo world  got failed  Stage '' not found in build file : resource not found exit status 1  How to determine what resource are missing? Or what should be done?",other-file | source-file,"Stage '' not found in build file : resource not found when drone exec type exec? Hi, Use only drone-cli in local from doc https://docs.drone.io/quickstart/cli/ install drone-cli  brew install drone-cli  Use the following .drone.yml:  kind: pipeline type: docker name: default steps: - name: test image: alpine commands: - echo hello - echo world  run is ok  drone exec  But got failed when update type: exec  kind: pipeline type: exec # just update name: default steps: - name: test image: alpine commands: - echo hello - echo world  got failed  Stage '' not found in build file : resource not found exit status 1  How to determine what resource are missing? Or what should be done? other-file source-file",no-bug,0.9
825,harness,https://github.com/harness/harness/issues/825,Drone killed build,"Hi I have been trying out drone by setting it up using vagrant and an ubuntu 14.04 image. I managed to get everything running but it seems my builds keeps getting killed,  /usr/local/bin/drone: line 82: 48 Killed bundle install  This is always right around the 4-5m mark. The part it gets killed at usually takes awhile as its installing native dependencies but I haven't been able to get a successful build in drone. I tried increasing the timeout to some ridiculous setting but that didn't do anything. I also don't see anything in the drone or docker logs that might help. I'm running version 0.3.0-alpha.",source-file | source-file | source-file | source-file,"Drone killed build Hi I have been trying out drone by setting it up using vagrant and an ubuntu 14.04 image. I managed to get everything running but it seems my builds keeps getting killed,  /usr/local/bin/drone: line 82: 48 Killed bundle install  This is always right around the 4-5m mark. The part it gets killed at usually takes awhile as its installing native dependencies but I haven't been able to get a successful build in drone. I tried increasing the timeout to some ridiculous setting but that didn't do anything. I also don't see anything in the drone or docker logs that might help. I'm running version 0.3.0-alpha. source-file source-file source-file source-file",no-bug,0.9
1208,harness,https://github.com/harness/harness/issues/1208,"Unable to fetch .drone.yml file, from gitlab","Hi, I am using drone.io + (custom) gitlab integration for some time, but it suddenly stopped to work for new repos I created. When the gitlab call drone hook to start build, the following is written to drone.log:  Unable to fetch .drone.yml file. *Gitlab.buildAndExecRequestRaw failed: <404>  Ok, it can be an auth/authz issue. However builds (ci runs) works for existing repo, already configured in drone. I have tried to use new ClientID for gitlab, netrc + add drone user to group, delete repo + reactivate on drone site - same behavior. Still not work only for new repos. Also I do not see any issues on Gitlab side, so it seems to me that drone.io fetch for .drone.yml fails silently which cause interruption during the build. Can you give me any guidance how to debug deeply whats going on, what auth/authz are being used. Thanks in advance.",documentation-file | other-file | other-file | other-file | other-file | other-file,"Unable to fetch .drone.yml file, from gitlab Hi, I am using drone.io + (custom) gitlab integration for some time, but it suddenly stopped to work for new repos I created. When the gitlab call drone hook to start build, the following is written to drone.log:  Unable to fetch .drone.yml file. *Gitlab.buildAndExecRequestRaw failed: <404>  Ok, it can be an auth/authz issue. However builds (ci runs) works for existing repo, already configured in drone. I have tried to use new ClientID for gitlab, netrc + add drone user to group, delete repo + reactivate on drone site - same behavior. Still not work only for new repos. Also I do not see any issues on Gitlab side, so it seems to me that drone.io fetch for .drone.yml fails silently which cause interruption during the build. Can you give me any guidance how to debug deeply whats going on, what auth/authz are being used. Thanks in advance. documentation-file other-file other-file other-file other-file other-file",no-bug,0.9
1775,harness,https://github.com/harness/harness/issues/1775,expose errors in oauth2 authorization code grant,"Right now when the oauth2 provider (ie Bitbucket) fails to grant an authorization code an `error` query parameter is returned, as defined in the oauth2 specification: https://tools.ietf.org/html/rfc6749#section-4.1.2.1 Drone currently looks for the `code` and re-directs, without checking for the `error` query parameter. In error scenarios (misconfiguration for example) this can result in redirect loops, and by not catching and exposing the error it can be difficult to debug. We should therefore start catching and returning the error. This is the block of code: https://github.com/drone/drone/blob/master/remote/bitbucket/bitbucket.go#L46:L50 Which could be adjusted to something like this:  diff package bitbucket import ( + ""errors"" ""fmt"" ""net/http"" ""net/url""   diff code := r.FormValue(""code"") + if err := r.FormValue(""error""); err != """" { + return nil, errors.New(err) + } if len(code) == 0 { http.Redirect(w, r, config.AuthCodeURL(""drone""), http.StatusSeeOther) return nil, nil }  Note that this should be adjusted in both the GitHub and Bitbucket implementations.",source-file | test-file | source-file | source-file | test-file | source-file | source-file,"expose errors in oauth2 authorization code grant Right now when the oauth2 provider (ie Bitbucket) fails to grant an authorization code an `error` query parameter is returned, as defined in the oauth2 specification: https://tools.ietf.org/html/rfc6749#section-4.1.2.1 Drone currently looks for the `code` and re-directs, without checking for the `error` query parameter. In error scenarios (misconfiguration for example) this can result in redirect loops, and by not catching and exposing the error it can be difficult to debug. We should therefore start catching and returning the error. This is the block of code: https://github.com/drone/drone/blob/master/remote/bitbucket/bitbucket.go#L46:L50 Which could be adjusted to something like this:  diff package bitbucket import ( + ""errors"" ""fmt"" ""net/http"" ""net/url""   diff code := r.FormValue(""code"") + if err := r.FormValue(""error""); err != """" { + return nil, errors.New(err) + } if len(code) == 0 { http.Redirect(w, r, config.AuthCodeURL(""drone""), http.StatusSeeOther) return nil, nil }  Note that this should be adjusted in both the GitHub and Bitbucket implementations. source-file test-file source-file source-file test-file source-file source-file",bug,0.9
3248,harness,https://github.com/harness/harness/issues/3248,Port forwarding,"I have this .drone.yml:  kind: pipeline name: default type: docker steps: - name: install_requirements image: python commands: - pip install -r requirements.txt - python main.py ports: - port expose: - 7632  I want to start fastapi/uvicorn app, but I need to forward ports(-p 7632:7632 in docker cli) to access the server. What should I do to solve this problem?",source-file | source-file | source-file | other-file | source-file | source-file | source-file,"Port forwarding I have this .drone.yml:  kind: pipeline name: default type: docker steps: - name: install_requirements image: python commands: - pip install -r requirements.txt - python main.py ports: - port expose: - 7632  I want to start fastapi/uvicorn app, but I need to forward ports(-p 7632:7632 in docker cli) to access the server. What should I do to solve this problem? source-file source-file source-file other-file source-file source-file source-file",no-bug,0.9
3015,harness,https://github.com/harness/harness/issues/3015,Secrets can be deleted and created by non admins,"Hello, So currently Drone allows secrets to be created and deleted by nonadmins to project. This is a security risk in my opinion where a malicious developer can inject some false secrets to the project and then deploy. I've created a PR to fix the issue. Currently, this is a big issue with one of my customer's teams where they require more RBAC like of control of their project.",other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | test-file | test-file | test-file | test-file | other-file | source-file | other-file | source-file | source-file | documentation-file | source-file,"Secrets can be deleted and created by non admins Hello, So currently Drone allows secrets to be created and deleted by nonadmins to project. This is a security risk in my opinion where a malicious developer can inject some false secrets to the project and then deploy. I've created a PR to fix the issue. Currently, this is a big issue with one of my customer's teams where they require more RBAC like of control of their project. other-file source-file other-file other-file source-file other-file other-file other-file source-file other-file other-file source-file other-file other-file test-file test-file test-file test-file other-file source-file other-file source-file source-file documentation-file source-file",no-bug,0.9
2705,harness,https://github.com/harness/harness/issues/2705,Distinct event trigger for Cron pipelines,"I can't skip some pipelines/steps during cron scheduling. When I use cron jobs, I can set pipeline trigger with cronjob name to include this pipline during cron execution.  trigger: cron: ['cron']  But I can't exclude some pipelines/steps from all cronjobs. I tried to use something like  trigger: cron: exclude: '*'  to exclude cronjobs from common pipelines for pushing code to repo. But when i commit to repo, I'm getting `trigger: skipping pipeline, does not match cron job`. It would be nice to add event type 'cron' to avoid this problem. I think it'll look like  trigger: event: exclude: 'cron'  Thanks",source-file,"Distinct event trigger for Cron pipelines I can't skip some pipelines/steps during cron scheduling. When I use cron jobs, I can set pipeline trigger with cronjob name to include this pipline during cron execution.  trigger: cron: ['cron']  But I can't exclude some pipelines/steps from all cronjobs. I tried to use something like  trigger: cron: exclude: '*'  to exclude cronjobs from common pipelines for pushing code to repo. But when i commit to repo, I'm getting `trigger: skipping pipeline, does not match cron job`. It would be nice to add event type 'cron' to avoid this problem. I think it'll look like  trigger: event: exclude: 'cron'  Thanks source-file",no-bug,0.8
368,harness,https://github.com/harness/harness/issues/368,"BitBucket hook ok, but no commits in drone","I installed drone on ubuntu 12.04, with commands wget http://downloads.drone.io/latest/drone.deb and sudo dpkg -i drone.deb. Setup was easy, I tried to add a public github project, that worked, I see commits coming in. Now I tried to add private bitbucket repo, that's not working. I see the hook in bitbucket http://cl.ly/image/2p3i2y2l0Q26, but I don't see the commits coming in I authorized oauth access on the team account so that's ok. I think maybe the version of drone I am running is maybe too old (March 17)? Can I see some logging somewhere maybe? Let me know",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"BitBucket hook ok, but no commits in drone I installed drone on ubuntu 12.04, with commands wget http://downloads.drone.io/latest/drone.deb and sudo dpkg -i drone.deb. Setup was easy, I tried to add a public github project, that worked, I see commits coming in. Now I tried to add private bitbucket repo, that's not working. I see the hook in bitbucket http://cl.ly/image/2p3i2y2l0Q26, but I don't see the commits coming in I authorized oauth access on the team account so that's ok. I think maybe the version of drone I am running is maybe too old (March 17)? Can I see some logging somewhere maybe? Let me know source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2022,harness,https://github.com/harness/harness/issues/2022,drone may restart previously finished builds on startup,"The build queue is persisted so that on restart we can re-queue pending builds. When a build is pulled from the queue it is deleted from the datastore. This doesn't seem to be working properly. As a result, when you restart drone, builds that have already finished might still be re-queued and re-executed. The impacts the 0.6 release candidate. Note that I only encountered this issue once and have been unable to repeat since. I will monitor closely over the next few days and report back.",source-file | source-file | source-file,"drone may restart previously finished builds on startup The build queue is persisted so that on restart we can re-queue pending builds. When a build is pulled from the queue it is deleted from the datastore. This doesn't seem to be working properly. As a result, when you restart drone, builds that have already finished might still be re-queued and re-executed. The impacts the 0.6 release candidate. Note that I only encountered this issue once and have been unable to repeat since. I will monitor closely over the next few days and report back. source-file source-file source-file",no-bug,0.9
979,harness,https://github.com/harness/harness/issues/979,Refresh repository values on hook,"Hi Using v 7.9.1 of gitlab (local) Have changes all referenses to hostname in gitlab, but drone seems to still use old hostname. Any way to make drone reload values from gitlab? Syncing is not changing the hostname. If hostname is not a value from gitlab, any way to set it manually? ![image](https://cloud.githubusercontent.com/assets/8895450/7180381/77bfca06-e441-11e4-8861-4da68ecb1ff0.png) ![image](https://cloud.githubusercontent.com/assets/8895450/7180395/9bb666e0-e441-11e4-9c1c-5f140f31defd.png) A",source-file,"Refresh repository values on hook Hi Using v 7.9.1 of gitlab (local) Have changes all referenses to hostname in gitlab, but drone seems to still use old hostname. Any way to make drone reload values from gitlab? Syncing is not changing the hostname. If hostname is not a value from gitlab, any way to set it manually? ![image](https://cloud.githubusercontent.com/assets/8895450/7180381/77bfca06-e441-11e4-8861-4da68ecb1ff0.png) ![image](https://cloud.githubusercontent.com/assets/8895450/7180395/9bb666e0-e441-11e4-9c1c-5f140f31defd.png) A source-file",no-bug,0.8
2417,harness,https://github.com/harness/harness/issues/2417,+refs/pull/<ID>/merge: not update after rebase and force push,"We have a problem with force-push. The essence can be understood from the correspondence with github support.  Greetings! Github have a bug when we doing rebase and force push. With 90% of cases the special branch `+refs/pull/<ID>/merge:` are not updated or update after some long time. The live example of that situation we have prepared at https://github.com/abak-press/apress-demands/pull/256 Right now it is reproduced in our CI and locally. Latest commit in a PR have ref de9ed321028b3338ec19689274ee596234c08d24 But doing this locally right now (and about during 30 minutes):  $ git init Initialized empty Git repository in /home/merkushin/code/tmp/demands-remove/.git/ $ git fetch --no-tags origin +refs/pull/256/merge: $ git checkout -qf FETCH_HEAD $ git log -2 commit 16aaa6d3f72a64ceb45d6dc96bf467cdc85bbf0a (HEAD) Merge: d8993a90 81018f75 Date: Tue May 22 11:38:28 2018 +0000 Merge 81018f751a953fc3458c1c67327a7c0f63a94d86 into d8993a90412871b3c3ce3d3568c99b15ddbb8721 commit 81018f751a953fc3458c1c67327a7c0f63a94d86 Date: Tue May 22 14:42:43 2018 +0500 chore: Check head commit in drone  This bug is very very very get frustrating us. We are currently is forced to use this crutch :(  if ! git merge-base --is-ancestor ${DRONE_COMMIT} HEAD; then echo ""The commit ${DRONE_COMMIT} has not been found in HEAD."" echo ""Try to restart a build or open a new pull-request."" exit 1 fi   Hey Michail! We currently wouldn't recommend using the merge ref directly as it can sometimes be out of date. As an alternative, our API can be used to trigger the update and retrieve the merge ref: https://developer.github.com/v3/git/#checking-mergeability-of-pull-requests Hope this helps and please let me know if you need anything else! Cheers Stacey",source-file,"+refs/pull/<ID>/merge: not update after rebase and force push We have a problem with force-push. The essence can be understood from the correspondence with github support.  Greetings! Github have a bug when we doing rebase and force push. With 90% of cases the special branch `+refs/pull/<ID>/merge:` are not updated or update after some long time. The live example of that situation we have prepared at https://github.com/abak-press/apress-demands/pull/256 Right now it is reproduced in our CI and locally. Latest commit in a PR have ref de9ed321028b3338ec19689274ee596234c08d24 But doing this locally right now (and about during 30 minutes):  $ git init Initialized empty Git repository in /home/merkushin/code/tmp/demands-remove/.git/ $ git fetch --no-tags origin +refs/pull/256/merge: $ git checkout -qf FETCH_HEAD $ git log -2 commit 16aaa6d3f72a64ceb45d6dc96bf467cdc85bbf0a (HEAD) Merge: d8993a90 81018f75 Date: Tue May 22 11:38:28 2018 +0000 Merge 81018f751a953fc3458c1c67327a7c0f63a94d86 into d8993a90412871b3c3ce3d3568c99b15ddbb8721 commit 81018f751a953fc3458c1c67327a7c0f63a94d86 Date: Tue May 22 14:42:43 2018 +0500 chore: Check head commit in drone  This bug is very very very get frustrating us. We are currently is forced to use this crutch :(  if ! git merge-base --is-ancestor ${DRONE_COMMIT} HEAD; then echo ""The commit ${DRONE_COMMIT} has not been found in HEAD."" echo ""Try to restart a build or open a new pull-request."" exit 1 fi   Hey Michail! We currently wouldn't recommend using the merge ref directly as it can sometimes be out of date. As an alternative, our API can be used to trigger the update and retrieve the merge ref: https://developer.github.com/v3/git/#checking-mergeability-of-pull-requests Hope this helps and please let me know if you need anything else! Cheers Stacey source-file",no-bug,0.9
31,harness,https://github.com/harness/harness/issues/31,More verbose logs and server answers,"This is low priority, but seems like drone doesn't like to tell user what is wrong. For example it only sends error messages like `Not found` or `Unauthorized` without context.",config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | test-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"More verbose logs and server answers This is low priority, but seems like drone doesn't like to tell user what is wrong. For example it only sends error messages like `Not found` or `Unauthorized` without context. config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file test-file source-file test-file source-file test-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file test-file source-file test-file source-file test-file source-file test-file source-file test-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file test-file source-file source-file test-file test-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.8
3222,harness,https://github.com/harness/harness/issues/3222,Cron expression error,"I have tried to set up cron via drone CLI weekly with custom time. But I faced with a problem. When I used same pattern for weekly cron which I used for daily cron. I faced with an error For daily : 12 14 * * * * is ok For Weekly 12 14 * * 7 I see an error. json {""message"":""Invalid Cronjob Expression""}  **Expected** Should be same pattern to each cron or fill additional info in docs",source-file | config-file | config-file | config-file | config-file,"Cron expression error I have tried to set up cron via drone CLI weekly with custom time. But I faced with a problem. When I used same pattern for weekly cron which I used for daily cron. I faced with an error For daily : 12 14 * * * * is ok For Weekly 12 14 * * 7 I see an error. json {""message"":""Invalid Cronjob Expression""}  **Expected** Should be same pattern to each cron or fill additional info in docs source-file config-file config-file config-file config-file",no-bug,0.8
2524,harness,https://github.com/harness/harness/issues/2524,1.0.0.-rc.1 agent - invalid character '<' looking for beginning of value,"Running agent rc.1 throws the following error in logs **{""level"":""error"",""error"":""invalid character '<' looking for beginning of value"",""platform"":""linux/amd64"",""time"":""2018-11-11T20:07:46Z"",""message"":""cannot get queue item""}** Happens regardless of specified platform",source-file | source-file | source-file,"1.0.0.-rc.1 agent - invalid character '<' looking for beginning of value Running agent rc.1 throws the following error in logs **{""level"":""error"",""error"":""invalid character '<' looking for beginning of value"",""platform"":""linux/amd64"",""time"":""2018-11-11T20:07:46Z"",""message"":""cannot get queue item""}** Happens regardless of specified platform source-file source-file source-file",bug,0.9
630,harness,https://github.com/harness/harness/issues/630,Error when attempting to spawn drone," ~/code/docker-drone (master) X  docker run --rm -it --link dronedb:db -v /var/run/docker.sock:/docker.sock -e DOCKER_HOST=""unix:docker.sock"" -p 80:8080 xena/drone  Running /etc/rc.local  Booting runit daemon  Runit started as PID 13 DRONE_DATABASE_DATASOURCE=host=172.17.0.4 user=postgres dbname=drone sslmode=disable DB_PORT=tcp://172.17.0.4:5432 HOSTNAME=b2aaa48dd364 DB_ENV_PG_MAJOR=9.3 DB_PORT_5432_TCP=tcp://172.17.0.4:5432 DB_NAME=/pensive_curie/db DRONE_WORKER_NODES=unix:docker.sock DB_ENV_PGDATA=/var/lib/postgresql/data DRONE_GITHUB_CLIENT=sadfasdfsadf TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin DB_ENV_PG_VERSION=9.3.5-1.pgdg70+1 DB_ENV_LANG=en_US.utf8 DRONE_GITHUB_SECRET=fozbroz INITRD=no DRONE_DATABASE_DRIVER=postgres DOCKER_HOST=unix:docker.sock DRONE_SERVER_PORT=:8080 PWD=/etc/service/drone DB_PORT_5432_TCP_ADDR=172.17.0.4 DB_PORT_5432_TCP_PORT=5432 DB_PORT_5432_TCP_PROTO=tcp Everything is okay. Starting up drone! panic: Could not get DB version: missing ""="" after ""drone.sqlite"" in connection info string"" goroutine 16 [running]: runtime.panic(0xa4fee0, 0xc2080aeb70) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 github.com/drone/drone/server/datastore/database.MustConnect(0x7fffb903af33, 0x8, 0xba0b10, 0xc, 0x0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:51 +0x8a main.main() /var/cache/drone/src/github.com/drone/drone/server/main.go:106 +0x2f1 goroutine 19 [finalizer wait]: runtime.park(0x4919d0, 0x112ad90, 0x11157e9) /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 runtime.parkunlock(0x112ad90, 0x11157e9) /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 22 [syscall]: os/signal.loop() /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e created by os/signal.init1 /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 goroutine 24 [runnable]: database/sql.(*DB).connectionOpener(0xc208052580) /usr/local/go/src/pkg/database/sql/sql.go:582 created by database/sql.Open /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c ^C Shutting down runit daemon (PID 13)  Killing all processes  My Dockerfile is [here](http://github.com/Xe/docker-drone). Is there anything I am obviously doing wrong?",other-file,"Error when attempting to spawn drone  ~/code/docker-drone (master) X  docker run --rm -it --link dronedb:db -v /var/run/docker.sock:/docker.sock -e DOCKER_HOST=""unix:docker.sock"" -p 80:8080 xena/drone  Running /etc/rc.local  Booting runit daemon  Runit started as PID 13 DRONE_DATABASE_DATASOURCE=host=172.17.0.4 user=postgres dbname=drone sslmode=disable DB_PORT=tcp://172.17.0.4:5432 HOSTNAME=b2aaa48dd364 DB_ENV_PG_MAJOR=9.3 DB_PORT_5432_TCP=tcp://172.17.0.4:5432 DB_NAME=/pensive_curie/db DRONE_WORKER_NODES=unix:docker.sock DB_ENV_PGDATA=/var/lib/postgresql/data DRONE_GITHUB_CLIENT=sadfasdfsadf TERM=xterm PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin DB_ENV_PG_VERSION=9.3.5-1.pgdg70+1 DB_ENV_LANG=en_US.utf8 DRONE_GITHUB_SECRET=fozbroz INITRD=no DRONE_DATABASE_DRIVER=postgres DOCKER_HOST=unix:docker.sock DRONE_SERVER_PORT=:8080 PWD=/etc/service/drone DB_PORT_5432_TCP_ADDR=172.17.0.4 DB_PORT_5432_TCP_PORT=5432 DB_PORT_5432_TCP_PROTO=tcp Everything is okay. Starting up drone! panic: Could not get DB version: missing ""="" after ""drone.sqlite"" in connection info string"" goroutine 16 [running]: runtime.panic(0xa4fee0, 0xc2080aeb70) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 github.com/drone/drone/server/datastore/database.MustConnect(0x7fffb903af33, 0x8, 0xba0b10, 0xc, 0x0) /var/cache/drone/src/github.com/drone/drone/server/datastore/database/database.go:51 +0x8a main.main() /var/cache/drone/src/github.com/drone/drone/server/main.go:106 +0x2f1 goroutine 19 [finalizer wait]: runtime.park(0x4919d0, 0x112ad90, 0x11157e9) /usr/local/go/src/pkg/runtime/proc.c:1369 +0x89 runtime.parkunlock(0x112ad90, 0x11157e9) /usr/local/go/src/pkg/runtime/proc.c:1385 +0x3b runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2644 +0xcf runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 22 [syscall]: os/signal.loop() /usr/local/go/src/pkg/os/signal/signal_unix.go:21 +0x1e created by os/signal.init1 /usr/local/go/src/pkg/os/signal/signal_unix.go:27 +0x32 goroutine 24 [runnable]: database/sql.(*DB).connectionOpener(0xc208052580) /usr/local/go/src/pkg/database/sql/sql.go:582 created by database/sql.Open /usr/local/go/src/pkg/database/sql/sql.go:442 +0x27c ^C Shutting down runit daemon (PID 13)  Killing all processes  My Dockerfile is [here](http://github.com/Xe/docker-drone). Is there anything I am obviously doing wrong? other-file",no-bug,0.9
786,harness,https://github.com/harness/harness/issues/786,Update postgres,"I may be wrong, but apparently the postgres service runs against postgres 9.1 which is quite old and seems to be buggy\* too - https://github.com/drone/images/issues/3",other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | source-file,"Update postgres I may be wrong, but apparently the postgres service runs against postgres 9.1 which is quite old and seems to be buggy\* too - https://github.com/drone/images/issues/3 other-file source-file other-file other-file other-file other-file other-file source-file documentation-file other-file other-file other-file source-file",no-bug,0.9
1160,harness,https://github.com/harness/harness/issues/1160,Plugin to clean workspace,"Now that we have cached repository volumes, we need to be able to give people a way to clean the cache. This can be a Docker container that is launched on each worker, on-demand. The reason for using Docker for this task is a technical requirement -- we have no direct disk access to our worker machines, and only have access to the Docker daemon",source-file | source-file,"Plugin to clean workspace Now that we have cached repository volumes, we need to be able to give people a way to clean the cache. This can be a Docker container that is launched on each worker, on-demand. The reason for using Docker for this task is a technical requirement -- we have no direct disk access to our worker machines, and only have access to the Docker daemon source-file source-file",no-bug,0.9
3301,harness,https://github.com/harness/harness/issues/3301,Support for multiple code data sources ?,Support for multiple code data sources ? My code is in multiple places like giteegithubgitlab. Can the drone be managed together?,source-file | other-file | source-file | other-file | other-file | source-file | other-file | documentation-file | documentation-file | source-file | source-file,Support for multiple code data sources ? Support for multiple code data sources ? My code is in multiple places like giteegithubgitlab. Can the drone be managed together? source-file other-file source-file other-file other-file source-file other-file documentation-file documentation-file source-file source-file,no-bug,0.9
721,harness,https://github.com/harness/harness/issues/721,"When using drone cli disable command returns ""Unauthorized""","I was trying to disable a repository using the command `drone disable :host/:owner:/:name` but the command returns ""Unauthorized"". I don't think cli should go through authentication.",source-file | other-file | other-file | other-file | other-file | source-file | documentation-file | source-file,"When using drone cli disable command returns ""Unauthorized"" I was trying to disable a repository using the command `drone disable :host/:owner:/:name` but the command returns ""Unauthorized"". I don't think cli should go through authentication. source-file other-file other-file other-file other-file source-file documentation-file source-file",no-bug,0.7
624,harness,https://github.com/harness/harness/issues/624,HipChat notifications error,"I'm having some troubles since updating to the master branch earlier today, my `drone.yml` looks like this:  notify: hipchat: RoomId: {{hipchatRoom}} Token: {{hipchatToken}} on_started: true on_success: true on_failure: true  I've also tried:  notify: hipchat: RoomId: $$hipchatRoom Token: $$hipchatToken on_started: true on_success: true on_failure: true  However all I get is this in `/var/log/upstart/drone.log`:  2014/10/25 16:49:23 dial tcp :0: connection refused 2014/10/25 16:49:23 The RoomId, From, and Message fields are all required. 2014/10/25 16:49:23 subscription's close channel received message  My params look like this (Token changed obviously):  hipchatRoom: Notifications hipchatToken: 12382468276-246  I'm running it on Ubuntu 14.04 with docker version:  root@docker-01:/etc# docker version Client version: 1.3.0 Client API version: 1.15 Go version (client): go1.3.3 Git commit (client): c78088f OS/Arch (client): linux/amd64 Server version: 1.3.0 Server API version: 1.15 Go version (server): go1.3.3 Git commit (server): c78088f root@docker-01:/etc#  Any other info I can give?",other-file,"HipChat notifications error I'm having some troubles since updating to the master branch earlier today, my `drone.yml` looks like this:  notify: hipchat: RoomId: {{hipchatRoom}} Token: {{hipchatToken}} on_started: true on_success: true on_failure: true  I've also tried:  notify: hipchat: RoomId: $$hipchatRoom Token: $$hipchatToken on_started: true on_success: true on_failure: true  However all I get is this in `/var/log/upstart/drone.log`:  2014/10/25 16:49:23 dial tcp :0: connection refused 2014/10/25 16:49:23 The RoomId, From, and Message fields are all required. 2014/10/25 16:49:23 subscription's close channel received message  My params look like this (Token changed obviously):  hipchatRoom: Notifications hipchatToken: 12382468276-246  I'm running it on Ubuntu 14.04 with docker version:  root@docker-01:/etc# docker version Client version: 1.3.0 Client API version: 1.15 Go version (client): go1.3.3 Git commit (client): c78088f OS/Arch (client): linux/amd64 Server version: 1.3.0 Server API version: 1.15 Go version (server): go1.3.3 Git commit (server): c78088f root@docker-01:/etc#  Any other info I can give? other-file",no-bug,0.9
934,harness,https://github.com/harness/harness/issues/934,separate own repos and repos of organisations,"i am in one organisation with about 80 repos and i contribute to 3 of them, so the rest disturbs me, especially when i search for one of my own repos. it should be organized in - own repos - organisation 1 - organisation 2",other-file,"separate own repos and repos of organisations i am in one organisation with about 80 repos and i contribute to 3 of them, so the rest disturbs me, especially when i search for one of my own repos. it should be organized in - own repos - organisation 1 - organisation 2 other-file",no-bug,0.9
2205,harness,https://github.com/harness/harness/issues/2205,Add SIGTERM support,Trigger graceful shutdown process on SIGTERM (in addition to SIGINT). RE: https://discourse.drone.io/t/termination-signals/647.,other-file,Add SIGTERM support Trigger graceful shutdown process on SIGTERM (in addition to SIGINT). RE: https://discourse.drone.io/t/termination-signals/647. other-file,no-bug,0.9
1104,harness,https://github.com/harness/harness/issues/1104,Documentation?,"Is there a canonical source for Drone's documentation? The README links to http://readme.drone.io/usage/overview/ (which in turn links to http://drone.readthedocs.org/en/latest/ which is dead) and https://github.com/drone/drone/blob/v0.2.1/README.md#builds which seems outdated. My googling also turned up http://docs.drone.io/ which doesn't seem up to date or is for an unreleased version of Drone. For example, I can't find this screen anywhere in my own installation: ![build script](http://docs.drone.io/img/build-script.png) So where should I go to find Drone documentation? Am I correct in thinking that Drone (the open source project) has been abandoned in favour of http://drone.io (the commercial hosted service)? Or is Drone open source development going to continue? I'm not complaining and there's nothing wrong with either decision, I'm just a bit puzzled.",other-file,"Documentation? Is there a canonical source for Drone's documentation? The README links to http://readme.drone.io/usage/overview/ (which in turn links to http://drone.readthedocs.org/en/latest/ which is dead) and https://github.com/drone/drone/blob/v0.2.1/README.md#builds which seems outdated. My googling also turned up http://docs.drone.io/ which doesn't seem up to date or is for an unreleased version of Drone. For example, I can't find this screen anywhere in my own installation: ![build script](http://docs.drone.io/img/build-script.png) So where should I go to find Drone documentation? Am I correct in thinking that Drone (the open source project) has been abandoned in favour of http://drone.io (the commercial hosted service)? Or is Drone open source development going to continue? I'm not complaining and there's nothing wrong with either decision, I'm just a bit puzzled. other-file",no-bug,0.95
2798,harness,https://github.com/harness/harness/issues/2798,Edit secrets,Currently to edit a secret you must: - trigger a build with a hack to dump the current secret variable - delete the secret in drone - re-create the secret Is it possible to make it easier ? My use case is: I have a secret per deployement ie. STAGING_ENV that contains a multiline list of env vars. Then in my .drone.yml I do `export $(echo $STAGING_ENV| xargs)`. Keep up the gr8 work :heart:,source-file,Edit secrets Currently to edit a secret you must: - trigger a build with a hack to dump the current secret variable - delete the secret in drone - re-create the secret Is it possible to make it easier ? My use case is: I have a secret per deployement ie. STAGING_ENV that contains a multiline list of env vars. Then in my .drone.yml I do `export $(echo $STAGING_ENV| xargs)`. Keep up the gr8 work :heart: source-file,no-bug,0.9
369,harness,https://github.com/harness/harness/issues/369,hipchat notification not for bitbucket repo,Hi. I have a running drone ci with a connected bitbucket repository. Everything is running fine except the status notifications. Everytime on start and end of the build I get the following error: `error updating github status: Not Found` It seems that the status update only works for github (https://github.com/drone/drone/blob/f16101af2c4bf265d9dfcaad4fba478bef49111b/pkg/queue/worker.go#L100). I also configured the hipchat notifications which also doesn't work.,other-file,hipchat notification not for bitbucket repo Hi. I have a running drone ci with a connected bitbucket repository. Everything is running fine except the status notifications. Everytime on start and end of the build I get the following error: `error updating github status: Not Found` It seems that the status update only works for github (https://github.com/drone/drone/blob/f16101af2c4bf265d9dfcaad4fba478bef49111b/pkg/queue/worker.go#L100). I also configured the hipchat notifications which also doesn't work. other-file,no-bug,0.8
1222,harness,https://github.com/harness/harness/issues/1222,Running droned produces an panic,"Hi, I am using a docker container pulled from docker hub, more info here: hub.docker.com/r/drone/drone I have edited the drone.toml contained in /gopath/src/github.com/drone/drone/packaging/root/etc/drone/ to try to configure drone with a gogs webhook. However, the following panic message pops up when running ""droned --config=/gopath/src/github.com/drone/drone/packaging/root/etc/drone/droned.toml"":  root@6cedb887917c:/gopath/src/github.com/drone/drone/packaging/root/etc/drone# droned --config=/gopath/src/github.com/drone/drone/packaging/root/etc/drone/drone.toml panic: listen tcp :80: bind: address already in use goroutine 1 [running]: main.main() /gopath/src/github.com/drone/drone/server/main.go:157 +0xc37 goroutine 7 [syscall]: os/signal.loop() /usr/local/go/src/os/signal/signal_unix.go:21 +0x1f created by os/signal.init1 /usr/local/go/src/os/signal/signal_unix.go:27 +0x35 goroutine 10 [runnable]: github.com/drone/drone/server/datastore/database.(*Commitstore).KillCommits(0xc20802b050, 0xc208058500, 0xc20802b050) /gopath/src/github.com/drone/drone/server/datastore/database/commit.go:102 created by main.main /gopath/src/github.com/drone/drone/server/main.go:105 +0x317 goroutine 9 [chan receive]: database/sql.(*DB).connectionOpener(0xc208058500) /usr/local/go/src/database/sql/sql.go:589 +0x4c created by database/sql.Open /usr/local/go/src/database/sql/sql.go:452 +0x31c goroutine 17 [syscall, locked to thread]: runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2232 +0x1  The same panic occurs not matter what I do to the drone.toml file (even use the default config), including saving the config file in another location and configuring with an alternative port number.  packaging/root/etc/drone# droned panic: listen tcp :80: bind: address already in use goroutine 1 [running]: main.main() /gopath/src/github.com/drone/drone/server/main.go:157 +0xc37 goroutine 7 [syscall]: os/signal.loop() /usr/local/go/src/os/signal/signal_unix.go:21 +0x1f created by os/signal.init1 /usr/local/go/src/os/signal/signal_unix.go:27 +0x35 goroutine 9 [chan receive]: database/sql.(*DB).connectionOpener(0xc208058500) /usr/local/go/src/database/sql/sql.go:589 +0x4c created by database/sql.Open /usr/local/go/src/database/sql/sql.go:452 +0x31c goroutine 17 [syscall, locked to thread]: runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2232 +0x1 goroutine 10 [runnable]: github.com/drone/drone/server/datastore/database.(*Commitstore).KillCommits(0xc2080fd520, 0xc208058500, 0xc2080fd520) /gopath/src/github.com/drone/drone/server/datastore/database/commit.go:102 created by main.main /gopath/src/github.com/drone/drone/server/main.go:105 +0x317  Your thoughts / advice will be greatly appreciated.",source-file | database-file | database-file | database-file | database-file | source-file | source-file,"Running droned produces an panic Hi, I am using a docker container pulled from docker hub, more info here: hub.docker.com/r/drone/drone I have edited the drone.toml contained in /gopath/src/github.com/drone/drone/packaging/root/etc/drone/ to try to configure drone with a gogs webhook. However, the following panic message pops up when running ""droned --config=/gopath/src/github.com/drone/drone/packaging/root/etc/drone/droned.toml"":  root@6cedb887917c:/gopath/src/github.com/drone/drone/packaging/root/etc/drone# droned --config=/gopath/src/github.com/drone/drone/packaging/root/etc/drone/drone.toml panic: listen tcp :80: bind: address already in use goroutine 1 [running]: main.main() /gopath/src/github.com/drone/drone/server/main.go:157 +0xc37 goroutine 7 [syscall]: os/signal.loop() /usr/local/go/src/os/signal/signal_unix.go:21 +0x1f created by os/signal.init1 /usr/local/go/src/os/signal/signal_unix.go:27 +0x35 goroutine 10 [runnable]: github.com/drone/drone/server/datastore/database.(*Commitstore).KillCommits(0xc20802b050, 0xc208058500, 0xc20802b050) /gopath/src/github.com/drone/drone/server/datastore/database/commit.go:102 created by main.main /gopath/src/github.com/drone/drone/server/main.go:105 +0x317 goroutine 9 [chan receive]: database/sql.(*DB).connectionOpener(0xc208058500) /usr/local/go/src/database/sql/sql.go:589 +0x4c created by database/sql.Open /usr/local/go/src/database/sql/sql.go:452 +0x31c goroutine 17 [syscall, locked to thread]: runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2232 +0x1  The same panic occurs not matter what I do to the drone.toml file (even use the default config), including saving the config file in another location and configuring with an alternative port number.  packaging/root/etc/drone# droned panic: listen tcp :80: bind: address already in use goroutine 1 [running]: main.main() /gopath/src/github.com/drone/drone/server/main.go:157 +0xc37 goroutine 7 [syscall]: os/signal.loop() /usr/local/go/src/os/signal/signal_unix.go:21 +0x1f created by os/signal.init1 /usr/local/go/src/os/signal/signal_unix.go:27 +0x35 goroutine 9 [chan receive]: database/sql.(*DB).connectionOpener(0xc208058500) /usr/local/go/src/database/sql/sql.go:589 +0x4c created by database/sql.Open /usr/local/go/src/database/sql/sql.go:452 +0x31c goroutine 17 [syscall, locked to thread]: runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2232 +0x1 goroutine 10 [runnable]: github.com/drone/drone/server/datastore/database.(*Commitstore).KillCommits(0xc2080fd520, 0xc208058500, 0xc2080fd520) /gopath/src/github.com/drone/drone/server/datastore/database/commit.go:102 created by main.main /gopath/src/github.com/drone/drone/server/main.go:105 +0x317  Your thoughts / advice will be greatly appreciated. source-file database-file database-file database-file database-file source-file source-file",no-bug,0.9
382,harness,https://github.com/harness/harness/issues/382,Follow the build by default,"Once a build starts it's almost impossible to hit the Follow button because it keeps on moving. Alternatively, make the Follow button position:absolute.",source-file | source-file | source-file | source-file,"Follow the build by default Once a build starts it's almost impossible to hit the Follow button because it keeps on moving. Alternatively, make the Follow button position:absolute. source-file source-file source-file source-file",no-bug,0.9
2720,harness,https://github.com/harness/harness/issues/2720,Don't run Docker image as root where it's not necessary,"It would be nice if the Dockerfiles would use non privileged users instead of root where possible. For example [like described here](https://medium.com/@mccode/processes-in-containers-should-not-run-as-root-2feae3f0df3b). [The server part could use a non-privileged port](https://github.com/drone/drone/blob/master/docker/Dockerfile.server.linux.amd64) because everyone can remap the port anyway on the host system for example. **EDIT:** Sorry, I saw too late that this topic already came up in #98 and #1006 (and maybe[?] #1283 & #2436)  or they are somehow related I guess",source-file,"Don't run Docker image as root where it's not necessary It would be nice if the Dockerfiles would use non privileged users instead of root where possible. For example [like described here](https://medium.com/@mccode/processes-in-containers-should-not-run-as-root-2feae3f0df3b). [The server part could use a non-privileged port](https://github.com/drone/drone/blob/master/docker/Dockerfile.server.linux.amd64) because everyone can remap the port anyway on the host system for example. **EDIT:** Sorry, I saw too late that this topic already came up in #98 and #1006 (and maybe[?] #1283 & #2436)  or they are somehow related I guess source-file",no-bug,0.9
2916,harness,https://github.com/harness/harness/issues/2916,"""go mod tidy"" produce error","go go: finding github.com/golang/groupcache latest github.com/drone/drone/scheduler/nomad imports github.com/hashicorp/nomad/api tested by github.com/hashicorp/nomad/api.test imports github.com/hashicorp/consul/testutil/retry: module github.com/hashicorp/consul@latest found (v1.6.3), but does not contain package github.com/hashicorp/consul/testutil/retry github.com/drone/drone/cmd/drone-agent imports github.com/drone/drone-runtime/engine/docker imports docker.io/go-docker tested by docker.io/go-docker.test imports github.com/docker/docker/internal/testutil: module github.com/docker/docker@latest found (v1.13.1), but does not contain package github.com/docker/docker/internal/testutil github.com/drone/drone/scheduler/nomad imports github.com/hashicorp/nomad/api tested by github.com/hashicorp/nomad/api.test imports github.com/hashicorp/nomad/testutil imports github.com/hashicorp/consul/lib/freeport: module github.com/hashicorp/consul@latest found (v1.6.3), but does not contain package github.com/hashicorp/consul/lib/freeport ",source-file | source-file,"""go mod tidy"" produce error go go: finding github.com/golang/groupcache latest github.com/drone/drone/scheduler/nomad imports github.com/hashicorp/nomad/api tested by github.com/hashicorp/nomad/api.test imports github.com/hashicorp/consul/testutil/retry: module github.com/hashicorp/consul@latest found (v1.6.3), but does not contain package github.com/hashicorp/consul/testutil/retry github.com/drone/drone/cmd/drone-agent imports github.com/drone/drone-runtime/engine/docker imports docker.io/go-docker tested by docker.io/go-docker.test imports github.com/docker/docker/internal/testutil: module github.com/docker/docker@latest found (v1.13.1), but does not contain package github.com/docker/docker/internal/testutil github.com/drone/drone/scheduler/nomad imports github.com/hashicorp/nomad/api tested by github.com/hashicorp/nomad/api.test imports github.com/hashicorp/nomad/testutil imports github.com/hashicorp/consul/lib/freeport: module github.com/hashicorp/consul@latest found (v1.6.3), but does not contain package github.com/hashicorp/consul/lib/freeport  source-file source-file",no-bug,0.9
670,harness,https://github.com/harness/harness/issues/670,Reeable hook or display hook url for specific repo,"If user deletes webhook or uses custom hook deployer. User needs to ""guess"" url and auth key Option is repos setting would be nice for those with same problems:  curl -X DELETE -H ""Authorization: APIKEY"" http://drone_host/api/repos/github.com/repo/project ",source-file | source-file | source-file | source-file | source-file | source-file,"Reeable hook or display hook url for specific repo If user deletes webhook or uses custom hook deployer. User needs to ""guess"" url and auth key Option is repos setting would be nice for those with same problems:  curl -X DELETE -H ""Authorization: APIKEY"" http://drone_host/api/repos/github.com/repo/project  source-file source-file source-file source-file source-file source-file",no-bug,0.7
2842,harness,https://github.com/harness/harness/issues/2842,"If the function provided to db.Update() panics, the transaction will not be rolled back","https://github.com/drone/drone/blob/master/store/shared/db/db.go#L110 If fn() panics, the tx.Rollback() will not be executed, and the transaction will not be released until it times out.",other-file,"If the function provided to db.Update() panics, the transaction will not be rolled back https://github.com/drone/drone/blob/master/store/shared/db/db.go#L110 If fn() panics, the tx.Rollback() will not be executed, and the transaction will not be released until it times out. other-file",no-bug,0.9
2593,harness,https://github.com/harness/harness/issues/2593,Run pipeline on cancel/timeout,"Creating a feature request as suggested [here](https://discourse.drone.io/t/is-it-possible-to-run-a-clean-up-task-after-a-build-has-been-canceled/2528/3?u=s0undt3ch). The background to the feature request is as follows. We have a build with a few pipelines that create AWS resources and in the end, after success or failure, those resources are destroyed. However, if the build is canceled, there's no chance to run any cleanup code which means AWS resources are left running _ad-eternum_ because, on our scenario, not all devs which can cancel builds have access to AWS to terminate said resources by hand. Doing it by hand also defeats the CI automation process :) The request is to add support for running a pipeline on `cancel` the same way there's support for `success` and `failure`.",other-file | other-file | other-file,"Run pipeline on cancel/timeout Creating a feature request as suggested [here](https://discourse.drone.io/t/is-it-possible-to-run-a-clean-up-task-after-a-build-has-been-canceled/2528/3?u=s0undt3ch). The background to the feature request is as follows. We have a build with a few pipelines that create AWS resources and in the end, after success or failure, those resources are destroyed. However, if the build is canceled, there's no chance to run any cleanup code which means AWS resources are left running _ad-eternum_ because, on our scenario, not all devs which can cancel builds have access to AWS to terminate said resources by hand. Doing it by hand also defeats the CI automation process :) The request is to add support for running a pipeline on `cancel` the same way there's support for `success` and `failure`. other-file other-file other-file",no-bug,0.9
2221,harness,https://github.com/harness/harness/issues/2221,Canceled should be a new status but not failed.,I prefer a new status `canceled`,other-file | other-file | other-file | other-file | other-file | documentation-file,Canceled should be a new status but not failed. I prefer a new status `canceled` other-file other-file other-file other-file other-file documentation-file,no-bug,0.9
2061,harness,https://github.com/harness/harness/issues/2061,Docker images for arm32 and arm64,This is a feature request for Docker images for arm32 and arm64 on docker hub.,source-file,Docker images for arm32 and arm64 This is a feature request for Docker images for arm32 and arm64 on docker hub. source-file,no-bug,0.95
143,harness,https://github.com/harness/harness/issues/143,Cache directories between builds,"Travis supports caching of directories. In my case with maven and java I'm downloading a lot of libraries from maven central. These are stored in ~/.m2/repository and it would be nice to persist this between runs using the same image. I was looking into docker volumes, either a mounted host directory or a shared volume between containers, but I'm not sure how to use it in relation to Drone. Would be nice if each container created by Drone is allowed to write in the shared volume to keep one up-to-date mvn repository. Any ideas on this?",source-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file,"Cache directories between builds Travis supports caching of directories. In my case with maven and java I'm downloading a lot of libraries from maven central. These are stored in ~/.m2/repository and it would be nice to persist this between runs using the same image. I was looking into docker volumes, either a mounted host directory or a shared volume between containers, but I'm not sure how to use it in relation to Drone. Would be nice if each container created by Drone is allowed to write in the shared volume to keep one up-to-date mvn repository. Any ideas on this? source-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file test-file source-file",no-bug,0.95
522,harness,https://github.com/harness/harness/issues/522,[0.3] rebuild job,there doesn't appear to be a way to rebuild a previous job from the ui in v0.3?,source-file | source-file | source-file,[0.3] rebuild job there doesn't appear to be a way to rebuild a previous job from the ui in v0.3? source-file source-file source-file,no-bug,0.7
778,harness,https://github.com/harness/harness/issues/778,using drone on a project with 2 containers,I created a new MEAN stack project: node.js and mongodb - https://github.com/oren/mean-drone/blob/master/.drone.yml The app is using a dockerfile and the mongodb is using the offical mongo from dockerhub. How to configure .drone.yml to run 'grunt test' against this project?,source-file,using drone on a project with 2 containers I created a new MEAN stack project: node.js and mongodb - https://github.com/oren/mean-drone/blob/master/.drone.yml The app is using a dockerfile and the mongodb is using the offical mongo from dockerhub. How to configure .drone.yml to run 'grunt test' against this project? source-file,no-bug,0.9
2897,harness,https://github.com/harness/harness/issues/2897,drone,<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io -->,documentation-file,drone <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> documentation-file,no-bug,0.9
93,harness,https://github.com/harness/harness/issues/93,.drone.yml example to deploy on Rackspace,Current examples show Heroku and Amazon deployments. It would be great if you can provide examples for the Rackspace too.,source-file | source-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,.drone.yml example to deploy on Rackspace Current examples show Heroku and Amazon deployments. It would be great if you can provide examples for the Rackspace too. source-file source-file other-file other-file other-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.95
949,harness,https://github.com/harness/harness/issues/949,Error when build image has -onbuild directive,"Man this took me a lot of head scratching Apparently because drone copies and re-tags the image that you specify in .drone.yml, if you use -onbuild images, e.g. library/node:0.12-onbuild; they fail very quietly. Should make a note of this in the documentation somewhere. This is what it looks like in the docker log:  Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""+job image_inspect(library/node:0.12-onbuild)"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""-job image_inspect(library/node:0.12-onbuild) = OK (0)"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""POST /v1.9/build?q=1&rm=1&t=drone-9b02bc62b7"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""+job build()"" Apr 02 16:51:09 <redacted> dockerd[629]: package.json: no such file or directory Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""-job build() = ERR (1)"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""GET /v1.9/images/drone-9b02bc62b7/json"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""+job image_inspect(drone-9b02bc62b7)"" Apr 02 16:51:09 <redacted> dockerd[629]: No such image: drone-9b02bc62b7 Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""-job image_inspect(drone-9b02bc62b7) = ERR (1)"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""error"" msg=""Handler for GET /images/{name:.*}/json returned error: No such image: drone-9b02bc62b7"" ",other-file,"Error when build image has -onbuild directive Man this took me a lot of head scratching Apparently because drone copies and re-tags the image that you specify in .drone.yml, if you use -onbuild images, e.g. library/node:0.12-onbuild; they fail very quietly. Should make a note of this in the documentation somewhere. This is what it looks like in the docker log:  Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""+job image_inspect(library/node:0.12-onbuild)"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""-job image_inspect(library/node:0.12-onbuild) = OK (0)"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""POST /v1.9/build?q=1&rm=1&t=drone-9b02bc62b7"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""+job build()"" Apr 02 16:51:09 <redacted> dockerd[629]: package.json: no such file or directory Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""-job build() = ERR (1)"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""GET /v1.9/images/drone-9b02bc62b7/json"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""+job image_inspect(drone-9b02bc62b7)"" Apr 02 16:51:09 <redacted> dockerd[629]: No such image: drone-9b02bc62b7 Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""info"" msg=""-job image_inspect(drone-9b02bc62b7) = ERR (1)"" Apr 02 16:51:09 <redacted> dockerd[629]: time=""2015-04-02T16:51:09Z"" level=""error"" msg=""Handler for GET /images/{name:.*}/json returned error: No such image: drone-9b02bc62b7""  other-file",no-bug,0.9
2572,harness,https://github.com/harness/harness/issues/2572,Provide multiarch images for arm/arm64,Please provide the drone image as multi-arch image so it works on ARM and ARM64 as well.,database-file | database-file | database-file | database-file | database-file | database-file,Provide multiarch images for arm/arm64 Please provide the drone image as multi-arch image so it works on ARM and ARM64 as well. database-file database-file database-file database-file database-file database-file,no-bug,0.9
2271,harness,https://github.com/harness/harness/issues/2271,Drone specific metrics?,"I see #2014 ad recently merged; Are there any Drone specific metrics that are exposed such as build counters, queue depth, connection stats between server<->agent(s)",source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file,"Drone specific metrics? I see #2014 ad recently merged; Are there any Drone specific metrics that are exposed such as build counters, queue depth, connection stats between server<->agent(s) source-file other-file other-file other-file other-file source-file other-file other-file other-file source-file",no-bug,0.9
223,harness,https://github.com/harness/harness/issues/223,droned fails to start on debian stable due to libc6 version requirement,"I tried installing Drone (via http://downloads.drone.io/latest/drone.deb) on a debian stable (wheezy) machine (a Google Compute Engine instance running a debian-7 image, to be precise). When trying to invoke droned I get the following error: $ /usr/local/bin/droned --port=:80 /usr/local/bin/drone: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.14' not found (required by /usr/local/bin/drone) The version of libc6 on wheezy is 2.13-38+deb7. Presumably, you all are building on Ubuntu Would it be possible to provide wheezy-compatible builds? (This would probably also cover Ubuntu lucid, which still has a year before EOL.)",other-file | source-file | other-file | source-file | documentation-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file | source-file | other-file,"droned fails to start on debian stable due to libc6 version requirement I tried installing Drone (via http://downloads.drone.io/latest/drone.deb) on a debian stable (wheezy) machine (a Google Compute Engine instance running a debian-7 image, to be precise). When trying to invoke droned I get the following error: $ /usr/local/bin/droned --port=:80 /usr/local/bin/drone: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.14' not found (required by /usr/local/bin/drone) The version of libc6 on wheezy is 2.13-38+deb7. Presumably, you all are building on Ubuntu Would it be possible to provide wheezy-compatible builds? (This would probably also cover Ubuntu lucid, which still has a year before EOL.) other-file source-file other-file source-file documentation-file other-file source-file other-file other-file other-file source-file other-file other-file source-file documentation-file other-file other-file source-file other-file",no-bug,0.95
772,harness,https://github.com/harness/harness/issues/772,packer as builder,What do you think about adding packer as alternative to docker ?,source-file | source-file | source-file | source-file | source-file,packer as builder What do you think about adding packer as alternative to docker ? source-file source-file source-file source-file source-file,no-bug,0.9
937,harness,https://github.com/harness/harness/issues/937,Cannot disable gitlab repo.,"I cannot disable any gitlab repo on my drone account:  drone disable git-server.de/nils/python-skeleton  does nothing, does not return anything, does not show any effect either. same with  drone delete git-server.de/nils/python-skeleton  however  drone status git-server.de/nils/python-skeleton  shows me the status of the last build.",source-file,"Cannot disable gitlab repo. I cannot disable any gitlab repo on my drone account:  drone disable git-server.de/nils/python-skeleton  does nothing, does not return anything, does not show any effect either. same with  drone delete git-server.de/nils/python-skeleton  however  drone status git-server.de/nils/python-skeleton  shows me the status of the last build. source-file",bug,0.85
2138,harness,https://github.com/harness/harness/issues/2138,"meddler.Insert: DB error in Exec: UNIQUE constraint failed: config.config_hash, config.config_repo_id","*As per our [chatroom discussion](https://gitter.im/drone/drone?at=59765a1376a757f80841cd78)* When two hooks are received at the same time, with the same yaml, and drone tries to insert both at the same time, the following exception occurs:  Jul 24 22:20:13 coreos0 docker: time=""2017-07-24T20:20:12Z"" level=error msg=""failure to persist config for ____GITHUB_ORG/GITHUB_PROJECT_______. meddler.Insert: DB error in Exec: UNIQUE constraint failed: config.config_hash, config.config_repo_id"" Jul 24 22:20:13 coreos0 docker: time=""2017-07-24T20:20:12Z"" level=error msg=""Error #01: meddler.Insert: DB error in Exec: UNIQUE constraint failed: config.config_hash, config.config_repo_id\n"" ip=192.30.252.34 latency=1.71155372s method=POST path=""/hook"" status=500 time=""2017-07-24T20:20:12Z"" user-agent=""GitHub-Hookshot/62709df""  Redelivering the payload via GitHub GUI solves the problem.  andreas@coreos0 ~ $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE drone/agent 0.8 230e966bc666 4 days ago 12.98 MB drone/drone 0.8 185b47a4268a 4 days ago 27.26 MB ",source-file | source-file | source-file | source-file | source-file,"meddler.Insert: DB error in Exec: UNIQUE constraint failed: config.config_hash, config.config_repo_id *As per our [chatroom discussion](https://gitter.im/drone/drone?at=59765a1376a757f80841cd78)* When two hooks are received at the same time, with the same yaml, and drone tries to insert both at the same time, the following exception occurs:  Jul 24 22:20:13 coreos0 docker: time=""2017-07-24T20:20:12Z"" level=error msg=""failure to persist config for ____GITHUB_ORG/GITHUB_PROJECT_______. meddler.Insert: DB error in Exec: UNIQUE constraint failed: config.config_hash, config.config_repo_id"" Jul 24 22:20:13 coreos0 docker: time=""2017-07-24T20:20:12Z"" level=error msg=""Error #01: meddler.Insert: DB error in Exec: UNIQUE constraint failed: config.config_hash, config.config_repo_id\n"" ip=192.30.252.34 latency=1.71155372s method=POST path=""/hook"" status=500 time=""2017-07-24T20:20:12Z"" user-agent=""GitHub-Hookshot/62709df""  Redelivering the payload via GitHub GUI solves the problem.  andreas@coreos0 ~ $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE drone/agent 0.8 230e966bc666 4 days ago 12.98 MB drone/drone 0.8 185b47a4268a 4 days ago 27.26 MB  source-file source-file source-file source-file source-file",no-bug,0.8
689,harness,https://github.com/harness/harness/issues/689,deploying multiple artifacts via SSH,"Deploying multiple files via SSH is annoying as all of a sudden the deploy mechanism switches to zipping the artifacts. I think the zipping should be independent of the number of files, or removed alltogether. When one wants a zip they should create it in the `script` section themselves. The current implementation is very unintuitive and forces users to implement the `scp` call themselves.",source-file | test-file,"deploying multiple artifacts via SSH Deploying multiple files via SSH is annoying as all of a sudden the deploy mechanism switches to zipping the artifacts. I think the zipping should be independent of the number of files, or removed alltogether. When one wants a zip they should create it in the `script` section themselves. The current implementation is very unintuitive and forces users to implement the `scp` call themselves. source-file test-file",no-bug,0.9
2748,harness,https://github.com/harness/harness/issues/2748,Restarting a promoted build loses target environment,"When I try to restart a build that has been run as the result of a promotion, drone seems to trigger a new promotion build, but with the variable set to empty - for example, if I run `drone build promote my/repository 123 production` It works fine, but when I hit the restart button in the UI for this build, it does something roughly the equivalent of `drone build promote my/repository 123` (after the 123 intentionally left blank)",source-file | source-file,"Restarting a promoted build loses target environment When I try to restart a build that has been run as the result of a promotion, drone seems to trigger a new promotion build, but with the variable set to empty - for example, if I run `drone build promote my/repository 123 production` It works fine, but when I hit the restart button in the UI for this build, it does something roughly the equivalent of `drone build promote my/repository 123` (after the 123 intentionally left blank) source-file source-file",no-bug,0.9
1263,harness,https://github.com/harness/harness/issues/1263,Gogs avatars without domain,"per issue #1260 the gogs implementation currently assumes a gravatar url with a format of `//1.gravatar.com/gravatar/<hash>`. If someone is not using gravatar, and has uploaded a custom avatar, the url format with be `/avatars/<id>`. we need to account for the latter by prepending the `//<hostname>`",source-file | test-file | source-file | test-file | source-file | source-file | test-file,"Gogs avatars without domain per issue #1260 the gogs implementation currently assumes a gravatar url with a format of `//1.gravatar.com/gravatar/<hash>`. If someone is not using gravatar, and has uploaded a custom avatar, the url format with be `/avatars/<id>`. we need to account for the latter by prepending the `//<hostname>` source-file test-file source-file test-file source-file source-file test-file",no-bug,0.7
2876,harness,https://github.com/harness/harness/issues/2876,[BUG] Cron jobs seems not working with DRONE_GITEA_SKIP_VERIFY variable and SelfSigned Certificates,"First I have to be grateful, for this great project to everybody who are working on it. About the bug, as described in the community (https://discourse.drone.io/t/cron-jobs-seems-not-working-with-drone-gitea-skip-verify-variable-and-selfsigned-certificates/6213) I've detected errors when cron needs renew the oauth token on a Gitea with self-signed certificate, but it doesn't take the DRONE_GITEA_SKIP_VERIFY variable. These are the errors. json {""branch"":""master"",""cron"":3,""error"":""Post https://git.myplatform.org/login/oauth/access_token: x509: certificate is valid for 413075044928d7b2d8864b1ada61ba7c.e5c739ab2bc51b1f4a195056046c6168.traefik.default, not git.myplatform.org"",""level"":""warning"",""msg"":""cron: cannot find commit"",""repo"":""myclient_probes/probe_firefox-google"",""time"":""2019-11-08T08:06:15Z""} {""branch"":""master"",""cron"":3,""error"":""Post https://git.myplatform.org/login/oauth/access_token: x509: certificate is valid for 413075044928d7b2d8864b1ada61ba7c.e5c739ab2bc51b1f4a195056046c6168.traefik.default, not git.myplatform.org"",""level"":""warning"",""msg"":""cron: cannot find commit"",""repo"":""myclient_probes/probe_firefox-google"",""time"":""2019-11-08T08:09:15Z""}  Login to the IU is working OK, but token renew fails and cron can not authenticate to the Gitea repos. I've reviewed the code and I will send a PR that has fixed the problem in two different platforms with the same behaviour. Lots of thanks",source-file | source-file | source-file | source-file | source-file | source-file,"[BUG] Cron jobs seems not working with DRONE_GITEA_SKIP_VERIFY variable and SelfSigned Certificates First I have to be grateful, for this great project to everybody who are working on it. About the bug, as described in the community (https://discourse.drone.io/t/cron-jobs-seems-not-working-with-drone-gitea-skip-verify-variable-and-selfsigned-certificates/6213) I've detected errors when cron needs renew the oauth token on a Gitea with self-signed certificate, but it doesn't take the DRONE_GITEA_SKIP_VERIFY variable. These are the errors. json {""branch"":""master"",""cron"":3,""error"":""Post https://git.myplatform.org/login/oauth/access_token: x509: certificate is valid for 413075044928d7b2d8864b1ada61ba7c.e5c739ab2bc51b1f4a195056046c6168.traefik.default, not git.myplatform.org"",""level"":""warning"",""msg"":""cron: cannot find commit"",""repo"":""myclient_probes/probe_firefox-google"",""time"":""2019-11-08T08:06:15Z""} {""branch"":""master"",""cron"":3,""error"":""Post https://git.myplatform.org/login/oauth/access_token: x509: certificate is valid for 413075044928d7b2d8864b1ada61ba7c.e5c739ab2bc51b1f4a195056046c6168.traefik.default, not git.myplatform.org"",""level"":""warning"",""msg"":""cron: cannot find commit"",""repo"":""myclient_probes/probe_firefox-google"",""time"":""2019-11-08T08:09:15Z""}  Login to the IU is working OK, but token renew fails and cron can not authenticate to the Gitea repos. I've reviewed the code and I will send a PR that has fixed the problem in two different platforms with the same behaviour. Lots of thanks source-file source-file source-file source-file source-file source-file",no-bug,0.8
97,harness,https://github.com/harness/harness/issues/97,Drone shows me the previous build for the same commit,"I have to branches on my repository, develop and master. I pushed one commit on develop, drone built it, and all specs passed. Next, I merged develop into master and pushed it to github. Drone is now building the master branch, current status is building, but if I click on the build, the previous build (from develop) is shown.",other-file,"Drone shows me the previous build for the same commit I have to branches on my repository, develop and master. I pushed one commit on develop, drone built it, and all specs passed. Next, I merged develop into master and pushed it to github. Drone is now building the master branch, current status is building, but if I click on the build, the previous build (from develop) is shown. other-file",no-bug,0.9
2667,harness,https://github.com/harness/harness/issues/2667,Pipeline hangs when trigger.status is failure,"problem with build hanging when pipeline dependency graph is defined, where the final node in the graph should only execute on failure (below). this was discussed in the comments of #2553 test kind: pipeline name: greeting steps: - name: en image: alpine:3.8 commands: - echo hello - echo world - sleep 10 - exit 1  kind: pipeline name: saludo steps: - name: es image: alpine:3.8 commands: - echo hola - echo mundo  kind: pipeline name: salutation steps: - name: fr image: alpine:3.8 commands: - echo bonjour - echo monde - echo $DRONE_BUILD_STATUS trigger: status: + - failure depends_on: - greeting - saludo ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file,"Pipeline hangs when trigger.status is failure problem with build hanging when pipeline dependency graph is defined, where the final node in the graph should only execute on failure (below). this was discussed in the comments of #2553 test kind: pipeline name: greeting steps: - name: en image: alpine:3.8 commands: - echo hello - echo world - sleep 10 - exit 1  kind: pipeline name: saludo steps: - name: es image: alpine:3.8 commands: - echo hola - echo mundo  kind: pipeline name: salutation steps: - name: fr image: alpine:3.8 commands: - echo bonjour - echo monde - echo $DRONE_BUILD_STATUS trigger: status: + - failure depends_on: - greeting - saludo  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file",no-bug,0.9
459,harness,https://github.com/harness/harness/issues/459,GitLab Pull Request Support,"I did setup drone on Amazon ec2 instance and I did configure drone with gitlab. Actually drone now run merges with upstream repo successfully, but the problem comes with pull requests. Once anyone submit a pull request to the upstream repo, I got the following error:  $ git clone --depth=50 --recursive --branch=master git@git.whitespace.company:whitespace/incident_report.git /var/cache/drone/src/git.whitespace.company/whitespace/incident_report Cloning into '/var/cache/drone/src/git.whitespace.company/whitespace/incident_report' Warning: Permanently added 'git.whitespace.company,54.186.255.10' (ECDSA) to the list of known hosts. $ git fetch origin +refs/pull/32/head:refs/remotes/origin/pr/32 fatal: Couldn't find remote ref refs/pull/32/head  So, any suggestions what's the problem here?",source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file,"GitLab Pull Request Support I did setup drone on Amazon ec2 instance and I did configure drone with gitlab. Actually drone now run merges with upstream repo successfully, but the problem comes with pull requests. Once anyone submit a pull request to the upstream repo, I got the following error:  $ git clone --depth=50 --recursive --branch=master git@git.whitespace.company:whitespace/incident_report.git /var/cache/drone/src/git.whitespace.company/whitespace/incident_report Cloning into '/var/cache/drone/src/git.whitespace.company/whitespace/incident_report' Warning: Permanently added 'git.whitespace.company,54.186.255.10' (ECDSA) to the list of known hosts. $ git fetch origin +refs/pull/32/head:refs/remotes/origin/pr/32 fatal: Couldn't find remote ref refs/pull/32/head  So, any suggestions what's the problem here? source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2573,harness,https://github.com/harness/harness/issues/2573,Kubernetes Multi-arch support,"I am running image: drone/drone:1.0.0-rc.4-linux-arm64 and created a simple build job. Drone creates a new kubernetes job that fails to execute because it uses amd64 docker image:   ""annotations"": { ""io.drone.build.id"": ""2"", ""io.drone.repo.id"": ""1"", ""io.drone.stage.arch"": ""arm64"", ""io.drone.stage.created"": ""2019-01-12 16:46:49 +0000 UTC"", ""io.drone.stage.id"": ""2"", ""io.drone.stage.number"": ""1"", ""io.drone.stage.os"": ""linux"",  ""spec"": { ""containers"": [ { ""name"": ""drone-controller"", ""image"": ""drone/controller:linux-amd64"",  Setting DRONE_RUNNER_PLATFORM=linux/arm64 did not have any effect. I think it would be best, if the arch would be extracted from the pipeline definition or uses a simple image name to use docker resolution of the right image through multi-arch manifest file.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Kubernetes Multi-arch support I am running image: drone/drone:1.0.0-rc.4-linux-arm64 and created a simple build job. Drone creates a new kubernetes job that fails to execute because it uses amd64 docker image:   ""annotations"": { ""io.drone.build.id"": ""2"", ""io.drone.repo.id"": ""1"", ""io.drone.stage.arch"": ""arm64"", ""io.drone.stage.created"": ""2019-01-12 16:46:49 +0000 UTC"", ""io.drone.stage.id"": ""2"", ""io.drone.stage.number"": ""1"", ""io.drone.stage.os"": ""linux"",  ""spec"": { ""containers"": [ { ""name"": ""drone-controller"", ""image"": ""drone/controller:linux-amd64"",  Setting DRONE_RUNNER_PLATFORM=linux/arm64 did not have any effect. I think it would be best, if the arch would be extracted from the pipeline definition or uses a simple image name to use docker resolution of the right image through multi-arch manifest file. source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3367,harness,https://github.com/harness/harness/issues/3367,Why a CLA is required to contribute on Gitness?,Why is there a CLA for Gitness which is basically allowing to relicense the complete contribution to another license? Have you considered to use a Developer Certificate of Origin? https://developercertificate.org/ https://cla-assistant.io/harness/drone?pullRequest=3355,container-file,Why a CLA is required to contribute on Gitness? Why is there a CLA for Gitness which is basically allowing to relicense the complete contribution to another license? Have you considered to use a Developer Certificate of Origin? https://developercertificate.org/ https://cla-assistant.io/harness/drone?pullRequest=3355 container-file,no-bug,0.95
2193,harness,https://github.com/harness/harness/issues/2193,Panic when trying to read non-existent vault secret,"If you try to reference a vault secret that does not exist in vault, drone will then panic and put the build in a forever pending state. This is with `drone/drone:0.8.0`. The stack trace:  Sep 5 21:46:11 drone6-server drone6[6307]: runtime error: invalid memory address or nil pointer dereference Sep 5 21:46:11 drone6-server drone6[6307]: /usr/local/go/src/runtime/panic.go:489 (0x42f29f) Sep 5 21:46:11 drone6-server drone6[6307]: /usr/local/go/src/runtime/panic.go:63 (0x42e14e) Sep 5 21:46:11 drone6-server drone6[6307]: /usr/local/go/src/runtime/signal_unix.go:290 (0x44430f) Sep 5 21:46:11 drone6-server drone6[6307]: /go/src/github.com/drone/drone/extras/secrets/vault.go:93 (0xa160c6) Sep 5 21:46:11 drone6-server drone6[6307]: /go/src/github.com/drone/drone/extras/secrets/vault.go:52 (0xa15c53) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/server/hook.go:222 (0x96871e) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/token/token.go:17 (0x8d3ff0) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/session/user.go:68 (0x8d3492) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/store.go:15 (0x9cd767) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/contrib/ginrus/ginrus.go:26 (0x9cdbbf) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/header/header.go:25 (0x8cb040) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/header/header.go:17 (0x8cafe9) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/recovery.go:45 (0x8c8caa) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/gin.go:284 (0x8c0850) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/gin.go:265 (0x8c016b) Sep 5 21:46:12 drone6-server drone6[6307]: /usr/local/go/src/net/http/server.go:2568 (0x6ceb92) Sep 5 21:46:12 drone6-server drone6[6307]: /usr/local/go/src/net/http/server.go:1825 (0x6cad32) Sep 5 21:46:12 drone6-server drone6[6307]: /usr/local/go/src/runtime/asm_amd64.s:2197 (0x45dda1) ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Panic when trying to read non-existent vault secret If you try to reference a vault secret that does not exist in vault, drone will then panic and put the build in a forever pending state. This is with `drone/drone:0.8.0`. The stack trace:  Sep 5 21:46:11 drone6-server drone6[6307]: runtime error: invalid memory address or nil pointer dereference Sep 5 21:46:11 drone6-server drone6[6307]: /usr/local/go/src/runtime/panic.go:489 (0x42f29f) Sep 5 21:46:11 drone6-server drone6[6307]: /usr/local/go/src/runtime/panic.go:63 (0x42e14e) Sep 5 21:46:11 drone6-server drone6[6307]: /usr/local/go/src/runtime/signal_unix.go:290 (0x44430f) Sep 5 21:46:11 drone6-server drone6[6307]: /go/src/github.com/drone/drone/extras/secrets/vault.go:93 (0xa160c6) Sep 5 21:46:11 drone6-server drone6[6307]: /go/src/github.com/drone/drone/extras/secrets/vault.go:52 (0xa15c53) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/server/hook.go:222 (0x96871e) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/token/token.go:17 (0x8d3ff0) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/session/user.go:68 (0x8d3492) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/store.go:15 (0x9cd767) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/contrib/ginrus/ginrus.go:26 (0x9cdbbf) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/header/header.go:25 (0x8cb040) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/router/middleware/header/header.go:17 (0x8cafe9) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/recovery.go:45 (0x8c8caa) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/context.go:97 (0x8baa1a) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/gin.go:284 (0x8c0850) Sep 5 21:46:12 drone6-server drone6[6307]: /go/src/github.com/drone/drone/vendor/github.com/gin-gonic/gin/gin.go:265 (0x8c016b) Sep 5 21:46:12 drone6-server drone6[6307]: /usr/local/go/src/net/http/server.go:2568 (0x6ceb92) Sep 5 21:46:12 drone6-server drone6[6307]: /usr/local/go/src/net/http/server.go:1825 (0x6cad32) Sep 5 21:46:12 drone6-server drone6[6307]: /usr/local/go/src/runtime/asm_amd64.s:2197 (0x45dda1)  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.9
197,harness,https://github.com/harness/harness/issues/197,Deploy Plugin - Appfog,Provide a deployment option for Appfog. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/appfog.go,other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file,Deploy Plugin - Appfog Provide a deployment option for Appfog. I have a placeholder file here: https://github.com/drone/drone/blob/master/pkg/plugin/deploy/appfog.go other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file source-file,no-bug,0.9
1005,harness,https://github.com/harness/harness/issues/1005,"Gitlab webhook calls fail due to ""object_kind"":""push""","Gitlab 7.9 added a field `""object_kind"":""push""` to the webhook POST body. Drone returns a 400 Bad Request with that property included, but succeeds if it's removed.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Gitlab webhook calls fail due to ""object_kind"":""push"" Gitlab 7.9 added a field `""object_kind"":""push""` to the webhook POST body. Drone returns a 400 Bad Request with that property included, but succeeds if it's removed. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.95
677,harness,https://github.com/harness/harness/issues/677,Incremental build number,"I don't found any issues about `CI_BUILD_NUMBER` variable. Now [it contains](https://github.com/drone/drone/blob/master/shared/build/build.go#L504) commit hash, that triggered build. This approach not working for building debian packages, which should have incremental verison `x.x.x-buildnumber` to be autoinstalled without warning (about downgrade). Is there workarounds for incremental build number in drone or should it be implemented by hands?",other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file,"Incremental build number I don't found any issues about `CI_BUILD_NUMBER` variable. Now [it contains](https://github.com/drone/drone/blob/master/shared/build/build.go#L504) commit hash, that triggered build. This approach not working for building debian packages, which should have incremental verison `x.x.x-buildnumber` to be autoinstalled without warning (about downgrade). Is there workarounds for incremental build number in drone or should it be implemented by hands? other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file",no-bug,0.9
2065,harness,https://github.com/harness/harness/issues/2065,Agent does not automatically recover from network failure,"This issue needs more research, but is here for tracking purposes. It may be possible under certain network conditions (usually when a reverse proxy or lb is involved) for network connections to terminate but not properly close. For this we should consider a heartbeat or timeout. cc @patrickjahns Some symptoms for this issue could include: - Builds not being pulled from queue - Build status not being updated with the server I will be locking this issue because there is nothing really more to say here. If one needs to discuss this issue please ping me in the main gitter channel.",source-file,"Agent does not automatically recover from network failure This issue needs more research, but is here for tracking purposes. It may be possible under certain network conditions (usually when a reverse proxy or lb is involved) for network connections to terminate but not properly close. For this we should consider a heartbeat or timeout. cc @patrickjahns Some symptoms for this issue could include: - Builds not being pulled from queue - Build status not being updated with the server I will be locking this issue because there is nothing really more to say here. If one needs to discuss this issue please ping me in the main gitter channel. source-file",no-bug,0.9
375,harness,https://github.com/harness/harness/issues/375,Docker file and webhook,"Hey Guys, How can i have drone to create a url for me after a successful build since an image is self killed after successfully completed. i was thinking of creating a dockerfile to accomplish however i am not sure how to make drone run a dockerfile since a must define a yaml file.",other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file,"Docker file and webhook Hey Guys, How can i have drone to create a url for me after a successful build since an image is self killed after successfully completed. i was thinking of creating a dockerfile to accomplish however i am not sure how to make drone run a dockerfile since a must define a yaml file. other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file",no-bug,0.9
3309,harness,https://github.com/harness/harness/issues/3309,Provide (optional) Ability to Use Docker Swarm as the Container Orchestrator,"With the ever-increasing popularity of Docker Swarm, I would love to see Drone runners interacting with the Swarm API or Drone using the Swarm natively for example when deployed within a Swarm stack etc. What I would like to do is to create services with Swarm mode replicated-jobs using Drone. Are there any works in development or future plans in the backlog? For example, launch a service called `ci-build` that has several tasks (replicated-jobs) such as `clone`, `frontend`, `backend`, `publish` etc. Current Drone features such as parallel steps would stay the same. In this case, `frontend` and `backend` tasks can be executed at the same time while `publish` `depends_on` both. The integration with Swarm would bring a lot of scalability, serviceability and portability benefits to Drone. This is just a simple use case I can think of right now but I am sure the community can benefit this integration in many different ways. There already is an entry in the forum which is long forgotten since 2018 :) https://community.harness.io/t/swarm-runtime-for-drone/8456",other-file | other-file | source-file | other-file,"Provide (optional) Ability to Use Docker Swarm as the Container Orchestrator With the ever-increasing popularity of Docker Swarm, I would love to see Drone runners interacting with the Swarm API or Drone using the Swarm natively for example when deployed within a Swarm stack etc. What I would like to do is to create services with Swarm mode replicated-jobs using Drone. Are there any works in development or future plans in the backlog? For example, launch a service called `ci-build` that has several tasks (replicated-jobs) such as `clone`, `frontend`, `backend`, `publish` etc. Current Drone features such as parallel steps would stay the same. In this case, `frontend` and `backend` tasks can be executed at the same time while `publish` `depends_on` both. The integration with Swarm would bring a lot of scalability, serviceability and portability benefits to Drone. This is just a simple use case I can think of right now but I am sure the community can benefit this integration in many different ways. There already is an entry in the forum which is long forgotten since 2018 :) https://community.harness.io/t/swarm-runtime-for-drone/8456 other-file other-file source-file other-file",no-bug,0.95
2058,harness,https://github.com/harness/harness/issues/2058,[Feature Request] ability to re-enable repo if it was disabled,"Sometimes builds get disabled and there's no simple way to re-enable and get the past history and next build. It would be great to have the ability to re-enable a past repo and have the build history come back. Right now it looks like it keeps it in the database but when enabling it just creates a ""new"" project. @bradrydzewski this is another one I'm down to take a stab at if you think it's worth it and have an idea of the best way to do it.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file,"[Feature Request] ability to re-enable repo if it was disabled Sometimes builds get disabled and there's no simple way to re-enable and get the past history and next build. It would be great to have the ability to re-enable a past repo and have the build history come back. Right now it looks like it keeps it in the database but when enabling it just creates a ""new"" project. @bradrydzewski this is another one I'm down to take a stab at if you think it's worth it and have an idea of the best way to do it. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file other-file other-file source-file source-file",no-bug,0.9
1183,harness,https://github.com/harness/harness/issues/1183,github auth defaulting to open,"Despite what the docs say, self registration is allowed unless I explicitly added `open=false` REMOTE_CONFIG=""https://github.com?client_id=$CLIENT&client_secret=$SECRET&open=false""",source-file | test-file | source-file | test-file | source-file | test-file | source-file,"github auth defaulting to open Despite what the docs say, self registration is allowed unless I explicitly added `open=false` REMOTE_CONFIG=""https://github.com?client_id=$CLIENT&client_secret=$SECRET&open=false"" source-file test-file source-file test-file source-file test-file source-file",bug,0.85
2893,harness,https://github.com/harness/harness/issues/2893,"Error ""connect: cannot assign requested address"" due to goroutine / socket leak","We recently upgraded to Drone 1.6.1 running in Kubernetes and just had an issue where all builds were failing with the following error: > Post http://localhost:3001: dial tcp 127.0.0.1:3001: connect: cannot assign requested address which is the `DRONE_CONVERT_PLUGIN_ENDPOINT` and in our case is the [drone-convert-starlark](https://github.com/drone/drone-convert-starlark) extension running as a sidecar in the pod spec. Restarting the drone-ci server pod fixed our issue. But having seen that error before (usually indicating exhaustion of ephemeral port range) I started looking into metrics and found what looks like a resource leak related to how the server calls the converter. `process_open_fds{kubernetes_namespace=""drone""}` grew to 28267 over ~22 days `go_goroutines{kubernetes_namespace=""drone""}` grew to 56547 indicating a potential issue with goroutines not returning/finishing Investigating the open connections inside the new pod we saw the connections from localhost to the converter service on 127.0.0.1:3001 were often (but not always) staying in the ESTABLISHED state. Established connections to the secret endpoint (drone-vault in our case) also may be leaking but at a much slower pace. Here you can see 4 samples each taken 10 minutes apart, showing src IPs and the local listening port they are connected to. In this data all the sockets are in the ESTABLISHED state, and you can also see the go_goroutines gauge metric is steadily increasing.  / # for run in `seq 1 10`; do uptime;netstat -nat > /dev/shm/netstat; echo ""Totals: $(curl -s 127.0.0.1:80/metrics|grep '^go_goroutines') Established $(grep 'ESTABLISHED' /dev/shm/netstat | wc -l)""; gawk 'BEGIN {OFS=""\t""} $1 ~ /tcp/ && $6 !~ /LISTEN/ && $4 ~ /:(3000|3001)$/{ndst=split($4,dst,"":"");nsrc=split($5,src,"":"");groups[(src[nsrc-1] ""-> :"" dst[ndst])]++;states[(src[nsrc-1] ""-> :"" dst[ndst])][$6]++}END{PROCINFO[""sorted_in""] = ""@val_num_desc"";for (g in groups) if (groups[g]>5) {statelist="" "";for (s in states[g]) statelist=statelist s ""="" states[g][s] "" "";print groups[g],g,statelist}}' /dev/shm/netstat; sleep 600;done; 23:50:40 up 6 days, 6:07, load average: 0.04, 0.75, 2.24 Totals: go_goroutines 2295 Established 2545 1088 127.0.0.1-> :3001 ESTABLISHED=1088 75 10.97.82.95-> :3000 ESTABLISHED=75 69 10.102.153.135-> :3000 ESTABLISHED=69 57 10.101.239.149-> :3000 ESTABLISHED=57 48 10.96.21.19-> :3000 ESTABLISHED=48 37 10.97.82.93-> :3000 ESTABLISHED=37 17 10.97.111.6-> :3000 ESTABLISHED=17 16 10.107.202.127-> :3000 ESTABLISHED=16 7 10.102.229.196-> :3000 ESTABLISHED=7 00:00:41 up 6 days, 6:17, load average: 0.00, 0.08, 1.15 Totals: go_goroutines 2350 Established 2637 1136 127.0.0.1-> :3001 ESTABLISHED=1136 77 10.97.82.95-> :3000 ESTABLISHED=77 70 10.102.153.135-> :3000 ESTABLISHED=70 55 10.101.239.149-> :3000 ESTABLISHED=55 51 10.96.21.19-> :3000 ESTABLISHED=51 38 10.97.82.93-> :3000 ESTABLISHED=38 22 10.97.111.6-> :3000 ESTABLISHED=22 18 10.107.202.127-> :3000 ESTABLISHED=18 9 10.102.229.196-> :3000 ESTABLISHED=9 00:10:41 up 6 days, 6:27, load average: 0.20, 0.10, 0.63 Totals: go_goroutines 2459 Established 2746 1167 127.0.0.1-> :3001 ESTABLISHED=1167 76 10.97.82.95-> :3000 ESTABLISHED=76 69 10.102.153.135-> :3000 ESTABLISHED=69 59 10.101.239.149-> :3000 ESTABLISHED=59 52 10.96.21.19-> :3000 ESTABLISHED=52 42 10.97.82.93-> :3000 ESTABLISHED=42 24 10.97.111.6-> :3000 ESTABLISHED=24 21 10.107.202.127-> :3000 ESTABLISHED=21 13 10.102.229.196-> :3000 ESTABLISHED=13 00:20:42 up 6 days, 6:37, load average: 0.19, 0.32, 0.47 Totals: go_goroutines 2490 Established 2785 1184 127.0.0.1-> :3001 ESTABLISHED=1184 75 10.97.82.95-> :3000 ESTABLISHED=75 69 10.102.153.135-> :3000 ESTABLISHED=69 62 10.101.239.149-> :3000 ESTABLISHED=62 55 10.96.21.19-> :3000 ESTABLISHED=55 42 10.97.82.93-> :3000 ESTABLISHED=42 24 10.97.111.6-> :3000 ESTABLISHED=24 23 10.107.202.127-> :3000 ESTABLISHED=23 15 10.102.229.196-> :3000 ESTABLISHED=15  Checking the code I do see a 60 second timeout in a few places ([remote converter method](https://github.com/drone/drone/blob/9c9b99bd70339af1d9272c2c34ae4539055aba96/plugin/converter/remote.go#L50), [http client Do method](https://github.com/drone/drone-go/blob/1d2e07e87e79109e32b9d7a1291751571433283a/plugin/internal/client/client.go#L95)) so I'd expect things to get cleaned up rather quickly, not continued growth like we're seeing. I don't see any pproff endpoints in the 1.6 server, but I hope to be able to get some stack traces via triggering a core dump using `pkill -SIGABRT $(pidof drone-server)`. Hopefully that will help track down what all the extra goroutines and sockets are doing.",other-file | source-file,"Error ""connect: cannot assign requested address"" due to goroutine / socket leak We recently upgraded to Drone 1.6.1 running in Kubernetes and just had an issue where all builds were failing with the following error: > Post http://localhost:3001: dial tcp 127.0.0.1:3001: connect: cannot assign requested address which is the `DRONE_CONVERT_PLUGIN_ENDPOINT` and in our case is the [drone-convert-starlark](https://github.com/drone/drone-convert-starlark) extension running as a sidecar in the pod spec. Restarting the drone-ci server pod fixed our issue. But having seen that error before (usually indicating exhaustion of ephemeral port range) I started looking into metrics and found what looks like a resource leak related to how the server calls the converter. `process_open_fds{kubernetes_namespace=""drone""}` grew to 28267 over ~22 days `go_goroutines{kubernetes_namespace=""drone""}` grew to 56547 indicating a potential issue with goroutines not returning/finishing Investigating the open connections inside the new pod we saw the connections from localhost to the converter service on 127.0.0.1:3001 were often (but not always) staying in the ESTABLISHED state. Established connections to the secret endpoint (drone-vault in our case) also may be leaking but at a much slower pace. Here you can see 4 samples each taken 10 minutes apart, showing src IPs and the local listening port they are connected to. In this data all the sockets are in the ESTABLISHED state, and you can also see the go_goroutines gauge metric is steadily increasing.  / # for run in `seq 1 10`; do uptime;netstat -nat > /dev/shm/netstat; echo ""Totals: $(curl -s 127.0.0.1:80/metrics|grep '^go_goroutines') Established $(grep 'ESTABLISHED' /dev/shm/netstat | wc -l)""; gawk 'BEGIN {OFS=""\t""} $1 ~ /tcp/ && $6 !~ /LISTEN/ && $4 ~ /:(3000|3001)$/{ndst=split($4,dst,"":"");nsrc=split($5,src,"":"");groups[(src[nsrc-1] ""-> :"" dst[ndst])]++;states[(src[nsrc-1] ""-> :"" dst[ndst])][$6]++}END{PROCINFO[""sorted_in""] = ""@val_num_desc"";for (g in groups) if (groups[g]>5) {statelist="" "";for (s in states[g]) statelist=statelist s ""="" states[g][s] "" "";print groups[g],g,statelist}}' /dev/shm/netstat; sleep 600;done; 23:50:40 up 6 days, 6:07, load average: 0.04, 0.75, 2.24 Totals: go_goroutines 2295 Established 2545 1088 127.0.0.1-> :3001 ESTABLISHED=1088 75 10.97.82.95-> :3000 ESTABLISHED=75 69 10.102.153.135-> :3000 ESTABLISHED=69 57 10.101.239.149-> :3000 ESTABLISHED=57 48 10.96.21.19-> :3000 ESTABLISHED=48 37 10.97.82.93-> :3000 ESTABLISHED=37 17 10.97.111.6-> :3000 ESTABLISHED=17 16 10.107.202.127-> :3000 ESTABLISHED=16 7 10.102.229.196-> :3000 ESTABLISHED=7 00:00:41 up 6 days, 6:17, load average: 0.00, 0.08, 1.15 Totals: go_goroutines 2350 Established 2637 1136 127.0.0.1-> :3001 ESTABLISHED=1136 77 10.97.82.95-> :3000 ESTABLISHED=77 70 10.102.153.135-> :3000 ESTABLISHED=70 55 10.101.239.149-> :3000 ESTABLISHED=55 51 10.96.21.19-> :3000 ESTABLISHED=51 38 10.97.82.93-> :3000 ESTABLISHED=38 22 10.97.111.6-> :3000 ESTABLISHED=22 18 10.107.202.127-> :3000 ESTABLISHED=18 9 10.102.229.196-> :3000 ESTABLISHED=9 00:10:41 up 6 days, 6:27, load average: 0.20, 0.10, 0.63 Totals: go_goroutines 2459 Established 2746 1167 127.0.0.1-> :3001 ESTABLISHED=1167 76 10.97.82.95-> :3000 ESTABLISHED=76 69 10.102.153.135-> :3000 ESTABLISHED=69 59 10.101.239.149-> :3000 ESTABLISHED=59 52 10.96.21.19-> :3000 ESTABLISHED=52 42 10.97.82.93-> :3000 ESTABLISHED=42 24 10.97.111.6-> :3000 ESTABLISHED=24 21 10.107.202.127-> :3000 ESTABLISHED=21 13 10.102.229.196-> :3000 ESTABLISHED=13 00:20:42 up 6 days, 6:37, load average: 0.19, 0.32, 0.47 Totals: go_goroutines 2490 Established 2785 1184 127.0.0.1-> :3001 ESTABLISHED=1184 75 10.97.82.95-> :3000 ESTABLISHED=75 69 10.102.153.135-> :3000 ESTABLISHED=69 62 10.101.239.149-> :3000 ESTABLISHED=62 55 10.96.21.19-> :3000 ESTABLISHED=55 42 10.97.82.93-> :3000 ESTABLISHED=42 24 10.97.111.6-> :3000 ESTABLISHED=24 23 10.107.202.127-> :3000 ESTABLISHED=23 15 10.102.229.196-> :3000 ESTABLISHED=15  Checking the code I do see a 60 second timeout in a few places ([remote converter method](https://github.com/drone/drone/blob/9c9b99bd70339af1d9272c2c34ae4539055aba96/plugin/converter/remote.go#L50), [http client Do method](https://github.com/drone/drone-go/blob/1d2e07e87e79109e32b9d7a1291751571433283a/plugin/internal/client/client.go#L95)) so I'd expect things to get cleaned up rather quickly, not continued growth like we're seeing. I don't see any pproff endpoints in the 1.6 server, but I hope to be able to get some stack traces via triggering a core dump using `pkill -SIGABRT $(pidof drone-server)`. Hopefully that will help track down what all the extra goroutines and sockets are doing. other-file source-file",no-bug,0.9
3445,harness,https://github.com/harness/harness/issues/3445,How to config the domain for gitness?,"Hello everyone, I run a gitness via docker, and I want to change this url. <img width=""766"" alt=""errd"" src=""https://github.com/harness/gitness/assets/535675/655626e1-abd1-4de4-a154-1303476b94d0""> I checked the gitness docs, but I didn't find how. Can anyone help? Thank you so mcuh.",source-file | source-file | source-file | source-file,"How to config the domain for gitness? Hello everyone, I run a gitness via docker, and I want to change this url. <img width=""766"" alt=""errd"" src=""https://github.com/harness/gitness/assets/535675/655626e1-abd1-4de4-a154-1303476b94d0""> I checked the gitness docs, but I didn't find how. Can anyone help? Thank you so mcuh. source-file source-file source-file source-file",no-bug,0.95
700,harness,https://github.com/harness/harness/issues/700,Remove/parameterize limit on /api/user/feed,Currently one has to get all repos and then iterate over `/api/repo/:host/:owner/:name` to get general build information. This makes writing status walls like `drone-wall` very cumbersome. It would be great to have an overview over the build status in the repos listing as well.,other-file | source-file | documentation-file | source-file,Remove/parameterize limit on /api/user/feed Currently one has to get all repos and then iterate over `/api/repo/:host/:owner/:name` to get general build information. This makes writing status walls like `drone-wall` very cumbersome. It would be great to have an overview over the build status in the repos listing as well. other-file source-file documentation-file source-file,no-bug,0.8
3548,harness,https://github.com/harness/harness/issues/3548,Docker Artifact push failed,"Docker push keeps getting stuck in a loop, repeatedly pushing without success. ![1](https://github.com/user-attachments/assets/686054ec-4f3a-4e76-b238-6ec17d7273d5)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Docker Artifact push failed Docker push keeps getting stuck in a loop, repeatedly pushing without success. ![1](https://github.com/user-attachments/assets/686054ec-4f3a-4e76-b238-6ec17d7273d5) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
15,harness,https://github.com/harness/harness/issues/15,Unable to complete registration after invite on clean install,"Using latest deb-file and sqlite, after a user clicks the activation link and adds their password, the register post-handler fails during saving to db complaining about token not being unique. `2014/02/08 17:24:28 meddler.Insert: DB error in Exec: column token is not unique`",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | other-file | source-file | other-file | other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | documentation-file | source-file | other-file | other-file,"Unable to complete registration after invite on clean install Using latest deb-file and sqlite, after a user clicks the activation link and adds their password, the register post-handler fails during saving to db complaining about token not being unique. `2014/02/08 17:24:28 meddler.Insert: DB error in Exec: column token is not unique` source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file test-file test-file test-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file other-file source-file other-file other-file other-file source-file documentation-file other-file other-file other-file other-file source-file other-file source-file other-file documentation-file source-file other-file other-file",no-bug,0.9
3430,harness,https://github.com/harness/harness/issues/3430,Can not login to dockerhub,"I am using [harness/gitness:3.0.0-beta.4](https://hub.docker.com/layers/harness/gitness/3.0.0-beta.4/images/sha256-a56874dd941eac647a6777678adbd6bcc791ad24d1d61f4b5cc9447cfd6433bb?context=explore). But when I using docker plugin in pipeline, something went wrong. I find [solution](https://docs.drone.io/plugins/popular/docker/#missing-username-or-password) in docs.drone.io, but it is not work for me. I am sure that password is correct, which can login success by command line. My pipeline file like below yaml kind: pipeline spec: stages: - name: build spec: platform: arch: amd64 os: linux steps: - type: plugin spec: name: docker inputs: auto_tag: true debug: true dockerfile: Dockerfile dry_run: ""false"" email: myemail force_tag: true password: dckr_pat_hxxxxxxxxxxxx_hvaQu-Kt5Tw // Anonymous token purge: ""true"" repo: ijkzen/javdb_spider username: ijkzen type: ci version: 1  debug_log is following  script latest: Pulling from plugins/docker Digest: sha256:2f157400c2cb7de1b309b0f044f119375108218e54d38e1340e00b9f93abdefb Status: Image is up to date for plugins/docker:latest + /usr/local/bin/dockerd --data-root /var/lib/docker --host=unix:var/run/docker.sock time=""2023-11-24T13:22:03.069913755Z"" level=info msg=""Starting up"" time=""2023-11-24T13:22:03.070797784Z"" level=warning msg=""could not change group /var/run/docker.sock to docker: group docker not found"" time=""2023-11-24T13:22:03.071411451Z"" level=info msg=""libcontainerd: started new containerd process"" pid=35 time=""2023-11-24T13:22:03.071432847Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpc time=""2023-11-24T13:22:03.071438966Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpc time=""2023-11-24T13:22:03.071452056Z"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:var/run/docker/containerd/containerd.sock <nil> 0 <nil>}] <nil> <nil>}"" module=grpc time=""2023-11-24T13:22:03.071461408Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpc time=""2023-11-24T13:22:03Z"" level=warning msg=""deprecated version : `1`, please switch to version `2`"" time=""2023-11-24T13:22:03.082555618Z"" level=info msg=""starting containerd"" revision=3df54a852345ae127d1fa3092b95168e4a88e2f8 version=v1.5.11 t ime=""2023-11-24T13:22:03.100989653Z"" level=info msg=""loading plugin \""io.containerd.content.v1.content\"""" type=io.containerd.content.v1 time=""2023-11-24T13:22:03.101107154Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.aufs\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.106887444Z"" level=info msg=""skip loading plugin \""io.containerd.snapshotter.v1.aufs\"""" error=""aufs is not supported (modprobe aufs failed: exit status 1 \""ip: can't find device 'aufs'\\nmodprobe: can't change directory to '/lib/modules': No such file or directory\\n\""): skip plugin"" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.106911188Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.btrfs\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107111110Z"" level=info msg=""skip loading plugin \""io.containerd.snapshotter.v1.btrfs\"""" error=""path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.btrfs (ext4) must be a btrfs filesystem to be used with the btrfs snapshotter: skip plugin"" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107136050Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.devmapper\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107155549Z"" level=warning msg=""failed to load plugin io.containerd.snapshotter.v1.devmapper"" error=""devmapper not configured"" time=""2023-11-24T13:22:03.107164009Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.native\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107286874Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.overlayfs\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107475990Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.zfs\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107625693Z"" level=info msg=""skip loading plugin \""io.containerd.snapshotter.v1.zfs\"""" error=""path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin"" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107644722Z"" level=info msg=""loading plugin \""io.containerd.metadata.v1.bolt\"""" type=io.containerd.metadata.v1 time=""2023-11-24T13:22:03.107692272Z"" level=warning msg=""could not use snapshotter devmapper in metadata plugin"" error=""devmapper not configured"" time=""2023-11-24T13:22:03.107702507Z"" level=info msg=""metadata content store policy set"" policy=shared time=""2023-11-24T13:22:03.109805594Z"" level=info msg=""loading plugin \""io.containerd.differ.v1.walking\"""" type=io.containerd.differ.v1 time=""2023-11-24T13:22:03.109827243Z"" level=info msg=""loading plugin \""io.containerd.gc.v1.scheduler\"""" type=io.containerd.gc.v1 time=""2023-11-24T13:22:03.109879255Z"" level=info msg=""loading plugin \""io.containerd.service.v1.introspection-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.109924718Z"" level=info msg=""loading plugin \""io.containerd.service.v1.containers-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.109967415Z"" level=info msg=""loading plugin \""io.containerd.service.v1.content-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110043712Z"" level=info msg=""loading plugin \""io.containerd.service.v1.diff-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110057430Z"" level=info msg=""loading plugin \""io.containerd.service.v1.images-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110067469Z"" level=info msg=""loading plugin \""io.containerd.service.v1.leases-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110093248Z"" level=info msg=""loading plugin \""io.containerd.service.v1.namespaces-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110115255Z"" level=info msg=""loading plugin \""io.containerd.service.v1.snapshots-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110136203Z"" level=info msg=""loading plugin \""io.containerd.runtime.v1.linux\"""" type=io.containerd.runtime.v1 t ime=""2023-11-24T13:22:03.110338429Z"" level=info msg=""loading plugin \""io.containerd.runtime.v2.task\"""" type=io.containerd.runtime.v2 time=""2023-11-24T13:22:03.110452834Z"" level=info msg=""loading plugin \""io.containerd.monitor.v1.cgroups\"""" type=io.containerd.monitor.v1 time=""2023-11-24T13:22:03.110686716Z"" level=info msg=""loading plugin \""io.containerd.service.v1.tasks-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110713604Z"" level=info msg=""loading plugin \""io.containerd.internal.v1.restart\"""" type=io.containerd.internal.v1 time=""2023-11-24T13:22:03.110756511Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.containers\"""" type=io.containerd.grpc.v1 t ime=""2023-11-24T13:22:03.110767713Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.content\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110787296Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.diff\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110795777Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.events\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110804828Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.healthcheck\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110813677Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.images\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110822966Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.leases\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110833586Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.namespaces\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110842360Z"" level=info msg=""loading plugin \""io.containerd.internal.v1.opt\"""" type=io.containerd.internal.v1 time=""2023-11-24T13:22:03.111021383Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.snapshots\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.111043977Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.tasks\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.111053949Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.version\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.111062391Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.introspection\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.111283097Z"" level=info msg=serving address=/var/run/docker/containerd/containerd-debug.sock time=""2023-11-24T13:22:03.111349767Z"" level=info msg=serving address=/var/run/docker/containerd/containerd.sock.ttrpc time=""2023-11-24T13:22:03.111408874Z"" level=info msg=serving address=/var/run/docker/containerd/containerd.sock time=""2023-11-24T13:22:03.111443227Z"" level=info msg=""containerd successfully booted in 0.030134s"" time=""2023-11-24T13:22:03.115054195Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpc time=""2023-11-24T13:22:03.115069431Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpc time=""2023-11-24T13:22:03.115081380Z"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:var/run/docker/containerd/containerd.sock <nil> 0 <nil>}] <nil> <nil>}"" module=grpc time=""2023-11-24T13:22:03.115088118Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpc time=""2023-11-24T13:22:03.115639278Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpc time=""2023-11-24T13:22:03.115651128Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpc time=""2023-11-24T13:22:03.115661973Z"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:var/run/docker/containerd/containerd.sock <nil> 0 <nil>}] <nil> <nil>}"" module=grpc time=""2023-11-24T13:22:03.115670029Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpc time=""2023-11-24T13:22:03.129429406Z"" level=info msg=""Loading containers: start."" time=""2023-11-24T13:22:03.170303636Z"" level=info msg=""Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"" time=""2023-11-24T13:22:03.195610323Z"" level=info msg=""Loading containers: done."" time=""2023-11-24T13:22:03.203655327Z"" level=info msg=""Docker daemon"" commit=87a90dc graphdriver(s)=overlay2 version=20.10.14 time=""2023-11-24T13:22:03.203759420Z"" level=info msg=""Daemon has completed initialization"" time=""2023-11-24T13:22:03.223018955Z"" level=info msg=""API listen on /var/run/docker.sock"" Detected registry credentials unknown shorthand flag: 'e' in -e See 'docker login --help'. time=""2023-11-24T13:22:04Z"" level=fatal msg=""error authenticating: exit status 1""  Please Help me. Thank you!",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Can not login to dockerhub I am using [harness/gitness:3.0.0-beta.4](https://hub.docker.com/layers/harness/gitness/3.0.0-beta.4/images/sha256-a56874dd941eac647a6777678adbd6bcc791ad24d1d61f4b5cc9447cfd6433bb?context=explore). But when I using docker plugin in pipeline, something went wrong. I find [solution](https://docs.drone.io/plugins/popular/docker/#missing-username-or-password) in docs.drone.io, but it is not work for me. I am sure that password is correct, which can login success by command line. My pipeline file like below yaml kind: pipeline spec: stages: - name: build spec: platform: arch: amd64 os: linux steps: - type: plugin spec: name: docker inputs: auto_tag: true debug: true dockerfile: Dockerfile dry_run: ""false"" email: myemail force_tag: true password: dckr_pat_hxxxxxxxxxxxx_hvaQu-Kt5Tw // Anonymous token purge: ""true"" repo: ijkzen/javdb_spider username: ijkzen type: ci version: 1  debug_log is following  script latest: Pulling from plugins/docker Digest: sha256:2f157400c2cb7de1b309b0f044f119375108218e54d38e1340e00b9f93abdefb Status: Image is up to date for plugins/docker:latest + /usr/local/bin/dockerd --data-root /var/lib/docker --host=unix:var/run/docker.sock time=""2023-11-24T13:22:03.069913755Z"" level=info msg=""Starting up"" time=""2023-11-24T13:22:03.070797784Z"" level=warning msg=""could not change group /var/run/docker.sock to docker: group docker not found"" time=""2023-11-24T13:22:03.071411451Z"" level=info msg=""libcontainerd: started new containerd process"" pid=35 time=""2023-11-24T13:22:03.071432847Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpc time=""2023-11-24T13:22:03.071438966Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpc time=""2023-11-24T13:22:03.071452056Z"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:var/run/docker/containerd/containerd.sock <nil> 0 <nil>}] <nil> <nil>}"" module=grpc time=""2023-11-24T13:22:03.071461408Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpc time=""2023-11-24T13:22:03Z"" level=warning msg=""deprecated version : `1`, please switch to version `2`"" time=""2023-11-24T13:22:03.082555618Z"" level=info msg=""starting containerd"" revision=3df54a852345ae127d1fa3092b95168e4a88e2f8 version=v1.5.11 t ime=""2023-11-24T13:22:03.100989653Z"" level=info msg=""loading plugin \""io.containerd.content.v1.content\"""" type=io.containerd.content.v1 time=""2023-11-24T13:22:03.101107154Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.aufs\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.106887444Z"" level=info msg=""skip loading plugin \""io.containerd.snapshotter.v1.aufs\"""" error=""aufs is not supported (modprobe aufs failed: exit status 1 \""ip: can't find device 'aufs'\\nmodprobe: can't change directory to '/lib/modules': No such file or directory\\n\""): skip plugin"" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.106911188Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.btrfs\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107111110Z"" level=info msg=""skip loading plugin \""io.containerd.snapshotter.v1.btrfs\"""" error=""path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.btrfs (ext4) must be a btrfs filesystem to be used with the btrfs snapshotter: skip plugin"" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107136050Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.devmapper\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107155549Z"" level=warning msg=""failed to load plugin io.containerd.snapshotter.v1.devmapper"" error=""devmapper not configured"" time=""2023-11-24T13:22:03.107164009Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.native\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107286874Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.overlayfs\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107475990Z"" level=info msg=""loading plugin \""io.containerd.snapshotter.v1.zfs\"""" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107625693Z"" level=info msg=""skip loading plugin \""io.containerd.snapshotter.v1.zfs\"""" error=""path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin"" type=io.containerd.snapshotter.v1 time=""2023-11-24T13:22:03.107644722Z"" level=info msg=""loading plugin \""io.containerd.metadata.v1.bolt\"""" type=io.containerd.metadata.v1 time=""2023-11-24T13:22:03.107692272Z"" level=warning msg=""could not use snapshotter devmapper in metadata plugin"" error=""devmapper not configured"" time=""2023-11-24T13:22:03.107702507Z"" level=info msg=""metadata content store policy set"" policy=shared time=""2023-11-24T13:22:03.109805594Z"" level=info msg=""loading plugin \""io.containerd.differ.v1.walking\"""" type=io.containerd.differ.v1 time=""2023-11-24T13:22:03.109827243Z"" level=info msg=""loading plugin \""io.containerd.gc.v1.scheduler\"""" type=io.containerd.gc.v1 time=""2023-11-24T13:22:03.109879255Z"" level=info msg=""loading plugin \""io.containerd.service.v1.introspection-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.109924718Z"" level=info msg=""loading plugin \""io.containerd.service.v1.containers-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.109967415Z"" level=info msg=""loading plugin \""io.containerd.service.v1.content-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110043712Z"" level=info msg=""loading plugin \""io.containerd.service.v1.diff-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110057430Z"" level=info msg=""loading plugin \""io.containerd.service.v1.images-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110067469Z"" level=info msg=""loading plugin \""io.containerd.service.v1.leases-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110093248Z"" level=info msg=""loading plugin \""io.containerd.service.v1.namespaces-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110115255Z"" level=info msg=""loading plugin \""io.containerd.service.v1.snapshots-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110136203Z"" level=info msg=""loading plugin \""io.containerd.runtime.v1.linux\"""" type=io.containerd.runtime.v1 t ime=""2023-11-24T13:22:03.110338429Z"" level=info msg=""loading plugin \""io.containerd.runtime.v2.task\"""" type=io.containerd.runtime.v2 time=""2023-11-24T13:22:03.110452834Z"" level=info msg=""loading plugin \""io.containerd.monitor.v1.cgroups\"""" type=io.containerd.monitor.v1 time=""2023-11-24T13:22:03.110686716Z"" level=info msg=""loading plugin \""io.containerd.service.v1.tasks-service\"""" type=io.containerd.service.v1 time=""2023-11-24T13:22:03.110713604Z"" level=info msg=""loading plugin \""io.containerd.internal.v1.restart\"""" type=io.containerd.internal.v1 time=""2023-11-24T13:22:03.110756511Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.containers\"""" type=io.containerd.grpc.v1 t ime=""2023-11-24T13:22:03.110767713Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.content\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110787296Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.diff\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110795777Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.events\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110804828Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.healthcheck\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110813677Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.images\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110822966Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.leases\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110833586Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.namespaces\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.110842360Z"" level=info msg=""loading plugin \""io.containerd.internal.v1.opt\"""" type=io.containerd.internal.v1 time=""2023-11-24T13:22:03.111021383Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.snapshots\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.111043977Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.tasks\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.111053949Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.version\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.111062391Z"" level=info msg=""loading plugin \""io.containerd.grpc.v1.introspection\"""" type=io.containerd.grpc.v1 time=""2023-11-24T13:22:03.111283097Z"" level=info msg=serving address=/var/run/docker/containerd/containerd-debug.sock time=""2023-11-24T13:22:03.111349767Z"" level=info msg=serving address=/var/run/docker/containerd/containerd.sock.ttrpc time=""2023-11-24T13:22:03.111408874Z"" level=info msg=serving address=/var/run/docker/containerd/containerd.sock time=""2023-11-24T13:22:03.111443227Z"" level=info msg=""containerd successfully booted in 0.030134s"" time=""2023-11-24T13:22:03.115054195Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpc time=""2023-11-24T13:22:03.115069431Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpc time=""2023-11-24T13:22:03.115081380Z"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:var/run/docker/containerd/containerd.sock <nil> 0 <nil>}] <nil> <nil>}"" module=grpc time=""2023-11-24T13:22:03.115088118Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpc time=""2023-11-24T13:22:03.115639278Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpc time=""2023-11-24T13:22:03.115651128Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpc time=""2023-11-24T13:22:03.115661973Z"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:var/run/docker/containerd/containerd.sock <nil> 0 <nil>}] <nil> <nil>}"" module=grpc time=""2023-11-24T13:22:03.115670029Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpc time=""2023-11-24T13:22:03.129429406Z"" level=info msg=""Loading containers: start."" time=""2023-11-24T13:22:03.170303636Z"" level=info msg=""Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"" time=""2023-11-24T13:22:03.195610323Z"" level=info msg=""Loading containers: done."" time=""2023-11-24T13:22:03.203655327Z"" level=info msg=""Docker daemon"" commit=87a90dc graphdriver(s)=overlay2 version=20.10.14 time=""2023-11-24T13:22:03.203759420Z"" level=info msg=""Daemon has completed initialization"" time=""2023-11-24T13:22:03.223018955Z"" level=info msg=""API listen on /var/run/docker.sock"" Detected registry credentials unknown shorthand flag: 'e' in -e See 'docker login --help'. time=""2023-11-24T13:22:04Z"" level=fatal msg=""error authenticating: exit status 1""  Please Help me. Thank you! source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
13,harness,https://github.com/harness/harness/issues/13,Why all imports are pointing to github?,"I was hacking around, to make drone work with enterprise github, but I got really frustrated, because [all imports](https://github.com/drone/drone/blob/bcaa46283892d731cfc06d7694d361db656b55dd/cmd/drone/drone.go#L13-L16) are pointed to github repo? I am newbie in go, so is it recommendation from language?",other-file | other-file | other-file | other-file | documentation-file | documentation-file | config-file | database-file | database-file | source-file | config-file,"Why all imports are pointing to github? I was hacking around, to make drone work with enterprise github, but I got really frustrated, because [all imports](https://github.com/drone/drone/blob/bcaa46283892d731cfc06d7694d361db656b55dd/cmd/drone/drone.go#L13-L16) are pointed to github repo? I am newbie in go, so is it recommendation from language? other-file other-file other-file other-file documentation-file documentation-file config-file database-file database-file source-file config-file",no-bug,0.9
272,harness,https://github.com/harness/harness/issues/272,Expose hipchat notification text as a template config,"I just started experimenting with hipchat notifications, and it'd be great if we could customize the message sent to hipchat (e.g. include a link to the commit in drone, convert emails to hipchat @nicknames, etc.). I think most of this would be solved if we could provide a template in the config.",other-file | other-file | other-file | source-file,"Expose hipchat notification text as a template config I just started experimenting with hipchat notifications, and it'd be great if we could customize the message sent to hipchat (e.g. include a link to the commit in drone, convert emails to hipchat @nicknames, etc.). I think most of this would be solved if we could provide a template in the config. other-file other-file other-file source-file",no-bug,0.9
651,harness,https://github.com/harness/harness/issues/651,Rebuild button for write-access members?,"According to (my understanding of ) the [`commit.html`](https://github.com/drone/drone/blob/50e368c24a01e1793ff607c3bba6f5cd9d190347/server/app/views/commit.html#L25) file people that have `repo.role.write` permissions should be able to see and activate rebuilds of failures. However, the people in my organization do not seem to be able to see the rebuild button. According to the `perms` table they user_id does have repo_write permission, so I'm not sure where the problem lies.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file,"Rebuild button for write-access members? According to (my understanding of ) the [`commit.html`](https://github.com/drone/drone/blob/50e368c24a01e1793ff607c3bba6f5cd9d190347/server/app/views/commit.html#L25) file people that have `repo.role.write` permissions should be able to see and activate rebuilds of failures. However, the people in my organization do not seem to be able to see the rebuild button. According to the `perms` table they user_id does have repo_write permission, so I'm not sure where the problem lies. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file",no-bug,0.8
718,harness,https://github.com/harness/harness/issues/718,Include python-ldap,"Relating to #714, can you include the ability to build and install python-ldap in the Python image? I believe it requires libsasl2, python-dev, and libldap2-dev.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Include python-ldap Relating to #714, can you include the ability to build and install python-ldap in the Python image? I believe it requires libsasl2, python-dev, and libldap2-dev. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
2814,harness,https://github.com/harness/harness/issues/2814,missing /api/info/queue endpoint documentation,"I'm thinking about how to set drone Docker workers to autoscale inside our Mesos/Marathon/Metronome cluster which isn't covered in the ""offical"" autoscaler & noticed it seems to have `/api/info/queue` endpoint that provides the needed info about the build queue - I found it referenced in a few closed tickets about it's creation but no documentation about it or any `/api/info` Is this endpoint still valid in 1.0 API? if so shouldn't it be documented?",source-file,"missing /api/info/queue endpoint documentation I'm thinking about how to set drone Docker workers to autoscale inside our Mesos/Marathon/Metronome cluster which isn't covered in the ""offical"" autoscaler & noticed it seems to have `/api/info/queue` endpoint that provides the needed info about the build queue - I found it referenced in a few closed tickets about it's creation but no documentation about it or any `/api/info` Is this endpoint still valid in 1.0 API? if so shouldn't it be documented? source-file",no-bug,0.9
3251,harness,https://github.com/harness/harness/issues/3251,[Feature] Support coding.net,,source-file | source-file | source-file | source-file | source-file | source-file | source-file,[Feature] Support coding.net  source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
402,harness,https://github.com/harness/harness/issues/402,"0.3 Release, Improve Email Notification Format","Email notifications were disabled in 0.3 and need to be re-added. I want to re-think how they are implemented, since it is kind of the oddball plugin compared to the rest. It is the only notification type that relies on configuration stored in the database ",other-file,"0.3 Release, Improve Email Notification Format Email notifications were disabled in 0.3 and need to be re-added. I want to re-think how they are implemented, since it is kind of the oddball plugin compared to the rest. It is the only notification type that relies on configuration stored in the database  other-file",no-bug,0.9
61,harness,https://github.com/harness/harness/issues/61,Clone other private repositories using Netrc file,"It would be great to be able to inject a pre-defined SSH key into containers. As part of our build process, we pull down dependencies that are in private GitHub repos. Currently there's no (easy) way of accessing these repos from Drone. This could be resolved by adding the ability to generate an SSH key that's used by containers (copied to `~/.ssh/id_rsa`), which we could then add as the deploy key for our dependencies.",source-file | source-file | source-file,"Clone other private repositories using Netrc file It would be great to be able to inject a pre-defined SSH key into containers. As part of our build process, we pull down dependencies that are in private GitHub repos. Currently there's no (easy) way of accessing these repos from Drone. This could be resolved by adding the ability to generate an SSH key that's used by containers (copied to `~/.ssh/id_rsa`), which we could then add as the deploy key for our dependencies. source-file source-file source-file",no-bug,0.9
1259,harness,https://github.com/harness/harness/issues/1259,Upgrade vendored pq library to support sslrootcert option,"I was not able to get the `sslrootcert` postgres connection option ([in the drone docs here](https://github.com/drone/drone/blob/master/docs/setup/postgres.md#postgres-options)) to work -- it seems to accept any value and have no effect. Digging deeper, it appears that the vendored version of `pq` that drone currently uses doesn't appear to support the `sslrootcert` option: there's no mention of it in the drone repo except for in documentation. Looks like this is supported in more recent versions of `pq`.",documentation-file | test-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | source-file | test-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | documentation-file | test-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | source-file | test-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file,"Upgrade vendored pq library to support sslrootcert option I was not able to get the `sslrootcert` postgres connection option ([in the drone docs here](https://github.com/drone/drone/blob/master/docs/setup/postgres.md#postgres-options)) to work -- it seems to accept any value and have no effect. Digging deeper, it appears that the vendored version of `pq` that drone currently uses doesn't appear to support the `sslrootcert` option: there's no mention of it in the drone repo except for in documentation. Looks like this is supported in more recent versions of `pq`. documentation-file test-file source-file documentation-file other-file other-file other-file other-file other-file source-file test-file test-file source-file test-file source-file source-file test-file source-file test-file source-file source-file test-file source-file test-file source-file source-file source-file documentation-file test-file source-file documentation-file other-file other-file other-file other-file other-file source-file test-file test-file source-file test-file source-file source-file test-file source-file test-file source-file source-file test-file source-file test-file source-file source-file source-file",no-bug,0.9
3396,harness,https://github.com/harness/harness/issues/3396,Failed to authenticate with credentials on repository,"I have the following compose, nothing else (yet): yaml name: gitness services: ship: image: harness/gitness:latest ports: - 3000:3000 volumes: - /var/run/docker.sock:/var/run/docker.sock - /tmp/gitness:/data - gitness:/app restart: always volumes: gitness: {}  In app I created the following credentials, on `localhost:3000` UID: `a` email: `test@test.ts` password: `Test123` And I was able to sign in, in the web UI. But once I created a private repository and tried to pull, I was asked to authenticate (obviously since it is a new remote) so I tried with both UID + pass & email + pass. Both failed on me, even after resetting the password and getting: `xnL23vsZRX` : a generated pass from gitness, it still failed for UID and email. So what could I be doing wrong?",other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | test-file | other-file | source-file | source-file,"Failed to authenticate with credentials on repository I have the following compose, nothing else (yet): yaml name: gitness services: ship: image: harness/gitness:latest ports: - 3000:3000 volumes: - /var/run/docker.sock:/var/run/docker.sock - /tmp/gitness:/data - gitness:/app restart: always volumes: gitness: {}  In app I created the following credentials, on `localhost:3000` UID: `a` email: `test@test.ts` password: `Test123` And I was able to sign in, in the web UI. But once I created a private repository and tried to pull, I was asked to authenticate (obviously since it is a new remote) so I tried with both UID + pass & email + pass. Both failed on me, even after resetting the password and getting: `xnL23vsZRX` : a generated pass from gitness, it still failed for UID and email. So what could I be doing wrong? other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file source-file other-file test-file other-file source-file source-file",no-bug,0.9
91,harness,https://github.com/harness/harness/issues/91,Make GitHub scopes configurable,cc @suguru this was brought up in issue #75 when GitHub enterprise is run in private mode it prevents using `git://` to clone public projects. This means every repository should be treated as a private repository -- using the `git@` url and adding the ssh deploy key.,source-file | test-file,Make GitHub scopes configurable cc @suguru this was brought up in issue #75 when GitHub enterprise is run in private mode it prevents using `git://` to clone public projects. This means every repository should be treated as a private repository -- using the `git@` url and adding the ssh deploy key. source-file test-file,no-bug,0.9
527,harness,https://github.com/harness/harness/issues/527,switch .deb to include drone.toml for config,,source-file | documentation-file | other-file,switch .deb to include drone.toml for config  source-file documentation-file other-file,no-bug,0.9
117,harness,https://github.com/harness/harness/issues/117,Can't see commits on RepView,![](http://f.cl.ly/items/281F2C3R1Y3W3r0X063c/github_com_Flipsicle_flipsicle_com_%C2%B7_Dashboard-2.png),other-file | other-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file,Can't see commits on RepView ![](http://f.cl.ly/items/281F2C3R1Y3W3r0X063c/github_com_Flipsicle_flipsicle_com_%C2%B7_Dashboard-2.png) other-file other-file source-file source-file source-file source-file source-file other-file other-file other-file other-file,no-bug,0.7
37,harness,https://github.com/harness/harness/issues/37,Unable to change user role to administrator - token error in database,Changing the role of a user to administrator fails with the following error: `Failed to update user data. meddler.Update: DB error in Exec: column token is not unique`,test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,Unable to change user role to administrator - token error in database Changing the role of a user to administrator fails with the following error: `Failed to update user data. meddler.Update: DB error in Exec: column token is not unique` test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file,no-bug,0.9
2140,harness,https://github.com/harness/harness/issues/2140,Compiling drone,I've seperated the drone agent and drone server and I'm not running a docker on the server running the drone server. Could you provide instructions on how to build drone or provide binaries ?,other-file | source-file | documentation-file | other-file | other-file | other-file | source-file | other-file | source-file,Compiling drone I've seperated the drone agent and drone server and I'm not running a docker on the server running the drone server. Could you provide instructions on how to build drone or provide binaries ? other-file source-file documentation-file other-file other-file other-file source-file other-file source-file,no-bug,0.9
90,harness,https://github.com/harness/harness/issues/90,"Check Docker version, show warning message","We should check for a minimum Docker version. The remote API changes between releases, and running an older version of Docker can cause panics and strange issues that are hard to debug. I'd like to check when the app first starts. If Docker is not installed, or is out of date, we should not serve any of the standard handlers. Instead we should display a single page that gives instructions to upgrade.",source-file | source-file | documentation-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | source-file,"Check Docker version, show warning message We should check for a minimum Docker version. The remote API changes between releases, and running an older version of Docker can cause panics and strange issues that are hard to debug. I'd like to check when the app first starts. If Docker is not installed, or is out of date, we should not serve any of the standard handlers. Instead we should display a single page that gives instructions to upgrade. source-file source-file documentation-file other-file other-file source-file other-file other-file other-file source-file source-file",no-bug,0.8
2143,harness,https://github.com/harness/harness/issues/2143,Additional Metrics,Since `/metrics` is not currently available to contribute to creating an issue that I'd like the following additional metrics: * Total number of builds performed * Number of activated repos,source-file | source-file | test-file | source-file,Additional Metrics Since `/metrics` is not currently available to contribute to creating an issue that I'd like the following additional metrics: * Total number of builds performed * Number of activated repos source-file source-file test-file source-file,no-bug,0.9
2172,harness,https://github.com/harness/harness/issues/2172,unable to access 'http://172.16.1.11:3000/root/go.git/',+ git init Initialized empty Git repository in /go/src/root/go/.git/ + git remote add origin http://172.16.1.11:3000/root/go.git + git fetch --no-tags origin +refs/heads/master: fatal: unable to access 'http://172.16.1.11:3000/root/go.git/': Failed to connect to 172.16.1.11 port 3000: Operation timed out exit status 128,source-file,unable to access 'http://172.16.1.11:3000/root/go.git/' + git init Initialized empty Git repository in /go/src/root/go/.git/ + git remote add origin http://172.16.1.11:3000/root/go.git + git fetch --no-tags origin +refs/heads/master: fatal: unable to access 'http://172.16.1.11:3000/root/go.git/': Failed to connect to 172.16.1.11 port 3000: Operation timed out exit status 128 source-file,no-bug,0.9
2035,harness,https://github.com/harness/harness/issues/2035,Restart will create new build number,"Restart has gotten much more complex over time. Previously when a build was restarted we just had to reset a few columns and re-run the build. But with 0.6 we now have to update multiple rows across multiple tables (matrix rows, step rows, step log rows, build row) This complexity has caused me to re-evaluate the current implementation. I believe going forward builds should be immutable. Once a build is complete the results can never be changed. Restarting a build will therefore create a new build number, and will re-direct the user to a new build results screen.",source-file | source-file | source-file,"Restart will create new build number Restart has gotten much more complex over time. Previously when a build was restarted we just had to reset a few columns and re-run the build. But with 0.6 we now have to update multiple rows across multiple tables (matrix rows, step rows, step log rows, build row) This complexity has caused me to re-evaluate the current implementation. I believe going forward builds should be immutable. Once a build is complete the results can never be changed. Restarting a build will therefore create a new build number, and will re-direct the user to a new build results screen. source-file source-file source-file",no-bug,0.9
3564,harness,https://github.com/harness/harness/issues/3564,Production Deployment,"Hi Harness team - congrats on v3.0! I would love to start hosting Harness Open Source (love the rebrand btw!) for my lab, however I would prefer to do so in a ""production-ready"" manor. There's a few features which are either missing or undocumented, and it would be great to hear if they are planned on being public, or only accessible within your managed offering for large enterprises. These features include: - Highly available deployments of Harness (2-3 node clusters) - Distributed pipeline runners (running CI pipelines on other VMs, allows easier multi-arch builds) - SSO authentication These features would bring the platform closer in-line with other open source alternatives, such as GitLab. Absolutely love what you all are doing, and look forward to whatever comes next.",source-file,"Production Deployment Hi Harness team - congrats on v3.0! I would love to start hosting Harness Open Source (love the rebrand btw!) for my lab, however I would prefer to do so in a ""production-ready"" manor. There's a few features which are either missing or undocumented, and it would be great to hear if they are planned on being public, or only accessible within your managed offering for large enterprises. These features include: - Highly available deployments of Harness (2-3 node clusters) - Distributed pipeline runners (running CI pipelines on other VMs, allows easier multi-arch builds) - SSO authentication These features would bring the platform closer in-line with other open source alternatives, such as GitLab. Absolutely love what you all are doing, and look forward to whatever comes next. source-file",no-bug,0.9
697,harness,https://github.com/harness/harness/issues/697,Support for Docker --pull Flag,"Currently, at least I couldn't find in the code how to tell drone to pull base build image before running `script` commands. We use our own build images and once we update them, drone has no way of knowing if we use the same build image tag, like `image: foo/bar:latest`. This should default to `false`, but there should be an option in `.drone.yml` to change that.  yaml image: foo/bar:latest image_pull: true script: - exit 0 ",other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | source-file | source-file,"Support for Docker --pull Flag Currently, at least I couldn't find in the code how to tell drone to pull base build image before running `script` commands. We use our own build images and once we update them, drone has no way of knowing if we use the same build image tag, like `image: foo/bar:latest`. This should default to `false`, but there should be an option in `.drone.yml` to change that.  yaml image: foo/bar:latest image_pull: true script: - exit 0  other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file source-file source-file",no-bug,0.9
412,harness,https://github.com/harness/harness/issues/412,more logging for s3 publish,"trying my go 1.3 image, seems to build and create the tarball just fine, same s3 config as before (which was working) however all I get is:  $ make build go get ./ go build -o build/red-range ./build/red-range --version 0.3.2 tar -zcf build.tgz build rm -fr build publishing to Amazon S3   and then it's marked as failed. logs don't show anything interesting, appears to complete in the logs actually, but the file is definitely not in s3  Successfully built fa13be4eb194 copying repository to /var/cache/drone/src/github.com/segmentio/red-range starting build temp directory is /tmp/drone removing build container removing build image ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"more logging for s3 publish trying my go 1.3 image, seems to build and create the tarball just fine, same s3 config as before (which was working) however all I get is:  $ make build go get ./ go build -o build/red-range ./build/red-range --version 0.3.2 tar -zcf build.tgz build rm -fr build publishing to Amazon S3   and then it's marked as failed. logs don't show anything interesting, appears to complete in the logs actually, but the file is definitely not in s3  Successfully built fa13be4eb194 copying repository to /var/cache/drone/src/github.com/segmentio/red-range starting build temp directory is /tmp/drone removing build container removing build image  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2689,harness,https://github.com/harness/harness/issues/2689,Fallback to Database when S3 Blob Not Found,this will allow teams to adopt S3 while still being able to access older logs stored in the database.,documentation-file | source-file | other-file | other-file | source-file | source-file,Fallback to Database when S3 Blob Not Found this will allow teams to adopt S3 while still being able to access older logs stored in the database. documentation-file source-file other-file other-file source-file source-file,no-bug,0.8
2596,harness,https://github.com/harness/harness/issues/2596,Streams leaking resources,"I'm raising this issue and a PR (#2597) to address memory and goroutine leaks in drone server.  The Problem I've noticed that, when using Streams, Drone was leaking go routines and heap space. I was able to reproduce it by doing the following: - Opening a new tab and access Drone - Refreshing the page multiple times (or opening multiple tabs) - Analysing the resource usage by accessing `/api/debug/pprof/`, `go tool pprof`, debug logs and chrome developer tools. The logs showed multiple connections being opened but never closed, just by refreshing the page ![connections](https://user-images.githubusercontent.com/4629568/52945024-b357c580-3368-11e9-927a-59cee9da76c9.png) Memory tracking showed that the heap never got garbage collected ![memory_pre](https://user-images.githubusercontent.com/4629568/52945400-8a840000-3369-11e9-8799-de6250d22385.png) Go routines would never terminate <img width=""2400"" alt=""goroutines"" src=""https://user-images.githubusercontent.com/4629568/52945604-01b99400-336a-11e9-8c57-5dda43b8f08b.png""> Go routines and heap usage confirmation in pprof endpoint ![pprof](https://user-images.githubusercontent.com/4629568/52945440-a4254780-3369-11e9-86a9-e71e83ee94f9.png) Idle streams not getting closed: <img width=""530"" alt=""stream duration"" src=""https://user-images.githubusercontent.com/4629568/52945765-64ab2b00-336a-11e9-806d-1836eea62822.png"">  Analysis When profiling I found the two main issues to be: **Timers memory leak** <img width=""288"" alt=""timer_leak"" src=""https://user-images.githubusercontent.com/4629568/52947069-9c67a200-336d-11e9-9dd9-cab454744523.png""> The 60 minute timer to close the stream was not actually working. This was due to the fact that a new timer was being created for every iteration of the for loop, which happened every 30 seconds when the ping timeout ran, which meant that new 60 minute timers were created every 60 seconds. This would also prevent the old timers from being garbage collected as Go won't consider them unused until they're triggered. I solved that issue by creating the timers outside of the for loop and properly reseting them only when data was flowing through the stream. **Stream not being closed** <img width=""435"" alt=""repolist"" src=""https://user-images.githubusercontent.com/4629568/52947459-accc4c80-336e-11e9-97f0-c2f1c15ff2e9.png""> Using drone with a large number of repositories (> 1000) means that the database call to retrieve the repos can generate a map of over 1MB in size. This is done for every stream (this means every tab, every page refresh, etc) and this is not cached and only cleaned up once the stream closes. Since the stream was not closing, the memory usage gets very high very quickly. The fix for this is to ensure the 1 hour idle timeout actually works and all this data can eventually be garbage collected. I also added some handlers to close the stream based on the gin context.  The Fix Memory being freed and reused after the 1 hour idle timeout ![post memory](https://user-images.githubusercontent.com/4629568/52945996-edc26200-336a-11e9-834d-51283db166af.png) Connections being properly closed by the server and reopened by the browser after the default 3 seconds ![post_conn](https://user-images.githubusercontent.com/4629568/52948188-b5be1d80-3370-11e9-9029-62e56cf3c20d.png) Testing the timers, both the ping and the idle timer work <img width=""335"" alt=""timers"" src=""https://user-images.githubusercontent.com/4629568/52946695-8c9b8e00-336c-11e9-8c05-63cd736fed65.png"">",source-file | source-file | source-file | source-file,"Streams leaking resources I'm raising this issue and a PR (#2597) to address memory and goroutine leaks in drone server.  The Problem I've noticed that, when using Streams, Drone was leaking go routines and heap space. I was able to reproduce it by doing the following: - Opening a new tab and access Drone - Refreshing the page multiple times (or opening multiple tabs) - Analysing the resource usage by accessing `/api/debug/pprof/`, `go tool pprof`, debug logs and chrome developer tools. The logs showed multiple connections being opened but never closed, just by refreshing the page ![connections](https://user-images.githubusercontent.com/4629568/52945024-b357c580-3368-11e9-927a-59cee9da76c9.png) Memory tracking showed that the heap never got garbage collected ![memory_pre](https://user-images.githubusercontent.com/4629568/52945400-8a840000-3369-11e9-8799-de6250d22385.png) Go routines would never terminate <img width=""2400"" alt=""goroutines"" src=""https://user-images.githubusercontent.com/4629568/52945604-01b99400-336a-11e9-8c57-5dda43b8f08b.png""> Go routines and heap usage confirmation in pprof endpoint ![pprof](https://user-images.githubusercontent.com/4629568/52945440-a4254780-3369-11e9-86a9-e71e83ee94f9.png) Idle streams not getting closed: <img width=""530"" alt=""stream duration"" src=""https://user-images.githubusercontent.com/4629568/52945765-64ab2b00-336a-11e9-806d-1836eea62822.png"">  Analysis When profiling I found the two main issues to be: **Timers memory leak** <img width=""288"" alt=""timer_leak"" src=""https://user-images.githubusercontent.com/4629568/52947069-9c67a200-336d-11e9-9dd9-cab454744523.png""> The 60 minute timer to close the stream was not actually working. This was due to the fact that a new timer was being created for every iteration of the for loop, which happened every 30 seconds when the ping timeout ran, which meant that new 60 minute timers were created every 60 seconds. This would also prevent the old timers from being garbage collected as Go won't consider them unused until they're triggered. I solved that issue by creating the timers outside of the for loop and properly reseting them only when data was flowing through the stream. **Stream not being closed** <img width=""435"" alt=""repolist"" src=""https://user-images.githubusercontent.com/4629568/52947459-accc4c80-336e-11e9-97f0-c2f1c15ff2e9.png""> Using drone with a large number of repositories (> 1000) means that the database call to retrieve the repos can generate a map of over 1MB in size. This is done for every stream (this means every tab, every page refresh, etc) and this is not cached and only cleaned up once the stream closes. Since the stream was not closing, the memory usage gets very high very quickly. The fix for this is to ensure the 1 hour idle timeout actually works and all this data can eventually be garbage collected. I also added some handlers to close the stream based on the gin context.  The Fix Memory being freed and reused after the 1 hour idle timeout ![post memory](https://user-images.githubusercontent.com/4629568/52945996-edc26200-336a-11e9-834d-51283db166af.png) Connections being properly closed by the server and reopened by the browser after the default 3 seconds ![post_conn](https://user-images.githubusercontent.com/4629568/52948188-b5be1d80-3370-11e9-9029-62e56cf3c20d.png) Testing the timers, both the ping and the idle timer work <img width=""335"" alt=""timers"" src=""https://user-images.githubusercontent.com/4629568/52946695-8c9b8e00-336c-11e9-8c05-63cd736fed65.png""> source-file source-file source-file source-file",no-bug,0.9
2296,harness,https://github.com/harness/harness/issues/2296,In drone got an error /bin/sh: 1: base64: not found .,"**My .drone.yml file as follows code .**  branches: include: [ master, dev ] exclude: [ develop, feature/* ] clone: git: image: plugins/git depth: 50 workspace: base: /go path: src/xink.com/metis pipeline: build: when: branch: master image: golang:alpine volumes: - /var/run/docker.sock:/var/run/docker.sock # - /usr/bin/base64:/bin/base64 environment: - CGO=0 - GOOS=linux - GOARCH=amd64 - PATH=$PATH:/go - GOPATH=/go commands: - go env - go build -v -o metis  ![tim 20180110105337](https://user-images.githubusercontent.com/18027793/34759158-27e78530-f615-11e7-9d47-812de0b7a5c2.png) **When push code the Drone start pipeline build step. I try "" /usr/bin/base64:/bin/base64 "" by volumes but got "" standard_init_linux.go:195: exec user process caused 'no such file or directory' "" .** ![tim 20180110144744](https://user-images.githubusercontent.com/18027793/34759175-3c58dcc6-f615-11e7-9e27-43244dd31a04.png) _**I make file as follows code got successful status.**_  branches: include: [ master, dev ] exclude: [ develop, feature/* ] clone: git: image: plugins/git depth: 50 workspace: base: /go path: src/xink.com/metis pipeline: build: when: branch: master image: golang:alpine commands: go build -v -o metis  ![tim 333](https://user-images.githubusercontent.com/18027793/34759231-6e9c23b4-f615-11e7-8146-d2d2f19586d8.png) **So  I think this should be a bug in resolve .drone.yml at ""environment"",""commands"",""volumes"" node with multiple parameters or my .drone.yml configuration file is wrong **",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"In drone got an error /bin/sh: 1: base64: not found . **My .drone.yml file as follows code .**  branches: include: [ master, dev ] exclude: [ develop, feature/* ] clone: git: image: plugins/git depth: 50 workspace: base: /go path: src/xink.com/metis pipeline: build: when: branch: master image: golang:alpine volumes: - /var/run/docker.sock:/var/run/docker.sock # - /usr/bin/base64:/bin/base64 environment: - CGO=0 - GOOS=linux - GOARCH=amd64 - PATH=$PATH:/go - GOPATH=/go commands: - go env - go build -v -o metis  ![tim 20180110105337](https://user-images.githubusercontent.com/18027793/34759158-27e78530-f615-11e7-9d47-812de0b7a5c2.png) **When push code the Drone start pipeline build step. I try "" /usr/bin/base64:/bin/base64 "" by volumes but got "" standard_init_linux.go:195: exec user process caused 'no such file or directory' "" .** ![tim 20180110144744](https://user-images.githubusercontent.com/18027793/34759175-3c58dcc6-f615-11e7-9e27-43244dd31a04.png) _**I make file as follows code got successful status.**_  branches: include: [ master, dev ] exclude: [ develop, feature/* ] clone: git: image: plugins/git depth: 50 workspace: base: /go path: src/xink.com/metis pipeline: build: when: branch: master image: golang:alpine commands: go build -v -o metis  ![tim 333](https://user-images.githubusercontent.com/18027793/34759231-6e9c23b4-f615-11e7-8146-d2d2f19586d8.png) **So  I think this should be a bug in resolve .drone.yml at ""environment"",""commands"",""volumes"" node with multiple parameters or my .drone.yml configuration file is wrong ** source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
660,harness,https://github.com/harness/harness/issues/660,Display login failure messages,"When using Drone with GitLab and using invalid credentials, the page shows a white screen. It would be helpful for the end user if there was an error message shown.",source-file,"Display login failure messages When using Drone with GitLab and using invalid credentials, the page shows a white screen. It would be helpful for the end user if there was an error message shown. source-file",bug,0.85
2130,harness,https://github.com/harness/harness/issues/2130,API scopes for personal tokens,"moved from https://github.com/drone/drone/issues/1812#issuecomment-253182687 > I don't mind having a real github user and then using drone to generate JWTs with different scopes. Would that be possible? yes, I think this would be a good compromise. you can find the token code here: https://github.com/drone/drone/blob/master/shared/token/token.go we could do something like this:  diff type Token struct { Kind string Text string + Scope []string // []string { ""repo:read"", ""repo:write"", ""repo:admin"" }  + Repos []string // []string { ""drone/drone"", ""drone/docs"" } }  Defining a set of scopes will be a bit of a challenge since I'm not sure how granular we want to get, so perhaps we can split this into phases. The first phase could be to add Repos. If the Repos slice is empty we can assume there are no restrictions. Otherwise if the repos slice is not empty we match the current repo to the contents of the slice. Once we have this working, we can get an RFC together with some fine-grained scopes. We should be able to solicit community input for this to make sure we have all of our bases covered.",other-file | source-file | other-file | other-file,"API scopes for personal tokens moved from https://github.com/drone/drone/issues/1812#issuecomment-253182687 > I don't mind having a real github user and then using drone to generate JWTs with different scopes. Would that be possible? yes, I think this would be a good compromise. you can find the token code here: https://github.com/drone/drone/blob/master/shared/token/token.go we could do something like this:  diff type Token struct { Kind string Text string + Scope []string // []string { ""repo:read"", ""repo:write"", ""repo:admin"" }  + Repos []string // []string { ""drone/drone"", ""drone/docs"" } }  Defining a set of scopes will be a bit of a challenge since I'm not sure how granular we want to get, so perhaps we can split this into phases. The first phase could be to add Repos. If the Repos slice is empty we can assume there are no restrictions. Otherwise if the repos slice is not empty we match the current repo to the contents of the slice. Once we have this working, we can get an RFC together with some fine-grained scopes. We should be able to solicit community input for this to make sure we have all of our bases covered. other-file source-file other-file other-file",no-bug,0.9
206,harness,https://github.com/harness/harness/issues/206,Builds hanging when fetching a repository,"I'm having an issue where my drone builds are occasionally hanging while fetching a repository. The docker container is still running afterwards, but the build is stuck in the 'Started' state forever. I'm wondering if maybe it's related to https://github.com/dotcloud/docker/issues/1474 ? Full drone logs: https://gist.github.com/mnutt/f422b2d84808f0e983bd (another PR came in halfway through the build so it's a bit convoluted)",source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file,"Builds hanging when fetching a repository I'm having an issue where my drone builds are occasionally hanging while fetching a repository. The docker container is still running afterwards, but the build is stuck in the 'Started' state forever. I'm wondering if maybe it's related to https://github.com/dotcloud/docker/issues/1474 ? Full drone logs: https://gist.github.com/mnutt/f422b2d84808f0e983bd (another PR came in halfway through the build so it's a bit convoluted) source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file",no-bug,0.9
2815,harness,https://github.com/harness/harness/issues/2815,API call to create PR builds,"Currently working on this but my `go` is still weak. There are API calls to create builds, but these will be push event ones. Being able to create a build from a pull request number would be great. https://github.com/drone/drone/blob/master/handler/api/repos/builds/create.go",source-file | source-file | source-file | source-file,"API call to create PR builds Currently working on this but my `go` is still weak. There are API calls to create builds, but these will be push event ones. Being able to create a build from a pull request number would be great. https://github.com/drone/drone/blob/master/handler/api/repos/builds/create.go source-file source-file source-file source-file",no-bug,0.2
1701,harness,https://github.com/harness/harness/issues/1701,"[gogs] Incorrect resolution of relative ""avatar_url""","Drone is showing all broken images as avatars for repositories from Gogs source. I've seen it's due to relative URLs being found in ""avatar_url"" element of the `api/v1/orgs/orgname` endpoint, for example: `""avatar_url"":""/gogs/avatars/6""` Drone is turning that into an url relative to the Drone url, not the Gogs url.",source-file | test-file,"[gogs] Incorrect resolution of relative ""avatar_url"" Drone is showing all broken images as avatars for repositories from Gogs source. I've seen it's due to relative URLs being found in ""avatar_url"" element of the `api/v1/orgs/orgname` endpoint, for example: `""avatar_url"":""/gogs/avatars/6""` Drone is turning that into an url relative to the Drone url, not the Gogs url. source-file test-file",bug,0.9
3529,harness,https://github.com/harness/harness/issues/3529,Gitness - Unauthenticated Git Pulls,"When setting a repository to Public under Gitness (which is described as ""Anyone with access to the Gitness environment can clone this repo""), browsing the repository via the Web UI is not possible, however, unauthenticated git pulls are. Personally, I'd be fine if Public on Gitness meant what Protected/Internal means everywhere else (if you can log in to Gitness, you can see and work with the repo), but this is a weird combination of both Public as in ""everyone in the world"" (can git pull), and Public as in ""everyone with an account"" (can see the repo in their browser) Is this a bug, or is this intended behaviour? It might be worthwhile to clarify the note on the visibility level if this is intended - point out that you don't need an account to do a pull.",source-file,"Gitness - Unauthenticated Git Pulls When setting a repository to Public under Gitness (which is described as ""Anyone with access to the Gitness environment can clone this repo""), browsing the repository via the Web UI is not possible, however, unauthenticated git pulls are. Personally, I'd be fine if Public on Gitness meant what Protected/Internal means everywhere else (if you can log in to Gitness, you can see and work with the repo), but this is a weird combination of both Public as in ""everyone in the world"" (can git pull), and Public as in ""everyone with an account"" (can see the repo in their browser) Is this a bug, or is this intended behaviour? It might be worthwhile to clarify the note on the visibility level if this is intended - point out that you don't need an account to do a pull. source-file",no-bug,0.8
531,harness,https://github.com/harness/harness/issues/531,Mysql driver problem,"Hi! I've installed drone with the mysql driver. All went well, untill I started building a repository. I've used a gitlab repository. And it seems that drone tries to clone it with user/password combination instead of using the ssh keys. I converted that setup into the default sqlite database and all went well. In the mysql repo table, the username and password was an empty string, instead of NULL. Could this be the bug?",other-file | source-file | other-file | other-file | other-file,"Mysql driver problem Hi! I've installed drone with the mysql driver. All went well, untill I started building a repository. I've used a gitlab repository. And it seems that drone tries to clone it with user/password combination instead of using the ssh keys. I converted that setup into the default sqlite database and all went well. In the mysql repo table, the username and password was an empty string, instead of NULL. Could this be the bug? other-file source-file other-file other-file other-file",no-bug,0.9
1533,harness,https://github.com/harness/harness/issues/1533,View for only activated repos,"The list of repos in the main view of drone can get very long, and it's difficult to tell which are actually active. This is a suggestion to split the repo screen into 2 - one that shows only activated projects and one that shows you all where you can choose to activate any of them.",source-file | other-file | other-file | source-file | source-file,"View for only activated repos The list of repos in the main view of drone can get very long, and it's difficult to tell which are actually active. This is a suggestion to split the repo screen into 2 - one that shows only activated projects and one that shows you all where you can choose to activate any of them. source-file other-file other-file source-file source-file",no-bug,0.9
2088,harness,https://github.com/harness/harness/issues/2088,Provide list of injected secrets in environment variables,"Plugin authors would like the ability to see a list of injected secrets. The proposal is that we would provide a `PLUGIN_SECRETS` environment variable that would include a comma-separated list of secrets passed to that plugin. So for the below yaml:  docker: image: plugins/docker repo: octocat/hello-world secrets: [docker_username, docker_password]  the docker plugin would receive the following environment variables:  PLUGIN_SECRETS=DOCKER_USERNAME,DOCKER_PASSWORD  cc @stephansnyt @dellintosh",other-file | other-file | source-file | source-file,"Provide list of injected secrets in environment variables Plugin authors would like the ability to see a list of injected secrets. The proposal is that we would provide a `PLUGIN_SECRETS` environment variable that would include a comma-separated list of secrets passed to that plugin. So for the below yaml:  docker: image: plugins/docker repo: octocat/hello-world secrets: [docker_username, docker_password]  the docker plugin would receive the following environment variables:  PLUGIN_SECRETS=DOCKER_USERNAME,DOCKER_PASSWORD  cc @stephansnyt @dellintosh other-file other-file source-file source-file",no-bug,0.9
3037,harness,https://github.com/harness/harness/issues/3037,disable,"version: '2' services: drone-server: image: drone/drone:latest ports: - 8080:80 volumes: - /var/lib/drone:/var/lib/drone/ restart: always environment: - DRONE_OPEN=true - DRONE_SERVER_HOST=192.168.101.65:8080 - DRONE_GITLAB=true - DRONE_SERVER_PROTO=http - DRONE_AGENTS_ENABLED=true - DRONE_GITLAB_SKIP_VERIFY=true - DRONE_GITLAB_SERVER=http://192.168.101.244/ - DRONE_GITLAB_CLIENT_ID=<id> - DRONE_GITLAB_CLIENT_SECRET=<secret> - DRONE_SECRET=<secret> - DRONE_LOGS_TRACE=true drone-agent: image: drone/agent:latest restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=http://192.168.101.65:8080 - DRONE_SECRET=<secret> - DRONE_LOGS_TRACE=true - DRONE_RPC_PROTO=http drone-agent_1 | 2020/11/13 08:15:09 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:09 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 10s (24 left) drone-agent_1 | 2020/11/13 08:15:19 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:19 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 10s (23 left) drone-agent_1 | 2020/11/13 08:15:29 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:29 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 10s (22 left) drone-agent_1 | 2020/11/13 08:15:39 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: context deadline exceeded drone-agent_1 | {""arch"":""amd64"",""level"":""debug"",""machine"":""4de0cd74800b"",""msg"":""runner: polling queue"",""os"":""linux"",""time"":""2020-11-13T08:15:39Z""} drone-agent_1 | 2020/11/13 08:15:39 [DEBUG] POST http://localhost:8080/rpc/v1/request drone-agent_1 | 2020/11/13 08:15:39 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:39 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 1s (30 left) drone-agent_1 | 2020/11/13 08:15:40 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:40 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 2s (29 left) drone-agent_1 | 2020/11/13 08:15:42 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:42 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 4s (28 left)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file,"disable version: '2' services: drone-server: image: drone/drone:latest ports: - 8080:80 volumes: - /var/lib/drone:/var/lib/drone/ restart: always environment: - DRONE_OPEN=true - DRONE_SERVER_HOST=192.168.101.65:8080 - DRONE_GITLAB=true - DRONE_SERVER_PROTO=http - DRONE_AGENTS_ENABLED=true - DRONE_GITLAB_SKIP_VERIFY=true - DRONE_GITLAB_SERVER=http://192.168.101.244/ - DRONE_GITLAB_CLIENT_ID=<id> - DRONE_GITLAB_CLIENT_SECRET=<secret> - DRONE_SECRET=<secret> - DRONE_LOGS_TRACE=true drone-agent: image: drone/agent:latest restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=http://192.168.101.65:8080 - DRONE_SECRET=<secret> - DRONE_LOGS_TRACE=true - DRONE_RPC_PROTO=http drone-agent_1 | 2020/11/13 08:15:09 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:09 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 10s (24 left) drone-agent_1 | 2020/11/13 08:15:19 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:19 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 10s (23 left) drone-agent_1 | 2020/11/13 08:15:29 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:29 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 10s (22 left) drone-agent_1 | 2020/11/13 08:15:39 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: context deadline exceeded drone-agent_1 | {""arch"":""amd64"",""level"":""debug"",""machine"":""4de0cd74800b"",""msg"":""runner: polling queue"",""os"":""linux"",""time"":""2020-11-13T08:15:39Z""} drone-agent_1 | 2020/11/13 08:15:39 [DEBUG] POST http://localhost:8080/rpc/v1/request drone-agent_1 | 2020/11/13 08:15:39 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:39 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 1s (30 left) drone-agent_1 | 2020/11/13 08:15:40 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:40 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 2s (29 left) drone-agent_1 | 2020/11/13 08:15:42 [ERR] POST http://localhost:8080/rpc/v1/request request failed: Post http://localhost:8080/rpc/v1/request: dial tcp 127.0.0.1:8080: connect: connection refused drone-agent_1 | 2020/11/13 08:15:42 [DEBUG] POST http://localhost:8080/rpc/v1/request: retrying in 4s (28 left) source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file source-file source-file",no-bug,0.9
152,harness,https://github.com/harness/harness/issues/152,SSH keys at user level?,"This comment pretty much sums it up: > Yes, I took that generated key, removed it from the 'deployment keys' on Github and added it to our 'automation github user'. However, as we have various projects with private dependencies, it gets quite cumbersome to repeat this for every new project. I think we have a couple of options **Option 1** We can allow the repository public and private key to be updated via the website (they are currently readonly). If we do this, do we need to add/replace the public key in GitHub? **Option 2** We can add a public key at the GitHub user account. We can add a checkbox on the repository screen that instructs the build to use the key at the user level. Option 1 is probably the easiest",source-file | source-file | container-file,"SSH keys at user level? This comment pretty much sums it up: > Yes, I took that generated key, removed it from the 'deployment keys' on Github and added it to our 'automation github user'. However, as we have various projects with private dependencies, it gets quite cumbersome to repeat this for every new project. I think we have a couple of options **Option 1** We can allow the repository public and private key to be updated via the website (they are currently readonly). If we do this, do we need to add/replace the public key in GitHub? **Option 2** We can add a public key at the GitHub user account. We can add a checkbox on the repository screen that instructs the build to use the key at the user level. Option 1 is probably the easiest source-file source-file container-file",no-bug,0.9
2658,harness,https://github.com/harness/harness/issues/2658,Sync issues when repository deleted and re-created,"When a repository is deleted and then re-created with the same name, Drone is unable to add the repository to list because an entry with the same name exists but a different unique identifier. We should be able to account for this in the synchornization process. If not, we should log some sort of error and then give a way to manually purge a repository by name from the database as a workaround.",source-file | other-file | other-file | test-file,"Sync issues when repository deleted and re-created When a repository is deleted and then re-created with the same name, Drone is unable to add the repository to list because an entry with the same name exists but a different unique identifier. We should be able to account for this in the synchornization process. If not, we should log some sort of error and then give a way to manually purge a repository by name from the database as a workaround. source-file other-file other-file test-file",no-bug,0.9
2726,harness,https://github.com/harness/harness/issues/2726,Wrong node affinity on EKS cluster,"## Problem When Drone configures affinity of pipelines' pods, it sets this chunk of code: yaml spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - ip-10-100-45-161.eu-west-1.compute.internal  Correct me if I'm wrong, but this affinity seems to be set based on pipeline's pod `spec.nodeName`. On AWS EKS, worker nodes names are tagged like `${HOST_DNS}.${AWS_REGION}.compute.internal`, but Kubernetes' label `kubernetes.io/hostname` is set to the actual host name of the EC2 instance, `${HOST_DNS}`, e.g.: bash kubectl get nodes -L kubernetes.io/hostname NAME STATUS ROLES AGE VERSION HOSTNAME ip-10-100-15-22.eu-west-1.compute.internal Ready <none> 12d v1.12.7 ip-10-100-15-22 ip-10-100-45-161.eu-west-1.compute.internal Ready <none> 121m v1.12.7 ip-10-100-45-161 ip-10-100-63-36.eu-west-1.compute.internal Ready <none> 11d v1.12.7 ip-10-100-63-36  So, when the pipeline launches a new namespace to run all the steps of the pipeline, child jobs have the upper affinity, and never find a node to schedule the pod. ## Possible solution You can set your nodes label `kubernetes.io/hostname` to the node name manually, and Drone would launch pods without errors. But maybe Drone should use another type of affinity, or none affinity at all, but I assume that the affinity setting is there for a reason. Let me know if you need more information. Thank you for everything!",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | other-file | other-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | source-file | documentation-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | other-file | source-file | other-file | other-file | test-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | other-file | other-file | other-file | documentation-file | source-file | other-file,"Wrong node affinity on EKS cluster ## Problem When Drone configures affinity of pipelines' pods, it sets this chunk of code: yaml spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - ip-10-100-45-161.eu-west-1.compute.internal  Correct me if I'm wrong, but this affinity seems to be set based on pipeline's pod `spec.nodeName`. On AWS EKS, worker nodes names are tagged like `${HOST_DNS}.${AWS_REGION}.compute.internal`, but Kubernetes' label `kubernetes.io/hostname` is set to the actual host name of the EC2 instance, `${HOST_DNS}`, e.g.: bash kubectl get nodes -L kubernetes.io/hostname NAME STATUS ROLES AGE VERSION HOSTNAME ip-10-100-15-22.eu-west-1.compute.internal Ready <none> 12d v1.12.7 ip-10-100-15-22 ip-10-100-45-161.eu-west-1.compute.internal Ready <none> 121m v1.12.7 ip-10-100-45-161 ip-10-100-63-36.eu-west-1.compute.internal Ready <none> 11d v1.12.7 ip-10-100-63-36  So, when the pipeline launches a new namespace to run all the steps of the pipeline, child jobs have the upper affinity, and never find a node to schedule the pod. ## Possible solution You can set your nodes label `kubernetes.io/hostname` to the node name manually, and Drone would launch pods without errors. But maybe Drone should use another type of affinity, or none affinity at all, but I assume that the affinity setting is there for a reason. Let me know if you need more information. Thank you for everything! other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file other-file other-file source-file source-file source-file other-file source-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file other-file source-file other-file source-file other-file other-file source-file source-file documentation-file source-file other-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file test-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file source-file other-file source-file other-file other-file test-file other-file other-file source-file other-file other-file other-file documentation-file other-file other-file other-file documentation-file source-file other-file",no-bug,0.95
2655,harness,https://github.com/harness/harness/issues/2655,How can I build a docker image with the drone source code?,or where is the docker makefile?,other-file | source-file,How can I build a docker image with the drone source code? or where is the docker makefile? other-file source-file,no-bug,0.9
725,harness,https://github.com/harness/harness/issues/725,Resync hooks,"Hi, I've accidently deleted my drone.io hook for a repository on GitHub Enterprise. How can I resync it / Re-Add the repository? Best regards, Michael",source-file | source-file | source-file,"Resync hooks Hi, I've accidently deleted my drone.io hook for a repository on GitHub Enterprise. How can I resync it / Re-Add the repository? Best regards, Michael source-file source-file source-file",no-bug,0.9
2633,harness,https://github.com/harness/harness/issues/2633,"on cloud.drone.io, i can't find my github public repo 'v7lin/fake_http'",<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> i have try 'SYNC' button many times.,other-file | other-file | other-file | other-file,"on cloud.drone.io, i can't find my github public repo 'v7lin/fake_http' <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified with community support: https://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> i have try 'SYNC' button many times. other-file other-file other-file other-file",no-bug,0.9
2552,harness,https://github.com/harness/harness/issues/2552,How to use Drone with self-hosted git repository,I've been searching and asking forums about this: is it possible to use Drone with self-hosted git repositories (**without** GitHub or GitLab) ?,other-file | other-file | other-file | other-file | other-file | other-file,How to use Drone with self-hosted git repository I've been searching and asking forums about this: is it possible to use Drone with self-hosted git repositories (**without** GitHub or GitLab) ? other-file other-file other-file other-file other-file other-file,no-bug,0.9
2908,harness,https://github.com/harness/harness/issues/2908,Build-limit confusion,"# This belongs to Discourse but I seem not to have permissions to create topics there. Hi, [Licensing and subscription FAQ](https://discourse.drone.io/t/licensing-and-subscription-faq/3839) states the following: >**Is Drone Enterprise Edition Free?** >Yes , the official docker image provides free access to all Drone Enterprise features, for up to 5,000 builds. This includes both commercial and non-commercial use. But [Open Source / Enterpise comparison matrix](https://drone.io/enterprise/features/) states that **Builds** for Open Source and Enterprise are both unlimited. Which statement is correct?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Build-limit confusion # This belongs to Discourse but I seem not to have permissions to create topics there. Hi, [Licensing and subscription FAQ](https://discourse.drone.io/t/licensing-and-subscription-faq/3839) states the following: >**Is Drone Enterprise Edition Free?** >Yes , the official docker image provides free access to all Drone Enterprise features, for up to 5,000 builds. This includes both commercial and non-commercial use. But [Open Source / Enterpise comparison matrix](https://drone.io/enterprise/features/) states that **Builds** for Open Source and Enterprise are both unlimited. Which statement is correct? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2793,harness,https://github.com/harness/harness/issues/2793,Drone missing nsswitch.conf,When pulling drone:1.1.0 there seems to be a regression from when this was last fixed in #1306 Drone no longer seems to respect /etc/hosts.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Drone missing nsswitch.conf When pulling drone:1.1.0 there seems to be a regression from when this was last fixed in #1306 Drone no longer seems to respect /etc/hosts. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.8
283,harness,https://github.com/harness/harness/issues/283,Shared Deployment Key,"Hi, I have put this [uservoice](http://drone.uservoice.com/forums/176976-feedback-for-drone-io/suggestions/5812947-shared-deployment-key), though I don't think it is receiving any love, so I post here as well. Feel free to close it down if it is not the appropriate place. Currently, each build has its own deployment key. It doesn't really scale well with my requirement. My project setup is like this: - There is 1 parent project that is the dependencies for all other projects. - There are lots of children projects that will clone that parent project during the build process. These children projects are the ones imported to drone. I can work around it by adding the key of the children projects one-by-one to the deployment key of the parent project. This doesn't scale well since I have hundreds of child projects. Can I have some kind of a shared key that the child projects share so I only need to add that one shared key to the deployment keys of the parent project?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | other-file | other-file | documentation-file,"Shared Deployment Key Hi, I have put this [uservoice](http://drone.uservoice.com/forums/176976-feedback-for-drone-io/suggestions/5812947-shared-deployment-key), though I don't think it is receiving any love, so I post here as well. Feel free to close it down if it is not the appropriate place. Currently, each build has its own deployment key. It doesn't really scale well with my requirement. My project setup is like this: - There is 1 parent project that is the dependencies for all other projects. - There are lots of children projects that will clone that parent project during the build process. These children projects are the ones imported to drone. I can work around it by adding the key of the children projects one-by-one to the deployment key of the parent project. This doesn't scale well since I have hundreds of child projects. Can I have some kind of a shared key that the child projects share so I only need to add that one shared key to the deployment keys of the parent project? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file other-file other-file documentation-file",no-bug,0.9
2832,harness,https://github.com/harness/harness/issues/2832,"manager: cannot find stage error=""<nil>""","I'm playing with the webhook functionality. I noticed this in the drone-server logs  WARN[0179] manager: cannot find stage error=""<nil>"" step-id=46  I feel like this code is wrong, and should be `err != nil` https://github.com/drone/drone/blob/master/operator/manager/manager.go#L468",source-file | source-file,"manager: cannot find stage error=""<nil>"" I'm playing with the webhook functionality. I noticed this in the drone-server logs  WARN[0179] manager: cannot find stage error=""<nil>"" step-id=46  I feel like this code is wrong, and should be `err != nil` https://github.com/drone/drone/blob/master/operator/manager/manager.go#L468 source-file source-file",no-bug,0.8
2463,harness,https://github.com/harness/harness/issues/2463,Override kubernetes vault token ttl and renewal,Proposed patch to enable customization of kubernetes vault ttl and token renewal. Source https://github.com/drone/drone/blob/master/plugins/secrets/vault/vault.go#L93:v94 diff +if v.ttl == 0 { v.ttl = ttl +} +if v.renew == 0 { v.renew = ttl / 2 +}  cc @praxist let me know your thoughts. I just want to make sure there aren't any gotchas that I'm not considering with this patch.,source-file | source-file | database-file,Override kubernetes vault token ttl and renewal Proposed patch to enable customization of kubernetes vault ttl and token renewal. Source https://github.com/drone/drone/blob/master/plugins/secrets/vault/vault.go#L93:v94 diff +if v.ttl == 0 { v.ttl = ttl +} +if v.renew == 0 { v.renew = ttl / 2 +}  cc @praxist let me know your thoughts. I just want to make sure there aren't any gotchas that I'm not considering with this patch. source-file source-file database-file,no-bug,0.9
289,harness,https://github.com/harness/harness/issues/289,script: not running,"When I call `drone build` from the command line the script: directive seems to run.  Step 16 : ENTRYPOINT /bin/bash -e /usr/local/bin/drone > Running in 157f36889c98 > f16c8aa5f495 Successfully built f16c8aa5f495 Removing intermediate container 024db1734ee0 Removing intermediate container 105d29809ef1 Removing intermediate container 211ffe648def Removing intermediate container 2dca87e78256 Removing intermediate container 411381c4d740 Removing intermediate container 1161cd2a8ab8 Removing intermediate container fdb3d6d768b6 Removing intermediate container a1c758f74d6a Removing intermediate container 157f36889c98 Removing intermediate container 6072c184c6f3 Removing intermediate container 52ca643e82ab Removing intermediate container 471580633ac3 Removing intermediate container dcbdefcdf89f Removing intermediate container 3004797f0af3 Removing intermediate container 2713e3c8322f Removing intermediate container 856990c90e38 [DRONE] starting build Drone Build Results (1)  (10 seconds)  However, when called via the github hook, it does nothing. From /var/log/upstart/drone.log  Step 15 : ENTRYPOINT /bin/bash -e /usr/local/bin/drone > Running in b1374773197c > 4b43d39eec1f Successfully built 4b43d39eec1f Removing intermediate container 831ac7aed997 Removing intermediate container 0565e9c01c56 Removing intermediate container adc4458f8cb6 Removing intermediate container 8426b1f52aac Removing intermediate container 364afa4cf6eb Removing intermediate container ea796f37ca90 Removing intermediate container 0c3f9ae0f0a1 Removing intermediate container 82af22cd06f6 Removing intermediate container ea35dd05f608 Removing intermediate container ab8f7512917d Removing intermediate container b857dc7a1ecb Removing intermediate container e9275429b8b6 Removing intermediate container fbb700d1d070 Removing intermediate container d7c62082ebad Removing intermediate container b1374773197c copying repository to /var/cache/drone/src/github.com/trq/proem starting build temp directory is /tmp/drone removing build container removing build image  This is a brand spanking new Digital Ocean Docker box (Ubuntu).  Linux ci 3.11.0-12-generic #19-Ubuntu SMP Wed Oct 9 16:20:46 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux ",source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file,"script: not running When I call `drone build` from the command line the script: directive seems to run.  Step 16 : ENTRYPOINT /bin/bash -e /usr/local/bin/drone > Running in 157f36889c98 > f16c8aa5f495 Successfully built f16c8aa5f495 Removing intermediate container 024db1734ee0 Removing intermediate container 105d29809ef1 Removing intermediate container 211ffe648def Removing intermediate container 2dca87e78256 Removing intermediate container 411381c4d740 Removing intermediate container 1161cd2a8ab8 Removing intermediate container fdb3d6d768b6 Removing intermediate container a1c758f74d6a Removing intermediate container 157f36889c98 Removing intermediate container 6072c184c6f3 Removing intermediate container 52ca643e82ab Removing intermediate container 471580633ac3 Removing intermediate container dcbdefcdf89f Removing intermediate container 3004797f0af3 Removing intermediate container 2713e3c8322f Removing intermediate container 856990c90e38 [DRONE] starting build Drone Build Results (1)  (10 seconds)  However, when called via the github hook, it does nothing. From /var/log/upstart/drone.log  Step 15 : ENTRYPOINT /bin/bash -e /usr/local/bin/drone > Running in b1374773197c > 4b43d39eec1f Successfully built 4b43d39eec1f Removing intermediate container 831ac7aed997 Removing intermediate container 0565e9c01c56 Removing intermediate container adc4458f8cb6 Removing intermediate container 8426b1f52aac Removing intermediate container 364afa4cf6eb Removing intermediate container ea796f37ca90 Removing intermediate container 0c3f9ae0f0a1 Removing intermediate container 82af22cd06f6 Removing intermediate container ea35dd05f608 Removing intermediate container ab8f7512917d Removing intermediate container b857dc7a1ecb Removing intermediate container e9275429b8b6 Removing intermediate container fbb700d1d070 Removing intermediate container d7c62082ebad Removing intermediate container b1374773197c copying repository to /var/cache/drone/src/github.com/trq/proem starting build temp directory is /tmp/drone removing build container removing build image  This is a brand spanking new Digital Ocean Docker box (Ubuntu).  Linux ci 3.11.0-12-generic #19-Ubuntu SMP Wed Oct 9 16:20:46 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux  source-file source-file documentation-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file source-file other-file documentation-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file",no-bug,0.9
157,harness,https://github.com/harness/harness/issues/157,ability to remove branches,We're starting to build up a bunch of old branches in the /{repo}/tree view. It'd be nice if we could clear some of these out.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,ability to remove branches We're starting to build up a bunch of old branches in the /{repo}/tree view. It'd be nice if we could clear some of these out. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
3538,harness,https://github.com/harness/harness/issues/3538,How to use S3 or GCS to store repos?,"How can I configure S3 storage in Gitness to store Git repositories? I noticed that GCS is configured in this repository: https://github.com/harness/gitness/tree/main/blob. Is it used for storing repositories? If so, which environment variables or paths need to be configured to mount S3-compatible storage for storing the Git repositories?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"How to use S3 or GCS to store repos? How can I configure S3 storage in Gitness to store Git repositories? I noticed that GCS is configured in this repository: https://github.com/harness/gitness/tree/main/blob. Is it used for storing repositories? If so, which environment variables or paths need to be configured to mount S3-compatible storage for storing the Git repositories? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
695,harness,https://github.com/harness/harness/issues/695,cannot get install screen,"After installing drone, going to http://host/install doesn't give me install screen. Still managed to login to github and list repositories. Same behavior was observed with installing it on ubuntu machine or on centos inside docker container, either using deb package or building it from a source. Settings are given through environment variables. If settings are not sent then link to manuals appears, but still there is no install screen. Is there something I am missing?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"cannot get install screen After installing drone, going to http://host/install doesn't give me install screen. Still managed to login to github and list repositories. Same behavior was observed with installing it on ubuntu machine or on centos inside docker container, either using deb package or building it from a source. Settings are given through environment variables. If settings are not sent then link to manuals appears, but still there is no install screen. Is there something I am missing? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.7
652,harness,https://github.com/harness/harness/issues/652,Cannot add BitBucket repo in 0.3,"For some reason I can't add a BitBucket repo at all in 0.3. It pulls my repos fine and syncs them locally, but it doesn't actually add any hooks on BitBuckets side. When I click activate the spinning wheel runs, then disappears and no errors get printed out to `/var/log/upstart/drone.log` but I do get a 500 error upon adding it in the developer console.  POST https://drone.mooash.com/api/repos/bitbucket.org/Mooash/Testing 500 (Internal Server Error) angular.js:7991 (anonymous function) angular.js:7991 C angular.js:7813f angular.js:7547 C angular.js:10943 C angular.js:10943 (anonymous function) angular.js:11029 h.$eval angular.js:11949 h.$digest angular.js:11775 h.$apply angular.js:12055 (anonymous function) angular.js:17833 (anonymous function) angular.js:2612 q angular.js:309 Zc.c angular.js:2611  At first I thought it was due to my repo being called something with spaces so `%20` characters get printed in the URL.",other-file | other-file | source-file | documentation-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file,"Cannot add BitBucket repo in 0.3 For some reason I can't add a BitBucket repo at all in 0.3. It pulls my repos fine and syncs them locally, but it doesn't actually add any hooks on BitBuckets side. When I click activate the spinning wheel runs, then disappears and no errors get printed out to `/var/log/upstart/drone.log` but I do get a 500 error upon adding it in the developer console.  POST https://drone.mooash.com/api/repos/bitbucket.org/Mooash/Testing 500 (Internal Server Error) angular.js:7991 (anonymous function) angular.js:7991 C angular.js:7813f angular.js:7547 C angular.js:10943 C angular.js:10943 (anonymous function) angular.js:11029 h.$eval angular.js:11949 h.$digest angular.js:11775 h.$apply angular.js:12055 (anonymous function) angular.js:17833 (anonymous function) angular.js:2612 q angular.js:309 Zc.c angular.js:2611  At first I thought it was due to my repo being called something with spaces so `%20` characters get printed in the URL. other-file other-file source-file documentation-file other-file other-file source-file other-file other-file source-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file source-file other-file",bug,0.9
32,harness,https://github.com/harness/harness/issues/32,external git repos,Is there a plan to integrate git repos like gitlab or any external source via public key?,source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | container-file,external git repos Is there a plan to integrate git repos like gitlab or any external source via public key? source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file source-file source-file source-file source-file source-file container-file,no-bug,0.9
2714,harness,https://github.com/harness/harness/issues/2714,Drone task branch matching,"When defining a drone task to have a branch condition such as:  branch: - snapshot/*  There seems to be a bug such that it doesn't match as expected (unless I'm missing something). Hence, a branch like this matches fine (**success**):  snapshot/RP-1915  But a branch like this does not (**fail**):  snapshot/any-text/RP-1915  I would think the wildcard glob would match both?!",source-file,"Drone task branch matching When defining a drone task to have a branch condition such as:  branch: - snapshot/*  There seems to be a bug such that it doesn't match as expected (unless I'm missing something). Hence, a branch like this matches fine (**success**):  snapshot/RP-1915  But a branch like this does not (**fail**):  snapshot/any-text/RP-1915  I would think the wildcard glob would match both?! source-file",no-bug,0.9
1269,harness,https://github.com/harness/harness/issues/1269,drone 0.4 docker image can't use /etc/hosts,"There is no `/etc/nsswitch.conf` in the image so I extended it and added one and it started working:  # /etc/nsswitch.conf # # Example configuration of GNU Name Service Switch functionality. # If you have the `glibc-doc-reference' and `info' packages installed, try: # `info libc ""Name Service Switch""' for information about this file. passwd: compat group: compat shadow: compat hosts: files dns networks: files protocols: db files services: db files ethers: db files rpc: db files netgroup: nis ",container-file | config-file | container-file | config-file | container-file | config-file,"drone 0.4 docker image can't use /etc/hosts There is no `/etc/nsswitch.conf` in the image so I extended it and added one and it started working:  # /etc/nsswitch.conf # # Example configuration of GNU Name Service Switch functionality. # If you have the `glibc-doc-reference' and `info' packages installed, try: # `info libc ""Name Service Switch""' for information about this file. passwd: compat group: compat shadow: compat hosts: files dns networks: files protocols: db files services: db files ethers: db files rpc: db files netgroup: nis  container-file config-file container-file config-file container-file config-file",no-bug,0.9
2023,harness,https://github.com/harness/harness/issues/2023,on OS X DNS link for services randomly isn't there for cli builds,"Drone version: .6 OS: OS X 10.12.4 Repro Steps: create any simple service and curl -v to it fairly randomly you'll get * Hostname was NOT found in DNS cache. Might be a docker native issue on os x? looks like something is going haywire for the dns resolution :/ here's what the reponse looks like when it works + curl -v ""http://database:3000"" > ./config/test.yml * Rebuilt URL to: http://database:3000/ * Hostname was NOT found in DNS cache % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Trying 172.25.0.3 * connect to 172.25.0.3 port 3000 failed: Connection refused * Trying 172.25.0.2 * Connected to database (172.25.0.2) port 3000 (#0) > GET / HTTP/1.1 > User-Agent: curl/7.38.0 > Host: database:3000 > Accept: */* > < HTTP/1.1 200 OK < X-Powered-By: Express < Content-Type: text/html; charset=utf-8 < Content-Length: 45 < ETag: W/""2d-45TgH8W+lGBPVIxV0wozrBCb9S8"" < Date: Fri, 05 May 2017 03:19:25 GMT < Connection: keep-alive < { [data not shown] 100 45 100 45 0 0 1476 0 --:--:-- --:--:-- --:--:-- 1666 * Connection #0 to host database left intact and here's what it looks like when it fails + curl -v ""http://database:3000"" > ./config/test.yml * Rebuilt URL to: http://database:3000/ * Hostname was NOT found in DNS cache % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Trying 172.22.0.2 * connect to 172.22.0.2 port 3000 failed: Connection refused * Failed to connect to database port 3000: Connection refused * Closing connection 0 curl: (7) Failed to connect to database port 3000: Connection refused drone_step_1 : exit code 7",other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | documentation-file | other-file | other-file | other-file,"on OS X DNS link for services randomly isn't there for cli builds Drone version: .6 OS: OS X 10.12.4 Repro Steps: create any simple service and curl -v to it fairly randomly you'll get * Hostname was NOT found in DNS cache. Might be a docker native issue on os x? looks like something is going haywire for the dns resolution :/ here's what the reponse looks like when it works + curl -v ""http://database:3000"" > ./config/test.yml * Rebuilt URL to: http://database:3000/ * Hostname was NOT found in DNS cache % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Trying 172.25.0.3 * connect to 172.25.0.3 port 3000 failed: Connection refused * Trying 172.25.0.2 * Connected to database (172.25.0.2) port 3000 (#0) > GET / HTTP/1.1 > User-Agent: curl/7.38.0 > Host: database:3000 > Accept: */* > < HTTP/1.1 200 OK < X-Powered-By: Express < Content-Type: text/html; charset=utf-8 < Content-Length: 45 < ETag: W/""2d-45TgH8W+lGBPVIxV0wozrBCb9S8"" < Date: Fri, 05 May 2017 03:19:25 GMT < Connection: keep-alive < { [data not shown] 100 45 100 45 0 0 1476 0 --:--:-- --:--:-- --:--:-- 1666 * Connection #0 to host database left intact and here's what it looks like when it fails + curl -v ""http://database:3000"" > ./config/test.yml * Rebuilt URL to: http://database:3000/ * Hostname was NOT found in DNS cache % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0* Trying 172.22.0.2 * connect to 172.22.0.2 port 3000 failed: Connection refused * Failed to connect to database port 3000: Connection refused * Closing connection 0 curl: (7) Failed to connect to database port 3000: Connection refused drone_step_1 : exit code 7 other-file other-file source-file other-file other-file other-file other-file source-file other-file source-file documentation-file other-file other-file other-file",no-bug,0.9
3517,harness,https://github.com/harness/harness/issues/3517,"Project and repo deletion actually do not delete the db spaces + repos, and do not free disk space","Using gitness 3.0.0 beta 7 ![image](https://github.com/harness/gitness/assets/4543570/60fe45b0-e9bd-434b-a145-a6354fa8f41d) It looks like deleting projects (spaces on db) and repos actually do not delete them from the db neither the disk. This is problematic, as the projects are still on the project selector and the disk space is not being recovered ![image](https://github.com/harness/gitness/assets/4543570/5a82f3a8-28a8-46af-aa0c-6b4692fe204d) ![image](https://github.com/harness/gitness/assets/4543570/7236ce00-d516-4dc7-b0cc-8151e2cddd90) **Table and available folder** Check the id and the available folder repo_id | repo_version | repo_parent_id | repo_uid | repo_description | repo_is_public | repo_created_by | repo_created | repo_updated | repo_git_uid | repo_default_branch | repo_fork_id | repo_pullreq_seq | repo_num_forks | repo_num_pulls | repo_num_closed_pulls | repo_num_open_pulls | repo_num_merged_pulls | repo_importing | repo_size | repo_size_updated | repo_deleted | repo_is_empty -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- 5 | 2 | 3 | Docker-Maldito-NUC | containers | 0 | 3 | 1699458420147 | 1716205945386 | 5kkugp099ch5p5zzrth398p3oaszx766c50mublqm9 | main | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 12959 | 1715299202539 | 1716205945384 | 0 ![image](https://github.com/harness/gitness/assets/4543570/85d5f0de-030e-434d-b27f-3cd993072634)",source-file | source-file | source-file | source-file | source-file,"Project and repo deletion actually do not delete the db spaces + repos, and do not free disk space Using gitness 3.0.0 beta 7 ![image](https://github.com/harness/gitness/assets/4543570/60fe45b0-e9bd-434b-a145-a6354fa8f41d) It looks like deleting projects (spaces on db) and repos actually do not delete them from the db neither the disk. This is problematic, as the projects are still on the project selector and the disk space is not being recovered ![image](https://github.com/harness/gitness/assets/4543570/5a82f3a8-28a8-46af-aa0c-6b4692fe204d) ![image](https://github.com/harness/gitness/assets/4543570/7236ce00-d516-4dc7-b0cc-8151e2cddd90) **Table and available folder** Check the id and the available folder repo_id | repo_version | repo_parent_id | repo_uid | repo_description | repo_is_public | repo_created_by | repo_created | repo_updated | repo_git_uid | repo_default_branch | repo_fork_id | repo_pullreq_seq | repo_num_forks | repo_num_pulls | repo_num_closed_pulls | repo_num_open_pulls | repo_num_merged_pulls | repo_importing | repo_size | repo_size_updated | repo_deleted | repo_is_empty -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- 5 | 2 | 3 | Docker-Maldito-NUC | containers | 0 | 3 | 1699458420147 | 1716205945386 | 5kkugp099ch5p5zzrth398p3oaszx766c50mublqm9 | main | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 12959 | 1715299202539 | 1716205945384 | 0 ![image](https://github.com/harness/gitness/assets/4543570/85d5f0de-030e-434d-b27f-3cd993072634) source-file source-file source-file source-file source-file",no-bug,0.9
3033,harness,https://github.com/harness/harness/issues/3033,'When: Local: false' not working during local build,"Steps to reproduce: drone.yml:  yaml pipeline: not_local: when: local: false image: alpine:3.6 commands: - echo ""hello world""  Output:  sh drone exec [not_local:0] + echo ""hello world"" [not_local:1] hello world  Expected: the step not to run when running drone locally. This is very useful for plugins.",source-file,"'When: Local: false' not working during local build Steps to reproduce: drone.yml:  yaml pipeline: not_local: when: local: false image: alpine:3.6 commands: - echo ""hello world""  Output:  sh drone exec [not_local:0] + echo ""hello world"" [not_local:1] hello world  Expected: the step not to run when running drone locally. This is very useful for plugins. source-file",no-bug,0.9
2206,harness,https://github.com/harness/harness/issues/2206,Gogs skip_verify is not work!,yml pipeline: clone: image: plugins/git depth: 50 tags: true skip_verify: true   + git init 0s 2 Initialized empty Git repository in /srv/app/src/bigdata/express/.git/ 0s 3 + git remote add origin https://192.168.20.248:3000/bigdata/express.git 0s 4 + git fetch --no-tags origin +refs/heads/master: 0s 5 fatal: unable to access 'https://192.168.20.248:3000/bigdata/express.git/': SSL certificate problem: self signed certificate 0s 6 exit status 128 ,other-file,Gogs skip_verify is not work! yml pipeline: clone: image: plugins/git depth: 50 tags: true skip_verify: true   + git init 0s 2 Initialized empty Git repository in /srv/app/src/bigdata/express/.git/ 0s 3 + git remote add origin https://192.168.20.248:3000/bigdata/express.git 0s 4 + git fetch --no-tags origin +refs/heads/master: 0s 5 fatal: unable to access 'https://192.168.20.248:3000/bigdata/express.git/': SSL certificate problem: self signed certificate 0s 6 exit status 128  other-file,no-bug,0.9
1523,harness,https://github.com/harness/harness/issues/1523,No logging output when using default journald logging driver,"For obvious reasons Drone fails to log output when using the journald driver in docker by default. However, it is possible in docker to specify logging driver per-container - so if this mode of operation is not supported, sensible default behavior for drone would be to force all containers to start with `log-driver=json`.",config-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | config-file | source-file,"No logging output when using default journald logging driver For obvious reasons Drone fails to log output when using the journald driver in docker by default. However, it is possible in docker to specify logging driver per-container - so if this mode of operation is not supported, sensible default behavior for drone would be to force all containers to start with `log-driver=json`. config-file documentation-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file config-file source-file",no-bug,0.9
2780,harness,https://github.com/harness/harness/issues/2780,[Feature] Autoscaler: Support external secret servers,"The autoscaler doesn't support external secrets like `drone/amazon-secrets`, because it doesn't set the necessary environment variables. It would be great, if passing the necessary environment variables `DRONE_SECRET_ENDPOINT` and `DRONE_SECRET_SECRET` would also be supported.",source-file,"[Feature] Autoscaler: Support external secret servers The autoscaler doesn't support external secrets like `drone/amazon-secrets`, because it doesn't set the necessary environment variables. It would be great, if passing the necessary environment variables `DRONE_SECRET_ENDPOINT` and `DRONE_SECRET_SECRET` would also be supported. source-file",no-bug,0.9
248,harness,https://github.com/harness/harness/issues/248,Can't see other members Builds. but it can by anonymous user.,"Can't see other members Builds. but it can by anonymous user. I'm creating a server. it runs drone.io. (e.g. http://192.168.100.100/ and I'm creating a Builds. It can seen from anywhere. (e.g. http://192.168.100.100/github.com/vvakame/FooBar by the way. new member joined to my server. his name are ""mhidaka"". but he can't see http://192.168.100.100/github.com/vvakame/FooBar If he was logout, he can see it. My expected behavior is mhidaka can see http://192.168.100.100/github.com/vvakame/FooBar and i can see his builds. Is anonymous user in a special positions? I'm do not want to limit anyone's view. It is nice to teach me how to use my wrong?  I was work to see this URL. http://drone.readthedocs.org/en/latest/install.html my drone.io version.  # dpkg -l drone Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description ---- ii drone 0.1 amd64 Drone continuous integration server ",documentation-file | other-file,"Can't see other members Builds. but it can by anonymous user. Can't see other members Builds. but it can by anonymous user. I'm creating a server. it runs drone.io. (e.g. http://192.168.100.100/ and I'm creating a Builds. It can seen from anywhere. (e.g. http://192.168.100.100/github.com/vvakame/FooBar by the way. new member joined to my server. his name are ""mhidaka"". but he can't see http://192.168.100.100/github.com/vvakame/FooBar If he was logout, he can see it. My expected behavior is mhidaka can see http://192.168.100.100/github.com/vvakame/FooBar and i can see his builds. Is anonymous user in a special positions? I'm do not want to limit anyone's view. It is nice to teach me how to use my wrong?  I was work to see this URL. http://drone.readthedocs.org/en/latest/install.html my drone.io version.  # dpkg -l drone Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description  ii drone 0.1 amd64 Drone continuous integration server  documentation-file other-file",no-bug,0.9
799,harness,https://github.com/harness/harness/issues/799,"npm publish plugin, only publish if version not exists","The proposed change is to check if the npm package/version have already been published. We can add something like this to check:  sh test -z ""$(npm info bower@1.3.12)"" if [ $? -eq 0 ] then npm publish bower else echo ""skipping publish, package bower@1.3.12 already published"" fi  Note this is just an example. We would need to substitute `bower` and `1.3.2` for injected values. We would also need a way to determine the current package version. I'm guessing we can get this with a command somehow. /cc @donny-dont Anything else I'm missing?",source-file | source-file | source-file | source-file,"npm publish plugin, only publish if version not exists The proposed change is to check if the npm package/version have already been published. We can add something like this to check:  sh test -z ""$(npm info bower@1.3.12)"" if [ $? -eq 0 ] then npm publish bower else echo ""skipping publish, package bower@1.3.12 already published"" fi  Note this is just an example. We would need to substitute `bower` and `1.3.2` for injected values. We would also need a way to determine the current package version. I'm guessing we can get this with a command somehow. /cc @donny-dont Anything else I'm missing? source-file source-file source-file source-file",no-bug,0.9
3305,harness,https://github.com/harness/harness/issues/3305,Support for custom action for the custom event trigger,"It would be very nice to have Drone's `custom` event type to support custom actions. E.g. If the trigger configuration is like this: yaml kind: pipeline type: kubernetes name: custom-with-action trigger: event: - custom action: - mycustomaction  the API call to trigger would look something like this. `curl -X POST <drone-base-url>/api/repos/<org>/<repo>/builds?action=mycustomaction` One use case would be to integrate Drone with an external CI system. Drone step would initiate a build on the other CI system that supports webhooks and when the other system finishes its job it makes the above POST request. Drone accepts that and looks at the action to choose a pipeline to run. You can currently do that without action, but if you have more than one custom trigger, all of them would be triggered.",source-file | source-file | source-file | source-file,"Support for custom action for the custom event trigger It would be very nice to have Drone's `custom` event type to support custom actions. E.g. If the trigger configuration is like this: yaml kind: pipeline type: kubernetes name: custom-with-action trigger: event: - custom action: - mycustomaction  the API call to trigger would look something like this. `curl -X POST <drone-base-url>/api/repos/<org>/<repo>/builds?action=mycustomaction` One use case would be to integrate Drone with an external CI system. Drone step would initiate a build on the other CI system that supports webhooks and when the other system finishes its job it makes the above POST request. Drone accepts that and looks at the action to choose a pipeline to run. You can currently do that without action, but if you have more than one custom trigger, all of them would be triggered. source-file source-file source-file source-file",no-bug,0.9
436,harness,https://github.com/harness/harness/issues/436,Set {{BRANCH_NAME}} in param injection context,"It would be helpful if the branch name was available in context for param injection. This would make it easy to pass along to commands as needed. My custom deployment commands need the name of the branch they are working on, but git complains about a detached head when I attempt to determine the branch name manually. My git foo is weak, so maybe there is a simple workaround. Is there currently any way to determine the branch name in the container?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Set {{BRANCH_NAME}} in param injection context It would be helpful if the branch name was available in context for param injection. This would make it easy to pass along to commands as needed. My custom deployment commands need the name of the branch they are working on, but git complains about a detached head when I attempt to determine the branch name manually. My git foo is weak, so maybe there is a simple workaround. Is there currently any way to determine the branch name in the container? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
538,harness,https://github.com/harness/harness/issues/538,Change private variable notation in YAML,"When private variables are defined in the user interface, Drone will attempt to inject them directly into the `.drone.yml` file using a mustache syntax. These variables will also be injected as environment variables in the Docker container. I'm planning to slightly change the notation for injecting private variables into the `drone.yml`. We will move away from a mustache syntax (ie `{{GITHUB_TOKEN}}` in favor of something more similar to a Makefile (ie `$$GITHUB_TOKEN`). The reason is that the mustache syntax will, at some point in the future, be used for matrix builds. See https://github.com/drone/drone/issues/6#issuecomment-36059400 for more details.",config-file | source-file | source-file | source-file | test-file | source-file | other-file | other-file,"Change private variable notation in YAML When private variables are defined in the user interface, Drone will attempt to inject them directly into the `.drone.yml` file using a mustache syntax. These variables will also be injected as environment variables in the Docker container. I'm planning to slightly change the notation for injecting private variables into the `drone.yml`. We will move away from a mustache syntax (ie `{{GITHUB_TOKEN}}` in favor of something more similar to a Makefile (ie `$$GITHUB_TOKEN`). The reason is that the mustache syntax will, at some point in the future, be used for matrix builds. See https://github.com/drone/drone/issues/6#issuecomment-36059400 for more details. config-file source-file source-file source-file test-file source-file other-file other-file",no-bug,0.9
1117,harness,https://github.com/harness/harness/issues/1117,Any plan to support tag_push_event of gitlab?,"As we wanna trigger some action by gitlab tag event, e.g. building&pushing docker image, tag_push_event supporting is required. i've submit a PR in Bugagazavr/go-gitlab-client to support tag_push_event by go-gitlab-client. https://github.com/Bugagazavr/go-gitlab-client/pull/11",source-file | test-file | source-file | test-file | source-file | test-file | source-file,"Any plan to support tag_push_event of gitlab? As we wanna trigger some action by gitlab tag event, e.g. building&pushing docker image, tag_push_event supporting is required. i've submit a PR in Bugagazavr/go-gitlab-client to support tag_push_event by go-gitlab-client. https://github.com/Bugagazavr/go-gitlab-client/pull/11 source-file test-file source-file test-file source-file test-file source-file",no-bug,0.8
740,harness,https://github.com/harness/harness/issues/740,Rebasing a branch doesn't trigger a branch rebuild,"Steps to reproduce: - branch master to feature-XXX - commits changes to feature-XXX - push <-- _this will trigger a branch build as expected_ - create a PR - make more changes to feature-XXX branch, commit and push _this trigger a branch and PR build as expected, so deploy section runs fine for branch build_ - Now add changes to master and rebase feature-XXX on top of it - push <-- **UI shows a branch and PR build but both links to PR, and none to the branch**, so deploy section didn't run.",source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file,"Rebasing a branch doesn't trigger a branch rebuild Steps to reproduce: - branch master to feature-XXX - commits changes to feature-XXX - push <-- _this will trigger a branch build as expected_ - create a PR - make more changes to feature-XXX branch, commit and push _this trigger a branch and PR build as expected, so deploy section runs fine for branch build_ - Now add changes to master and rebase feature-XXX on top of it - push <-- **UI shows a branch and PR build but both links to PR, and none to the branch**, so deploy section didn't run. source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file",no-bug,0.9
357,harness,https://github.com/harness/harness/issues/357,make deps from source code,"new to drone, fantastic work and experience, encounter a problem when build from source go get -u -t -v ./ idl@ubuntu:~/opensource/drone$ make deps > out import ""_/home/idl/opensource/drone/cmd/drone"": import path doesn't contain a hostname package _/home/idl/opensource/drone/cmd/drone: unrecognized import path ""_/home/idl/opensource/drone/cmd/drone"" import ""_/home/idl/opensource/drone/cmd/droned"": import path doesn't contain a hostname package _/home/idl/opensource/drone/cmd/droned: unrecognized import path ""_/home/idl/opensource/drone/cmd/droned"" import ""_/home/idl/opensource/drone/pkg/build"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build: unrecognized import path ""_/home/idl/opensource/drone/pkg/build"" import ""_/home/idl/opensource/drone/pkg/build/buildfile"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/buildfile: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/buildfile"" import ""_/home/idl/opensource/drone/pkg/build/docker"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/docker: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/docker"" import ""_/home/idl/opensource/drone/pkg/build/dockerfile"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/dockerfile: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/dockerfile"" import ""_/home/idl/opensource/drone/pkg/build/git"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/git: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/git"" import ""_/home/idl/opensource/drone/pkg/build/log"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/log: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/log"" import ""_/home/idl/opensource/drone/pkg/build/proxy"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/proxy: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/proxy"" import ""_/home/idl/opensource/drone/pkg/build/repo"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/repo: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/repo"" import ""_/home/idl/opensource/drone/pkg/build/script"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/script: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/script"" import ""_/home/idl/opensource/drone/pkg/channel"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/channel: unrecognized import path ""_/home/idl/opensource/drone/pkg/channel"" import ""_/home/idl/opensource/drone/pkg/database"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database: unrecognized import path ""_/home/idl/opensource/drone/pkg/database"" import ""_/home/idl/opensource/drone/pkg/database/encrypt"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/encrypt: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/encrypt"" import ""_/home/idl/opensource/drone/pkg/database/migrate"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/migrate: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/migrate"" import ""_/home/idl/opensource/drone/pkg/database/migrate/testing"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/migrate/testing: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/migrate/testing"" import ""_/home/idl/opensource/drone/pkg/database/schema"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/schema: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/schema"" import ""_/home/idl/opensource/drone/pkg/database/testing"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/testing: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/testing"" import ""_/home/idl/opensource/drone/pkg/handler"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/handler: unrecognized import path ""_/home/idl/opensource/drone/pkg/handler"" import ""_/home/idl/opensource/drone/pkg/handler/testing"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/handler/testing: unrecognized import path ""_/home/idl/opensource/drone/pkg/handler/testing"" import ""_/home/idl/opensource/drone/pkg/mail"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/mail: unrecognized import path ""_/home/idl/opensource/drone/pkg/mail"" import ""_/home/idl/opensource/drone/pkg/model"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/model: unrecognized import path ""_/home/idl/opensource/drone/pkg/model"" import ""_/home/idl/opensource/drone/pkg/plugin/deploy"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/plugin/deploy: unrecognized import path ""_/home/idl/opensource/drone/pkg/plugin/deploy"" import ""_/home/idl/opensource/drone/pkg/plugin/notify"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/plugin/notify: unrecognized import path ""_/home/idl/opensource/drone/pkg/plugin/notify"" import ""_/home/idl/opensource/drone/pkg/plugin/publish"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/plugin/publish: unrecognized import path ""_/home/idl/opensource/drone/pkg/plugin/publish"" import ""_/home/idl/opensource/drone/pkg/queue"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/queue: unrecognized import path ""_/home/idl/opensource/drone/pkg/queue"" import ""_/home/idl/opensource/drone/pkg/template"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/template: unrecognized import path ""_/home/idl/opensource/drone/pkg/template"" make: **\* [deps] Error 1",documentation-file | documentation-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | other-file,"make deps from source code new to drone, fantastic work and experience, encounter a problem when build from source go get -u -t -v ./ idl@ubuntu:~/opensource/drone$ make deps > out import ""_/home/idl/opensource/drone/cmd/drone"": import path doesn't contain a hostname package _/home/idl/opensource/drone/cmd/drone: unrecognized import path ""_/home/idl/opensource/drone/cmd/drone"" import ""_/home/idl/opensource/drone/cmd/droned"": import path doesn't contain a hostname package _/home/idl/opensource/drone/cmd/droned: unrecognized import path ""_/home/idl/opensource/drone/cmd/droned"" import ""_/home/idl/opensource/drone/pkg/build"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build: unrecognized import path ""_/home/idl/opensource/drone/pkg/build"" import ""_/home/idl/opensource/drone/pkg/build/buildfile"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/buildfile: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/buildfile"" import ""_/home/idl/opensource/drone/pkg/build/docker"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/docker: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/docker"" import ""_/home/idl/opensource/drone/pkg/build/dockerfile"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/dockerfile: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/dockerfile"" import ""_/home/idl/opensource/drone/pkg/build/git"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/git: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/git"" import ""_/home/idl/opensource/drone/pkg/build/log"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/log: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/log"" import ""_/home/idl/opensource/drone/pkg/build/proxy"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/proxy: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/proxy"" import ""_/home/idl/opensource/drone/pkg/build/repo"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/repo: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/repo"" import ""_/home/idl/opensource/drone/pkg/build/script"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/build/script: unrecognized import path ""_/home/idl/opensource/drone/pkg/build/script"" import ""_/home/idl/opensource/drone/pkg/channel"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/channel: unrecognized import path ""_/home/idl/opensource/drone/pkg/channel"" import ""_/home/idl/opensource/drone/pkg/database"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database: unrecognized import path ""_/home/idl/opensource/drone/pkg/database"" import ""_/home/idl/opensource/drone/pkg/database/encrypt"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/encrypt: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/encrypt"" import ""_/home/idl/opensource/drone/pkg/database/migrate"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/migrate: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/migrate"" import ""_/home/idl/opensource/drone/pkg/database/migrate/testing"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/migrate/testing: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/migrate/testing"" import ""_/home/idl/opensource/drone/pkg/database/schema"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/schema: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/schema"" import ""_/home/idl/opensource/drone/pkg/database/testing"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/database/testing: unrecognized import path ""_/home/idl/opensource/drone/pkg/database/testing"" import ""_/home/idl/opensource/drone/pkg/handler"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/handler: unrecognized import path ""_/home/idl/opensource/drone/pkg/handler"" import ""_/home/idl/opensource/drone/pkg/handler/testing"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/handler/testing: unrecognized import path ""_/home/idl/opensource/drone/pkg/handler/testing"" import ""_/home/idl/opensource/drone/pkg/mail"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/mail: unrecognized import path ""_/home/idl/opensource/drone/pkg/mail"" import ""_/home/idl/opensource/drone/pkg/model"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/model: unrecognized import path ""_/home/idl/opensource/drone/pkg/model"" import ""_/home/idl/opensource/drone/pkg/plugin/deploy"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/plugin/deploy: unrecognized import path ""_/home/idl/opensource/drone/pkg/plugin/deploy"" import ""_/home/idl/opensource/drone/pkg/plugin/notify"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/plugin/notify: unrecognized import path ""_/home/idl/opensource/drone/pkg/plugin/notify"" import ""_/home/idl/opensource/drone/pkg/plugin/publish"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/plugin/publish: unrecognized import path ""_/home/idl/opensource/drone/pkg/plugin/publish"" import ""_/home/idl/opensource/drone/pkg/queue"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/queue: unrecognized import path ""_/home/idl/opensource/drone/pkg/queue"" import ""_/home/idl/opensource/drone/pkg/template"": import path doesn't contain a hostname package _/home/idl/opensource/drone/pkg/template: unrecognized import path ""_/home/idl/opensource/drone/pkg/template"" make: **\* [deps] Error 1 documentation-file documentation-file other-file other-file source-file other-file other-file other-file documentation-file other-file",no-bug,0.95
316,harness,https://github.com/harness/harness/issues/316,Run docker on drone.io?,"Hi, I'm wondering if I can run a docker on drone.io? I have some Dockerfiles and a shell script. The script will use those Dockerfiles to somehow build a docker images. Therefore, I'll need a docker client & docker daemon. I try to install & run docker via the following commands on drone.io:  sudo apt-get update sudo apt-get install -y linux-image-extra-`uname -r` sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9 sudo sh -c ""echo deb http://get.docker.io/ubuntu docker main\ > /etc/apt/sources.list.d/docker.list"" sudo apt-get update sudo apt-get install -y lxc-docker sudo service docker status sudo cat /var/log/upstart/docker.log sleep 60 sudo service docker status sudo docker -H unix:var/run/docker.sock version  However, the docker status gives:  sudo service docker status docker stop/waiting  and the log `/var/log/upstart/docker.log`:  $ sudo cat /var/log/upstart/docker.log mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only 2014/05/22 07:01:41 WARNING: You are running linux kernel version 3.2.0-23-virtual, which might be unstable running docker. Please upgrade your kernel to 3.8.0. 2014/05/22 07:01:41 docker daemon: 0.11.1 fb99f99; execdriver: native; graphdriver: [7210a4bc] +job serveapi(unix:var/run/docker.sock) [7210a4bc] +job initserver() [7210a4bc.initserver()] Creating server 2014/05/22 07:01:41 Listening for HTTP on unix (/var/run/docker.sock) permission denied [7210a4bc] -job initserver() = ERR (1) 2014/05/22 07:01:41 permission denied  and the `docker info` gives  $ sudo docker -H unix:var/run/docker.sock version Client version: 0.11.1 Client API version: 1.11 Go version (client): go1.2.1 Git commit (client): fb99f99 2014/05/22 07:02:41 Cannot connect to the Docker daemon. Is 'docker -d' running on this host?  Did I miss something?",other-file | source-file | other-file | other-file | source-file | other-file | source-file | documentation-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file,"Run docker on drone.io? Hi, I'm wondering if I can run a docker on drone.io? I have some Dockerfiles and a shell script. The script will use those Dockerfiles to somehow build a docker images. Therefore, I'll need a docker client & docker daemon. I try to install & run docker via the following commands on drone.io:  sudo apt-get update sudo apt-get install -y linux-image-extra-`uname -r` sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9 sudo sh -c ""echo deb http://get.docker.io/ubuntu docker main\ > /etc/apt/sources.list.d/docker.list"" sudo apt-get update sudo apt-get install -y lxc-docker sudo service docker status sudo cat /var/log/upstart/docker.log sleep 60 sudo service docker status sudo docker -H unix:var/run/docker.sock version  However, the docker status gives:  sudo service docker status docker stop/waiting  and the log `/var/log/upstart/docker.log`:  $ sudo cat /var/log/upstart/docker.log mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only mount: block device cgroup is write-protected, mounting read-only mount: cannot mount block device cgroup read-only 2014/05/22 07:01:41 WARNING: You are running linux kernel version 3.2.0-23-virtual, which might be unstable running docker. Please upgrade your kernel to 3.8.0. 2014/05/22 07:01:41 docker daemon: 0.11.1 fb99f99; execdriver: native; graphdriver: [7210a4bc] +job serveapi(unix:var/run/docker.sock) [7210a4bc] +job initserver() [7210a4bc.initserver()] Creating server 2014/05/22 07:01:41 Listening for HTTP on unix (/var/run/docker.sock) permission denied [7210a4bc] -job initserver() = ERR (1) 2014/05/22 07:01:41 permission denied  and the `docker info` gives  $ sudo docker -H unix:var/run/docker.sock version Client version: 0.11.1 Client API version: 1.11 Go version (client): go1.2.1 Git commit (client): fb99f99 2014/05/22 07:02:41 Cannot connect to the Docker daemon. Is 'docker -d' running on this host?  Did I miss something? other-file source-file other-file other-file source-file other-file source-file documentation-file other-file source-file other-file other-file other-file other-file source-file other-file",no-bug,0.95
1097,harness,https://github.com/harness/harness/issues/1097,Cache?,I couldn't find any docs on whether it is possible to cache folders between builds. More specifically I'd like to cache `node_modules` to avoid reinstalling packages between builds.,other-file,Cache? I couldn't find any docs on whether it is possible to cache folders between builds. More specifically I'd like to cache `node_modules` to avoid reinstalling packages between builds. other-file,no-bug,0.95
2643,harness,https://github.com/harness/harness/issues/2643,Issue with sub-projects with Gitlab,"When not using sub projects Drone is fine when we try activation Drone with a sub-project we get a 404 error as follows. {""admin"":false,""error"":""404 Project Not Found"",""level"":""warning"",""msg"":""api: cannot sync repository permissions"",""name"":""android-pipeline-test"",""namespace"":""android"",""read"":true,""request-id"":""1JPTXf4qtGu0Uo5qJ9G4VQuGBby"",""time"":""2019-04-04T16:36:13Z"",""user.login"":""drone.ci"",""write"":false}",documentation-file | source-file | source-file | source-file | source-file,"Issue with sub-projects with Gitlab When not using sub projects Drone is fine when we try activation Drone with a sub-project we get a 404 error as follows. {""admin"":false,""error"":""404 Project Not Found"",""level"":""warning"",""msg"":""api: cannot sync repository permissions"",""name"":""android-pipeline-test"",""namespace"":""android"",""read"":true,""request-id"":""1JPTXf4qtGu0Uo5qJ9G4VQuGBby"",""time"":""2019-04-04T16:36:13Z"",""user.login"":""drone.ci"",""write"":false} documentation-file source-file source-file source-file source-file",bug,0.9
3217,harness,https://github.com/harness/harness/issues/3217,drone list at most 100 repos from gitee.com,"<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> # Expected Behavior After finishing configure gitee's OAuth2 for drone, drone server syncs all repos from gitee.com. # Current Behavior After finishing configure gitee's OAuth2 for drone, drone server only syncs at most 100 repos. # Context drone version: v1.12.1 # detail description After checking source code from drone/service/repo/repo.go +52: go repos := []*core.Repository{} opts := scm.ListOptions{Size: 100} for { result, meta, err := s.client.Repositories.List(ctx, opts) if err != nil { return nil, err } for _, src := range result { if src != nil { repos = append(repos, convertRepository(src, s.visibility, s.trusted)) } } opts.Page = meta.Page.Next opts.URL = meta.Page.NextURL if opts.Page == 0 && opts.URL == """" { break } }  I find that drone actually tries to sync all repos even if there is pagination in repo api. So I check the implementation from go-scm:v1.21.1, which is the dependant version for drone, and found an error in the source from go-scm/scm/drivce/gitee/gitee.go +128: go func populatePageValues(req *scm.Request, resp *scm.Response) { last, totalError := strconv.Atoi(resp.Header.Get(""total_page"")) reqURL, err := url.Parse(req.Path) if err != nil { return } current, currentError := strconv.Atoi(reqURL.Query().Get(""page"")) if totalError != nil && currentError != nil { return } resp.Page.First = 1 if last != 0 { resp.Page.Last = last } if current != 0 { if current < resp.Page.Last { resp.Page.Next = current + 1 } else { resp.Page.Next = resp.Page.Last } if current > resp.Page.First { resp.Page.Prev = current - 1 } else { resp.Page.Prev = resp.Page.First } } }  The Page.Next will be 2 when total_page > 1 and not page option is given as drone implement, which results in only 100 repos are accessed for gitee.com # Possible Solution After upgrading go-scm from v.1.21.1 to v.1.23.0, the problem could be solved.",source-file | source-file,"drone list at most 100 repos from gitee.com <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://discourse.drone.io/ https://discourse.drone.io/c/bugs https://discourse.drone.io/c/ideas Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> # Expected Behavior After finishing configure gitee's OAuth2 for drone, drone server syncs all repos from gitee.com. # Current Behavior After finishing configure gitee's OAuth2 for drone, drone server only syncs at most 100 repos. # Context drone version: v1.12.1 # detail description After checking source code from drone/service/repo/repo.go +52: go repos := []*core.Repository{} opts := scm.ListOptions{Size: 100} for { result, meta, err := s.client.Repositories.List(ctx, opts) if err != nil { return nil, err } for _, src := range result { if src != nil { repos = append(repos, convertRepository(src, s.visibility, s.trusted)) } } opts.Page = meta.Page.Next opts.URL = meta.Page.NextURL if opts.Page == 0 && opts.URL == """" { break } }  I find that drone actually tries to sync all repos even if there is pagination in repo api. So I check the implementation from go-scm:v1.21.1, which is the dependant version for drone, and found an error in the source from go-scm/scm/drivce/gitee/gitee.go +128: go func populatePageValues(req *scm.Request, resp *scm.Response) { last, totalError := strconv.Atoi(resp.Header.Get(""total_page"")) reqURL, err := url.Parse(req.Path) if err != nil { return } current, currentError := strconv.Atoi(reqURL.Query().Get(""page"")) if totalError != nil && currentError != nil { return } resp.Page.First = 1 if last != 0 { resp.Page.Last = last } if current != 0 { if current < resp.Page.Last { resp.Page.Next = current + 1 } else { resp.Page.Next = resp.Page.Last } if current > resp.Page.First { resp.Page.Prev = current - 1 } else { resp.Page.Prev = resp.Page.First } } }  The Page.Next will be 2 when total_page > 1 and not page option is given as drone implement, which results in only 100 repos are accessed for gitee.com # Possible Solution After upgrading go-scm from v.1.21.1 to v.1.23.0, the problem could be solved. source-file source-file",no-bug,0.9
1092,harness,https://github.com/harness/harness/issues/1092,Unable to fetch submodule,"Hi, I am trying to test a repository that require to pull a submodule repo in order to be deployed, when the deploy starts, the main repository look to have the right key but when it try to fetch the git submodules it throws an error saying that the repository was not found: here is the error on the stacktrace  $ git clone --depth=50 --recursive --branch=my-branch git@github.com:xxx/main_repo.git /var/cache/drone/src/github.com/xxx/main_repo Cloning into '/var/cache/drone/src/github.com/xxx/main_repo' Warning: Permanently added 'github.com,x.x.x.x' (RSA) to the list of known hosts. Submodule 'submodule_repo' (git@github.com:xxx/submodule_repo.git) registered for path 'submodule_repo' Cloning into 'submodule_repo' ERROR: Repository not found. fatal: The remote end hung up unexpectedly Clone of 'git@github.com:xxx/submodule_repo.git' into submodule path 'submodule_repo' failed  I checked the public key and they look correct for both the main repo and the submodule repo here is my `.drone.yml` file  yml image: bradrydzewski/ruby:1.9.3 env: - RAILS_ENV=test script: - cp config/drone.database.yml config/database.yml - bundle install - psql -c 'create database test;' -U postgres -h 127.0.0.1 - bundle exec rake db:schema:load - bundle exec rspec spec services: - postgres  Any idea why it cannot find the repo?",other-file | other-file,"Unable to fetch submodule Hi, I am trying to test a repository that require to pull a submodule repo in order to be deployed, when the deploy starts, the main repository look to have the right key but when it try to fetch the git submodules it throws an error saying that the repository was not found: here is the error on the stacktrace  $ git clone --depth=50 --recursive --branch=my-branch git@github.com:xxx/main_repo.git /var/cache/drone/src/github.com/xxx/main_repo Cloning into '/var/cache/drone/src/github.com/xxx/main_repo' Warning: Permanently added 'github.com,x.x.x.x' (RSA) to the list of known hosts. Submodule 'submodule_repo' (git@github.com:xxx/submodule_repo.git) registered for path 'submodule_repo' Cloning into 'submodule_repo' ERROR: Repository not found. fatal: The remote end hung up unexpectedly Clone of 'git@github.com:xxx/submodule_repo.git' into submodule path 'submodule_repo' failed  I checked the public key and they look correct for both the main repo and the submodule repo here is my `.drone.yml` file  yml image: bradrydzewski/ruby:1.9.3 env: - RAILS_ENV=test script: - cp config/drone.database.yml config/database.yml - bundle install - psql -c 'create database test;' -U postgres -h 127.0.0.1 - bundle exec rake db:schema:load - bundle exec rspec spec services: - postgres  Any idea why it cannot find the repo? other-file other-file",no-bug,0.95
2587,harness,https://github.com/harness/harness/issues/2587,please update detail to docker hub,,source-file | source-file,please update detail to docker hub  source-file source-file,no-bug,0.8
198,harness,https://github.com/harness/harness/issues/198,Zapier Plugin,It would be awesome to have a Zapier notification plugin. This would effectively allow Drone to integrate with hundreds of 3rd party systems. I have a placeholder file here in the code: https://github.com/drone/drone/blob/master/pkg/plugin/notify/zapier.go I think most of the work is creating zapier mappings? not really sure,source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file | source-file | source-file,Zapier Plugin It would be awesome to have a Zapier notification plugin. This would effectively allow Drone to integrate with hundreds of 3rd party systems. I have a placeholder file here in the code: https://github.com/drone/drone/blob/master/pkg/plugin/notify/zapier.go I think most of the work is creating zapier mappings? not really sure source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file documentation-file source-file source-file source-file,no-bug,0.9
215,harness,https://github.com/harness/harness/issues/215,Repository's build is publicly available except for another user?,"I just noticed here: https://github.com/drone/drone/blob/master/pkg/handler/handler.go#L105 That while public commits is accessible without authentication, authenticated users will get 404 if they're not the owner of that repo, I supposed this is not intended?",source-file,"Repository's build is publicly available except for another user? I just noticed here: https://github.com/drone/drone/blob/master/pkg/handler/handler.go#L105 That while public commits is accessible without authentication, authenticated users will get 404 if they're not the owner of that repo, I supposed this is not intended? source-file",no-bug,0.7
1082,harness,https://github.com/harness/harness/issues/1082,Add / Remove Docker Workers without stopping / re-starting,"Hi, Right now if I want to tweak conccurency (add/remove worker nodes), I need to do a full restart, stopping all running build. I would be nice if I could just send a `SIGHUP` to drone process and it will reload config without stopping drone.",source-file,"Add / Remove Docker Workers without stopping / re-starting Hi, Right now if I want to tweak conccurency (add/remove worker nodes), I need to do a full restart, stopping all running build. I would be nice if I could just send a `SIGHUP` to drone process and it will reload config without stopping drone. source-file",no-bug,0.9
722,harness,https://github.com/harness/harness/issues/722,absolute URLs,Drone appears to be hardwired to use absolute URLs pretty much everywhere - frontend and backend. This prevents drone from being used behind a reverse proxy that performs a path rewrite e.g. rewrite `http://frontend/drone` to `http://backend/`,source-file | source-file,absolute URLs Drone appears to be hardwired to use absolute URLs pretty much everywhere - frontend and backend. This prevents drone from being used behind a reverse proxy that performs a path rewrite e.g. rewrite `http://frontend/drone` to `http://backend/` source-file source-file,no-bug,0.7
649,harness,https://github.com/harness/harness/issues/649,In-progress builds aren't visible to valid team members,"In our test environment we have 3 people who have access to the same repo. Each has selected vokalinteractive/repo in the Repositories list. When User A triggers a build, User B and User C see nothing in the dashboard whereas User A see's the in progress build. When the build completes, User B and User C see the final build result. It seems like two things would vastly clear up the user experience here: 1. Why do additional users need to select the repo in the repositories list to see it in their dashboard? This is contradictory to work across a team, especially since it shows up as green/selected in the repos list for the new users already. 2. In-progress builds should show up for all members of the team rather than only finished build statuses. This is enormously beneficial given that we have roughly 40+ repos on a given team in our organization. When a build is running it should be as easy as jumping into Drone to see what builds are pending.",other-file,"In-progress builds aren't visible to valid team members In our test environment we have 3 people who have access to the same repo. Each has selected vokalinteractive/repo in the Repositories list. When User A triggers a build, User B and User C see nothing in the dashboard whereas User A see's the in progress build. When the build completes, User B and User C see the final build result. It seems like two things would vastly clear up the user experience here: 1. Why do additional users need to select the repo in the repositories list to see it in their dashboard? This is contradictory to work across a team, especially since it shows up as green/selected in the repos list for the new users already. 2. In-progress builds should show up for all members of the team rather than only finished build statuses. This is enormously beneficial given that we have roughly 40+ repos on a given team in our organization. When a build is running it should be as easy as jumping into Drone to see what builds are pending. other-file",no-bug,0.9
1274,harness,https://github.com/harness/harness/issues/1274,Migration failed: table users already exists,"I have a Docker container running Drone, which I just tried to migrate by running  bash docker stop droneci docker rm droneci docker pull drone/drone:0.4 /usr/bin/docker run --name droneci \ # Some arguments omitted for clarity -e 'DRONE_DATABASE_DATASOURCE=/var/lib/drone/drone.sqlite' \ -v '/srv/drone:/var/lib/drone' \ drone/drone:0.4  However, the new container now outputs the following to stdout and quits:  time=""2015-10-28T21:05:25Z"" level=info msg=""using database driver sqlite3"" time=""2015-10-28T21:05:25Z"" level=info msg=""using database config /var/lib/drone/drone.sqlite"" time=""2015-10-28T21:05:25Z"" level=error msg=""table users already exists"" time=""2015-10-28T21:05:25Z"" level=fatal msg=""migration failed""  I found #224, which seems similar but has been fixed already. The version in the `migration_version` table is 3. The `users` table does indeed exist, and has an entry for me in it (I was the only user).",documentation-file,"Migration failed: table users already exists I have a Docker container running Drone, which I just tried to migrate by running  bash docker stop droneci docker rm droneci docker pull drone/drone:0.4 /usr/bin/docker run --name droneci \ # Some arguments omitted for clarity -e 'DRONE_DATABASE_DATASOURCE=/var/lib/drone/drone.sqlite' \ -v '/srv/drone:/var/lib/drone' \ drone/drone:0.4  However, the new container now outputs the following to stdout and quits:  time=""2015-10-28T21:05:25Z"" level=info msg=""using database driver sqlite3"" time=""2015-10-28T21:05:25Z"" level=info msg=""using database config /var/lib/drone/drone.sqlite"" time=""2015-10-28T21:05:25Z"" level=error msg=""table users already exists"" time=""2015-10-28T21:05:25Z"" level=fatal msg=""migration failed""  I found #224, which seems similar but has been fixed already. The version in the `migration_version` table is 3. The `users` table does indeed exist, and has an entry for me in it (I was the only user). documentation-file",no-bug,0.9
2683,harness,https://github.com/harness/harness/issues/2683,Root node that runs on failure should skip,"If a root node in the graph is set to run on failure, it will execute regardless. This is more of an edge case in practice, but something that should be resolved. This was spun out as a separate issue from https://github.com/drone/drone/issues/2634. Example root node: text kind: pipeline name: foo steps: - name: foo image: alpine:3.8 trigger: status: [ failure ]  Example root node through skipped dependency: text kind: pipeline name: foo steps: - name: foo image: alpine:3.8 trigger: branch: [ some-fake-branch ]  kind: pipeline name: bar steps: - name: bar image: alpine:3.8 trigger: status: [ failure ] depends_on: [ foo ] ",source-file | documentation-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file,"Root node that runs on failure should skip If a root node in the graph is set to run on failure, it will execute regardless. This is more of an edge case in practice, but something that should be resolved. This was spun out as a separate issue from https://github.com/drone/drone/issues/2634. Example root node: text kind: pipeline name: foo steps: - name: foo image: alpine:3.8 trigger: status: [ failure ]  Example root node through skipped dependency: text kind: pipeline name: foo steps: - name: foo image: alpine:3.8 trigger: branch: [ some-fake-branch ]  kind: pipeline name: bar steps: - name: bar image: alpine:3.8 trigger: status: [ failure ] depends_on: [ foo ]  source-file documentation-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file documentation-file",no-bug,0.9
227,harness,https://github.com/harness/harness/issues/227,Hipchat Notification not working,Has anyone been able to get the Hipchat notification working?,other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file,Hipchat Notification not working Has anyone been able to get the Hipchat notification working? other-file source-file other-file other-file source-file documentation-file other-file source-file other-file other-file source-file other-file other-file,no-bug,0.3
400,harness,https://github.com/harness/harness/issues/400,Add Rubinius to available Rubies,What would it take to add Rubinius to the available Rubies?,source-file | source-file | source-file,Add Rubinius to available Rubies What would it take to add Rubinius to the available Rubies? source-file source-file source-file,no-bug,0.9
2431,harness,https://github.com/harness/harness/issues/2431,Support *BSD systems for build workers,"Currently Drone only can work on Linux. Would be nice to be able to have some workers at FreeBSD, OpenBSD, etc.",source-file,"Support *BSD systems for build workers Currently Drone only can work on Linux. Would be nice to be able to have some workers at FreeBSD, OpenBSD, etc. source-file",no-bug,0.9
342,harness,https://github.com/harness/harness/issues/342,Private key size,I spent some time struggling with this: The private keys being generated were truncated in mysql because where longer than 1024. Altering that value fixed my issues. Shouldn't https://github.com/drone/drone/blob/cb042e1c1a58e593a7268a8af0be0e25e56e2fb3/pkg/database/schema/schema.sql#L62 be at least 2048? The truncation was really hard to debug :P but now things work great.,source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file,Private key size I spent some time struggling with this: The private keys being generated were truncated in mysql because where longer than 1024. Altering that value fixed my issues. Shouldn't https://github.com/drone/drone/blob/cb042e1c1a58e593a7268a8af0be0e25e56e2fb3/pkg/database/schema/schema.sql#L62 be at least 2048? The truncation was really hard to debug :P but now things work great. source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file,no-bug,0.9
2157,harness,https://github.com/harness/harness/issues/2157,The UI intermittently stops working in the build view,The following error appears in the console:  GET https://drone.asgard.8d.com/stream/events 504 ()  After which the UI stops updating and does not respond to clicking on the different steps. Drone 0.8.0-rc3 on GKE Chrome 60 on OS X Sierra,other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | documentation-file,The UI intermittently stops working in the build view The following error appears in the console:  GET https://drone.asgard.8d.com/stream/events 504 ()  After which the UI stops updating and does not respond to clicking on the different steps. Drone 0.8.0-rc3 on GKE Chrome 60 on OS X Sierra other-file other-file source-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file source-file other-file source-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file documentation-file,no-bug,0.7
455,harness,https://github.com/harness/harness/issues/455,kubernetes/fleet support,"It would be really nice to be able to send a build to kubernetes/fleet and have a nice cluster behind the build farm. Currently I have a CoreOS cluster that is hosting the drone as a docker, I would love to be able to use that same cluster through kubernetes or fleet to have the builds run in, instead of a docker inside my docker container. If that isn't on the radar at least being able to farm it off to a different docker would be ideal (if it already isn't through environment variables).",source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file,"kubernetes/fleet support It would be really nice to be able to send a build to kubernetes/fleet and have a nice cluster behind the build farm. Currently I have a CoreOS cluster that is hosting the drone as a docker, I would love to be able to use that same cluster through kubernetes or fleet to have the builds run in, instead of a docker inside my docker container. If that isn't on the radar at least being able to farm it off to a different docker would be ideal (if it already isn't through environment variables). source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file",no-bug,0.9
2698,harness,https://github.com/harness/harness/issues/2698,RFC: don't inject drone env variables to plugins container by default,"The plugin system is really great. And undoubtedly, docker image as plugin is a more advanced way because of portability. It could be a revolution in the whole CI ecosystem. People can share these plugins across CIs. But then I realize one thing, Drone injects its own env variables to the plugins container by default. And all env variable names start with DRONE_ prefix. This design breaks the portability across CIs, which could be better. I prefer not to inject all env to the container by default. Instead, people should fully control what variables they want. For example, `GitHub Pages` use some default env variables, required or option. [DRONE_REMOTE_URL](https://github.com/drone-plugins/drone-gh-pages/blob/master/main.go#L64) is a required variable. In my mind, it should be named as `PLUGIN_REMOTE_URL`, and be transferred by user. yaml steps: - name: publish image: plugins/gh-pages settings: username: from_secret: github_username password: from_secret: github_password pages_directory: public/ remote_url: $DRONE_REMOTE_URL  This can pull out `plugins` from specific `Drone` system, and can make plugins more easy to test and use.",source-file | source-file | source-file | source-file,"RFC: don't inject drone env variables to plugins container by default The plugin system is really great. And undoubtedly, docker image as plugin is a more advanced way because of portability. It could be a revolution in the whole CI ecosystem. People can share these plugins across CIs. But then I realize one thing, Drone injects its own env variables to the plugins container by default. And all env variable names start with DRONE_ prefix. This design breaks the portability across CIs, which could be better. I prefer not to inject all env to the container by default. Instead, people should fully control what variables they want. For example, `GitHub Pages` use some default env variables, required or option. [DRONE_REMOTE_URL](https://github.com/drone-plugins/drone-gh-pages/blob/master/main.go#L64) is a required variable. In my mind, it should be named as `PLUGIN_REMOTE_URL`, and be transferred by user. yaml steps: - name: publish image: plugins/gh-pages settings: username: from_secret: github_username password: from_secret: github_password pages_directory: public/ remote_url: $DRONE_REMOTE_URL  This can pull out `plugins` from specific `Drone` system, and can make plugins more easy to test and use. source-file source-file source-file source-file",no-bug,0.9
2728,harness,https://github.com/harness/harness/issues/2728,Restart older build that succeeded,"Rebuild an older succeeded build, on the commit of that build.",source-file,"Restart older build that succeeded Rebuild an older succeeded build, on the commit of that build. source-file",no-bug,0.9
180,harness,https://github.com/harness/harness/issues/180,"/var/cache/drone is used, but not created",Now `/var/cache/drone` is not created automatically. We also cannot just put `mkdir -p /var/cache/drone` in Makefile because it requires sudo access.,source-file | source-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"/var/cache/drone is used, but not created Now `/var/cache/drone` is not created automatically. We also cannot just put `mkdir -p /var/cache/drone` in Makefile because it requires sudo access. source-file source-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
1113,harness,https://github.com/harness/harness/issues/1113,Implement aliases for services,"There is no clear understanding of how it must be implemented in drone YAML schema, but the background is that we need somehow to handle images with different tags but from the same repository:  yaml image: worker-unit script: - ./.drone/build.sh services: - buildpack-deps:jessie - buildpack-deps:trusty # - buildpack-deps:trusty:stage-ubuntu this of course doesn't look well, should be a cleaner way to represent an alias.  However the clue might be be taken from docker-compose, let's have a look here:  yaml worker: image: ubuntu command: bash -c 'cat /etc/hosts' links: - trusty:stage-ubuntu - jessie:stage-debian trusty: image: buildpack-deps:trusty command: bash -c 'sleep infinity' jessie: image: buildpack-deps:trusty command: bash -c 'sleep infinity'  First docker-compose names specific images, so they come with another name other than its image repository. However a more important feature it's how compose handles links (which are technically the same to _drone **services**_). These links support **aliases**, and exactly this feature would be useful in drone. Btw here are the details for what we can see in the hosts file.  172.17.0.40 trusty_1 9be73b7257a9 tmp_trusty_1 172.17.0.39 jessie_1 10db588f9d9a tmp_jessie_1 172.17.0.39 stage-debian 10db588f9d9a tmp_jessie_1 172.17.0.40 stage-ubuntu 9be73b7257a9 tmp_trusty_1 172.17.0.39 tmp_jessie_1 10db588f9d9a 172.17.0.40 tmp_trusty_1 9be73b7257a9 ",other-file | other-file,"Implement aliases for services There is no clear understanding of how it must be implemented in drone YAML schema, but the background is that we need somehow to handle images with different tags but from the same repository:  yaml image: worker-unit script: - ./.drone/build.sh services: - buildpack-deps:jessie - buildpack-deps:trusty # - buildpack-deps:trusty:stage-ubuntu this of course doesn't look well, should be a cleaner way to represent an alias.  However the clue might be be taken from docker-compose, let's have a look here:  yaml worker: image: ubuntu command: bash -c 'cat /etc/hosts' links: - trusty:stage-ubuntu - jessie:stage-debian trusty: image: buildpack-deps:trusty command: bash -c 'sleep infinity' jessie: image: buildpack-deps:trusty command: bash -c 'sleep infinity'  First docker-compose names specific images, so they come with another name other than its image repository. However a more important feature it's how compose handles links (which are technically the same to _drone **services**_). These links support **aliases**, and exactly this feature would be useful in drone. Btw here are the details for what we can see in the hosts file.  172.17.0.40 trusty_1 9be73b7257a9 tmp_trusty_1 172.17.0.39 jessie_1 10db588f9d9a tmp_jessie_1 172.17.0.39 stage-debian 10db588f9d9a tmp_jessie_1 172.17.0.40 stage-ubuntu 9be73b7257a9 tmp_trusty_1 172.17.0.39 tmp_jessie_1 10db588f9d9a 172.17.0.40 tmp_trusty_1 9be73b7257a9  other-file other-file",no-bug,0.9
265,harness,https://github.com/harness/harness/issues/265,URLs from Slack and github has been broken.,"Seems https://github.com/drone/drone/pull/247/files changed to require a branch parameter, which is missing from some of the places that links to build, at least for me slack notify and link from github pull request are failing now. They use these urls respectively: from slack: http://myserver.com/github.com/Nordaaker/Input/commit/14fb2f277a7fa5042b2b2ef67cda2dc5e0018c3d gives sql: no rows in result set and from github: http://myserver.com/github.com/Nordaaker/Input/commit/reset-pwd/14fb2f277a7fa5042b2b2ef67cda2dc5e0018c3d (Github pull requests - gives a 404) Not sure if the right fix here is to make those old urls work or to only use the first format with ?branch=<> added.",source-file | test-file | source-file | test-file | source-file | source-file,"URLs from Slack and github has been broken. Seems https://github.com/drone/drone/pull/247/files changed to require a branch parameter, which is missing from some of the places that links to build, at least for me slack notify and link from github pull request are failing now. They use these urls respectively: from slack: http://myserver.com/github.com/Nordaaker/Input/commit/14fb2f277a7fa5042b2b2ef67cda2dc5e0018c3d gives sql: no rows in result set and from github: http://myserver.com/github.com/Nordaaker/Input/commit/reset-pwd/14fb2f277a7fa5042b2b2ef67cda2dc5e0018c3d (Github pull requests - gives a 404) Not sure if the right fix here is to make those old urls work or to only use the first format with ?branch=<> added. source-file test-file source-file test-file source-file source-file",bug,0.9
2073,harness,https://github.com/harness/harness/issues/2073,Squash drone/drone PRs,"What do you think about turning on squash merging on GitHub of PRs? With good PR titles, it would help in parsing through the [change log](https://github.com/drone/drone/compare/v0.6.0v0.7.1) to identify what happened by removing possibly noisy commit messages. <img width=""773"" alt=""image"" src=""https://user-images.githubusercontent.com/3250776/27106791-ec37e2ee-5062-11e7-9cf9-404aa2b4a03c.png"">",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file,"Squash drone/drone PRs What do you think about turning on squash merging on GitHub of PRs? With good PR titles, it would help in parsing through the [change log](https://github.com/drone/drone/compare/v0.6.0v0.7.1) to identify what happened by removing possibly noisy commit messages. <img width=""773"" alt=""image"" src=""https://user-images.githubusercontent.com/3250776/27106791-ec37e2ee-5062-11e7-9cf9-404aa2b4a03c.png""> source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
3475,harness,https://github.com/harness/harness/issues/3475,Drone pipeline converter cache/memorizer?,I can't find anything related to pipeline cache in Drone docs but it seems there is such thing. I'm using a conversion extension (starlark - external one). When I update it's components Drone does not apply it in the pipelines. It's using the older version that was built by the extension before the change. It works if i trigger a different pipeline or just restart the drone server. Is it possible to force Drone to parse pipeline every time even if there is no change in the file (I mean the main .drone.yml/.drone.star)?,other-file | other-file,Drone pipeline converter cache/memorizer? I can't find anything related to pipeline cache in Drone docs but it seems there is such thing. I'm using a conversion extension (starlark - external one). When I update it's components Drone does not apply it in the pipelines. It's using the older version that was built by the extension before the change. It works if i trigger a different pipeline or just restart the drone server. Is it possible to force Drone to parse pipeline every time even if there is no change in the file (I mean the main .drone.yml/.drone.star)? other-file other-file,no-bug,0.9
931,harness,https://github.com/harness/harness/issues/931,Add io.js and Node.js v0.12 support,"Node.js has v0.12, and io.js has been released. I would like to add these environments.",other-file | other-file | other-file | source-file | other-file,"Add io.js and Node.js v0.12 support Node.js has v0.12, and io.js has been released. I would like to add these environments. other-file other-file other-file source-file other-file",no-bug,0.9
3039,harness,https://github.com/harness/harness/issues/3039,"Jsonnet cleans ""trigger"" from steps","Hi. Jsonnet removes ""trigger"" while converting to `.drone.yaml`  { name: ""Send slack info"", depends_on: [ ""OTHER_STEP"" ], image: ""plugins/slack"", settings: { channel: ""notifications"", link_names: true, template: ""{{#success build.status}}Cron build passed. Good job.{{else}}Cron build failed. Fix me please.{{/success}}"", }, trigger: { event: [""cron""] }, when: {status: ['success', 'failure'] } }  And after running `drone jsonnet --stream --format=false --stdout` I'm receiving this:  - name: Send slack info image: plugins/slack settings: channel: notifications link_names: true template: ""{{#success build.status}}Cron build passed. Good job.{{else}}Cron build failed. Fix me please.{{/success}}"" when: status: - success - failure depends_on: - OTHER_STEP  there's no  trigger: event: - corn ",source-file,"Jsonnet cleans ""trigger"" from steps Hi. Jsonnet removes ""trigger"" while converting to `.drone.yaml`  { name: ""Send slack info"", depends_on: [ ""OTHER_STEP"" ], image: ""plugins/slack"", settings: { channel: ""notifications"", link_names: true, template: ""{{#success build.status}}Cron build passed. Good job.{{else}}Cron build failed. Fix me please.{{/success}}"", }, trigger: { event: [""cron""] }, when: {status: ['success', 'failure'] } }  And after running `drone jsonnet --stream --format=false --stdout` I'm receiving this:  - name: Send slack info image: plugins/slack settings: channel: notifications link_names: true template: ""{{#success build.status}}Cron build passed. Good job.{{else}}Cron build failed. Fix me please.{{/success}}"" when: status: - success - failure depends_on: - OTHER_STEP  there's no  trigger: event: - corn  source-file",no-bug,0.9
2790,harness,https://github.com/harness/harness/issues/2790,Suggestion: Continuous Fuzzing,"Hi, I'm Yevgeny Pats Founder of [Fuzzit](https://fuzzit.dev) - Continuous fuzzing as a service platform. We have a free plan for OSS and I would be happy to contribute a PR if that's interesting. The PR will include the following - [go-fuzz](https://github.com/dvyukov/go-fuzz) fuzzers - Continuous Fuzzing of master branch which will generate new corpus and look for new crashes - Regression on every PR that will run the fuzzers through all the generated corpus and fixed crashes from previous step. This will prevent new or old bugs from crippling into master. You can see our basic example [here](https://github.com/fuzzitdev/example-go) and you can see an example of ""in the wild"" integration [here](https://github.com/google/syzkaller). Let me know if this is something worth working on. Also, we have a [reward](https://fuzzit.dev/2019/08/12/announcing-rewards-for-go-rust-oss-projects/) program. If you are interested in implementing the fuzzers and the integration yourself Ill be happy to reward you as well as to get unbiased feedback on how smooth the integration was. Cheers, Yevgeny",other-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | documentation-file | source-file | other-file | documentation-file,"Suggestion: Continuous Fuzzing Hi, I'm Yevgeny Pats Founder of [Fuzzit](https://fuzzit.dev) - Continuous fuzzing as a service platform. We have a free plan for OSS and I would be happy to contribute a PR if that's interesting. The PR will include the following - [go-fuzz](https://github.com/dvyukov/go-fuzz) fuzzers - Continuous Fuzzing of master branch which will generate new corpus and look for new crashes - Regression on every PR that will run the fuzzers through all the generated corpus and fixed crashes from previous step. This will prevent new or old bugs from crippling into master. You can see our basic example [here](https://github.com/fuzzitdev/example-go) and you can see an example of ""in the wild"" integration [here](https://github.com/google/syzkaller). Let me know if this is something worth working on. Also, we have a [reward](https://fuzzit.dev/2019/08/12/announcing-rewards-for-go-rust-oss-projects/) program. If you are interested in implementing the fuzzers and the integration yourself Ill be happy to reward you as well as to get unbiased feedback on how smooth the integration was. Cheers, Yevgeny other-file other-file other-file other-file other-file source-file other-file source-file other-file other-file other-file other-file documentation-file source-file other-file documentation-file",no-bug,0.95
324,harness,https://github.com/harness/harness/issues/324,Multiple Language Images,"Currently, Drone has language for only one language at a time. What if I would like to use ruby, nodejs and go together?",other-file | source-file | other-file | source-file | documentation-file | other-file | source-file | other-file | other-file,"Multiple Language Images Currently, Drone has language for only one language at a time. What if I would like to use ruby, nodejs and go together? other-file source-file other-file source-file documentation-file other-file source-file other-file other-file",no-bug,0.9
253,harness,https://github.com/harness/harness/issues/253,"some builds fail immediately with ""build: No such id: """,This happens occasionally and seems to be some Docker-related flakiness. ![screen shot 2014-04-10 at 9 20 21 am](https://cloud.githubusercontent.com/assets/1880/2670315/0ef48046-c0cc-11e3-89cb-c766611e4760.png),source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"some builds fail immediately with ""build: No such id: "" This happens occasionally and seems to be some Docker-related flakiness. ![screen shot 2014-04-10 at 9 20 21 am](https://cloud.githubusercontent.com/assets/1880/2670315/0ef48046-c0cc-11e3-89cb-c766611e4760.png) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2421,harness,https://github.com/harness/harness/issues/2421,[new metrics] drone_http_response_code_[2/3/4/5]xx,`drone_http_response_code_2xx` Type: counter Purpose: tracks response code segments Labels: - endpoint - specific code (200|etc)  `drone_http_response_code_3xx` Type: counter Purpose: tracks response code segments Labels: - endpoint - specific code (304|etc)  `drone_http_response_code_4xx` Type: counter Purpose: tracks response code segments Labels: - endpoint - specific code (401|404|etc)  `drone_http_response_code_5xx` Type: counter Purpose: tracks response code segments Labels: - endpoint - specific code (500|502|etc),source-file | other-file | other-file | source-file | source-file | source-file,[new metrics] drone_http_response_code_[2/3/4/5]xx `drone_http_response_code_2xx` Type: counter Purpose: tracks response code segments Labels: - endpoint - specific code (200|etc)  `drone_http_response_code_3xx` Type: counter Purpose: tracks response code segments Labels: - endpoint - specific code (304|etc)  `drone_http_response_code_4xx` Type: counter Purpose: tracks response code segments Labels: - endpoint - specific code (401|404|etc)  `drone_http_response_code_5xx` Type: counter Purpose: tracks response code segments Labels: - endpoint - specific code (500|502|etc) source-file other-file other-file source-file source-file source-file,no-bug,0.9
915,harness,https://github.com/harness/harness/issues/915,Vagrant provisioning broken,"The Vagrant file isn't bringing up the system as expected. Steps to repro:  bash git clone git@github.com:drone/drone.git cd drone vagrant up  Results:  ==> ubuntu: make: ==> ubuntu:  [deps] Error 1 The SSH command responded with a non-zero exit status. Vagrant assumes that this means the command failed. The output for this command should be in the log above. Please read the output to determine what went wrong.  Drone doesn't appear to have installed. After connecting via `vagrant ssh`, there's no drone process running and upstart doesn't know about it:  bash sudo status drone status: Unknown job: drone  Not sure if this is related, but there appears to be something wrong with an earlier step:  bash ==> ubuntu: Building Drone ==> ubuntu: go get github.com/GeertJohan/go.rice/rice ==> ubuntu: go get -t -v ./ ==> ubuntu: code.google.com/p/goauth2 (download) ==> ubuntu: github.com/andybons/hipchat (download) ==> ubuntu: github.com/codegangsta/cli (download) ==> ubuntu: github.com/docker/docker (download) ==> ubuntu: github.com/Sirupsen/logrus (download) ==> ubuntu: package code.google.com/p/goauth2/oauth ==> ubuntu: imports github.com/andybons/hipchat ==> ubuntu: imports github.com/codegangsta/cli ==> ubuntu: imports github.com/docker/docker/pkg/archive ==> ubuntu: imports github.com/Sirupsen/logrus ==> ubuntu: imports github.com/docker/docker/pkg/parsers ==> ubuntu: imports github.com/docker/docker/pkg/stdcopy ==> ubuntu: imports github.com/docker/docker/pkg/term ==> ubuntu: imports github.com/docker/docker/utils ==> ubuntu: imports github.com/docker/docker/autogen/dockerversion ==> ubuntu: imports github.com/docker/docker/autogen/dockerversion ==> ubuntu: imports github.com/docker/docker/autogen/dockerversion: cannot find package ""github.com/docker/docker/autogen/dockerversion"" in any of: ==> ubuntu: /usr/local/go/src/pkg/github.com/docker/docker/autogen/dockerversion (from $GOROOT) ==> ubuntu: /opt/go/src/github.com/docker/docker/autogen/dockerversion (from $GOPATH)  Related to https://github.com/docker/docker/issues/10922 ?",source-file,"Vagrant provisioning broken The Vagrant file isn't bringing up the system as expected. Steps to repro:  bash git clone git@github.com:drone/drone.git cd drone vagrant up  Results:  ==> ubuntu: make: ==> ubuntu:  [deps] Error 1 The SSH command responded with a non-zero exit status. Vagrant assumes that this means the command failed. The output for this command should be in the log above. Please read the output to determine what went wrong.  Drone doesn't appear to have installed. After connecting via `vagrant ssh`, there's no drone process running and upstart doesn't know about it:  bash sudo status drone status: Unknown job: drone  Not sure if this is related, but there appears to be something wrong with an earlier step:  bash ==> ubuntu: Building Drone ==> ubuntu: go get github.com/GeertJohan/go.rice/rice ==> ubuntu: go get -t -v ./ ==> ubuntu: code.google.com/p/goauth2 (download) ==> ubuntu: github.com/andybons/hipchat (download) ==> ubuntu: github.com/codegangsta/cli (download) ==> ubuntu: github.com/docker/docker (download) ==> ubuntu: github.com/Sirupsen/logrus (download) ==> ubuntu: package code.google.com/p/goauth2/oauth ==> ubuntu: imports github.com/andybons/hipchat ==> ubuntu: imports github.com/codegangsta/cli ==> ubuntu: imports github.com/docker/docker/pkg/archive ==> ubuntu: imports github.com/Sirupsen/logrus ==> ubuntu: imports github.com/docker/docker/pkg/parsers ==> ubuntu: imports github.com/docker/docker/pkg/stdcopy ==> ubuntu: imports github.com/docker/docker/pkg/term ==> ubuntu: imports github.com/docker/docker/utils ==> ubuntu: imports github.com/docker/docker/autogen/dockerversion ==> ubuntu: imports github.com/docker/docker/autogen/dockerversion ==> ubuntu: imports github.com/docker/docker/autogen/dockerversion: cannot find package ""github.com/docker/docker/autogen/dockerversion"" in any of: ==> ubuntu: /usr/local/go/src/pkg/github.com/docker/docker/autogen/dockerversion (from $GOROOT) ==> ubuntu: /opt/go/src/github.com/docker/docker/autogen/dockerversion (from $GOPATH)  Related to https://github.com/docker/docker/issues/10922 ? source-file",no-bug,0.95
2472,harness,https://github.com/harness/harness/issues/2472,[FR] add Condition by agent labels for building,"since both docker and kubernetes support labels, maybe it's better to support label in drone as the same. because current condition(instance,Platform) can be export by docker inspect. if there is label support in drone, then we can implement more complex condition, include Multi-Platform and Multi-Machine Pipelines. it's easy to special agent for special build steps",source-file | source-file | source-file | source-file | source-file | config-file,"[FR] add Condition by agent labels for building since both docker and kubernetes support labels, maybe it's better to support label in drone as the same. because current condition(instance,Platform) can be export by docker inspect. if there is label support in drone, then we can implement more complex condition, include Multi-Platform and Multi-Machine Pipelines. it's easy to special agent for special build steps source-file source-file source-file source-file source-file config-file",no-bug,0.9
808,harness,https://github.com/harness/harness/issues/808,Allow for optional Gravatar username overrides,"As someone using Drone in a CI environment to test my builds in, I would like to be clearly identified using my own Gravatar which does not use the email address I commit with. In my example, I commit with a work email address but my Gravatar belongs to a personal email address. I shouldn't have to create a WordPress.com/Gravatar account for my work email address.",source-file | source-file,"Allow for optional Gravatar username overrides As someone using Drone in a CI environment to test my builds in, I would like to be clearly identified using my own Gravatar which does not use the email address I commit with. In my example, I commit with a work email address but my Gravatar belongs to a personal email address. I shouldn't have to create a WordPress.com/Gravatar account for my work email address. source-file source-file",no-bug,0.9
3390,harness,https://github.com/harness/harness/issues/3390,Feature Request: Project repository templating,"Hello, Like GitHub, adding like a repository template would be pretty good in my opinion. I'm often using that feature, and would be such a bless with gitness. Best regards,",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Feature Request: Project repository templating Hello, Like GitHub, adding like a repository template would be pretty good in my opinion. I'm often using that feature, and would be such a bless with gitness. Best regards, source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
2848,harness,https://github.com/harness/harness/issues/2848,documentation not up to date/right,"The [documentation on cloning](https://docker-runner.docs.drone.io/configuration/cloning/) is wrong. It says to use the alpine:git image for cloning. This image doesn't exist. Also, a `go build` won't work by default on `golang` image because the drone workspace is on `/drone/src` volume and the GOPATH in the `golang` image points to `/go`. So, it clones a Go project to `/drone/src` which is outside GOPATH. And the build will fail because it can't get the deps right. I guess the solution would be to have a Go project using modules. I haven't tried yet.",source-file | source-file | source-file | source-file | source-file,"documentation not up to date/right The [documentation on cloning](https://docker-runner.docs.drone.io/configuration/cloning/) is wrong. It says to use the alpine:git image for cloning. This image doesn't exist. Also, a `go build` won't work by default on `golang` image because the drone workspace is on `/drone/src` volume and the GOPATH in the `golang` image points to `/go`. So, it clones a Go project to `/drone/src` which is outside GOPATH. And the build will fail because it can't get the deps right. I guess the solution would be to have a Go project using modules. I haven't tried yet. source-file source-file source-file source-file source-file",no-bug,0.9
1207,harness,https://github.com/harness/harness/issues/1207,Azure Deployment Plugin,"Please provide ability to deploy on Azure. Here are some links for your reference: - http://blogs.msdn.com/b/holgerkenn/archive/2014/03/20/azure-from-the-linux-command-line-part-1.aspx - http://blogs.msdn.com/b/holgerkenn/archive/2014/04/15/azure-from-the-linux-command-line-part-2.aspx - https://github.com/Azure/azure-xplat-cli - https://github.com/Azure/azure-cli-docker - https://github.com/Azure/azure-docker-extension - https://github.com/Azure/azure-linux-automation - https://github.com/Azure/azure-linux-extensions - https://github.com/Azure/WALinuxAgent On a bright side, it will provide additional opportunities for service consumers IMO.",other-file | source-file | documentation-file | source-file | source-file | documentation-file | source-file | source-file | source-file | other-file | documentation-file,"Azure Deployment Plugin Please provide ability to deploy on Azure. Here are some links for your reference: - http://blogs.msdn.com/b/holgerkenn/archive/2014/03/20/azure-from-the-linux-command-line-part-1.aspx - http://blogs.msdn.com/b/holgerkenn/archive/2014/04/15/azure-from-the-linux-command-line-part-2.aspx - https://github.com/Azure/azure-xplat-cli - https://github.com/Azure/azure-cli-docker - https://github.com/Azure/azure-docker-extension - https://github.com/Azure/azure-linux-automation - https://github.com/Azure/azure-linux-extensions - https://github.com/Azure/WALinuxAgent On a bright side, it will provide additional opportunities for service consumers IMO. other-file source-file documentation-file source-file source-file documentation-file source-file source-file source-file other-file documentation-file",no-bug,0.95
3415,harness,https://github.com/harness/harness/issues/3415,matrix support list,"this work  kind: pipeline spec: stages: - type: ci spec: steps: - name: test type: script strategy: type: matrix spec: axis: node_version: [ ""12"", ""14"" ] spec: image: node:${{ matrix.node_version }} run: |- npm install npm test  but this not work, i have a long list , so i hope list them as a list wilth `- 12 -14`  kind: pipeline spec: stages: - type: ci spec: steps: - name: test type: script strategy: type: matrix spec: axis: node_version: - 12 - 14 spec: image: node:${{ matrix.node_version }} run: |- npm install npm test ",source-file | source-file,"matrix support list this work  kind: pipeline spec: stages: - type: ci spec: steps: - name: test type: script strategy: type: matrix spec: axis: node_version: [ ""12"", ""14"" ] spec: image: node:${{ matrix.node_version }} run: |- npm install npm test  but this not work, i have a long list , so i hope list them as a list wilth `- 12 -14`  kind: pipeline spec: stages: - type: ci spec: steps: - name: test type: script strategy: type: matrix spec: axis: node_version: - 12 - 14 spec: image: node:${{ matrix.node_version }} run: |- npm install npm test  source-file source-file",no-bug,0.9
440,harness,https://github.com/harness/harness/issues/440,"Add some reporting (unit tests, code coverage)","(feature request) Most build tools support execution of tests and reporting (e.g. maven uses surefire to run unit test and creates reports from it). It would be nice if drone could parse such reports and display them on the history. In addtion, such information could be part of the status mails (like ""3/100 tests"" failed).",source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file,"Add some reporting (unit tests, code coverage) (feature request) Most build tools support execution of tests and reporting (e.g. maven uses surefire to run unit test and creates reports from it). It would be nice if drone could parse such reports and display them on the history. In addtion, such information could be part of the status mails (like ""3/100 tests"" failed). source-file source-file other-file other-file other-file other-file other-file other-file source-file other-file source-file documentation-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file",no-bug,0.95
627,harness,https://github.com/harness/harness/issues/627,Unable to copy repository. exit status 1,"Hi, I wanted to build a repo of a gitlab instance. Somehow drone fails when it tries to copy the repository from a local path path (even though this is a gitlab ssh/https repo). repo: gitlab@192.168<> -> src: /tmp/drone-503742147/src It fails here: https://github.com/drone/drone/blob/master/shared/build/build.go#L154",other-file,"Unable to copy repository. exit status 1 Hi, I wanted to build a repo of a gitlab instance. Somehow drone fails when it tries to copy the repository from a local path path (even though this is a gitlab ssh/https repo). repo: gitlab@192.168<> -> src: /tmp/drone-503742147/src It fails here: https://github.com/drone/drone/blob/master/shared/build/build.go#L154 other-file",no-bug,0.9
2783,harness,https://github.com/harness/harness/issues/2783,"nodeSelector,resource quota,namespace support for drone jobs.","Drone Version: v1.2.3 K8s Version: 1.13 Wanted to know if there are plans for adding nodeSelector, resource quota, namespace support for the k8s drone jobs? Having an option to specify a nodeSelector, namespace, resources in the `.drone.yml` can help us segregate workloads better.",source-file | test-file | source-file | test-file,"nodeSelector,resource quota,namespace support for drone jobs. Drone Version: v1.2.3 K8s Version: 1.13 Wanted to know if there are plans for adding nodeSelector, resource quota, namespace support for the k8s drone jobs? Having an option to specify a nodeSelector, namespace, resources in the `.drone.yml` can help us segregate workloads better. source-file test-file source-file test-file",no-bug,0.9
392,harness,https://github.com/harness/harness/issues/392,Error: Unable to pull image bradrydzewski/redis:2.8,"""Error: Unable to pull image bradrydzewski/redis:2.8"" is all I get for the build, and with log.debug I'm not seeing anything at all in the drone.log, any hints?",other-file | test-file | other-file,"Error: Unable to pull image bradrydzewski/redis:2.8 ""Error: Unable to pull image bradrydzewski/redis:2.8"" is all I get for the build, and with log.debug I'm not seeing anything at all in the drone.log, any hints? other-file test-file other-file",no-bug,0.9
805,harness,https://github.com/harness/harness/issues/805,Ability to enable open registration on a per-plugin basis,"We use both GitHub.com and a private instance of GitHub Enterprise. For our GHE users, we would be happy to allow open registration, i.e. anyone with a GHE account can log in. For GitHub.com however, we would need to restrict which users can use Drone. Currently open registration is a global option affecting all remote plugins. I'd like to be able to enable/disable open registration for specific remotes.",source-file,"Ability to enable open registration on a per-plugin basis We use both GitHub.com and a private instance of GitHub Enterprise. For our GHE users, we would be happy to allow open registration, i.e. anyone with a GHE account can log in. For GitHub.com however, we would need to restrict which users can use Drone. Currently open registration is a global option affecting all remote plugins. I'd like to be able to enable/disable open registration for specific remotes. source-file",no-bug,0.9
2238,harness,https://github.com/harness/harness/issues/2238,Uncaught (in promise) RangeError: Invalid time value,"I got some builds which are using `group:` for parallel execution, there it can happen that some `procs` don't have a start date defined which will result in a javascript error as stated in the title. With this error it's not possible to see the build details anymore. <img width=""1440"" alt=""bildschirmfoto 2017-10-06 um 22 03 00"" src=""https://user-images.githubusercontent.com/156964/31296437-8f9511ee-aae2-11e7-884d-c6685de909bc.png""> After that I prepared a query to look for the `procs` values:  sqlite> select proc_id, proc_name, proc_state, proc_started, proc_stopped, build_id, repo_full_name from procs left join builds on (proc_build_id = build_id) left join repos on (build_repo_id = repo_id) where repo_full_name = 'demos/launcher' and build_number = 5; 568||failure|1507131916|1507132244|129|demos/launcher 569|clone|success|1507131916|1507131922|129|demos/launcher 570|restore|success|1507131922|1507131928|129|demos/launcher 571|frontend-prepare|success|1507131928|1507131986|129|demos/launcher 572|frontend-lint|success|1507131986|1507132000|129|demos/launcher 573|frontend-test|success|1507131986|1507131998|129|demos/launcher 574|frontend-build|success|1507131986|1507132014|129|demos/launcher 575|backend-prepare|success|1507132015|1507132151|129|demos/launcher 576|backend-vet|success|0|1507132186|129|demos/launcher 577|backend-varcheck|success|1507132151|1507132187|129|demos/launcher 578|backend-structcheck|success|1507132151|1507132184|129|demos/launcher 579|backend-unconvert|success|1507132151|1507132172|129|demos/launcher 580|backend-ineffassign|success|1507132151|1507132159|129|demos/launcher 581|backend-lint|success|1507132151|1507132174|129|demos/launcher 582|backend-test|success|1507132151|1507132201|129|demos/launcher 583|backend-build|success|1507132151|1507132186|129|demos/launcher 584|docker|failure|1507132201|1507132233|129|demos/launcher 585|rebuild|skipped|0|0|129|demos/launcher 586|flush|skipped|0|0|129|demos/launcher 587|slack|failure|1507132233|1507132241|129|demos/launcher  After setting the `proc_started` values for ids 576 to a real date the UI started to work as expected agin.",source-file,"Uncaught (in promise) RangeError: Invalid time value I got some builds which are using `group:` for parallel execution, there it can happen that some `procs` don't have a start date defined which will result in a javascript error as stated in the title. With this error it's not possible to see the build details anymore. <img width=""1440"" alt=""bildschirmfoto 2017-10-06 um 22 03 00"" src=""https://user-images.githubusercontent.com/156964/31296437-8f9511ee-aae2-11e7-884d-c6685de909bc.png""> After that I prepared a query to look for the `procs` values:  sqlite> select proc_id, proc_name, proc_state, proc_started, proc_stopped, build_id, repo_full_name from procs left join builds on (proc_build_id = build_id) left join repos on (build_repo_id = repo_id) where repo_full_name = 'demos/launcher' and build_number = 5; 568||failure|1507131916|1507132244|129|demos/launcher 569|clone|success|1507131916|1507131922|129|demos/launcher 570|restore|success|1507131922|1507131928|129|demos/launcher 571|frontend-prepare|success|1507131928|1507131986|129|demos/launcher 572|frontend-lint|success|1507131986|1507132000|129|demos/launcher 573|frontend-test|success|1507131986|1507131998|129|demos/launcher 574|frontend-build|success|1507131986|1507132014|129|demos/launcher 575|backend-prepare|success|1507132015|1507132151|129|demos/launcher 576|backend-vet|success|0|1507132186|129|demos/launcher 577|backend-varcheck|success|1507132151|1507132187|129|demos/launcher 578|backend-structcheck|success|1507132151|1507132184|129|demos/launcher 579|backend-unconvert|success|1507132151|1507132172|129|demos/launcher 580|backend-ineffassign|success|1507132151|1507132159|129|demos/launcher 581|backend-lint|success|1507132151|1507132174|129|demos/launcher 582|backend-test|success|1507132151|1507132201|129|demos/launcher 583|backend-build|success|1507132151|1507132186|129|demos/launcher 584|docker|failure|1507132201|1507132233|129|demos/launcher 585|rebuild|skipped|0|0|129|demos/launcher 586|flush|skipped|0|0|129|demos/launcher 587|slack|failure|1507132233|1507132241|129|demos/launcher  After setting the `proc_started` values for ids 576 to a real date the UI started to work as expected agin. source-file",no-bug,0.9
2760,harness,https://github.com/harness/harness/issues/2760,Filtering on cron trigger can't be restarted,"A pipeline that has a trigger like: yaml trigger: cron: - update-github-pages  Will not restart, as the server skips it on the missing cron name criteria. json { ""commit"": ""e4c1c3fd1646f782944f3b6b982349f095d691eb"", ""event"": ""push"", ""level"": ""info"", ""msg"": ""trigger: skipping pipeline, does not match cron job"", ""pipeline"": ""update-github-pages"", ""ref"": ""refs/heads/master"", ""repo"": """", ""time"": ""2019-07-15T11:22:46Z"" } { ""commit"": ""e4c1c3fd1646f782944f3b6b982349f095d691eb"", ""event"": ""push"", ""level"": ""info"", ""msg"": ""trigger: skipping build, no matching pipelines"", ""pipeline"": ""update-github-pages"", ""ref"": ""refs/heads/master"", ""repo"": """", ""time"": ""2019-07-15T11:22:46Z"" } ",documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Filtering on cron trigger can't be restarted A pipeline that has a trigger like: yaml trigger: cron: - update-github-pages  Will not restart, as the server skips it on the missing cron name criteria. json { ""commit"": ""e4c1c3fd1646f782944f3b6b982349f095d691eb"", ""event"": ""push"", ""level"": ""info"", ""msg"": ""trigger: skipping pipeline, does not match cron job"", ""pipeline"": ""update-github-pages"", ""ref"": ""refs/heads/master"", ""repo"": """", ""time"": ""2019-07-15T11:22:46Z"" } { ""commit"": ""e4c1c3fd1646f782944f3b6b982349f095d691eb"", ""event"": ""push"", ""level"": ""info"", ""msg"": ""trigger: skipping build, no matching pipelines"", ""pipeline"": ""update-github-pages"", ""ref"": ""refs/heads/master"", ""repo"": """", ""time"": ""2019-07-15T11:22:46Z"" }  documentation-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
404,harness,https://github.com/harness/harness/issues/404,"0.3 Release, Re-add GitLab integration","This was removed because we completely changed how Drone works. We remove the Drone username/password in favor of 3rd party login. GitLab, however, does not support OAuth. My proposal: 1. user enters their GitLab username / password in Drone 2. Drone uses the GitLab API with username / password to verify identity 3. Drone creates account, stores password in Auth Token field The above flow is for a new user. For an existing user: 1. user enters their GitLab username / password in Drone 2. Drone uses the GitLab API with username / password to verify identity 3. Drone sees user account exists, updates password in Auth Token field (in case it changed) Typically I wouldn't advocate entering a username / password in Drone for a 3rd party system. However, GitLab doesn't give us much of a choice. Furthermore, both GitLab and Drone are open source and self-hosted, so there shouldn't be any security implications.",source-file,"0.3 Release, Re-add GitLab integration This was removed because we completely changed how Drone works. We remove the Drone username/password in favor of 3rd party login. GitLab, however, does not support OAuth. My proposal: 1. user enters their GitLab username / password in Drone 2. Drone uses the GitLab API with username / password to verify identity 3. Drone creates account, stores password in Auth Token field The above flow is for a new user. For an existing user: 1. user enters their GitLab username / password in Drone 2. Drone uses the GitLab API with username / password to verify identity 3. Drone sees user account exists, updates password in Auth Token field (in case it changed) Typically I wouldn't advocate entering a username / password in Drone for a 3rd party system. However, GitLab doesn't give us much of a choice. Furthermore, both GitLab and Drone are open source and self-hosted, so there shouldn't be any security implications. source-file",no-bug,0.9
1177,harness,https://github.com/harness/harness/issues/1177,Drone cannot clone repo: could not read Username for 'URL',"Good day everyone! my drone build is failing due to not being able to clone the repository from my gogs server My gogs server is running behind a nginx proxy that serves https but serving it directly without nginx doesnt fix the problem! This is the output from Drone:  $ git clone --depth=50 --recursive --branch=master http://domain/user/repo.git /var/cache/drone/src/domain/user/repo Cloning into '/var/cache/drone/src/domain/user/repo' fatal: could not read Username for 'http://domain': No such device or address  and this is my .drone.yml  image: drone_nodejs script: - cd NodejsWebApp1/NodejsWebApp1 - npm install - npm test  and for the sake of completion my Dockerfile for drone_nodejs  FROM node:0.12.7-slim RUN apt-get update -y \ && apt-get install -y git CMD [ ""node"" ] ",documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | documentation-file | other-file | other-file | other-file,"Drone cannot clone repo: could not read Username for 'URL' Good day everyone! my drone build is failing due to not being able to clone the repository from my gogs server My gogs server is running behind a nginx proxy that serves https but serving it directly without nginx doesnt fix the problem! This is the output from Drone:  $ git clone --depth=50 --recursive --branch=master http://domain/user/repo.git /var/cache/drone/src/domain/user/repo Cloning into '/var/cache/drone/src/domain/user/repo' fatal: could not read Username for 'http://domain': No such device or address  and this is my .drone.yml  image: drone_nodejs script: - cd NodejsWebApp1/NodejsWebApp1 - npm install - npm test  and for the sake of completion my Dockerfile for drone_nodejs  FROM node:0.12.7-slim RUN apt-get update -y \ && apt-get install -y git CMD [ ""node"" ]  documentation-file other-file other-file other-file other-file source-file other-file other-file other-file source-file other-file documentation-file other-file other-file other-file",no-bug,0.9
2489,harness,https://github.com/harness/harness/issues/2489,Changing settings doesn't alter Github webhooks,"Changing repository settings doesn't alter Github webhooks. For example, we want to disable pull requests from triggering Drone builds but unchecking that checkbox doesn't change Github webhook settings.",database-file,"Changing settings doesn't alter Github webhooks Changing repository settings doesn't alter Github webhooks. For example, we want to disable pull requests from triggering Drone builds but unchecking that checkbox doesn't change Github webhook settings. database-file",no-bug,0.8
3553,harness,https://github.com/harness/harness/issues/3553,Cannot commit to the newly created repo,"Hi I run the Gitness app locally by pulling in the latest code from the `main` branch and compiling it but fail to push any commits to the newly created repository through Gitness web GUI. Every time I push changes to the repository, it fails with no detailed information. However, in the console log of the Gitness server running locally, I see the error messages as seen in the screenshot below. Can anyone please advise what I am doing wrong? Thanks! <img width=""963"" alt=""image"" src=""https://github.com/user-attachments/assets/5946c6dd-c73a-498f-b669-bf86b7272e5f"">",source-file | source-file | source-file | source-file | test-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file,"Cannot commit to the newly created repo Hi I run the Gitness app locally by pulling in the latest code from the `main` branch and compiling it but fail to push any commits to the newly created repository through Gitness web GUI. Every time I push changes to the repository, it fails with no detailed information. However, in the console log of the Gitness server running locally, I see the error messages as seen in the screenshot below. Can anyone please advise what I am doing wrong? Thanks! <img width=""963"" alt=""image"" src=""https://github.com/user-attachments/assets/5946c6dd-c73a-498f-b669-bf86b7272e5f""> source-file source-file source-file source-file test-file documentation-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
3256,harness,https://github.com/harness/harness/issues/3256,Skipping not working on bitbucket server (stash),We are using drone together with Bitbucket Server and https://docs.drone.io/pipeline/skipping/ is not working properly. The stash hook does not provide the message of the commit but this could be solve as drone fill those fields after the hook is received.,source-file | source-file,Skipping not working on bitbucket server (stash) We are using drone together with Bitbucket Server and https://docs.drone.io/pipeline/skipping/ is not working properly. The stash hook does not provide the message of the commit but this could be solve as drone fill those fields after the hook is received. source-file source-file,no-bug,0.7
1175,harness,https://github.com/harness/harness/issues/1175,Token Implementation,"The token implementation is un-finished and is poorly designed. This includes user tokens, access tokens and post-commit hook tokens. Finalize an implementation and move on!",documentation-file | config-file | documentation-file | documentation-file | source-file | source-file | test-file | source-file | source-file | test-file | test-file | source-file | test-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file,"Token Implementation The token implementation is un-finished and is poorly designed. This includes user tokens, access tokens and post-commit hook tokens. Finalize an implementation and move on! documentation-file config-file documentation-file documentation-file source-file source-file test-file source-file source-file test-file test-file source-file test-file source-file test-file test-file test-file test-file test-file test-file test-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file test-file",no-bug,0.7
905,harness,https://github.com/harness/harness/issues/905,empty page on GitHub login redirect,"I've setup a local Drone environment for Docker image testing. I'm able to login and work with the interface. A colleague of mine tried to login as well, but gets stuck on a redirect happening after initial login on GitHub. The redirect URL is as follows (changed the keys): `http://ourdrone.com/api/auth/github.com?code=26314215f822zadcc8ebe&state=HLISSI2IG44RPACYZ6IJM55ZL63N7IUAONPHI3HNZAGSTRGN52NQ%3D%3D%3D%3D` After the white page, we checked GitHub and Drone is actually authorised on his account. We also tried logging in again, this time GitHub redirected right away (due to already given access), but still a white page came up. Our drone instance is configured like this:  [github] client = ""xxx"" secret = ""xxx"" orgs = [""blendle""] ",source-file,"empty page on GitHub login redirect I've setup a local Drone environment for Docker image testing. I'm able to login and work with the interface. A colleague of mine tried to login as well, but gets stuck on a redirect happening after initial login on GitHub. The redirect URL is as follows (changed the keys): `http://ourdrone.com/api/auth/github.com?code=26314215f822zadcc8ebe&state=HLISSI2IG44RPACYZ6IJM55ZL63N7IUAONPHI3HNZAGSTRGN52NQ%3D%3D%3D%3D` After the white page, we checked GitHub and Drone is actually authorised on his account. We also tried logging in again, this time GitHub redirected right away (due to already given access), but still a white page came up. Our drone instance is configured like this:  [github] client = ""xxx"" secret = ""xxx"" orgs = [""blendle""]  source-file",no-bug,0.8
203,harness,https://github.com/harness/harness/issues/203,Publish Plugin - Pypi,"Allow publishing python libraries to pypi on successful build. Placeholder here: https://github.com/drone/drone/blob/master/pkg/plugin/publish/pypi.go I had some code for this (from the old, closed source version of Drone). This is probably better left to someone with more python experience than me.  Go // Credentials represents the PyPi authentication credentials // that are stored in the .pypirc file var pypirc = ` cat <<EOF > $HOME/.pypirc [pypirc] servers = pypi [server-login] username:%s password:%s EOF` type Pypi struct { // The Username used by pypi to connect // and publish to the central repository User string // The Password used by pypi to connect // and deploy to the central repository Pass string } func (p *Pypi) Write(f *buildfile.Buildfile) { if len(p.User) == 0 || len(p.Pass) == 0 { return } // debugging purposes so we can see if / where something is failing f.WriteCmdSilent(""echo 'publishing python module to Pypi '"") // generate .pypirc file that stores your pip credentials f.WriteCmdSilent(pypirc, p.User, p.Pass) // upload to pypi f.WriteCmd(""python setup.py sdist --formats gztar,zip upload"") }  **NOTE** this is pseudo code an is untested. It also assumes the deployment is being executed from the root of the github repository. It is possible the `pwd` could have changed. It is also possible that the publish command should be executed from a sub-directory of the repository.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | source-file | documentation-file | other-file | other-file | other-file | source-file | other-file | other-file | documentation-file,"Publish Plugin - Pypi Allow publishing python libraries to pypi on successful build. Placeholder here: https://github.com/drone/drone/blob/master/pkg/plugin/publish/pypi.go I had some code for this (from the old, closed source version of Drone). This is probably better left to someone with more python experience than me.  Go // Credentials represents the PyPi authentication credentials // that are stored in the .pypirc file var pypirc = ` cat <<EOF > $HOME/.pypirc [pypirc] servers = pypi [server-login] username:%s password:%s EOF` type Pypi struct { // The Username used by pypi to connect // and publish to the central repository User string // The Password used by pypi to connect // and deploy to the central repository Pass string } func (p *Pypi) Write(f *buildfile.Buildfile) { if len(p.User) == 0 || len(p.Pass) == 0 { return } // debugging purposes so we can see if / where something is failing f.WriteCmdSilent(""echo 'publishing python module to Pypi '"") // generate .pypirc file that stores your pip credentials f.WriteCmdSilent(pypirc, p.User, p.Pass) // upload to pypi f.WriteCmd(""python setup.py sdist --formats gztar,zip upload"") }  **NOTE** this is pseudo code an is untested. It also assumes the deployment is being executed from the root of the github repository. It is possible the `pwd` could have changed. It is also possible that the publish command should be executed from a sub-directory of the repository. source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file other-file other-file other-file other-file source-file source-file documentation-file other-file other-file other-file source-file other-file other-file documentation-file",no-bug,0.9
202,harness,https://github.com/harness/harness/issues/202,Publish Plugin - NPM,"Automatically publish libraries to NPM. I have a placeholder in the code here: https://github.com/drone/drone/blob/master/pkg/plugin/publish/npm.go I started working on something a while back but never got implemented:  Go type NPM struct { // The Email address used by NPM to connect // and publish to the central repository Email string // The Password used by NPM to connect // and deploy to the central repository Password string // Fails if the package name and version combination already // exists in the registry. Overwrites when the ""--force"" flag is set. Force bool } func (n *NPM) Write(f *buildfile.Buildfile) { // skip if npm username and password are empty if len(n.Email) == 0 || len(n.Password) == 0 { return } // TODO we need to login to npm // this will generate a $HOME/.npmrc file // debugging purposes so we can see if / where something is failing f.WriteCmdSilent(""echo 'publishing to NPM '"") if n.Force { f.WriteCmd(""npm publish"") } else { f.WriteCmd(""npm publish --force"") }  **NOTE** we should probably ensure that this is being executed from the root of the repository. We should also give the option to push an npm library that is in a subdirectory of the root",other-file | source-file | source-file | source-file | source-file,"Publish Plugin - NPM Automatically publish libraries to NPM. I have a placeholder in the code here: https://github.com/drone/drone/blob/master/pkg/plugin/publish/npm.go I started working on something a while back but never got implemented:  Go type NPM struct { // The Email address used by NPM to connect // and publish to the central repository Email string // The Password used by NPM to connect // and deploy to the central repository Password string // Fails if the package name and version combination already // exists in the registry. Overwrites when the ""--force"" flag is set. Force bool } func (n *NPM) Write(f *buildfile.Buildfile) { // skip if npm username and password are empty if len(n.Email) == 0 || len(n.Password) == 0 { return } // TODO we need to login to npm // this will generate a $HOME/.npmrc file // debugging purposes so we can see if / where something is failing f.WriteCmdSilent(""echo 'publishing to NPM '"") if n.Force { f.WriteCmd(""npm publish"") } else { f.WriteCmd(""npm publish --force"") }  **NOTE** we should probably ensure that this is being executed from the root of the repository. We should also give the option to push an npm library that is in a subdirectory of the root other-file source-file source-file source-file source-file",no-bug,0.9
1280,harness,https://github.com/harness/harness/issues/1280,Problem with BitBucket,"hi, wanted to try drone today in combination with BitBucket. Sadly did not have very much luck. Used the latest docker-container (0.4) and followed the instructions. First it seemed to work fine. After I pressed ""Login"" it displays me the repositories and when I then click on one, it tells me that it has to get activated first. So I press ""Activate Now"". That is when the problem starts. Because all I get then is the following error message:  Unable to activate this repository. You must have administrative access to this repository. Also, please check the third-party application access policy to ensure Drone is approved.  In the browser console I get:  http://localhost:8800/api/repos/janoberhauser/drone-test: Failed to load resource: the server responded with a status of 500 (Internal Server Error)  and in Docker:  Error #01: Bad request  To be sure I really gave it all the access-rights there are. So that can not be the issue. Also was I totally unable to find any kind of third-party application access policy in BitBucket. I guess that is only in GitHub. So anybody any idea what is going wrong. Is there maybe something wrong with the container because it is just 19h old. Thanks!",source-file | source-file,"Problem with BitBucket hi, wanted to try drone today in combination with BitBucket. Sadly did not have very much luck. Used the latest docker-container (0.4) and followed the instructions. First it seemed to work fine. After I pressed ""Login"" it displays me the repositories and when I then click on one, it tells me that it has to get activated first. So I press ""Activate Now"". That is when the problem starts. Because all I get then is the following error message:  Unable to activate this repository. You must have administrative access to this repository. Also, please check the third-party application access policy to ensure Drone is approved.  In the browser console I get:  http://localhost:8800/api/repos/janoberhauser/drone-test: Failed to load resource: the server responded with a status of 500 (Internal Server Error)  and in Docker:  Error #01: Bad request  To be sure I really gave it all the access-rights there are. So that can not be the issue. Also was I totally unable to find any kind of third-party application access policy in BitBucket. I guess that is only in GitHub. So anybody any idea what is going wrong. Is there maybe something wrong with the container because it is just 19h old. Thanks! source-file source-file",bug,0.85
3347,harness,https://github.com/harness/harness/issues/3347,Issue with environment variables in build,"Hello, I'm having an issue with environment variable interpolation in drone CI. I want to define an environment variable called VERSION and use it in my build to define a docker tag. This variable has to be concatenated with DRONE_COMMIT_BRANCH variable. I have tried many thing like putting this variable at the top of the file, using it like $VERSION, $$VERSION or ${VERSION} but nothing works on my side. Can you help me, please, figure out what I'm doing wrong ? Thanks in advance, Alexandre. yml kind: pipeline type: kubernetes name: default environment: DRONE_LOGS_DEBUG: true platform: os: linux arch: amd64 steps: - name: build and push docker image on IAM registry image: git.toto.com/tools/drone-docker-plugin:latest privileged: true environment: VERSION: 0.0.1-SNAPSHOT PLUGIN_MTU: 1300 settings: tags: - ${DRONE_COMMIT_BRANCH}_$VERSION - latest username: drone dockerfile: Dockerfile context: . password: password repo: git.toto.com/iam/keycloak-ak-sk-spi registry: git.toto.com ",source-file,"Issue with environment variables in build Hello, I'm having an issue with environment variable interpolation in drone CI. I want to define an environment variable called VERSION and use it in my build to define a docker tag. This variable has to be concatenated with DRONE_COMMIT_BRANCH variable. I have tried many thing like putting this variable at the top of the file, using it like $VERSION, $$VERSION or ${VERSION} but nothing works on my side. Can you help me, please, figure out what I'm doing wrong ? Thanks in advance, Alexandre. yml kind: pipeline type: kubernetes name: default environment: DRONE_LOGS_DEBUG: true platform: os: linux arch: amd64 steps: - name: build and push docker image on IAM registry image: git.toto.com/tools/drone-docker-plugin:latest privileged: true environment: VERSION: 0.0.1-SNAPSHOT PLUGIN_MTU: 1300 settings: tags: - ${DRONE_COMMIT_BRANCH}_$VERSION - latest username: drone dockerfile: Dockerfile context: . password: password repo: git.toto.com/iam/keycloak-ak-sk-spi registry: git.toto.com  source-file",no-bug,0.9
2564,harness,https://github.com/harness/harness/issues/2564,Error 1118: Row size too large,"drone: container_name: dsci-drone image: 'drone/drone:1.0.0-rc.3' restart: always hostname: drone.dev ports: - '80:80' - '443:443' volumes: - './data/drone:/data' - '/var/run/docker.sock:/var/run/docker.sock' restart: always environment: - 'DRONE_GITEA_SERVER=http://100.100.100.3:3000' - 'DRONE_GITEA_SKIP_VERIFY=false' - 'DRONE_GIT_ALWAYS_AUTH=false' - 'DRONE_RUNNER_CAPACITY=2' - 'DRONE_SERVER_HOST=100.100.100.4' - 'DRONE_SERVER_PROTO=http' - 'DRONE_TLS_AUTOCERT=false' - 'DRONE_ADMIN=milan' - 'DRONE_OPEN=true' - 'MYSQL_ALLOW_EMPTY_PASSWORD=yes' - 'MYSQL_DATABASE=drone' - 'DRONE_DATABASE_DRIVER=mysql' - 'DRONE_DATABASE_DATASOURCE=drone:drone@tcp(100.100.100.2:3306)/drone?parseTime=true' networks: gitea: ipv4_address: 100.100.100.4  Everything works except when I try to change database provider from sqlite to mysql. It throws an error that some column type needs to be changed from varchar/blob to text. Also, how do I add volume to be trusted. All docs I have been over through have different answers which does not work in this version of drone drone/drone:1.0.0-rc.3 (docker)",other-file | other-file,"Error 1118: Row size too large drone: container_name: dsci-drone image: 'drone/drone:1.0.0-rc.3' restart: always hostname: drone.dev ports: - '80:80' - '443:443' volumes: - './data/drone:/data' - '/var/run/docker.sock:/var/run/docker.sock' restart: always environment: - 'DRONE_GITEA_SERVER=http://100.100.100.3:3000' - 'DRONE_GITEA_SKIP_VERIFY=false' - 'DRONE_GIT_ALWAYS_AUTH=false' - 'DRONE_RUNNER_CAPACITY=2' - 'DRONE_SERVER_HOST=100.100.100.4' - 'DRONE_SERVER_PROTO=http' - 'DRONE_TLS_AUTOCERT=false' - 'DRONE_ADMIN=milan' - 'DRONE_OPEN=true' - 'MYSQL_ALLOW_EMPTY_PASSWORD=yes' - 'MYSQL_DATABASE=drone' - 'DRONE_DATABASE_DRIVER=mysql' - 'DRONE_DATABASE_DATASOURCE=drone:drone@tcp(100.100.100.2:3306)/drone?parseTime=true' networks: gitea: ipv4_address: 100.100.100.4  Everything works except when I try to change database provider from sqlite to mysql. It throws an error that some column type needs to be changed from varchar/blob to text. Also, how do I add volume to be trusted. All docs I have been over through have different answers which does not work in this version of drone drone/drone:1.0.0-rc.3 (docker) other-file other-file",no-bug,0.9
1232,harness,https://github.com/harness/harness/issues/1232,Invalidate Repo and Permission Cache,"The list of user repositories and the permissions to those repositories are cached in a simple LRU cache without expiration (due to lack of time on my part to focus on caching). We need a TTL to avoid rendering stale data in the user interface, otherwise this can result in the following behavior: 1. search results / auto-complete do not include recently added repositories 2. dashboard does not include recently added repositories 3. recently elevated repository permissions (ie changing write -> admin) are not considered There will still be situations where our cache is stale, but we can handle this well enough in the user interface. For example, when I search for a repository that isn't in our cache (perhaps was recently created) we can show a message that says something like this: > {repo_name} is unknown or does not exist. Click here to visit this repository page and activate. We can also provide a button to manually flush the cache in order to force a refresh.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | other-file,"Invalidate Repo and Permission Cache The list of user repositories and the permissions to those repositories are cached in a simple LRU cache without expiration (due to lack of time on my part to focus on caching). We need a TTL to avoid rendering stale data in the user interface, otherwise this can result in the following behavior: 1. search results / auto-complete do not include recently added repositories 2. dashboard does not include recently added repositories 3. recently elevated repository permissions (ie changing write -> admin) are not considered There will still be situations where our cache is stale, but we can handle this well enough in the user interface. For example, when I search for a repository that isn't in our cache (perhaps was recently created) we can show a message that says something like this: > {repo_name} is unknown or does not exist. Click here to visit this repository page and activate. We can also provide a button to manually flush the cache in order to force a refresh. source-file source-file source-file source-file source-file source-file source-file source-file documentation-file other-file",no-bug,0.9
3400,harness,https://github.com/harness/harness/issues/3400,Feature Request: storing multi-line values in Gitness secret,"Does the Gitness secret support storing multi-line values (like CA certificates)? If not, is there a plan to do so? I'm working with a K8s deployment and was passing token and CA cert from Gitness secret. But the formatting of these breaks when being passed to the pipeline.",source-file | source-file,"Feature Request: storing multi-line values in Gitness secret Does the Gitness secret support storing multi-line values (like CA certificates)? If not, is there a plan to do so? I'm working with a K8s deployment and was passing token and CA cert from Gitness secret. But the formatting of these breaks when being passed to the pipeline. source-file source-file",no-bug,0.85
727,harness,https://github.com/harness/harness/issues/727,No longer able to clone private GitHub repo,All new builds suddenly started failing with the following message:  bash $ git clone --depth=50 --recursive --branch=master git@github.com:XX/xx.frontend.git /var/cache/drone/src/github.com/XX/xx.frontend Cloning into '/var/cache/drone/src/github.com/XX/xx.frontend' Host key verification failed. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists.  Rerunning older builds worked fine until I reset/revoked GitHub tokens while trying for a fix. Any ideas/help or debugging tips would be appreciated.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,No longer able to clone private GitHub repo All new builds suddenly started failing with the following message:  bash $ git clone --depth=50 --recursive --branch=master git@github.com:XX/xx.frontend.git /var/cache/drone/src/github.com/XX/xx.frontend Cloning into '/var/cache/drone/src/github.com/XX/xx.frontend' Host key verification failed. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists.  Rerunning older builds worked fine until I reset/revoked GitHub tokens while trying for a fix. Any ideas/help or debugging tips would be appreciated. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
683,harness,https://github.com/harness/harness/issues/683,Prevent build concurrency?,"Is there a way to prevent builds from occurring concurrently? I have code that I need to test, but it can't be run at the same time. Currently drone is building the master branch, and a merged hotfix branch at the same time, and develop appears to be queued (hotfix was merged into develop as well). I've only ever seen drone run two builds at the same time, but is there a way to drop it to one for a project or the whole install?",source-file,"Prevent build concurrency? Is there a way to prevent builds from occurring concurrently? I have code that I need to test, but it can't be run at the same time. Currently drone is building the master branch, and a merged hotfix branch at the same time, and develop appears to be queued (hotfix was merged into develop as well). I've only ever seen drone run two builds at the same time, but is there a way to drop it to one for a project or the whole install? source-file",no-bug,0.9
3332,harness,https://github.com/harness/harness/issues/3332,Can't activate gitlab project,"gitlab integrates Drone, when the gitlab project is activated in Drone, an error message pops up, and the error message is empty, The version of gitlab is 15.3.1, and the version of Drone is the latest version. docker run \ --volume=/var/lib/drone:/data \ --env=DRONE_GITLAB_SERVER=http://192.168.0.150:9090 \ --env=DRONE_GITLAB_CLIENT_ID=8bae21f3d3c8b5a722ae1aa55c61eb6dbd14d9e1aca9a7f720fb638a3ca4c5ca \ --env=DRONE_GITLAB_CLIENT_SECRET=b0927a462d5c19eae39216483ee7a0d83f8c31e5c7b2011c9bb6a8c976a3cd0b \ --env=DRONE_RPC_SECRET=b63a8848e42f3d96108e04a5fb99f41e \ --env=DRONE_SERVER_HOST=192.168.0.150:7070 \ --env=DRONE_SERVER_PROTO=http \ --env=DRONE_USER_CREATE=username:root,admin:true \ --publish=7070:80 \ --publish=8443:443 \ --restart=always \ --detach=true \ --name=drone \ drone/drone:2",source-file | source-file,"Can't activate gitlab project gitlab integrates Drone, when the gitlab project is activated in Drone, an error message pops up, and the error message is empty, The version of gitlab is 15.3.1, and the version of Drone is the latest version. docker run \ --volume=/var/lib/drone:/data \ --env=DRONE_GITLAB_SERVER=http://192.168.0.150:9090 \ --env=DRONE_GITLAB_CLIENT_ID=8bae21f3d3c8b5a722ae1aa55c61eb6dbd14d9e1aca9a7f720fb638a3ca4c5ca \ --env=DRONE_GITLAB_CLIENT_SECRET=b0927a462d5c19eae39216483ee7a0d83f8c31e5c7b2011c9bb6a8c976a3cd0b \ --env=DRONE_RPC_SECRET=b63a8848e42f3d96108e04a5fb99f41e \ --env=DRONE_SERVER_HOST=192.168.0.150:7070 \ --env=DRONE_SERVER_PROTO=http \ --env=DRONE_USER_CREATE=username:root,admin:true \ --publish=7070:80 \ --publish=8443:443 \ --restart=always \ --detach=true \ --name=drone \ drone/drone:2 source-file source-file",no-bug,0.7
3391,harness,https://github.com/harness/harness/issues/3391,[Feature request] User Registration control,Can we have a feature to disable user registration and only allow manually registered users?,other-file | other-file | other-file | other-file,[Feature request] User Registration control Can we have a feature to disable user registration and only allow manually registered users? other-file other-file other-file other-file,no-bug,0.9
312,harness,https://github.com/harness/harness/issues/312,Plugin to customize GitHub status behavior,"Right now, Drone just sets [four simple messages](https://github.com/drone/drone/blob/master/pkg/queue/worker.go#L200) for the Github status. I'd love it if this was configurable - for example, we'd like to source things like build time or test coverage through the same mechanism.",source-file | source-file | test-file | source-file | source-file | source-file | source-file,"Plugin to customize GitHub status behavior Right now, Drone just sets [four simple messages](https://github.com/drone/drone/blob/master/pkg/queue/worker.go#L200) for the Github status. I'd love it if this was configurable - for example, we'd like to source things like build time or test coverage through the same mechanism. source-file source-file test-file source-file source-file source-file source-file",no-bug,0.9
2632,harness,https://github.com/harness/harness/issues/2632,error docker:dind,"Id like to do docker-compose up -d Seems like `plugins/docker` is able to do what I want, but it fails if I dont specify the publish-related stuff. I want to use it without publishing. Another alternative could be services, but I try always failed kind: pipeline steps: - name: test image: docker:dind volumes: - /var/run/docker.sock:/var/run/docker.sock commands: - docker ps -a services: docker: image: docker:dind privileged: true volumes: - /var/run/docker.sock:/var/run/docker.sock error: yaml: unmarshal errors: line 8: cannot unmarshal !!str `/var/ru` into yaml.VolumeMount line 13: cannot unmarshal !!map into []*yaml.Container",source-file | source-file | config-file | config-file | source-file | source-file,"error docker:dind Id like to do docker-compose up -d Seems like `plugins/docker` is able to do what I want, but it fails if I dont specify the publish-related stuff. I want to use it without publishing. Another alternative could be services, but I try always failed kind: pipeline steps: - name: test image: docker:dind volumes: - /var/run/docker.sock:/var/run/docker.sock commands: - docker ps -a services: docker: image: docker:dind privileged: true volumes: - /var/run/docker.sock:/var/run/docker.sock error: yaml: unmarshal errors: line 8: cannot unmarshal !!str `/var/ru` into yaml.VolumeMount line 13: cannot unmarshal !!map into []*yaml.Container source-file source-file config-file config-file source-file source-file",no-bug,0.9
70,harness,https://github.com/harness/harness/issues/70,"GitHub caching badge, causing problems",see our README.md as an example,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,"GitHub caching badge, causing problems see our README.md as an example source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file",no-bug,0.8
719,harness,https://github.com/harness/harness/issues/719,UI reports 45 years ago when build in progress,If a build is in progress the placard reads 45 years ago for last build. Should probably say the build is in progress instead.,source-file,UI reports 45 years ago when build in progress If a build is in progress the placard reads 45 years ago for last build. Should probably say the build is in progress instead. source-file,no-bug,0.9
3385,harness,https://github.com/harness/harness/issues/3385,Tag a new gitness release?,"Hey! I'm hoping to package gitness for our Linux distribution Wolfi, and have it almost ready to go. The latest tagged release (2.20.1) predates the gitness switch, and much of the build system has been refactored. Will there be a new tagged release soon? If so - will it pick up on the same version scheme, or will you start with a new one?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file,"Tag a new gitness release? Hey! I'm hoping to package gitness for our Linux distribution Wolfi, and have it almost ready to go. The latest tagged release (2.20.1) predates the gitness switch, and much of the build system has been refactored. Will there be a new tagged release soon? If so - will it pick up on the same version scheme, or will you start with a new one? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file",no-bug,0.95
3401,harness,https://github.com/harness/harness/issues/3401,Pullrequest event (pullreq_closed) missing,I did not find any mention of an event for pullrequest close in the code,test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | other-file | test-file | test-file | test-file | other-file | test-file | source-file | other-file | other-file | test-file,Pullrequest event (pullreq_closed) missing I did not find any mention of an event for pullrequest close in the code test-file test-file test-file test-file test-file test-file test-file test-file other-file test-file test-file test-file other-file test-file source-file other-file other-file test-file,no-bug,0.7
3324,harness,https://github.com/harness/harness/issues/3324,Drone pipeline Build getting Struck building the Image with plugins/ecr,"<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> self-hosted versions: drone:2.11.1 drone-runner-kube:1.0.0-rc.3 moved to linux-amd64 envrinomet: k3s running the Drone and drone-runner-kube, CI been triggering successfully but build is being struck in the step of building the docker image with plugins/ecr stage and I have changed the version of the plugins/ecr even same issue . the build getting struck in the steps of building the docker image for every repo as same issue. and we have fsnotify error I was not able to see the logs and I have checked the logs form the container where drone runner running the builds I see that it is been struck since more than 90mins and trying with restart the builds getting struck at same step. no any error log. if I build the Image locally It was building the Image .",source-file | source-file | source-file,"Drone pipeline Build getting Struck building the Image with plugins/ecr <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> self-hosted versions: drone:2.11.1 drone-runner-kube:1.0.0-rc.3 moved to linux-amd64 envrinomet: k3s running the Drone and drone-runner-kube, CI been triggering successfully but build is being struck in the step of building the docker image with plugins/ecr stage and I have changed the version of the plugins/ecr even same issue . the build getting struck in the steps of building the docker image for every repo as same issue. and we have fsnotify error I was not able to see the logs and I have checked the logs form the container where drone runner running the builds I see that it is been struck since more than 90mins and trying with restart the builds getting struck at same step. no any error log. if I build the Image locally It was building the Image . source-file source-file source-file",no-bug,0.9
3345,harness,https://github.com/harness/harness/issues/3345,Drone CI/CD Pipeline Stuck in Pending State with 'http: no content returned: re-connect and re-try' in Runner Logs,"I have been encountering repeated ""http: no content returned: re-connect and re-try"" errors in the logs of my Drone Runner. My build status in Drone CI/CD is always ""pending"" and does not proceed. I have been unable to identify the cause of this issue. Here are the relevant configurations and logs: My drone.yml configuration:  kind: pipeline type: ssh name: drone clone: disable: true steps: - name: build-and-deploy-ipa environment: SCP_PASSWORD: from_secret: scp_password SSH_PASSWORD: from_secret: ssh_password commands: - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'cd /Projects/project-gitlab/project_app && git fetch origin && git checkout feature/sit-clone && git pull origin feature/sit-clone' - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'cd /Projects/project-gitlab/project_app && rm -f build/ios/ipa/app.ipa && flutter pub get' - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'cd /Projects/project-gitlab/project_app && flutter build ipa --export-options-plist=ios/exportOptions.plist --dart-define=BYPASS_VERSION_CHECK=true' - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'scp -p $SCP_PASSWORD build/ios/ipa/app.ipa root@xxx:/srv/nginx/content/download/ios/sunod' - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'echo ""Deployed ipa @LAB"" trigger: branch: - feature/test  The intention of this pipeline is to have the runner SSH into a Mac and execute several commands, particularly Flutter commands, My docker-compose.yml configuration:  version: '3' services: drone-server: image: drone/drone:latest container_name: drone-server ports: - 80:80 volumes: - /var/lib/drone:/data restart: always environment: - DRONE_LOGS_DEBUG=true - DRONE_GITLAB_SERVER=xxx - DRONE_GITLAB_CLIENT_ID=xxx - DRONE_GITLAB_CLIENT_SECRET=xxx - DRONE_SERVER_HOST=xxx - DRONE_SERVER_PROTO=http - DRONE_RPC_SECRET=xxx - DRONE_USER_CREATE=username:xxx,machine:false,admin:true,token:xxx - DRONE_LOGS_TRACE=true drone-runner: image: drone/drone-runner-docker:latest container_name: drone-runner ports: - 3000:3000 restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_RPC_HOST=drone-server - DRONE_RPC_PROTO=http - DRONE_RPC_SECRET=xxx - DRONE_RUNNER_CAPACITY=2 - DRONE_RUNNER_NAME=drone-runner - DRONE_LOGS_TRACE=true  log messages from my Drone Runner: `time=""2023-08-05T19:30:29Z"" level=trace msg=""http: no content returned: re-connect and re-try"" time=""2023-08-05T19:30:59Z"" level=trace msg=""http: no content returned: re-connect and re-try"" time=""2023-08-05T19:31:09Z"" level=trace msg=""http: no content returned: re-connect and re-try"" `",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Drone CI/CD Pipeline Stuck in Pending State with 'http: no content returned: re-connect and re-try' in Runner Logs I have been encountering repeated ""http: no content returned: re-connect and re-try"" errors in the logs of my Drone Runner. My build status in Drone CI/CD is always ""pending"" and does not proceed. I have been unable to identify the cause of this issue. Here are the relevant configurations and logs: My drone.yml configuration:  kind: pipeline type: ssh name: drone clone: disable: true steps: - name: build-and-deploy-ipa environment: SCP_PASSWORD: from_secret: scp_password SSH_PASSWORD: from_secret: ssh_password commands: - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'cd /Projects/project-gitlab/project_app && git fetch origin && git checkout feature/sit-clone && git pull origin feature/sit-clone' - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'cd /Projects/project-gitlab/project_app && rm -f build/ios/ipa/app.ipa && flutter pub get' - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'cd /Projects/project-gitlab/project_app && flutter build ipa --export-options-plist=ios/exportOptions.plist --dart-define=BYPASS_VERSION_CHECK=true' - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'scp -p $SCP_PASSWORD build/ios/ipa/app.ipa root@xxx:/srv/nginx/content/download/ios/sunod' - sshpass -p $SSH_PASSWORD ssh -p 1022 xxx@xxx 'echo ""Deployed ipa @LAB"" trigger: branch: - feature/test  The intention of this pipeline is to have the runner SSH into a Mac and execute several commands, particularly Flutter commands, My docker-compose.yml configuration:  version: '3' services: drone-server: image: drone/drone:latest container_name: drone-server ports: - 80:80 volumes: - /var/lib/drone:/data restart: always environment: - DRONE_LOGS_DEBUG=true - DRONE_GITLAB_SERVER=xxx - DRONE_GITLAB_CLIENT_ID=xxx - DRONE_GITLAB_CLIENT_SECRET=xxx - DRONE_SERVER_HOST=xxx - DRONE_SERVER_PROTO=http - DRONE_RPC_SECRET=xxx - DRONE_USER_CREATE=username:xxx,machine:false,admin:true,token:xxx - DRONE_LOGS_TRACE=true drone-runner: image: drone/drone-runner-docker:latest container_name: drone-runner ports: - 3000:3000 restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_RPC_HOST=drone-server - DRONE_RPC_PROTO=http - DRONE_RPC_SECRET=xxx - DRONE_RUNNER_CAPACITY=2 - DRONE_RUNNER_NAME=drone-runner - DRONE_LOGS_TRACE=true  log messages from my Drone Runner: `time=""2023-08-05T19:30:29Z"" level=trace msg=""http: no content returned: re-connect and re-try"" time=""2023-08-05T19:30:59Z"" level=trace msg=""http: no content returned: re-connect and re-try"" time=""2023-08-05T19:31:09Z"" level=trace msg=""http: no content returned: re-connect and re-try"" ` source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
761,harness,https://github.com/harness/harness/issues/761,"Bitbucket integration should use the slug to build URLs, not the name of the repo","Hi! Currently the bitbucket integration uses the name of the repo to build up the clone, git and SSH urls. This breaks if the name of the repo includes whitespace or special characters since Bitbucket generates a slug from the name of the repo to build the URLs. Using the slug returned from the Bitbucket API instead would solve this.",source-file,"Bitbucket integration should use the slug to build URLs, not the name of the repo Hi! Currently the bitbucket integration uses the name of the repo to build up the clone, git and SSH urls. This breaks if the name of the repo includes whitespace or special characters since Bitbucket generates a slug from the name of the repo to build the URLs. Using the slug returned from the Bitbucket API instead would solve this. source-file",no-bug,0.8
299,harness,https://github.com/harness/harness/issues/299,Local git cache,"On a very large repository even with the option depth = 50 cloning process takes 10 to 15 minutes. Very necessary to realize the possibility of local cache repository, as is done in Capistrano. For example:  bash if [ -d /home/pc/shared/cached-copy ]; then cd /home/pc/shared/cached-copy && git fetch -q origin && git fetch --tags -q origin && git reset -q --hard b541548f1105aae300345e4973a06fa8a29bdde5 && git clean -q -d -x -f; else git clone -q git@github.com:abak-press/pulscen.git /home/pc/shared/cached-copy && cd /home/pc/shared/cached-copy && git checkout -q -b deploy b541548f1105aae300345e4973a06fa8a29bdde5; fi  With this implementation process will take a few seconds",other-file | source-file,"Local git cache On a very large repository even with the option depth = 50 cloning process takes 10 to 15 minutes. Very necessary to realize the possibility of local cache repository, as is done in Capistrano. For example:  bash if [ -d /home/pc/shared/cached-copy ]; then cd /home/pc/shared/cached-copy && git fetch -q origin && git fetch --tags -q origin && git reset -q --hard b541548f1105aae300345e4973a06fa8a29bdde5 && git clean -q -d -x -f; else git clone -q git@github.com:abak-press/pulscen.git /home/pc/shared/cached-copy && cd /home/pc/shared/cached-copy && git checkout -q -b deploy b541548f1105aae300345e4973a06fa8a29bdde5; fi  With this implementation process will take a few seconds other-file source-file",no-bug,0.95
953,harness,https://github.com/harness/harness/issues/953,Is it possible to use it with github without callback url?,"We have our repos in github.com (privately) and the machine I want to try drone can't receive requests from the internet. Is it possible to configure the permissions manually? I am admin in the github org, so I can do whatever on that end, but I'm not certain how to configure drone. Thanks!",documentation-file | other-file,"Is it possible to use it with github without callback url? We have our repos in github.com (privately) and the machine I want to try drone can't receive requests from the internet. Is it possible to configure the permissions manually? I am admin in the github org, so I can do whatever on that end, but I'm not certain how to configure drone. Thanks! documentation-file other-file",no-bug,0.9
2892,harness,https://github.com/harness/harness/issues/2892,Docs: single machine setup guide and DRONE_AGENTS_DISABLED missing,"Since the docs were updated for Drone 1.x, the instructions for a single machine setup without a runner/agent is missing. I asked in Gitter around 2 months ago, if the setup is still valid and will be supported in the future, what has been confirmed. Today, after I updated my Drone installation and all my Builds were stuck at Pending, I read the [FAQ](https://discourse.drone.io/t/builds-are-stuck-in-pending-status/4437) about this problem and wondered about the statement under **Verify Runner Installation**, which, in my opinion, clearly says **""You need a runner""**. After the irritation I found the solutions to my problem in the changelog (`DRONE_AGENTS_DISABLED=true`, which is not documented too btw.), but nevertheless I would be great to have this in the documentation. I would be happy to make a PR for this, but unfortunately the current docs are not public yet.",other-file | other-file | source-file | documentation-file | source-file,"Docs: single machine setup guide and DRONE_AGENTS_DISABLED missing Since the docs were updated for Drone 1.x, the instructions for a single machine setup without a runner/agent is missing. I asked in Gitter around 2 months ago, if the setup is still valid and will be supported in the future, what has been confirmed. Today, after I updated my Drone installation and all my Builds were stuck at Pending, I read the [FAQ](https://discourse.drone.io/t/builds-are-stuck-in-pending-status/4437) about this problem and wondered about the statement under **Verify Runner Installation**, which, in my opinion, clearly says **""You need a runner""**. After the irritation I found the solutions to my problem in the changelog (`DRONE_AGENTS_DISABLED=true`, which is not documented too btw.), but nevertheless I would be great to have this in the documentation. I would be happy to make a PR for this, but unfortunately the current docs are not public yet. other-file other-file source-file documentation-file source-file",no-bug,0.9
607,harness,https://github.com/harness/harness/issues/607,"Drone reporting pull request branches as ""master""","In builds I'm getting some branches reported as master, which is pretty bad because our build script checks DRONE_BRANCH for master and then deploys. Seems like drone is pulling out the base branch? Surely this would be wrong? https://github.com/drone/drone/blob/c3966b1a59b542e3337b02e05819a918d0fd444e/plugin/remote/github/github.go#L280 Here's some example json from a green PR (https://github.com/AndrewVos/builder-test-green-repo/pull/2)  json { ""repository"": { ""master_branch"": ""master"", ""default_branch"": ""master"", ""full_name"": ""AndrewVos/builder-test-green-repo"", ""name"": ""builder-test-green-repo"", ""id"": 15211076 }, ""pull_request"": { ""base"": { ""repo"": { ""master_branch"": ""master"", ""default_branch"": ""master"", ""full_name"": ""AndrewVos/builder-test-green-repo"", ""name"": ""builder-test-green-repo"", ""id"": 15211076 }, ""sha"": ""576be25d7e3d5320e92472d5734b50b17c1822e0"", ""ref"": ""master"", ""label"": ""AndrewVos:master"" }, ""head"": { ""repo"": { ""full_name"": ""AndrewVos/builder-test-green-repo"", ""name"": ""builder-test-green-repo"", }, ""sha"": ""7f39d6495acae9db022cc20e7f0d940158e0337d"", ""ref"": ""pool-request"", ""label"": ""AndrewVos:pool-request"" }, }, ""number"": 2, ""action"": ""opened"" } ",source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Drone reporting pull request branches as ""master"" In builds I'm getting some branches reported as master, which is pretty bad because our build script checks DRONE_BRANCH for master and then deploys. Seems like drone is pulling out the base branch? Surely this would be wrong? https://github.com/drone/drone/blob/c3966b1a59b542e3337b02e05819a918d0fd444e/plugin/remote/github/github.go#L280 Here's some example json from a green PR (https://github.com/AndrewVos/builder-test-green-repo/pull/2)  json { ""repository"": { ""master_branch"": ""master"", ""default_branch"": ""master"", ""full_name"": ""AndrewVos/builder-test-green-repo"", ""name"": ""builder-test-green-repo"", ""id"": 15211076 }, ""pull_request"": { ""base"": { ""repo"": { ""master_branch"": ""master"", ""default_branch"": ""master"", ""full_name"": ""AndrewVos/builder-test-green-repo"", ""name"": ""builder-test-green-repo"", ""id"": 15211076 }, ""sha"": ""576be25d7e3d5320e92472d5734b50b17c1822e0"", ""ref"": ""master"", ""label"": ""AndrewVos:master"" }, ""head"": { ""repo"": { ""full_name"": ""AndrewVos/builder-test-green-repo"", ""name"": ""builder-test-green-repo"", }, ""sha"": ""7f39d6495acae9db022cc20e7f0d940158e0337d"", ""ref"": ""pool-request"", ""label"": ""AndrewVos:pool-request"" }, }, ""number"": 2, ""action"": ""opened"" }  source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
3326,harness,https://github.com/harness/harness/issues/3326,Does drone support issue events to trigger builds?,"<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> In the github action, we can set up some CI flow when the issue is created But I didn't find a similar event in Drone Are there plans to support this in the future?",other-file | other-file | other-file | other-file | other-file | other-file | source-file,"Does drone support issue events to trigger builds? <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please create a new topic in our Discourse forum. We are migrating all Drone repositories to Discourse for bug tracking. New GitHub issues may be automatically deleted. https://community.harness.io/ https://community.harness.io/c/bugs/17 https://community.harness.io/c/ideas/11 Failing Builds? Please do not use GitHub issues for generic support questions. Instead please use Stack Overflow: http://stackoverflow.com/questions/tagged/drone.io --> In the github action, we can set up some CI flow when the issue is created But I didn't find a similar event in Drone Are there plans to support this in the future? other-file other-file other-file other-file other-file other-file source-file",no-bug,0.9
997,harness,https://github.com/harness/harness/issues/997,Running curl as a drone script command,"Hi part of my .drone-yml deploy: bash: script: - curl -X DELETE http://192.168.1.21:8080/v2/apps/organusfrontend - curl -X POST -H ""Content-Type: application/json"" http://192.168.1.21:8080/v2/apps -d@organus_frontend.json The first curl line gives a response and runs ok The second does not, no response and is not running. I have tried to add escape character \' and \"" with no luck It seem like running a curl command within drone is failing if the command contains the characters ' or "". Any suggestion on how to run curl? Arild",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Running curl as a drone script command Hi part of my .drone-yml deploy: bash: script: - curl -X DELETE http://192.168.1.21:8080/v2/apps/organusfrontend - curl -X POST -H ""Content-Type: application/json"" http://192.168.1.21:8080/v2/apps -d@organus_frontend.json The first curl line gives a response and runs ok The second does not, no response and is not running. I have tried to add escape character \' and \"" with no luck It seem like running a curl command within drone is failing if the command contains the characters ' or "". Any suggestion on how to run curl? Arild source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
1217,harness,https://github.com/harness/harness/issues/1217,Missing webhooks when commit message is big,I had to run this on drone 0.3 `alter table commits alter column commit_message type varchar;` the commit message was limited to 255 characters and it was causing missing webhooks.  2015/09/29 20:19:00 Unable to persist commit bbd96e4c1908177b81b4b3a8e77c3aaf8aea9974@develop. meddler.Insert: DB error in QueryRow: pq: value too long for type character varying(255) ,source-file,Missing webhooks when commit message is big I had to run this on drone 0.3 `alter table commits alter column commit_message type varchar;` the commit message was limited to 255 characters and it was causing missing webhooks.  2015/09/29 20:19:00 Unable to persist commit bbd96e4c1908177b81b4b3a8e77c3aaf8aea9974@develop. meddler.Insert: DB error in QueryRow: pq: value too long for type character varying(255)  source-file,bug,0.85
2101,harness,https://github.com/harness/harness/issues/2101,Got an internal_error after auth Gitlab,"version : latest, 0.7 I follow the official installation guide to build the drone server. Run docker using the following variables > #!/bin/bash > docker run -d \ > --dns {MY_OWN} \ > -e DRONE_GITLAB=true \ > -e DRONE_GITLAB_CLIENT={FROM_GITLAB} \ > -e DRONE_GITLAB_SECRET={FROM_GITLAB} \ > -e DRONE_GITLAB_SKIP_VERIFY=true \ > -e DRONE_GITLAB_URL=https://{PRIVATE_GITLAB}.com \ > -e DRONE_SECRET=0 \ > -e DRONE_OPEN=true \ > -e DRONE_ADMIN={USER_NAME} \ > -v /var/lib/drone:/var/lib/drone \ > -P \ > --restart=always \ > --name=drone_latest \ > drone/drone:latest **And I can login my Gitlab successfully, but after I press the green access button.** ![image](https://user-images.githubusercontent.com/15358211/27939417-0fdf33f4-62f7-11e7-9df2-a64e484fa51f.png) **It show me an interal_error** ![image](https://user-images.githubusercontent.com/15358211/27939474-7931a5d0-62f7-11e7-8c05-de4e6d07c907.png) **Here is my log:**  eddler.Targets: column [user_remote] not found in struct meddler.Targets: column [user_access] not found in struct meddler.Targets: column [user_name] not found in struct meddler.Targets: column [user_gravatar] not found in struct meddler.Targets: column [user_syncing] not found in struct meddler.Targets: column [user_created] not found in struct meddler.Targets: column [user_updated] not found in struct meddler.Targets: column [user_synced] not found in struct meddler.Targets: column [user_access_expires] not found in struct meddler.WriteTargets: column [user_remote] not found in struct meddler.WriteTargets: column [user_access] not found in struct meddler.WriteTargets: column [user_name] not found in struct meddler.WriteTargets: column [user_gravatar] not found in struct meddler.WriteTargets: column [user_syncing] not found in struct meddler.WriteTargets: column [user_created] not found in struct meddler.WriteTargets: column [user_updated] not found in struct meddler.WriteTargets: column [user_synced] not found in struct meddler.WriteTargets: column [user_access_expires] not found in struct time=""2017-07-07T01:24:23Z"" level=error msg=""cannot update bob.li. meddler.Update: DB error in Exec: no such column: user_expiry"" meddler.Targets: column [user_remote] not found in struct meddler.Targets: column [user_access] not found in struct meddler.Targets: column [user_name] not found in struct meddler.Targets: column [user_gravatar] not found in struct meddler.Targets: column [user_syncing] not found in struct meddler.Targets: column [user_created] not found in struct meddler.Targets: column [user_updated] not found in struct meddler.Targets: column [user_synced] not found in struct meddler.Targets: column [user_access_expires] not found in struct meddler.WriteTargets: column [user_remote] not found in struct meddler.WriteTargets: column [user_access] not found in struct meddler.WriteTargets: column [user_name] not found in struct meddler.WriteTargets: column [user_gravatar] not found in struct meddler.WriteTargets: column [user_syncing] not found in struct meddler.WriteTargets: column [user_created] not found in struct meddler.WriteTargets: column [user_updated] not found in struct meddler.WriteTargets: column [user_synced] not found in struct meddler.WriteTargets: column [user_access_expires] not found in struct time=""2017-07-07T01:31:43Z"" level=error msg=""cannot update bob.li. meddler.Update: DB error in Exec: no such column: user_expiry"" ",source-file | source-file | source-file | other-file | other-file,"Got an internal_error after auth Gitlab version : latest, 0.7 I follow the official installation guide to build the drone server. Run docker using the following variables > #!/bin/bash > docker run -d \ > --dns {MY_OWN} \ > -e DRONE_GITLAB=true \ > -e DRONE_GITLAB_CLIENT={FROM_GITLAB} \ > -e DRONE_GITLAB_SECRET={FROM_GITLAB} \ > -e DRONE_GITLAB_SKIP_VERIFY=true \ > -e DRONE_GITLAB_URL=https://{PRIVATE_GITLAB}.com \ > -e DRONE_SECRET=0 \ > -e DRONE_OPEN=true \ > -e DRONE_ADMIN={USER_NAME} \ > -v /var/lib/drone:/var/lib/drone \ > -P \ > --restart=always \ > --name=drone_latest \ > drone/drone:latest **And I can login my Gitlab successfully, but after I press the green access button.** ![image](https://user-images.githubusercontent.com/15358211/27939417-0fdf33f4-62f7-11e7-9df2-a64e484fa51f.png) **It show me an interal_error** ![image](https://user-images.githubusercontent.com/15358211/27939474-7931a5d0-62f7-11e7-8c05-de4e6d07c907.png) **Here is my log:**  eddler.Targets: column [user_remote] not found in struct meddler.Targets: column [user_access] not found in struct meddler.Targets: column [user_name] not found in struct meddler.Targets: column [user_gravatar] not found in struct meddler.Targets: column [user_syncing] not found in struct meddler.Targets: column [user_created] not found in struct meddler.Targets: column [user_updated] not found in struct meddler.Targets: column [user_synced] not found in struct meddler.Targets: column [user_access_expires] not found in struct meddler.WriteTargets: column [user_remote] not found in struct meddler.WriteTargets: column [user_access] not found in struct meddler.WriteTargets: column [user_name] not found in struct meddler.WriteTargets: column [user_gravatar] not found in struct meddler.WriteTargets: column [user_syncing] not found in struct meddler.WriteTargets: column [user_created] not found in struct meddler.WriteTargets: column [user_updated] not found in struct meddler.WriteTargets: column [user_synced] not found in struct meddler.WriteTargets: column [user_access_expires] not found in struct time=""2017-07-07T01:24:23Z"" level=error msg=""cannot update bob.li. meddler.Update: DB error in Exec: no such column: user_expiry"" meddler.Targets: column [user_remote] not found in struct meddler.Targets: column [user_access] not found in struct meddler.Targets: column [user_name] not found in struct meddler.Targets: column [user_gravatar] not found in struct meddler.Targets: column [user_syncing] not found in struct meddler.Targets: column [user_created] not found in struct meddler.Targets: column [user_updated] not found in struct meddler.Targets: column [user_synced] not found in struct meddler.Targets: column [user_access_expires] not found in struct meddler.WriteTargets: column [user_remote] not found in struct meddler.WriteTargets: column [user_access] not found in struct meddler.WriteTargets: column [user_name] not found in struct meddler.WriteTargets: column [user_gravatar] not found in struct meddler.WriteTargets: column [user_syncing] not found in struct meddler.WriteTargets: column [user_created] not found in struct meddler.WriteTargets: column [user_updated] not found in struct meddler.WriteTargets: column [user_synced] not found in struct meddler.WriteTargets: column [user_access_expires] not found in struct time=""2017-07-07T01:31:43Z"" level=error msg=""cannot update bob.li. meddler.Update: DB error in Exec: no such column: user_expiry""  source-file source-file source-file other-file other-file",no-bug,0.8
430,harness,https://github.com/harness/harness/issues/430,Feature-Request: Postgres Driver for Meddler,Any chance support for Postgres DB storage could be configured? I believe the best lib to use is `pq` located [here](https://github.com/lib/pq),other-file | other-file,Feature-Request: Postgres Driver for Meddler Any chance support for Postgres DB storage could be configured? I believe the best lib to use is `pq` located [here](https://github.com/lib/pq) other-file other-file,no-bug,0.95
1068,harness,https://github.com/harness/harness/issues/1068,Failure to create build container with Drone 0.3.0 on Docker 1.7,"Docker 1.7 came out. Something about that broke Drone's ability to publish built images to Docker Hub after a successful build. So, I figured I'll just upgrade to 1.7 on my build machine to see if that fixes the problem with pushing to Docker Hub. But now, builds don't even start. I just get this error:  Error: Failed to create build container. Internal Server Error  which seems to come from this line: https://github.com/drone/drone/blob/90de72aacc9502d1fe454c00f9e7d18124b1705a/shared/build/build.go#L394 Any thoughts?",source-file,"Failure to create build container with Drone 0.3.0 on Docker 1.7 Docker 1.7 came out. Something about that broke Drone's ability to publish built images to Docker Hub after a successful build. So, I figured I'll just upgrade to 1.7 on my build machine to see if that fixes the problem with pushing to Docker Hub. But now, builds don't even start. I just get this error:  Error: Failed to create build container. Internal Server Error  which seems to come from this line: https://github.com/drone/drone/blob/90de72aacc9502d1fe454c00f9e7d18124b1705a/shared/build/build.go#L394 Any thoughts? source-file",no-bug,0.9
3395,harness,https://github.com/harness/harness/issues/3395,Pipelines are not being triggered when gitness is deployed behind reverse proxy,"Hello, i started moving away all my repositories from github and github actions to gitness. I have a VPS running gitness inside a docker container using the following docker compose file: yaml version: '3.3' services: gitness: ports: - '3000:3000' volumes: - '/var/run/docker.sock:/var/run/docker.sock' - './data:/data' container_name: gitness restart: always image: harness/gitness environment: GITNESS_USER_SIGNUP_ENABLED: false GITNESS_NESTED_SPACES_ENABLED: true GITNESS_URL_BASE: https://$DOMAIN GITNESS_URL_GIT: https://$DOMAIN/git GITNESS_URL_API: https://$DOMAIN/api GITNESS_URL_UI: https://$DOMAIN GITNESS_HTTP_PROTO: https GITNESS_CI_PARALLEL_WORKERS: 4  OBS: replaced my actual domain name with $DOMAIN The gitnes is being served behind a caddy reverse proxy:  $DOMAIN { reverse_proxy localhost:3000 }  The pipeline: yaml version: 1 kind: pipeline spec: stages: - name: build type: ci spec: steps: - name: build type: run spec: container: mcr.microsoft.com/dotnet/sdk:8.0 envs: SLEET_FEED_CONNECTIONSTRING: ${{secrets.get(""SLEET_FEED_CONNECTIONSTRING"")}} SLEET_FEED_CONTAINER: ${{secrets.get(""SLEET_FEED_CONTAINER"")}} SLEET_FEED_TYPE: ${{secrets.get(""SLEET_FEED_TYPE"")}} script: |- dotnet nuget add source https://$DOMAIN/sleet/index.json --name sleet dotnet tool install -g sleet export PATH=""$PATH:/root/.dotnet/tools"" export NUGET_VERSION=$(date --utc '+%Y.%m.%d.%H%M' | sed 's/\.\(0*\)/./g') echo $NUGET_VERSION dotnet pack ./src/AutoSystem.Devops/AutoSystem.Devops.csproj -p:PackageVersion=$NUGET_VERSION -o ./nuget sleet push ./nuget --skip-existing  Using the UI, API, cloning projects and running pipelines manually are all working correctly, but when i commit something the pipelines are not being triggered, am i missing a configuration about webhooks or something?",other-file | other-file | other-file | other-file | other-file | other-file,"Pipelines are not being triggered when gitness is deployed behind reverse proxy Hello, i started moving away all my repositories from github and github actions to gitness. I have a VPS running gitness inside a docker container using the following docker compose file: yaml version: '3.3' services: gitness: ports: - '3000:3000' volumes: - '/var/run/docker.sock:/var/run/docker.sock' - './data:/data' container_name: gitness restart: always image: harness/gitness environment: GITNESS_USER_SIGNUP_ENABLED: false GITNESS_NESTED_SPACES_ENABLED: true GITNESS_URL_BASE: https://$DOMAIN GITNESS_URL_GIT: https://$DOMAIN/git GITNESS_URL_API: https://$DOMAIN/api GITNESS_URL_UI: https://$DOMAIN GITNESS_HTTP_PROTO: https GITNESS_CI_PARALLEL_WORKERS: 4  OBS: replaced my actual domain name with $DOMAIN The gitnes is being served behind a caddy reverse proxy:  $DOMAIN { reverse_proxy localhost:3000 }  The pipeline: yaml version: 1 kind: pipeline spec: stages: - name: build type: ci spec: steps: - name: build type: run spec: container: mcr.microsoft.com/dotnet/sdk:8.0 envs: SLEET_FEED_CONNECTIONSTRING: ${{secrets.get(""SLEET_FEED_CONNECTIONSTRING"")}} SLEET_FEED_CONTAINER: ${{secrets.get(""SLEET_FEED_CONTAINER"")}} SLEET_FEED_TYPE: ${{secrets.get(""SLEET_FEED_TYPE"")}} script: |- dotnet nuget add source https://$DOMAIN/sleet/index.json --name sleet dotnet tool install -g sleet export PATH=""$PATH:/root/.dotnet/tools"" export NUGET_VERSION=$(date --utc '+%Y.%m.%d.%H%M' | sed 's/\.\(0*\)/./g') echo $NUGET_VERSION dotnet pack ./src/AutoSystem.Devops/AutoSystem.Devops.csproj -p:PackageVersion=$NUGET_VERSION -o ./nuget sleet push ./nuget --skip-existing  Using the UI, API, cloning projects and running pipelines manually are all working correctly, but when i commit something the pipelines are not being triggered, am i missing a configuration about webhooks or something? other-file other-file other-file other-file other-file other-file",no-bug,0.9
2124,harness,https://github.com/harness/harness/issues/2124,Plugin with no yaml parameters interpreted as a service,There is currently an issue where a plugin with no parameters is interpreted as a service. This will result in the plugin exiting early with an exit code of 0 Example configuration:  pipeline: something: image: plugins/foo  Example workaround by adding at least one configuration parameter: diff pipeline: something: image: plugins/foo + dummy: true  The fix for this is to only interpret steps as services if they exist in the services section OR if they have the `detach: true` attribute set.,source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | documentation-file,Plugin with no yaml parameters interpreted as a service There is currently an issue where a plugin with no parameters is interpreted as a service. This will result in the plugin exiting early with an exit code of 0 Example configuration:  pipeline: something: image: plugins/foo  Example workaround by adding at least one configuration parameter: diff pipeline: something: image: plugins/foo + dummy: true  The fix for this is to only interpret steps as services if they exist in the services section OR if they have the `detach: true` attribute set. source-file source-file source-file documentation-file source-file source-file source-file documentation-file,no-bug,0.8
3280,harness,https://github.com/harness/harness/issues/3280,zlib vulnerability,Drone image has zlib vulnerability. Is there any plan to fix this in future? ![image](https://user-images.githubusercontent.com/18351717/198373266-42c38cee-1dba-4a7b-9d81-6551f4905781.png),source-file,zlib vulnerability Drone image has zlib vulnerability. Is there any plan to fix this in future? ![image](https://user-images.githubusercontent.com/18351717/198373266-42c38cee-1dba-4a7b-9d81-6551f4905781.png) source-file,no-bug,0.95
1009,harness,https://github.com/harness/harness/issues/1009,Deprecate official drone images,"Currently, the official Drone service and language images are built from: https://github.com/drone/images Then published under @bradrydzewski's personal Docker account: https://hub.docker.com/u/bradrydzewski/ https://github.com/drone/drone/blob/f7eeeff64f887111f73db75ce6f584de1112c367/shared/build/images.go#L25 We'd like the ability to customise where the official Drone images are pulled from because we'd like to have control over the images we use for our CI builds and plan to fork the drone/images repo. I'm aware that there are [plans](https://github.com/drone/drone/issues/483#issuecomment-56770495) to do away with the official images and also to support [custom image repositories](https://github.com/drone/drone/pull/615). Would you be willing to accept a pull request that allowed the Docker organisation that these images are pulled from to be set using an configuration setting?",other-file | other-file | other-file | source-file | other-file | test-file | test-file | test-file | source-file | documentation-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | other-file | source-file | other-file,"Deprecate official drone images Currently, the official Drone service and language images are built from: https://github.com/drone/images Then published under @bradrydzewski's personal Docker account: https://hub.docker.com/u/bradrydzewski/ https://github.com/drone/drone/blob/f7eeeff64f887111f73db75ce6f584de1112c367/shared/build/images.go#L25 We'd like the ability to customise where the official Drone images are pulled from because we'd like to have control over the images we use for our CI builds and plan to fork the drone/images repo. I'm aware that there are [plans](https://github.com/drone/drone/issues/483#issuecomment-56770495) to do away with the official images and also to support [custom image repositories](https://github.com/drone/drone/pull/615). Would you be willing to accept a pull request that allowed the Docker organisation that these images are pulled from to be set using an configuration setting? other-file other-file other-file source-file other-file test-file test-file test-file source-file documentation-file other-file other-file other-file source-file other-file other-file other-file documentation-file other-file source-file other-file",no-bug,0.9
477,harness,https://github.com/harness/harness/issues/477,Gravatars no longer showing up,"So I'm working on the drone wall project, and consuming the ""gravatar"" field to get people's faces to show up. A few days, ago, most gravatar fields started coming back blank. Some research yielded the following: https://developer.github.com/changes/2014-09-05-removing-gravatar-id/ Would it be possible for drone to surface this avatar_url field rather than (or in addition to) the now-empty gravatar one?",other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file,"Gravatars no longer showing up So I'm working on the drone wall project, and consuming the ""gravatar"" field to get people's faces to show up. A few days, ago, most gravatar fields started coming back blank. Some research yielded the following: https://developer.github.com/changes/2014-09-05-removing-gravatar-id/ Would it be possible for drone to surface this avatar_url field rather than (or in addition to) the now-empty gravatar one? other-file other-file source-file other-file other-file other-file other-file other-file documentation-file source-file",bug,0.85
3360,harness,https://github.com/harness/harness/issues/3360,drone trigger paths,The directory update trigger does not take effect. There is no directory trigger code in the source code. Could you please fix it? Thank you.  kind: pipeline type: docker name: my-pipeline steps: - name: checkout image: alpine/git commands: - ls /tmp trigger: paths: - hexiaoshi/ ,source-file,drone trigger paths The directory update trigger does not take effect. There is no directory trigger code in the source code. Could you please fix it? Thank you.  kind: pipeline type: docker name: my-pipeline steps: - name: checkout image: alpine/git commands: - ls /tmp trigger: paths: - hexiaoshi/  source-file,no-bug,0.7
2574,harness,https://github.com/harness/harness/issues/2574,Benchmark Results?,"I couldn't find the benchmark results of the this project. I'm just wondering; How many users can `drone` (API) server handle, approximately? (1k, 10k, ?) (Of course; It depends by bandwidth and CPU) Assuming that the servers can handle the high-load, Can the `drone` server respond to 100K thousand users instantly without any instability?",source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file,"Benchmark Results? I couldn't find the benchmark results of the this project. I'm just wondering; How many users can `drone` (API) server handle, approximately? (1k, 10k, ?) (Of course; It depends by bandwidth and CPU) Assuming that the servers can handle the high-load, Can the `drone` server respond to 100K thousand users instantly without any instability? source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file",no-bug,0.95
366,harness,https://github.com/harness/harness/issues/366,Dropbox as a Remote,Dropbox is just like git. It would be cool if there was support for building on dropbox file changes.,source-file | test-file,Dropbox as a Remote Dropbox is just like git. It would be cool if there was support for building on dropbox file changes. source-file test-file,no-bug,0.9
806,harness,https://github.com/harness/harness/issues/806,What's the use case for the CLI versus the web UI (as admin)?,"Not an issue but more of a question; what's the purpose of the commandline tool as opposed to using the web UI as an admin? I'd like to better understand the distinction between the two - it seems that some actions (e.g. disable a repo) would be desirable in the UI, but I feel I'm missing some context.",source-file | source-file | source-file | source-file | source-file,"What's the use case for the CLI versus the web UI (as admin)? Not an issue but more of a question; what's the purpose of the commandline tool as opposed to using the web UI as an admin? I'd like to better understand the distinction between the two - it seems that some actions (e.g. disable a repo) would be desirable in the UI, but I feel I'm missing some context. source-file source-file source-file source-file source-file",no-bug,0.95
3376,harness,https://github.com/harness/harness/issues/3376,Gitness on Docker Support/Docs,Trying to use the Docker version of GitNess - I have it up and running but!! 1. Would be great to have an ARM version of this to run on RPi 4 2. Running up on Intel not sure what port 3001 is for! I assumed SSL but this does not seem to offer SSL connection 3. On creating new REPO for testing the Clone URL shows Localhost:3000 instead of the external address I used via Traefik I am coming from using Gitea and thought I would give this a try but 3 above is a significant issue which I presume is a matter of an environment variable not set - but I could find not documentation relating to that hence the issue.,test-file,Gitness on Docker Support/Docs Trying to use the Docker version of GitNess - I have it up and running but!! 1. Would be great to have an ARM version of this to run on RPi 4 2. Running up on Intel not sure what port 3001 is for! I assumed SSL but this does not seem to offer SSL connection 3. On creating new REPO for testing the Clone URL shows Localhost:3000 instead of the external address I used via Traefik I am coming from using Gitea and thought I would give this a try but 3 above is a significant issue which I presume is a matter of an environment variable not set - but I could find not documentation relating to that hence the issue. test-file,no-bug,0.8
2865,harness,https://github.com/harness/harness/issues/2865,drone-runner-docker amd64 vs arm64,"Hey, The `DRONE_PLATFORM_ARCH` variable is not correct in the docker hub! amd64 for linux-arm64 and arm64 for linux-amd64. Good luck,",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"drone-runner-docker amd64 vs arm64 Hey, The `DRONE_PLATFORM_ARCH` variable is not correct in the docker hub! amd64 for linux-arm64 and arm64 for linux-amd64. Good luck, source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.7
2135,harness,https://github.com/harness/harness/issues/2135,The new UI in version 0.8 does not integrate with browser password manager in login form in Chromium,"In version 0.8 the new login form does not integrate with browser password manager. It not autocomplete user and password and, in a clean browser, does not ask for save login data. Tested with Chromium Versin 59.0.3071.115. With Firefox seems work well.",other-file,"The new UI in version 0.8 does not integrate with browser password manager in login form in Chromium In version 0.8 the new login form does not integrate with browser password manager. It not autocomplete user and password and, in a clean browser, does not ask for save login data. Tested with Chromium Versin 59.0.3071.115. With Firefox seems work well. other-file",no-bug,0.9
383,harness,https://github.com/harness/harness/issues/383,Branch based deploys,"It would be nice to be able to have different deploy options based on git branch. I would imagine the drone.yml would look something like this:  deploy: staging: heroku: app: safe-island-6261-staging master: heroku: app: safe-island-6261-staging  We generally don't deploy our development branch (used for local testing only), but deploy both our staging and master branches.",other-file | other-file | documentation-file | other-file | other-file,"Branch based deploys It would be nice to be able to have different deploy options based on git branch. I would imagine the drone.yml would look something like this:  deploy: staging: heroku: app: safe-island-6261-staging master: heroku: app: safe-island-6261-staging  We generally don't deploy our development branch (used for local testing only), but deploy both our staging and master branches. other-file other-file documentation-file other-file other-file",no-bug,0.95
110,harness,https://github.com/harness/harness/issues/110,TLS on SMTP is not enabled,"When entering the TLS port `465` for SMTP, TLS is not started and mail does not get delivered.",source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | source-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | documentation-file | source-file,"TLS on SMTP is not enabled When entering the TLS port `465` for SMTP, TLS is not started and mail does not get delivered. source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file source-file source-file documentation-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file documentation-file source-file",no-bug,0.9
325,harness,https://github.com/harness/harness/issues/325,"drone.sqlite too big, add purge routine",Our `drone.sqlite` file is now over 500MB. What is the process for deleting old builds?,other-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"drone.sqlite too big, add purge routine Our `drone.sqlite` file is now over 500MB. What is the process for deleting old builds? other-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
717,harness,https://github.com/harness/harness/issues/717,Broaden glob support for artifact specification,"I'm using Drone.io (Free) for a Go program that's being built for multiple platforms and want all resulting executables saved as build artifacts. Generated artifacts are laid out as follows:  $ tree . |-- darwin-386 | `-- foo |-- darwin-amd64 | `-- foo |-- linux-386 | `-- foo |-- linux-amd64 | `-- foo |-- windows-386 | `-- foo.exe `-- windows-amd64 `-- foo.exe 6 directories, 6 files  A concise glob to catch them all in a single line would be `{linux,darwin,windows}-{amd64,386}/foo*`. Doing an `ls` with this pattern returns all files as expected. Shells used to verify: - `GNU bash, version 4.3.30(1)-release (x86_64-apple-darwin13.4.0)` - `zsh 5.0.6 (x86_64-apple-darwin13.3.0)` When using this pattern as input in Drone's settings, my files are not being picked up. I cross-checked and added the files one-by-one which worked out seamlessly. So I request support for full Bash style globs, not only `*` (at least that's the only operator mentioned in [the docs](http://docs.drone.io/artifacts.html)). I'd be happy to assist in adding this but had difficulties finding the implementation for artifact ""lookup"". Please give me pointers.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Broaden glob support for artifact specification I'm using Drone.io (Free) for a Go program that's being built for multiple platforms and want all resulting executables saved as build artifacts. Generated artifacts are laid out as follows:  $ tree . |-- darwin-386 | `-- foo |-- darwin-amd64 | `-- foo |-- linux-386 | `-- foo |-- linux-amd64 | `-- foo |-- windows-386 | `-- foo.exe `-- windows-amd64 `-- foo.exe 6 directories, 6 files  A concise glob to catch them all in a single line would be `{linux,darwin,windows}-{amd64,386}/foo*`. Doing an `ls` with this pattern returns all files as expected. Shells used to verify: - `GNU bash, version 4.3.30(1)-release (x86_64-apple-darwin13.4.0)` - `zsh 5.0.6 (x86_64-apple-darwin13.3.0)` When using this pattern as input in Drone's settings, my files are not being picked up. I cross-checked and added the files one-by-one which worked out seamlessly. So I request support for full Bash style globs, not only `*` (at least that's the only operator mentioned in [the docs](http://docs.drone.io/artifacts.html)). I'd be happy to assist in adding this but had difficulties finding the implementation for artifact ""lookup"". Please give me pointers. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2989,harness,https://github.com/harness/harness/issues/2989,Can't login to Gogs,"I have the following composefile  version: '3' services: # https://developpaper.com/build-your-own-ci-cd-system-with-drone-and-gogs/ drone-server: container_name: 'drone-server' image: drone/drone:latest ports: - ""8080:80"" - 8843:443 - 9000 volumes: - ./drone:/var/lib/drone/ - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_OPEN=true - DRONE_SERVER_HOST=drone-server - DRONE_DEBUG=true - DRONE_GIT_ALWAYS_AUTH=false - DRONE_GOGS=true - DRONE_GOGS_SKIP_VERIFY=false - DRONE_GOGS_SERVER=http://gogs:3000 - DRONE_PROVIDER=gogs - DRONE_DATABASE_DATASOURCE=/var/lib/drone/drone.sqlite - DRONE_DATABASE_DRIVER=sqlite3 - DRONE_SERVER_PROTO=http - DRONE_RPC_SECRET=ALQU2M0KdptXUdTPKcEwHww - DRONE_SECRET=ALQU2M0KdptXUdTPKcEwHww gogs: container_name: 'gogs' image: hypriot/rpi-gogs-raspbian:latest ports: - ""10022:22"" - ""3000:3000"" volumes: - ./data/gogs:/data depends_on: - mysql mysql: container_name: 'mysql' image: ""hypriot/rpi-mysql"" volumes: - ./gogs/mysql:/var/lib/mysql ports: - 3308:3306 command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci environment: MYSQL_ROOT_PASSWORD: pass MYSQL_DATABASE: gogs MYSQL_USER: gogs MYSQL_PASSWORD: pass TZ: Europe/London drone-agent: container_name: 'drone-agent' image: drone/agent:latest volumes: - /var/run/docker.sock:/var/run/docker.sock depends_on: - drone-server environment: - DRONE_RPC_SERVER=http://drone-server - DRONE_RPC_SECRET=ALQU2M0KdptXUdTPKcEwHww - DRONE_DEBUG=true - DRONE_SERVER=drone-server:9000 - DRONE_SECRET=ALQU2M0KdptXUdTPKcEwHww - DRONE_MAX_PROCS=5  When trying to login to drone, Gogs will return `gogs | [Macaron] Completed /api/v1/user 404 Not Found in 7.359052ms `. From a little reading this seems to be an issue with authentication. What else can I do to debug?",source-file | source-file,"Can't login to Gogs I have the following composefile  version: '3' services: # https://developpaper.com/build-your-own-ci-cd-system-with-drone-and-gogs/ drone-server: container_name: 'drone-server' image: drone/drone:latest ports: - ""8080:80"" - 8843:443 - 9000 volumes: - ./drone:/var/lib/drone/ - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_OPEN=true - DRONE_SERVER_HOST=drone-server - DRONE_DEBUG=true - DRONE_GIT_ALWAYS_AUTH=false - DRONE_GOGS=true - DRONE_GOGS_SKIP_VERIFY=false - DRONE_GOGS_SERVER=http://gogs:3000 - DRONE_PROVIDER=gogs - DRONE_DATABASE_DATASOURCE=/var/lib/drone/drone.sqlite - DRONE_DATABASE_DRIVER=sqlite3 - DRONE_SERVER_PROTO=http - DRONE_RPC_SECRET=ALQU2M0KdptXUdTPKcEwHww - DRONE_SECRET=ALQU2M0KdptXUdTPKcEwHww gogs: container_name: 'gogs' image: hypriot/rpi-gogs-raspbian:latest ports: - ""10022:22"" - ""3000:3000"" volumes: - ./data/gogs:/data depends_on: - mysql mysql: container_name: 'mysql' image: ""hypriot/rpi-mysql"" volumes: - ./gogs/mysql:/var/lib/mysql ports: - 3308:3306 command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci environment: MYSQL_ROOT_PASSWORD: pass MYSQL_DATABASE: gogs MYSQL_USER: gogs MYSQL_PASSWORD: pass TZ: Europe/London drone-agent: container_name: 'drone-agent' image: drone/agent:latest volumes: - /var/run/docker.sock:/var/run/docker.sock depends_on: - drone-server environment: - DRONE_RPC_SERVER=http://drone-server - DRONE_RPC_SECRET=ALQU2M0KdptXUdTPKcEwHww - DRONE_DEBUG=true - DRONE_SERVER=drone-server:9000 - DRONE_SECRET=ALQU2M0KdptXUdTPKcEwHww - DRONE_MAX_PROCS=5  When trying to login to drone, Gogs will return `gogs | [Macaron] Completed /api/v1/user 404 Not Found in 7.359052ms `. From a little reading this seems to be an issue with authentication. What else can I do to debug? source-file source-file",no-bug,0.9
42,harness,https://github.com/harness/harness/issues/42,PPA repository for install via APT,"Hello, looks great! If you've already set up your .deb building from deb-src, could you please put it up in a PPA? It would make installation much simpler, particularly for those of us who have our CI server configuration in puppet or chef scripts. Cheers! Michael",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | test-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | documentation-file | other-file | other-file | source-file,"PPA repository for install via APT Hello, looks great! If you've already set up your .deb building from deb-src, could you please put it up in a PPA? It would make installation much simpler, particularly for those of us who have our CI server configuration in puppet or chef scripts. Cheers! Michael source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file test-file other-file other-file other-file source-file other-file other-file source-file documentation-file other-file other-file other-file other-file source-file other-file other-file other-file other-file documentation-file other-file other-file source-file",no-bug,0.95
2591,harness,https://github.com/harness/harness/issues/2591,Docker hub publish Drone 0.8.10 release,I am seeing Drone had a tagged feature set for `0.8.10` but Docker hub does not have a published image. I was wondering if that release was going to be published to Docker Hub. Drone Docker Hub: https://hub.docker.com/r/drone/drone/tags?page=1 Drone Release Page: https://github.com/drone/drone/releases/tag/v0.8.10  docker pull drone/drone:0.8.10 Error response from daemon: manifest for drone/drone:0.8.10 not found 8c8590ada100:drone-agent z001nr1$ docker pull drone/drone:0.8.9 0.8.9: Pulling from drone/drone 297640bfa2ef: Pull complete 6d34061bcde3: Pull complete Digest: sha256:6056575462036f2579d17885532e5152e5478cf1c495ef183d2381a7e0cd8668 Status: Downloaded newer image for drone/drone:0.8.9 ,source-file | source-file | source-file | source-file,Docker hub publish Drone 0.8.10 release I am seeing Drone had a tagged feature set for `0.8.10` but Docker hub does not have a published image. I was wondering if that release was going to be published to Docker Hub. Drone Docker Hub: https://hub.docker.com/r/drone/drone/tags?page=1 Drone Release Page: https://github.com/drone/drone/releases/tag/v0.8.10  docker pull drone/drone:0.8.10 Error response from daemon: manifest for drone/drone:0.8.10 not found 8c8590ada100:drone-agent z001nr1$ docker pull drone/drone:0.8.9 0.8.9: Pulling from drone/drone 297640bfa2ef: Pull complete 6d34061bcde3: Pull complete Digest: sha256:6056575462036f2579d17885532e5152e5478cf1c495ef183d2381a7e0cd8668 Status: Downloaded newer image for drone/drone:0.8.9  source-file source-file source-file source-file,no-bug,0.9
2441,harness,https://github.com/harness/harness/issues/2441,RFC: repo status per build step," Summary This is a proposal to add the ability for every step in a Drone pipeline to be able to create a repo status. Currently only 1 ""global"" status is created for the entire pipeline (e.g. all steps together). I feel this could be extremely valuable combined with new ability to allow for a single step not to fail the pipeline (#2071).  Goals Here are some goals I envision. There are details in each goal that could be tweaked, for example naming of things. * each status would update immediately after a step finishes (not waiting for an entire `group` to finish for example) * each status would link directly to the logs of that step inside the build * would be ""opt-in"", meaning a step would not create a status by default but can be configured to do so from `.drone.yml` * allow to customize `context` for a step, defaults to `continuous-integration/drone/<step-name>`  Example Pipeline  pipeline: # Does not create a status restore-cache: image: plugins/drone-s3-cache # Creates a status with default context lint: image: node group: test status: true commands: - lint command # Creates a status with default context test: image: node group: test status: true commands: - test command # Does not create a status rebuild-cache: image: plugins/drone-s3-cache # Create a status with custom context build: image: plugins/docker status: continuous-delivery/docker # Create a status with custom context deploy-test: group: deploy status: continuous-delivery/k8s/test # Create a status with custom context deploy-master: group: deploy status: continuous-delivery/k8s/master ",source-file,"RFC: repo status per build step  Summary This is a proposal to add the ability for every step in a Drone pipeline to be able to create a repo status. Currently only 1 ""global"" status is created for the entire pipeline (e.g. all steps together). I feel this could be extremely valuable combined with new ability to allow for a single step not to fail the pipeline (#2071).  Goals Here are some goals I envision. There are details in each goal that could be tweaked, for example naming of things. * each status would update immediately after a step finishes (not waiting for an entire `group` to finish for example) * each status would link directly to the logs of that step inside the build * would be ""opt-in"", meaning a step would not create a status by default but can be configured to do so from `.drone.yml` * allow to customize `context` for a step, defaults to `continuous-integration/drone/<step-name>`  Example Pipeline  pipeline: # Does not create a status restore-cache: image: plugins/drone-s3-cache # Creates a status with default context lint: image: node group: test status: true commands: - lint command # Creates a status with default context test: image: node group: test status: true commands: - test command # Does not create a status rebuild-cache: image: plugins/drone-s3-cache # Create a status with custom context build: image: plugins/docker status: continuous-delivery/docker # Create a status with custom context deploy-test: group: deploy status: continuous-delivery/k8s/test # Create a status with custom context deploy-master: group: deploy status: continuous-delivery/k8s/master  source-file",no-bug,0.9
2656,harness,https://github.com/harness/harness/issues/2656,Timeout not honored sometimes,"We have configured a timeout of 1 hour for jobs: ![Bildschirmfoto 2019-04-10 um 13 54 05](https://user-images.githubusercontent.com/245432/55876646-62aa5f00-5b98-11e9-87fd-5fed2f14b700.png) Sometimes it happens that one step is running longer than the specified timeout and thus causing a never finishing job (especially bad with the autoscaler we are currently testing, because then pending-jobs are counted in as still running processes that never get into the worker scale downs): ![Bildschirmfoto 2019-04-10 um 13 53 46](https://user-images.githubusercontent.com/245432/55876793-c5035f80-5b98-11e9-9382-4141cfd011ed.png) ![Bildschirmfoto 2019-04-10 um 13 53 40](https://user-images.githubusercontent.com/245432/55876792-c5035f80-5b98-11e9-829e-172ab66f7b28.png) Any further idea what this could have caused and what data is needed here? Currently I clean them up by a hacky SQL update, but this should not really be needed to accomplish this and also requires that you know the maximum timeout of all the repos: sql UPDATE stages SET stage_status = 'killed' WHERE stage_status IN ('pending', 'running') AND UNIX_TIMESTAMP() - stage_updated > 3600;  I also checked all workers and there are no dangling containers or something suspicious.",source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file,"Timeout not honored sometimes We have configured a timeout of 1 hour for jobs: ![Bildschirmfoto 2019-04-10 um 13 54 05](https://user-images.githubusercontent.com/245432/55876646-62aa5f00-5b98-11e9-87fd-5fed2f14b700.png) Sometimes it happens that one step is running longer than the specified timeout and thus causing a never finishing job (especially bad with the autoscaler we are currently testing, because then pending-jobs are counted in as still running processes that never get into the worker scale downs): ![Bildschirmfoto 2019-04-10 um 13 53 46](https://user-images.githubusercontent.com/245432/55876793-c5035f80-5b98-11e9-9382-4141cfd011ed.png) ![Bildschirmfoto 2019-04-10 um 13 53 40](https://user-images.githubusercontent.com/245432/55876792-c5035f80-5b98-11e9-829e-172ab66f7b28.png) Any further idea what this could have caused and what data is needed here? Currently I clean them up by a hacky SQL update, but this should not really be needed to accomplish this and also requires that you know the maximum timeout of all the repos: sql UPDATE stages SET stage_status = 'killed' WHERE stage_status IN ('pending', 'running') AND UNIX_TIMESTAMP() - stage_updated > 3600;  I also checked all workers and there are no dangling containers or something suspicious. source-file source-file source-file source-file source-file test-file source-file test-file",no-bug,0.9
399,harness,https://github.com/harness/harness/issues/399,docker code update,docker changed its code repo and util.ParseRepoTag like function are now in parser https://github.com/docker/docker/commit/4398108433121ce2ac9942e607da20fa1680871a so should we update drone code according to this?,other-file | source-file | source-file | source-file | source-file | source-file | other-file | documentation-file,docker code update docker changed its code repo and util.ParseRepoTag like function are now in parser https://github.com/docker/docker/commit/4398108433121ce2ac9942e607da20fa1680871a so should we update drone code according to this? other-file source-file source-file source-file source-file source-file other-file documentation-file,no-bug,0.9
2117,harness,https://github.com/harness/harness/issues/2117,Documentation: How to know which agent runs which build,"Hi, We use Drone on multiple machines with different hardware capabilities. I'd like to know which builds runs on which agent, for debugging purpose. Unfortunately I couldn't find anything in the docs, in GitHub issues or on [stackoverflow/drone.io](stackoverflow.com/questions/tagged/drone.io). 1. Is there a way to print the agent's name? There does not seem to be an env variable for that. Otherwise is there a way to define custom per-agent variables, like asked in drone/drone#1808? If not, is there a way to get this information by ssh-ing on the Drone server (or agents) after builds are complete and containers deleted? 2. I'd like to improve Drone documentation by answering this question, because I think it's a legitimate one :)",source-file,"Documentation: How to know which agent runs which build Hi, We use Drone on multiple machines with different hardware capabilities. I'd like to know which builds runs on which agent, for debugging purpose. Unfortunately I couldn't find anything in the docs, in GitHub issues or on [stackoverflow/drone.io](stackoverflow.com/questions/tagged/drone.io). 1. Is there a way to print the agent's name? There does not seem to be an env variable for that. Otherwise is there a way to define custom per-agent variables, like asked in drone/drone#1808? If not, is there a way to get this information by ssh-ing on the Drone server (or agents) after builds are complete and containers deleted? 2. I'd like to improve Drone documentation by answering this question, because I think it's a legitimate one :) source-file",no-bug,0.95
270,harness,https://github.com/harness/harness/issues/270,"What is the correct image prefix and when did it change from ""app/"" to ""dokku/"" or vice versa?","Running into issues like these:  Unable to find image 'dokku/thereponame' locally Pulling repository dokku/thereponame 2014/04/15 07:30:37 HTTP code: 404  All my images were created by dokku 0.2.1 as ""app/thereponame"" until a recent dokku upgrade to the master branch, after which they are being created as ""dokku/thereponame"". Plugins seems to be either looking for ""dokku/thereponame"" or ""app/thereponame"" depending on how long it was since they were updated.",source-file | source-file | source-file | source-file,"What is the correct image prefix and when did it change from ""app/"" to ""dokku/"" or vice versa? Running into issues like these:  Unable to find image 'dokku/thereponame' locally Pulling repository dokku/thereponame 2014/04/15 07:30:37 HTTP code: 404  All my images were created by dokku 0.2.1 as ""app/thereponame"" until a recent dokku upgrade to the master branch, after which they are being created as ""dokku/thereponame"". Plugins seems to be either looking for ""dokku/thereponame"" or ""app/thereponame"" depending on how long it was since they were updated. source-file source-file source-file source-file",no-bug,0.9
958,harness,https://github.com/harness/harness/issues/958,Database: Unit Testing,we should have very high test coverage for our data storage tier: https://github.com/drone/drone/tree/bolt/datastore/bolt these are some reference tests: https://github.com/drone/drone/blob/bolt/datastore/bolt/user_test.go let's add tests for all functions,source-file | test-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file,Database: Unit Testing we should have very high test coverage for our data storage tier: https://github.com/drone/drone/tree/bolt/datastore/bolt these are some reference tests: https://github.com/drone/drone/blob/bolt/datastore/bolt/user_test.go let's add tests for all functions source-file test-file source-file source-file database-file database-file database-file database-file source-file source-file,no-bug,0.9
2495,harness,https://github.com/harness/harness/issues/2495,agent should verify docker connectivity before accepting builds,before an agent starts accepting builds we should 1. ping the docker daemon (with a backoff) to ensure connectivity and 2. ping the agent server (with a backoff) and exit with an error if N ping attempts fail,documentation-file,agent should verify docker connectivity before accepting builds before an agent starts accepting builds we should 1. ping the docker daemon (with a backoff) to ensure connectivity and 2. ping the agent server (with a backoff) and exit with an error if N ping attempts fail documentation-file,no-bug,0.9
1193,harness,https://github.com/harness/harness/issues/1193,Plugin upgrades leave untagged layers,"When a plugin automatically upgrades, docker untags the older image layers, leaving them labeled as `<none>`. This is an example of what we see when running `docker images`:  REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE <none> <none> a3599da68365 8 hours ago 15.6 MB <none> <none> 80e7709b7395 8 hours ago 15.64 MB <none> <none> 9e0802a7fe0b 25 hours ago 15.6 MB <none> <none> e2c70e7e5329 29 hours ago 15.59 MB <none> <none> 0bc862fde87b 30 hours ago 15.59 MB  The can be removed with the following command:  sudo docker rmi $(sudo docker images -f ""dangling=true"" -q)  We should implement or document a strategy for dealing with these dangling images. We may implement something directly in drone. We may recommend a cron job. We may recommend running `docker-gc` [1] as a cron job. [1] https://github.com/spotify/docker-gc",,"Plugin upgrades leave untagged layers When a plugin automatically upgrades, docker untags the older image layers, leaving them labeled as `<none>`. This is an example of what we see when running `docker images`:  REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE <none> <none> a3599da68365 8 hours ago 15.6 MB <none> <none> 80e7709b7395 8 hours ago 15.64 MB <none> <none> 9e0802a7fe0b 25 hours ago 15.6 MB <none> <none> e2c70e7e5329 29 hours ago 15.59 MB <none> <none> 0bc862fde87b 30 hours ago 15.59 MB  The can be removed with the following command:  sudo docker rmi $(sudo docker images -f ""dangling=true"" -q)  We should implement or document a strategy for dealing with these dangling images. We may implement something directly in drone. We may recommend a cron job. We may recommend running `docker-gc` [1] as a cron job. [1] https://github.com/spotify/docker-gc",no-bug,0.95
306,harness,https://github.com/harness/harness/issues/306,Archive build artifacts in Drone,"The existing artefact support is great for downloads, but it would be awesome if you could specify one or more directory to host as HTML after the build. As it is, you'd have to push these assets elsewhere during the build, which complicates things and is less ideal for proprietary codebases.",source-file,"Archive build artifacts in Drone The existing artefact support is great for downloads, but it would be awesome if you could specify one or more directory to host as HTML after the build. As it is, you'd have to push these assets elsewhere during the build, which complicates things and is less ideal for proprietary codebases. source-file",no-bug,0.9
1060,harness,https://github.com/harness/harness/issues/1060,Use DSN strings for configuration,"> **TL;DR** configuration needs more flexibility to support plugins without being overly abstracted. The existing 0.4 implementation is overly abstracted, inflexible, and is increasingly difficult to map to environment variables. With the 0.4 release we are introducing a plugin model that allows certain pieces of Drone to be completely replaced, for example, the database layer, the queue layer, etc. This requires an added level of flexibility in terms of configuration that is difficult to achieve with the current `drone.toml` **Issue: Static Typing** This is due primarily to the nature of Go and static typing. We decode the toml into a structure that has a pre-defined hierarchy and set of fields. It is highly likely that a plugin will need configuration parameters that are not defined in the toml. **Issue: Toml vs Env** A more complex `drone.toml` file is increasingly difficult to represent the configuration in Toml and Environment variables. Environment variable are the recommended method to define configuration (per 12-factor apps) and has become the emerging standard in the Docker community. Ideally we could implement a single approach and move on. We have bigger and more important things to focus on. **Looking Forward: Systemd** Systemd is now the standard init system on almost all Linux distributions, which gives us options for configuration that did not exist with upstart. Specifically, the ability to define `EnvironmentFile=`  **Proposal** The proposal is to use environment variables as the sole method to configuration Drone along with DSN formatting configuration strings. The systemd init file will look like this:  ini EnvironmentFile=/etc/drone/drone.conf  And the configuration file will look like this:  sh SERVER_ADDR="":80"" SERVER_CRT=""/path/to/cert.crt"" SERVER_KEY=""/path/to/key.key"" DATABASE=""postgres://user:pass@localhost/foo"" REMOTE=""github://token:secret@github.com?open=false&orgs=foo,bar""  **DSN format** So how do we give different plugins (ie queue, database, etc) flexible configuration capabilities? After doing a bit of research I believe database abstractions (ie `jdbc`, `database/sql`, etc) have already solved this issue with connection strings in DSN format. The DSN format typically looks like the following: `<driver>://<user>:<pass>@<host>?<key>=<value>`. The most important part of the configuration URL (for Drone) is the `<driver>://` section, so that Drone knows which Driver to load. The remainder of the string is simply passed along to the Driver. This means the Driver itself determines the string format, and has a good amount of flexibility. **Remote Examples**  github://<client>:<secret>@github.com?open=false&orgs=foo,bar gitlab://<client>:<secret>@foo.com?open=false&orgs=foo,bar&ssl=skip bitbucket://<client>:<secret>@bitbucket.org  Or maybe someone wants to create a custom remote plugin, that runs as an RCP service:  tcp://<username>:<password>@localhost  **Database Examples**  sqlite:var/lib/drone/drone.sqlite postgres://root:@localhost/drone  **Queue Examples**  redis://localhost:5367  The benefit is that the URI format is defined by the plugin. This means that Drone will enable any configuration that can fit inside a URI, which has worked pretty well for databases over the years. **Challenges** This is probably out of scope for `0.4.0`, however, it would be interesting to make the Docker backend pluggable as well. For example, could we allow people to choose `swarm` or `mesos` as a backend?  docker:var/run/docker.sock?ca=/path/to/ca&cert=/path/to/cert&key=/path/to/key swarm://6856663cdefdec325839a4b7e1de38e8@swarm-master.cloudapp.net:4243  The only real challenge here that I need to think through is how to supply multiple Docker deamon endpoints. The above example only provides a single daemon URL, however, it is likely that larger installations will need to declare multiple. Suggestions welcome.",source-file,"Use DSN strings for configuration > **TL;DR** configuration needs more flexibility to support plugins without being overly abstracted. The existing 0.4 implementation is overly abstracted, inflexible, and is increasingly difficult to map to environment variables. With the 0.4 release we are introducing a plugin model that allows certain pieces of Drone to be completely replaced, for example, the database layer, the queue layer, etc. This requires an added level of flexibility in terms of configuration that is difficult to achieve with the current `drone.toml` **Issue: Static Typing** This is due primarily to the nature of Go and static typing. We decode the toml into a structure that has a pre-defined hierarchy and set of fields. It is highly likely that a plugin will need configuration parameters that are not defined in the toml. **Issue: Toml vs Env** A more complex `drone.toml` file is increasingly difficult to represent the configuration in Toml and Environment variables. Environment variable are the recommended method to define configuration (per 12-factor apps) and has become the emerging standard in the Docker community. Ideally we could implement a single approach and move on. We have bigger and more important things to focus on. **Looking Forward: Systemd** Systemd is now the standard init system on almost all Linux distributions, which gives us options for configuration that did not exist with upstart. Specifically, the ability to define `EnvironmentFile=`  **Proposal** The proposal is to use environment variables as the sole method to configuration Drone along with DSN formatting configuration strings. The systemd init file will look like this:  ini EnvironmentFile=/etc/drone/drone.conf  And the configuration file will look like this:  sh SERVER_ADDR="":80"" SERVER_CRT=""/path/to/cert.crt"" SERVER_KEY=""/path/to/key.key"" DATABASE=""postgres://user:pass@localhost/foo"" REMOTE=""github://token:secret@github.com?open=false&orgs=foo,bar""  **DSN format** So how do we give different plugins (ie queue, database, etc) flexible configuration capabilities? After doing a bit of research I believe database abstractions (ie `jdbc`, `database/sql`, etc) have already solved this issue with connection strings in DSN format. The DSN format typically looks like the following: `<driver>://<user>:<pass>@<host>?<key>=<value>`. The most important part of the configuration URL (for Drone) is the `<driver>://` section, so that Drone knows which Driver to load. The remainder of the string is simply passed along to the Driver. This means the Driver itself determines the string format, and has a good amount of flexibility. **Remote Examples**  github://<client>:<secret>@github.com?open=false&orgs=foo,bar gitlab://<client>:<secret>@foo.com?open=false&orgs=foo,bar&ssl=skip bitbucket://<client>:<secret>@bitbucket.org  Or maybe someone wants to create a custom remote plugin, that runs as an RCP service:  tcp://<username>:<password>@localhost  **Database Examples**  sqlite:var/lib/drone/drone.sqlite postgres://root:@localhost/drone  **Queue Examples**  redis://localhost:5367  The benefit is that the URI format is defined by the plugin. This means that Drone will enable any configuration that can fit inside a URI, which has worked pretty well for databases over the years. **Challenges** This is probably out of scope for `0.4.0`, however, it would be interesting to make the Docker backend pluggable as well. For example, could we allow people to choose `swarm` or `mesos` as a backend?  docker:var/run/docker.sock?ca=/path/to/ca&cert=/path/to/cert&key=/path/to/key swarm://6856663cdefdec325839a4b7e1de38e8@swarm-master.cloudapp.net:4243  The only real challenge here that I need to think through is how to supply multiple Docker deamon endpoints. The above example only provides a single daemon URL, however, it is likely that larger installations will need to declare multiple. Suggestions welcome. source-file",no-bug,0.95
473,harness,https://github.com/harness/harness/issues/473,Base-url for gitlab,"GitLab is often located under example `admin.example.com/git/`, and with a setting called `Base URL for GitLab` is really confusing since it looks like it supports having /git/. I changed https://github.com/drone/drone/blob/master/pkg/handler/gitlab.go#L26 and that solved my problem, tho, not a good solution. I'm sorry, no pull-request. I don't know Go",source-file,"Base-url for gitlab GitLab is often located under example `admin.example.com/git/`, and with a setting called `Base URL for GitLab` is really confusing since it looks like it supports having /git/. I changed https://github.com/drone/drone/blob/master/pkg/handler/gitlab.go#L26 and that solved my problem, tho, not a good solution. I'm sorry, no pull-request. I don't know Go source-file",no-bug,0.7
945,harness,https://github.com/harness/harness/issues/945,Drone container linking problem [0.3.0-alpha],"Hi, i am trying to work with drone and I have a problem with services. i have to set of integration tests that runs agains a mongodb database. My drone file is this one:  image: wdalmut/php:5.5 services: - wdalmut/mongo:2.6 script: - echo ""date.timezone=Europe/Rome"" > /usr/local/etc/php/php.ini - echo ""memory_limit=512M"" >> /usr/local/etc/php/php.ini - curl -Ss http://getcomposer.org/installer | php - php composer.phar install - bin/phpunit -c app  The script section works correctly and the container is correctly prepared and executed. Same things for the MongoDB service that is effectively started as described in my `.drone.yml` The problem is that containers are not linked and my testing scenarios cannot connect to mongodb using ""locahost:27017"". I have also inspected both containers and there is no linking between them. I checked out the docs and i see that the `.drone.yml` is correctly configured. There is anything that i'm missing? Thanks Walter",other-file,"Drone container linking problem [0.3.0-alpha] Hi, i am trying to work with drone and I have a problem with services. i have to set of integration tests that runs agains a mongodb database. My drone file is this one:  image: wdalmut/php:5.5 services: - wdalmut/mongo:2.6 script: - echo ""date.timezone=Europe/Rome"" > /usr/local/etc/php/php.ini - echo ""memory_limit=512M"" >> /usr/local/etc/php/php.ini - curl -Ss http://getcomposer.org/installer | php - php composer.phar install - bin/phpunit -c app  The script section works correctly and the container is correctly prepared and executed. Same things for the MongoDB service that is effectively started as described in my `.drone.yml` The problem is that containers are not linked and my testing scenarios cannot connect to mongodb using ""locahost:27017"". I have also inspected both containers and there is no linking between them. I checked out the docs and i see that the `.drone.yml` is correctly configured. There is anything that i'm missing? Thanks Walter other-file",no-bug,0.9
3593,harness,https://github.com/harness/harness/issues/3593,Configure S3 with v4 sign,"v4 is more secure, for example by removing functions such as md5. And the new aws s3 region only supports v4 signatures. go already has a number of mature v4 sign repositories, such as https://github.com/smarty-archives/go-aws-auth, etc. I hope this can save your workload. Thank you very much for bringing us such a good product.",source-file | test-file,"Configure S3 with v4 sign v4 is more secure, for example by removing functions such as md5. And the new aws s3 region only supports v4 signatures. go already has a number of mature v4 sign repositories, such as https://github.com/smarty-archives/go-aws-auth, etc. I hope this can save your workload. Thank you very much for bringing us such a good product. source-file test-file",no-bug,0.9
1099,harness,https://github.com/harness/harness/issues/1099,High CPU usage by droned process,"I am running a drone docker container integrated with GitLab with Drone Version: 0.3.0-alpha-1436428588. The CPU utilization reaches 99.9% generally after 24 hours of uptime of 'droned' process. Following is output of 'top' from the 'Ubuntu 14.04.2 LTS, Trusty Tahr' host running drone. top - 18:09:56 up 1 day, 17:32, 1 user, load average: 1.00, 1.01, 0.97 Tasks: 75 total, 3 running, 72 sleeping, 0 stopped, 0 zombie %Cpu0 : 99.0 us, 0.7 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.3 si, 0.0 st KiB Mem: 2050060 total, 813368 used, 1236692 free, 262560 buffers KiB Swap: 0 total, 0 used, 0 free. 349076 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2724 root 20 0 487928 17616 7676 R 99.9 0.9 55:54.18 droned There hardly 2-3 builds running in a day so most of the time drone is inactive, in spite of inactivity it utilizes 99% of CPU. Please look into this issue. I can provide you more details if needed regarding this issue for debug.",other-file,"High CPU usage by droned process I am running a drone docker container integrated with GitLab with Drone Version: 0.3.0-alpha-1436428588. The CPU utilization reaches 99.9% generally after 24 hours of uptime of 'droned' process. Following is output of 'top' from the 'Ubuntu 14.04.2 LTS, Trusty Tahr' host running drone. top - 18:09:56 up 1 day, 17:32, 1 user, load average: 1.00, 1.01, 0.97 Tasks: 75 total, 3 running, 72 sleeping, 0 stopped, 0 zombie %Cpu0 : 99.0 us, 0.7 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.3 si, 0.0 st KiB Mem: 2050060 total, 813368 used, 1236692 free, 262560 buffers KiB Swap: 0 total, 0 used, 0 free. 349076 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2724 root 20 0 487928 17616 7676 R 99.9 0.9 55:54.18 droned There hardly 2-3 builds running in a day so most of the time drone is inactive, in spite of inactivity it utilizes 99% of CPU. Please look into this issue. I can provide you more details if needed regarding this issue for debug. other-file",no-bug,0.95
2062,harness,https://github.com/harness/harness/issues/2062,[Feature Request] Ability to run pipeline steps after all matrix builds finish successfully,Consider the following pipeline:  pipeline: test: image: python:${PYTHON_VERSION} matrix: PYTHON_VERSION: - 2.7 - 3.5  I'm trying to add a `publish` step which runs after all the matrix builds are successful but I don't seam to find a proper way to implement it.,source-file | documentation-file | other-file | other-file,[Feature Request] Ability to run pipeline steps after all matrix builds finish successfully Consider the following pipeline:  pipeline: test: image: python:${PYTHON_VERSION} matrix: PYTHON_VERSION: - 2.7 - 3.5  I'm trying to add a `publish` step which runs after all the matrix builds are successful but I don't seam to find a proper way to implement it. source-file documentation-file other-file other-file,no-bug,0.9
2854,harness,https://github.com/harness/harness/issues/2854,Cancelling a buid doesnt stop the containers,"When I cancel a build on the UI, the build it marked as canceled but containers are still running on the containers created by agents. There's a DELETE request send and it gives this response :  { ""JSON"": { ""action"": """", ""after"": ""806aca4d7ded658a087e8be0b053b6bf19c3c726"", ""author_avatar"": ""https://secure.gravatar.com/avatar/0ab45d63adae19f314668733071e1674?s=80&d=identicon"", ""author_email"": """", ""author_login"": ""User.Name"", ""author_name"": ""User.Name"", ""before"": """", ""created"": 1569875380, ""event"": ""push"", ""finished"": 1569876638, ""id"": 530, ""link"": ""https://git.mydomain.com/project/project/commit/806aca4d7ded658a087e8be0b053b6bf19c3c726"", ""message"": ""[MIGRATION] Better: Update Attachment with deprecated attachable_type 'MobileChat::Message' RD-11323\n"", ""number"": 110, ""ref"": ""refs/heads/rd-11323-migrate-attachment-for-mobile-chat"", ""repo_id"": 2133, ""sender"": ""User.Name"", ""source"": ""rd-11323-migrate-attachment-for-mobile-chat"", ""source_repo"": """", ""stages"": [ { ""arch"": ""amd64"", ""build_id"": 530, ""created"": 1569875380, ""errignore"": false, ""exit_code"": 0, ""id"": 512, ""kind"": ""pipeline"", ""machine"": ""end01-t01-utl04"", ""name"": ""default"", ""number"": 1, ""on_failure"": false, ""on_success"": true, ""os"": ""linux"", ""repo_id"": 2133, ""started"": 1569875730, ""status"": ""killed"", ""steps"": [ { ""exit_code"": 130, ""id"": 5139, ""name"": ""mongo"", ""number"": 1, ""started"": 1569875730, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5140, ""name"": ""redis"", ""number"": 2, ""started"": 1569875730, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5141, ""name"": ""elasticsearch"", ""number"": 3, ""started"": 1569875730, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5142, ""name"": ""memcache"", ""number"": 4, ""started"": 1569875730, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5143, ""name"": ""git"", ""number"": 5, ""started"": 1569875730, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569875750, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5144, ""name"": ""restore-cache"", ""number"": 6, ""started"": 1569875750, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569875843, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5145, ""name"": ""prepare"", ""number"": 7, ""started"": 1569875843, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569875862, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5146, ""name"": ""rspec"", ""number"": 8, ""started"": 1569875862, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5147, ""name"": ""rspec-features"", ""number"": 9, ""started"": 1569875862, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5148, ""name"": ""jasmine"", ""number"": 10, ""started"": 1569875862, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569876020, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5149, ""name"": ""assets-precompilation"", ""number"": 11, ""started"": 1569875862, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569876167, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5150, ""name"": ""rubocop"", ""number"": 12, ""started"": 1569875862, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569875892, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5151, ""name"": ""code-coverage"", ""number"": 13, ""started"": 1569876638, ""status"": ""skipped"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 2 }, { ""exit_code"": 130, ""id"": 5152, ""name"": ""rebuild-cache"", ""number"": 14, ""started"": 1569876638, ""status"": ""skipped"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 2 } ], ""stopped"": 1569876638, ""type"": ""docker"", ""updated"": 1569875730, ""version"": 4 } ], ""started"": 1569875730, ""status"": ""killed"", ""target"": ""rd-11323-migrate-attachment-for-mobile-chat"", ""timestamp"": 0, ""trigger"": ""my.name"", ""updated"": 1569875730, ""version"": 3 }, ""Response payload"": { ""EDITOR_CONFIG"": { ""mode"": ""application/json"", ""text"": ""{\""id\"":530,\""repo_id\"":2133,\""trigger\"":\""my.namel\"",\""number\"":110,\""status\"":\""killed\"",\""event\"":\""push\"",\""action\"":\""\"",\""link\"":\""https://git.mydomain.com/project/project/commit/806aca4d7ded658a087e8be0b053b6bf19c3c726\"",\""timestamp\"":0,\""message\"":\""[MIGRATION] Better: Update Attachment with deprecated attachable_type 'MobileChat::Message' RD-11323\\n\"",\""before\"":\""\"",\""after\"":\""806aca4d7ded658a087e8be0b053b6bf19c3c726\"",\""ref\"":\""refs/heads/rd-11323-migrate-attachment-for-mobile-chat\"",\""source_repo\"":\""\"",\""source\"":\""rd-11323-migrate-attachment-for-mobile-chat\"",\""target\"":\""rd-11323-migrate-attachment-for-mobile-chat\"",\""author_login\"":\""User.Name\"",\""author_name\"":\""User.Name\"",\""author_email\"":\""\"",\""author_avatar\"":\""https://secure.gravatar.com/avatar/0ab45d63adae19f314668733071e1674?s=80\\u0026d=identicon\"",\""sender\"":\""User.Name\"",\""started\"":1569875730,\""finished\"":1569876638,\""created\"":1569875380,\""updated\"":1569875730,\""version\"":3,\""stages\"":[{\""id\"":512,\""repo_id\"":2133,\""build_id\"":530,\""number\"":1,\""name\"":\""default\"",\""kind\"":\""pipeline\"",\""type\"":\""docker\"",\""status\"":\""killed\"",\""errignore\"":false,\""exit_code\"":0,\""machine\"":\""end01-t01-utl04\"",\""os\"":\""linux\"",\""arch\"":\""amd64\"",\""started\"":1569875730,\""stopped\"":1569876638,\""created\"":1569875380,\""updated\"":1569875730,\""version\"":4,\""on_success\"":true,\""on_failure\"":false,\""steps\"":[{\""id\"":5139,\""step_id\"":512,\""number\"":1,\""name\"":\""mongo\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875730,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5140,\""step_id\"":512,\""number\"":2,\""name\"":\""redis\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875730,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5141,\""step_id\"":512,\""number\"":3,\""name\"":\""elasticsearch\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875730,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5142,\""step_id\"":512,\""number\"":4,\""name\"":\""memcache\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875730,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5143,\""step_id\"":512,\""number\"":5,\""name\"":\""git\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875730,\""stopped\"":1569875750,\""version\"":3},{\""id\"":5144,\""step_id\"":512,\""number\"":6,\""name\"":\""restore-cache\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875750,\""stopped\"":1569875843,\""version\"":3},{\""id\"":5145,\""step_id\"":512,\""number\"":7,\""name\"":\""prepare\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875843,\""stopped\"":1569875862,\""version\"":3},{\""id\"":5146,\""step_id\"":512,\""number\"":8,\""name\"":\""rspec\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875862,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5147,\""step_id\"":512,\""number\"":9,\""name\"":\""rspec-features\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875862,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5148,\""step_id\"":512,\""number\"":10,\""name\"":\""jasmine\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875862,\""stopped\"":1569876020,\""version\"":3},{\""id\"":5149,\""step_id\"":512,\""number\"":11,\""name\"":\""assets-precompilation\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875862,\""stopped\"":1569876167,\""version\"":3},{\""id\"":5150,\""step_id\"":512,\""number\"":12,\""name\"":\""rubocop\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875862,\""stopped\"":1569875892,\""version\"":3},{\""id\"":5151,\""step_id\"":512,\""number\"":13,\""name\"":\""code-coverage\"",\""status\"":\""skipped\"",\""exit_code\"":130,\""started\"":1569876638,\""stopped\"":1569876638,\""version\"":2},{\""id\"":5152,\""step_id\"":512,\""number\"":14,\""name\"":\""rebuild-cache\"",\""status\"":\""skipped\"",\""exit_code\"":130,\""started\"":1569876638,\""stopped\"":1569876638,\""version\"":2}]}]}\n"" } } }  Steps are marked as kill but aren't. I took the time to understand how it works and I understood than the canceling request is placed in a queue which is supposed to transmit the call, via a PubSub system, to [this line](https://github.com/drone/drone-runtime/blob/master/engine/docker/docker.go#L259) but I can't go further. I don't understand everything and I don't develop in GO. I'm ready to do more effort to fix the bug. Just let me know what you need.",documentation-file | source-file,"Cancelling a buid doesnt stop the containers When I cancel a build on the UI, the build it marked as canceled but containers are still running on the containers created by agents. There's a DELETE request send and it gives this response :  { ""JSON"": { ""action"": """", ""after"": ""806aca4d7ded658a087e8be0b053b6bf19c3c726"", ""author_avatar"": ""https://secure.gravatar.com/avatar/0ab45d63adae19f314668733071e1674?s=80&d=identicon"", ""author_email"": """", ""author_login"": ""User.Name"", ""author_name"": ""User.Name"", ""before"": """", ""created"": 1569875380, ""event"": ""push"", ""finished"": 1569876638, ""id"": 530, ""link"": ""https://git.mydomain.com/project/project/commit/806aca4d7ded658a087e8be0b053b6bf19c3c726"", ""message"": ""[MIGRATION] Better: Update Attachment with deprecated attachable_type 'MobileChat::Message' RD-11323\n"", ""number"": 110, ""ref"": ""refs/heads/rd-11323-migrate-attachment-for-mobile-chat"", ""repo_id"": 2133, ""sender"": ""User.Name"", ""source"": ""rd-11323-migrate-attachment-for-mobile-chat"", ""source_repo"": """", ""stages"": [ { ""arch"": ""amd64"", ""build_id"": 530, ""created"": 1569875380, ""errignore"": false, ""exit_code"": 0, ""id"": 512, ""kind"": ""pipeline"", ""machine"": ""end01-t01-utl04"", ""name"": ""default"", ""number"": 1, ""on_failure"": false, ""on_success"": true, ""os"": ""linux"", ""repo_id"": 2133, ""started"": 1569875730, ""status"": ""killed"", ""steps"": [ { ""exit_code"": 130, ""id"": 5139, ""name"": ""mongo"", ""number"": 1, ""started"": 1569875730, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5140, ""name"": ""redis"", ""number"": 2, ""started"": 1569875730, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5141, ""name"": ""elasticsearch"", ""number"": 3, ""started"": 1569875730, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5142, ""name"": ""memcache"", ""number"": 4, ""started"": 1569875730, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5143, ""name"": ""git"", ""number"": 5, ""started"": 1569875730, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569875750, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5144, ""name"": ""restore-cache"", ""number"": 6, ""started"": 1569875750, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569875843, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5145, ""name"": ""prepare"", ""number"": 7, ""started"": 1569875843, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569875862, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5146, ""name"": ""rspec"", ""number"": 8, ""started"": 1569875862, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5147, ""name"": ""rspec-features"", ""number"": 9, ""started"": 1569875862, ""status"": ""killed"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5148, ""name"": ""jasmine"", ""number"": 10, ""started"": 1569875862, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569876020, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5149, ""name"": ""assets-precompilation"", ""number"": 11, ""started"": 1569875862, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569876167, ""version"": 3 }, { ""exit_code"": 0, ""id"": 5150, ""name"": ""rubocop"", ""number"": 12, ""started"": 1569875862, ""status"": ""success"", ""step_id"": 512, ""stopped"": 1569875892, ""version"": 3 }, { ""exit_code"": 130, ""id"": 5151, ""name"": ""code-coverage"", ""number"": 13, ""started"": 1569876638, ""status"": ""skipped"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 2 }, { ""exit_code"": 130, ""id"": 5152, ""name"": ""rebuild-cache"", ""number"": 14, ""started"": 1569876638, ""status"": ""skipped"", ""step_id"": 512, ""stopped"": 1569876638, ""version"": 2 } ], ""stopped"": 1569876638, ""type"": ""docker"", ""updated"": 1569875730, ""version"": 4 } ], ""started"": 1569875730, ""status"": ""killed"", ""target"": ""rd-11323-migrate-attachment-for-mobile-chat"", ""timestamp"": 0, ""trigger"": ""my.name"", ""updated"": 1569875730, ""version"": 3 }, ""Response payload"": { ""EDITOR_CONFIG"": { ""mode"": ""application/json"", ""text"": ""{\""id\"":530,\""repo_id\"":2133,\""trigger\"":\""my.namel\"",\""number\"":110,\""status\"":\""killed\"",\""event\"":\""push\"",\""action\"":\""\"",\""link\"":\""https://git.mydomain.com/project/project/commit/806aca4d7ded658a087e8be0b053b6bf19c3c726\"",\""timestamp\"":0,\""message\"":\""[MIGRATION] Better: Update Attachment with deprecated attachable_type 'MobileChat::Message' RD-11323\\n\"",\""before\"":\""\"",\""after\"":\""806aca4d7ded658a087e8be0b053b6bf19c3c726\"",\""ref\"":\""refs/heads/rd-11323-migrate-attachment-for-mobile-chat\"",\""source_repo\"":\""\"",\""source\"":\""rd-11323-migrate-attachment-for-mobile-chat\"",\""target\"":\""rd-11323-migrate-attachment-for-mobile-chat\"",\""author_login\"":\""User.Name\"",\""author_name\"":\""User.Name\"",\""author_email\"":\""\"",\""author_avatar\"":\""https://secure.gravatar.com/avatar/0ab45d63adae19f314668733071e1674?s=80\\u0026d=identicon\"",\""sender\"":\""User.Name\"",\""started\"":1569875730,\""finished\"":1569876638,\""created\"":1569875380,\""updated\"":1569875730,\""version\"":3,\""stages\"":[{\""id\"":512,\""repo_id\"":2133,\""build_id\"":530,\""number\"":1,\""name\"":\""default\"",\""kind\"":\""pipeline\"",\""type\"":\""docker\"",\""status\"":\""killed\"",\""errignore\"":false,\""exit_code\"":0,\""machine\"":\""end01-t01-utl04\"",\""os\"":\""linux\"",\""arch\"":\""amd64\"",\""started\"":1569875730,\""stopped\"":1569876638,\""created\"":1569875380,\""updated\"":1569875730,\""version\"":4,\""on_success\"":true,\""on_failure\"":false,\""steps\"":[{\""id\"":5139,\""step_id\"":512,\""number\"":1,\""name\"":\""mongo\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875730,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5140,\""step_id\"":512,\""number\"":2,\""name\"":\""redis\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875730,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5141,\""step_id\"":512,\""number\"":3,\""name\"":\""elasticsearch\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875730,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5142,\""step_id\"":512,\""number\"":4,\""name\"":\""memcache\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875730,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5143,\""step_id\"":512,\""number\"":5,\""name\"":\""git\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875730,\""stopped\"":1569875750,\""version\"":3},{\""id\"":5144,\""step_id\"":512,\""number\"":6,\""name\"":\""restore-cache\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875750,\""stopped\"":1569875843,\""version\"":3},{\""id\"":5145,\""step_id\"":512,\""number\"":7,\""name\"":\""prepare\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875843,\""stopped\"":1569875862,\""version\"":3},{\""id\"":5146,\""step_id\"":512,\""number\"":8,\""name\"":\""rspec\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875862,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5147,\""step_id\"":512,\""number\"":9,\""name\"":\""rspec-features\"",\""status\"":\""killed\"",\""exit_code\"":130,\""started\"":1569875862,\""stopped\"":1569876638,\""version\"":3},{\""id\"":5148,\""step_id\"":512,\""number\"":10,\""name\"":\""jasmine\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875862,\""stopped\"":1569876020,\""version\"":3},{\""id\"":5149,\""step_id\"":512,\""number\"":11,\""name\"":\""assets-precompilation\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875862,\""stopped\"":1569876167,\""version\"":3},{\""id\"":5150,\""step_id\"":512,\""number\"":12,\""name\"":\""rubocop\"",\""status\"":\""success\"",\""exit_code\"":0,\""started\"":1569875862,\""stopped\"":1569875892,\""version\"":3},{\""id\"":5151,\""step_id\"":512,\""number\"":13,\""name\"":\""code-coverage\"",\""status\"":\""skipped\"",\""exit_code\"":130,\""started\"":1569876638,\""stopped\"":1569876638,\""version\"":2},{\""id\"":5152,\""step_id\"":512,\""number\"":14,\""name\"":\""rebuild-cache\"",\""status\"":\""skipped\"",\""exit_code\"":130,\""started\"":1569876638,\""stopped\"":1569876638,\""version\"":2}]}]}\n"" } } }  Steps are marked as kill but aren't. I took the time to understand how it works and I understood than the canceling request is placed in a queue which is supposed to transmit the call, via a PubSub system, to [this line](https://github.com/drone/drone-runtime/blob/master/engine/docker/docker.go#L259) but I can't go further. I don't understand everything and I don't develop in GO. I'm ready to do more effort to fix the bug. Just let me know what you need. documentation-file source-file",no-bug,0.8
2156,harness,https://github.com/harness/harness/issues/2156,Logs intermittently stop working in the UI,The following error is displayed in the console:  Uncaught TypeError: Cannot read property 'full_name' of undefined at subscribeLogs (drone-app.html:20943) at drone-app.html:21390  Drone 0.8.0-rc3 on GKE Chrome 60 on OS X Sierra,other-file,Logs intermittently stop working in the UI The following error is displayed in the console:  Uncaught TypeError: Cannot read property 'full_name' of undefined at subscribeLogs (drone-app.html:20943) at drone-app.html:21390  Drone 0.8.0-rc3 on GKE Chrome 60 on OS X Sierra other-file,no-bug,0.9
513,harness,https://github.com/harness/harness/issues/513,[0.3] missing slack colors,The messages are missing the nice fancy message colors in 0.3.,source-file,[0.3] missing slack colors The messages are missing the nice fancy message colors in 0.3. source-file,no-bug,0.7
298,harness,https://github.com/harness/harness/issues/298,"Scrolling Jumps, Unable to Scroll Down","I'm unable to scroll down in a build window in Mac/Chrome and Mac/Firefox (I haven't tried other browsers.) I suspect this has something to do with the autoscroll functionality. Here's a video demonstrating the problem: http://cl.ly/VK3P/drone%20Scroll%20Bug.mp4 (Love drone, BTW. Thanks for such a great open source project!)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,"Scrolling Jumps, Unable to Scroll Down I'm unable to scroll down in a build window in Mac/Chrome and Mac/Firefox (I haven't tried other browsers.) I suspect this has something to do with the autoscroll functionality. Here's a video demonstrating the problem: http://cl.ly/VK3P/drone%20Scroll%20Bug.mp4 (Love drone, BTW. Thanks for such a great open source project!) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file",no-bug,0.95
2577,harness,https://github.com/harness/harness/issues/2577,Customize GitHub Status Message (1.0),"When we abstracted the go-scm library we made it more difficult to customize the status message, which is why it is currently disabled in the latest release candidate. I think we can satisfy customization and support for all providers by exposing this as a generic template string:  continuous-integration/drone/{{ if .Build.Event eq ""pull_request"" }}pr{{ else }}push{{ end }} ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Customize GitHub Status Message (1.0) When we abstracted the go-scm library we made it more difficult to customize the status message, which is why it is currently disabled in the latest release candidate. I think we can satisfy customization and support for all providers by exposing this as a generic template string:  continuous-integration/drone/{{ if .Build.Event eq ""pull_request"" }}pr{{ else }}push{{ end }}  source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
443,harness,https://github.com/harness/harness/issues/443,0.3 github login fails,"- open /login - click Github login - error shown in browser: received empty access token from authorization server The log is showing:  Sep 05 15:12:36 support-2 bash[32386]: 2014/09/05 15:12:36 http: panic serving 212.238.236.125:56129: runtime error: invalid memory address or nil pointer dereference Sep 05 15:12:36 support-2 bash[32386]: goroutine 19 [running]: Sep 05 15:12:36 support-2 bash[32386]: net/http.func009() Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1093 +0xae Sep 05 15:12:36 support-2 bash[32386]: runtime.panic(0x999660, 0x12f5da8) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/runtime/panic.c:248 +0x106 Sep 05 15:12:36 support-2 bash[32386]: github.com/drone/drone/plugin/remote/github.(*GitHub).Authorize(0xc2100e0380, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410, 0xa, ) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/plugin/remote/github/github.go:95 +0x86b Sep 05 15:12:36 support-2 bash[32386]: github.com/drone/drone/server/handler.(*LoginHandler).GetLogin(0xc210034f00, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410, 0x7f32ff9c9b80, ) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/server/handler/login.go:39 +0x19c Sep 05 15:12:36 support-2 bash[32386]: github.com/drone/drone/server/handler.*LoginHandler.GetLoginfm(0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410, 0x0, 0x0) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/server/handler/login.go:158 +0x56 Sep 05 15:12:36 support-2 bash[32386]: github.com/drone/drone/server/handler.func002(0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/server/handler/error.go:32 +0x53 Sep 05 15:12:36 support-2 bash[32386]: net/http.HandlerFunc.ServeHTTP(0xc21010e340, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1220 +0x40 Sep 05 15:12:36 support-2 bash[32386]: github.com/gorilla/pat.(*Router).ServeHTTP(0xc210096370, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/gorilla/pat/pat.go:75 +0x1b8 Sep 05 15:12:36 support-2 bash[32386]: main.func001(0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/server/main.go:150 +0x4f7 Sep 05 15:12:36 support-2 bash[32386]: net/http.HandlerFunc.ServeHTTP(0xc2101407e0, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1220 +0x40 Sep 05 15:12:36 support-2 bash[32386]: net/http.(*ServeMux).ServeHTTP(0xc2100338d0, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1496 +0x163 Sep 05 15:12:36 support-2 bash[32386]: net/http.serverHandler.ServeHTTP(0xc21014a050, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1597 +0x16e Sep 05 15:12:36 support-2 bash[32386]: net/http.(*conn).serve(0xc21011d700) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1167 +0x7b7 Sep 05 15:12:36 support-2 bash[32386]: created by net/http.(*Server).Serve Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1644 +0x28b Sep 05 15:12:36 support-2 bash[32386]: 2014/09/05 15:12:36 GET /login/github.com Sep 05 15:12:36 support-2 bash[32386]: 2014/09/05 15:12:36 received empty access token from authorization server ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"0.3 github login fails - open /login - click Github login - error shown in browser: received empty access token from authorization server The log is showing:  Sep 05 15:12:36 support-2 bash[32386]: 2014/09/05 15:12:36 http: panic serving 212.238.236.125:56129: runtime error: invalid memory address or nil pointer dereference Sep 05 15:12:36 support-2 bash[32386]: goroutine 19 [running]: Sep 05 15:12:36 support-2 bash[32386]: net/http.func009() Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1093 +0xae Sep 05 15:12:36 support-2 bash[32386]: runtime.panic(0x999660, 0x12f5da8) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/runtime/panic.c:248 +0x106 Sep 05 15:12:36 support-2 bash[32386]: github.com/drone/drone/plugin/remote/github.(*GitHub).Authorize(0xc2100e0380, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410, 0xa, ) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/plugin/remote/github/github.go:95 +0x86b Sep 05 15:12:36 support-2 bash[32386]: github.com/drone/drone/server/handler.(*LoginHandler).GetLogin(0xc210034f00, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410, 0x7f32ff9c9b80, ) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/server/handler/login.go:39 +0x19c Sep 05 15:12:36 support-2 bash[32386]: github.com/drone/drone/server/handler.*LoginHandler.GetLoginfm(0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410, 0x0, 0x0) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/server/handler/login.go:158 +0x56 Sep 05 15:12:36 support-2 bash[32386]: github.com/drone/drone/server/handler.func002(0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/server/handler/error.go:32 +0x53 Sep 05 15:12:36 support-2 bash[32386]: net/http.HandlerFunc.ServeHTTP(0xc21010e340, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1220 +0x40 Sep 05 15:12:36 support-2 bash[32386]: github.com/gorilla/pat.(*Router).ServeHTTP(0xc210096370, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/gorilla/pat/pat.go:75 +0x1b8 Sep 05 15:12:36 support-2 bash[32386]: main.func001(0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /var/cache/drone/src/github.com/drone/drone/server/main.go:150 +0x4f7 Sep 05 15:12:36 support-2 bash[32386]: net/http.HandlerFunc.ServeHTTP(0xc2101407e0, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1220 +0x40 Sep 05 15:12:36 support-2 bash[32386]: net/http.(*ServeMux).ServeHTTP(0xc2100338d0, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1496 +0x163 Sep 05 15:12:36 support-2 bash[32386]: net/http.serverHandler.ServeHTTP(0xc21014a050, 0x7f32ffb55d20, 0xc2101440a0, 0xc2100c8410) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1597 +0x16e Sep 05 15:12:36 support-2 bash[32386]: net/http.(*conn).serve(0xc21011d700) Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1167 +0x7b7 Sep 05 15:12:36 support-2 bash[32386]: created by net/http.(*Server).Serve Sep 05 15:12:36 support-2 bash[32386]: /usr/local/go/src/pkg/net/http/server.go:1644 +0x28b Sep 05 15:12:36 support-2 bash[32386]: 2014/09/05 15:12:36 GET /login/github.com Sep 05 15:12:36 support-2 bash[32386]: 2014/09/05 15:12:36 received empty access token from authorization server  source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.9
2646,harness,https://github.com/harness/harness/issues/2646,Allow environment variables in DRONE_RUNNER_VOLUMES,"I would like all of my repositories to have their own host folder mounted via `${DRONE_REPO}`. Currently this is possible by trusting all repositories, and allowing each one to mount a host directory on their own. I am suggesting that `DRONE_RUNNER_VOLUMES` should allow appending a `DRONE_REPO` to the host path before a runner is created, and preferably before `drone.yml` has had a chance to alter any `DRONE_*` environment variables (if altering `DRONE_*` variables is even possible). Example: yaml DRONE_RUNNER_VOLUMES: ""/var/www/html/${DRONE_REPO}:/webroot"" ",other-file | other-file | other-file | source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file | source-file | source-file,"Allow environment variables in DRONE_RUNNER_VOLUMES I would like all of my repositories to have their own host folder mounted via `${DRONE_REPO}`. Currently this is possible by trusting all repositories, and allowing each one to mount a host directory on their own. I am suggesting that `DRONE_RUNNER_VOLUMES` should allow appending a `DRONE_REPO` to the host path before a runner is created, and preferably before `drone.yml` has had a chance to alter any `DRONE_*` environment variables (if altering `DRONE_*` variables is even possible). Example: yaml DRONE_RUNNER_VOLUMES: ""/var/www/html/${DRONE_REPO}:/webroot""  other-file other-file other-file source-file source-file documentation-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file source-file source-file source-file",no-bug,0.9
1998,harness,https://github.com/harness/harness/issues/1998,Pluggable registry store,Similar to #1997 but for registry credentials. In 0.6 registry credentials (for pulling private images) are stored and managed separately from secrets.,source-file,Pluggable registry store Similar to #1997 but for registry credentials. In 0.6 registry credentials (for pulling private images) are stored and managed separately from secrets. source-file,no-bug,0.9
3410,harness,https://github.com/harness/harness/issues/3410,Gitness repository extension,"Github provide a discussions which we usually used for documentation and the review co-ordination purpose, does Gitness have same things or any plan for adding new feature. Can any one share steps to write our own custom plugin for comments and discussion using Drone and Gitness.",source-file | other-file,"Gitness repository extension Github provide a discussions which we usually used for documentation and the review co-ordination purpose, does Gitness have same things or any plan for adding new feature. Can any one share steps to write our own custom plugin for comments and discussion using Drone and Gitness. source-file other-file",no-bug,0.9
2493,harness,https://github.com/harness/harness/issues/2493,Reverse proxy support,"According to this issue #2246, using a reverse proxy is not supported until certain bugs are fixed/features implemented. The documentation however provides instructions for various proxies, i.e. http://docs.drone.io/setup-with-nginx/ If reverse proxy support really is broken this should be stated in the documentation",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | source-file | source-file | documentation-file | other-file | documentation-file,"Reverse proxy support According to this issue #2246, using a reverse proxy is not supported until certain bugs are fixed/features implemented. The documentation however provides instructions for various proxies, i.e. http://docs.drone.io/setup-with-nginx/ If reverse proxy support really is broken this should be stated in the documentation source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file source-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file source-file other-file source-file other-file source-file other-file source-file other-file source-file other-file other-file source-file other-file other-file other-file other-file source-file other-file source-file other-file other-file other-file source-file source-file documentation-file other-file documentation-file",no-bug,0.7
2087,harness,https://github.com/harness/harness/issues/2087,support Docker HEALTHCHECK,support a healthcheck for the server and agent  HEALTHCHECK CMD curl --fail http://localhost:3000/ || exit 1 ,source-file,support Docker HEALTHCHECK support a healthcheck for the server and agent  HEALTHCHECK CMD curl --fail http://localhost:3000/ || exit 1  source-file,no-bug,0.9
235,harness,https://github.com/harness/harness/issues/235,Add support for restricting publish/deploy plugins to certain branches,"It looks like the S3 plugin for example refers to a branch field in the .drone.yaml file, but this seems to be unused?",other-file | other-file | other-file | other-file | other-file | source-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | source-file,"Add support for restricting publish/deploy plugins to certain branches It looks like the S3 plugin for example refers to a branch field in the .drone.yaml file, but this seems to be unused? other-file other-file other-file other-file other-file source-file source-file other-file other-file source-file other-file other-file other-file source-file source-file documentation-file other-file other-file other-file other-file source-file",no-bug,0.7
512,harness,https://github.com/harness/harness/issues/512,[0.3] activate adding wrong hook url,When I active a gitlab repo it sets up the deploy key and the webhook but it seems like the webhook is incorrect: `http://10.1.7.87/v1/hook/gitlab.com?owner=:owner&name=:name` when it seems like it should be `http://10.1.7.87/api/hook/gitlab.com?owner=:owner&name=:repo`,other-file,[0.3] activate adding wrong hook url When I active a gitlab repo it sets up the deploy key and the webhook but it seems like the webhook is incorrect: `http://10.1.7.87/v1/hook/gitlab.com?owner=:owner&name=:name` when it seems like it should be `http://10.1.7.87/api/hook/gitlab.com?owner=:owner&name=:repo` other-file,bug,0.8
3392,harness,https://github.com/harness/harness/issues/3392,[Feature request] SSH Cloning,It would be great to clone the repositories using an SSH key instead of login and ~~password~~ api key,other-file | other-file | other-file | other-file,[Feature request] SSH Cloning It would be great to clone the repositories using an SSH key instead of login and ~~password~~ api key other-file other-file other-file other-file,no-bug,0.95
2523,harness,https://github.com/harness/harness/issues/2523,"1.0.0-rc.1: ""npm insta""","My pipeline looks like this:  kind: pipeline name: default steps: - name: build image: node:8-alpine commands: - npm install  Drone logs the following:  + npm insta Usage: npm <command> where <command> is one of:  npm@6.4.1 /usr/local/lib/node_modules/npm Did you mean one of these? init install unstar  So clearly the ""ll"" went missing somewhere.",source-file | other-file | source-file | other-file | other-file | other-file | other-file,"1.0.0-rc.1: ""npm insta"" My pipeline looks like this:  kind: pipeline name: default steps: - name: build image: node:8-alpine commands: - npm install  Drone logs the following:  + npm insta Usage: npm <command> where <command> is one of:  npm@6.4.1 /usr/local/lib/node_modules/npm Did you mean one of these? init install unstar  So clearly the ""ll"" went missing somewhere. source-file other-file source-file other-file other-file other-file other-file",no-bug,0.9
2259,harness,https://github.com/harness/harness/issues/2259,"Missing ""VOLUME /var/lib/drone"" in the Docker image","The drone database driver is `sqlite3` by default in the `drone/drone` docker image, and the database file will be stored at `/var/lib/drone/drone.sqlite` as `DATABASE_CONFIG` say. dockerfile ENV DATABASE_DRIVER=sqlite3 ENV DATABASE_CONFIG=/var/lib/drone/drone.sqlite ENV GODEBUG=netdns=go ENV XDG_CACHE_HOME /var/lib/drone  However, the directory is not available by default, that will lead to database creation failure during the container boot up if not further `-v` instructions is given. Here is a example setup without `volumes`: yaml version: '2' services: drone-server: image: drone/drone:0.7 ports: - 80:8000 restart: always environment: - DRONE_OPEN=true - DRONE_HOST=${DRONE_HOST} - DRONE_GOGS=true - DRONE_GOGS_URL=${DRONE_GOGS_URL} - DRONE_SECRET=${DRONE_SECRET} drone-agent: image: drone/drone:0.7 command: agent restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=ws://drone-server:8000/ws/broker - DRONE_SECRET=${DRONE_SECRET}  And the error for `drone-server` will be something like this: bash drone-server_1 | time=""2017-11-07T13:14:22Z"" level=error msg=""unable to open database file"" drone-server_1 | time=""2017-11-07T13:14:22Z"" level=fatal msg=""database ping attempts failed""  To avoid such error, an anonymous volume can be setup at `/var/lib/drone` in the `Dockerfile`. Dockerfile VOLUME [ ""/var/lib/drone"" ]  Actually, there was a `VOLUME` instruction before, however it's been removed somehow.",container-file | container-file | config-file,"Missing ""VOLUME /var/lib/drone"" in the Docker image The drone database driver is `sqlite3` by default in the `drone/drone` docker image, and the database file will be stored at `/var/lib/drone/drone.sqlite` as `DATABASE_CONFIG` say. dockerfile ENV DATABASE_DRIVER=sqlite3 ENV DATABASE_CONFIG=/var/lib/drone/drone.sqlite ENV GODEBUG=netdns=go ENV XDG_CACHE_HOME /var/lib/drone  However, the directory is not available by default, that will lead to database creation failure during the container boot up if not further `-v` instructions is given. Here is a example setup without `volumes`: yaml version: '2' services: drone-server: image: drone/drone:0.7 ports: - 80:8000 restart: always environment: - DRONE_OPEN=true - DRONE_HOST=${DRONE_HOST} - DRONE_GOGS=true - DRONE_GOGS_URL=${DRONE_GOGS_URL} - DRONE_SECRET=${DRONE_SECRET} drone-agent: image: drone/drone:0.7 command: agent restart: always depends_on: - drone-server volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_SERVER=ws://drone-server:8000/ws/broker - DRONE_SECRET=${DRONE_SECRET}  And the error for `drone-server` will be something like this: bash drone-server_1 | time=""2017-11-07T13:14:22Z"" level=error msg=""unable to open database file"" drone-server_1 | time=""2017-11-07T13:14:22Z"" level=fatal msg=""database ping attempts failed""  To avoid such error, an anonymous volume can be setup at `/var/lib/drone` in the `Dockerfile`. Dockerfile VOLUME [ ""/var/lib/drone"" ]  Actually, there was a `VOLUME` instruction before, however it's been removed somehow. container-file container-file config-file",no-bug,0.9
895,harness,https://github.com/harness/harness/issues/895,"Store build number in database, remove sha + branch unique index","I propose we start storing `ref` field with the commit record. This is a better way to uniquely identify commits, pull requests, branches, tags, etc. This is a pre-requisite if we want to support building, testing, and deploying tags. The commit+ref is a much better unique identifier than commit+branch:  cd1fed3d5344d49f1e913f9b6c03ebd2296f8855 refs/heads/master c3966b1a59b542e3337b02e05819a918d0fd444e refs/heads/matrix 4c7cd974219774b380820171e39b94f2a15da49d refs/tags/v0.2.0 55a99f1ebc45766ca31d197f6009e7a25b7e55f5 refs/tags/v0.2.1 8d6a233744a5dcacbf2605d4592a4bfe8b37320d refs/pull/877/merge   database changes We could image a database change like this:  diff var commitTable = ` CREATE TABLE IF NOT EXISTS commits ( commit_id INTEGER PRIMARY KEY AUTOINCREMENT ,repo_id INTEGER ,commit_status VARCHAR(255) ,commit_started INTEGER ,commit_finished INTEGER ,commit_duration INTEGER + ,commit_ref VARCHAR(255) ,commit_sha VARCHAR(255) ,commit_branch VARCHAR(255) ,commit_pr VARCHAR(255) ,commit_author VARCHAR(255) ,commit_gravatar VARCHAR(255) ,commit_timestamp VARCHAR(255) ,commit_message VARCHAR(255) ,commit_yaml BLOB ,commit_created INTEGER ,commit_updated INTEGER + ,UNIQUE(commit_sha, commit_ref, repo_id) - ,UNIQUE(commit_sha, commit_ref, repo_id) ); `  **important** the actual implementation will differ from above. We will need to ensure that we can migrate older versions of Drone. Therefore we should probably `drop` and then `add` the unique index. We should also populate the `commit_ref` field for older records before adding the unique index.  rest changes We may need to update the restful API accordingly. Let's figure out a strategy here before we proceed. I'm not quite sure how we want to represent this in the URL.",other-file | other-file | other-file | source-file,"Store build number in database, remove sha + branch unique index I propose we start storing `ref` field with the commit record. This is a better way to uniquely identify commits, pull requests, branches, tags, etc. This is a pre-requisite if we want to support building, testing, and deploying tags. The commit+ref is a much better unique identifier than commit+branch:  cd1fed3d5344d49f1e913f9b6c03ebd2296f8855 refs/heads/master c3966b1a59b542e3337b02e05819a918d0fd444e refs/heads/matrix 4c7cd974219774b380820171e39b94f2a15da49d refs/tags/v0.2.0 55a99f1ebc45766ca31d197f6009e7a25b7e55f5 refs/tags/v0.2.1 8d6a233744a5dcacbf2605d4592a4bfe8b37320d refs/pull/877/merge   database changes We could image a database change like this:  diff var commitTable = ` CREATE TABLE IF NOT EXISTS commits ( commit_id INTEGER PRIMARY KEY AUTOINCREMENT ,repo_id INTEGER ,commit_status VARCHAR(255) ,commit_started INTEGER ,commit_finished INTEGER ,commit_duration INTEGER + ,commit_ref VARCHAR(255) ,commit_sha VARCHAR(255) ,commit_branch VARCHAR(255) ,commit_pr VARCHAR(255) ,commit_author VARCHAR(255) ,commit_gravatar VARCHAR(255) ,commit_timestamp VARCHAR(255) ,commit_message VARCHAR(255) ,commit_yaml BLOB ,commit_created INTEGER ,commit_updated INTEGER + ,UNIQUE(commit_sha, commit_ref, repo_id) - ,UNIQUE(commit_sha, commit_ref, repo_id) ); `  **important** the actual implementation will differ from above. We will need to ensure that we can migrate older versions of Drone. Therefore we should probably `drop` and then `add` the unique index. We should also populate the `commit_ref` field for older records before adding the unique index.  rest changes We may need to update the restful API accordingly. Let's figure out a strategy here before we proceed. I'm not quite sure how we want to represent this in the URL. other-file other-file other-file source-file",no-bug,0.9
1081,harness,https://github.com/harness/harness/issues/1081,no logs when docker.tty = true,requested in #1048 unfortunately the feature to enable a tty will hide all log output. I set up a test project for this: https://github.com/fommil/drone-tests with  yaml image: ensime/ensime:latest docker: tty: false script: - echo hello  and then  yaml image: ensime/ensime:latest docker: tty: true script: - echo hello  confirming that this is the minimal change needed to trigger the problem.,other-file,no logs when docker.tty = true requested in #1048 unfortunately the feature to enable a tty will hide all log output. I set up a test project for this: https://github.com/fommil/drone-tests with  yaml image: ensime/ensime:latest docker: tty: false script: - echo hello  and then  yaml image: ensime/ensime:latest docker: tty: true script: - echo hello  confirming that this is the minimal change needed to trigger the problem. other-file,no-bug,0.9
17,harness,https://github.com/harness/harness/issues/17,GitHub Enterprise Support,"I don't have access to GitHub enterprise, so I'm just guessing here, but this is what I think will need to get altered. It should be a relatively straightforward change  **step 1:** alter the github client to accept a custom url  go NewClient(url, token)  https://github.com/drone/go-github/blob/master/github/github.go#L4 https://github.com/drone/go-github/blob/master/github/http.go#L44 **step 2:** alter our github oauth code (for linking accounts) to use custom access token and authorization urls:  go var oauth = oauth2.Client{ RedirectURL: settings.URL().String() + ""/auth/login/github"", AccessTokenURL: ""https://github.com/login/oauth/access_token"", AuthorizationURL: ""https://github.com/login/oauth/authorize"", ClientId: settings.GitHubKey, ClientSecret: settings.GitHubSecret, }  https://github.com/drone/drone/blob/master/pkg/handler/auth.go#L43",other-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file,"GitHub Enterprise Support I don't have access to GitHub enterprise, so I'm just guessing here, but this is what I think will need to get altered. It should be a relatively straightforward change  **step 1:** alter the github client to accept a custom url  go NewClient(url, token)  https://github.com/drone/go-github/blob/master/github/github.go#L4 https://github.com/drone/go-github/blob/master/github/http.go#L44 **step 2:** alter our github oauth code (for linking accounts) to use custom access token and authorization urls:  go var oauth = oauth2.Client{ RedirectURL: settings.URL().String() + ""/auth/login/github"", AccessTokenURL: ""https://github.com/login/oauth/access_token"", AuthorizationURL: ""https://github.com/login/oauth/authorize"", ClientId: settings.GitHubKey, ClientSecret: settings.GitHubSecret, }  https://github.com/drone/drone/blob/master/pkg/handler/auth.go#L43 other-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file database-file database-file source-file source-file source-file source-file source-file",no-bug,0.9
208,harness,https://github.com/harness/harness/issues/208,"Builds stay ""running"" for much longer than they actually are","Haven't tracked this down yet, but on my deployment every build stays ""running"" for minutes on end, long after I see them actually complete. They eventually clear up. Is this some background job or something that polls infrequently?",other-file | other-file | other-file | other-file | other-file | other-file | other-file | test-file | other-file | source-file | other-file | other-file | source-file | other-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file,"Builds stay ""running"" for much longer than they actually are Haven't tracked this down yet, but on my deployment every build stays ""running"" for minutes on end, long after I see them actually complete. They eventually clear up. Is this some background job or something that polls infrequently? other-file other-file other-file other-file other-file other-file other-file test-file other-file source-file other-file other-file source-file other-file documentation-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file source-file source-file",no-bug,0.7
3536,harness,https://github.com/harness/harness/issues/3536,Support LFS,"Hello Team, Gitness local setup is very smooth. I have few questions: 1. How should I use S3 in Fitness to store the git repository to save on storage cost? 2. To manage LFS files does Gitness have any integration with Git-LFS or DVC? Thanks!",source-file,"Support LFS Hello Team, Gitness local setup is very smooth. I have few questions: 1. How should I use S3 in Fitness to store the git repository to save on storage cost? 2. To manage LFS files does Gitness have any integration with Git-LFS or DVC? Thanks! source-file",no-bug,0.95
3010,harness,https://github.com/harness/harness/issues/3010,can not Sync Gitlab project in subgroups,"today i upgrade drone to last version but aslo cant sync project in subgroups  before upgrade ,the web page of "" repo list "" can show the project but after upgrade,it not display in the list",source-file | source-file | config-file,"can not Sync Gitlab project in subgroups today i upgrade drone to last version but aslo cant sync project in subgroups  before upgrade ,the web page of "" repo list "" can show the project but after upgrade,it not display in the list source-file source-file config-file",bug,0.8
1192,harness,https://github.com/harness/harness/issues/1192,"Error ""tls: first record does not look like a TLS handshake"" when accessing site","I set up a new drone server by downloading the .deb. When I surf to it, my browser downloads a small binary file. Running drone from the command line shows the following when I try to access the page:  root@tetrad:/etc/ssl/certs# cd root@tetrad:~# droned -config /etc/drone/drone.toml 2015/09/06 19:33:54 http: TLS handshake error from 208.70.50.7:36073: tls: first record does not look like a TLS handshake  I double-checked my cert files, and they both appear normal, and are used by other services on the box without problems.",source-file | source-file,"Error ""tls: first record does not look like a TLS handshake"" when accessing site I set up a new drone server by downloading the .deb. When I surf to it, my browser downloads a small binary file. Running drone from the command line shows the following when I try to access the page:  root@tetrad:/etc/ssl/certs# cd root@tetrad:~# droned -config /etc/drone/drone.toml 2015/09/06 19:33:54 http: TLS handshake error from 208.70.50.7:36073: tls: first record does not look like a TLS handshake  I double-checked my cert files, and they both appear normal, and are used by other services on the box without problems. source-file source-file",no-bug,0.9
259,harness,https://github.com/harness/harness/issues/259,Docs need update for new build process,The docs at http://drone.readthedocs.org/en/latest/install.html#from-source are no longer correct since #243. It should read something like  $ git clone git://github.com/drone/drone.git $ cd drone $ git submodule update --init $ make build $ make dpkg ,other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file,Docs need update for new build process The docs at http://drone.readthedocs.org/en/latest/install.html#from-source are no longer correct since #243. It should read something like  $ git clone git://github.com/drone/drone.git $ cd drone $ git submodule update --init $ make build $ make dpkg  other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file,no-bug,0.9
1063,harness,https://github.com/harness/harness/issues/1063,how to get color output in console,"Hi, sorry for the ticket, but I have failed to figure it out several time. Obviously some color codes are translated as seen is source code. I googled an post from 2012 where you even mention it. However when I do on my ubuntu/debian image during the run:  $ git clone https://github.com/huyz/dircolors-solarized ~/.dircolors-solarized Cloning into '/root/.dircolors-solarized' $ ln -s ~/.dircolors-solarized/dircolors.ansi-dark ~/.dircolors $ ln -s ~/.dircolors-solarized/dircolors.ansi-dark ~/.dir_colors $ ls -l ~/.dircolors ~/.dir_colors lrwxrwxrwx 1 root root 46 Jun 16 11:39 /root/.dircolors -> /root/.dircolors-solarized/dircolors.ansi-dark lrwxrwxrwx 1 root root 46 Jun 16 11:39 /root/.dir_colors -> /root/.dircolors-solarized/dircolors.ansi-dark $ echo 'eval `dircolors ~/.dircolors`' >> .bash_profile $ echo 'export TERM=screen' >> .bash_profile $ eval `dircolors ~/.dircolors` $ export TERM=screen $ ls -l -colors . total 52 4 -rw-r--r-- 1 root 3265 Jun 16 11:38 Vagrantfile 4 -rw-r--r-- 1 root 86 Jun 16 11:38 Thorfile 4 drwxr-xr-x 3 root 4096 Jun 16 11:38 test 4 drwxr-xr-x 3 root 4096 Jun 16 11:38 templates 4 drwxr-xr-x 2 root 4096 Jun 16 11:38 recipes 4 -rw-r--r-- 1 root 792 Jun 16 11:38 README.md 4 -rw-r--r-- 1 root 496 Jun 16 11:38 metadata.rb 4 -rw-r--r-- 1 root 72 Jun 16 11:38 LICENSE 4 -rw-r--r-- 1 root 47 Jun 16 11:38 Gemfile 4 -rw-r--r-- 1 root 985 Jun 16 11:38 chefignore 4 -rw-r--r-- 1 root 82 Jun 16 11:38 CHANGELOG.md 4 -rw-r--r-- 1 root 685 Jun 16 11:38 Berksfile 4 drwxr-xr-x 2 root 4096 Jun 16 11:38 attributes     Note I have tried to set TERM to multiple values like: xterm, xterm-256colors, screen etc.. If the feature is supported, what settings you are using? Thanks",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file,"how to get color output in console Hi, sorry for the ticket, but I have failed to figure it out several time. Obviously some color codes are translated as seen is source code. I googled an post from 2012 where you even mention it. However when I do on my ubuntu/debian image during the run:  $ git clone https://github.com/huyz/dircolors-solarized ~/.dircolors-solarized Cloning into '/root/.dircolors-solarized' $ ln -s ~/.dircolors-solarized/dircolors.ansi-dark ~/.dircolors $ ln -s ~/.dircolors-solarized/dircolors.ansi-dark ~/.dir_colors $ ls -l ~/.dircolors ~/.dir_colors lrwxrwxrwx 1 root root 46 Jun 16 11:39 /root/.dircolors -> /root/.dircolors-solarized/dircolors.ansi-dark lrwxrwxrwx 1 root root 46 Jun 16 11:39 /root/.dir_colors -> /root/.dircolors-solarized/dircolors.ansi-dark $ echo 'eval `dircolors ~/.dircolors`' >> .bash_profile $ echo 'export TERM=screen' >> .bash_profile $ eval `dircolors ~/.dircolors` $ export TERM=screen $ ls -l -colors . total 52 4 -rw-r--r-- 1 root 3265 Jun 16 11:38 Vagrantfile 4 -rw-r--r-- 1 root 86 Jun 16 11:38 Thorfile 4 drwxr-xr-x 3 root 4096 Jun 16 11:38 test 4 drwxr-xr-x 3 root 4096 Jun 16 11:38 templates 4 drwxr-xr-x 2 root 4096 Jun 16 11:38 recipes 4 -rw-r--r-- 1 root 792 Jun 16 11:38 README.md 4 -rw-r--r-- 1 root 496 Jun 16 11:38 metadata.rb 4 -rw-r--r-- 1 root 72 Jun 16 11:38 LICENSE 4 -rw-r--r-- 1 root 47 Jun 16 11:38 Gemfile 4 -rw-r--r-- 1 root 985 Jun 16 11:38 chefignore 4 -rw-r--r-- 1 root 82 Jun 16 11:38 CHANGELOG.md 4 -rw-r--r-- 1 root 685 Jun 16 11:38 Berksfile 4 drwxr-xr-x 2 root 4096 Jun 16 11:38 attributes     Note I have tried to set TERM to multiple values like: xterm, xterm-256colors, screen etc.. If the feature is supported, what settings you are using? Thanks source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file source-file source-file source-file test-file source-file test-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file",no-bug,0.95
148,harness,https://github.com/harness/harness/issues/148,Should be able to retry build,"It would be helpful if there were a way to retry a build without a commit. I think there is an issue with my drone installation that's causing the failure, and it's not an issue with my repository. Retrying would be helpful to debug this case. Specifically, the problem is: dial tcp 0.0.0.0:4243: connection refused",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Should be able to retry build It would be helpful if there were a way to retry a build without a commit. I think there is an issue with my drone installation that's causing the failure, and it's not an issue with my repository. Retrying would be helpful to debug this case. Specifically, the problem is: dial tcp 0.0.0.0:4243: connection refused source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
927,harness,https://github.com/harness/harness/issues/927,Drone Status API,"We should have a Drone status API that allows 3rd party system to annotate commits and link back to those 3rd party systems. This would be similar to the GitHub status API. An example use case would be a coverage system. A coverage system would store detailed coverage metrics, but could provide Drone with a high-level status and link to those detailed coverage reports. This came out of #239",other-file | other-file | source-file | other-file | other-file | source-file,"Drone Status API We should have a Drone status API that allows 3rd party system to annotate commits and link back to those 3rd party systems. This would be similar to the GitHub status API. An example use case would be a coverage system. A coverage system would store detailed coverage metrics, but could provide Drone with a high-level status and link to those detailed coverage reports. This came out of #239 other-file other-file source-file other-file other-file source-file",no-bug,0.9
2082,harness,https://github.com/harness/harness/issues/2082,Bitbucket server integration issue with pull hook,Hello! I'm using drone 0.7.0v with private bitbucket server. When I do push to git repo build on drone don't start. Slider for push hook is enabled on UI. Bitbucket server version v5.1.0,documentation-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file,Bitbucket server integration issue with pull hook Hello! I'm using drone 0.7.0v with private bitbucket server. When I do push to git repo build on drone don't start. Slider for push hook is enabled on UI. Bitbucket server version v5.1.0 documentation-file other-file other-file source-file other-file source-file other-file other-file documentation-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file source-file other-file other-file other-file other-file,no-bug,0.7
147,harness,https://github.com/harness/harness/issues/147,Implement proper Caching,"I was playing around with Drone.io over the weekend and I'm really impressed. However, there is one big issue for our Rails project: Bundling all the Gems (~ 250 Gems, where about 10 of these are git checkouts) takes about 10 minutes for each build, as I've found no way to provide a cacheable directory to Bundler. I've seen the issues #43 and #143, but as far as I understood the solution proposed in #43, the cache would only be invalidated when the actual setup commands have changed. In my case, it would need to re-run the commands when the content of the project's `Gemfile.lock` has changed. Furthermore, it would be neat to be able to share a cache directory between different projects. In our current Jenkins setup, we're sharing a global Bundler directory, which speeds up new project builds enormously. Here is an excerpt of our build file:  bash BUNDLE_PATH=""$JENKINS_HOME/shared/bundle"" bundle install --path=""$BUNDLE_PATH"" ",source-file | documentation-file,"Implement proper Caching I was playing around with Drone.io over the weekend and I'm really impressed. However, there is one big issue for our Rails project: Bundling all the Gems (~ 250 Gems, where about 10 of these are git checkouts) takes about 10 minutes for each build, as I've found no way to provide a cacheable directory to Bundler. I've seen the issues #43 and #143, but as far as I understood the solution proposed in #43, the cache would only be invalidated when the actual setup commands have changed. In my case, it would need to re-run the commands when the content of the project's `Gemfile.lock` has changed. Furthermore, it would be neat to be able to share a cache directory between different projects. In our current Jenkins setup, we're sharing a global Bundler directory, which speeds up new project builds enormously. Here is an excerpt of our build file:  bash BUNDLE_PATH=""$JENKINS_HOME/shared/bundle"" bundle install --path=""$BUNDLE_PATH""  source-file documentation-file",no-bug,0.95
47,harness,https://github.com/harness/harness/issues/47,Hostname to container routing/Container persistence,"A couple of feature suggestions. They might be out of scope of the project but I thought I'd throw them out there. Hostname/Port to container routing: - Routes ports to containers - For HTTP based protocols, also route on `Host` header - Use wildcard DNS entry to allow host names to be dynamically generated for containers: `branch.repo.org.mytestdomain.com` - Hostname pattern specified in `.drone.yml` - Would allow external access to built projects without having the containers directly exposed - In our case this would allow Selenium Grid nodes to test projects Container persistence: - Keep containers running until pull request is closed or build is superseded - Used with hostname/port routing to - allow for manual checking of failures - allow for manual testing of pull request features/bug fixes",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file,"Hostname to container routing/Container persistence A couple of feature suggestions. They might be out of scope of the project but I thought I'd throw them out there. Hostname/Port to container routing: - Routes ports to containers - For HTTP based protocols, also route on `Host` header - Use wildcard DNS entry to allow host names to be dynamically generated for containers: `branch.repo.org.mytestdomain.com` - Hostname pattern specified in `.drone.yml` - Would allow external access to built projects without having the containers directly exposed - In our case this would allow Selenium Grid nodes to test projects Container persistence: - Keep containers running until pull request is closed or build is superseded - Used with hostname/port routing to - allow for manual checking of failures - allow for manual testing of pull request features/bug fixes other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file other-file source-file other-file other-file other-file other-file other-file",no-bug,0.9
957,harness,https://github.com/harness/harness/issues/957,Database Changes for 0.4,"This is a meta-issue that is used to describe overall data storage changes. Individual tasks will be split into a series of separate issues.  In order to facilitate matrix builds and pull requests for systems like Bitbucket and Gitlab we'll need to heavily modify our data structure. This is also a good time to re-evaluate this tier of the application and see what improvements can be made. ## Document Oriented We currently have a very flat data structure. I'd like something a bit more document oriented that allows us to store data in nested structures. Here is how we could represent the build of a Commit:  js { ""number"": 1, ""started_at"": ""2011-01-26T19:06:43Z"", ""finished_at"": ""2011-01-26T19:07:43Z"", ""duration"": 100, ""state"": ""success"", ""commit"": { ""sha"": ""c5b97d5ae6c19d5c5df71a34c7fbeeda2479ccbc"", ""ref"": ""master"", ""message"": ""Merge pull request #6 from Spaceghost/patch-1"", ""author"": { ""name"": ""The Octocat"", ""login"": ""octocat"", ""email"": ""octocat@nowhere.com"" } } }  This is how we could represent the build of a Pull Request:  js { ""number"": 1, ""started_at"": ""2011-01-26T19:06:43Z"", ""finished_at"": ""2011-01-26T19:07:43Z"", ""duration"": 100, ""state"": ""success"", ""pull_request"": { ""number"": ""6"", ""title"": ""new feature"", ""body"": ""Please pull these awesome changes"", ""source"": { ""sha"": ""c5b97d5ae6c19d5c5df71a34c7fbeeda2479ccbc"", ""ref"": ""my-feature-branch"", ""remote"": { ""clone_url"": ""https://github.com/octocat/Hello-World.git"", ""name"": ""octocat"", ""owner"": ""Hello-World"" }, ""author"": { ""name"": ""The Octocat"", ""login"": ""octocat"", ""email"": ""octocat@nowhere.com"" } }, ""target"": { ""sha"": ""6dcb09b5b57875f334f61aebed695e2e4193db5e"", ""ref"": ""master"" } } }  These align much more closely with the GitHub data structures that we receive in our post commit hooks, and play nicely with Bitbucket and Gitlab as well. Note: a pull request contains addition details such as the source repository details, which are required for cloning pull requests in systems like Bitbucket or Gitlab that don't expose the pull request as refs in the target repo. ## BoltDB In order to support a more flexible data model we'll need to switch from SQLite to BoltDB (embedded key value store). This means we can continue to ship with a high-performance, embedded database. As an added benefit BoltDB is written in Go which removes our CGO dependency. See https://github.com/boltdb/bolt ## Plugin Other Databases Some teams may prefer to use alternative databases, such as Cassandra, MongoDB, Postgres, etc. Drone will provide the ability to create database plugins to swap out implementations. This allows teams to choose the database they are most equipped to support. Note that plugins **are not** compiled into the binary. We will provide a protocol spec that will allow Drone to interop with external databases. This protocol will be defined this week (April 12 2015). The folks at Cisco Cloud are interested in contributing a Cassandra implementation, which we can probably use as a reference implementation.",source-file | source-file | source-file,"Database Changes for 0.4 This is a meta-issue that is used to describe overall data storage changes. Individual tasks will be split into a series of separate issues.  In order to facilitate matrix builds and pull requests for systems like Bitbucket and Gitlab we'll need to heavily modify our data structure. This is also a good time to re-evaluate this tier of the application and see what improvements can be made. ## Document Oriented We currently have a very flat data structure. I'd like something a bit more document oriented that allows us to store data in nested structures. Here is how we could represent the build of a Commit:  js { ""number"": 1, ""started_at"": ""2011-01-26T19:06:43Z"", ""finished_at"": ""2011-01-26T19:07:43Z"", ""duration"": 100, ""state"": ""success"", ""commit"": { ""sha"": ""c5b97d5ae6c19d5c5df71a34c7fbeeda2479ccbc"", ""ref"": ""master"", ""message"": ""Merge pull request #6 from Spaceghost/patch-1"", ""author"": { ""name"": ""The Octocat"", ""login"": ""octocat"", ""email"": ""octocat@nowhere.com"" } } }  This is how we could represent the build of a Pull Request:  js { ""number"": 1, ""started_at"": ""2011-01-26T19:06:43Z"", ""finished_at"": ""2011-01-26T19:07:43Z"", ""duration"": 100, ""state"": ""success"", ""pull_request"": { ""number"": ""6"", ""title"": ""new feature"", ""body"": ""Please pull these awesome changes"", ""source"": { ""sha"": ""c5b97d5ae6c19d5c5df71a34c7fbeeda2479ccbc"", ""ref"": ""my-feature-branch"", ""remote"": { ""clone_url"": ""https://github.com/octocat/Hello-World.git"", ""name"": ""octocat"", ""owner"": ""Hello-World"" }, ""author"": { ""name"": ""The Octocat"", ""login"": ""octocat"", ""email"": ""octocat@nowhere.com"" } }, ""target"": { ""sha"": ""6dcb09b5b57875f334f61aebed695e2e4193db5e"", ""ref"": ""master"" } } }  These align much more closely with the GitHub data structures that we receive in our post commit hooks, and play nicely with Bitbucket and Gitlab as well. Note: a pull request contains addition details such as the source repository details, which are required for cloning pull requests in systems like Bitbucket or Gitlab that don't expose the pull request as refs in the target repo. ## BoltDB In order to support a more flexible data model we'll need to switch from SQLite to BoltDB (embedded key value store). This means we can continue to ship with a high-performance, embedded database. As an added benefit BoltDB is written in Go which removes our CGO dependency. See https://github.com/boltdb/bolt ## Plugin Other Databases Some teams may prefer to use alternative databases, such as Cassandra, MongoDB, Postgres, etc. Drone will provide the ability to create database plugins to swap out implementations. This allows teams to choose the database they are most equipped to support. Note that plugins **are not** compiled into the binary. We will provide a protocol spec that will allow Drone to interop with external databases. This protocol will be defined this week (April 12 2015). The folks at Cisco Cloud are interested in contributing a Cassandra implementation, which we can probably use as a reference implementation. source-file source-file source-file",no-bug,0.95
3035,harness,https://github.com/harness/harness/issues/3035,plugins/docker How do you configure global host and let clone specify IP or domain name on the IntranetThe same cloud service bandwidth is very small Clone,plugins/docker How do you configure global host and let clone specify IP or domain name on the IntranetThe same cloud service bandwidth is very small Clone,source-file | source-file | source-file | source-file | source-file,plugins/docker How do you configure global host and let clone specify IP or domain name on the IntranetThe same cloud service bandwidth is very small Clone plugins/docker How do you configure global host and let clone specify IP or domain name on the IntranetThe same cloud service bandwidth is very small Clone source-file source-file source-file source-file source-file,no-bug,0.9
655,harness,https://github.com/harness/harness/issues/655,Deliver static files with nginx,I am planning to run an nginx instance as reverse proxy for the various applications I want to run on my server. Is it possible to serve the static files in drone via nginx or is this extra configuration effort useless?,other-file | other-file,Deliver static files with nginx I am planning to run an nginx instance as reverse proxy for the various applications I want to run on my server. Is it possible to serve the static files in drone via nginx or is this extra configuration effort useless? other-file other-file,no-bug,0.9
3370,harness,https://github.com/harness/harness/issues/3370,Dropdown Escape issue,"on clicking escape key on dropdown it close the dialog. Expected Behaviour: It should dismiss dropdown instead of dialog box <img width=""818"" alt=""Screenshot 2023-09-23 at 1 08 48 AM"" src=""https://github.com/harness/gitness/assets/114856815/435d603c-c776-4c69-8b1b-1d1f7333169c"">",container-file,"Dropdown Escape issue on clicking escape key on dropdown it close the dialog. Expected Behaviour: It should dismiss dropdown instead of dialog box <img width=""818"" alt=""Screenshot 2023-09-23 at 1 08 48 AM"" src=""https://github.com/harness/gitness/assets/114856815/435d603c-c776-4c69-8b1b-1d1f7333169c""> container-file",no-bug,0.9
2619,harness,https://github.com/harness/harness/issues/2619,Jsonnet extension not working,"I have started the Jsonnet extension as specified in https://docs.drone.io/extend/config/jsonnet/. Drone server however does not seem to connect the extension (DRONE_YAML_ENDPOINT and DRONE_YAML_SECRET are specified) and connectivity is tested to work using `nc` inside the Drone server container. Drone attempts to find the YAML but does not contact the extension:  {""commit"":""7a59cce5230cc14bb0e05b0df90f3850c3ae6008"",""error"":""Not Found"",""event"":""push"",""level"":""warning"",""msg"":""trigger: cannot find yaml"",""ref"":""refs/heads/test"",""repo"":""xxx/xxx"",""time"":""2019-03-04T08:30:34+02:00""}  Tested with `1.0.0-rc.5` and `latest`.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file,"Jsonnet extension not working I have started the Jsonnet extension as specified in https://docs.drone.io/extend/config/jsonnet/. Drone server however does not seem to connect the extension (DRONE_YAML_ENDPOINT and DRONE_YAML_SECRET are specified) and connectivity is tested to work using `nc` inside the Drone server container. Drone attempts to find the YAML but does not contact the extension:  {""commit"":""7a59cce5230cc14bb0e05b0df90f3850c3ae6008"",""error"":""Not Found"",""event"":""push"",""level"":""warning"",""msg"":""trigger: cannot find yaml"",""ref"":""refs/heads/test"",""repo"":""xxx/xxx"",""time"":""2019-03-04T08:30:34+02:00""}  Tested with `1.0.0-rc.5` and `latest`. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file",no-bug,0.9
210,harness,https://github.com/harness/harness/issues/210,Can't login to Drone,"I did a fresh install via deb package and ran thru the installer, created a admin account. afterwards I restarted drone service and now I can't login with my admin account and ""Forgot Password"" button isn't working.",source-file | source-file | source-file | source-file | source-file | source-file,"Can't login to Drone I did a fresh install via deb package and ran thru the installer, created a admin account. afterwards I restarted drone service and now I can't login with my admin account and ""Forgot Password"" button isn't working. source-file source-file source-file source-file source-file source-file",no-bug,0.8
214,harness,https://github.com/harness/harness/issues/214,Godoc package documentation strings,"Trying to get a sense of the drone codebase, the lack of package-level docstrings makes navigating much harder than it would otherwise be. E.G. http://godoc.org/github.com/drone/drone vs http://godoc.org/code.google.com/p/go.net",source-file | source-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | documentation-file,"Godoc package documentation strings Trying to get a sense of the drone codebase, the lack of package-level docstrings makes navigating much harder than it would otherwise be. E.G. http://godoc.org/github.com/drone/drone vs http://godoc.org/code.google.com/p/go.net source-file source-file database-file database-file source-file source-file source-file source-file source-file other-file other-file documentation-file",no-bug,0.95
2496,harness,https://github.com/harness/harness/issues/2496,"Add custom command into ""when:"" property for runtime-decision of stage execution","It would be very nice if we had an opportunity to detect whether to execute some stage at the runtime, like, we don't check the code if it was not changed (talking about rust and `cargo clippy`): yaml cargo-clippy: when: command: <any custom command here>  This would help a lot to not waste CI's time doing useless stuff like checking already checked code or doing anything else which is not needed due to some reason.",source-file | source-file | source-file | source-file | source-file,"Add custom command into ""when:"" property for runtime-decision of stage execution It would be very nice if we had an opportunity to detect whether to execute some stage at the runtime, like, we don't check the code if it was not changed (talking about rust and `cargo clippy`): yaml cargo-clippy: when: command: <any custom command here>  This would help a lot to not waste CI's time doing useless stuff like checking already checked code or doing anything else which is not needed due to some reason. source-file source-file source-file source-file source-file",no-bug,0.9
419,harness,https://github.com/harness/harness/issues/419,RPMs,"I'd love it if you shipped RPMs as well as debs; `alien` is an ok stopgap, but ""official"" RPMs would be great please!",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"RPMs I'd love it if you shipped RPMs as well as debs; `alien` is an ok stopgap, but ""official"" RPMs would be great please! source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
439,harness,https://github.com/harness/harness/issues/439,GitHub Release Plugin,We've started to do more and more publishing of (mostly Go binaries) via Github releases. Right now the process is `make release` to put a bunch of release artifacts in a folder (e.g. `release/`) and then run a script that creates a Github release and uploads the contents of this directory. I think we could turn this into a fairly generic drone publish plugin. Configuration options: - `script`: list of commands (or a single command?) to run to build a release - `dir`: directory to find release artifacts after script is run - `token`: Github token to use to interact with the Releases API. - `version_file`: defaults to VERSION at the root of the repository - `branch`: restrict to this branch Example: if we were etcd and we wanted to produce their releases (https://github.com/coreos/etcd/releases) the config would look like:  publish: github: script: scripts/build_release dir: release  Thoughts?,other-file | other-file | other-file | other-file,GitHub Release Plugin We've started to do more and more publishing of (mostly Go binaries) via Github releases. Right now the process is `make release` to put a bunch of release artifacts in a folder (e.g. `release/`) and then run a script that creates a Github release and uploads the contents of this directory. I think we could turn this into a fairly generic drone publish plugin. Configuration options: - `script`: list of commands (or a single command?) to run to build a release - `dir`: directory to find release artifacts after script is run - `token`: Github token to use to interact with the Releases API. - `version_file`: defaults to VERSION at the root of the repository - `branch`: restrict to this branch Example: if we were etcd and we wanted to produce their releases (https://github.com/coreos/etcd/releases) the config would look like:  publish: github: script: scripts/build_release dir: release  Thoughts? other-file other-file other-file other-file,no-bug,0.95
95,harness,https://github.com/harness/harness/issues/95,Additional Security Measures for Login,"Since drone needs to accept git hooks from github, it needs to be exposed on the public internet. It'd be nice if there were some protections on the login page: - Two-factor auth - Captcha after incorrect attempts originating from same IP or against same username - IP whitelisting",source-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | documentation-file | source-file | source-file | source-file | test-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | documentation-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file,"Additional Security Measures for Login Since drone needs to accept git hooks from github, it needs to be exposed on the public internet. It'd be nice if there were some protections on the login page: - Two-factor auth - Captcha after incorrect attempts originating from same IP or against same username - IP whitelisting source-file other-file other-file other-file other-file other-file source-file source-file source-file source-file documentation-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file other-file documentation-file source-file source-file source-file test-file other-file source-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file source-file source-file source-file documentation-file other-file other-file other-file source-file other-file other-file other-file other-file",no-bug,0.9
619,harness,https://github.com/harness/harness/issues/619,"Dependency to ""git""","hi, i used a docker image which did not contain `git`. But it looks like you're generating a `Dockerfile` which is based on my image given in `.drone.yml`. In this Dockerfile you're executing a `drone` script which contains the `git clone ` this does not work as there is no ""git"" command in my docker image. now i added `git` to my base image, but it would be better to first clone the repository and then mounting this data to the new image. i think there should be no dependency to specific commands in the docker image. </usc>",source-file | documentation-file | other-file | other-file | source-file,"Dependency to ""git"" hi, i used a docker image which did not contain `git`. But it looks like you're generating a `Dockerfile` which is based on my image given in `.drone.yml`. In this Dockerfile you're executing a `drone` script which contains the `git clone ` this does not work as there is no ""git"" command in my docker image. now i added `git` to my base image, but it would be better to first clone the repository and then mounting this data to the new image. i think there should be no dependency to specific commands in the docker image. </usc> source-file documentation-file other-file other-file source-file",no-bug,0.9
643,harness,https://github.com/harness/harness/issues/643,401 (Unauthorized) /api/user,"I'm following the basic instructions for getting Drone up and running locally in an Ubuntu virtual machine. I manage to get to http://localhost:8080/install, but see nothing but the top bar with a link to /login, along with an HTTP error 401 when trying to access /api/user. When I click the login button I'm instructed to read the setup guide. I followed this guide once before and it seemed outdated. I feel like I'm probably just missing something. Is there a stable version of Drone that corresponds exactly to a setup and install guide? I feel like the package version available at http://downloads.drone.io/master/drone.deb should always correspond exactly to the instructions at http://drone.readthedocs.org/en/latest/install.html. Though, it seems the .deb is the latest 0.3-dev version.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file | documentation-file,"401 (Unauthorized) /api/user I'm following the basic instructions for getting Drone up and running locally in an Ubuntu virtual machine. I manage to get to http://localhost:8080/install, but see nothing but the top bar with a link to /login, along with an HTTP error 401 when trying to access /api/user. When I click the login button I'm instructed to read the setup guide. I followed this guide once before and it seemed outdated. I feel like I'm probably just missing something. Is there a stable version of Drone that corresponds exactly to a setup and install guide? I feel like the package version available at http://downloads.drone.io/master/drone.deb should always correspond exactly to the instructions at http://drone.readthedocs.org/en/latest/install.html. Though, it seems the .deb is the latest 0.3-dev version. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file documentation-file other-file other-file documentation-file",no-bug,0.8
323,harness,https://github.com/harness/harness/issues/323,PhantomJS Upgrade from 1.8.1 to 1.9.7,"PhantomJS 1.8.1 seems to be the latest version available for drone's Ubuntu, but causes `Error: Unknown option: webdriver-logfile` for Selenium 2.42.0 tests. Can PhantomJS be upgraded to 1.9.7 (or 1.9.7 be included as the default)?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"PhantomJS Upgrade from 1.8.1 to 1.9.7 PhantomJS 1.8.1 seems to be the latest version available for drone's Ubuntu, but causes `Error: Unknown option: webdriver-logfile` for Selenium 2.42.0 tests. Can PhantomJS be upgraded to 1.9.7 (or 1.9.7 be included as the default)? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2044,harness,https://github.com/harness/harness/issues/2044,submodule_override option doesn't work to subdirectory more.,"This setting worked in version `0.5` but no longer works in version `0.6`: yaml pipeline: clone: image: plugins/git recursive: true submodule_override: ""submodules/proto"": https://github.com/cicerocomp/proto.git  I tried this too: yaml pipeline: clone: image: plugins/git recursive: true submodule_override: submodules/proto: https://github.com/cicerocomp/proto.git  OUTPUT ERROR:  + git init Initialized empty Git repository in /go2/src/github.com/cicerocomp/this/.git/ + git remote add origin https://github.com/cicerocomp/this.git + git fetch --no-tags origin +refs/heads/development: From https://github.com/cicerocomp/this * branch development -> FETCH_HEAD * [new branch] development -> origin/development + git reset --hard -q 566b2d3db6e9abdb66cff190bc5ce647d142b3e3 + git submodule update --init --recursive Submodule 'submodules/proto' (git@github.com:cicerocomp/proto.git) registered for path 'submodules/proto' Cloning into '/go2/src/github.com/cicerocomp/this/submodules/proto' Host key verification failed. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. fatal: clone of 'git@github.com:cicerocomp/proto.git' into submodule path '/go2/src/github.com/cicerocomp/this/submodules/proto' failed exit status 128 ",source-file | other-file | other-file | source-file,"submodule_override option doesn't work to subdirectory more. This setting worked in version `0.5` but no longer works in version `0.6`: yaml pipeline: clone: image: plugins/git recursive: true submodule_override: ""submodules/proto"": https://github.com/cicerocomp/proto.git  I tried this too: yaml pipeline: clone: image: plugins/git recursive: true submodule_override: submodules/proto: https://github.com/cicerocomp/proto.git  OUTPUT ERROR:  + git init Initialized empty Git repository in /go2/src/github.com/cicerocomp/this/.git/ + git remote add origin https://github.com/cicerocomp/this.git + git fetch --no-tags origin +refs/heads/development: From https://github.com/cicerocomp/this * branch development -> FETCH_HEAD * [new branch] development -> origin/development + git reset --hard -q 566b2d3db6e9abdb66cff190bc5ce647d142b3e3 + git submodule update --init --recursive Submodule 'submodules/proto' (git@github.com:cicerocomp/proto.git) registered for path 'submodules/proto' Cloning into '/go2/src/github.com/cicerocomp/this/submodules/proto' Host key verification failed. fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. fatal: clone of 'git@github.com:cicerocomp/proto.git' into submodule path '/go2/src/github.com/cicerocomp/this/submodules/proto' failed exit status 128  source-file other-file other-file source-file",no-bug,0.9
1180,harness,https://github.com/harness/harness/issues/1180,Force pull image is slow without `:latest`,"When pulling an image we should check for a tag. If not exists, append `:latest`",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Force pull image is slow without `:latest` When pulling an image we should check for a tag. If not exists, append `:latest` source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
1136,harness,https://github.com/harness/harness/issues/1136,0.4 don't work build,"remote - gitlab run like  git pull origin 0.4-database && make all sudo DOCKER_HOST=""unix:var/run/docker.sock"" SERVER_ADDR="":8084"" REMOTE_DRIVER=""gitlab"" REMOTE_CONFIG=""http://gitlab.local/?client_id={client}&client_secret={sec}"" ./bin/drone  .drone.yml  build: image: golang commands: - go get - go build - go test  error log  panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0x0 pc=0x404241] goroutine 16 [running]: runtime.panic(0x706920, 0x8f7f73) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 main.createClone(0xc20804c200, 0x0, 0x0) /home/brad/gocode/src/github.com/drone/drone/cmd/drone-build/main.go:119 +0x411 main.main() /home/brad/gocode/src/github.com/drone/drone/cmd/drone-build/main.go:40 +0x18a goroutine 17 [runnable]: runtime.MHeap_Scavenger() /usr/local/go/src/pkg/runtime/mheap.c:507 runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 18 [runnable]: bgsweep() /usr/local/go/src/pkg/runtime/mgc0.c:1976 runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 19 [runnable]: runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2606 runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445  ![image](https://cloud.githubusercontent.com/assets/1614346/9268815/6a5c2b56-426b-11e5-90cb-9b2dd2d5a462.png)",other-file | source-file | documentation-file,"0.4 don't work build remote - gitlab run like  git pull origin 0.4-database && make all sudo DOCKER_HOST=""unix:var/run/docker.sock"" SERVER_ADDR="":8084"" REMOTE_DRIVER=""gitlab"" REMOTE_CONFIG=""http://gitlab.local/?client_id={client}&client_secret={sec}"" ./bin/drone  .drone.yml  build: image: golang commands: - go get - go build - go test  error log  panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0x0 pc=0x404241] goroutine 16 [running]: runtime.panic(0x706920, 0x8f7f73) /usr/local/go/src/pkg/runtime/panic.c:279 +0xf5 main.createClone(0xc20804c200, 0x0, 0x0) /home/brad/gocode/src/github.com/drone/drone/cmd/drone-build/main.go:119 +0x411 main.main() /home/brad/gocode/src/github.com/drone/drone/cmd/drone-build/main.go:40 +0x18a goroutine 17 [runnable]: runtime.MHeap_Scavenger() /usr/local/go/src/pkg/runtime/mheap.c:507 runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 18 [runnable]: bgsweep() /usr/local/go/src/pkg/runtime/mgc0.c:1976 runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445 goroutine 19 [runnable]: runfinq() /usr/local/go/src/pkg/runtime/mgc0.c:2606 runtime.goexit() /usr/local/go/src/pkg/runtime/proc.c:1445  ![image](https://cloud.githubusercontent.com/assets/1614346/9268815/6a5c2b56-426b-11e5-90cb-9b2dd2d5a462.png) other-file source-file documentation-file",no-bug,0.9
365,harness,https://github.com/harness/harness/issues/365,Drone status on Github doesn't show when build is pending,"If a build has status 'pending' on Drone, Github does not show any information about Drone status in the PR view: http://cl.ly/image/0Z2d26362X2x. When the build is running (status 'started'), it shows a message that the build is pending on Drone: http://cl.ly/image/1J2R1t173J0i. This message should be shown when the build is pending as well.",documentation-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | source-file | other-file,"Drone status on Github doesn't show when build is pending If a build has status 'pending' on Drone, Github does not show any information about Drone status in the PR view: http://cl.ly/image/0Z2d26362X2x. When the build is running (status 'started'), it shows a message that the build is pending on Drone: http://cl.ly/image/1J2R1t173J0i. This message should be shown when the build is pending as well. documentation-file other-file other-file other-file source-file other-file other-file source-file documentation-file other-file other-file other-file source-file other-file",no-bug,0.8
2901,harness,https://github.com/harness/harness/issues/2901,Running and targeting multiple runners,"Hi, I already have one exec runner (ER-1) running on one machine connected to drone server (DS-A). Now I want another exec runner (ER-2) to be run on another machine. And I want certain .drone.yml files to target ER-1 and others to target ER-2. My questions: 1. Is it possible to run multiple exec runners on separate machines connected to DS-A 2. If Yes, then how can I tell repositories (via .drone.yml) to target specific runner? Thanks",source-file | other-file | other-file | documentation-file | source-file | source-file,"Running and targeting multiple runners Hi, I already have one exec runner (ER-1) running on one machine connected to drone server (DS-A). Now I want another exec runner (ER-2) to be run on another machine. And I want certain .drone.yml files to target ER-1 and others to target ER-2. My questions: 1. Is it possible to run multiple exec runners on separate machines connected to DS-A 2. If Yes, then how can I tell repositories (via .drone.yml) to target specific runner? Thanks source-file other-file other-file documentation-file source-file source-file",no-bug,0.9
1014,harness,https://github.com/harness/harness/issues/1014,Modify user permissions from /admin/users,"I recently got the self hosted drone running and we have a few administrative members on our team. I can't seem to find any way in the UI to modify user permissions. I ended up having to manually change the `user_admin` attribute in the db to allow them to see the settings button. The page itself wasn't restricted to only admins, though less data was shown without the admin flag. ![image](https://cloud.githubusercontent.com/assets/1580651/7618391/aea7afe0-f966-11e4-9faa-6b0528a71716.png) I think it would be useful to allow user permissions to be modified on the `/admin/users/:scope/:user` page. ![image](https://cloud.githubusercontent.com/assets/1580651/7618473/36590a7e-f967-11e4-8cc8-06ce803f425c.png)",source-file,"Modify user permissions from /admin/users I recently got the self hosted drone running and we have a few administrative members on our team. I can't seem to find any way in the UI to modify user permissions. I ended up having to manually change the `user_admin` attribute in the db to allow them to see the settings button. The page itself wasn't restricted to only admins, though less data was shown without the admin flag. ![image](https://cloud.githubusercontent.com/assets/1580651/7618391/aea7afe0-f966-11e4-9faa-6b0528a71716.png) I think it would be useful to allow user permissions to be modified on the `/admin/users/:scope/:user` page. ![image](https://cloud.githubusercontent.com/assets/1580651/7618473/36590a7e-f967-11e4-8cc8-06ce803f425c.png) source-file",no-bug,0.8
2300,harness,https://github.com/harness/harness/issues/2300,Let's encrypt tls-sni challenge,Due to https://community.letsencrypt.org/t/2018-01-11-update-regarding-acme-tls-sni-and-shared-hosting-infrastructure/50188 New accounts won't be able to use lets encrypt with the current tls-sni and also won't work in drone until it's migrated to http-01 challenge Also related https://github.com/golang/go/issues/21890,source-file | source-file | source-file | source-file,Let's encrypt tls-sni challenge Due to https://community.letsencrypt.org/t/2018-01-11-update-regarding-acme-tls-sni-and-shared-hosting-infrastructure/50188 New accounts won't be able to use lets encrypt with the current tls-sni and also won't work in drone until it's migrated to http-01 challenge Also related https://github.com/golang/go/issues/21890 source-file source-file source-file source-file,no-bug,0.9
2075,harness,https://github.com/harness/harness/issues/2075,Different workspace behaviour on agents and with drone exec,"Not sure if this issue should be here, or rather be discussed in the cli repository - please let me know if I should move it. I've noticed, that when running `drone exec` there will be no temporary volume created for `workspace`. This leads to different behaviour on the agent and with drone exec: On the agent: - the folder `/workspace` will stay persistent between builds Locally: - `/workspace` is not persistent between steps Scenario where this is relevant: I have a pipeline, where I test modules for an application. That application expects these modules to be place in a specific directory (`/application/modules/<mymodule>`) otherwise they can't be tested within the application framework. With the following definition for workspace+path I am able to accomplish this when running my builds on an agent:  workspace: base: /workspace path: application/modules/mymodule pipeline: prepare: image:  commands: - cp -r /application /workspace/application test: image:  commands: - run_tests   The contents created at `/workspace/application` will persist between further drone steps (when run on an agent). However locally, this is not the case. When comparing both execution flows, I realized that drone exec only mounts the current folder to workspace+path, but does not create a volume for `/workspace` When using `drone exec --volumes ""workspace:/workspace""` the behaviour would be the same as when run on an agent. Simple yaml to reproduce the effect:  workspace: base: /workspace path: application/modules/mymodule pipeline: step1: image: alpine commands: - touch /workspace/hello - ls /workspace step2: image: alpine commands: - ls /workspace  Proposal: Also create a workspace volume when running locally",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file,"Different workspace behaviour on agents and with drone exec Not sure if this issue should be here, or rather be discussed in the cli repository - please let me know if I should move it. I've noticed, that when running `drone exec` there will be no temporary volume created for `workspace`. This leads to different behaviour on the agent and with drone exec: On the agent: - the folder `/workspace` will stay persistent between builds Locally: - `/workspace` is not persistent between steps Scenario where this is relevant: I have a pipeline, where I test modules for an application. That application expects these modules to be place in a specific directory (`/application/modules/<mymodule>`) otherwise they can't be tested within the application framework. With the following definition for workspace+path I am able to accomplish this when running my builds on an agent:  workspace: base: /workspace path: application/modules/mymodule pipeline: prepare: image:  commands: - cp -r /application /workspace/application test: image:  commands: - run_tests   The contents created at `/workspace/application` will persist between further drone steps (when run on an agent). However locally, this is not the case. When comparing both execution flows, I realized that drone exec only mounts the current folder to workspace+path, but does not create a volume for `/workspace` When using `drone exec --volumes ""workspace:/workspace""` the behaviour would be the same as when run on an agent. Simple yaml to reproduce the effect:  workspace: base: /workspace path: application/modules/mymodule pipeline: step1: image: alpine commands: - touch /workspace/hello - ls /workspace step2: image: alpine commands: - ls /workspace  Proposal: Also create a workspace volume when running locally other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file",no-bug,0.9
620,harness,https://github.com/harness/harness/issues/620,`drone enable` command fails to update key if exists,Now with the tokens it is not even possible anymore to guess the correct hook URL. A button somewhere in the settings to re-activate a repo is needed.,source-file | documentation-file,`drone enable` command fails to update key if exists Now with the tokens it is not even possible anymore to guess the correct hook URL. A button somewhere in the settings to re-activate a repo is needed. source-file documentation-file,no-bug,0.7
168,harness,https://github.com/harness/harness/issues/168,32-bit support?,"This is just a question, not a feature request, but why is drone only available for 64-bit archs?",source-file | source-file | source-file | source-file | other-file,"32-bit support? This is just a question, not a feature request, but why is drone only available for 64-bit archs? source-file source-file source-file source-file other-file",no-bug,0.9
769,harness,https://github.com/harness/harness/issues/769,Build in PHP server not accessable when starting it with the drone script,"I'm trying to start the build in PHP server to run my acceptance tests. My reason is that it's a lot easier than to setup a nginx or apache. The problem I'm having is that I can't seem to access it. When drone sets it up in docker. It seems that I need to tell drone to open the `8888` port or something. When I do `netstat` I also can see that it's listening to any commands.  netstat -tulpn Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 75/socat  So I check the processes it is running.  ubuntu 191 0.0 0.0 47004 2272 ? R 18:52 0:00 php -S localhost:8888 -t public  Also when I start the container itself and ssh into it with the following command:  docker run -i -t bradrydzewski/php:5.5 /bin/bash  And run the PHP build-in server everything seems to work correctly. I think it has to so with the way drone runs the commands in the `.drone.yml` that the build-in webserver does not work. The issue I'm having is that I just can't get it to work correctly so I'm hoping there is a way to solve this issue. My script if the following,  image: bradrydzewski/php:5.5 script: - php -S localhost:8888 -t public > /dev/null 2>&1 & services: - mysql:5.5 ",source-file,"Build in PHP server not accessable when starting it with the drone script I'm trying to start the build in PHP server to run my acceptance tests. My reason is that it's a lot easier than to setup a nginx or apache. The problem I'm having is that I can't seem to access it. When drone sets it up in docker. It seems that I need to tell drone to open the `8888` port or something. When I do `netstat` I also can see that it's listening to any commands.  netstat -tulpn Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 75/socat  So I check the processes it is running.  ubuntu 191 0.0 0.0 47004 2272 ? R 18:52 0:00 php -S localhost:8888 -t public  Also when I start the container itself and ssh into it with the following command:  docker run -i -t bradrydzewski/php:5.5 /bin/bash  And run the PHP build-in server everything seems to work correctly. I think it has to so with the way drone runs the commands in the `.drone.yml` that the build-in webserver does not work. The issue I'm having is that I just can't get it to work correctly so I'm hoping there is a way to solve this issue. My script if the following,  image: bradrydzewski/php:5.5 script: - php -S localhost:8888 -t public > /dev/null 2>&1 & services: - mysql:5.5  source-file",no-bug,0.9
341,harness,https://github.com/harness/harness/issues/341,Hung Jobs,"So, I've updated to latest drone and noticed that I still have jobs that hang at this point or take 20+hours to complete. Warning: Permanently added 'github.com,192.30.252.130' (RSA) to the list of known hosts. I've also noticed that there are several features missing from the open-source version compared to the Hosted drone.ci, like ""Build"" button and deploy feature. Is that on purpose?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Hung Jobs So, I've updated to latest drone and noticed that I still have jobs that hang at this point or take 20+hours to complete. Warning: Permanently added 'github.com,192.30.252.130' (RSA) to the list of known hosts. I've also noticed that there are several features missing from the open-source version compared to the Hosted drone.ci, like ""Build"" button and deploy feature. Is that on purpose? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
370,harness,https://github.com/harness/harness/issues/370,Incorrectly formatted .drone.yml will cause the individual commit page to load over and over again,"I had `{token}}` instead of `{{token}}` in my `.drone.yml`. This manifested itself in a weird way, which is that the individual commit page reloaded over and over when I viewed it. I fixed the missing opening curly brace and the page doesn't reload every second or so anymore. Seems like there needs to be some better validation of the configuration file.",documentation-file | documentation-file,"Incorrectly formatted .drone.yml will cause the individual commit page to load over and over again I had `{token}}` instead of `{{token}}` in my `.drone.yml`. This manifested itself in a weird way, which is that the individual commit page reloaded over and over when I viewed it. I fixed the missing opening curly brace and the page doesn't reload every second or so anymore. Seems like there needs to be some better validation of the configuration file. documentation-file documentation-file",no-bug,0.9
2231,harness,https://github.com/harness/harness/issues/2231,Vault Environment Variables,"We are currently using the [`DefaultConfig`](https://godoc.org/github.com/hashicorp/vault/api#DefaultConfig) function when loading vault credentials and configuration setting. This will load the address and token, but will not apply any other configuration setting. We should instead remove `DefaultConfig` and pass a nil configuration to the vault client. When vault encounters a nil configuration, it will read from the environment automatically, including all parameters. Reference vault code: https://github.com/hashicorp/vault/blob/master/api/client.go#L253:L259 cc @eriklincoln",container-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Vault Environment Variables We are currently using the [`DefaultConfig`](https://godoc.org/github.com/hashicorp/vault/api#DefaultConfig) function when loading vault credentials and configuration setting. This will load the address and token, but will not apply any other configuration setting. We should instead remove `DefaultConfig` and pass a nil configuration to the vault client. When vault encounters a nil configuration, it will read from the environment automatically, including all parameters. Reference vault code: https://github.com/hashicorp/vault/blob/master/api/client.go#L253:L259 cc @eriklincoln container-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
174,harness,https://github.com/harness/harness/issues/174,-path option has no effect,I can't see it being used in the source either. sqlite file is always in current working directory.,source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | documentation-file | other-file | source-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | documentation-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | source-file | other-file,-path option has no effect I can't see it being used in the source either. sqlite file is always in current working directory. source-file source-file source-file source-file documentation-file source-file source-file source-file documentation-file other-file source-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file source-file source-file source-file documentation-file other-file other-file other-file source-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file source-file source-file other-file,no-bug,0.8
3524,harness,https://github.com/harness/harness/issues/3524,Gitness Integration with Open Source Dev Environment Manager.,"Hi, I am working on project. I want to add support for gitness to be added as git-provider. I am facing one small problem where I need to fetch Organizations via API. I have checked all swagger APIs. but did not find useful. I don't even know does gitness support Organizations like github? Can anyone tell me how do I fetch Organizations via API?",source-file | source-file,"Gitness Integration with Open Source Dev Environment Manager. Hi, I am working on project. I want to add support for gitness to be added as git-provider. I am facing one small problem where I need to fetch Organizations via API. I have checked all swagger APIs. but did not find useful. I don't even know does gitness support Organizations like github? Can anyone tell me how do I fetch Organizations via API? source-file source-file",no-bug,0.9
2678,harness,https://github.com/harness/harness/issues/2678,agent does not always gracefully shut down,"Watchtower (utility to auto-upgrade Docker images) is not properly stopping the Agent on upgrade, which causes stuck builds. The root cause is unknown and requires more research. Hopefully it is something simple ",other-file,"agent does not always gracefully shut down Watchtower (utility to auto-upgrade Docker images) is not properly stopping the Agent on upgrade, which causes stuck builds. The root cause is unknown and requires more research. Hopefully it is something simple  other-file",no-bug,0.9
3404,harness,https://github.com/harness/harness/issues/3404,Unable to import repository from GOGS,"I too am unable to import a repo, internally hosted on an old GOGS implementation ( Gogs Version: 0.11.91.0811) The URL is 'http://aurowgit01.rbc.int:3000/mwoodward/Ansible' (also tried appending .git but does not work either) I get 'Invalid GitHub or GitLab URL' I have 'requires auth' ticked and username/password entered.",test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | other-file | other-file | other-file | other-file | test-file | other-file | other-file | other-file | source-file | other-file,"Unable to import repository from GOGS I too am unable to import a repo, internally hosted on an old GOGS implementation ( Gogs Version: 0.11.91.0811) The URL is 'http://aurowgit01.rbc.int:3000/mwoodward/Ansible' (also tried appending .git but does not work either) I get 'Invalid GitHub or GitLab URL' I have 'requires auth' ticked and username/password entered. test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file other-file other-file other-file other-file test-file other-file other-file other-file source-file other-file",no-bug,0.9
2810,harness,https://github.com/harness/harness/issues/2810,Git SSL certificate problem: unable to get local issuer certificate,"unable to access 'https://gitlab.XXXXXX.com/marvinpan/drone-ci-demo.git/': SSL certificate problem: unable to get local issuer certificate? I use container drone/drone:1.3.1-linux-amd64,and run in kubernetes mode: the ENV as below, can you help me?  - name: DRONE_KUBERNETES_ENABLED value: ""true"" - name: DRONE_KUBERNETES_NAMESPACE value: drone - name: DRONE_GITLAB_SERVER value: https://gitlab.xxxx.net - name: DRONE_GITLAB_CLIENT_ID value: XXXX - name: DRONE_GITLAB_CLIENT_SECRET value: XXXXX - name: DRONE_GITLAB_SKIP_VERIFY value: ""true"" - name: DRONE_SERVER_HOST value: drone.xxxx.domain - name: DRONE_SERVER_PROTO value: https - name: DRONE_DATABASE_DRIVER value: sqlite3 - name: DRONE_DATABASE_DATASOURCE value: ""/data/database.sqlite"" - name: DRONE_USER_CREATE value: username:root,admin:true - name: DRONE_SECRET_SECRET value: XXXX - name: DRONE_SECRET_ENDPOINT value: http://drone-secrets-service - name: DRONE_RPC_SECRET value: XXXX - name: DRONE_RPC_HOST value: drone-server-service - name: DRONE_RPC_PROTO value: http - name: DRONE_RPC_DEBUG value: ""true"" - name: DRONE_LOGS_TRACE value: ""true"" - name: DRONE_LOGS_DEBUG value: ""true"" - name: DRONE_LOGS_COLOR value: ""true"" - name: DRONE_LOGS_PRETTY value: ""true"" - name: DRONE_LOGS_TEXT value: ""true"" - name: DRONE_RUNNER_IMAGE value: drone/controller:1.3.1-linux-amd64 - name: DRONE_DATADOG_ENABLED value: ""false"" - name: DRONE_GITLAB_DEBUG value: ""true"" - name: DRONE_REGISTRIES_SKIPVERIFY value: ""true"" ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Git SSL certificate problem: unable to get local issuer certificate unable to access 'https://gitlab.XXXXXX.com/marvinpan/drone-ci-demo.git/': SSL certificate problem: unable to get local issuer certificate? I use container drone/drone:1.3.1-linux-amd64,and run in kubernetes mode: the ENV as below, can you help me?  - name: DRONE_KUBERNETES_ENABLED value: ""true"" - name: DRONE_KUBERNETES_NAMESPACE value: drone - name: DRONE_GITLAB_SERVER value: https://gitlab.xxxx.net - name: DRONE_GITLAB_CLIENT_ID value: XXXX - name: DRONE_GITLAB_CLIENT_SECRET value: XXXXX - name: DRONE_GITLAB_SKIP_VERIFY value: ""true"" - name: DRONE_SERVER_HOST value: drone.xxxx.domain - name: DRONE_SERVER_PROTO value: https - name: DRONE_DATABASE_DRIVER value: sqlite3 - name: DRONE_DATABASE_DATASOURCE value: ""/data/database.sqlite"" - name: DRONE_USER_CREATE value: username:root,admin:true - name: DRONE_SECRET_SECRET value: XXXX - name: DRONE_SECRET_ENDPOINT value: http://drone-secrets-service - name: DRONE_RPC_SECRET value: XXXX - name: DRONE_RPC_HOST value: drone-server-service - name: DRONE_RPC_PROTO value: http - name: DRONE_RPC_DEBUG value: ""true"" - name: DRONE_LOGS_TRACE value: ""true"" - name: DRONE_LOGS_DEBUG value: ""true"" - name: DRONE_LOGS_COLOR value: ""true"" - name: DRONE_LOGS_PRETTY value: ""true"" - name: DRONE_LOGS_TEXT value: ""true"" - name: DRONE_RUNNER_IMAGE value: drone/controller:1.3.1-linux-amd64 - name: DRONE_DATADOG_ENABLED value: ""false"" - name: DRONE_GITLAB_DEBUG value: ""true"" - name: DRONE_REGISTRIES_SKIPVERIFY value: ""true""  source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2132,harness,https://github.com/harness/harness/issues/2132,Ability to use default bridge for pipeline network,We should give the ability to use the default `bridge` network. With 0.6 we started creating a new bridge network for each build (similar to docker-compose) however this appears to be problematic for some setups that use custom network drivers.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file,Ability to use default bridge for pipeline network We should give the ability to use the default `bridge` network. With 0.6 we started creating a new bridge network for each build (similar to docker-compose) however this appears to be problematic for some setups that use custom network drivers. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file,no-bug,0.8
2803,harness,https://github.com/harness/harness/issues/2803,Editable environment variables,"Currenttly, there is only secret variable management, that are cumbersome to update because it takes an extra build that exposes the variable and prints it out to get the current value. This feature request proposes to add CI-stored non-secret environment variables that would be editable: ![2019-08-27-082239_519x83_scrot](https://user-images.githubusercontent.com/94636/63746064-23a94b80-c8a4-11e9-9d4e-f17a68f5fc69.png) By editable, I mean easy to consult and update, in contrast with the burden of editing secrets which requires to circumvent the security in place as administrator.",other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file | source-file | source-file | other-file,"Editable environment variables Currenttly, there is only secret variable management, that are cumbersome to update because it takes an extra build that exposes the variable and prints it out to get the current value. This feature request proposes to add CI-stored non-secret environment variables that would be editable: ![2019-08-27-082239_519x83_scrot](https://user-images.githubusercontent.com/94636/63746064-23a94b80-c8a4-11e9-9d4e-f17a68f5fc69.png) By editable, I mean easy to consult and update, in contrast with the burden of editing secrets which requires to circumvent the security in place as administrator. other-file other-file source-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file documentation-file source-file source-file other-file",no-bug,0.9
524,harness,https://github.com/harness/harness/issues/524,Audit and coverage,"Is it possible to grab any audit/coverage results for build, and show it after build?",other-file | other-file | source-file | source-file | source-file,"Audit and coverage Is it possible to grab any audit/coverage results for build, and show it after build? other-file other-file source-file source-file source-file",no-bug,0.9
2766,harness,https://github.com/harness/harness/issues/2766,Github usernames case sensitivity,"Not sure how github handles usernames, but I seem to get logged in als ""Niondir"" in drone but in an earlier version it was ""niondir"". Now my admin permissions were missing, I just found out by looking into the database. If usernames on github are not case-sensitive, you should sanitize them in the database.",source-file | source-file | source-file | source-file | source-file | source-file,"Github usernames case sensitivity Not sure how github handles usernames, but I seem to get logged in als ""Niondir"" in drone but in an earlier version it was ""niondir"". Now my admin permissions were missing, I just found out by looking into the database. If usernames on github are not case-sensitive, you should sanitize them in the database. source-file source-file source-file source-file source-file source-file",bug,0.85
2882,harness,https://github.com/harness/harness/issues/2882,Incorrect working directory when using kubernetes runner," Warning Failed 52s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 52s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 37s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Normal Pulling 37s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Warning Failed 37s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulled 33s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 33s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 33s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 31s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 31s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 31s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 29s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 29s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 29s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 23s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 23s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 23s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 19s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 19s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 19s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 17s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 17s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 17s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1""  I have following in .drone.yml:  workspace: base: /go path: src/github.company.com/kaas/kapi  The build does not start",source-file | other-file | other-file | other-file | test-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | documentation-file,"Incorrect working directory when using kubernetes runner  Warning Failed 52s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 52s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 37s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Normal Pulling 37s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Warning Failed 37s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulled 33s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 33s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 33s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 31s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 31s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 31s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 29s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 29s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 29s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 23s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 23s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 23s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 19s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 19s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 19s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1"" Normal Pulled 17s kubelet, nodes-z1-1-drone-k8s-local Successfully pulled image ""drone/placeholder:1"" Warning Failed 17s kubelet, nodes-z1-1-drone-k8s-local Error: Error response from daemon: the working directory 'src/github.company.com/kaas/kapi' is invalid, it needs to be an absolute path Normal Pulling 17s kubelet, nodes-z1-1-drone-k8s-local Pulling image ""drone/placeholder:1""  I have following in .drone.yml:  workspace: base: /go path: src/github.company.com/kaas/kapi  The build does not start source-file other-file other-file other-file test-file other-file source-file other-file other-file other-file other-file other-file other-file other-file documentation-file",no-bug,0.9
348,harness,https://github.com/harness/harness/issues/348,Drone Dockerfile build fails missing package rsrc.,"I'm on a fresh checkout of drone (40fe4305815dd898ffbeeccee2f5bdd979896d72) I get this error:  bash Step 11 : RUN make > Running in a5344ae88a06 cd cmd/droned/assets && find js -name ""*.js"" ! -name '.*' ! -name ""main.js"" -exec cat {} \; > js/main.js go install github.com/GeertJohan/go.rice/rice ../../GeertJohan/go.rice/rice/writecoff.go:5:2: cannot find package ""github.com/akavel/rsrc/binutil"" in any of: /go/src/pkg/github.com/akavel/rsrc/binutil (from $GOROOT) /gocode/src/github.com/akavel/rsrc/binutil (from $GOPATH) ../../GeertJohan/go.rice/rice/embed-syso.go:8:2: cannot find package ""github.com/akavel/rsrc/coff"" in any of: /go/src/pkg/github.com/akavel/rsrc/coff (from $GOROOT) /gocode/src/github.com/akavel/rsrc/coff (from $GOPATH) make:  [rice] Error 1 2014/06/07 15:20:23 The command [/bin/sh -c make] returned a non-zero code: 2  If I check that out into vendor, it all works. I suggest adding it to .gitmodules.",other-file | source-file | other-file,"Drone Dockerfile build fails missing package rsrc. I'm on a fresh checkout of drone (40fe4305815dd898ffbeeccee2f5bdd979896d72) I get this error:  bash Step 11 : RUN make > Running in a5344ae88a06 cd cmd/droned/assets && find js -name ""*.js"" ! -name '.*' ! -name ""main.js"" -exec cat {} \; > js/main.js go install github.com/GeertJohan/go.rice/rice ../../GeertJohan/go.rice/rice/writecoff.go:5:2: cannot find package ""github.com/akavel/rsrc/binutil"" in any of: /go/src/pkg/github.com/akavel/rsrc/binutil (from $GOROOT) /gocode/src/github.com/akavel/rsrc/binutil (from $GOPATH) ../../GeertJohan/go.rice/rice/embed-syso.go:8:2: cannot find package ""github.com/akavel/rsrc/coff"" in any of: /go/src/pkg/github.com/akavel/rsrc/coff (from $GOROOT) /gocode/src/github.com/akavel/rsrc/coff (from $GOPATH) make:  [rice] Error 1 2014/06/07 15:20:23 The command [/bin/sh -c make] returned a non-zero code: 2  If I check that out into vendor, it all works. I suggest adding it to .gitmodules. other-file source-file other-file",no-bug,0.9
534,harness,https://github.com/harness/harness/issues/534,Re-adding private BitBucket repo fails,"If you attempt to re-add a private repository it fails, and the error shown in ""docker logs"" is ""Unable to add Public Key to your BitBucket repository: Bad Request."" Deleting the key under ""Deployment Keys"" in BitBucket.org and then retrying adding the repository in Drone works, which suggests that the failure is because it's not checking to see if the key already exists.",source-file,"Re-adding private BitBucket repo fails If you attempt to re-add a private repository it fails, and the error shown in ""docker logs"" is ""Unable to add Public Key to your BitBucket repository: Bad Request."" Deleting the key under ""Deployment Keys"" in BitBucket.org and then retrying adding the repository in Drone works, which suggests that the failure is because it's not checking to see if the key already exists. source-file",no-bug,0.8
230,harness,https://github.com/harness/harness/issues/230,`drone version` doesn't return anything.,"Fairly self explanatory, the command `drone version` doesn't actually return anything yet it is a documented option in the help. I've tried this on Ubuntu 13.04 with the 'official' debian package install. Also on Amazon Linux with a drone built from source:  [user@myhost bin]$ ./drone -h Drone is a tool for building and testing code in Docker containers. Usage: drone command [arguments] The commands are: build build and test the repository version print the version number vet validate the yaml configuration file -v runs drone with verbose output -h display this help and exit --parallel runs drone build tasks in parallel --timeout=300ms timeout build after 300 milliseconds --privileged runs drone build in a privileged container Examples: drone build builds the source in the pwd drone build /path/to/repo builds the source repository Use ""drone help [command]"" for more information about a command. [user@myhost bin]$ ./drone version [user@myhost bin]$ ",other-file | source-file | source-file,"`drone version` doesn't return anything. Fairly self explanatory, the command `drone version` doesn't actually return anything yet it is a documented option in the help. I've tried this on Ubuntu 13.04 with the 'official' debian package install. Also on Amazon Linux with a drone built from source:  [user@myhost bin]$ ./drone -h Drone is a tool for building and testing code in Docker containers. Usage: drone command [arguments] The commands are: build build and test the repository version print the version number vet validate the yaml configuration file -v runs drone with verbose output -h display this help and exit --parallel runs drone build tasks in parallel --timeout=300ms timeout build after 300 milliseconds --privileged runs drone build in a privileged container Examples: drone build builds the source in the pwd drone build /path/to/repo builds the source repository Use ""drone help [command]"" for more information about a command. [user@myhost bin]$ ./drone version [user@myhost bin]$  other-file source-file source-file",no-bug,0.9
108,harness,https://github.com/harness/harness/issues/108,Marking someone as an admin of the application does not save,When changing a users status from `admin no` to `admin yes` does not save.,other-file | source-file | documentation-file | other-file | source-file | other-file | other-file,Marking someone as an admin of the application does not save When changing a users status from `admin no` to `admin yes` does not save. other-file source-file documentation-file other-file source-file other-file other-file,no-bug,0.7
3058,harness,https://github.com/harness/harness/issues/3058,I would suggest go-embed instead of fileb0x,[https://github.com/golang/proposal/blob/master/design/draft-embed.md](url),source-file | source-file,I would suggest go-embed instead of fileb0x [https://github.com/golang/proposal/blob/master/design/draft-embed.md](url) source-file source-file,no-bug,0.9
1161,harness,https://github.com/harness/harness/issues/1161,Post-activation plugin (PR to automatically add a .drone.yml),"We should add the ability to specify plugins post-activation (and maybe post-deactivation) and perhaps after other system events as well. An example for this sort of plugin would be opening a pull request to automatically add a `.drone.yml` or badge to the `README.md` file. The reason this makes sense as a plugin is because Drone supports multiple remote systems (GitHub, Bitbucket, etc) and each one has slightly different APIs and processes that need to be followed. Bitbucket, for example, requires Mercurial integration as well as Git. By pushing this functionality to a plugin, instead of a core Drone feature, it gives us flexibility and allows teams to customize this functionality to meet their specific organizational needs. It also means it can be turned on or off by the system admin. Or maybe you want the `.drone.yml` auto-populated with common commands or notification settings for your org -- you could alter the plugin to do so.",source-file,"Post-activation plugin (PR to automatically add a .drone.yml) We should add the ability to specify plugins post-activation (and maybe post-deactivation) and perhaps after other system events as well. An example for this sort of plugin would be opening a pull request to automatically add a `.drone.yml` or badge to the `README.md` file. The reason this makes sense as a plugin is because Drone supports multiple remote systems (GitHub, Bitbucket, etc) and each one has slightly different APIs and processes that need to be followed. Bitbucket, for example, requires Mercurial integration as well as Git. By pushing this functionality to a plugin, instead of a core Drone feature, it gives us flexibility and allows teams to customize this functionality to meet their specific organizational needs. It also means it can be turned on or off by the system admin. Or maybe you want the `.drone.yml` auto-populated with common commands or notification settings for your org -- you could alter the plugin to do so. source-file",no-bug,0.9
1144,harness,https://github.com/harness/harness/issues/1144,Support GitHub deployment API,"Looks like GitHub has an API to trigger deployments, https://developer.github.com/v3/repos/deployments/. Having support for this would be great as an explicit deployment point can be supported. Probably need to support the specific hook type to be able to access it within the config and then do actual deploys.",source-file | other-file | other-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file,"Support GitHub deployment API Looks like GitHub has an API to trigger deployments, https://developer.github.com/v3/repos/deployments/. Having support for this would be great as an explicit deployment point can be supported. Probably need to support the specific hook type to be able to access it within the config and then do actual deploys. source-file other-file other-file source-file source-file source-file other-file other-file other-file other-file other-file",no-bug,0.8
933,harness,https://github.com/harness/harness/issues/933,Pull requests with more than 1 commit break the tests,"Sending a suggested change on #911 break the test because there is more than 1 commit on the pull request. This made me open another pull request #932, cherry pick only the last change. This made the test pass. Is this really how it should work? Here is the test result for que PR with 2 commits: http://test.drone.io/github.com/drone/drone/check_presence_socat_anywhere_in_path/0d36b85e65b51f9820825de360f21b56c0ab7599",source-file,"Pull requests with more than 1 commit break the tests Sending a suggested change on #911 break the test because there is more than 1 commit on the pull request. This made me open another pull request #932, cherry pick only the last change. This made the test pass. Is this really how it should work? Here is the test result for que PR with 2 commits: http://test.drone.io/github.com/drone/drone/check_presence_socat_anywhere_in_path/0d36b85e65b51f9820825de360f21b56c0ab7599 source-file",no-bug,0.9
2949,harness,https://github.com/harness/harness/issues/2949,how to save docker image?,is drone ci support pull and save docker images?,source-file | source-file | source-file | source-file | source-file | source-file | source-file,how to save docker image? is drone ci support pull and save docker images? source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
1931,harness,https://github.com/harness/harness/issues/1931,$DRONE_PULL_REQUEST not defined for MRs from non-forks,"Hey , We are using Gitlab and Drone 0.4. I've found from testing that when drone runs for MRs that orginated in the same repo `$DRONE_PULL_REQUEST` is not defined whereas when a build is ran for an MR from a fork it is defined. Is this expected or do we have a problem with our setup somewhere?",source-file,"$DRONE_PULL_REQUEST not defined for MRs from non-forks Hey , We are using Gitlab and Drone 0.4. I've found from testing that when drone runs for MRs that orginated in the same repo `$DRONE_PULL_REQUEST` is not defined whereas when a build is ran for an MR from a fork it is defined. Is this expected or do we have a problem with our setup somewhere? source-file",no-bug,0.9
748,harness,https://github.com/harness/harness/issues/748,RHEL 6.5 Installation,"Trying to install and run Drone on RHEL 6.5 gives the same error as clconway was seeing on issue #223 Trying to compile as recommended in #223 hangs with the below output  bash $ make deps # which npm && npm -g install uglify-js less autoprefixer go get github.com/GeertJohan/go.rice/rice go get github.com/franela/goblin go get -t -v ./ Fetching https://gopkg.in/yaml.v1?go-get=1 Parsing meta tags from https://gopkg.in/yaml.v1?go-get=1 (status code 200) get ""gopkg.in/yaml.v1"": found meta tag main.metaImport{Prefix:""gopkg.in/yaml.v1"", VCS:""git"", RepoRoot:""https://gopkg.in/yaml.v1""} at https://gopkg.in/yaml.v1?go-get=1 gopkg.in/yaml.v1 (download)  Is there currently a solution to this?",source-file | source-file | source-file | source-file | other-file | other-file | source-file,"RHEL 6.5 Installation Trying to install and run Drone on RHEL 6.5 gives the same error as clconway was seeing on issue #223 Trying to compile as recommended in #223 hangs with the below output  bash $ make deps # which npm && npm -g install uglify-js less autoprefixer go get github.com/GeertJohan/go.rice/rice go get github.com/franela/goblin go get -t -v ./ Fetching https://gopkg.in/yaml.v1?go-get=1 Parsing meta tags from https://gopkg.in/yaml.v1?go-get=1 (status code 200) get ""gopkg.in/yaml.v1"": found meta tag main.metaImport{Prefix:""gopkg.in/yaml.v1"", VCS:""git"", RepoRoot:""https://gopkg.in/yaml.v1""} at https://gopkg.in/yaml.v1?go-get=1 gopkg.in/yaml.v1 (download)  Is there currently a solution to this? source-file source-file source-file source-file other-file other-file source-file",no-bug,0.9
2757,harness,https://github.com/harness/harness/issues/2757,Drone on Kubernetes can't execute some command in Dockerfile,"Hello, I've an instance of of Drone in Kubernetes native mode deployed on my K8s cluster. Everything work fine except one think, if the project Dockerfile I'm trying to build contain some commands like :  FROM alpine:latest AS final RUN apk update && apk add ghostscript < This one  The Drone build process at docker stage **can** (not each time) stay stuck at :  > Running in e774d51cde4d -- 86 | fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz  It looks to a network issue in the ""DinD"" process (even if under Kubernetes, DinD isn't used anymore from what I understand). Any idea ?",other-file | other-file,"Drone on Kubernetes can't execute some command in Dockerfile Hello, I've an instance of of Drone in Kubernetes native mode deployed on my K8s cluster. Everything work fine except one think, if the project Dockerfile I'm trying to build contain some commands like :  FROM alpine:latest AS final RUN apk update && apk add ghostscript < This one  The Drone build process at docker stage **can** (not each time) stay stuck at :  > Running in e774d51cde4d -- 86 | fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz  It looks to a network issue in the ""DinD"" process (even if under Kubernetes, DinD isn't used anymore from what I understand). Any idea ? other-file other-file",no-bug,0.9
3523,harness,https://github.com/harness/harness/issues/3523,Using drone is a real pain,"The development of such a system has raised concerns regarding the user experience, which is deemed unsatisfactory. I took the lessons.",other-file | source-file | other-file | other-file | other-file | documentation-file | source-file | other-file | other-file | other-file | source-file | source-file | other-file | documentation-file | source-file,"Using drone is a real pain The development of such a system has raised concerns regarding the user experience, which is deemed unsatisfactory. I took the lessons. other-file source-file other-file other-file other-file documentation-file source-file other-file other-file other-file source-file source-file other-file documentation-file source-file",no-bug,0.9
3444,harness,https://github.com/harness/harness/issues/3444,Simultaneously support multiple version control systems,"Simultaneously support multiple version control systems I use github, gitlab on one dronebut now only on valid",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Simultaneously support multiple version control systems Simultaneously support multiple version control systems I use github, gitlab on one dronebut now only on valid source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.3
993,harness,https://github.com/harness/harness/issues/993,How to debug wsod on github/bitbucket authentication,"Have following the installation and configuration instructions carefully, but obviously something is not correct. Trying to login, but some github/bitbucket users just get stuck on wsod on the following urls: http://<myhost>/api/auth/github.com?code=12e561562e5126e5&state=LAKSDJHLDGWSDFG672683F287G378HRU8HWFEHIUSFEHU9SEF%3D%3D%3D%3D http://<myhost>/api/auth/bitbucket.org?oauth_verifier=13123123123&oauth_token=83f7g2873rfgh2f837 Just a white screen. 403 status code. No logging to syslog. Also found a comment on about drone from back in january stating https://www.digitalocean.com/community/tutorials/how-to-perform-continuous-integration-testing-with-drone-io-on-coreos-and-docker ""This thing is useless. The github authentication is not working and there is no way to debug why is not working."" Logging out from bitbucket/github and using some other users has worked, but for instance my personal github account has never worked. Please make it possible to know why it won't work.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file,"How to debug wsod on github/bitbucket authentication Have following the installation and configuration instructions carefully, but obviously something is not correct. Trying to login, but some github/bitbucket users just get stuck on wsod on the following urls: http://<myhost>/api/auth/github.com?code=12e561562e5126e5&state=LAKSDJHLDGWSDFG672683F287G378HRU8HWFEHIUSFEHU9SEF%3D%3D%3D%3D http://<myhost>/api/auth/bitbucket.org?oauth_verifier=13123123123&oauth_token=83f7g2873rfgh2f837 Just a white screen. 403 status code. No logging to syslog. Also found a comment on about drone from back in january stating https://www.digitalocean.com/community/tutorials/how-to-perform-continuous-integration-testing-with-drone-io-on-coreos-and-docker ""This thing is useless. The github authentication is not working and there is no way to debug why is not working."" Logging out from bitbucket/github and using some other users has worked, but for instance my personal github account has never worked. Please make it possible to know why it won't work. source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file",bug,0.85
221,harness,https://github.com/harness/harness/issues/221,Having problems downloading the image for nodejs,"Hi, i have some problems downloading image for nodejs. below is the log root@ip-10-130-163-244:~# docker pull bradrydzewski/node:0.10 Pulling repository bradrydzewski/node c52118cf1448: Error pulling image (0.10) from bradrydzewski/node, flate: read error at offset 200403383: unexpected EOF 4c1208b690c6: Download complete 735f5db56261: Download complete edd1c3750c7d: Download complete 91c5dcc714a6: Download complete 8dd1f2fbe194: Download complete eb4e1eff516d: Download complete 763a4d0ad1dc: Download complete 45519cb7087f: Download complete d33a03b60c0b: Download complete 9ecb2de0e544: Download complete de1674b7017f: Download complete d94561b048ac: Download complete ecfb6dbe1d0c: Download complete a61130d6a0f3: Download complete 00fb4af118c1: Error downloading dependent layers 2014/03/26 09:16:13 Could not find repository on any of the indexed registries.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file,"Having problems downloading the image for nodejs Hi, i have some problems downloading image for nodejs. below is the log root@ip-10-130-163-244:~# docker pull bradrydzewski/node:0.10 Pulling repository bradrydzewski/node c52118cf1448: Error pulling image (0.10) from bradrydzewski/node, flate: read error at offset 200403383: unexpected EOF 4c1208b690c6: Download complete 735f5db56261: Download complete edd1c3750c7d: Download complete 91c5dcc714a6: Download complete 8dd1f2fbe194: Download complete eb4e1eff516d: Download complete 763a4d0ad1dc: Download complete 45519cb7087f: Download complete d33a03b60c0b: Download complete 9ecb2de0e544: Download complete de1674b7017f: Download complete d94561b048ac: Download complete ecfb6dbe1d0c: Download complete a61130d6a0f3: Download complete 00fb4af118c1: Error downloading dependent layers 2014/03/26 09:16:13 Could not find repository on any of the indexed registries. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file",no-bug,0.9
886,harness,https://github.com/harness/harness/issues/886,Azure plugin,Missing plugin support for Azure Storage for blob object upload,source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Azure plugin Missing plugin support for Azure Storage for blob object upload source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.8
1198,harness,https://github.com/harness/harness/issues/1198,Bug: Cannot delete repo through the API,"I can GET the repo using the API request and it seems to work fine. However, using the DELETE method it outputs the following stack trace:  2015/09/13 16:26:22 http: panic serving 80.200.141.199:53109: runtime error: invalid memory address or nil pointer dereference goroutine 653 [running]: net/http.func011() /usr/local/go/src/net/http/server.go:1130 +0xbb github.com/drone/drone/plugin/remote/github.DeleteKey(0xc208630a50, 0xc208357898, 0x7, 0xc2083578e0, 0xa, 0xc208309a60, 0x16, 0xc208126900, 0x17d, 0x0, ) /gopath/src/github.com/drone/drone/plugin/remote/github/helper.go:250 +0xfa github.com/drone/drone/plugin/remote/github.(*GitHub).Deactivate(0xc2080101c0, 0xc208630840, 0xc208196500, 0xc2085c0960, 0x55, 0x0, 0x0) /gopath/src/github.com/drone/drone/plugin/remote/github/github.go:207 +0x15f github.com/drone/drone/server/handler.DelRepo(0xc2086c70e0, 0xc2086c6f00, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/handler/repo.go:78 +0x8a5 github.com/zenazn/goji/web.handlerFuncWrap.ServeHTTPC(0xd81c90, 0xc2086c70e0, 0xc2086c6f00, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/handler.go:25 +0x55 github.com/zenazn/goji/web.(*router).route(0xc208010ab8, 0xc2086c7110, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/router.go:119 +0x144 github.com/zenazn/goji/web.func002(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/middleware.go:88 +0x60 net/http.HandlerFunc.ServeHTTP(0xc208309600, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func005(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/repo.go:104 +0x441 net/http.HandlerFunc.ServeHTTP(0xc208309620, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func004(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/repo.go:62 +0x21c net/http.HandlerFunc.ServeHTTP(0xc208309660, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func003(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/repo.go:36 +0x5ec net/http.HandlerFunc.ServeHTTP(0xc208309680, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/zenazn/goji/web.(*cStack).ServeHTTPC(0xc2086c7110, 0xc2086c70e0, 0xc2086c6f00, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/middleware.go:50 +0x91 github.com/zenazn/goji/web.(*Mux).ServeHTTPC(0xc208010a80, 0xc2086c70e0, 0xc2086c6f00, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/mux.go:53 +0x74 github.com/zenazn/goji/web.(*router).route(0xc2080103b8, 0xc2086c6ed0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/router.go:119 +0x144 github.com/zenazn/goji/web.func002(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/middleware.go:88 +0x60 net/http.HandlerFunc.ServeHTTP(0xc2083090a0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func006(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/user.go:21 +0x1b1 net/http.HandlerFunc.ServeHTTP(0xc2083090e0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func001(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/header.go:28 +0x4cc net/http.HandlerFunc.ServeHTTP(0xc208356800, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 main.func002(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/main.go:176 +0x885 net/http.HandlerFunc.ServeHTTP(0xc208309120, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func002(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/options.go:22 +0x256 net/http.HandlerFunc.ServeHTTP(0xc208356830, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/zenazn/goji/web.(*cStack).ServeHTTP(0xc2086c6ed0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/middleware.go:46 +0x72 github.com/zenazn/goji/web.(*Mux).ServeHTTP(0xc208010380, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/mux.go:45 +0x60 net/http.(*ServeMux).ServeHTTP(0xc20803a960, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1541 +0x17d net/http.serverHandler.ServeHTTP(0xc20802f5c0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1703 +0x19a net/http.(*conn).serve(0xc208058e60) /usr/local/go/src/net/http/server.go:1204 +0xb57 created by net/http.(*Server).Serve /usr/local/go/src/net/http/server.go:1751 +0x35e ",documentation-file | other-file | other-file,"Bug: Cannot delete repo through the API I can GET the repo using the API request and it seems to work fine. However, using the DELETE method it outputs the following stack trace:  2015/09/13 16:26:22 http: panic serving 80.200.141.199:53109: runtime error: invalid memory address or nil pointer dereference goroutine 653 [running]: net/http.func011() /usr/local/go/src/net/http/server.go:1130 +0xbb github.com/drone/drone/plugin/remote/github.DeleteKey(0xc208630a50, 0xc208357898, 0x7, 0xc2083578e0, 0xa, 0xc208309a60, 0x16, 0xc208126900, 0x17d, 0x0, ) /gopath/src/github.com/drone/drone/plugin/remote/github/helper.go:250 +0xfa github.com/drone/drone/plugin/remote/github.(*GitHub).Deactivate(0xc2080101c0, 0xc208630840, 0xc208196500, 0xc2085c0960, 0x55, 0x0, 0x0) /gopath/src/github.com/drone/drone/plugin/remote/github/github.go:207 +0x15f github.com/drone/drone/server/handler.DelRepo(0xc2086c70e0, 0xc2086c6f00, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/handler/repo.go:78 +0x8a5 github.com/zenazn/goji/web.handlerFuncWrap.ServeHTTPC(0xd81c90, 0xc2086c70e0, 0xc2086c6f00, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/handler.go:25 +0x55 github.com/zenazn/goji/web.(*router).route(0xc208010ab8, 0xc2086c7110, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/router.go:119 +0x144 github.com/zenazn/goji/web.func002(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/middleware.go:88 +0x60 net/http.HandlerFunc.ServeHTTP(0xc208309600, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func005(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/repo.go:104 +0x441 net/http.HandlerFunc.ServeHTTP(0xc208309620, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func004(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/repo.go:62 +0x21c net/http.HandlerFunc.ServeHTTP(0xc208309660, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func003(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/repo.go:36 +0x5ec net/http.HandlerFunc.ServeHTTP(0xc208309680, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/zenazn/goji/web.(*cStack).ServeHTTPC(0xc2086c7110, 0xc2086c70e0, 0xc2086c6f00, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/middleware.go:50 +0x91 github.com/zenazn/goji/web.(*Mux).ServeHTTPC(0xc208010a80, 0xc2086c70e0, 0xc2086c6f00, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/mux.go:53 +0x74 github.com/zenazn/goji/web.(*router).route(0xc2080103b8, 0xc2086c6ed0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/router.go:119 +0x144 github.com/zenazn/goji/web.func002(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/middleware.go:88 +0x60 net/http.HandlerFunc.ServeHTTP(0xc2083090a0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func006(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/user.go:21 +0x1b1 net/http.HandlerFunc.ServeHTTP(0xc2083090e0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func001(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/header.go:28 +0x4cc net/http.HandlerFunc.ServeHTTP(0xc208356800, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 main.func002(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/main.go:176 +0x885 net/http.HandlerFunc.ServeHTTP(0xc208309120, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/drone/drone/server/middleware.func002(0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/drone/drone/server/middleware/options.go:22 +0x256 net/http.HandlerFunc.ServeHTTP(0xc208356830, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1265 +0x41 github.com/zenazn/goji/web.(*cStack).ServeHTTP(0xc2086c6ed0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/middleware.go:46 +0x72 github.com/zenazn/goji/web.(*Mux).ServeHTTP(0xc208010380, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /gopath/src/github.com/zenazn/goji/web/mux.go:45 +0x60 net/http.(*ServeMux).ServeHTTP(0xc20803a960, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1541 +0x17d net/http.serverHandler.ServeHTTP(0xc20802f5c0, 0x7fdffec4afe8, 0xc208376960, 0xc20861eea0) /usr/local/go/src/net/http/server.go:1703 +0x19a net/http.(*conn).serve(0xc208058e60) /usr/local/go/src/net/http/server.go:1204 +0xb57 created by net/http.(*Server).Serve /usr/local/go/src/net/http/server.go:1751 +0x35e  documentation-file other-file other-file",bug,0.95
2068,harness,https://github.com/harness/harness/issues/2068,Migrate Gitlab API client to API V4,"API V3 will be removed in GitLab 9.5, to be released on August 22, 2017. https://docs.gitlab.com/ce/api/v3_to_v4.html",source-file | source-file | source-file | source-file | test-file | source-file,"Migrate Gitlab API client to API V4 API V3 will be removed in GitLab 9.5, to be released on August 22, 2017. https://docs.gitlab.com/ce/api/v3_to_v4.html source-file source-file source-file source-file test-file source-file",no-bug,0.8
3446,harness,https://github.com/harness/harness/issues/3446,Set the docker enpoint (TCP),Best practices for docker encourage to avoid accessing the Docker API without any restriction (aka `/var/run/docker.sock`) Possible solutions are expose the Docker socket over TCP or SSH. For TCP exposing I use [the TecnativaDocker Socket Proxy](https://github.com/Tecnativa/docker-socket-proxy). This approach requires to connect the docker client to that socket exposed as e.g.`tcp://docker-socket-proxy:2375` E.g. - Traefik -> set `providers.docker.endpoint=tcp://docker-socket-proxy:2375` - Portainer -> `command: -H tcp://docker-socket-proxy:2375` in my `docker-compose.yml` file and removing `/var/run/docker.sock:/var/run/docker.sock` from the volumes How to achieve that with gitness? I tried: - set `command` as in portainer but gitness does not start at all - set `GITNESS_URL_CONTAINER=tcp://docker-socket-proxy:2375`. Executing a pipeline I get the following > Cannot connect to the Docker daemon at unix:var/run/docker.sock. Is the docker daemon running? Any advice? Thanks,source-file,Set the docker enpoint (TCP) Best practices for docker encourage to avoid accessing the Docker API without any restriction (aka `/var/run/docker.sock`) Possible solutions are expose the Docker socket over TCP or SSH. For TCP exposing I use [the TecnativaDocker Socket Proxy](https://github.com/Tecnativa/docker-socket-proxy). This approach requires to connect the docker client to that socket exposed as e.g.`tcp://docker-socket-proxy:2375` E.g. - Traefik -> set `providers.docker.endpoint=tcp://docker-socket-proxy:2375` - Portainer -> `command: -H tcp://docker-socket-proxy:2375` in my `docker-compose.yml` file and removing `/var/run/docker.sock:/var/run/docker.sock` from the volumes How to achieve that with gitness? I tried: - set `command` as in portainer but gitness does not start at all - set `GITNESS_URL_CONTAINER=tcp://docker-socket-proxy:2375`. Executing a pipeline I get the following > Cannot connect to the Docker daemon at unix:var/run/docker.sock. Is the docker daemon running? Any advice? Thanks source-file,no-bug,0.9
2903,harness,https://github.com/harness/harness/issues/2903,"Detected accuracy problems on cron jobs with ""@every XX"" with XX period time","Hi to all drone followers. First I would like to be grateful with drone owners and collaborators for this great software. As previously discused in https://discourse.drone.io/t/triggered-builds-by-cron-have-high-deviation-against-expected-time/6612/4 , we have detected some accuracy problems with builds triggered from cron with expressions `@every XX` ( continuous period without no important where it exact begins) The 2 main discussion issues was. ## Accumulated delay on jobs needed to have a stable cadence (with acceptance of some jitter) it could be a problem as there is lack of data. **With current drone version** ![image](https://user-images.githubusercontent.com/5883405/72604755-d2b1f680-391b-11ea-8e91-acd28202f44b.png) En the previous image cron jobs should be triggered each 10min but all cron-jobs has been accumulating time until bypass one period **Expected** ![image](https://user-images.githubusercontent.com/5883405/72604826-eeb59800-391b-11ea-867a-c6fe29119dc9.png) This is the expected behaviour, where there is one execution on each time bucket ## job alignment Right now drone changes the triggering time depending on the DRONE_CRON_INTERVAL if drone-server (for maintenance or for incidence) has been stopped more than one ""XX period"" on restart all cron jobs will be triggered first at the same time. This fact could have impact on not much efficient resource consumption distributin and could overload runner system. Could be interesting if Drone could maintain the cron deploy initial time by the end user ( this is like delegate resource load distribucion on the end user ) , instead of changing it with this dangerous behaviour",source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | other-file | test-file | source-file | source-file | test-file | source-file | other-file | test-file | source-file | source-file | test-file,"Detected accuracy problems on cron jobs with ""@every XX"" with XX period time Hi to all drone followers. First I would like to be grateful with drone owners and collaborators for this great software. As previously discused in https://discourse.drone.io/t/triggered-builds-by-cron-have-high-deviation-against-expected-time/6612/4 , we have detected some accuracy problems with builds triggered from cron with expressions `@every XX` ( continuous period without no important where it exact begins) The 2 main discussion issues was. ## Accumulated delay on jobs needed to have a stable cadence (with acceptance of some jitter) it could be a problem as there is lack of data. **With current drone version** ![image](https://user-images.githubusercontent.com/5883405/72604755-d2b1f680-391b-11ea-8e91-acd28202f44b.png) En the previous image cron jobs should be triggered each 10min but all cron-jobs has been accumulating time until bypass one period **Expected** ![image](https://user-images.githubusercontent.com/5883405/72604826-eeb59800-391b-11ea-867a-c6fe29119dc9.png) This is the expected behaviour, where there is one execution on each time bucket ## job alignment Right now drone changes the triggering time depending on the DRONE_CRON_INTERVAL if drone-server (for maintenance or for incidence) has been stopped more than one ""XX period"" on restart all cron jobs will be triggered first at the same time. This fact could have impact on not much efficient resource consumption distributin and could overload runner system. Could be interesting if Drone could maintain the cron deploy initial time by the end user ( this is like delegate resource load distribucion on the end user ) , instead of changing it with this dangerous behaviour source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file test-file source-file other-file test-file source-file source-file test-file source-file other-file test-file source-file source-file test-file",no-bug,0.9
1126,harness,https://github.com/harness/harness/issues/1126,Drone .deb package requires lsb_release to install cleanly on Debian 8,"When installing Drone with the .deb package on a completely fresh Debian 8 install, the user is prompted with the following message:  $ dpkg -i drone.deb Selecting previously unselected package drone. (Reading database  13553 files and directories currently installed.) Preparing to unpack drone.deb  Unpacking drone (0.3.0-alpha-1438588567)  Setting up drone (0.3.0-alpha-1438588567)  /var/lib/dpkg/info/drone.postinst: 20: /var/lib/dpkg/info/drone.postinst: lsb_release: not found /var/lib/dpkg/info/drone.postinst: 20: /var/lib/dpkg/info/drone.postinst: lsb_release: not found /var/lib/dpkg/info/drone.postinst: 24: /var/lib/dpkg/info/drone.postinst: lsb_release: not found Your system This system is not supported, you can install service manually  Installing the `lsb-release` package and trying again features no errors, so adding to the `Depends` should fix this.",source-file,"Drone .deb package requires lsb_release to install cleanly on Debian 8 When installing Drone with the .deb package on a completely fresh Debian 8 install, the user is prompted with the following message:  $ dpkg -i drone.deb Selecting previously unselected package drone. (Reading database  13553 files and directories currently installed.) Preparing to unpack drone.deb  Unpacking drone (0.3.0-alpha-1438588567)  Setting up drone (0.3.0-alpha-1438588567)  /var/lib/dpkg/info/drone.postinst: 20: /var/lib/dpkg/info/drone.postinst: lsb_release: not found /var/lib/dpkg/info/drone.postinst: 20: /var/lib/dpkg/info/drone.postinst: lsb_release: not found /var/lib/dpkg/info/drone.postinst: 24: /var/lib/dpkg/info/drone.postinst: lsb_release: not found Your system This system is not supported, you can install service manually  Installing the `lsb-release` package and trying again features no errors, so adding to the `Depends` should fix this. source-file",no-bug,0.9
849,harness,https://github.com/harness/harness/issues/849,Move privileged flag to yaml file,"I would like to move the `Privileged` field to the Docker section of the yaml file:  docker: privileged: true net: host  And then change the `Privileged` field to `Trusted`:  diff type Repo struct { - Privileged bool `meddler:""repo_privileged"" json:""privileged""` + Trusted bool `meddler:""repo_privileged"" json:""trusted""`  Note that for compatibility reasons we should leave the database field alone (as `repo_privileged`) to avoid complicating our migrations. The reasons for this change is that we are adding features (like Volume support) that require elevated privileges in order to enable. Enabling volumes, however, does not mean that someone wants to run the build in a Docker container with privileged mode. This is why I think it makes sense to start differentiating between `trusted` and `privileged`",documentation-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | source-file | other-file | other-file | source-file | source-file | source-file | other-file | documentation-file | other-file | source-file | other-file,"Move privileged flag to yaml file I would like to move the `Privileged` field to the Docker section of the yaml file:  docker: privileged: true net: host  And then change the `Privileged` field to `Trusted`:  diff type Repo struct { - Privileged bool `meddler:""repo_privileged"" json:""privileged""` + Trusted bool `meddler:""repo_privileged"" json:""trusted""`  Note that for compatibility reasons we should leave the database field alone (as `repo_privileged`) to avoid complicating our migrations. The reasons for this change is that we are adding features (like Volume support) that require elevated privileges in order to enable. Enabling volumes, however, does not mean that someone wants to run the build in a Docker container with privileged mode. This is why I think it makes sense to start differentiating between `trusted` and `privileged` documentation-file other-file source-file other-file source-file other-file source-file other-file other-file source-file other-file other-file source-file other-file source-file other-file other-file source-file source-file source-file other-file documentation-file other-file source-file other-file",no-bug,0.85
2247,harness,https://github.com/harness/harness/issues/2247,README.md does not contains build instructions,"I spent the last 30 minutes trying to figure out how to build the drone server, thinking about upgrading a production server from 0.5 to current (0.8?). Is there any reason not to write simple instructions in the README.md file ? For the 0.5 branch there was a Makefile, which was basically self-documented, why not putting it back ?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | other-file | other-file,"README.md does not contains build instructions I spent the last 30 minutes trying to figure out how to build the drone server, thinking about upgrading a production server from 0.5 to current (0.8?). Is there any reason not to write simple instructions in the README.md file ? For the 0.5 branch there was a Makefile, which was basically self-documented, why not putting it back ? source-file source-file source-file source-file source-file source-file source-file documentation-file other-file other-file",no-bug,0.95
149,harness,https://github.com/harness/harness/issues/149,dial tcp 0.0.0.0:4243: connection refused,"I get the following error after installing drone and configuring it with my repository: ""dial tcp 0.0.0.0:4243: connection refused"" This is on Ubuntu with docker installed in the standard fashion. I believe that means it uses a unix socket. But it looks like drone is trying to connect with docker on TCP. I issued the following command to run docker on port 4243:  sudo service stop docker sudo docker -d -H 127.0.0.1:4243  Did I do something wrong during configuration?",source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file,"dial tcp 0.0.0.0:4243: connection refused I get the following error after installing drone and configuring it with my repository: ""dial tcp 0.0.0.0:4243: connection refused"" This is on Ubuntu with docker installed in the standard fashion. I believe that means it uses a unix socket. But it looks like drone is trying to connect with docker on TCP. I issued the following command to run docker on port 4243:  sudo service stop docker sudo docker -d -H 127.0.0.1:4243  Did I do something wrong during configuration? source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file source-file source-file documentation-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file source-file source-file source-file",no-bug,0.9
166,harness,https://github.com/harness/harness/issues/166,Needs a better logo for sharing drone.io URLs,https://developers.google.com/+/web/snippet/,other-file | documentation-file | other-file | source-file,Needs a better logo for sharing drone.io URLs https://developers.google.com/+/web/snippet/ other-file documentation-file other-file source-file,no-bug,0.95
2127,harness,https://github.com/harness/harness/issues/2127,[Docs Request] Docs for Contributing 101,"I've RTFMed out the [installation](http://docs.drone.io/installation/) instructions and [help](http://docs.drone.io/installation-help/) docs. Since I've also been interested in contributing I've been checking out the [Github Issues](https://github.com/drone/drone/issues) and thought that having some documentation around getting started from a documentation perspective would be super helpful. Something, when one is asking to dive into assist with things, could read over quickly to get started. ## Topics Would Include: * Cloning the Drone.io Repository. * Getting a successful Drone.io build. * Knowing the architecture of the Drone.io build. * Setting up the environment for testing. * Submitting a [Feature Request] with a Github Issue. (i.e. the details, what it is, why, how it would affect others/projects, what benefits it would provide) * Submitting feature code pull request. (i.e. prereqs, what should be included, the code, proven tests, etc)",source-file,"[Docs Request] Docs for Contributing 101 I've RTFMed out the [installation](http://docs.drone.io/installation/) instructions and [help](http://docs.drone.io/installation-help/) docs. Since I've also been interested in contributing I've been checking out the [Github Issues](https://github.com/drone/drone/issues) and thought that having some documentation around getting started from a documentation perspective would be super helpful. Something, when one is asking to dive into assist with things, could read over quickly to get started. ## Topics Would Include: * Cloning the Drone.io Repository. * Getting a successful Drone.io build. * Knowing the architecture of the Drone.io build. * Setting up the environment for testing. * Submitting a [Feature Request] with a Github Issue. (i.e. the details, what it is, why, how it would affect others/projects, what benefits it would provide) * Submitting feature code pull request. (i.e. prereqs, what should be included, the code, proven tests, etc) source-file",no-bug,0.95
3435,harness,https://github.com/harness/harness/issues/3435,gitness support cron and schedules Triggers,can gitness support cron and schedules Triggers? ![image](https://github.com/harness/gitness/assets/33590311/e0aa0e02-fe5a-4ee1-acee-396cb3b9d5dd),other-file | test-file | test-file | other-file,gitness support cron and schedules Triggers can gitness support cron and schedules Triggers? ![image](https://github.com/harness/gitness/assets/33590311/e0aa0e02-fe5a-4ee1-acee-396cb3b9d5dd) other-file test-file test-file other-file,no-bug,0.9
219,harness,https://github.com/harness/harness/issues/219,No Build button,"I noticed that Drone doesn't have a Build button on the projects but hosted Drone.IO does, is this by design?",other-file | source-file | other-file | other-file,"No Build button I noticed that Drone doesn't have a Build button on the projects but hosted Drone.IO does, is this by design? other-file source-file other-file other-file",no-bug,0.9
682,harness,https://github.com/harness/harness/issues/682,"""Build"" when pull request is closed?","Apologies is this is just Not How Things Work, but is there any way Drone could trigger an abbreviated ""build,"" wherein nothing is actually built but there is a build record created, when a pull request is closed instead of merged? It's an issue I've been trying to deal with on the Drone Wall, wherein closed pull requests will just stay attached to a repo visually forever, since the only way we know to hide them is if they get merged. A closed pull request doesn't trigger anything in Drone, so it just stays up there forever. Right now I just hide any pull request that's been inactive for two days, but it's not ideal. So yeah, a one-line build with a status of ""Closed"" or something like that, doesn't actually re-build any code, but broadcasts that a change of state has occurred. Feasible? Not?",documentation-file,"""Build"" when pull request is closed? Apologies is this is just Not How Things Work, but is there any way Drone could trigger an abbreviated ""build,"" wherein nothing is actually built but there is a build record created, when a pull request is closed instead of merged? It's an issue I've been trying to deal with on the Drone Wall, wherein closed pull requests will just stay attached to a repo visually forever, since the only way we know to hide them is if they get merged. A closed pull request doesn't trigger anything in Drone, so it just stays up there forever. Right now I just hide any pull request that's been inactive for two days, but it's not ideal. So yeah, a one-line build with a status of ""Closed"" or something like that, doesn't actually re-build any code, but broadcasts that a change of state has occurred. Feasible? Not? documentation-file",no-bug,0.9
3579,harness,https://github.com/harness/harness/issues/3579,Google Auth Login and signup flow,Hello Can you please add Google Auth to signin and sign up flow? It will be easier for user migration and added security.,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Google Auth Login and signup flow Hello Can you please add Google Auth to signin and sign up flow? It will be easier for user migration and added security. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
1495,harness,https://github.com/harness/harness/issues/1495,REST endpoint(s) for querying builds based on branches,"It would be great if there was a way to query for builds based on a branch. In swagger this would look like  /repos/{owner}/{name}/{branch}/builds: get: parameters: - name: owner in: path type: string description: owner of the repository - name: name in: path type: string description: name of the repository - name: branch in: path type: string description: the branch of the buil tags: - Builds summary: Get recent builds description: Returns recent builds for the repository based on name. security: - accessToken: [] responses: 200: description: The recent builds on the branch. schema: type: array items: $ref: ""#/definitions/Build"" 404: description: | Unable to find the Repository in the database  Additionally it may be useful to get a listing of all the branches that have been seen or maybe the latest build on a per branch basis. This would also potentially have the pagination ala #1494.",documentation-file | source-file | test-file,"REST endpoint(s) for querying builds based on branches It would be great if there was a way to query for builds based on a branch. In swagger this would look like  /repos/{owner}/{name}/{branch}/builds: get: parameters: - name: owner in: path type: string description: owner of the repository - name: name in: path type: string description: name of the repository - name: branch in: path type: string description: the branch of the buil tags: - Builds summary: Get recent builds description: Returns recent builds for the repository based on name. security: - accessToken: [] responses: 200: description: The recent builds on the branch. schema: type: array items: $ref: ""#/definitions/Build"" 404: description: | Unable to find the Repository in the database  Additionally it may be useful to get a listing of all the branches that have been seen or maybe the latest build on a per branch basis. This would also potentially have the pagination ala #1494. documentation-file source-file test-file",no-bug,0.9
3359,harness,https://github.com/harness/harness/issues/3359,"Update documentation regarding ""community"" Slack","This line should be updated: https://github.com/harness/drone/blob/e63b8f9326969220df73b9d74349405eb86c1073/.github/readme.md?plain=1#L21 The Slack is clearly not open for the community, since one must have a @harness.io address to join: ![Slack enforces users to have a @harness.io address](https://github.com/harness/drone/assets/7773090/6e77e4ad-5cb3-41a4-9965-b6c46d766b27)",container-file,"Update documentation regarding ""community"" Slack This line should be updated: https://github.com/harness/drone/blob/e63b8f9326969220df73b9d74349405eb86c1073/.github/readme.md?plain=1#L21 The Slack is clearly not open for the community, since one must have a @harness.io address to join: ![Slack enforces users to have a @harness.io address](https://github.com/harness/drone/assets/7773090/6e77e4ad-5cb3-41a4-9965-b6c46d766b27) container-file",no-bug,0.95
2968,harness,https://github.com/harness/harness/issues/2968,show version number on ui,Why not to show the version number in ui? I can't find the version number of current running instance,source-file,show version number on ui Why not to show the version number in ui? I can't find the version number of current running instance source-file,no-bug,0.9
3375,harness,https://github.com/harness/harness/issues/3375,make build failed on mac,"internal/api/usererror/translate.go:27:2: github.com/harness/go-rbac@v0.0.0-20230829014129-c9b217856ea2: invalid version: git ls-remote -q origin in /Users/xyz/go/pkg/mod/cache/vcs/40d64810da2531b923441e2458e47c2849215bcd631e15353e5941e1aca2d37a: exit status 128: fatal: could not read Username for 'https://github.com': terminal prompts disabled Confirm the import path was entered correctly. If this is a private repository, see https://golang.org/doc/faq#git_https for additional information. make:  [build] Error 1",source-file | source-file | test-file | source-file | test-file | test-file | source-file | source-file | test-file | source-file | source-file,"make build failed on mac internal/api/usererror/translate.go:27:2: github.com/harness/go-rbac@v0.0.0-20230829014129-c9b217856ea2: invalid version: git ls-remote -q origin in /Users/xyz/go/pkg/mod/cache/vcs/40d64810da2531b923441e2458e47c2849215bcd631e15353e5941e1aca2d37a: exit status 128: fatal: could not read Username for 'https://github.com': terminal prompts disabled Confirm the import path was entered correctly. If this is a private repository, see https://golang.org/doc/faq#git_https for additional information. make:  [build] Error 1 source-file source-file test-file source-file test-file test-file source-file source-file test-file source-file source-file",no-bug,0.95
2795,harness,https://github.com/harness/harness/issues/2795,GitHub 'closed' webhook is ignored,"I'm testing the functionality introduced in https://github.com/drone/drone/issues/2685, but it seems like the `closed` action is ignored. This can be also seen in the database, where there are just `create`, `sync`, `opened`, `synchronized` in the `build_action` column of the `builds` database. I would have expected all of the actions to be recorded based on: https://github.com/drone/drone/blob/bcdd4bf0245c82c060407b3b24b9b87301d15ac1/service/hook/parser/parse.go#L249 Upd: just noticed that everything apart of open and sync is ignored: https://github.com/drone/drone/blob/bcdd4bf0245c82c060407b3b24b9b87301d15ac1/service/hook/parser/parse.go#L234-L237 Would it be enough to simply change that to to include close, while adding the corresponding action? https://github.com/drone/drone/blob/e855881324dcdf912e70f94d6c7abc1d985cdbd3/core/hook.go#L22-L28 However, I do not understand where the `synchronized` action comes from which can be seen in the database.",source-file,"GitHub 'closed' webhook is ignored I'm testing the functionality introduced in https://github.com/drone/drone/issues/2685, but it seems like the `closed` action is ignored. This can be also seen in the database, where there are just `create`, `sync`, `opened`, `synchronized` in the `build_action` column of the `builds` database. I would have expected all of the actions to be recorded based on: https://github.com/drone/drone/blob/bcdd4bf0245c82c060407b3b24b9b87301d15ac1/service/hook/parser/parse.go#L249 Upd: just noticed that everything apart of open and sync is ignored: https://github.com/drone/drone/blob/bcdd4bf0245c82c060407b3b24b9b87301d15ac1/service/hook/parser/parse.go#L234-L237 Would it be enough to simply change that to to include close, while adding the corresponding action? https://github.com/drone/drone/blob/e855881324dcdf912e70f94d6c7abc1d985cdbd3/core/hook.go#L22-L28 However, I do not understand where the `synchronized` action comes from which can be seen in the database. source-file",no-bug,0.8
2031,harness,https://github.com/harness/harness/issues/2031,"SSL enable plugins, docs and downloads subdomains","The subdomains are currently S3 buckets, so we'll need to use something like cloudflare [1] or move to digital ocean with caddy. [1] https://support.cloudflare.com/hc/en-us/articles/200168926-How-do-I-use-Cloudflare-with-Amazon-s-S3-Service-",other-file,"SSL enable plugins, docs and downloads subdomains The subdomains are currently S3 buckets, so we'll need to use something like cloudflare [1] or move to digital ocean with caddy. [1] https://support.cloudflare.com/hc/en-us/articles/200168926-How-do-I-use-Cloudflare-with-Amazon-s-S3-Service- other-file",no-bug,0.9
2105,harness,https://github.com/harness/harness/issues/2105,panic: runtime error with DRONE_STASH_CONSUMER_RSA_STRING,"**Drone 7.3** from **docker** hub Configured to use Bitbucker server (stash). Privarte key in **DRONE_STASH_CONSUMER_RSA_STRING**  panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x958051] goroutine 1 [running]: github.com/drone/drone/remote/bitbucketserver.New(0xc420014040, 0x13, 0xc42000c0b9, 0x6, 0xc4200140a9, 0x9, 0xc420014079, 0x14, 0x0, 0x0, ) /go/src/github.com/drone/drone/remote/bitbucketserver/bitbucketserver.go:83 +0x151 github.com/drone/drone/router/middleware.setupStash(0xc4203a6f00, 0xdbcd4a, 0x5, 0x1, 0x0) /go/src/github.com/drone/drone/router/middleware/remote.go:90 +0x306 github.com/drone/drone/router/middleware.setupRemote(0xc4203a6f00, 0x20, 0xcfa800, 0x9e2701, 0xc420403d80) /go/src/github.com/drone/drone/router/middleware/remote.go:40 +0x22f github.com/drone/drone/router/middleware.Remote(0xc4203a6f00, 0x13cb580) /go/src/github.com/drone/drone/router/middleware/remote.go:21 +0x2f github.com/drone/drone/extras/cmd/drone/server.server(0xc4203a6f00, 0x0, 0xc4203a6f00) /go/src/github.com/drone/drone/extras/cmd/drone/server/server.go:408 +0x161 github.com/drone/drone/vendor/github.com/urfave/cli.HandleAction(0xc9e220, 0xdf5720, 0xc4203a6f00, 0xc4203aa400, 0x0) /go/src/github.com/drone/drone/vendor/github.com/urfave/cli/app.go:485 +0xd4 github.com/drone/drone/vendor/github.com/urfave/cli.Command.Run(0xdbdf88, 0x6, 0x0, 0x0, 0x0, 0x0, 0x0, 0xdd69c4, 0x1e, 0x0, ) /go/src/github.com/drone/drone/vendor/github.com/urfave/cli/command.go:207 +0xb72 github.com/drone/drone/vendor/github.com/urfave/cli.(*App).Run(0xc4203c6680, 0xc42008a060, 0x2, 0x2, 0x0, 0x0) /go/src/github.com/drone/drone/vendor/github.com/urfave/cli/app.go:250 +0x7d0 main.main() /go/src/github.com/drone/drone/drone/main_extras.go:43 +0x386 ",source-file | source-file | source-file,"panic: runtime error with DRONE_STASH_CONSUMER_RSA_STRING **Drone 7.3** from **docker** hub Configured to use Bitbucker server (stash). Privarte key in **DRONE_STASH_CONSUMER_RSA_STRING**  panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x958051] goroutine 1 [running]: github.com/drone/drone/remote/bitbucketserver.New(0xc420014040, 0x13, 0xc42000c0b9, 0x6, 0xc4200140a9, 0x9, 0xc420014079, 0x14, 0x0, 0x0, ) /go/src/github.com/drone/drone/remote/bitbucketserver/bitbucketserver.go:83 +0x151 github.com/drone/drone/router/middleware.setupStash(0xc4203a6f00, 0xdbcd4a, 0x5, 0x1, 0x0) /go/src/github.com/drone/drone/router/middleware/remote.go:90 +0x306 github.com/drone/drone/router/middleware.setupRemote(0xc4203a6f00, 0x20, 0xcfa800, 0x9e2701, 0xc420403d80) /go/src/github.com/drone/drone/router/middleware/remote.go:40 +0x22f github.com/drone/drone/router/middleware.Remote(0xc4203a6f00, 0x13cb580) /go/src/github.com/drone/drone/router/middleware/remote.go:21 +0x2f github.com/drone/drone/extras/cmd/drone/server.server(0xc4203a6f00, 0x0, 0xc4203a6f00) /go/src/github.com/drone/drone/extras/cmd/drone/server/server.go:408 +0x161 github.com/drone/drone/vendor/github.com/urfave/cli.HandleAction(0xc9e220, 0xdf5720, 0xc4203a6f00, 0xc4203aa400, 0x0) /go/src/github.com/drone/drone/vendor/github.com/urfave/cli/app.go:485 +0xd4 github.com/drone/drone/vendor/github.com/urfave/cli.Command.Run(0xdbdf88, 0x6, 0x0, 0x0, 0x0, 0x0, 0x0, 0xdd69c4, 0x1e, 0x0, ) /go/src/github.com/drone/drone/vendor/github.com/urfave/cli/command.go:207 +0xb72 github.com/drone/drone/vendor/github.com/urfave/cli.(*App).Run(0xc4203c6680, 0xc42008a060, 0x2, 0x2, 0x0, 0x0) /go/src/github.com/drone/drone/vendor/github.com/urfave/cli/app.go:250 +0x7d0 main.main() /go/src/github.com/drone/drone/drone/main_extras.go:43 +0x386  source-file source-file source-file",no-bug,0.9
1176,harness,https://github.com/harness/harness/issues/1176,webhook with gogs,"Hi all, i try to use drone with gogs on docker. I use two images : - https://hub.docker.com/r/gogs/gogs/ - https://hub.docker.com/r/drone/drone/ i activated link to gogs and drone : i authenticted on drone with gogs login but i can not activated the webhooks someone would it do that ? Thx",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file,"webhook with gogs Hi all, i try to use drone with gogs on docker. I use two images : - https://hub.docker.com/r/gogs/gogs/ - https://hub.docker.com/r/drone/drone/ i activated link to gogs and drone : i authenticted on drone with gogs login but i can not activated the webhooks someone would it do that ? Thx source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file",no-bug,0.7
466,harness,https://github.com/harness/harness/issues/466,Restrict deploy to specific branch,"Right now with the publish plugins, you can restrict to a specific branch, but not the deploy plugins. The flow in my .drone.yml is: on all: test on master: build and publish docker image to hub on all (NOT DESIRED): deploy to staging But right now, I can't restrict the deploy to master. At least when publishing with the docker plugin, deploying is pretty senseless without the publish step. (note also that it seems that the git env we're in during the deploy step is odd. I thought I could do something like: `test ""$(git symbolic-ref --short -q HEAD)"" = ""master"" && deploy-script` But the symbolic ref is coming back empty. I also tried `$(git rev-parse --abbrev-ref HEAD)` and that just printed HEAD.) As a side note, I suspect this would be relatively easy to implement - it seems like adding a `Branch` field to the struct in `pkg/plugin/deploy/bash.go` and then replicating the logic to test branches that is in `pkg/plugin/publish/publish.go` in `pkg/plugin/deploy/deployment.go`, but I've never written anything in go before, and my attempts were thwarted by the fact that what is built by `make` dousn't seem to be the source code, at least by default (I wiped out all of `pkg` and it still built fine).",source-file,"Restrict deploy to specific branch Right now with the publish plugins, you can restrict to a specific branch, but not the deploy plugins. The flow in my .drone.yml is: on all: test on master: build and publish docker image to hub on all (NOT DESIRED): deploy to staging But right now, I can't restrict the deploy to master. At least when publishing with the docker plugin, deploying is pretty senseless without the publish step. (note also that it seems that the git env we're in during the deploy step is odd. I thought I could do something like: `test ""$(git symbolic-ref --short -q HEAD)"" = ""master"" && deploy-script` But the symbolic ref is coming back empty. I also tried `$(git rev-parse --abbrev-ref HEAD)` and that just printed HEAD.) As a side note, I suspect this would be relatively easy to implement - it seems like adding a `Branch` field to the struct in `pkg/plugin/deploy/bash.go` and then replicating the logic to test branches that is in `pkg/plugin/publish/publish.go` in `pkg/plugin/deploy/deployment.go`, but I've never written anything in go before, and my attempts were thwarted by the fact that what is built by `make` dousn't seem to be the source code, at least by default (I wiped out all of `pkg` and it still built fine). source-file",no-bug,0.9
1030,harness,https://github.com/harness/harness/issues/1030,0.4.0 Meta Issue,"This is a meta issue for 0.4.0 There are a lot of features that have not yet been ported to the 0.4 branch. Instead of tracking individually, we will track these in a meta-issue. Here are just a few and I'm sure more will be added: - [x] migrate Gitlab to 0.4 - [ ] migrate Bitbucket to 0.4 - [ ] yaml condition should include `on_success` and `on_failure` for notification plugins - [x] load config from env vars (as opposed to toml) using new `pkg/config` [pull request #1032] - [ ] re-enable multiple Docker nodes in the yaml. Currently accepts a `string`. Change to `[]string` And some bugs / features that need to be worked out: - [x] cancel a build leaves behind artifacts. The drone-build container should trap the kill event and perform cleanup before it shuts down - [x] cancel build behavior needs to change. We should be able to cancel a pending (in queue) build including all matrix builds. Once a build is started, however, we should only be able to cancel each individual matrix build. There are technical reasons for this. I can explain - [x] build timeout should be moved to the `drone-build` container instead of inside the Drone web app - [ ] verify plugin white-list works - [ ] verify global environment variables work And some UI stuff: - [x] finish styling the build page - [x] if only a single build (ie no build matrix) should immediately display build output And document the following: - [x] document api via swagger spec at `doc/swagger.json` - [x] document how to install and setup 0.4 - [x] document how to configure build yaml in 0.4 In addition, the following plugins need to be migrated to the new plugin model. Note that we will not hold up the `0.4` release on the account of plugins, since they can be added at any time without any changes to the core Drone codebase: - [ ] Email plugin at `drone-plugins/drone-email` - [ ] Hipchat plugin at `drone-plugins/drone-hipchat` - [ ] Heroku plugin using [hk](https://github.com/heroku/hk) at `drone-plugins/drone-heroku` - [x] Git Push plugin at `drone-plugins/drone-git-push` - [ ] Rsync Deploy plugin at `drone-plugins/drone-rsync` - [ ] Flowdock plugin at `drone-plugins/drone-flowdock` - [ ] NPM plugin at `drone-plugins/drone-npm` - [ ] Pypi plugin at `drone-plugins/drone-pypi` - [ ] Bintray plugin at `drone-plugins/drone-bintray` - [ ] GitHub release plugin at `drone-plugins/drone-github-release`",other-file,"0.4.0 Meta Issue This is a meta issue for 0.4.0 There are a lot of features that have not yet been ported to the 0.4 branch. Instead of tracking individually, we will track these in a meta-issue. Here are just a few and I'm sure more will be added: - [x] migrate Gitlab to 0.4 - [ ] migrate Bitbucket to 0.4 - [ ] yaml condition should include `on_success` and `on_failure` for notification plugins - [x] load config from env vars (as opposed to toml) using new `pkg/config` [pull request #1032] - [ ] re-enable multiple Docker nodes in the yaml. Currently accepts a `string`. Change to `[]string` And some bugs / features that need to be worked out: - [x] cancel a build leaves behind artifacts. The drone-build container should trap the kill event and perform cleanup before it shuts down - [x] cancel build behavior needs to change. We should be able to cancel a pending (in queue) build including all matrix builds. Once a build is started, however, we should only be able to cancel each individual matrix build. There are technical reasons for this. I can explain - [x] build timeout should be moved to the `drone-build` container instead of inside the Drone web app - [ ] verify plugin white-list works - [ ] verify global environment variables work And some UI stuff: - [x] finish styling the build page - [x] if only a single build (ie no build matrix) should immediately display build output And document the following: - [x] document api via swagger spec at `doc/swagger.json` - [x] document how to install and setup 0.4 - [x] document how to configure build yaml in 0.4 In addition, the following plugins need to be migrated to the new plugin model. Note that we will not hold up the `0.4` release on the account of plugins, since they can be added at any time without any changes to the core Drone codebase: - [ ] Email plugin at `drone-plugins/drone-email` - [ ] Hipchat plugin at `drone-plugins/drone-hipchat` - [ ] Heroku plugin using [hk](https://github.com/heroku/hk) at `drone-plugins/drone-heroku` - [x] Git Push plugin at `drone-plugins/drone-git-push` - [ ] Rsync Deploy plugin at `drone-plugins/drone-rsync` - [ ] Flowdock plugin at `drone-plugins/drone-flowdock` - [ ] NPM plugin at `drone-plugins/drone-npm` - [ ] Pypi plugin at `drone-plugins/drone-pypi` - [ ] Bintray plugin at `drone-plugins/drone-bintray` - [ ] GitHub release plugin at `drone-plugins/drone-github-release` other-file",no-bug,0.9
1048,harness,https://github.com/harness/harness/issues/1048,dumb terminal,"As discussed on gitter and http://stackoverflow.com/questions/30674922/ my builds need access to a tty (even though it is not used). It appears that passing `-t` to docker should make this work. I'd be happy to test a self-built cut of drone with this change if that helps. Just let me know the commit to cherry pick on top of the last stable (or give me a branch that I can build assuming you don't have a CI job for `.deb` snapshot files, which would be awesome btw!)",other-file,"dumb terminal As discussed on gitter and http://stackoverflow.com/questions/30674922/ my builds need access to a tty (even though it is not used). It appears that passing `-t` to docker should make this work. I'd be happy to test a self-built cut of drone with this change if that helps. Just let me know the commit to cherry pick on top of the last stable (or give me a branch that I can build assuming you don't have a CI job for `.deb` snapshot files, which would be awesome btw!) other-file",no-bug,0.9
999,harness,https://github.com/harness/harness/issues/999,question: why are PRs built against their original predecessor,"Ditto. I see two conflicting angles here: 1. a PR has the most chance of getting built against its predecessor (ie the original parent revision) 2. the _Merge pull request_ action would pull the commits and then merge them, so the consecutive build may produce a vastly different result (when other PRs are merged before) The thing here is that (2) may fail even if (1) succeeded. It would be really nice to run CI on the ""post merge"" code, whatever it happens to be at the time. That, however, is a moving target as PRs get merged in parallel What is the most meaningful way forward?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | source-file | source-file,"question: why are PRs built against their original predecessor Ditto. I see two conflicting angles here: 1. a PR has the most chance of getting built against its predecessor (ie the original parent revision) 2. the _Merge pull request_ action would pull the commits and then merge them, so the consecutive build may produce a vastly different result (when other PRs are merged before) The thing here is that (2) may fail even if (1) succeeded. It would be really nice to run CI on the ""post merge"" code, whatever it happens to be at the time. That, however, is a moving target as PRs get merged in parallel What is the most meaningful way forward? source-file source-file source-file source-file source-file source-file source-file test-file test-file test-file source-file source-file",no-bug,0.95
2446,harness,https://github.com/harness/harness/issues/2446,Support array in .drone.yml config,Currently map is used to specify steps and map doesn't guarantee order. So it would be nice to support syntax with an array like this: yaml pipeline: - name: backend image: golang commands: - go build - go test - name: frontend image: node commands: - npm install - npm run test - npm run build ,other-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file,Support array in .drone.yml config Currently map is used to specify steps and map doesn't guarantee order. So it would be nice to support syntax with an array like this: yaml pipeline: - name: backend image: golang commands: - go build - go test - name: frontend image: node commands: - npm install - npm run test - npm run build  other-file source-file source-file source-file test-file source-file source-file source-file,no-bug,0.9
810,harness,https://github.com/harness/harness/issues/810,Time estimation wrong on dashboard.,"There's an issue (not a huge one, just a minor thing) with the time estimates on the dashboard ![screen shot 2015-01-13 at 10 22 45 am](https://cloud.githubusercontent.com/assets/2027925/5724078/97978c28-9b0e-11e4-8c01-6804f145e005.png) Since I find the idea that this repository being 45 years old a little hard to swallow, I figured I'd report it here.",source-file | source-file | source-file | source-file,"Time estimation wrong on dashboard. There's an issue (not a huge one, just a minor thing) with the time estimates on the dashboard ![screen shot 2015-01-13 at 10 22 45 am](https://cloud.githubusercontent.com/assets/2027925/5724078/97978c28-9b0e-11e4-8c01-6804f145e005.png) Since I find the idea that this repository being 45 years old a little hard to swallow, I figured I'd report it here. source-file source-file source-file source-file",no-bug,0.9
779,harness,https://github.com/harness/harness/issues/779,Wierd URL stuff,"If I go to http://drone.io/shadowfacts/EnFusion, everything works perfectly fine. But if I go to http://drone.io/shadowfacts/EnFusion/ I get a 404 page not found error. The second URL should work as well.",source-file,"Wierd URL stuff If I go to http://drone.io/shadowfacts/EnFusion, everything works perfectly fine. But if I go to http://drone.io/shadowfacts/EnFusion/ I get a 404 page not found error. The second URL should work as well. source-file",bug,0.9
586,harness,https://github.com/harness/harness/issues/586,Feature: Please add branch to Slack / Hipchat notifications,"In notify messages in Slack or HipChat, you see the repo status after a build, but not the branch. We use the Gitflow method of branch strategy and have many branches. Is it possible to add which branch was built/failed in the output to the chat clients?",test-file | source-file | test-file | other-file | source-file | other-file | other-file,"Feature: Please add branch to Slack / Hipchat notifications In notify messages in Slack or HipChat, you see the repo status after a build, but not the branch. We use the Gitflow method of branch strategy and have many branches. Is it possible to add which branch was built/failed in the output to the chat clients? test-file source-file test-file other-file source-file other-file other-file",no-bug,0.9
3467,harness,https://github.com/harness/harness/issues/3467,Drone Issue | Where is host volumes data stored in drone runner container?,"I use self-hosted drone server and drone runner which all run in docker containers. I use host volumes features to set up cache for speeding up my building steps like this: yaml volumes - name: gocache host: path: /var/lib/cache/gocache  Everything works fine, building is much quicker than before. However, when I try to figure out where is the host volume data stored, I came into problems. I have only one drone runner, so I think my cache files will in my drone container, and its path will be `/var/lib/cache/gocache`. When I try to list with command `docker run drone-runner ls /var/lib/cache`, only `apk` and `misc` are listed. The cache works fine, but **where is the cache files actually**? I have no idea, could you offer to help? FYI: my drone runner version is `1.8.3`, while drone server version is `2.22.0`.",other-file,"Drone Issue | Where is host volumes data stored in drone runner container? I use self-hosted drone server and drone runner which all run in docker containers. I use host volumes features to set up cache for speeding up my building steps like this: yaml volumes - name: gocache host: path: /var/lib/cache/gocache  Everything works fine, building is much quicker than before. However, when I try to figure out where is the host volume data stored, I came into problems. I have only one drone runner, so I think my cache files will in my drone container, and its path will be `/var/lib/cache/gocache`. When I try to list with command `docker run drone-runner ls /var/lib/cache`, only `apk` and `misc` are listed. The cache works fine, but **where is the cache files actually**? I have no idea, could you offer to help? FYI: my drone runner version is `1.8.3`, while drone server version is `2.22.0`. other-file",no-bug,0.9
914,harness,https://github.com/harness/harness/issues/914,Long commit message causes postgres insert error,"The postgres schema for commits uses VARCHAR(255) for the message. If the commit message exceeds this length, then an error occurs trying to commit the commit to the DB. By the way, the error handling in the hook handler leaves a lot to be desired. A lot of these 400s really should be 500s, and all of them discard the error string instead of logging or returning it, leaving us guessing as to the cause.",source-file | test-file | source-file,"Long commit message causes postgres insert error The postgres schema for commits uses VARCHAR(255) for the message. If the commit message exceeds this length, then an error occurs trying to commit the commit to the DB. By the way, the error handling in the hook handler leaves a lot to be desired. A lot of these 400s really should be 500s, and all of them discard the error string instead of logging or returning it, leaving us guessing as to the cause. source-file test-file source-file",bug,0.85
868,harness,https://github.com/harness/harness/issues/868,Add STS header when TLS,It wil be good to add the Strict-Transport-Security header when drone is running with TLS activate.,other-file | other-file | other-file,Add STS header when TLS It wil be good to add the Strict-Transport-Security header when drone is running with TLS activate. other-file other-file other-file,no-bug,0.9
2032,harness,https://github.com/harness/harness/issues/2032,oc,<!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified on the mailing list: http://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead use the mailing list or Stack Overflow: http://discourse.drone.io/ http://stackoverflow.com/questions/tagged/drone.io -->,documentation-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | documentation-file | other-file,oc <!-- PLEASE READ BEFORE DELETING Bugs or Issues? Please do not open a GitHub issue until you have discussed and verified on the mailing list: http://discourse.drone.io/ Failing Builds? Please do not use GitHub issues for generic support questions. Instead use the mailing list or Stack Overflow: http://discourse.drone.io/ http://stackoverflow.com/questions/tagged/drone.io --> documentation-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file source-file other-file other-file source-file other-file other-file source-file documentation-file other-file other-file other-file other-file other-file other-file other-file other-file source-file documentation-file other-file,no-bug,0.9
798,harness,https://github.com/harness/harness/issues/798,Should be able to kill a test that is run away,"After starting a test, I realized my the timeout was 60 minutes. My test became run away because a background command ran in the foreground. There should be a way to kill the test through the interface.",source-file,"Should be able to kill a test that is run away After starting a test, I realized my the timeout was 60 minutes. My test became run away because a background command ran in the foreground. There should be a way to kill the test through the interface. source-file",no-bug,0.9
132,harness,https://github.com/harness/harness/issues/132,Not enough logging for not being able to add a project,"Whenever I try to add a project and it fails the log file just says: ""Not Found"" no matter what actualy went wrong. Also if I allready added the project it will also just say not found. Can we improve logging here ? Also improve the messages going back to the web page because you simply are in the dark.",documentation-file | other-file | source-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | source-file | other-file | documentation-file | other-file,"Not enough logging for not being able to add a project Whenever I try to add a project and it fails the log file just says: ""Not Found"" no matter what actualy went wrong. Also if I allready added the project it will also just say not found. Can we improve logging here ? Also improve the messages going back to the web page because you simply are in the dark. documentation-file other-file source-file other-file other-file other-file other-file source-file other-file source-file source-file other-file documentation-file other-file",no-bug,0.8
1040,harness,https://github.com/harness/harness/issues/1040,CouchDB 1.6 service,The most recent CouchDB version that is available as a service is `1.5`. The actual release is `1.6.1`.,source-file | source-file | source-file | source-file | source-file,CouchDB 1.6 service The most recent CouchDB version that is available as a service is `1.5`. The actual release is `1.6.1`. source-file source-file source-file source-file source-file,no-bug,0.9
3532,harness,https://github.com/harness/harness/issues/3532,Feature Request: MFA or external authentication via OAuth2/OIDC,"Hi, looks like a really interesting product you are building here. TL;DR: MFA and/or a generic OIDC solution would be awesome. The biggest issue that stops us from using this in a real way is security. It would be nice to have multifactor-authentication and/or external authentication (where we can have MFA). I did not find anything about this in the documentation but the way it worked in Drone was very nice, although I understand that signing in with a git-provider account kind of defeats the purpose here.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Feature Request: MFA or external authentication via OAuth2/OIDC Hi, looks like a really interesting product you are building here. TL;DR: MFA and/or a generic OIDC solution would be awesome. The biggest issue that stops us from using this in a real way is security. It would be nice to have multifactor-authentication and/or external authentication (where we can have MFA). I did not find anything about this in the documentation but the way it worked in Drone was very nice, although I understand that signing in with a git-provider account kind of defeats the purpose here. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
25,harness,https://github.com/harness/harness/issues/25,secure build config parameters,"Is what I can put in the repo's secure build params limited to just ""key: value"" pairs? I wanted to inject:  notify: email: recipients: - some@email.com  And the UI reports it saved it successfully, but if I navigate away from the page or peek at the repo's sqlite table it doesn't actually persist. Random entries like ""somekey: foo"" work fine though.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | container-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file,"secure build config parameters Is what I can put in the repo's secure build params limited to just ""key: value"" pairs? I wanted to inject:  notify: email: recipients: - some@email.com  And the UI reports it saved it successfully, but if I navigate away from the page or peek at the repo's sqlite table it doesn't actually persist. Random entries like ""somekey: foo"" work fine though. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file container-file other-file other-file source-file source-file source-file source-file source-file",no-bug,0.9
2715,harness,https://github.com/harness/harness/issues/2715,Build promote: Display environment,"With drone 1.1.0 I can promote (previously called deploy) a build with:  drone build promote [command options] <repo/name> <build> <environment>  where I can specify a target environment. In the web interface however, I can't seem to find out which environment a build has been promoted to. I only see:  user-xxx promoted `branch`  I would like instead:  user-xxx promoted `branch` to `env`  (or any other way to display that info.) I remember drone 0.8 used to display target environments when running a `drone deploy`. Thanks",source-file,"Build promote: Display environment With drone 1.1.0 I can promote (previously called deploy) a build with:  drone build promote [command options] <repo/name> <build> <environment>  where I can specify a target environment. In the web interface however, I can't seem to find out which environment a build has been promoted to. I only see:  user-xxx promoted `branch`  I would like instead:  user-xxx promoted `branch` to `env`  (or any other way to display that info.) I remember drone 0.8 used to display target environments when running a `drone deploy`. Thanks source-file",no-bug,0.9
372,harness,https://github.com/harness/harness/issues/372,Unable to run grep?,"This is weird, I have a .drone.yml as follows  image: myimage script: - cp -r /var/cache/drone/src/github.com/myuser/repo/* /srv - rm /tmp/salt.log || true - salt-call state.highstate > /tmp/salt.log - cat /tmp/salt.log - grep ""Failed: 0"" /tmp/salt.log  When it builds, the grep just never runs, ever. The logic doesn't run and the command doesn't get echo'd out to the log. I took the grep statement and put it into a bash script, and it gets executed without a problem. As soon as I add grep to any line, it no longer runs. For instance, cat /tmp/salt.log | grep hi, would cause the entire command not to run.",other-file | other-file,"Unable to run grep? This is weird, I have a .drone.yml as follows  image: myimage script: - cp -r /var/cache/drone/src/github.com/myuser/repo/* /srv - rm /tmp/salt.log || true - salt-call state.highstate > /tmp/salt.log - cat /tmp/salt.log - grep ""Failed: 0"" /tmp/salt.log  When it builds, the grep just never runs, ever. The logic doesn't run and the command doesn't get echo'd out to the log. I took the grep statement and put it into a bash script, and it gets executed without a problem. As soon as I add grep to any line, it no longer runs. For instance, cat /tmp/salt.log | grep hi, would cause the entire command not to run. other-file other-file",no-bug,0.95
429,harness,https://github.com/harness/harness/issues/429,Dockerfile fails to build,"I'm trying to build to the Dockerfile, but am getting the following error, is there something I'm missing?  Step 10 : RUN make deps > Running in dd835b8f36df go get -u -t -v ./ github.com/drone/drone (download) code.google.com/p/go.crypto (download) code.google.com/p/go.text (download) github.com/GeertJohan/go.rice (download) bitbucket.org/kardianos/osext (download) github.com/daaku/go.zipexe (download) github.com/andybons/hipchat (download) github.com/dchest/uniuri (download) github.com/dotcloud/docker (download) github.com/docker/docker (download) github.com/go-sql-driver/mysql (download) github.com/mattn/go-sqlite3 (download) github.com/russross/meddler (download) github.com/fluffle/goirc (download) code.google.com/p/gomock (download) github.com/fluffle/goevent (download) github.com/fluffle/golog (download) launchpad.net/goyaml (download) code.google.com/p/go.net (download) github.com/bmizerany/pat (download) github.com/dchest/authcookie (download) github.com/dchest/passwordreset (download) github.com/drone/go-github (download) github.com/drone/go-bitbucket (download) github.com/plouc/go-gitlab-client (download) github.com/smartystreets/goconvey (download) Fetching https://gopkg.in/v1/yaml?go-get=1 Parsing meta tags from https://gopkg.in/v1/yaml?go-get=1 (status code 200) get ""gopkg.in/v1/yaml"": found meta tag main.metaImport{Prefix:""gopkg.in/v1/yaml"", VCS:""git"", RepoRoot:""https://gopkg.in/v1/yaml""} at https://gopkg.in/v1/yaml?go-get=1 gopkg.in/v1/yaml (download) github.com/drone/drone/pkg/build/buildfile github.com/docker/docker/pkg/log github.com/docker/docker/pkg/system github.com/docker/docker/dockerversion github.com/docker/docker/pkg/term github.com/docker/docker/pkg/units github.com/docker/docker/vendor/src/code.google.com/p/go/src/pkg/archive/tar github.com/dotcloud/docker/pkg/term github.com/drone/drone/pkg/build/dockerfile github.com/drone/drone/pkg/build/log github.com/drone/drone/pkg/build/proxy github.com/drone/drone/pkg/build/repo github.com/drone/drone/pkg/build/git github.com/andybons/hipchat github.com/dchest/uniuri code.google.com/p/go.crypto/blowfish code.google.com/p/go.crypto/ssh code.google.com/p/go.text/transform github.com/go-sql-driver/mysql github.com/mattn/go-sqlite3 github.com/russross/meddler bitbucket.org/kardianos/osext github.com/GeertJohan/go.rice/embedded github.com/daaku/go.zipexe code.google.com/p/gomock/gomock launchpad.net/goyaml code.google.com/p/go.net/websocket github.com/bmizerany/pat github.com/dchest/authcookie github.com/drone/go-github/github github.com/drone/go-bitbucket/oauth1 github.com/drone/go-github/oauth2 github.com/plouc/go-gitlab-client github.com/drone/drone/pkg/database/encrypt code.google.com/p/go.crypto/bcrypt github.com/drone/drone/pkg/database/schema github.com/drone/drone/pkg/handler/testing github.com/dchest/passwordreset github.com/drone/drone/pkg/plugin/deploy github.com/GeertJohan/go.rice github.com/drone/drone/pkg/plugin/publish code.google.com/p/go.text/unicode/norm github.com/drone/drone/pkg/database/migrate github.com/fluffle/goevent/event github.com/fluffle/golog/logging github.com/docker/docker/utils github.com/dotcloud/docker/utils github.com/drone/drone/pkg/channel github.com/drone/go-bitbucket/bitbucket github.com/fluffle/goirc/state github.com/drone/drone/pkg/template github.com/drone/drone/pkg/database/migrate/testing github.com/fluffle/goirc/client github.com/dotcloud/docker/archive github.com/drone/drone/pkg/build/docker github.com/drone/drone/pkg/model # github.com/drone/drone/pkg/build/docker pkg/build/docker/image.go:66: undefined: ""github.com/dotcloud/docker/utils"".ParseRepositoryTag github.com/drone/drone/pkg/database github.com/drone/drone/pkg/mail github.com/drone/drone/pkg/database/testing github.com/drone/drone/pkg/plugin/notify github.com/drone/drone/pkg/build/script make:  [deps] Error 2 2014/08/20 09:15:28 The command [/bin/sh -c make deps] returned a non-zero code: 2 ",source-file | other-file | documentation-file | other-file | other-file | other-file | other-file,"Dockerfile fails to build I'm trying to build to the Dockerfile, but am getting the following error, is there something I'm missing?  Step 10 : RUN make deps > Running in dd835b8f36df go get -u -t -v ./ github.com/drone/drone (download) code.google.com/p/go.crypto (download) code.google.com/p/go.text (download) github.com/GeertJohan/go.rice (download) bitbucket.org/kardianos/osext (download) github.com/daaku/go.zipexe (download) github.com/andybons/hipchat (download) github.com/dchest/uniuri (download) github.com/dotcloud/docker (download) github.com/docker/docker (download) github.com/go-sql-driver/mysql (download) github.com/mattn/go-sqlite3 (download) github.com/russross/meddler (download) github.com/fluffle/goirc (download) code.google.com/p/gomock (download) github.com/fluffle/goevent (download) github.com/fluffle/golog (download) launchpad.net/goyaml (download) code.google.com/p/go.net (download) github.com/bmizerany/pat (download) github.com/dchest/authcookie (download) github.com/dchest/passwordreset (download) github.com/drone/go-github (download) github.com/drone/go-bitbucket (download) github.com/plouc/go-gitlab-client (download) github.com/smartystreets/goconvey (download) Fetching https://gopkg.in/v1/yaml?go-get=1 Parsing meta tags from https://gopkg.in/v1/yaml?go-get=1 (status code 200) get ""gopkg.in/v1/yaml"": found meta tag main.metaImport{Prefix:""gopkg.in/v1/yaml"", VCS:""git"", RepoRoot:""https://gopkg.in/v1/yaml""} at https://gopkg.in/v1/yaml?go-get=1 gopkg.in/v1/yaml (download) github.com/drone/drone/pkg/build/buildfile github.com/docker/docker/pkg/log github.com/docker/docker/pkg/system github.com/docker/docker/dockerversion github.com/docker/docker/pkg/term github.com/docker/docker/pkg/units github.com/docker/docker/vendor/src/code.google.com/p/go/src/pkg/archive/tar github.com/dotcloud/docker/pkg/term github.com/drone/drone/pkg/build/dockerfile github.com/drone/drone/pkg/build/log github.com/drone/drone/pkg/build/proxy github.com/drone/drone/pkg/build/repo github.com/drone/drone/pkg/build/git github.com/andybons/hipchat github.com/dchest/uniuri code.google.com/p/go.crypto/blowfish code.google.com/p/go.crypto/ssh code.google.com/p/go.text/transform github.com/go-sql-driver/mysql github.com/mattn/go-sqlite3 github.com/russross/meddler bitbucket.org/kardianos/osext github.com/GeertJohan/go.rice/embedded github.com/daaku/go.zipexe code.google.com/p/gomock/gomock launchpad.net/goyaml code.google.com/p/go.net/websocket github.com/bmizerany/pat github.com/dchest/authcookie github.com/drone/go-github/github github.com/drone/go-bitbucket/oauth1 github.com/drone/go-github/oauth2 github.com/plouc/go-gitlab-client github.com/drone/drone/pkg/database/encrypt code.google.com/p/go.crypto/bcrypt github.com/drone/drone/pkg/database/schema github.com/drone/drone/pkg/handler/testing github.com/dchest/passwordreset github.com/drone/drone/pkg/plugin/deploy github.com/GeertJohan/go.rice github.com/drone/drone/pkg/plugin/publish code.google.com/p/go.text/unicode/norm github.com/drone/drone/pkg/database/migrate github.com/fluffle/goevent/event github.com/fluffle/golog/logging github.com/docker/docker/utils github.com/dotcloud/docker/utils github.com/drone/drone/pkg/channel github.com/drone/go-bitbucket/bitbucket github.com/fluffle/goirc/state github.com/drone/drone/pkg/template github.com/drone/drone/pkg/database/migrate/testing github.com/fluffle/goirc/client github.com/dotcloud/docker/archive github.com/drone/drone/pkg/build/docker github.com/drone/drone/pkg/model # github.com/drone/drone/pkg/build/docker pkg/build/docker/image.go:66: undefined: ""github.com/dotcloud/docker/utils"".ParseRepositoryTag github.com/drone/drone/pkg/database github.com/drone/drone/pkg/mail github.com/drone/drone/pkg/database/testing github.com/drone/drone/pkg/plugin/notify github.com/drone/drone/pkg/build/script make:  [deps] Error 2 2014/08/20 09:15:28 The command [/bin/sh -c make deps] returned a non-zero code: 2  source-file other-file documentation-file other-file other-file other-file other-file",no-bug,0.95
1074,harness,https://github.com/harness/harness/issues/1074,Support rust 1.1.0,Subj.,other-file,Support rust 1.1.0 Subj. other-file,no-bug,0.9
63,harness,https://github.com/harness/harness/issues/63,How can I know which commits the latest drone.deb includes without reinstalling Drone?,How can I know which commits the latest drone.deb includes without reinstalling Drone? The latest drone.deb includes merged PR as soon as possible?,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,How can I know which commits the latest drone.deb includes without reinstalling Drone? How can I know which commits the latest drone.deb includes without reinstalling Drone? The latest drone.deb includes merged PR as soon as possible? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file other-file,no-bug,0.9
2850,harness,https://github.com/harness/harness/issues/2850,[>=1.5.0] Docker pipeline unable to start / is stalled.,"Using Drone with the command `docker run --volume=/var/run/docker.sock:/var/run/docker.sock --volume=/var/lib/drone:/data --env-file=./drone.env --publish=80:80 --publish=443:443 --restart=always --name=drone drone/drone:1.5.0` causes all new builds to stall / hang and not even start when pushing a new commit (from GitHub). Using the UI and going into a stalled build, it just shows the name of the pipeline, and does not show the individual steps of the pipeline like it used to. Downgrading to 1.4.0 allows pipelines to run as normal when pushing a new commit.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[>=1.5.0] Docker pipeline unable to start / is stalled. Using Drone with the command `docker run --volume=/var/run/docker.sock:/var/run/docker.sock --volume=/var/lib/drone:/data --env-file=./drone.env --publish=80:80 --publish=443:443 --restart=always --name=drone drone/drone:1.5.0` causes all new builds to stall / hang and not even start when pushing a new commit (from GitHub). Using the UI and going into a stalled build, it just shows the name of the pipeline, and does not show the individual steps of the pipeline like it used to. Downgrading to 1.4.0 allows pipelines to run as normal when pushing a new commit. source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
975,harness,https://github.com/harness/harness/issues/975,"Modify REST endpoints to use build number, and support build matrix","The 0.4 angular app and REST API are complete but the routes are a bit messy. This is my proposal to cleanup the routes and finalize our REST API:  sh GET PUT /api/user # get, update currently authenticated user GET /api/user/repos # gets all repos the user is watching GET /api/user/tokens POST /api/user/tokens/:label # creates a token with the given label GET PUT POST /api/repos/:owner/:repo POST /api/repos/:owner/:repo/watch DEL /api/repos/:owner/:repo/unwatch GET /api/repos/:owner/:repo/builds # gets recent builds for the repository GET DEL POST /api/repos/:owner/:repo/builds/:build # delete and post will cancel, restart a build, get will return the build and all build tasks GET /api/repos/:owner/:repo/builds/:build/:task # returns a specific build task GET /api/repos/:owner/:repo/builds/:build/:task/logs POST /api/builds/drone/drone/builds/:build/status # gets all build statuses GET /api/builds/drone/drone/builds/:build/status/:label # appends a build status POST /hook # receives post-commit hook from github, etc ",source-file | source-file | source-file,"Modify REST endpoints to use build number, and support build matrix The 0.4 angular app and REST API are complete but the routes are a bit messy. This is my proposal to cleanup the routes and finalize our REST API:  sh GET PUT /api/user # get, update currently authenticated user GET /api/user/repos # gets all repos the user is watching GET /api/user/tokens POST /api/user/tokens/:label # creates a token with the given label GET PUT POST /api/repos/:owner/:repo POST /api/repos/:owner/:repo/watch DEL /api/repos/:owner/:repo/unwatch GET /api/repos/:owner/:repo/builds # gets recent builds for the repository GET DEL POST /api/repos/:owner/:repo/builds/:build # delete and post will cancel, restart a build, get will return the build and all build tasks GET /api/repos/:owner/:repo/builds/:build/:task # returns a specific build task GET /api/repos/:owner/:repo/builds/:build/:task/logs POST /api/builds/drone/drone/builds/:build/status # gets all build statuses GET /api/builds/drone/drone/builds/:build/status/:label # appends a build status POST /hook # receives post-commit hook from github, etc  source-file source-file source-file",no-bug,0.8
692,harness,https://github.com/harness/harness/issues/692,Private Parameters Injection Lazy Behavior,"While testing Private Parameters during build I came across an interesting behavior . During variable injection it seems that it is using a _lazy_ match. **I was wondering if this was a bug or intended?** For example (Look at the **registry_login_url** entry): A drone.yml file with:   docker: dockerfile: Dockerfile image_name: $$username/wsapp docker_host: $$docker_host docker_version: $$docker_version registry_login_url: $$registry_login_url registry_login: $$registry_login username: $$username password: $$password email: $$email keep_builds: false tag: 0.1 branch: master   And the Private Params contain:   username: someUser password: somePassword email: someEmail@email.email docker_host: tcp://0.0.0.0:2375 docker_version: 1.3.0 registry_login: true registry_login_url: https://registry.hub.docker.com/v1/   The above will then be injected in the drone.yml as:   docker: dockerfile: Dockerfile image_name: someUser/someregistry docker_host: tcp://0.0.0.0:2375 docker_version: 1.3.0 registry_login_url: true_url registry_login: true username: someUser password: somePassword email: someEmail@email.email keep_builds: false tag: 0.1 branch: master   As you can see the **registry_login** entry is a subset of **registry_login_url** and it is contained within the beginning of that entry, so when the Params are injected, the **registry_login** entry value will be inserted into **registry_login_url** thus creating **true_url** I haven't tested other scenarios.",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Private Parameters Injection Lazy Behavior While testing Private Parameters during build I came across an interesting behavior . During variable injection it seems that it is using a _lazy_ match. **I was wondering if this was a bug or intended?** For example (Look at the **registry_login_url** entry): A drone.yml file with:   docker: dockerfile: Dockerfile image_name: $$username/wsapp docker_host: $$docker_host docker_version: $$docker_version registry_login_url: $$registry_login_url registry_login: $$registry_login username: $$username password: $$password email: $$email keep_builds: false tag: 0.1 branch: master   And the Private Params contain:   username: someUser password: somePassword email: someEmail@email.email docker_host: tcp://0.0.0.0:2375 docker_version: 1.3.0 registry_login: true registry_login_url: https://registry.hub.docker.com/v1/   The above will then be injected in the drone.yml as:   docker: dockerfile: Dockerfile image_name: someUser/someregistry docker_host: tcp://0.0.0.0:2375 docker_version: 1.3.0 registry_login_url: true_url registry_login: true username: someUser password: somePassword email: someEmail@email.email keep_builds: false tag: 0.1 branch: master   As you can see the **registry_login** entry is a subset of **registry_login_url** and it is contained within the beginning of that entry, so when the Params are injected, the **registry_login** entry value will be inserted into **registry_login_url** thus creating **true_url** I haven't tested other scenarios. source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
2739,harness,https://github.com/harness/harness/issues/2739,Drone UI not accessible due to bad port configuration,"Running `drone/drone:1` on Kubernetes results in a broken web UI. The cause seems to be a malformed port configuration, which is logged by the pod on startup: {""acme"":false,""host"":""drone.mydomain.com"",""level"":""info"",""msg"":""starting the http server"",""port"":""tcp://1.2.3.4:80"",""proto"":""https"",""time"":""2019-06-23T09:17:21Z"",""url"":""https://drone.mydomain.com""} No explicit port is set. With this configuration, the web UI is inaccessible even when using `kubectl exec` to get into the pod. I currently use the following workaround. DRONE_SERVER_PORT: "":80"" Setting this should not be necessary, right? It seems like drone is auto-discovering some kind of cluster IP (real IP redacted in the log above) and adding it to the port config. Or maybe my configuration is wrong. I'm pasting the entire `yaml` file below.",other-file | other-file | source-file | other-file,"Drone UI not accessible due to bad port configuration Running `drone/drone:1` on Kubernetes results in a broken web UI. The cause seems to be a malformed port configuration, which is logged by the pod on startup: {""acme"":false,""host"":""drone.mydomain.com"",""level"":""info"",""msg"":""starting the http server"",""port"":""tcp://1.2.3.4:80"",""proto"":""https"",""time"":""2019-06-23T09:17:21Z"",""url"":""https://drone.mydomain.com""} No explicit port is set. With this configuration, the web UI is inaccessible even when using `kubectl exec` to get into the pod. I currently use the following workaround. DRONE_SERVER_PORT: "":80"" Setting this should not be necessary, right? It seems like drone is auto-discovering some kind of cluster IP (real IP redacted in the log above) and adding it to the port config. Or maybe my configuration is wrong. I'm pasting the entire `yaml` file below. other-file other-file source-file other-file",no-bug,0.9
3387,harness,https://github.com/harness/harness/issues/3387,Security - docker-scout vulnerability scan shows too many issues,"When I pulled the gitness latest image and ran a vulnerability scanner from docker-scout, it shows me too many high and critical issues. Have you considered these reports?",other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file,"Security - docker-scout vulnerability scan shows too many issues When I pulled the gitness latest image and ran a vulnerability scanner from docker-scout, it shows me too many high and critical issues. Have you considered these reports? other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file",no-bug,0.9
882,harness,https://github.com/harness/harness/issues/882,WS: Error getting permissions for repository,"In some repositories I get following error in logs: `WS: Error getting permissions for repository grid-client-js. Error: sql: no rows in result set` And no output in UI is printed. However after build is finished, all output is there. Where should I start digging?",source-file | source-file | source-file | source-file | other-file,"WS: Error getting permissions for repository In some repositories I get following error in logs: `WS: Error getting permissions for repository grid-client-js. Error: sql: no rows in result set` And no output in UI is printed. However after build is finished, all output is there. Where should I start digging? source-file source-file source-file source-file other-file",no-bug,0.8
2048,harness,https://github.com/harness/harness/issues/2048,"client is newer than server (client API version: 1.26, server API version: 1.24)","Quote of the ""full"" error log in the build: `ERROR: Error response from daemon: client is newer than server (client API version: 1.26, server API version: 1.24)` Infrastructure is on Rancher with [CoreOS Stable](https://coreos.com/releases/) currently running docker version `1.12.6`. Where do I start to dig deeper as to why this error happens?",source-file | source-file,"client is newer than server (client API version: 1.26, server API version: 1.24) Quote of the ""full"" error log in the build: `ERROR: Error response from daemon: client is newer than server (client API version: 1.26, server API version: 1.24)` Infrastructure is on Rancher with [CoreOS Stable](https://coreos.com/releases/) currently running docker version `1.12.6`. Where do I start to dig deeper as to why this error happens? source-file source-file",no-bug,0.9
2851,harness,https://github.com/harness/harness/issues/2851,Does webhook interface support custom pipelines,I want webhook event to support pipeline parameters instead of creating .yaml file in the repository. Is there any way to achieve it?,source-file,Does webhook interface support custom pipelines I want webhook event to support pipeline parameters instead of creating .yaml file in the repository. Is there any way to achieve it? source-file,no-bug,0.7
959,harness,https://github.com/harness/harness/issues/959,Database Repo Foreign Keys,"Deleting a repository should remove all associated keys, params, builds, build tasks and logs: https://github.com/drone/drone/blob/bolt/datastore/bolt/repo.go#L69",source-file | test-file | source-file | source-file,"Database Repo Foreign Keys Deleting a repository should remove all associated keys, params, builds, build tasks and logs: https://github.com/drone/drone/blob/bolt/datastore/bolt/repo.go#L69 source-file test-file source-file source-file",no-bug,0.9
2003,harness,https://github.com/harness/harness/issues/2003,discuss.drone.io moved -> discourse.drone.io,trying to open https://discuss.drone.io/c/how-tos I get: ![screenshot from 2017-04-13 17-47-32](https://cloud.githubusercontent.com/assets/1733686/24999760/60f44e78-2071-11e7-93ef-be073404ca1b.png),source-file | source-file | source-file,discuss.drone.io moved -> discourse.drone.io trying to open https://discuss.drone.io/c/how-tos I get: ![screenshot from 2017-04-13 17-47-32](https://cloud.githubusercontent.com/assets/1733686/24999760/60f44e78-2071-11e7-93ef-be073404ca1b.png) source-file source-file source-file,no-bug,0.9
1003,harness,https://github.com/harness/harness/issues/1003,Scala 2.11 support,"Looked great, and I started setting up Drone for my projects. But then I realized that only Scala 2.9 is supported! Sadly I had to pull myself out of using Drone. :( Can you please start support for Scala 2.11?",source-file | source-file | source-file,"Scala 2.11 support Looked great, and I started setting up Drone for my projects. But then I realized that only Scala 2.9 is supported! Sadly I had to pull myself out of using Drone. :( Can you please start support for Scala 2.11? source-file source-file source-file",no-bug,0.9
1140,harness,https://github.com/harness/harness/issues/1140,Support `.drone.yml` and `.drone.yaml` variant,"I made the mistake of setting up my project with '.drone.yaml' file. I know the project setup instruction specifically say to create a '.drone.yml' file but it should really support '.drone.yaml' as well. i mean the official website is yaml.org and I think the '.yaml' extension is more widely used. I was only able to figure out after getting help from the Gitter drone channel, shout out to tboerger! Error from drone log: https://api.github.com/repos/zaro0508/play2/contents/.drone.yml?ref=9161a2ae341eed1c5fcbe54c1d037ba0ba41e102: 404 Not Found []",source-file | documentation-file | other-file | source-file | other-file | source-file,"Support `.drone.yml` and `.drone.yaml` variant I made the mistake of setting up my project with '.drone.yaml' file. I know the project setup instruction specifically say to create a '.drone.yml' file but it should really support '.drone.yaml' as well. i mean the official website is yaml.org and I think the '.yaml' extension is more widely used. I was only able to figure out after getting help from the Gitter drone channel, shout out to tboerger! Error from drone log: https://api.github.com/repos/zaro0508/play2/contents/.drone.yml?ref=9161a2ae341eed1c5fcbe54c1d037ba0ba41e102: 404 Not Found [] source-file documentation-file other-file source-file other-file source-file",no-bug,0.9
925,harness,https://github.com/harness/harness/issues/925,Build in Ramdisk,add an option to clone repository into a ramdisk. i had experienced performance improvements by using a ramdisk inside a docker container. maybe add an option for the drone admin to disable it since the hosted version has not unlimited RAM and maybe everybody uses it.,other-file,Build in Ramdisk add an option to clone repository into a ramdisk. i had experienced performance improvements by using a ramdisk inside a docker container. maybe add an option for the drone admin to disable it since the hosted version has not unlimited RAM and maybe everybody uses it. other-file,no-bug,0.95
50,harness,https://github.com/harness/harness/issues/50,Error when a non-admin tries to add a repo,When a non-admin goes to add a repository to their dashboard the first time they are (correctly) prompted to link their Github accounts. This always causes an error when the Github callback URL is invoked: `meddler.Update: DB error in Exec: column token is not unique` I believe this error is being thrown around line 85 of `pkg/handler/auth.go` but I won't be able to take a look until later tonight.,test-file | source-file | documentation-file | other-file | other-file | other-file | other-file | source-file | other-file | test-file | test-file | test-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file,Error when a non-admin tries to add a repo When a non-admin goes to add a repository to their dashboard the first time they are (correctly) prompted to link their Github accounts. This always causes an error when the Github callback URL is invoked: `meddler.Update: DB error in Exec: column token is not unique` I believe this error is being thrown around line 85 of `pkg/handler/auth.go` but I won't be able to take a look until later tonight. test-file source-file documentation-file other-file other-file other-file other-file source-file other-file test-file test-file test-file source-file source-file other-file other-file other-file other-file other-file,no-bug,0.8
1008,harness,https://github.com/harness/harness/issues/1008,Documentation request: add installation from sources,Currently it is not clear (also Makefile default build option is something different from this) how to install Drone from the git sources (and how to update without harming settings/database). It would awesome to add these instructions in the readme or /doc.,source-file | source-file | source-file | source-file,Documentation request: add installation from sources Currently it is not clear (also Makefile default build option is something different from this) how to install Drone from the git sources (and how to update without harming settings/database). It would awesome to add these instructions in the readme or /doc. source-file source-file source-file source-file,no-bug,0.95
431,harness,https://github.com/harness/harness/issues/431,Reproducible builds using Gitian LXC containers,"Reproducible builds using Gitian (the build system used by Bitcoin and Tor) would be really useful, a potential killer app which services like Travis-CI can't handle. Reportedly Gitian is working within Docker. Some more info is posted at https://github.com/devrandom/gitian-builder/issues/53 . Could this be integrated with Drone?",source-file | documentation-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | source-file | other-file | source-file | documentation-file | documentation-file | other-file | source-file | other-file | other-file | source-file | other-file,"Reproducible builds using Gitian LXC containers Reproducible builds using Gitian (the build system used by Bitcoin and Tor) would be really useful, a potential killer app which services like Travis-CI can't handle. Reportedly Gitian is working within Docker. Some more info is posted at https://github.com/devrandom/gitian-builder/issues/53 . Could this be integrated with Drone? source-file documentation-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file other-file other-file source-file documentation-file other-file source-file other-file source-file documentation-file documentation-file other-file source-file other-file other-file source-file other-file",no-bug,0.95
2500,harness,https://github.com/harness/harness/issues/2500,About linking external containers,"I need to link the external database container to generate data in my build step. But `.drone.yml` has no **external_links** option. Does it mean that it cannot be done? Sorry, my discourse.drone.io account has been placed on hold so I posted it here.",source-file | source-file | source-file | source-file | source-file | source-file,"About linking external containers I need to link the external database container to generate data in my build step. But `.drone.yml` has no **external_links** option. Does it mean that it cannot be done? Sorry, my discourse.drone.io account has been placed on hold so I posted it here. source-file source-file source-file source-file source-file source-file",no-bug,0.9
1206,harness,https://github.com/harness/harness/issues/1206,create mariadb database if not existant,Is there a reason the database is not generated based on the information the drone.toml config file provides (given authorization is granted)? Or is this due to the fact that the operation db user may not have sufficient rights to create a database?,source-file | source-file,create mariadb database if not existant Is there a reason the database is not generated based on the information the drone.toml config file provides (given authorization is granted)? Or is this due to the fact that the operation db user may not have sufficient rights to create a database? source-file source-file,no-bug,0.9
3384,harness,https://github.com/harness/harness/issues/3384,Need information about Gitness development stage,"In the README it's mentioned: > Drone development will continue in the drone branch until we a ready for our first tagged Gitness release, at which point the project will fully converge. I'm here to question about the current stage of Gitness development. I've tested it, and it worked well. However, couldn't find information in the README or the docs regarding whether it's production-ready. I apologize if I've missed this information.",other-file | other-file | other-file,"Need information about Gitness development stage In the README it's mentioned: > Drone development will continue in the drone branch until we a ready for our first tagged Gitness release, at which point the project will fully converge. I'm here to question about the current stage of Gitness development. I've tested it, and it worked well. However, couldn't find information in the README or the docs regarding whether it's production-ready. I apologize if I've missed this information. other-file other-file other-file",no-bug,0.95
2805,harness,https://github.com/harness/harness/issues/2805,Please reopen #2628,"I commented on https://github.com/drone/drone/issues/2628 a few months ago, as the issue as described was never fully implemented. Can it be reopened, or at least clarified?",source-file | source-file | source-file | source-file | source-file,"Please reopen #2628 I commented on https://github.com/drone/drone/issues/2628 a few months ago, as the issue as described was never fully implemented. Can it be reopened, or at least clarified? source-file source-file source-file source-file source-file",no-bug,0.7
84,harness,https://github.com/harness/harness/issues/84,image for D,"I really like the idea of having a web service like drone.io to build projects. I have still to find a service that provides ways to build D (http://dlang.org) projects with dedictated environments. So can drone be the first one please? With some guidance on your ways of providing images, I'm likely able to provide an image myself. I guess a D image should be pulled into the drone/images repo right? Is this Repo also providing images for the drone.io web service?",other-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | documentation-file | other-file | source-file,"image for D I really like the idea of having a web service like drone.io to build projects. I have still to find a service that provides ways to build D (http://dlang.org) projects with dedictated environments. So can drone be the first one please? With some guidance on your ways of providing images, I'm likely able to provide an image myself. I guess a D image should be pulled into the drone/images repo right? Is this Repo also providing images for the drone.io web service? other-file source-file other-file other-file source-file other-file other-file source-file documentation-file other-file source-file",no-bug,0.95
8,harness,https://github.com/harness/harness/issues/8,Wrong links at add repository page?,Wondering if [this](https://github.com/drone/drone/blob/master/pkg/template/pages/github_add.html#L17) were suppposed to be `/new/github.com` instead of `/github.com/drone/drone/settings`? also in github_link.html,documentation-file | other-file | other-file | source-file | test-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Wrong links at add repository page? Wondering if [this](https://github.com/drone/drone/blob/master/pkg/template/pages/github_add.html#L17) were suppposed to be `/new/github.com` instead of `/github.com/drone/drone/settings`? also in github_link.html documentation-file other-file other-file source-file test-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.8
3013,harness,https://github.com/harness/harness/issues/3013,[Feature] Missing Vertex For Clone In Local Exec,"As a developer, it would be nice not to constantly modify drone yaml on pipelines that have dependency chains to test them locally. bash $ drone exec --branch master --event pull_request 2020/08/21 09:08:02 missing vertex  Missing vertex errors show up when locally running a pipeline that happens to have a dependency chain (`depends_on`), the server requires the first stage to have a depends on set for the `clone` stage in order to start the dependency chain, while the local exec environment does not perform a clone step (since the code understood to be already present). yaml - name: step1 image: user/image:1.0.0 depends_on: - clone  It would be great if the `clone` dependency could somehow be understood / ignored when using local exec environments.  References - https://discourse.drone.io/t/drone-exec-doesnt-execute-multi-machine-pipeline/4127/3 - https://discourse.drone.io/t/missing-vertex-error/3274",other-file | source-file | other-file | source-file | other-file | other-file | documentation-file | source-file | other-file | documentation-file,"[Feature] Missing Vertex For Clone In Local Exec As a developer, it would be nice not to constantly modify drone yaml on pipelines that have dependency chains to test them locally. bash $ drone exec --branch master --event pull_request 2020/08/21 09:08:02 missing vertex  Missing vertex errors show up when locally running a pipeline that happens to have a dependency chain (`depends_on`), the server requires the first stage to have a depends on set for the `clone` stage in order to start the dependency chain, while the local exec environment does not perform a clone step (since the code understood to be already present). yaml - name: step1 image: user/image:1.0.0 depends_on: - clone  It would be great if the `clone` dependency could somehow be understood / ignored when using local exec environments.  References - https://discourse.drone.io/t/drone-exec-doesnt-execute-multi-machine-pipeline/4127/3 - https://discourse.drone.io/t/missing-vertex-error/3274 other-file source-file other-file source-file other-file other-file documentation-file source-file other-file documentation-file",no-bug,0.9
653,harness,https://github.com/harness/harness/issues/653,Can't load the install page,"I followed the instructions  wget downloads.drone.io/master/drone.rpm $ sha1sum drone.rpm 674747c3bd58640b34a5f0d36c0d12be16af894a drone.rpm sudo yum localinstall drone.rpm droned  Then I typed `localhost/install` in web browser, and got nothing:  <!doctype html> <html ng-app=""app""> <head> <meta charset=""utf-8""> <meta name=""author"" content=""Brad Rydzewski"" /> <meta name=""viewport"" content=""width=device-width, user-scalable=no""> <title></title> <link rel=""shortcut icon"" href=""/static/favicon.ico"" /> <link rel=""stylesheet"" href=""//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css"" /> <link rel=""stylesheet"" href=""//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/grids-responsive-min.css"" /> <link rel=""stylesheet"" href=""//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css"" /> <link rel=""stylesheet"" href=""//fonts.googleapis.com/css?family=Open+Sans"" /> <link rel=""stylesheet"" href=""//fonts.googleapis.com/css?family=Orbitron"" /> <link rel=""stylesheet"" href=""//fonts.googleapis.com/css?family=Droid+Sans+Mono"" /> <link rel=""stylesheet"" href=""/static/styles/drone.css"" /> </head> <body ng-controller=""MainCtrl"" ng-cloak> <div id=""container""> <input id=""drawer-checkbox"" type=""checkbox"" ng-if=""user != undefined"" /> <header id=""header"" ng-include src="" '/static/views/header.html' ""></header> <aside id=""drawer"" ng-include src="" '/static/views/drawer.html' ""></aside> <div ng-view id=""body""></div> </div> <script src=""//cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js""></script> <script src=""//cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular-route.min.js""></script> <script src=""//cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular-resource.min.js""></script> <script src=""//cdnjs.cloudflare.com/ajax/libs/angular-ui/0.4.0/angular-ui.min.js""></script> <script src=""//cdnjs.cloudflare.com/ajax/libs/moment.js/2.6.0/moment.min.js""></script> <!-- main javascript application --> <script src=""/static/scripts/line_formatter.js""></script> <script src=""/static/scripts/commit_updates.js""></script> <script src=""/static/scripts/app.js""></script> <script src=""/static/scripts/controllers/conf.js""></script> <script src=""/static/scripts/controllers/home.js""></script> <script src=""/static/scripts/controllers/repo.js""></script> <script src=""/static/scripts/controllers/commit.js""></script> <script src=""/static/scripts/controllers/user.js""></script> <script src=""/static/scripts/controllers/users.js""></script> <script src=""/static/scripts/controllers/setup.js""></script> <script src=""/static/scripts/controllers/sync.js""></script> <script src=""/static/scripts/controllers/main.js""></script> <script src=""/static/scripts/controllers/login.js""></script> <script src=""/static/scripts/controllers/logout.js""></script> <script src=""/static/scripts/services/auth.js""></script> <script src=""/static/scripts/services/conf.js""></script> <script src=""/static/scripts/services/repo.js""></script> <script src=""/static/scripts/services/user.js""></script> <script src=""/static/scripts/services/feed.js""></script> <script src=""/static/scripts/services/remote.js""></script> <script src=""/static/scripts/services/stdout.js""></script> <script src=""/static/scripts/filters/filters.js""></script> </body> </html>  Is this a bug? How should this be fixed?",other-file | other-file,"Can't load the install page I followed the instructions  wget downloads.drone.io/master/drone.rpm $ sha1sum drone.rpm 674747c3bd58640b34a5f0d36c0d12be16af894a drone.rpm sudo yum localinstall drone.rpm droned  Then I typed `localhost/install` in web browser, and got nothing:  <!doctype html> <html ng-app=""app""> <head> <meta charset=""utf-8""> <meta name=""author"" content=""Brad Rydzewski"" /> <meta name=""viewport"" content=""width=device-width, user-scalable=no""> <title></title> <link rel=""shortcut icon"" href=""/static/favicon.ico"" /> <link rel=""stylesheet"" href=""//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css"" /> <link rel=""stylesheet"" href=""//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/grids-responsive-min.css"" /> <link rel=""stylesheet"" href=""//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css"" /> <link rel=""stylesheet"" href=""//fonts.googleapis.com/css?family=Open+Sans"" /> <link rel=""stylesheet"" href=""//fonts.googleapis.com/css?family=Orbitron"" /> <link rel=""stylesheet"" href=""//fonts.googleapis.com/css?family=Droid+Sans+Mono"" /> <link rel=""stylesheet"" href=""/static/styles/drone.css"" /> </head> <body ng-controller=""MainCtrl"" ng-cloak> <div id=""container""> <input id=""drawer-checkbox"" type=""checkbox"" ng-if=""user != undefined"" /> <header id=""header"" ng-include src="" '/static/views/header.html' ""></header> <aside id=""drawer"" ng-include src="" '/static/views/drawer.html' ""></aside> <div ng-view id=""body""></div> </div> <script src=""//cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular.min.js""></script> <script src=""//cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular-route.min.js""></script> <script src=""//cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.8/angular-resource.min.js""></script> <script src=""//cdnjs.cloudflare.com/ajax/libs/angular-ui/0.4.0/angular-ui.min.js""></script> <script src=""//cdnjs.cloudflare.com/ajax/libs/moment.js/2.6.0/moment.min.js""></script> <!-- main javascript application --> <script src=""/static/scripts/line_formatter.js""></script> <script src=""/static/scripts/commit_updates.js""></script> <script src=""/static/scripts/app.js""></script> <script src=""/static/scripts/controllers/conf.js""></script> <script src=""/static/scripts/controllers/home.js""></script> <script src=""/static/scripts/controllers/repo.js""></script> <script src=""/static/scripts/controllers/commit.js""></script> <script src=""/static/scripts/controllers/user.js""></script> <script src=""/static/scripts/controllers/users.js""></script> <script src=""/static/scripts/controllers/setup.js""></script> <script src=""/static/scripts/controllers/sync.js""></script> <script src=""/static/scripts/controllers/main.js""></script> <script src=""/static/scripts/controllers/login.js""></script> <script src=""/static/scripts/controllers/logout.js""></script> <script src=""/static/scripts/services/auth.js""></script> <script src=""/static/scripts/services/conf.js""></script> <script src=""/static/scripts/services/repo.js""></script> <script src=""/static/scripts/services/user.js""></script> <script src=""/static/scripts/services/feed.js""></script> <script src=""/static/scripts/services/remote.js""></script> <script src=""/static/scripts/services/stdout.js""></script> <script src=""/static/scripts/filters/filters.js""></script> </body> </html>  Is this a bug? How should this be fixed? other-file other-file",no-bug,0.9
982,harness,https://github.com/harness/harness/issues/982,nil pointer dereference on Rebuild,"Im running [Drone in a container](https://www.digitalocean.com/community/tutorials/how-to-perform-continuous-integration-testing-with-drone-io-on-coreos-and-docker) and I was having network issues so I was adding and removing the drone server. Got this after I clicked ""Rebuild"".  2015/04/18 09:37:27 http: panic serving 172.17.8.1:53133: runtime error: invalid memory address or nil pointer dereference goroutine 31 [running]: net/http.func011() /usr/local/go/src/pkg/net/http/server.go:1100 +0xb7 runtime.panic(0xb3afc0, 0x11ad913) /usr/local/go/src/pkg/runtime/panic.c:248 +0x18d github.com/drone/drone/server/handler.PostCommit(0xc2081815f0, 0xc2081812f0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/handler/commit.go:104 +0x5e3 github.com/zenazn/goji/web.handlerFuncWrap.ServeHTTPC(0xd52dd0, 0xc2081815f0, 0xc2081812f0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/handler.go:25 +0x54 github.com/zenazn/goji/web.(*router).route(0xc208028b28, 0xc2081dc630, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/router.go:119 +0x143 github.com/zenazn/goji/web.func002(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:88 +0x5f net/http.HandlerFunc.ServeHTTP(0xc2081c7900, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func005(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/repo.go:104 +0x45b net/http.HandlerFunc.ServeHTTP(0xc2081c7920, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func004(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/repo.go:62 +0x21d net/http.HandlerFunc.ServeHTTP(0xc2081c7940, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func003(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/repo.go:36 +0x5dc net/http.HandlerFunc.ServeHTTP(0xc2081c7960, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/zenazn/goji/web.(*cStack).ServeHTTPC(0xc2081dc630, 0xc2081815f0, 0xc2081812f0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:50 +0x69 github.com/zenazn/goji/web.(*Mux).ServeHTTPC(0xc208028af0, 0xc2081815f0, 0xc2081812f0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/mux.go:53 +0x73 github.com/zenazn/goji/web.(*router).route(0xc208028348, 0xc2081b76e0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/router.go:119 +0x143 github.com/zenazn/goji/web.func002(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:88 +0x5f net/http.HandlerFunc.ServeHTTP(0xc2081c7c40, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func006(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/user.go:21 +0x1a6 net/http.HandlerFunc.ServeHTTP(0xc2081c7c60, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func001(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/header.go:28 +0x4e9 net/http.HandlerFunc.ServeHTTP(0xc208176860, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 main.func002(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/main.go:176 +0x721 net/http.HandlerFunc.ServeHTTP(0xc2081c7c80, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func002(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/options.go:22 +0x261 net/http.HandlerFunc.ServeHTTP(0xc208176890, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/zenazn/goji/web.(*cStack).ServeHTTP(0xc2081b76e0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:46 +0x7f github.com/zenazn/goji/web.(*Mux).ServeHTTP(0xc208028310, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/mux.go:45 +0x5f net/http.(*ServeMux).ServeHTTP(0xc208022930, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1511 +0x1a3 net/http.serverHandler.ServeHTTP(0xc2080059e0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1673 +0x19f net/http.(*conn).serve(0xc208051100) /usr/local/go/src/pkg/net/http/server.go:1174 +0xa7e created by net/http.(*Server).Serve /usr/local/go/src/pkg/net/http/server.go:1721 +0x313 ",source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"nil pointer dereference on Rebuild Im running [Drone in a container](https://www.digitalocean.com/community/tutorials/how-to-perform-continuous-integration-testing-with-drone-io-on-coreos-and-docker) and I was having network issues so I was adding and removing the drone server. Got this after I clicked ""Rebuild"".  2015/04/18 09:37:27 http: panic serving 172.17.8.1:53133: runtime error: invalid memory address or nil pointer dereference goroutine 31 [running]: net/http.func011() /usr/local/go/src/pkg/net/http/server.go:1100 +0xb7 runtime.panic(0xb3afc0, 0x11ad913) /usr/local/go/src/pkg/runtime/panic.c:248 +0x18d github.com/drone/drone/server/handler.PostCommit(0xc2081815f0, 0xc2081812f0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/handler/commit.go:104 +0x5e3 github.com/zenazn/goji/web.handlerFuncWrap.ServeHTTPC(0xd52dd0, 0xc2081815f0, 0xc2081812f0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/handler.go:25 +0x54 github.com/zenazn/goji/web.(*router).route(0xc208028b28, 0xc2081dc630, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/router.go:119 +0x143 github.com/zenazn/goji/web.func002(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:88 +0x5f net/http.HandlerFunc.ServeHTTP(0xc2081c7900, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func005(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/repo.go:104 +0x45b net/http.HandlerFunc.ServeHTTP(0xc2081c7920, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func004(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/repo.go:62 +0x21d net/http.HandlerFunc.ServeHTTP(0xc2081c7940, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func003(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/repo.go:36 +0x5dc net/http.HandlerFunc.ServeHTTP(0xc2081c7960, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/zenazn/goji/web.(*cStack).ServeHTTPC(0xc2081dc630, 0xc2081815f0, 0xc2081812f0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:50 +0x69 github.com/zenazn/goji/web.(*Mux).ServeHTTPC(0xc208028af0, 0xc2081815f0, 0xc2081812f0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/mux.go:53 +0x73 github.com/zenazn/goji/web.(*router).route(0xc208028348, 0xc2081b76e0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/router.go:119 +0x143 github.com/zenazn/goji/web.func002(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:88 +0x5f net/http.HandlerFunc.ServeHTTP(0xc2081c7c40, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func006(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/user.go:21 +0x1a6 net/http.HandlerFunc.ServeHTTP(0xc2081c7c60, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func001(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/header.go:28 +0x4e9 net/http.HandlerFunc.ServeHTTP(0xc208176860, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 main.func002(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/main.go:176 +0x721 net/http.HandlerFunc.ServeHTTP(0xc2081c7c80, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/drone/drone/server/middleware.func002(0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/drone/drone/server/middleware/options.go:22 +0x261 net/http.HandlerFunc.ServeHTTP(0xc208176890, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1235 +0x40 github.com/zenazn/goji/web.(*cStack).ServeHTTP(0xc2081b76e0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/middleware.go:46 +0x7f github.com/zenazn/goji/web.(*Mux).ServeHTTP(0xc208028310, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /var/cache/drone/src/github.com/zenazn/goji/web/mux.go:45 +0x5f net/http.(*ServeMux).ServeHTTP(0xc208022930, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1511 +0x1a3 net/http.serverHandler.ServeHTTP(0xc2080059e0, 0x7fabe81609f0, 0xc2081b9400, 0xc2081f4c30) /usr/local/go/src/pkg/net/http/server.go:1673 +0x19f net/http.(*conn).serve(0xc208051100) /usr/local/go/src/pkg/net/http/server.go:1174 +0xa7e created by net/http.(*Server).Serve /usr/local/go/src/pkg/net/http/server.go:1721 +0x313  source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.9
120,harness,https://github.com/harness/harness/issues/120,The build status page hangs my browser,"The build status page seems to hang my browser (in firefox) and my tab (in chrome). I`m on a fast machine 16gb ram, octacore Intel(R) Core(TM) i7-4800MQ CPU @ 2.70GHz. Ubuntu LTS 12.04.4 I can give you more info if you need that or debug this if you give me some hints as to what to check.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"The build status page hangs my browser The build status page seems to hang my browser (in firefox) and my tab (in chrome). I`m on a fast machine 16gb ram, octacore Intel(R) Core(TM) i7-4800MQ CPU @ 2.70GHz. Ubuntu LTS 12.04.4 I can give you more info if you need that or debug this if you give me some hints as to what to check. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
922,harness,https://github.com/harness/harness/issues/922,IS_PULL_REQUEST environment variable,Drone should provide an environment variable on pull request so that we can avoid deploying. Related to #156,other-file | source-file | other-file | other-file | source-file | other-file,IS_PULL_REQUEST environment variable Drone should provide an environment variable on pull request so that we can avoid deploying. Related to #156 other-file source-file other-file other-file source-file other-file,no-bug,0.9
2566,harness,https://github.com/harness/harness/issues/2566,Unable to fetch stage details when using string interpolation in pipeline,"I added the following in my `.drone.yml`: yaml environment: build_number: ${BUILD_NUMBER}  and this shows up in my logs: yaml {""commit"":""bd36d59f700cdf217d8efc030ebe3d4dec7b4fc0"",""event"":""push"",""level"":""debug"",""msg"":""webhook parsed"",""name"":""bazare-public"",""namespace"":""tjimsk"",""time"":""2019-01-04T21:15:04Z""} {""commit"":""bd36d59f700cdf217d8efc030ebe3d4dec7b4fc0"",""event"":""push"",""level"":""debug"",""msg"":""trigger: received"",""ref"":""refs/heads/master"",""repo"":""<repository-name>"",""time"":""2019-01-04T21:15:04Z""} {""fields.time"":""2019-01-04T21:15:06Z"",""latency"":1589002566,""level"":""debug"",""method"":""POST"",""msg"":"""",""remote"":""10.28.3.5:51760"",""request"":""/hook"",""request-id"":""596a9389-0fe3-4f72-b3c8-a815e94c1e15"",""time"":""2019-01-04T21:15:06Z""} {""level"":""debug"",""machine"":""drone-74666b56c4-lqt8k"",""msg"":""manager: accept stage"",""stage-id"":2,""time"":""2019-01-04T21:15:06Z""} {""level"":""debug"",""machine"":""drone-74666b56c4-lqt8k"",""msg"":""manager: stage accepted"",""stage-id"":2,""time"":""2019-01-04T21:15:06Z""} {""level"":""debug"",""msg"":""manager: fetching stage details"",""step-id"":2,""time"":""2019-01-04T21:15:06Z""} {""arch"":""amd64"",""build"":2,""error"":""runtime error: invalid memory address or nil pointer dereference"",""level"":""error"",""machine"":""drone-74666b56c4-lqt8k"",""msg"":""runner: unexpected panic"",""os"":""linux"",""pipeline"":""public"",""repo"":""<repository-name>"",""stage"":1,""time"":""2019-01-04T21:15:06Z""} {""arch"":""amd64"",""level"":""debug"",""machine"":""drone-74666b56c4-lqt8k"",""msg"":""runner: polling queue"",""os"":""linux"",""time"":""2019-01-04T21:15:06Z""} {""arch"":""amd64"",""kernel"":"""",""level"":""debug"",""msg"":""manager: request queue item"",""os"":""linux"",""time"":""2019-01-04T21:15:06Z"",""variant"":""""} {""level"":""debug"",""msg"":""events: stream eror"",""request-id"":""729b25b5-260a-457c-be9e-f1b51bb7b4dc"",""time"":""2019-01-04T21:16:12Z"",""user.admin"":true,""user.login"":""tjimsk""} {""level"":""debug"",""msg"":""events: stream closed"",""request-id"":""729b25b5-260a-457c-be9e-f1b51bb7b4dc"",""time"":""2019-01-04T21:16:12Z"",""user.admin"":true,""user.login"":""tjimsk""}  The pipeline gets stuck instead of reporting it can't find the variable. That should be handled better as even the logs don't really say that much.",source-file,"Unable to fetch stage details when using string interpolation in pipeline I added the following in my `.drone.yml`: yaml environment: build_number: ${BUILD_NUMBER}  and this shows up in my logs: yaml {""commit"":""bd36d59f700cdf217d8efc030ebe3d4dec7b4fc0"",""event"":""push"",""level"":""debug"",""msg"":""webhook parsed"",""name"":""bazare-public"",""namespace"":""tjimsk"",""time"":""2019-01-04T21:15:04Z""} {""commit"":""bd36d59f700cdf217d8efc030ebe3d4dec7b4fc0"",""event"":""push"",""level"":""debug"",""msg"":""trigger: received"",""ref"":""refs/heads/master"",""repo"":""<repository-name>"",""time"":""2019-01-04T21:15:04Z""} {""fields.time"":""2019-01-04T21:15:06Z"",""latency"":1589002566,""level"":""debug"",""method"":""POST"",""msg"":"""",""remote"":""10.28.3.5:51760"",""request"":""/hook"",""request-id"":""596a9389-0fe3-4f72-b3c8-a815e94c1e15"",""time"":""2019-01-04T21:15:06Z""} {""level"":""debug"",""machine"":""drone-74666b56c4-lqt8k"",""msg"":""manager: accept stage"",""stage-id"":2,""time"":""2019-01-04T21:15:06Z""} {""level"":""debug"",""machine"":""drone-74666b56c4-lqt8k"",""msg"":""manager: stage accepted"",""stage-id"":2,""time"":""2019-01-04T21:15:06Z""} {""level"":""debug"",""msg"":""manager: fetching stage details"",""step-id"":2,""time"":""2019-01-04T21:15:06Z""} {""arch"":""amd64"",""build"":2,""error"":""runtime error: invalid memory address or nil pointer dereference"",""level"":""error"",""machine"":""drone-74666b56c4-lqt8k"",""msg"":""runner: unexpected panic"",""os"":""linux"",""pipeline"":""public"",""repo"":""<repository-name>"",""stage"":1,""time"":""2019-01-04T21:15:06Z""} {""arch"":""amd64"",""level"":""debug"",""machine"":""drone-74666b56c4-lqt8k"",""msg"":""runner: polling queue"",""os"":""linux"",""time"":""2019-01-04T21:15:06Z""} {""arch"":""amd64"",""kernel"":"""",""level"":""debug"",""msg"":""manager: request queue item"",""os"":""linux"",""time"":""2019-01-04T21:15:06Z"",""variant"":""""} {""level"":""debug"",""msg"":""events: stream eror"",""request-id"":""729b25b5-260a-457c-be9e-f1b51bb7b4dc"",""time"":""2019-01-04T21:16:12Z"",""user.admin"":true,""user.login"":""tjimsk""} {""level"":""debug"",""msg"":""events: stream closed"",""request-id"":""729b25b5-260a-457c-be9e-f1b51bb7b4dc"",""time"":""2019-01-04T21:16:12Z"",""user.admin"":true,""user.login"":""tjimsk""}  The pipeline gets stuck instead of reporting it can't find the variable. That should be handled better as even the logs don't really say that much. source-file",bug,0.85
308,harness,https://github.com/harness/harness/issues/308,Docker container start failure not detected correctly,"While the issue described in this [mailing list thread](https://groups.google.com/d/msg/drone-dev/teea2XSrK2M/mDZcfuwCU5YJ) was a docker-problem and not a drone-problem, drone still fails to detect the docker failures correctly and marks builds as ok although docker wasn't even able to fire up the containers where the build should run. Steps to reproduce: - Set up a drone project that uses a database service:  yaml image: node0.10 script: - npm install - npm test services: - bradrydzewski/postgres:9.3  - Start docker. - Check iptables:  iptables -L -n -t nat --line-numbers Chain PREROUTING (policy ACCEPT) num target prot opt source destination 1 DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCAL Chain INPUT (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination 1 DOCKER all -- 0.0.0.0/0 !127.0.0.0/8 ADDRTYPE match dst-type LOCAL Chain POSTROUTING (policy ACCEPT) num target prot opt source destination 1 MASQUERADE all -- 172.17.0.0/16 !172.17.0.0/16 Chain DOCKER (2 references) num target prot opt source destination  - Run a build, it should pass. - Remove the firewall rules (be careful, rulenumbers should match the linenumbers from the output above):  iptables -t nat -D PREROUTING 1 iptables -t nat -D OUTPUT 1 iptables -t nat -D POSTROUTING 1 iptables -t nat -X DOCKER iptables -L -n -t nat --line-numbers Chain PREROUTING (policy ACCEPT) num target prot opt source destination Chain INPUT (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination Chain POSTROUTING (policy ACCEPT) num target prot opt source destination  - Re-run the build, it will be marked as OK but the build script will actually never be run. - Check `/var/log/upstart/drone.log` (it looks like for a successful build):   Step 16 : ENTRYPOINT /bin/bash -e /usr/local/bin/drone > Running in 1fa8c2cc6cc2 > 2c49102ab872 Removing intermediate container 1fa8c2cc6cc2 Successfully built 2c49102ab872 copying repository to /var/cache/drone/src/github.com// starting build temp directory is /tmp/drone mounting volume /tmp/drone/github.com///test-drone/tmp/npm:/tmp/npm removing build container removing service container bradrydzewski/postgres:9.3 removing build image  - Check `/var/log/upstart/docker.log`:  2014/05/11 12:27:43 GET /v1.9/images/bradrydzewski/postgres:9.3/json [c800b788] +job inspect(bradrydzewski/postgres:9.3, image) [c800b788] -job inspect(bradrydzewski/postgres:9.3, image) = OK (0) 2014/05/11 12:27:43 POST /v1.9/containers/create [c800b788] +job create() [c800b788] -job create() = OK (0) 2014/05/11 12:27:43 POST /v1.9/containers/3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d/start [c800b788] +job start(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] +job allocate_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job allocate_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) [c800b788] +job allocate_port(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) iptables failed: iptables -t nat -A DOCKER -p tcp -d 127.0.0.1 --dport 49155 ! -i docker0 -j DNAT --to-destination 172.17.0.2:5432: iptables: No chain/target/match by that name. (exit status 1) [c800b788] -job allocate_port(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = ERR (1) [c800b788] +job release_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job release_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) [c800b788] +job release_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job release_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) Cannot start container 3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d: (exit status 1) [c800b788] -job start(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = ERR (1) [error] server.go:1011 Error: Cannot start container 3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d: (exit status 1) [error] server.go:90 HTTP Error: statusCode=500 Cannot start container 3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d: (exit status 1) 2014/05/11 12:27:43 GET /v1.9/containers/3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d/json [c800b788] +job inspect(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d, container) [c800b788] -job inspect(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d, container) = OK (0) 2014/05/11 12:27:43 GET /v1.9/images/bradrydzewski/node:0.10/json [c800b788] +job inspect(bradrydzewski/node:0.10, image) [c800b788] -job inspect(bradrydzewski/node:0.10, image) = OK (0) 2014/05/11 12:27:43 POST /v1.9/build?q=1&rm=1&t=drone-086b240e9b [c800b788] +job build() [c800b788] +job allocate_interface(736e7cd2b209e969a457f2ced54be44745412b08a20c54a6988567279abee841) [c800b788] -job allocate_interface(736e7cd2b209e969a457f2ced54be44745412b08a20c54a6988567279abee841) = OK (0) [c800b788] +job release_interface(736e7cd2b209e969a457f2ced54be44745412b08a20c54a6988567279abee841) [c800b788] -job release_interface(736e7cd2b209e969a457f2ced54be44745412b08a20c54a6988567279abee841) = OK (0) [c800b788] +job allocate_interface(88d3525561c3e43ce75e2c3274924a3f70ab8824efcee90f0e15b07a4fa0def3) [c800b788] -job allocate_interface(88d3525561c3e43ce75e2c3274924a3f70ab8824efcee90f0e15b07a4fa0def3) = OK (0) [c800b788] +job release_interface(88d3525561c3e43ce75e2c3274924a3f70ab8824efcee90f0e15b07a4fa0def3) [c800b788] -job release_interface(88d3525561c3e43ce75e2c3274924a3f70ab8824efcee90f0e15b07a4fa0def3) = OK (0) [c800b788] +job allocate_interface(1ef4af6b89c5e14a450194ab91a8470ca83075e60b7fe96ef786bfa50c79903c) [c800b788] -job allocate_interface(1ef4af6b89c5e14a450194ab91a8470ca83075e60b7fe96ef786bfa50c79903c) = OK (0) [c800b788] +job release_interface(1ef4af6b89c5e14a450194ab91a8470ca83075e60b7fe96ef786bfa50c79903c) [c800b788] -job release_interface(1ef4af6b89c5e14a450194ab91a8470ca83075e60b7fe96ef786bfa50c79903c) = OK (0) [c800b788] +job allocate_interface(3543a0ae8d2d31af147b7f5379247a59a0a251beb284324b85a8862d029ca671) [c800b788] -job allocate_interface(3543a0ae8d2d31af147b7f5379247a59a0a251beb284324b85a8862d029ca671) = OK (0) [c800b788] +job release_interface(3543a0ae8d2d31af147b7f5379247a59a0a251beb284324b85a8862d029ca671) [c800b788] -job release_interface(3543a0ae8d2d31af147b7f5379247a59a0a251beb284324b85a8862d029ca671) = OK (0) [c800b788] -job build() = OK (0) 2014/05/11 12:27:48 GET /v1.9/images/drone-086b240e9b/json [c800b788] +job inspect(drone-086b240e9b, image) [c800b788] -job inspect(drone-086b240e9b, image) = OK (0) 2014/05/11 12:27:48 POST /v1.9/containers/create [c800b788] +job create() [c800b788] -job create() = OK (0) 2014/05/11 12:27:48 POST /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e/start [c800b788] +job start(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) 2014/05/11 12:27:48 POST /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e/attach?&stream=1&stdout=1&stderr=1 [c800b788] +job inspect(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e, container) [c800b788] -job inspect(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e, container) = OK (0) [c800b788] +job attach(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] +job allocate_interface(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job allocate_interface(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) [c800b788] +job release_interface(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job release_interface(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) [c800b788] -job attach(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) Cannot start container 78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e: Cannot link to a non running container: /loving_feynman AS /loving_colden/postgres [c800b788] -job start(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = ERR (1) [error] server.go:1011 Error: Cannot start container 78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e: Cannot link to a non running container: /loving_feynman AS /loving_colden/postgres [error] server.go:90 HTTP Error: statusCode=500 Cannot start container 78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e: Cannot link to a non running container: /loving_feynman AS /loving_colden/postgres 2014/05/11 12:27:48 POST /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e/wait [c800b788] +job wait(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job wait(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) 2014/05/11 12:27:48 POST /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e/stop?t=15 [c800b788] +job stop(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job stop(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) 2014/05/11 12:27:48 DELETE /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e [c800b788] +job container_delete(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job container_delete(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) 2014/05/11 12:27:48 POST /v1.9/containers/3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d/stop?t=15 [c800b788] +job stop(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job stop(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) 2014/05/11 12:27:48 DELETE /v1.9/containers/3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d [c800b788] +job container_delete(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job container_delete(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) 2014/05/11 12:27:49 DELETE /v1.9/images/0847b81088b1e7fb6ab87f96f0547674cecc9d7913f935218a44dab141f7f863 [c800b788] +job image_delete(0847b81088b1e7fb6ab87f96f0547674cecc9d7913f935218a44dab141f7f863) [c800b788] -job image_delete(0847b81088b1e7fb6ab87f96f0547674cecc9d7913f935218a44dab141f7f863) = OK (0)  Docker clearly shows that errors creating the containers but somehow drone doesn't seem to notice.",other-file,"Docker container start failure not detected correctly While the issue described in this [mailing list thread](https://groups.google.com/d/msg/drone-dev/teea2XSrK2M/mDZcfuwCU5YJ) was a docker-problem and not a drone-problem, drone still fails to detect the docker failures correctly and marks builds as ok although docker wasn't even able to fire up the containers where the build should run. Steps to reproduce: - Set up a drone project that uses a database service:  yaml image: node0.10 script: - npm install - npm test services: - bradrydzewski/postgres:9.3  - Start docker. - Check iptables:  iptables -L -n -t nat --line-numbers Chain PREROUTING (policy ACCEPT) num target prot opt source destination 1 DOCKER all -- 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCAL Chain INPUT (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination 1 DOCKER all -- 0.0.0.0/0 !127.0.0.0/8 ADDRTYPE match dst-type LOCAL Chain POSTROUTING (policy ACCEPT) num target prot opt source destination 1 MASQUERADE all -- 172.17.0.0/16 !172.17.0.0/16 Chain DOCKER (2 references) num target prot opt source destination  - Run a build, it should pass. - Remove the firewall rules (be careful, rulenumbers should match the linenumbers from the output above):  iptables -t nat -D PREROUTING 1 iptables -t nat -D OUTPUT 1 iptables -t nat -D POSTROUTING 1 iptables -t nat -X DOCKER iptables -L -n -t nat --line-numbers Chain PREROUTING (policy ACCEPT) num target prot opt source destination Chain INPUT (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination Chain POSTROUTING (policy ACCEPT) num target prot opt source destination  - Re-run the build, it will be marked as OK but the build script will actually never be run. - Check `/var/log/upstart/drone.log` (it looks like for a successful build):   Step 16 : ENTRYPOINT /bin/bash -e /usr/local/bin/drone > Running in 1fa8c2cc6cc2 > 2c49102ab872 Removing intermediate container 1fa8c2cc6cc2 Successfully built 2c49102ab872 copying repository to /var/cache/drone/src/github.com// starting build temp directory is /tmp/drone mounting volume /tmp/drone/github.comtest-drone/tmp/npm:/tmp/npm removing build container removing service container bradrydzewski/postgres:9.3 removing build image  - Check `/var/log/upstart/docker.log`:  2014/05/11 12:27:43 GET /v1.9/images/bradrydzewski/postgres:9.3/json [c800b788] +job inspect(bradrydzewski/postgres:9.3, image) [c800b788] -job inspect(bradrydzewski/postgres:9.3, image) = OK (0) 2014/05/11 12:27:43 POST /v1.9/containers/create [c800b788] +job create() [c800b788] -job create() = OK (0) 2014/05/11 12:27:43 POST /v1.9/containers/3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d/start [c800b788] +job start(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] +job allocate_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job allocate_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) [c800b788] +job allocate_port(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) iptables failed: iptables -t nat -A DOCKER -p tcp -d 127.0.0.1 --dport 49155 ! -i docker0 -j DNAT --to-destination 172.17.0.2:5432: iptables: No chain/target/match by that name. (exit status 1) [c800b788] -job allocate_port(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = ERR (1) [c800b788] +job release_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job release_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) [c800b788] +job release_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job release_interface(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) Cannot start container 3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d: (exit status 1) [c800b788] -job start(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = ERR (1) [error] server.go:1011 Error: Cannot start container 3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d: (exit status 1) [error] server.go:90 HTTP Error: statusCode=500 Cannot start container 3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d: (exit status 1) 2014/05/11 12:27:43 GET /v1.9/containers/3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d/json [c800b788] +job inspect(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d, container) [c800b788] -job inspect(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d, container) = OK (0) 2014/05/11 12:27:43 GET /v1.9/images/bradrydzewski/node:0.10/json [c800b788] +job inspect(bradrydzewski/node:0.10, image) [c800b788] -job inspect(bradrydzewski/node:0.10, image) = OK (0) 2014/05/11 12:27:43 POST /v1.9/build?q=1&rm=1&t=drone-086b240e9b [c800b788] +job build() [c800b788] +job allocate_interface(736e7cd2b209e969a457f2ced54be44745412b08a20c54a6988567279abee841) [c800b788] -job allocate_interface(736e7cd2b209e969a457f2ced54be44745412b08a20c54a6988567279abee841) = OK (0) [c800b788] +job release_interface(736e7cd2b209e969a457f2ced54be44745412b08a20c54a6988567279abee841) [c800b788] -job release_interface(736e7cd2b209e969a457f2ced54be44745412b08a20c54a6988567279abee841) = OK (0) [c800b788] +job allocate_interface(88d3525561c3e43ce75e2c3274924a3f70ab8824efcee90f0e15b07a4fa0def3) [c800b788] -job allocate_interface(88d3525561c3e43ce75e2c3274924a3f70ab8824efcee90f0e15b07a4fa0def3) = OK (0) [c800b788] +job release_interface(88d3525561c3e43ce75e2c3274924a3f70ab8824efcee90f0e15b07a4fa0def3) [c800b788] -job release_interface(88d3525561c3e43ce75e2c3274924a3f70ab8824efcee90f0e15b07a4fa0def3) = OK (0) [c800b788] +job allocate_interface(1ef4af6b89c5e14a450194ab91a8470ca83075e60b7fe96ef786bfa50c79903c) [c800b788] -job allocate_interface(1ef4af6b89c5e14a450194ab91a8470ca83075e60b7fe96ef786bfa50c79903c) = OK (0) [c800b788] +job release_interface(1ef4af6b89c5e14a450194ab91a8470ca83075e60b7fe96ef786bfa50c79903c) [c800b788] -job release_interface(1ef4af6b89c5e14a450194ab91a8470ca83075e60b7fe96ef786bfa50c79903c) = OK (0) [c800b788] +job allocate_interface(3543a0ae8d2d31af147b7f5379247a59a0a251beb284324b85a8862d029ca671) [c800b788] -job allocate_interface(3543a0ae8d2d31af147b7f5379247a59a0a251beb284324b85a8862d029ca671) = OK (0) [c800b788] +job release_interface(3543a0ae8d2d31af147b7f5379247a59a0a251beb284324b85a8862d029ca671) [c800b788] -job release_interface(3543a0ae8d2d31af147b7f5379247a59a0a251beb284324b85a8862d029ca671) = OK (0) [c800b788] -job build() = OK (0) 2014/05/11 12:27:48 GET /v1.9/images/drone-086b240e9b/json [c800b788] +job inspect(drone-086b240e9b, image) [c800b788] -job inspect(drone-086b240e9b, image) = OK (0) 2014/05/11 12:27:48 POST /v1.9/containers/create [c800b788] +job create() [c800b788] -job create() = OK (0) 2014/05/11 12:27:48 POST /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e/start [c800b788] +job start(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) 2014/05/11 12:27:48 POST /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e/attach?&stream=1&stdout=1&stderr=1 [c800b788] +job inspect(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e, container) [c800b788] -job inspect(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e, container) = OK (0) [c800b788] +job attach(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] +job allocate_interface(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job allocate_interface(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) [c800b788] +job release_interface(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job release_interface(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) [c800b788] -job attach(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) Cannot start container 78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e: Cannot link to a non running container: /loving_feynman AS /loving_colden/postgres [c800b788] -job start(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = ERR (1) [error] server.go:1011 Error: Cannot start container 78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e: Cannot link to a non running container: /loving_feynman AS /loving_colden/postgres [error] server.go:90 HTTP Error: statusCode=500 Cannot start container 78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e: Cannot link to a non running container: /loving_feynman AS /loving_colden/postgres 2014/05/11 12:27:48 POST /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e/wait [c800b788] +job wait(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job wait(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) 2014/05/11 12:27:48 POST /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e/stop?t=15 [c800b788] +job stop(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job stop(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) 2014/05/11 12:27:48 DELETE /v1.9/containers/78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e [c800b788] +job container_delete(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) [c800b788] -job container_delete(78c3db403c1cbd67673662879ba793fb43242dbb493380468a15c8324e1eea0e) = OK (0) 2014/05/11 12:27:48 POST /v1.9/containers/3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d/stop?t=15 [c800b788] +job stop(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job stop(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) 2014/05/11 12:27:48 DELETE /v1.9/containers/3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d [c800b788] +job container_delete(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) [c800b788] -job container_delete(3d0eee92e2088c91ec5eec6d236d9343b7907ffea7db39043ef13bd1f5e77f0d) = OK (0) 2014/05/11 12:27:49 DELETE /v1.9/images/0847b81088b1e7fb6ab87f96f0547674cecc9d7913f935218a44dab141f7f863 [c800b788] +job image_delete(0847b81088b1e7fb6ab87f96f0547674cecc9d7913f935218a44dab141f7f863) [c800b788] -job image_delete(0847b81088b1e7fb6ab87f96f0547674cecc9d7913f935218a44dab141f7f863) = OK (0)  Docker clearly shows that errors creating the containers but somehow drone doesn't seem to notice. other-file",no-bug,0.9
2538,harness,https://github.com/harness/harness/issues/2538,Missing usefull error message on login fail,"Logging in with a unverified email address fails with generic error message. The server log states:  time=""2018-11-30T07:55:31Z"" level=error msg=""cannot authenticate user. No verified Email address for GitHub account""  It would be very helpful to display this message to the user.",source-file,"Missing usefull error message on login fail Logging in with a unverified email address fails with generic error message. The server log states:  time=""2018-11-30T07:55:31Z"" level=error msg=""cannot authenticate user. No verified Email address for GitHub account""  It would be very helpful to display this message to the user. source-file",bug,0.9
102,harness,https://github.com/harness/harness/issues/102,link repository fails,"I'm using github enterprise and I can hook up the drone application ok When I try to link up github account it switches over to github fine, I click 'Allow Access' and then it goes back to http://drone/auth/login/github?code=d243b2becacf840743af&state=FqB4EbagQ2o and just prints 'Not Found' in the browser window. /var/log/upstart/drone.log is less than helpful  2014/02/19 22:57:32 Successfully upgraded to Revision 201402200603 2014/02/19 22:57:32 Successfully upgraded to Revision 201402211147 2014/02/19 23:01:51 Database already up-to-date. 2014/02/19 23:02:48 Not Found ",other-file | documentation-file | other-file | other-file | source-file | documentation-file | other-file | other-file,"link repository fails I'm using github enterprise and I can hook up the drone application ok When I try to link up github account it switches over to github fine, I click 'Allow Access' and then it goes back to http://drone/auth/login/github?code=d243b2becacf840743af&state=FqB4EbagQ2o and just prints 'Not Found' in the browser window. /var/log/upstart/drone.log is less than helpful  2014/02/19 22:57:32 Successfully upgraded to Revision 201402200603 2014/02/19 22:57:32 Successfully upgraded to Revision 201402211147 2014/02/19 23:01:51 Database already up-to-date. 2014/02/19 23:02:48 Not Found  other-file documentation-file other-file other-file source-file documentation-file other-file other-file",no-bug,0.7
362,harness,https://github.com/harness/harness/issues/362,Run Docker with custom option,"hi @bradrydzewski, i want to run docker containers with custom option like: `docker run --net=host <image-name>` when drone run my repository test. So, how could i add `--net=host` option when drone start a docker container?",source-file | documentation-file | source-file,"Run Docker with custom option hi @bradrydzewski, i want to run docker containers with custom option like: `docker run --net=host <image-name>` when drone run my repository test. So, how could i add `--net=host` option when drone start a docker container? source-file documentation-file source-file",no-bug,0.9
663,harness,https://github.com/harness/harness/issues/663,Safari 8.0 OAuth Login and Cookie Settings,"Whenever I try to log in to drone using Safari, I get redirected to GitHub to log in, type in my name and password, and then get an error message from GitHub. It doesn't appear to redirect back to drone. However, I'm already logged in to GitHub and using it. My only guess is an issue with redirects or cookies.",source-file | other-file,"Safari 8.0 OAuth Login and Cookie Settings Whenever I try to log in to drone using Safari, I get redirected to GitHub to log in, type in my name and password, and then get an error message from GitHub. It doesn't appear to redirect back to drone. However, I'm already logged in to GitHub and using it. My only guess is an issue with redirects or cookies. source-file other-file",no-bug,0.7
2680,harness,https://github.com/harness/harness/issues/2680,[PROPOSAL] Drone Custom Stage Definitions,"This proposal is to create a new category of plugin for Drone, which I am tentatively describing as Custom Stage Definitions, which are heavily inspired by custom resource definitions for Kubernetes. Today a pipeline is a series of steps that execute in Docker containers. These pipelines are classified as Docker pipelines. When the `type` field is empty we assume this is the default pipeline type. text kind: pipeline  The goal is to allow additional types of pipelines with their own custom yaml syntax. For example, we could have a knative plugin that uses knative syntax. diff kind: pipeline +type: knative  or a pipeline that runs commands directly on the host machine: diff kind: pipeline +type: exec  Each custom stage provider would be responsible for parsing the body of the yaml, interpreting and executing the contents. For example: text kind: pipeline type: exec platform: os: darwin arch: amd64 steps: - name: build commands: - go build - go test  ## Kinds The `kind` field could be used to create stages that do not qualify as pipelines. For example maybe we want stages to handle approvals: text kind: approval  or highly customized deployment strategies: text kind: deployment type: redblack|canary  ## Design I will begin moving the agent <> server code to the [runner-go](https://github.com/drone/runner-go) library and I will create a starter project for creating custom stage operators. You can think of this as, effectively, creating your own Drone agent. Drone will ship with the default Docker pipeline runner only. All other runners will be community contributed and managed. I will create a separate organization, called [drone-runners](https://github.com/drone-runners), to help organize community development. ## Why? I realized that the core Drone team is too inexperienced with Kubernetes and is stretched too thin to offer the Kubernetes runtime. Instead we can open this up to the community, and hand over control, just like we did with plugins years ago. Plugins quickly became one of the defining and most loved features in Drone. I believe Custom Stage Definition will have a similar impact on the project and community. I envision the community creating all sorts of interesting runners: - exec runner launches builds on the host machine - chroot runner, similar to exec, but in a chroot - tekton runner - virtualbox runner - vmware vsphere runner (for osx) - aws runner (launches ad-hoc ephemeral vms) - gcp runner (launches ad-hoc ephemeral vms) - digitalocean runner (launches ad-hoc ephemeral vms)",source-file | documentation-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | documentation-file,"[PROPOSAL] Drone Custom Stage Definitions This proposal is to create a new category of plugin for Drone, which I am tentatively describing as Custom Stage Definitions, which are heavily inspired by custom resource definitions for Kubernetes. Today a pipeline is a series of steps that execute in Docker containers. These pipelines are classified as Docker pipelines. When the `type` field is empty we assume this is the default pipeline type. text kind: pipeline  The goal is to allow additional types of pipelines with their own custom yaml syntax. For example, we could have a knative plugin that uses knative syntax. diff kind: pipeline +type: knative  or a pipeline that runs commands directly on the host machine: diff kind: pipeline +type: exec  Each custom stage provider would be responsible for parsing the body of the yaml, interpreting and executing the contents. For example: text kind: pipeline type: exec platform: os: darwin arch: amd64 steps: - name: build commands: - go build - go test  ## Kinds The `kind` field could be used to create stages that do not qualify as pipelines. For example maybe we want stages to handle approvals: text kind: approval  or highly customized deployment strategies: text kind: deployment type: redblack|canary  ## Design I will begin moving the agent <> server code to the [runner-go](https://github.com/drone/runner-go) library and I will create a starter project for creating custom stage operators. You can think of this as, effectively, creating your own Drone agent. Drone will ship with the default Docker pipeline runner only. All other runners will be community contributed and managed. I will create a separate organization, called [drone-runners](https://github.com/drone-runners), to help organize community development. ## Why? I realized that the core Drone team is too inexperienced with Kubernetes and is stretched too thin to offer the Kubernetes runtime. Instead we can open this up to the community, and hand over control, just like we did with plugins years ago. Plugins quickly became one of the defining and most loved features in Drone. I believe Custom Stage Definition will have a similar impact on the project and community. I envision the community creating all sorts of interesting runners: - exec runner launches builds on the host machine - chroot runner, similar to exec, but in a chroot - tekton runner - virtualbox runner - vmware vsphere runner (for osx) - aws runner (launches ad-hoc ephemeral vms) - gcp runner (launches ad-hoc ephemeral vms) - digitalocean runner (launches ad-hoc ephemeral vms) source-file documentation-file other-file other-file source-file other-file other-file other-file other-file other-file documentation-file",no-bug,0.95
2740,harness,https://github.com/harness/harness/issues/2740,Question - Valid yaml? Some yaml linters seem to think not.,"Is this valid yaml in Drone? Can I define **git** twice with different events?  workspace: base: /test path: webtools clone: git: image: plugins/git recursive: true submodule_override: rest/map/data: https://github.com/ec-europa/euwebtoolsnuts.git when: event: [ push, pull_request, tag ] git: image: fpfis/true when: event: [ deployment ]  Some yaml linters like in Symfony trow errors on this because it's a duplicate key. I just want to know if this is valid in Drone, or you can use different keys for the git checkout. If this is only possible with duplicate keys I'll have to use a yaml linter that doesn't fall over this.",other-file | other-file,"Question - Valid yaml? Some yaml linters seem to think not. Is this valid yaml in Drone? Can I define **git** twice with different events?  workspace: base: /test path: webtools clone: git: image: plugins/git recursive: true submodule_override: rest/map/data: https://github.com/ec-europa/euwebtoolsnuts.git when: event: [ push, pull_request, tag ] git: image: fpfis/true when: event: [ deployment ]  Some yaml linters like in Symfony trow errors on this because it's a duplicate key. I just want to know if this is valid in Drone, or you can use different keys for the git checkout. If this is only possible with duplicate keys I'll have to use a yaml linter that doesn't fall over this. other-file other-file",no-bug,0.9
43,harness,https://github.com/harness/harness/issues/43,Cache Docker images,documenting suggestion from @afex on irc add a section to the `.drone.yml` called setup  setup: - apt-get update - apt-get -y install libsqlite3 libsqlite3-dev  add these install scripts to the Dockerfile that we generate: https://github.com/drone/drone/blob/master/pkg/build/build.go#L365  RUN apt-get update RUN apt-get -y install libsqlite3 libsqlite3-dev  this would allow us to take advantage of Docker's layer caching. The build would use the cached image and avoid re-running install and setup commands. Saves time! If build script commands changed the cache would be invalidated and a new image would be generated. question: how does this impact matrix builds?,source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | database-file | database-file | database-file | database-file | source-file | source-file,Cache Docker images documenting suggestion from @afex on irc add a section to the `.drone.yml` called setup  setup: - apt-get update - apt-get -y install libsqlite3 libsqlite3-dev  add these install scripts to the Dockerfile that we generate: https://github.com/drone/drone/blob/master/pkg/build/build.go#L365  RUN apt-get update RUN apt-get -y install libsqlite3 libsqlite3-dev  this would allow us to take advantage of Docker's layer caching. The build would use the cached image and avoid re-running install and setup commands. Saves time! If build script commands changed the cache would be invalidated and a new image would be generated. question: how does this impact matrix builds? source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file database-file database-file database-file database-file source-file source-file,no-bug,0.95
3436,harness,https://github.com/harness/harness/issues/3436,How can I backup my repositories?,"I work in a company that doesn't use any versioning services because they are web based, I discovered Gitness these days and I need to make backups of project files to an internal server, how can I get the folders where the repository files are? I made a docker-compose.yaml so I could use gitness. ![image](https://github.com/harness/gitness/assets/47448206/551e6066-68fe-4244-b70e-b38c9bbfd465) I tried using the docker cp command but it did basically what docker-compose.yaml did. I'm new to docker.",other-file,"How can I backup my repositories? I work in a company that doesn't use any versioning services because they are web based, I discovered Gitness these days and I need to make backups of project files to an internal server, how can I get the folders where the repository files are? I made a docker-compose.yaml so I could use gitness. ![image](https://github.com/harness/gitness/assets/47448206/551e6066-68fe-4244-b70e-b38c9bbfd465) I tried using the docker cp command but it did basically what docker-compose.yaml did. I'm new to docker. other-file",no-bug,0.95
3518,harness,https://github.com/harness/harness/issues/3518,Pipeline Only Mode,"Given that Gitness builds on Drone, are there plans to allow someone deploying this to disable the git repo management side of this application? I tried Gitness for a good few months. but with it missing issues, projects, discussions, time tracking and all the other features my workflow requires, I decided to switch to Gitea and use Drone instead. now that I've been building out my repos and such in Gitea, I don't want to switch again even if gitness does end up getting all the features, I don't want to be in a situation where I'm forced to either switch to Gitness down the line or be stuck with Drone as it slowly decays from Harness' priority list. Basically, I'm asking if I should hold onto Drone until gitness launches, fully featured and replace Drone or if I should be looking to replace Drone now with some other CI/CD Pipeline system.",other-file,"Pipeline Only Mode Given that Gitness builds on Drone, are there plans to allow someone deploying this to disable the git repo management side of this application? I tried Gitness for a good few months. but with it missing issues, projects, discussions, time tracking and all the other features my workflow requires, I decided to switch to Gitea and use Drone instead. now that I've been building out my repos and such in Gitea, I don't want to switch again even if gitness does end up getting all the features, I don't want to be in a situation where I'm forced to either switch to Gitness down the line or be stuck with Drone as it slowly decays from Harness' priority list. Basically, I'm asking if I should hold onto Drone until gitness launches, fully featured and replace Drone or if I should be looking to replace Drone now with some other CI/CD Pipeline system. other-file",no-bug,0.9
2652,harness,https://github.com/harness/harness/issues/2652,"Autoscaler debug output recursively adds ""id""","I tested today the autoscaler and realized, that when debug output is enabled then the logs for the capacity check have a growing number of `id` values on each output: json {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""min-pool"":0,""max-pool"":10,""server-capacity"":20,""server-count"":10,""pending-builds"":373,""running-builds"":57,""time"":""2019-04-08T20:28:51Z"",""message"":""check capacity""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""time"":""2019-04-08T20:28:51Z"",""message"":""allocate 0 servers""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""time"":""2019-04-08T20:28:51Z"",""message"":""check capacity complete""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""min-pool"":0,""max-pool"":10,""server-capacity"":20,""server-count"":10,""pending-builds"":323,""running-builds"":58,""time"":""2019-04-08T20:33:51Z"",""message"":""check capacity""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""time"":""2019-04-08T20:33:51Z"",""message"":""allocate 0 servers""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""time"":""2019-04-08T20:33:51Z"",""message"":""check capacity complete""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""id"":""P5Jvlq79YaGGs42d"",""min-pool"":0,""max-pool"":10,""server-capacity"":20,""server-count"":10,""pending-builds"":268,""running-builds"":57,""time"":""2019-04-08T20:38:51Z"",""message"":""check capacity""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""id"":""P5Jvlq79YaGGs42d"",""time"":""2019-04-08T20:38:51Z"",""message"":""allocate 0 servers""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""id"":""P5Jvlq79YaGGs42d"",""time"":""2019-04-08T20:38:51Z"",""message"":""check capacity complete""}  It's originating in https://github.com/drone/autoscaler/blob/87b0e621fa0a8b2679bbf8d9ee2c8b5e329ea156/engine/planner.go#L58-L65 and seem to be added in https://github.com/drone/autoscaler/blob/87b0e621fa0a8b2679bbf8d9ee2c8b5e329ea156/engine/planner.go#L42 Unfortunately I can't spot where this duplication is happening. Any further idea what is going on here?",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file,"Autoscaler debug output recursively adds ""id"" I tested today the autoscaler and realized, that when debug output is enabled then the logs for the capacity check have a growing number of `id` values on each output: json {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""min-pool"":0,""max-pool"":10,""server-capacity"":20,""server-count"":10,""pending-builds"":373,""running-builds"":57,""time"":""2019-04-08T20:28:51Z"",""message"":""check capacity""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""time"":""2019-04-08T20:28:51Z"",""message"":""allocate 0 servers""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""time"":""2019-04-08T20:28:51Z"",""message"":""check capacity complete""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""min-pool"":0,""max-pool"":10,""server-capacity"":20,""server-count"":10,""pending-builds"":323,""running-builds"":58,""time"":""2019-04-08T20:33:51Z"",""message"":""check capacity""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""time"":""2019-04-08T20:33:51Z"",""message"":""allocate 0 servers""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""time"":""2019-04-08T20:33:51Z"",""message"":""check capacity complete""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""id"":""P5Jvlq79YaGGs42d"",""min-pool"":0,""max-pool"":10,""server-capacity"":20,""server-count"":10,""pending-builds"":268,""running-builds"":57,""time"":""2019-04-08T20:38:51Z"",""message"":""check capacity""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""id"":""P5Jvlq79YaGGs42d"",""time"":""2019-04-08T20:38:51Z"",""message"":""allocate 0 servers""} {""level"":""debug"",""id"":""86by2xKgAZkECILr"",""id"":""t7Aj3IoVotZMSB0l"",""id"":""P5Jvlq79YaGGs42d"",""time"":""2019-04-08T20:38:51Z"",""message"":""check capacity complete""}  It's originating in https://github.com/drone/autoscaler/blob/87b0e621fa0a8b2679bbf8d9ee2c8b5e329ea156/engine/planner.go#L58-L65 and seem to be added in https://github.com/drone/autoscaler/blob/87b0e621fa0a8b2679bbf8d9ee2c8b5e329ea156/engine/planner.go#L42 Unfortunately I can't spot where this duplication is happening. Any further idea what is going on here? source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file",no-bug,0.9
326,harness,https://github.com/harness/harness/issues/326,Global/Team/User Parameters,"I'd like to see the option to set parameters at a Global, Team, and User level, instead of just at the single repository level. I find myself needing to define the same parameters over and over. A good example is the swift publish module. Being able to set something at my user level would prevent me from having to define the same user name and apikey each time I added a repo.",documentation-file | other-file | source-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file,"Global/Team/User Parameters I'd like to see the option to set parameters at a Global, Team, and User level, instead of just at the single repository level. I find myself needing to define the same parameters over and over. A good example is the swift publish module. Being able to set something at my user level would prevent me from having to define the same user name and apikey each time I added a repo. documentation-file other-file source-file other-file other-file source-file other-file other-file other-file other-file other-file other-file",no-bug,0.9
484,harness,https://github.com/harness/harness/issues/484,"Release 0.3, docker images are pulled on each build","I have strange feeling, that docker image `node0.10` (in my case) is pulled again and again:  REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE <none> <none> 95c6fa17d5ca 15 seconds ago 3.536 GB bradrydzewski/node 0.10 c52118cf1448 9 months ago 3.536 GB  Logs says `starting build` with no evidence of `Pulling repository bradrydzewski/node`, but sequential builds are taking about 6 minutes. Could it be, that my docker setup is somehow wrong or any other hints?",source-file,"Release 0.3, docker images are pulled on each build I have strange feeling, that docker image `node0.10` (in my case) is pulled again and again:  REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE <none> <none> 95c6fa17d5ca 15 seconds ago 3.536 GB bradrydzewski/node 0.10 c52118cf1448 9 months ago 3.536 GB  Logs says `starting build` with no evidence of `Pulling repository bradrydzewski/node`, but sequential builds are taking about 6 minutes. Could it be, that my docker setup is somehow wrong or any other hints? source-file",no-bug,0.9
107,harness,https://github.com/harness/harness/issues/107,Allow an option to retest without a commit,"Some jobs could potentially run commands that do work remotely or require a re-run, but not necessarily require new code to be committed. It would be nice to have a redo type button on specific commit/pull requests.",other-file | other-file | documentation-file,"Allow an option to retest without a commit Some jobs could potentially run commands that do work remotely or require a re-run, but not necessarily require new code to be committed. It would be nice to have a redo type button on specific commit/pull requests. other-file other-file documentation-file",no-bug,0.9
258,harness,https://github.com/harness/harness/issues/258,Runtime Panic,"I'm following a very simple setup described [here](http://jipiboily.com/2014/from-zero-to-fully-working-ci-server-in-less-than-10-minutes-with-drone-docker). I'm running Ubuntu 12.04.4 x64. After `dpkg -i drone.deb`, nothing seems to work, even after repeated `start drone` commands:  Bash root@drone-ci:~# tail -n 100 /var/log/upstart/drone.log panic: stat /var/cache/drone/src/github.com/drone/drone/pkg/template/pages: no such file or directory goroutine 1 [running]: runtime.panic(0x922660, 0xc21008bde0) /usr/local/go/src/pkg/runtime/panic.c:266 +0xb6 github.com/GeertJohan/go%2erice.MustFindBox(0xa05500, 0x5, 0x48ef8a) /var/cache/drone/src/github.com/drone/drone/Godeps/_workspace/src/github.com/GeertJohan/go.rice/box.go:81 +0x71 github.com/drone/drone/pkg/template.init1() /var/cache/drone/src/github.com/drone/drone/pkg/template/template.go:36 +0x3f github.com/drone/drone/pkg/template.init() /var/cache/drone/src/github.com/drone/drone/pkg/template/template.go:178 +0xbb github.com/drone/drone/pkg/mail.init() /var/cache/drone/src/github.com/drone/drone/pkg/mail/mail.go:142 +0x3d github.com/drone/drone/pkg/plugin/notify.init() /var/cache/drone/src/github.com/drone/drone/pkg/plugin/notify/zapier.go:1 +0x65 github.com/drone/drone/pkg/queue.init() /var/cache/drone/src/github.com/drone/drone/pkg/queue/worker.go:243 +0x4c main.init() /var/cache/drone/src/github.com/drone/drone/cmd/droned/drone.go:264 +0x3d ",source-file | documentation-file | other-file | source-file | other-file | other-file | source-file,"Runtime Panic I'm following a very simple setup described [here](http://jipiboily.com/2014/from-zero-to-fully-working-ci-server-in-less-than-10-minutes-with-drone-docker). I'm running Ubuntu 12.04.4 x64. After `dpkg -i drone.deb`, nothing seems to work, even after repeated `start drone` commands:  Bash root@drone-ci:~# tail -n 100 /var/log/upstart/drone.log panic: stat /var/cache/drone/src/github.com/drone/drone/pkg/template/pages: no such file or directory goroutine 1 [running]: runtime.panic(0x922660, 0xc21008bde0) /usr/local/go/src/pkg/runtime/panic.c:266 +0xb6 github.com/GeertJohan/go%2erice.MustFindBox(0xa05500, 0x5, 0x48ef8a) /var/cache/drone/src/github.com/drone/drone/Godeps/_workspace/src/github.com/GeertJohan/go.rice/box.go:81 +0x71 github.com/drone/drone/pkg/template.init1() /var/cache/drone/src/github.com/drone/drone/pkg/template/template.go:36 +0x3f github.com/drone/drone/pkg/template.init() /var/cache/drone/src/github.com/drone/drone/pkg/template/template.go:178 +0xbb github.com/drone/drone/pkg/mail.init() /var/cache/drone/src/github.com/drone/drone/pkg/mail/mail.go:142 +0x3d github.com/drone/drone/pkg/plugin/notify.init() /var/cache/drone/src/github.com/drone/drone/pkg/plugin/notify/zapier.go:1 +0x65 github.com/drone/drone/pkg/queue.init() /var/cache/drone/src/github.com/drone/drone/pkg/queue/worker.go:243 +0x4c main.init() /var/cache/drone/src/github.com/drone/drone/cmd/droned/drone.go:264 +0x3d  source-file documentation-file other-file source-file other-file other-file source-file",no-bug,0.9
