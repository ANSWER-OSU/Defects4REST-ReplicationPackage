issue_no,repo,issue_url,title,description,buggy_msg,patch_msgs,patched_files,patched_file_types,text_for_topic_modeling,prediction,confidence
213,Annif,https://github.com/NatLibFi/Annif/issues/213,Include optional swagger-ui,"Connexion 2.0 made swagger-ui optional, I think we need to depend on it explicitly. I'm seeing this error with a fresh install via TestPyPI (#195): ``` The swagger_ui directory could not be found. Please install connexion with extra install: pip install connexion[swagger-ui] or provide the path to your local installation by passing swagger_path=<your path> ```",Bump version: 0.36.1 → 0.36.2,Depend on connexion[swagger-ui] which is separate since connexion 2.0. Fixes #213 | Also depend on swagger_ui_bundle. Fixes #213,Pipfile | setup.py | Pipfile | setup.py,other-file | source-file | other-file | source-file,"Include optional swagger-ui Connexion 2.0 made swagger-ui optional, I think we need to depend on it explicitly. I'm seeing this error with a fresh install via TestPyPI (#195): ``` The swagger_ui directory could not be found. Please install connexion with extra install: pip install connexion[swagger-ui] or provide the path to your local installation by passing swagger_path=<your path> ``` Bump version: 0.36.1 → 0.36.2 Depend on connexion[swagger-ui] which is separate since connexion 2.0. Fixes #213 Also depend on swagger_ui_bundle. Fixes #213",no-bug,0.9
134,Annif,https://github.com/NatLibFi/Annif/issues/134,fastText backend fails when encountering an unknown subject URI,"Traceback: ``` Backend fasttext: creating fastText training file from documents Traceback (most recent call last): File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/bin/annif"", line 11, in <module> load_entry_point('Annif', 'console_scripts', 'annif')() File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 722, in __call__ return self.main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/flask/cli.py"", line 557, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 697, in main rv = self.invoke(ctx) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 1066, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 895, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 535, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/flask/cli.py"", line 412, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 535, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/git/Annif/annif/cli.py"", line 122, in run_loaddocs proj.load_documents(documents) File ""/home/oisuomin/git/Annif/annif/project.py"", line 222, in load_documents self._load_documents_to_backends(documents, subjects) File ""/home/oisuomin/git/Annif/annif/project.py"", line 202, in _load_documents_to_backends backend.load_documents(documents, project=self) File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 124, in load_documents self._create_train_file_from_documents(documents, project) File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 107, in _create_train_file_from_documents method=self._write_train_file) File ""/home/oisuomin/git/Annif/annif/util.py"", line 19, in atomic_save method(obj, tempfilename) File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 66, in _write_train_file labels = [cls._id_to_label(sid) for sid in subject_ids] File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 66, in <listcomp> labels = [cls._id_to_label(sid) for sid in subject_ids] File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 55, in _id_to_label return ""__label__{:d}"".format(subject_id) TypeError: non-empty format string passed to object.__format__ ``` Probably `subject_id` here is None, because the TSV document mentions a subject URI that is not in the SubjectIndex.",Merge pull request #133 from NatLibFi/issue132-uris-without-brackets Support URIs without angle brackets in vocabulary TSV file. Fixes #132,Handle documents unknown subject URIs in fastText backend. Fixes #134 | Merge pull request #135 from NatLibFi/issue134-fasttext-unknown-subject Handle documents unknown subject URIs in fastText backend. Fixes #134,annif/backend/fasttext.py | annif/corpus/subject.py | tests/test_backend_fasttext.py | annif/backend/fasttext.py | annif/corpus/subject.py | tests/test_backend_fasttext.py,source-file | source-file | test-file | source-file | source-file | test-file,"fastText backend fails when encountering an unknown subject URI Traceback: ``` Backend fasttext: creating fastText training file from documents Traceback (most recent call last): File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/bin/annif"", line 11, in <module> load_entry_point('Annif', 'console_scripts', 'annif')() File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 722, in __call__ return self.main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/flask/cli.py"", line 557, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 697, in main rv = self.invoke(ctx) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 1066, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 895, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 535, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/flask/cli.py"", line 412, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 535, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/git/Annif/annif/cli.py"", line 122, in run_loaddocs proj.load_documents(documents) File ""/home/oisuomin/git/Annif/annif/project.py"", line 222, in load_documents self._load_documents_to_backends(documents, subjects) File ""/home/oisuomin/git/Annif/annif/project.py"", line 202, in _load_documents_to_backends backend.load_documents(documents, project=self) File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 124, in load_documents self._create_train_file_from_documents(documents, project) File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 107, in _create_train_file_from_documents method=self._write_train_file) File ""/home/oisuomin/git/Annif/annif/util.py"", line 19, in atomic_save method(obj, tempfilename) File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 66, in _write_train_file labels = [cls._id_to_label(sid) for sid in subject_ids] File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 66, in <listcomp> labels = [cls._id_to_label(sid) for sid in subject_ids] File ""/home/oisuomin/git/Annif/annif/backend/fasttext.py"", line 55, in _id_to_label return ""__label__{:d}"".format(subject_id) TypeError: non-empty format string passed to object.__format__ ``` Probably `subject_id` here is None, because the TSV document mentions a subject URI that is not in the SubjectIndex. Merge pull request #133 from NatLibFi/issue132-uris-without-brackets Support URIs without angle brackets in vocabulary TSV file. Fixes #132 Handle documents unknown subject URIs in fastText backend. Fixes #134 Merge pull request #135 from NatLibFi/issue134-fasttext-unknown-subject Handle documents unknown subject URIs in fastText backend. Fixes #134",no-bug,0.9
363,Annif,https://github.com/NatLibFi/Annif/issues/363,Use LMDB to store vectors in nn_ensemble,"When the `nn_ensemble` backend is trained, it sends all documents through the source projects and aggregates their suggestion vectors in memory. This can take up a significant amount of RAM. For example, with three YSO based source projects, I could only train a NN ensemble with 8k documents on a machine with 16GB RAM - any larger training set leads to an out of memory situation. If we instead streamed the vectors to a LMDB database, and then read them back from the LMDB in batches, the backend could scale to much larger training data sets. An additional benefit would be that the LMDB could be retained on disk, so that another training run could be made using the same documents but different hyperparameters (this would require implementing the `--cached` option - see #342), without having to process the documents again, so it would be much faster. LMDB seems to be ideal for this as it is very fast and supports streaming style operations both for reading and writing. It will introduce an additional dependency, though.",Merge pull request #379 from NatLibFi/issue377-pav-sparse-vectors Use sparse vectors in PAV backend,"Use LMDB and sparse vectors in nn_ensemble backend, instead of aggregating large vectors in RAM (#363)",.travis.yml | annif/backend/nn_ensemble.py | setup.py,config-file | source-file | source-file,"Use LMDB to store vectors in nn_ensemble When the `nn_ensemble` backend is trained, it sends all documents through the source projects and aggregates their suggestion vectors in memory. This can take up a significant amount of RAM. For example, with three YSO based source projects, I could only train a NN ensemble with 8k documents on a machine with 16GB RAM - any larger training set leads to an out of memory situation. If we instead streamed the vectors to a LMDB database, and then read them back from the LMDB in batches, the backend could scale to much larger training data sets. An additional benefit would be that the LMDB could be retained on disk, so that another training run could be made using the same documents but different hyperparameters (this would require implementing the `--cached` option - see #342), without having to process the documents again, so it would be much faster. LMDB seems to be ideal for this as it is very fast and supports streaming style operations both for reading and writing. It will introduce an additional dependency, though. Merge pull request #379 from NatLibFi/issue377-pav-sparse-vectors Use sparse vectors in PAV backend Use LMDB and sparse vectors in nn_ensemble backend, instead of aggregating large vectors in RAM (#363)",no-bug,0.9
85,Annif,https://github.com/NatLibFi/Annif/issues/85,Eliminate chunking from tf-idf backend,"Experiments show that large chunk sizes perform best, so there is no point in chunking",Merge pull request #90 from NatLibFi/eval-limits Add optimize command for determining best limit/threshold parameters,Eliminate useless chunking from TF-IDF backend. Fixes #85 | Merge pull request #91 from NatLibFi/eliminate-chunking Eliminate useless chunking from TF-IDF backend. Fixes #85,annif/backend/tfidf.py | backends.cfg | tests/backends.cfg | tests/test_backend.py | tests/test_backend_tfidf.py | annif/backend/tfidf.py | backends.cfg | tests/backends.cfg | tests/test_backend.py | tests/test_backend_tfidf.py,source-file | other-file | test-file | test-file | test-file | source-file | other-file | test-file | test-file | test-file,"Eliminate chunking from tf-idf backend Experiments show that large chunk sizes perform best, so there is no point in chunking Merge pull request #90 from NatLibFi/eval-limits Add optimize command for determining best limit/threshold parameters Eliminate useless chunking from TF-IDF backend. Fixes #85 Merge pull request #91 from NatLibFi/eliminate-chunking Eliminate useless chunking from TF-IDF backend. Fixes #85",no-bug,0.8
195,Annif,https://github.com/NatLibFi/Annif/issues/195,PyPI release,It should be possible to install Annif from PyPI. There is a [test build](https://test.pypi.org/project/Annif/) on TestPyPI. Outstanding issues: - [x] README is incorrectly formatted - probably need to specify it's in Markdown format - [x] cannot find config.py since it's outside the annif module - need to think about how to handle configuration,Merge pull request #194 from NatLibFi/web-ui Remake the web UI using Bootstrap 4.1.3 properly,"Set Markdown content type and add Trove classifiers, to help with eventual PyPI release (#195) | Rename package to lowercase ""annif"" to follow Python package naming conventions. Part of #195 | Update README to reflect PyPI availability. Part of #195 | Try to make Travis auto-deploy to PyPI. YAML file reformatted by travis CLI tool. Part of #195",setup.py | setup.py | README.md | .travis.yml,source-file | source-file | documentation-file | config-file,"PyPI release It should be possible to install Annif from PyPI. There is a [test build](https://test.pypi.org/project/Annif/) on TestPyPI. Outstanding issues: - [x] README is incorrectly formatted - probably need to specify it's in Markdown format - [x] cannot find config.py since it's outside the annif module - need to think about how to handle configuration Merge pull request #194 from NatLibFi/web-ui Remake the web UI using Bootstrap 4.1.3 properly Set Markdown content type and add Trove classifiers, to help with eventual PyPI release (#195) Rename package to lowercase ""annif"" to follow Python package naming conventions. Part of #195 Update README to reflect PyPI availability. Part of #195 Try to make Travis auto-deploy to PyPI. YAML file reformatted by travis CLI tool. Part of #195",no-bug,0.9
10,Annif,https://github.com/NatLibFi/Annif/issues/10,Switch to Connexion framework,"Use Connexion for REST API implementation, using the Swagger API spec to define the functionality",Use the right swagger specification,Return JSON from show_project. Fixes #10.,annif.py,source-file,"Switch to Connexion framework Use Connexion for REST API implementation, using the Swagger API spec to define the functionality Use the right swagger specification Return JSON from show_project. Fixes #10.",no-bug,0.8
102,Annif,https://github.com/NatLibFi/Annif/issues/102,Support MauiService REST API via HTTP backend,"The [MauiService](https://github.com/NatLibFi/mauiservice) REST API returns results as a JSON object that looks like this: ```json { ""results"": [{ ""uri"": ""http://www.yso.fi/onto/yso/p12345"", ""label"": ""lastenvaunut"", ""score"": 0.88 }] } ``` The `http` backend should recognize this format. Also need to make sure that limit and threshold parameters are properly passed to MauiService.","make specifying analyzer optional, for projects that don't actually need it",Initial support for MauiService REST API. Fixes #102,annif/backend/http.py | backends.cfg | projects.cfg,source-file | other-file | other-file,"Support MauiService REST API via HTTP backend The [MauiService](https://github.com/NatLibFi/mauiservice) REST API returns results as a JSON object that looks like this: ```json { ""results"": [{ ""uri"": ""http://www.yso.fi/onto/yso/p12345"", ""label"": ""lastenvaunut"", ""score"": 0.88 }] } ``` The `http` backend should recognize this format. Also need to make sure that limit and threshold parameters are properly passed to MauiService. make specifying analyzer optional, for projects that don't actually need it Initial support for MauiService REST API. Fixes #102",no-bug,0.8
57,Annif,https://github.com/NatLibFi/Annif/issues/57,Representation of subject corpus,We need a class like DocumentDirectory that allows iterating through a subject corpus one subject at a time. Prerequisite for #14,Merge branch 'tsv-subject' into subject-corpus,Add Subject and SubjectDirectory classes for representing subject corpus. Fixes #57,annif/corpus/__init__.py | annif/corpus/subject.py | tests/test_corpus.py,source-file | source-file | test-file,Representation of subject corpus We need a class like DocumentDirectory that allows iterating through a subject corpus one subject at a time. Prerequisite for #14 Merge branch 'tsv-subject' into subject-corpus Add Subject and SubjectDirectory classes for representing subject corpus. Fixes #57,no-bug,0.9
593,Annif,https://github.com/NatLibFi/Annif/issues/593,Replace pycld3 dependency?,The pycld3 language detection library which we depend on seems to have install issues on Python 3.10 (see #589). The last [release 0.22](https://pypi.org/project/pycld3/#history) was in March 2021. I think we should consider switching to a more actively maintained library. This should be easy now that we are only using language detection for language filtering but not in other parts of the Annif codebase. A possible promising candidate would be [Lingua](https://github.com/pemistahl/lingua-py) but there are others.,"Update README.md - Fix link to ReadTheDocs (point to docs, not to project page) - Use https in link for annif.org - Mention Finto AI",Use Lingua instead of pycld3 for language detection. Fixes #593,annif/transform/__init__.py | annif/transform/langfilter.py | setup.py | tests/test_transform_langfilter.py,source-file | source-file | source-file | test-file,"Replace pycld3 dependency? The pycld3 language detection library which we depend on seems to have install issues on Python 3.10 (see #589). The last [release 0.22](https://pypi.org/project/pycld3/#history) was in March 2021. I think we should consider switching to a more actively maintained library. This should be easy now that we are only using language detection for language filtering but not in other parts of the Annif codebase. A possible promising candidate would be [Lingua](https://github.com/pemistahl/lingua-py) but there are others. Update README.md - Fix link to ReadTheDocs (point to docs, not to project page) - Use https in link for annif.org - Mention Finto AI Use Lingua instead of pycld3 for language detection. Fixes #593",no-bug,0.9
443,Annif,https://github.com/NatLibFi/Annif/issues/443,Allow use of cached data after cancelled training of nn_ensemble backend,"When cancelling training of the `nn_ensemble` backend after the data transformation was completed, the backend is not able to use the cached data written to the lmdb file. A quick fix for me was to disable locking when opening the lmdb file but that opens another can of worms. Another possible solution could be to close the db after writing all the data and reopening it in readonly mode. Have not tested yet whether this would do the trick.","Add meter styling for webkit browsers, to match firefox",Commit transaction and reopen LMDB read-only for NN ensemble training. Fixes #443,annif/backend/nn_ensemble.py,source-file,"Allow use of cached data after cancelled training of nn_ensemble backend When cancelling training of the `nn_ensemble` backend after the data transformation was completed, the backend is not able to use the cached data written to the lmdb file. A quick fix for me was to disable locking when opening the lmdb file but that opens another can of worms. Another possible solution could be to close the db after writing all the data and reopening it in readonly mode. Have not tested yet whether this would do the trick. Add meter styling for webkit browsers, to match firefox Commit transaction and reopen LMDB read-only for NN ensemble training. Fixes #443",no-bug,0.8
603,Annif,https://github.com/NatLibFi/Annif/issues/603,Share vocabulary objects between projects,"Currently, each AnnifProject creates its own vocabulary (AnnifVocabulary object, which wraps a SubjectIndex) even though in reality many projects may use the same vocabulary - which is now even more likely since vocabularies are multilingual (#600). This leads to unnecessary use of RAM and also CPU when the subject index has to be recreated many times. Instead, the vocabularies could be moved under AnnifRegistry which currently only stores projects. The vocabularies could be loaded lazily as needed using a get_vocab method, similar to the current get_vocab method in annif.vocab.",Update copyright years,Store vocabs in AnnifRegistry so they are shared between projects. Fixes #603,annif/project.py | annif/registry.py | annif/vocab.py | tests/test_vocab.py,source-file | source-file | source-file | test-file,"Share vocabulary objects between projects Currently, each AnnifProject creates its own vocabulary (AnnifVocabulary object, which wraps a SubjectIndex) even though in reality many projects may use the same vocabulary - which is now even more likely since vocabularies are multilingual (#600). This leads to unnecessary use of RAM and also CPU when the subject index has to be recreated many times. Instead, the vocabularies could be moved under AnnifRegistry which currently only stores projects. The vocabularies could be loaded lazily as needed using a get_vocab method, similar to the current get_vocab method in annif.vocab. Update copyright years Store vocabs in AnnifRegistry so they are shared between projects. Fixes #603",no-bug,0.9
64,Annif,https://github.com/NatLibFi/Annif/issues/64,More statistical measures,"Currently Annif reports precision, recall and F-measure. We could have more, e.g. * confusion matrix (true positives, false positives, true negatives, false negatives) * top false positive concepts * top false negative concepts * top true positive concepts * precision@K (K=1,3,5) * normalized Discounted Cumulative Gain",Avoid returning results with zero scores from http and tfidf backend. Fixes #68,Add precision@K eval measures. Part of #64,annif/eval.py | tests/test_cli.py,source-file | test-file,"More statistical measures Currently Annif reports precision, recall and F-measure. We could have more, e.g. * confusion matrix (true positives, false positives, true negatives, false negatives) * top false positive concepts * top false negative concepts * top true positive concepts * precision@K (K=1,3,5) * normalized Discounted Cumulative Gain Avoid returning results with zero scores from http and tfidf backend. Fixes #68 Add precision@K eval measures. Part of #64",no-bug,0.9
119,Annif,https://github.com/NatLibFi/Annif/issues/119,Define entry point and enable local install,"Currently the Annif CLI can only be run using the awkward `python -m annif.cli` command. We should define an entry point via setuptools and make it possible to install it locally, probably using `pipenv install -e .`, so that the command `annif` works directly.",Swagger spec fix: analyze method may also return 404,Add setup.py script and enable local editable install via pipenv. Fixes #119 | Merge pull request #121 from NatLibFi/issue119-local-install Enable installing package via setuptools. Fixes #119,Pipfile | README.md | autopep8.sh | setup.py | .codecov.yml | .scrutinizer.yml | Pipfile | README.md | autopep8.sh | setup.py,other-file | documentation-file | config-file | source-file | config-file | config-file | other-file | documentation-file | config-file | source-file,"Define entry point and enable local install Currently the Annif CLI can only be run using the awkward `python -m annif.cli` command. We should define an entry point via setuptools and make it possible to install it locally, probably using `pipenv install -e .`, so that the command `annif` works directly. Swagger spec fix: analyze method may also return 404 Add setup.py script and enable local editable install via pipenv. Fixes #119 Merge pull request #121 from NatLibFi/issue119-local-install Enable installing package via setuptools. Fixes #119",no-bug,0.9
484,Annif,https://github.com/NatLibFi/Annif/issues/484,MLLM train on empty corpus fails with error,"When trying to train MLLM on an empty corpus it fails with this: ``` File ""/data/Annif/annif/lexical/mllm.py"", line 184, in prepare_train for candidates in train_x]), np.array(train_y)) File ""<__array_function__ internals>"", line 6, in vstack File ""/data/Annif/venv/lib/python3.6/site-packages/numpy/core/shape_base.py"", line 283, in vstack return _nx.concatenate(arrs, 0) File ""<__array_function__ internals>"", line 6, in concatenate ValueError: need at least one array to concatenate ``` It would be better to show an informative error, similar to the ""cannot evaluate empty corpus"" message.",Merge pull request #486 from NatLibFi/feature-svc-backend New SVC (support vector classification) backend using scikit-learn,Show error when training MLLM on empty corpus. Fixes #484,annif/backend/mllm.py | tests/test_backend_mllm.py,source-file | test-file,"MLLM train on empty corpus fails with error When trying to train MLLM on an empty corpus it fails with this: ``` File ""/data/Annif/annif/lexical/mllm.py"", line 184, in prepare_train for candidates in train_x]), np.array(train_y)) File ""<__array_function__ internals>"", line 6, in vstack File ""/data/Annif/venv/lib/python3.6/site-packages/numpy/core/shape_base.py"", line 283, in vstack return _nx.concatenate(arrs, 0) File ""<__array_function__ internals>"", line 6, in concatenate ValueError: need at least one array to concatenate ``` It would be better to show an informative error, similar to the ""cannot evaluate empty corpus"" message. Merge pull request #486 from NatLibFi/feature-svc-backend New SVC (support vector classification) backend using scikit-learn Show error when training MLLM on empty corpus. Fixes #484",no-bug,0.9
94,Annif,https://github.com/NatLibFi/Annif/issues/94,analyzedir command,"The analyze command only analyzes one document. For some backends the startup overhead is very significant so this is inefficient. We could have an `analyzedir` CLI command that works similar to `evaldir` (and MauiTopicIndexer), i.e. it runs analyze on a directory of .txt files and writes the result into TSV files. The file extension / suffix could default to `.annif` but it should be possible to set on the command line. Something like ``` annif analyzedir [--suffix .annif] [--limit 10] [--threshold 0.00] [--verbosity INFO] <backend> <directory> ``` (also `--backend-param` should be supported)",Merge pull request #92 from NatLibFi/fasttext-backend Add fastText backend. Fixes #74,Initial implementation of analyzedir command. Fixes #94,annif/cli.py,source-file,"analyzedir command The analyze command only analyzes one document. For some backends the startup overhead is very significant so this is inefficient. We could have an `analyzedir` CLI command that works similar to `evaldir` (and MauiTopicIndexer), i.e. it runs analyze on a directory of .txt files and writes the result into TSV files. The file extension / suffix could default to `.annif` but it should be possible to set on the command line. Something like ``` annif analyzedir [--suffix .annif] [--limit 10] [--threshold 0.00] [--verbosity INFO] <backend> <directory> ``` (also `--backend-param` should be supported) Merge pull request #92 from NatLibFi/fasttext-backend Add fastText backend. Fixes #74 Initial implementation of analyzedir command. Fixes #94",no-bug,0.9
229,Annif,https://github.com/NatLibFi/Annif/issues/229,Make fastText an optional dependency,"The fastText package needs the native library to be compiled during install. While it has worked reasonably well, I think it would make sense to make all non-pure-Python dependencies optional so that the core Annif can be installed without any compilation of native code. So the fasttext (actually `fasttextmirror`) dependency should be moved from `install_requires` to `extras_requires` in `setup.py` and similar for the Pipfile. The backend code should check whether the `fasttext` module can be imported and fail gracefully if not. Unit tests should also notice if fastText is missing and skip the tests that require it.",Merge pull request #232 from NatLibFi/issue218-simplify-backends Simplify project configuration by allowing only one backend per project,Make fastText an optional dependency. Fixes #229,Pipfile | annif/analyzer/__init__.py | annif/backend/__init__.py | annif/project.py | setup.py | tests/test_analyzer_voikko.py | tests/test_backend_fasttext.py | tests/test_project.py,other-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file,"Make fastText an optional dependency The fastText package needs the native library to be compiled during install. While it has worked reasonably well, I think it would make sense to make all non-pure-Python dependencies optional so that the core Annif can be installed without any compilation of native code. So the fasttext (actually `fasttextmirror`) dependency should be moved from `install_requires` to `extras_requires` in `setup.py` and similar for the Pipfile. The backend code should check whether the `fasttext` module can be imported and fail gracefully if not. Unit tests should also notice if fastText is missing and skip the tests that require it. Merge pull request #232 from NatLibFi/issue218-simplify-backends Simplify project configuration by allowing only one backend per project Make fastText an optional dependency. Fixes #229",no-bug,0.95
111,Annif,https://github.com/NatLibFi/Annif/issues/111,Initialize backends when starting WSGI server,"Currently backends are initialized lazily. Models are only loaded when the first request comes in. This is good for development as it avoids unnecessary delays, but bad for production setups where the first request to come in after the service has started may take a very long time to process. Should initialize the models when the WSGI service starts up, at least in when not in debug/development mode.",remove unnecessary config,Initial support for initializing backends in WSGI setting (#111),annif/__init__.py | annif/backend/backend.py | annif/project.py | config.py,source-file | source-file | source-file | source-file,"Initialize backends when starting WSGI server Currently backends are initialized lazily. Models are only loaded when the first request comes in. This is good for development as it avoids unnecessary delays, but bad for production setups where the first request to come in after the service has started may take a very long time to process. Should initialize the models when the WSGI service starts up, at least in when not in debug/development mode. remove unnecessary config Initial support for initializing backends in WSGI setting (#111)",no-bug,0.9
459,Annif,https://github.com/NatLibFi/Annif/issues/459,Limit parameter is not passed to MauiServer,"Maui backend gives at most 10 suggestions even if a larger `limit` value is set in Annif. At training time [only `id` and `lang` parameters are passed to MauiServer](https://github.com/NatLibFi/Annif/blob/98bde2375abe17a6a1d368fd9acae6f2edf09c00/annif/backend/maui.py#L82), and [the default value of 10](https://github.com/NatLibFi/MauiServer/blob/master/src/main/java/org/topbraid/mauiserver/tagger/TaggerConfiguration.java#L36) is always used for `max_topics_per_document`. ``` # http://localhost:8080/mauiserver/tmp-maui-fi/config id | ""tmp-maui-fi"" -- | -- title | ""tmp-maui-fi"" description | null lang | ""fi"" stemmer_class | null stopwords_class | null cross_validation_passes | 10 max_topics_per_document | 10 probability_threshold | 0 ``` When Maui backend is used in an ensemble project, getting more suggestions would be advantageous.",Merge pull request #458 from NatLibFi/nn-ensemble-tweaks2 Improved handling of source weights in NN ensemble,Pass limit parameter to Maui Server (as max_topics_per_document) during train. Fixes #459,annif/backend/maui.py | tests/test_backend_maui.py,source-file | test-file,"Limit parameter is not passed to MauiServer Maui backend gives at most 10 suggestions even if a larger `limit` value is set in Annif. At training time [only `id` and `lang` parameters are passed to MauiServer](https://github.com/NatLibFi/Annif/blob/98bde2375abe17a6a1d368fd9acae6f2edf09c00/annif/backend/maui.py#L82), and [the default value of 10](https://github.com/NatLibFi/MauiServer/blob/master/src/main/java/org/topbraid/mauiserver/tagger/TaggerConfiguration.java#L36) is always used for `max_topics_per_document`. ``` # http://localhost:8080/mauiserver/tmp-maui-fi/config id | ""tmp-maui-fi"" -- | -- title | ""tmp-maui-fi"" description | null lang | ""fi"" stemmer_class | null stopwords_class | null cross_validation_passes | 10 max_topics_per_document | 10 probability_threshold | 0 ``` When Maui backend is used in an ensemble project, getting more suggestions would be advantageous. Merge pull request #458 from NatLibFi/nn-ensemble-tweaks2 Improved handling of source weights in NN ensemble Pass limit parameter to Maui Server (as max_topics_per_document) during train. Fixes #459",bug,0.9
208,Annif,https://github.com/NatLibFi/Annif/issues/208,Robustness issues in HTTP backend,"These issues are similar enough that I'm only opening a single issue. When using the `arto-fi` data set to train a PAV model, I got this exception: ``` File ""/srv/Annif/annif/backend/pav.py"", line 69, in _analyze_train_corpus hits = source_project.analyze(doc.text) File ""/srv/Annif/annif/project.py"", line 158, in analyze hits_from_backends = self._analyze_with_backends(text, backend_params) File ""/srv/Annif/annif/project.py"", line 109, in _analyze_with_backends hits = backend.analyze(text, project=self, params=beparams) File ""/srv/Annif/annif/backend/backend.py"", line 53, in analyze return self._analyze(text, project, params=beparams) File ""/srv/Annif/annif/backend/http.py"", line 17, in _analyze req = requests.post(params['endpoint'], data=data) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/api.py"", line 116, in post return request('post', url, data=data, json=json, **kwargs) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/api.py"", line 60, in request return session.request(method=method, url=url, **kwargs) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/sessions.py"", line 533, in request resp = self.send(prep, **send_kwargs) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/sessions.py"", line 646, in send r = adapter.send(request, **kwargs) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/adapters.py"", line 498, in send raise ConnectionError(err, request=request) requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')) ``` When training a PAV model with the `jyu-fin` data set, I got this: ``` File ""/srv/Annif/annif/backend/pav.py"", line 80, in _create_pav_model scores, true = self._analyze_train_corpus(source_project, corpus) File ""/srv/Annif/annif/backend/pav.py"", line 69, in _analyze_train_corpus hits = source_project.analyze(doc.text) File ""/srv/Annif/annif/project.py"", line 158, in analyze hits_from_backends = self._analyze_with_backends(text, backend_params) File ""/srv/Annif/annif/project.py"", line 109, in _analyze_with_backends hits = backend.analyze(text, project=self, params=beparams) File ""/srv/Annif/annif/backend/backend.py"", line 53, in analyze return self._analyze(text, project, params=beparams) File ""/srv/Annif/annif/backend/http.py"", line 26, in _analyze for h in results File ""/srv/Annif/annif/backend/http.py"", line 27, in <listcomp> if h['score'] > 0.0], TypeError: string indices must be integers ``` In both cases the problem is that HTTP exceptions and other error conditions are not properly handled by the HTTP backend.",Use errors=replace for more robust handling of text corpus files. Fixes #207,Handle HTTP exceptions and error codes in http backend. Part of #208 | Handle case where JSON decoding fails in HTTP backend. Part of #208 | Handle unexpected JSON data in HTTP backend. Part of #208,annif/backend/http.py | tests/test_backend_http.py | annif/backend/http.py | tests/test_backend_http.py | annif/backend/http.py | tests/test_backend_http.py,source-file | test-file | source-file | test-file | source-file | test-file,"Robustness issues in HTTP backend These issues are similar enough that I'm only opening a single issue. When using the `arto-fi` data set to train a PAV model, I got this exception: ``` File ""/srv/Annif/annif/backend/pav.py"", line 69, in _analyze_train_corpus hits = source_project.analyze(doc.text) File ""/srv/Annif/annif/project.py"", line 158, in analyze hits_from_backends = self._analyze_with_backends(text, backend_params) File ""/srv/Annif/annif/project.py"", line 109, in _analyze_with_backends hits = backend.analyze(text, project=self, params=beparams) File ""/srv/Annif/annif/backend/backend.py"", line 53, in analyze return self._analyze(text, project, params=beparams) File ""/srv/Annif/annif/backend/http.py"", line 17, in _analyze req = requests.post(params['endpoint'], data=data) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/api.py"", line 116, in post return request('post', url, data=data, json=json, **kwargs) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/api.py"", line 60, in request return session.request(method=method, url=url, **kwargs) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/sessions.py"", line 533, in request resp = self.send(prep, **send_kwargs) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/sessions.py"", line 646, in send r = adapter.send(request, **kwargs) File ""/srv/Annif/.venv/lib/python3.6/site-packages/requests/adapters.py"", line 498, in send raise ConnectionError(err, request=request) requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')) ``` When training a PAV model with the `jyu-fin` data set, I got this: ``` File ""/srv/Annif/annif/backend/pav.py"", line 80, in _create_pav_model scores, true = self._analyze_train_corpus(source_project, corpus) File ""/srv/Annif/annif/backend/pav.py"", line 69, in _analyze_train_corpus hits = source_project.analyze(doc.text) File ""/srv/Annif/annif/project.py"", line 158, in analyze hits_from_backends = self._analyze_with_backends(text, backend_params) File ""/srv/Annif/annif/project.py"", line 109, in _analyze_with_backends hits = backend.analyze(text, project=self, params=beparams) File ""/srv/Annif/annif/backend/backend.py"", line 53, in analyze return self._analyze(text, project, params=beparams) File ""/srv/Annif/annif/backend/http.py"", line 26, in _analyze for h in results File ""/srv/Annif/annif/backend/http.py"", line 27, in <listcomp> if h['score'] > 0.0], TypeError: string indices must be integers ``` In both cases the problem is that HTTP exceptions and other error conditions are not properly handled by the HTTP backend. Use errors=replace for more robust handling of text corpus files. Fixes #207 Handle HTTP exceptions and error codes in http backend. Part of #208 Handle case where JSON decoding fails in HTTP backend. Part of #208 Handle unexpected JSON data in HTTP backend. Part of #208",bug,0.9
112,Annif,https://github.com/NatLibFi/Annif/issues/112,Simplify project/backend setup,"Currently there are projects (instances of AnnifProject, configured in projects.cfg) and backends (instances of subclasses of AnnifBackend, configured in backends.cfg) with a one-to-many mapping between projects and backends. This makes it cumbersome to set up a basic project with a 1:1 correspondence to a backend, as both have to be configured separately. Instead the model could be flattened like this: * A backend is the class that implements a specific kind of algorithm (implemented as a subclass of AnnifBackend, as currently) * A project is an instance of a backend with a specific configuration With this approach we only need one configuration file (projects.cfg) that could look like this: ``` [fasttext-fi] name=fastText Finnish type=fasttext language=fi analyzer=snowball(finnish) dim=500 lr=0.25 epoch=30 loss=hs limit=100 chunksize=24 ``` Note that some parameters are backend-specific (here dim, lr, epoch, loss, chunksize) whereas others are common to all projects. Then we need a special backend for combining the results of two projects. I will make a separate issue of it.",add clarification that you have to run pipenv shell first,Simplify project/backend setup by getting rid of backend configuration file. Fixes #112 | Merge pull request #123 from NatLibFi/issue112-simplify-project-backend Simplify project/backend setup. Fixes #112,annif/__init__.py | annif/backend/__init__.py | annif/project.py | backends.cfg | projects.cfg | tests/backends.cfg | tests/projects.cfg | tests/test_backend.py | tests/test_backend_fasttext.py | tests/test_backend_http.py | tests/test_backend_tfidf.py | annif/__init__.py | annif/backend/__init__.py | annif/backend/backend.py | annif/backend/fasttext.py | annif/backend/tfidf.py | annif/project.py | backends.cfg | projects.cfg | tests/backends.cfg | tests/projects.cfg | tests/test_backend.py | tests/test_backend_fasttext.py | tests/test_backend_http.py | tests/test_backend_tfidf.py | tests/test_cli.py,source-file | source-file | source-file | other-file | other-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file,"Simplify project/backend setup Currently there are projects (instances of AnnifProject, configured in projects.cfg) and backends (instances of subclasses of AnnifBackend, configured in backends.cfg) with a one-to-many mapping between projects and backends. This makes it cumbersome to set up a basic project with a 1:1 correspondence to a backend, as both have to be configured separately. Instead the model could be flattened like this: * A backend is the class that implements a specific kind of algorithm (implemented as a subclass of AnnifBackend, as currently) * A project is an instance of a backend with a specific configuration With this approach we only need one configuration file (projects.cfg) that could look like this: ``` [fasttext-fi] name=fastText Finnish type=fasttext language=fi analyzer=snowball(finnish) dim=500 lr=0.25 epoch=30 loss=hs limit=100 chunksize=24 ``` Note that some parameters are backend-specific (here dim, lr, epoch, loss, chunksize) whereas others are common to all projects. Then we need a special backend for combining the results of two projects. I will make a separate issue of it. add clarification that you have to run pipenv shell first Simplify project/backend setup by getting rid of backend configuration file. Fixes #112 Merge pull request #123 from NatLibFi/issue112-simplify-project-backend Simplify project/backend setup. Fixes #112",no-bug,0.9
132,Annif,https://github.com/NatLibFi/Annif/issues/132,Support URIs without angle brackets when loading TSV vocabulary,"Currently the loading silently fails, with a `subjects` file where the first and last character of the URI has been stripped: ``` <ttp://urn.fi/URN:NBN:fi:au:ykl:> YLEISTEOKSET. KIRJA-ALA. KIRJASTOTOIMI YLEINEN KULTTUURIPOLITIIKKA. JOUKKOTIEDOTUS <ttp://urn.fi/URN:NBN:fi:au:ykl:0> KIRJA-ALA <ttp://urn.fi/URN:NBN:fi:au:ykl:00.> Kirjoitus ```",Bump version: 0.25.0 → 0.26.0,Support URIs without angle brackets in vocabulary TSV file. Fixes #132 | Merge pull request #133 from NatLibFi/issue132-uris-without-brackets Support URIs without angle brackets in vocabulary TSV file. Fixes #132,annif/corpus/subject.py | tests/test_vocab_skos.py | tests/test_vocab_tsv.py | annif/corpus/subject.py | tests/test_vocab_skos.py | tests/test_vocab_tsv.py,source-file | test-file | test-file | source-file | test-file | test-file,"Support URIs without angle brackets when loading TSV vocabulary Currently the loading silently fails, with a `subjects` file where the first and last character of the URI has been stripped: ``` <ttp://urn.fi/URN:NBN:fi:au:ykl:> YLEISTEOKSET. KIRJA-ALA. KIRJASTOTOIMI YLEINEN KULTTUURIPOLITIIKKA. JOUKKOTIEDOTUS <ttp://urn.fi/URN:NBN:fi:au:ykl:0> KIRJA-ALA <ttp://urn.fi/URN:NBN:fi:au:ykl:00.> Kirjoitus ``` Bump version: 0.25.0 → 0.26.0 Support URIs without angle brackets in vocabulary TSV file. Fixes #132 Merge pull request #133 from NatLibFi/issue132-uris-without-brackets Support URIs without angle brackets in vocabulary TSV file. Fixes #132",no-bug,0.8
526,Annif,https://github.com/NatLibFi/Annif/issues/526,Parameter to force overwriting the vocabulary in loadvoc command,"Suggested by @niko2342 in #516: The `loadvoc` command could have a parameter such as `--replace`, `--overwrite` or `--force` that would replace the existing vocabulary instead of trying to update it and preserve subject IDs.",Merge pull request #560 from NatLibFi/issue547-config-toml-format Support TOML as a configuration file format alongside CFG/INI.,Add --force parameter to loadvoc to force replacing the vocabulary. Fixes #526,annif/cli.py | annif/vocab.py | tests/test_vocab.py,source-file | source-file | test-file,"Parameter to force overwriting the vocabulary in loadvoc command Suggested by @niko2342 in #516: The `loadvoc` command could have a parameter such as `--replace`, `--overwrite` or `--force` that would replace the existing vocabulary instead of trying to update it and preserve subject IDs. Merge pull request #560 from NatLibFi/issue547-config-toml-format Support TOML as a configuration file format alongside CFG/INI. Add --force parameter to loadvoc to force replacing the vocabulary. Fixes #526",no-bug,0.9
521,Annif,https://github.com/NatLibFi/Annif/issues/521,"Attempting to use a private project returns ""No projects found with id"" from inside command line.","Looking at the documentation of the access settings, it seems that the purpose of hidden projects is to hide them from the UI, but still expose them to the API, and the purpose of private projects is to hide them from any REST API entirely, but still make them usable from within the command line. Instead, making a project private within projects.cfg also makes it unusable from within the command line. I am running annif following the instructions here: https://github.com/NatLibFi/Annif/wiki/Running-as-a-WSGI-service",Merge pull request #520 from NatLibFi/feature-optimize-limit-mask Optimize limit_mask creation,Allow private projects to be accessed from CLI. Fixes #521,annif/cli.py,source-file,"Attempting to use a private project returns ""No projects found with id"" from inside command line. Looking at the documentation of the access settings, it seems that the purpose of hidden projects is to hide them from the UI, but still expose them to the API, and the purpose of private projects is to hide them from any REST API entirely, but still make them usable from within the command line. Instead, making a project private within projects.cfg also makes it unusable from within the command line. I am running annif following the instructions here: https://github.com/NatLibFi/Annif/wiki/Running-as-a-WSGI-service Merge pull request #520 from NatLibFi/feature-optimize-limit-mask Optimize limit_mask creation Allow private projects to be accessed from CLI. Fixes #521",no-bug,0.8
113,Annif,https://github.com/NatLibFi/Annif/issues/113,Ensemble backend,"With #112 we lose the ability to combine results from multiple backends. We could fix that by adding a special backend that combines the results from multiple projects. It could be called `ensemble`. It could be configured like this: ``` [yso-fi] name=YSO Finnish ensemble type=ensemble language=fi sources=tfidf-fi,fasttext-fi ``` The `sources` setting would correspond to the old `backends` setting of projects, except in the new model it would refer to other projects (configured backends). It could also be used to specify weights.",Merge pull request #152 from NatLibFi/issue150-use-click-file use click.Path type arguments in CLI. Fixes #150,Initial version of ensemble backend. Fixes #113 | Merge pull request #153 from NatLibFi/issue113-ensemble-backend Initial version of ensemble backend. Fixes #113,annif/backend/__init__.py | annif/backend/ensemble.py | annif/corpus/subject.py | tests/projects.cfg | tests/test_cli.py | annif/backend/__init__.py | annif/backend/ensemble.py | annif/corpus/subject.py | annif/hit.py | annif/project.py | annif/util.py | autopep8.sh | tests/projects.cfg | tests/test_cli.py,source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file,"Ensemble backend With #112 we lose the ability to combine results from multiple backends. We could fix that by adding a special backend that combines the results from multiple projects. It could be called `ensemble`. It could be configured like this: ``` [yso-fi] name=YSO Finnish ensemble type=ensemble language=fi sources=tfidf-fi,fasttext-fi ``` The `sources` setting would correspond to the old `backends` setting of projects, except in the new model it would refer to other projects (configured backends). It could also be used to specify weights. Merge pull request #152 from NatLibFi/issue150-use-click-file use click.Path type arguments in CLI. Fixes #150 Initial version of ensemble backend. Fixes #113 Merge pull request #153 from NatLibFi/issue113-ensemble-backend Initial version of ensemble backend. Fixes #113",no-bug,0.9
141,Annif,https://github.com/NatLibFi/Annif/issues/141,Support additional metrics,Sklearn has a few more metrics for multilabel evaluation. Especially interesting are metrics that can work with large result sets without needing to specify a limit. To use these we probably need to turn the results into vectors instead of the current approach which evaluates one document at a time. The evaldir and optimize commands should also show how many documents were evaluated.,Merge pull request #165 from NatLibFi/ndcg-from-arrays reimplement NDCG metric using NumPy arrays for input,Add some more DCG/nDCG unit tests based on Wikipedia examples (part of #141),tests/test_eval.py,test-file,Support additional metrics Sklearn has a few more metrics for multilabel evaluation. Especially interesting are metrics that can work with large result sets without needing to specify a limit. To use these we probably need to turn the results into vectors instead of the current approach which evaluates one document at a time. The evaldir and optimize commands should also show how many documents were evaluated. Merge pull request #165 from NatLibFi/ndcg-from-arrays reimplement NDCG metric using NumPy arrays for input Add some more DCG/nDCG unit tests based on Wikipedia examples (part of #141),no-bug,0.9
4,Annif,https://github.com/NatLibFi/Annif/issues/4,Integration with static analyzers,We should set up static analyzers that monitor code quality. These tools can be integrated directly with GitHub so that they check each committed version. We could use one or more of these tools: (even all of them if it's not too much work) * Codebeat * Scrutinizer * Code Climate * SourceClear,Set analyzer min token size to two.,Merge pull request #4 from NatLibFi/master update from natlibfi/annif,annif/suggestion.py | tests/test_suggestion.py,source-file | test-file,Integration with static analyzers We should set up static analyzers that monitor code quality. These tools can be integrated directly with GitHub so that they check each committed version. We could use one or more of these tools: (even all of them if it's not too much work) * Codebeat * Scrutinizer * Code Climate * SourceClear Set analyzer min token size to two. Merge pull request #4 from NatLibFi/master update from natlibfi/annif,no-bug,0.9
76,Annif,https://github.com/NatLibFi/Annif/issues/76,Separate test config from real config,Currently we use the same config files for both. The config files for unit tests should be placed under `tests/` and selection of config files should be done using an environment variable.,"change tmpdir fixture to module scope, as it's only used in this module",separate test and real config (#76). Some CLI tests still need fixing,README.md | annif/__init__.py | annif/backend/__init__.py | annif/backend/backend.py | annif/cli.py | annif/project.py | config.py | tests/conftest.py | tests/test_backend.py | tests/test_backend_http.py | tests/test_backend_tfidf.py | tests/test_cli.py | tests/test_project.py,documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file,"Separate test config from real config Currently we use the same config files for both. The config files for unit tests should be placed under `tests/` and selection of config files should be done using an environment variable. change tmpdir fixture to module scope, as it's only used in this module separate test and real config (#76). Some CLI tests still need fixing",no-bug,0.9
180,Annif,https://github.com/NatLibFi/Annif/issues/180,Manage vocabularies separately from projects,"Currently each project needs its own vocabulary. This is awkward especially for ensembles where the same vocabulary needs to be loaded for each backend project (plus potentially the ensemble itself, although not required right now). Instead we could store the vocabularies as independent objects. The projects would simply indicate the vocabulary id, e.g. ``` [tfidf-fi] name=TF-IDF Finnish language=fi backends=tfidf analyzer=snowball(finnish) limit=10 vocab=yso-fi [fasttext-fi] name=fastText Finnish language=fi backends=fasttext analyzer=snowball(finnish) dim=100 lr=0.25 epoch=5 loss=hs limit=100 chunksize=24 vocab=yso-fi ``` The vocabulary would be loaded just once: annif loadvoc yso-fi yso-skos.rdf It would be stored under `data/vocabs/<vocabid>` instead of under the project.",Merge pull request #185 from NatLibFi/issue176-cleanup remove dead code (project.load_subjects) left after #176,"Separate vocab management from projects. Fixes #180 | Merge pull request #186 from NatLibFi/issue180-separate-vocab Separate vocab management from projects. Fixes #180 | Add vocab settings to example configuration file, needed after #180",annif/cli.py | annif/project.py | annif/vocab.py | tests/projects.cfg | tests/test_cli.py | tests/test_project.py | annif/cli.py | annif/project.py | annif/vocab.py | tests/projects.cfg | tests/test_cli.py | tests/test_project.py | projects.cfg.dist,source-file | source-file | source-file | test-file | test-file | test-file | source-file | source-file | source-file | test-file | test-file | test-file | other-file,"Manage vocabularies separately from projects Currently each project needs its own vocabulary. This is awkward especially for ensembles where the same vocabulary needs to be loaded for each backend project (plus potentially the ensemble itself, although not required right now). Instead we could store the vocabularies as independent objects. The projects would simply indicate the vocabulary id, e.g. ``` [tfidf-fi] name=TF-IDF Finnish language=fi backends=tfidf analyzer=snowball(finnish) limit=10 vocab=yso-fi [fasttext-fi] name=fastText Finnish language=fi backends=fasttext analyzer=snowball(finnish) dim=100 lr=0.25 epoch=5 loss=hs limit=100 chunksize=24 vocab=yso-fi ``` The vocabulary would be loaded just once: annif loadvoc yso-fi yso-skos.rdf It would be stored under `data/vocabs/<vocabid>` instead of under the project. Merge pull request #185 from NatLibFi/issue176-cleanup remove dead code (project.load_subjects) left after #176 Separate vocab management from projects. Fixes #180 Merge pull request #186 from NatLibFi/issue180-separate-vocab Separate vocab management from projects. Fixes #180 Add vocab settings to example configuration file, needed after #180",no-bug,0.9
202,Annif,https://github.com/NatLibFi/Annif/issues/202,SubjectSet.as_vector() gives invalid result on unknown subjects,"I noticed that when a SubjectSet contains a concept that is not in the subject vocabulary, as_vector() returns a vector of ones.",Bump version: 0.34.0 → 0.35.0,Don't return a vector of ones when encountering unknown subjects. Fixes #202 | Merge pull request #203 from NatLibFi/issue202-fix-subjectset-asvector Don't return a vector of ones when encountering unknown subjects. Fixes #202,annif/corpus/subject.py | tests/test_corpus.py | annif/corpus/subject.py | tests/test_corpus.py,source-file | test-file | source-file | test-file,"SubjectSet.as_vector() gives invalid result on unknown subjects I noticed that when a SubjectSet contains a concept that is not in the subject vocabulary, as_vector() returns a vector of ones. Bump version: 0.34.0 → 0.35.0 Don't return a vector of ones when encountering unknown subjects. Fixes #202 Merge pull request #203 from NatLibFi/issue202-fix-subjectset-asvector Don't return a vector of ones when encountering unknown subjects. Fixes #202",no-bug,0.8
75,Annif,https://github.com/NatLibFi/Annif/issues/75,Override backend parameters from CLI,The CLI analyze and eval/evaldir commands could support a parameter like `--backend-param tfidf-fi.chunksize=5` that could be used to override backend options defined in backends.cfg. This would make it easier to experiment with different parameters.,Merge pull request #77 from NatLibFi/separate-config Separate unit test config from real config. Fixes #76,"Add --backend-param (-b) option for analyze, eval, evaldir commands. Fixes #75",annif/backend/backend.py | annif/backend/dummy.py | annif/backend/http.py | annif/backend/tfidf.py | annif/cli.py | annif/project.py | tests/test_cli.py,source-file | source-file | source-file | source-file | source-file | source-file | test-file,"Override backend parameters from CLI The CLI analyze and eval/evaldir commands could support a parameter like `--backend-param tfidf-fi.chunksize=5` that could be used to override backend options defined in backends.cfg. This would make it easier to experiment with different parameters. Merge pull request #77 from NatLibFi/separate-config Separate unit test config from real config. Fixes #76 Add --backend-param (-b) option for analyze, eval, evaldir commands. Fixes #75",no-bug,0.9
332,Annif,https://github.com/NatLibFi/Annif/issues/332,Eval crash on TFIDF with multiple training files,"When evaluating a TFIDF project trained on multiple files (`CombinedCorpus`) the `eval` crashes: ``` (Annif) jmminkin@lx8-9811-008:/home/local/jmminkin/git/Annif$ annif train tfidf-fi yso-cicero-finna-fi-head-500-lines.tsv yso-cicero-finna-fi-tail-500-lines.tsv creating vectorizer warning: Unknown subject URI <http://www.yso.fi/onto/yso/p14645> ... Backend tfidf: creating similarity index (Annif) jmminkin@lx8-9811-008:/home/local/jmminkin/git/Annif$ annif eval tfidf-fi ~/annif-projects/Annif-corpora/fulltext/kirjastonhoitaja/test/ warning: Unknown subject URI <http://www.yso.fi/onto/yso/p1997> ... Traceback (most recent call last): File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/flask/cli.py"", line 586, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/flask/cli.py"", line 426, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/local/jmminkin/git/Annif/annif/cli.py"", line 276, in run_eval for metric, score in eval_batch.results().items(): File ""/home/local/jmminkin/git/Annif/annif/eval.py"", line 143, in results y_true, y_pred, metrics) File ""/home/local/jmminkin/git/Annif/annif/eval.py"", line 93, in _evaluate_samples y_true, y_pred_binary, average='samples') File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/sklearn/metrics/classification.py"", line 1569, in precision_score sample_weight=sample_weight) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/sklearn/metrics/classification.py"", line 1415, in precision_recall_fscore_support pos_label) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/sklearn/metrics/classification.py"", line 1240, in _check_set_wise_labels present_labels = unique_labels(y_true, y_pred) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/sklearn/utils/multiclass.py"", line 88, in unique_labels raise ValueError(""Multi-label binary indicator input with "" ValueError: Multi-label binary indicator input with different numbers of labels ``` Also `suggest` does not seem to work with such a project (although this could be unrelated): ``` $ echo testi tekstia tassa nain | annif suggest tfidf-fi (Annif) jmminkin@lx8-9811-008:/home/local/jmminkin/git/Annif$ (no results) ``` If a fasttext project is trained on multiple files like above, `eval` works and `suggest` produces results. The `eval` crash might be due to that TFIDF backend [saves the `_index`](https://github.com/NatLibFi/Annif/blob/master/annif/backend/tfidf.py#L44) that is created in training (when its size is multiplied by the number of the input files), and then for predictions the same `_index` is loaded and used (but this is not the case for fasttext project). However, `eval` simply uses the project's vocabulary](https://github.com/NatLibFi/Annif/blob/master/annif/cli.py#L266) which does not know about the multiplied size of the `_index`, leading to [the size mismatch mentioned in the traceback](https://github.com/NatLibFi/Annif/blob/master/annif/eval.py#L93).",Merge pull request #322 from NatLibFi/issue318-handle-missing-or-invalid-path-input-for-commands Issue318 handle missing or invalid path input for commands,Merge subjects in CombinedCorpus instead of concatenating them. Fixes #332,annif/corpus/combine.py | tests/test_corpus.py,source-file | test-file,"Eval crash on TFIDF with multiple training files When evaluating a TFIDF project trained on multiple files (`CombinedCorpus`) the `eval` crashes: ``` (Annif) jmminkin@lx8-9811-008:/home/local/jmminkin/git/Annif$ annif train tfidf-fi yso-cicero-finna-fi-head-500-lines.tsv yso-cicero-finna-fi-tail-500-lines.tsv creating vectorizer warning: Unknown subject URI <http://www.yso.fi/onto/yso/p14645> ... Backend tfidf: creating similarity index (Annif) jmminkin@lx8-9811-008:/home/local/jmminkin/git/Annif$ annif eval tfidf-fi ~/annif-projects/Annif-corpora/fulltext/kirjastonhoitaja/test/ warning: Unknown subject URI <http://www.yso.fi/onto/yso/p1997> ... Traceback (most recent call last): File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/flask/cli.py"", line 586, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/flask/cli.py"", line 426, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/local/jmminkin/git/Annif/annif/cli.py"", line 276, in run_eval for metric, score in eval_batch.results().items(): File ""/home/local/jmminkin/git/Annif/annif/eval.py"", line 143, in results y_true, y_pred, metrics) File ""/home/local/jmminkin/git/Annif/annif/eval.py"", line 93, in _evaluate_samples y_true, y_pred_binary, average='samples') File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/sklearn/metrics/classification.py"", line 1569, in precision_score sample_weight=sample_weight) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/sklearn/metrics/classification.py"", line 1415, in precision_recall_fscore_support pos_label) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/sklearn/metrics/classification.py"", line 1240, in _check_set_wise_labels present_labels = unique_labels(y_true, y_pred) File ""/home/jmminkin/.local/share/virtualenvs/Annif-b5vsMxU8/lib/python3.6/site-packages/sklearn/utils/multiclass.py"", line 88, in unique_labels raise ValueError(""Multi-label binary indicator input with "" ValueError: Multi-label binary indicator input with different numbers of labels ``` Also `suggest` does not seem to work with such a project (although this could be unrelated): ``` $ echo testi tekstia tassa nain | annif suggest tfidf-fi (Annif) jmminkin@lx8-9811-008:/home/local/jmminkin/git/Annif$ (no results) ``` If a fasttext project is trained on multiple files like above, `eval` works and `suggest` produces results. The `eval` crash might be due to that TFIDF backend [saves the `_index`](https://github.com/NatLibFi/Annif/blob/master/annif/backend/tfidf.py#L44) that is created in training (when its size is multiplied by the number of the input files), and then for predictions the same `_index` is loaded and used (but this is not the case for fasttext project). However, `eval` simply uses the project's vocabulary](https://github.com/NatLibFi/Annif/blob/master/annif/cli.py#L266) which does not know about the multiplied size of the `_index`, leading to [the size mismatch mentioned in the traceback](https://github.com/NatLibFi/Annif/blob/master/annif/eval.py#L93). Merge pull request #322 from NatLibFi/issue318-handle-missing-or-invalid-path-input-for-commands Issue318 handle missing or invalid path input for commands Merge subjects in CombinedCorpus instead of concatenating them. Fixes #332",no-bug,0.8
79,Annif,https://github.com/NatLibFi/Annif/issues/79,Make analyzer project-specific (again),"It turns out that backend-specific analyzers aren't so great after all. The analyzer should be project-specific (like all the feature extraction from text, but that's a separate issue)",add autopep8.sh convenience script,Move analyzer from backend to project. Fixes #79 | Merge pull request #82 from NatLibFi/project-specific-analyzer Move analyzer from backend to project. Fixes #79,annif/__init__.py | annif/analyzer/snowball.py | annif/backend/__init__.py | annif/backend/backend.py | annif/backend/dummy.py | annif/backend/http.py | annif/backend/tfidf.py | annif/project.py | backends.cfg | projects.cfg | tests/backends.cfg | tests/projects.cfg | tests/test_backend.py | tests/test_backend_http.py | tests/test_backend_tfidf.py | tests/test_project.py | annif/__init__.py | annif/analyzer/__init__.py | annif/analyzer/analyzer.py | annif/analyzer/snowball.py | annif/backend/__init__.py | annif/backend/backend.py | annif/backend/dummy.py | annif/backend/http.py | annif/backend/tfidf.py | annif/project.py | backends.cfg | projects.cfg | tests/backends.cfg | tests/projects.cfg | tests/test_backend.py | tests/test_backend_http.py | tests/test_backend_tfidf.py | tests/test_project.py,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | test-file | test-file | test-file | test-file | test-file | test-file,"Make analyzer project-specific (again) It turns out that backend-specific analyzers aren't so great after all. The analyzer should be project-specific (like all the feature extraction from text, but that's a separate issue) add autopep8.sh convenience script Move analyzer from backend to project. Fixes #79 Merge pull request #82 from NatLibFi/project-specific-analyzer Move analyzer from backend to project. Fixes #79",no-bug,0.9
222,Annif,https://github.com/NatLibFi/Annif/issues/222,Travis build fails due to boto / google_compute_engine import error,"The latest Travis builds fail with an error like this: ``` ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/gensim/__init__.py:5: in <module> from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils # noqa:F401 ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/gensim/parsing/__init__.py:4: in <module> from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2, # noqa:F401 ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/gensim/parsing/preprocessing.py:40: in <module> from gensim import utils ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/gensim/utils.py:45: in <module> from smart_open import smart_open ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/smart_open/__init__.py:1: in <module> from .smart_open_lib import * ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/smart_open/smart_open_lib.py:45: in <module> from boto.compat import BytesIO, urlsplit, six ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/boto/__init__.py:1216: in <module> boto.plugin.load_plugins(config) ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/boto/plugin.py:93: in load_plugins _import_module(file) ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/boto/plugin.py:75: in _import_module return imp.load_module(name, file, filename, data) ../../../virtualenv/python3.5.6/lib/python3.5/imp.py:235: in load_module return load_source(name, filename, file) ../../../virtualenv/python3.5.6/lib/python3.5/imp.py:172: in load_source module = _load(spec) /usr/lib/python2.7/dist-packages/google_compute_engine/boto/compute_auth.py:19: in <module> from google_compute_engine import logger E ImportError: No module named 'google_compute_engine' The command ""pytest --cov=./"" exited with 4. ``` This seems to be due to this [travis issue](https://github.com/travis-ci/travis-ci/issues/7940)",Bump version: 0.37.0 → 0.37.1,Try to fix Travis build failures (#222),.travis.yml,config-file,"Travis build fails due to boto / google_compute_engine import error The latest Travis builds fail with an error like this: ``` ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/gensim/__init__.py:5: in <module> from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils # noqa:F401 ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/gensim/parsing/__init__.py:4: in <module> from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2, # noqa:F401 ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/gensim/parsing/preprocessing.py:40: in <module> from gensim import utils ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/gensim/utils.py:45: in <module> from smart_open import smart_open ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/smart_open/__init__.py:1: in <module> from .smart_open_lib import * ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/smart_open/smart_open_lib.py:45: in <module> from boto.compat import BytesIO, urlsplit, six ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/boto/__init__.py:1216: in <module> boto.plugin.load_plugins(config) ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/boto/plugin.py:93: in load_plugins _import_module(file) ../../../virtualenv/python3.5.6/lib/python3.5/site-packages/boto/plugin.py:75: in _import_module return imp.load_module(name, file, filename, data) ../../../virtualenv/python3.5.6/lib/python3.5/imp.py:235: in load_module return load_source(name, filename, file) ../../../virtualenv/python3.5.6/lib/python3.5/imp.py:172: in load_source module = _load(spec) /usr/lib/python2.7/dist-packages/google_compute_engine/boto/compute_auth.py:19: in <module> from google_compute_engine import logger E ImportError: No module named 'google_compute_engine' The command ""pytest --cov=./"" exited with 4. ``` This seems to be due to this [travis issue](https://github.com/travis-ci/travis-ci/issues/7940) Bump version: 0.37.0 → 0.37.1 Try to fix Travis build failures (#222)",no-bug,0.95
107,Annif,https://github.com/NatLibFi/Annif/issues/107,Upgrade fastText,"We currently use old, unofficial fastText bindings that are available via PyPI. They rely on Cython which makes the install process awkward (see README.md and .travis.yml). We should upgrade to the official fastText bindings as soon as they are available via PyPI. Currently the package fastText 0.8.22 is available on TestPyPI, see https://github.com/facebookresearch/fastText/issues/436",Merge pull request #109 from NatLibFi/issue108-simple-analyzer Add Simple analyzer. Fixes #108,Issue #107: Upgrade fastText bindings to latest found on testpypi,Pipfile | annif/backend/fasttext.py | tests/test_backend_fasttext.py,other-file | source-file | test-file,"Upgrade fastText We currently use old, unofficial fastText bindings that are available via PyPI. They rely on Cython which makes the install process awkward (see README.md and .travis.yml). We should upgrade to the official fastText bindings as soon as they are available via PyPI. Currently the package fastText 0.8.22 is available on TestPyPI, see https://github.com/facebookresearch/fastText/issues/436 Merge pull request #109 from NatLibFi/issue108-simple-analyzer Add Simple analyzer. Fixes #108 Issue #107: Upgrade fastText bindings to latest found on testpypi",no-bug,0.9
267,Annif,https://github.com/NatLibFi/Annif/issues/267,Rename CLI analyze command to suggest,"I'd like to rename the `analyze` CLI command (and also the REST method, but that's a separate issue) into `suggest`, following the example of the [Maui Server API](https://github.com/TopQuadrant/MauiServer/blob/master/API.md) which has a similar method. I realize this may break existing uses, but hey, Annif is still in 0.x versions where breakage is expected, and if you're going to do it it's better to do this early. I've never been very happy with the `analyze` command name, for example because it clashes with the concept of Analyzers which are just the first part of the operation. After the change the wiki documentation needs to be updated as well.",Merge pull request #263 from Veldhoen/pull-request Explicit character encoding for all calls to open() Fixes #262,"Rename CLI command analyze to suggest, and analyzedir to index. Part of #267 | Rename analyze methods in the codebase to suggest. Fix docstrings. Part of #267 | Refactor: Rename analyze methods in the codebase to suggest. Fix docstrings. Part of #267 | Refactor: Rename AnalysisHit to SubjectSuggestion. Part of #267 | Refactor: Rename *AnalysisResult to *SuggestionResult. Part of #267 | Refactor: Rename HitFilter to SuggestionFilter. Part of #267 | Refactor: rename annif.hit module to annif.suggestion . Part of #267 | Refactor: Rename WeightedHits to WeightedSuggestion. Part of #267 | Refactor: rename test_hit.py to test_suggestion.py, fix method and var names. Part of #267",annif/cli.py | tests/test_cli.py | annif/backend/backend.py | annif/backend/dummy.py | annif/backend/ensemble.py | annif/backend/fasttext.py | annif/backend/http.py | annif/backend/mixins.py | annif/backend/pav.py | annif/backend/tfidf.py | annif/backend/vw_multi.py | annif/cli.py | annif/project.py | annif/rest.py | tests/test_backend.py | tests/test_backend_fasttext.py | tests/test_backend_http.py | tests/test_backend_pav.py | tests/test_backend_tfidf.py | tests/test_backend_vw_multi.py | tests/test_project.py | annif/backend/backend.py | annif/backend/dummy.py | annif/backend/ensemble.py | annif/backend/fasttext.py | annif/backend/http.py | annif/backend/mixins.py | annif/backend/pav.py | annif/backend/tfidf.py | annif/backend/vw_multi.py | annif/cli.py | annif/project.py | annif/rest.py | tests/test_backend.py | tests/test_backend_fasttext.py | tests/test_backend_http.py | tests/test_backend_pav.py | tests/test_backend_tfidf.py | tests/test_backend_vw_multi.py | tests/test_project.py | annif/backend/backend.py | annif/backend/dummy.py | annif/backend/fasttext.py | annif/backend/http.py | annif/backend/pav.py | annif/hit.py | annif/project.py | tests/test_eval.py | tests/test_hit.py | annif/backend/dummy.py | annif/backend/fasttext.py | annif/backend/http.py | annif/backend/mixins.py | annif/backend/pav.py | annif/backend/tfidf.py | annif/backend/vw_multi.py | annif/hit.py | annif/swagger/annif.yaml | annif/util.py | tests/test_eval.py | tests/test_hit.py | annif/cli.py | annif/hit.py | annif/rest.py | tests/test_hit.py | annif/backend/dummy.py | annif/backend/ensemble.py | annif/backend/fasttext.py | annif/backend/http.py | annif/backend/mixins.py | annif/backend/pav.py | annif/backend/tfidf.py | annif/backend/vw_multi.py | annif/cli.py | annif/project.py | annif/rest.py | annif/suggestion.py | annif/util.py | tests/test_eval.py | tests/test_hit.py | annif/backend/ensemble.py | annif/suggestion.py | annif/util.py | tests/test_hit.py | tests/test_suggestion.py,source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | test-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | test-file | test-file,"Rename CLI analyze command to suggest I'd like to rename the `analyze` CLI command (and also the REST method, but that's a separate issue) into `suggest`, following the example of the [Maui Server API](https://github.com/TopQuadrant/MauiServer/blob/master/API.md) which has a similar method. I realize this may break existing uses, but hey, Annif is still in 0.x versions where breakage is expected, and if you're going to do it it's better to do this early. I've never been very happy with the `analyze` command name, for example because it clashes with the concept of Analyzers which are just the first part of the operation. After the change the wiki documentation needs to be updated as well. Merge pull request #263 from Veldhoen/pull-request Explicit character encoding for all calls to open() Fixes #262 Rename CLI command analyze to suggest, and analyzedir to index. Part of #267 Rename analyze methods in the codebase to suggest. Fix docstrings. Part of #267 Refactor: Rename analyze methods in the codebase to suggest. Fix docstrings. Part of #267 Refactor: Rename AnalysisHit to SubjectSuggestion. Part of #267 Refactor: Rename *AnalysisResult to *SuggestionResult. Part of #267 Refactor: Rename HitFilter to SuggestionFilter. Part of #267 Refactor: rename annif.hit module to annif.suggestion . Part of #267 Refactor: Rename WeightedHits to WeightedSuggestion. Part of #267 Refactor: rename test_hit.py to test_suggestion.py, fix method and var names. Part of #267",no-bug,0.9
46,Annif,https://github.com/NatLibFi/Annif/issues/46,Gensim TF-IDF backend,Make a tf-idf backend using gensim. The load operation needs to be implemented for this. We probably need some toy test data for unit tests.,Support backend specific data directories. Fixes #61,"Add ""tfidf"" backend and make a Directory. Part of #46 | Create a TF-IDF model. Part of #46 | Create similarity index of vectorized corpus. Part of #46 | keep dictionary, tfidf model and index in instance variables. Part of #46 | First working version of TF-IDF backend. Fixes #46",annif/backend/__init__.py | annif/backend/backend.py | annif/backend/tfidf.py | requirements.txt | tests/test_backend_tfidf.py | annif/backend/tfidf.py | tests/test_backend_tfidf.py | annif/backend/tfidf.py | tests/test_backend_tfidf.py | annif/backend/tfidf.py | annif/backend/tfidf.py | annif/corpus/subject.py | tests/test_backend_tfidf.py | tests/test_corpus.py,source-file | source-file | source-file | other-file | test-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | test-file | test-file,"Gensim TF-IDF backend Make a tf-idf backend using gensim. The load operation needs to be implemented for this. We probably need some toy test data for unit tests. Support backend specific data directories. Fixes #61 Add ""tfidf"" backend and make a Directory. Part of #46 Create a TF-IDF model. Part of #46 Create similarity index of vectorized corpus. Part of #46 keep dictionary, tfidf model and index in instance variables. Part of #46 First working version of TF-IDF backend. Fixes #46",no-bug,0.9
318,Annif,https://github.com/NatLibFi/Annif/issues/318,Handle missing or invalid path input for commands,"A full traceback is shown for trying to e.g. train on a nonexistent path: ``` $ annif train tfidf-fi nonexistent_path ... File ""/home/local/jmminkin/git/Annif/annif/corpus/document.py"", line 65, in documents with opener(self.path) as tsvfile: FileNotFoundError: [Errno 2] No such file or directory: 'nonexistent_path' ``` Similarly for trying to train without a path: ``` $ annif train tfidf-fi ... File ""/home/local/jmminkin/git/Annif/annif/cli.py"", line 53, in open_documents docs = open_doc_path(paths[0]) IndexError: tuple index out of range ``` The first case could be resolved by adding `exists=True` argument to `type=click.Path()`. This (at least alone) does not work in the second case, for which maybe `required=True` could be used, but the [Note on Non-Empty Variadic Arguments](https://click.palletsprojects.com/en/7.x/arguments/) should be considered. Similar tracebacks arise when using: - train - learn - eval - optimize For some reason `index` behaves differently: - It gives proper error when not given a path: ``` $ annif index tfidf-fi Usage: annif index [OPTIONS] PROJECT_ID DIRECTORY Try ""annif index --help"" for help. Error: Missing argument ""DIRECTORY"". ``` - It does not produce any output or error with nonexistent path: ``` $ annif index tfidf-fi nonexistent $ ```",Adapt to PR #313,Let Click handle nonexistent files (issue #318),annif/corpus/document.py | tests/test_corpus.py,source-file | test-file,"Handle missing or invalid path input for commands A full traceback is shown for trying to e.g. train on a nonexistent path: ``` $ annif train tfidf-fi nonexistent_path ... File ""/home/local/jmminkin/git/Annif/annif/corpus/document.py"", line 65, in documents with opener(self.path) as tsvfile: FileNotFoundError: [Errno 2] No such file or directory: 'nonexistent_path' ``` Similarly for trying to train without a path: ``` $ annif train tfidf-fi ... File ""/home/local/jmminkin/git/Annif/annif/cli.py"", line 53, in open_documents docs = open_doc_path(paths[0]) IndexError: tuple index out of range ``` The first case could be resolved by adding `exists=True` argument to `type=click.Path()`. This (at least alone) does not work in the second case, for which maybe `required=True` could be used, but the [Note on Non-Empty Variadic Arguments](https://click.palletsprojects.com/en/7.x/arguments/) should be considered. Similar tracebacks arise when using: - train - learn - eval - optimize For some reason `index` behaves differently: - It gives proper error when not given a path: ``` $ annif index tfidf-fi Usage: annif index [OPTIONS] PROJECT_ID DIRECTORY Try ""annif index --help"" for help. Error: Missing argument ""DIRECTORY"". ``` - It does not produce any output or error with nonexistent path: ``` $ annif index tfidf-fi nonexistent $ ``` Adapt to PR #313 Let Click handle nonexistent files (issue #318)",no-bug,0.9
37,Annif,https://github.com/NatLibFi/Annif/issues/37,Better Finnish analyzer based on libvoikko,In #34 I resorted to a Snowball stemmer for Finnish because of difficulties installing libvoikko in a virtual environment (and Travis might be problematic too). But it would be worth at least trying whether libvoikko gives better results than the stupid Snowball stemmer.,Bump version: 0.31.0 → 0.32.0,Add support for voikko analyzer. Fixes #37 | Switch test and example configs to use Voikko analyzer for Finnish. Part of #37 | Add support for voikko analyzer. Fixes #37 | Switch test and example configs to use Voikko analyzer for Finnish. Part of #37,Pipfile | annif/analyzer/__init__.py | annif/analyzer/voikko.py | setup.py | tests/test_analyzer.py | projects.cfg.dist | tests/projects.cfg | tests/test_project.py | Pipfile | annif/analyzer/__init__.py | annif/analyzer/voikko.py | setup.py | tests/test_analyzer.py | projects.cfg.dist | tests/projects.cfg | tests/test_project.py,other-file | source-file | source-file | source-file | test-file | other-file | test-file | test-file | other-file | source-file | source-file | source-file | test-file | other-file | test-file | test-file,Better Finnish analyzer based on libvoikko In #34 I resorted to a Snowball stemmer for Finnish because of difficulties installing libvoikko in a virtual environment (and Travis might be problematic too). But it would be worth at least trying whether libvoikko gives better results than the stupid Snowball stemmer. Bump version: 0.31.0 → 0.32.0 Add support for voikko analyzer. Fixes #37 Switch test and example configs to use Voikko analyzer for Finnish. Part of #37 Add support for voikko analyzer. Fixes #37 Switch test and example configs to use Voikko analyzer for Finnish. Part of #37,no-bug,0.9
230,Annif,https://github.com/NatLibFi/Annif/issues/230,Vowpal Wabbit regular backend,"The Vowpal Wabbit (VW) online learning systems seems promising as a backend for Annif. It could be used in at least two ways: 1. As a basic backend that inputs text and predicts classes/concepts/subjects. 2. As an ensemble backend that intelligently combines results from other backends, similar to PAV. For case 1, the limitation of VW is that while it can perform multiclass and multilabel tasks, internally those tasks will be converted to K (mostly) independent classifiers, where K is the number of classes. When K is large, and there are also many input features, the resulting combinatorial explosion will cause problems despite the inherent scalability in VW. Thus the VW backend would probably work best for classification tasks where there are at most a few thousand classes. Also it would be useful to be able to use the output (concepts with scores) of other backends as input to the VW classifier; that would make it possible to e.g. predict UDC classes based on YSO subjects assigned by other backends. The big attraction of VW, alongside its speed and scalability, is that it is oriented around online learning. So whatever it has been trained on, it can always learn to adapt based on feedback. It would be natural to implement VW support first, when adding support for online learning / feedback to Annif (#225). VW requires a native library to be built, and building it can be difficult in some environments. It should be an optional dependency like voikko (#37) and fastText (#229).",Merge pull request #256 from NatLibFi/issue230-vw-multi-input-from-projects vw-multi backend: use input from other projects,Initial support for online learning in vw_multi backend. Part of #225 and #230,annif/backend/backend.py | annif/backend/vw_multi.py | tests/test_backend_vw_multi.py,source-file | source-file | test-file,"Vowpal Wabbit regular backend The Vowpal Wabbit (VW) online learning systems seems promising as a backend for Annif. It could be used in at least two ways: 1. As a basic backend that inputs text and predicts classes/concepts/subjects. 2. As an ensemble backend that intelligently combines results from other backends, similar to PAV. For case 1, the limitation of VW is that while it can perform multiclass and multilabel tasks, internally those tasks will be converted to K (mostly) independent classifiers, where K is the number of classes. When K is large, and there are also many input features, the resulting combinatorial explosion will cause problems despite the inherent scalability in VW. Thus the VW backend would probably work best for classification tasks where there are at most a few thousand classes. Also it would be useful to be able to use the output (concepts with scores) of other backends as input to the VW classifier; that would make it possible to e.g. predict UDC classes based on YSO subjects assigned by other backends. The big attraction of VW, alongside its speed and scalability, is that it is oriented around online learning. So whatever it has been trained on, it can always learn to adapt based on feedback. It would be natural to implement VW support first, when adding support for online learning / feedback to Annif (#225). VW requires a native library to be built, and building it can be difficult in some environments. It should be an optional dependency like voikko (#37) and fastText (#229). Merge pull request #256 from NatLibFi/issue230-vw-multi-input-from-projects vw-multi backend: use input from other projects Initial support for online learning in vw_multi backend. Part of #225 and #230",no-bug,0.9
27,Annif,https://github.com/NatLibFi/Annif/issues/27,Support Problem JSON in Swagger spec and REST API,Our REST responses in error situations should follow [RFC 7807](https://tools.ietf.org/html/rfc7807). Some concrete guidance can be found in the [Zalando RESTful API guidelines](https://zalando.github.io/restful-api-guidelines/#176),Merge pull request #117 from NatLibFi/issue89-rest-tests Implement REST API tests using swagger-tester. Fixes #89,Use Problem JSON (RFC 7807) to report errors in REST API. Fixes #27 | Merge pull request #118 from NatLibFi/issue27-rest-problem-json Use Problem JSON (RFC 7807) to report errors in REST API. Fixes #27,annif/rest.py | swagger/annif.yaml | annif/rest.py | swagger/annif.yaml,source-file | documentation-file | source-file | documentation-file,Support Problem JSON in Swagger spec and REST API Our REST responses in error situations should follow [RFC 7807](https://tools.ietf.org/html/rfc7807). Some concrete guidance can be found in the [Zalando RESTful API guidelines](https://zalando.github.io/restful-api-guidelines/#176) Merge pull request #117 from NatLibFi/issue89-rest-tests Implement REST API tests using swagger-tester. Fixes #89 Use Problem JSON (RFC 7807) to report errors in REST API. Fixes #27 Merge pull request #118 from NatLibFi/issue27-rest-problem-json Use Problem JSON (RFC 7807) to report errors in REST API. Fixes #27,bug,0.85
62,Annif,https://github.com/NatLibFi/Annif/issues/62,Load subjects operation,We need to support the load-subjects CLI command to be able to test the TF-IDF backend (#46). Part of #14,more careful unit testing of TF-IDF backend,Implement load command. Fixes #62,.gitignore | annif/backend/tfidf.py | annif/cli.py | annif/project.py | backends.cfg | projects.cfg | tests/test_cli.py,other-file | source-file | source-file | source-file | other-file | other-file | test-file,Load subjects operation We need to support the load-subjects CLI command to be able to test the TF-IDF backend (#46). Part of #14 more careful unit testing of TF-IDF backend Implement load command. Fixes #62,no-bug,0.9
617,Annif,https://github.com/NatLibFi/Annif/issues/617,Upgrade simplemma dependency and remove function cache,"Hi, I just noticed that you wrapped a custom class around [simplemma](https://github.com/adbar/simplemma/), notably to use a function cache. Interestingly, I had the same idea which indeed speeds up the process. The cache is included in the versions that you use (0.7.* upwards), so you could delete the following line without any impact on performance: https://github.com/NatLibFi/Annif/blob/aa50441e769a4c93866ca93ee07d3b9677c4d201/annif/analyzer/simplemma.py#L15 In addition, you could use the `lang` attribute (new in 0.7.0) directly with `simplemma.lemmatize()`. Best, Adrien","Update README.md - Fix link to ReadTheDocs (point to docs, not to project page) - Use https in link for annif.org - Mention Finto AI",upgrade to simplemma 0.8 and disable unnecessary cache. Fixes #617,annif/analyzer/simplemma.py | setup.py,source-file | source-file,"Upgrade simplemma dependency and remove function cache Hi, I just noticed that you wrapped a custom class around [simplemma](https://github.com/adbar/simplemma/), notably to use a function cache. Interestingly, I had the same idea which indeed speeds up the process. The cache is included in the versions that you use (0.7.* upwards), so you could delete the following line without any impact on performance: https://github.com/NatLibFi/Annif/blob/aa50441e769a4c93866ca93ee07d3b9677c4d201/annif/analyzer/simplemma.py#L15 In addition, you could use the `lang` attribute (new in 0.7.0) directly with `simplemma.lemmatize()`. Best, Adrien Update README.md - Fix link to ReadTheDocs (point to docs, not to project page) - Use https in link for annif.org - Mention Finto AI upgrade to simplemma 0.8 and disable unnecessary cache. Fixes #617",no-bug,0.9
1,Annif,https://github.com/NatLibFi/Annif/issues/1,OpenAPI (Swagger) specification,We need a specification of the REST API as an OpenAPI YAML file.,WEB-UI: Remove empty entry from list of projects.,Merge pull request #1 from NatLibFi/master Merge with natlibfi/annif,setup.py,source-file,OpenAPI (Swagger) specification We need a specification of the REST API as an OpenAPI YAML file. WEB-UI: Remove empty entry from list of projects. Merge pull request #1 from NatLibFi/master Merge with natlibfi/annif,no-bug,0.9
516,Annif,https://github.com/NatLibFi/Annif/issues/516,Improve performance of updating an existing vocabulary,"Hi, to update an existing vocabulary with more than 1.3 million of concepts takes hours, because the existings graph is loaded and each triple is checked. I think it would be an good improvement to add an `--overwrite` or `--force` parameter to the loadvoc command. After the existing graph is deleted the loadvoc command behaves as it would load a new vocabulary. What do you think? Kind regards Nico",test triggering drone build on tag event only (#523),Much faster updating of existing large vocabulary. Fixes #516 | Much faster updating of existing large vocabulary. Fixes #516,annif/corpus/subject.py | annif/corpus/subject.py,source-file | source-file,"Improve performance of updating an existing vocabulary Hi, to update an existing vocabulary with more than 1.3 million of concepts takes hours, because the existings graph is loaded and each triple is checked. I think it would be an good improvement to add an `--overwrite` or `--force` parameter to the loadvoc command. After the existing graph is deleted the loadvoc command behaves as it would load a new vocabulary. What do you think? Kind regards Nico test triggering drone build on tag event only (#523) Much faster updating of existing large vocabulary. Fixes #516 Much faster updating of existing large vocabulary. Fixes #516",no-bug,0.9
309,Annif,https://github.com/NatLibFi/Annif/issues/309,Training from .key files with only subject labels fails,"As pointed out in #303, it's impossible to train from a directory with `.txt` and `.key` files which contain only subject labels but no URIs. Example traceback with `tfidf` backend: ``` Traceback (most recent call last): File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/flask/cli.py"", line 569, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/flask/cli.py"", line 419, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/local/oisuomin/git/Annif/annif/cli.py"", line 154, in run_train proj.train(documents) File ""/home/local/oisuomin/git/Annif/annif/project.py"", line 197, in train self._create_vectorizer(corpus) File ""/home/local/oisuomin/git/Annif/annif/project.py"", line 186, in _create_vectorizer self._vectorizer.fit((subj.text for subj in subjectcorpus.subjects)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/sklearn/feature_extraction/text.py"", line 1631, in fit X = super().fit_transform(raw_documents) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/sklearn/feature_extraction/text.py"", line 1058, in fit_transform self.fixed_vocabulary_) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/sklearn/feature_extraction/text.py"", line 989, in _count_vocab raise ValueError(""empty vocabulary; perhaps the documents only"" ValueError: empty vocabulary; perhaps the documents only contain stop words ``` With `fasttext` backend: ``` Traceback (most recent call last): File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/flask/cli.py"", line 569, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/flask/cli.py"", line 419, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/local/oisuomin/git/Annif/annif/cli.py"", line 154, in run_train proj.train(documents) File ""/home/local/oisuomin/git/Annif/annif/project.py"", line 198, in train self.backend.train(corpus, project=self) File ""/home/local/oisuomin/git/Annif/annif/backend/fasttext.py"", line 108, in train self._create_model() File ""/home/local/oisuomin/git/Annif/annif/backend/fasttext.py"", line 103, in _create_model self._model = fastText.train_supervised(trainpath, **params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/fastText/FastText.py"", line 343, in train_supervised fasttext.train(ft.f, a) ValueError: Empty vocabulary. Try a smaller -minCount value. ``` The problem seems to be that subject labels are not being converted to URIs internally, although they should.",Merge pull request #296 from NatLibFi/use-VW-version-8.7 Use vw version 8.7,Add failing unit test for #309 | Look up URIs/labels as necessary when creating Documents. Make sure test for #309 passes,tests/test_corpus.py | annif/corpus/document.py | annif/corpus/types.py | tests/test_corpus.py,test-file | source-file | source-file | test-file,"Training from .key files with only subject labels fails As pointed out in #303, it's impossible to train from a directory with `.txt` and `.key` files which contain only subject labels but no URIs. Example traceback with `tfidf` backend: ``` Traceback (most recent call last): File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/flask/cli.py"", line 569, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/flask/cli.py"", line 419, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/local/oisuomin/git/Annif/annif/cli.py"", line 154, in run_train proj.train(documents) File ""/home/local/oisuomin/git/Annif/annif/project.py"", line 197, in train self._create_vectorizer(corpus) File ""/home/local/oisuomin/git/Annif/annif/project.py"", line 186, in _create_vectorizer self._vectorizer.fit((subj.text for subj in subjectcorpus.subjects)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/sklearn/feature_extraction/text.py"", line 1631, in fit X = super().fit_transform(raw_documents) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/sklearn/feature_extraction/text.py"", line 1058, in fit_transform self.fixed_vocabulary_) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/sklearn/feature_extraction/text.py"", line 989, in _count_vocab raise ValueError(""empty vocabulary; perhaps the documents only"" ValueError: empty vocabulary; perhaps the documents only contain stop words ``` With `fasttext` backend: ``` Traceback (most recent call last): File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/flask/cli.py"", line 569, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/flask/cli.py"", line 419, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/local/oisuomin/git/Annif/annif/cli.py"", line 154, in run_train proj.train(documents) File ""/home/local/oisuomin/git/Annif/annif/project.py"", line 198, in train self.backend.train(corpus, project=self) File ""/home/local/oisuomin/git/Annif/annif/backend/fasttext.py"", line 108, in train self._create_model() File ""/home/local/oisuomin/git/Annif/annif/backend/fasttext.py"", line 103, in _create_model self._model = fastText.train_supervised(trainpath, **params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-G8ShVyyO/lib/python3.5/site-packages/fastText/FastText.py"", line 343, in train_supervised fasttext.train(ft.f, a) ValueError: Empty vocabulary. Try a smaller -minCount value. ``` The problem seems to be that subject labels are not being converted to URIs internally, although they should. Merge pull request #296 from NatLibFi/use-VW-version-8.7 Use vw version 8.7 Add failing unit test for #309 Look up URIs/labels as necessary when creating Documents. Make sure test for #309 passes",no-bug,0.8
149,Annif,https://github.com/NatLibFi/Annif/issues/149,Load multiple corpora in a single operation,"The loaddocs command could accept multiple TSV files in the same operation, e.g. annif loaddocs tfidf-fi finna-fi.tsv fennica-fi.tsv makupalat-fi.tsv This would make it easy to test the effect of combining multiple corpora vs. using them alone.",Bump version: 0.28.0 → 0.29.0,Support loading multiple document corpora in a single operation. Fixes #149 | Merge pull request #151 from NatLibFi/issue149-load-multiple Support loading multiple document corpora in a single operation. Fixes #149,annif/cli.py | annif/corpus/__init__.py | annif/corpus/combine.py | tests/test_cli.py | annif/cli.py | annif/corpus/__init__.py | annif/corpus/combine.py | tests/test_cli.py,source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file,"Load multiple corpora in a single operation The loaddocs command could accept multiple TSV files in the same operation, e.g. annif loaddocs tfidf-fi finna-fi.tsv fennica-fi.tsv makupalat-fi.tsv This would make it easy to test the effect of combining multiple corpora vs. using them alone. Bump version: 0.28.0 → 0.29.0 Support loading multiple document corpora in a single operation. Fixes #149 Merge pull request #151 from NatLibFi/issue149-load-multiple Support loading multiple document corpora in a single operation. Fixes #149",no-bug,0.9
223,Annif,https://github.com/NatLibFi/Annif/issues/223,Sorting issue breaks test_docdir_as_doccorpus,Apparently something has changed in the Travis environment and now test_docdir_as_doccorpus fails. It seems to be related to the order of filenames returned by `glob.glob`.,Try to fix Travis build failures (#222),Try to fix docdir sorting issue when running tests under Travis. Fixes #223,annif/corpus/document.py,source-file,Sorting issue breaks test_docdir_as_doccorpus Apparently something has changed in the Travis environment and now test_docdir_as_doccorpus fails. It seems to be related to the order of filenames returned by `glob.glob`. Try to fix Travis build failures (#222) Try to fix docdir sorting issue when running tests under Travis. Fixes #223,no-bug,0.8
177,Annif,https://github.com/NatLibFi/Annif/issues/177,Replace load and loaddocs CLI commands with new train command,"The load and loaddocs commands have several problems: * the subject corpus format for `load` is not very good (#176) * there are two separate commands when we could have just one that takes either a file (tsv) or directory (txt+tsv instead of the current subject corpus format - see #145) * it's badly named, as e.g. for fastText it does training as well as loading The current `load` and `loaddocs` commands should be replaced with a new `train` command that takes either a file or a directory.",refactor: helper function to open a document corpus (either file or directory),"Make loaddocs accept either directories or TSV files, and eval and optimize accept multiple paths. Related to #177 | Rename loaddocs command to train. Fixes #177",annif/cli.py | annif/cli.py | tests/test_cli.py,source-file | source-file | test-file,"Replace load and loaddocs CLI commands with new train command The load and loaddocs commands have several problems: * the subject corpus format for `load` is not very good (#176) * there are two separate commands when we could have just one that takes either a file (tsv) or directory (txt+tsv instead of the current subject corpus format - see #145) * it's badly named, as e.g. for fastText it does training as well as loading The current `load` and `loaddocs` commands should be replaced with a new `train` command that takes either a file or a directory. refactor: helper function to open a document corpus (either file or directory) Make loaddocs accept either directories or TSV files, and eval and optimize accept multiple paths. Related to #177 Rename loaddocs command to train. Fixes #177",no-bug,0.9
59,Annif,https://github.com/NatLibFi/Annif/issues/59,Filter words / tokens,"Analyzers should support a method for filtering words. The basic rules should be: * words should have a minimum length (3 is OK as a starting value) * the word should have at least one letter character, based on Unicode character properties",Combine Snowball analyzers into one parametrized analyzer. Fixes #53,Filter and normalize words when tokenizing. Fixes #59,annif/analyzer/analyzer.py | annif/analyzer/snowball.py | tests/test_analyzer.py,source-file | source-file | test-file,"Filter words / tokens Analyzers should support a method for filtering words. The basic rules should be: * words should have a minimum length (3 is OK as a starting value) * the word should have at least one letter character, based on Unicode character properties Combine Snowball analyzers into one parametrized analyzer. Fixes #53 Filter and normalize words when tokenizing. Fixes #59",no-bug,0.8
225,Annif,https://github.com/NatLibFi/Annif/issues/225,Incremental / online learning based on user feedback,"Right now all models are built once and then remain static. But at least for `tfidf` and `pav` backends it would be possible to improve the model over time based on user feedback, i.e. documents that were analyzed, a human reviewed the result and rejected some subjects (false positives) and/or added new ones (false negatives). This issue is about providing the infrastructure for such functionality and the CLI commands and REST API methods. I will open separate issues for adding online learning support for each backend. The CLI command could be annif learn <projectid> <corpus> ~~(still thinking about what would be the best command name, maybe also `increment[al]` or `retrain`)~~ **learn** is fine, used by e.g. Vowpal Wabbit The REST API method could be (for a single command) POST /projects/<projectid>/learn with parameters corresponding to the CLI command. Ensemble style backends (currently `ensemble` and `pav`) should propagate the learn operation first to the source projects, reanalyze the document, and only then update their own model.",Merge pull request #256 from NatLibFi/issue230-vw-multi-input-from-projects vw-multi backend: use input from other projects,Initial support for online learning in vw_multi backend. Part of #225 and #230,annif/backend/backend.py | annif/backend/vw_multi.py | tests/test_backend_vw_multi.py,source-file | source-file | test-file,"Incremental / online learning based on user feedback Right now all models are built once and then remain static. But at least for `tfidf` and `pav` backends it would be possible to improve the model over time based on user feedback, i.e. documents that were analyzed, a human reviewed the result and rejected some subjects (false positives) and/or added new ones (false negatives). This issue is about providing the infrastructure for such functionality and the CLI commands and REST API methods. I will open separate issues for adding online learning support for each backend. The CLI command could be annif learn <projectid> <corpus> ~~(still thinking about what would be the best command name, maybe also `increment[al]` or `retrain`)~~ **learn** is fine, used by e.g. Vowpal Wabbit The REST API method could be (for a single command) POST /projects/<projectid>/learn with parameters corresponding to the CLI command. Ensemble style backends (currently `ensemble` and `pav`) should propagate the learn operation first to the source projects, reanalyze the document, and only then update their own model. Merge pull request #256 from NatLibFi/issue230-vw-multi-input-from-projects vw-multi backend: use input from other projects Initial support for online learning in vw_multi backend. Part of #225 and #230",no-bug,0.9
190,Annif,https://github.com/NatLibFi/Annif/issues/190,Support CORS requests,The REST API should be CORS-enabled.,"Add vocab settings to example configuration file, needed after #180",Enable CORS requests to REST API using flask-cors. Fixes #190 | Merge pull request #191 from NatLibFi/issue190-enable-cors Enable CORS requests to REST API using flask-cors. Fixes #190,Pipfile | annif/__init__.py | setup.py | tests/test_swagger.py | Pipfile | annif/__init__.py | setup.py | tests/test_swagger.py,other-file | source-file | source-file | test-file | other-file | source-file | source-file | test-file,"Support CORS requests The REST API should be CORS-enabled. Add vocab settings to example configuration file, needed after #180 Enable CORS requests to REST API using flask-cors. Fixes #190 Merge pull request #191 from NatLibFi/issue190-enable-cors Enable CORS requests to REST API using flask-cors. Fixes #190",no-bug,0.7
556,Annif,https://github.com/NatLibFi/Annif/issues/556,vocabulary in SKOS (Turtle serialization) should be loaded even in case of lacking language tags,"Hi! I've noticed some potentially inconsistent behaviour of the annif loadvoc command when loading voacabulary in ttl SKOS without language tags. We've currently switched in our project from simple tsv vocabulary format to SKOS. I assumed that since we do not provide any information about language in tsv file, we don't necessarily have to add appropriate language tags in SKOS either. But it turned out, that loading vocabulary in SKOS without language tags prevents annif from creating the subject index (though original ttl file is being copied and gzipped file is being dumped). It seems, that when annif converts tsv to SKOS, it adds language tags (they're based upon language configuration in projects.cfg), but when it loads vocabulary directly from SKOS format, it checks if language tag for a label is the same as language code in projects.cfg, and when it's not **or if there is no language tag at all** it skips the whole concept: ``` def get_concept_labels(self, concept, label_types, language): return [str(label) for label_type in label_types for label in self.graph.objects(concept, label_type) if label.language == language] ``` ``` @property def subjects(self): for concept in self.concepts: labels = self.get_concept_labels( concept, [SKOS.prefLabel, RDFS.label], self.language) notation = self.graph.value(concept, SKOS.notation, None, any=True) if not labels: continue label = labels[0] if notation is not None: notation = str(notation) yield Subject(uri=str(concept), label=label, notation=notation, text=None) ``` I think, that maybe it would be safer to assume, that when there is no explicit information about the language in SKOS file (there is a label without the language tag), its language corresponds with the language defined in projects.cfg and skip a concept (or label from the concept) only when the language tag truly exists and is not equal to the language from projects.cfg. If this change is not possible for some reasons, it would be nice to provide some information about this behaviour in annif wiki (it took me some time to find this ""bug""). Maciej Sagata, National Library of Poland",Merge pull request #594 from NatLibFi/upgrade-simplemma-0.7 Upgrade Simplemma to version 0.7,Include labels without language tag and concepts without labels in vocabulary. Fixes #556 | Include labels without language tag and concepts without labels in vocabulary. Fixes #556,annif/corpus/skos.py | tests/test_vocab_skos.py | annif/corpus/skos.py | tests/test_vocab_skos.py,source-file | test-file | source-file | test-file,"vocabulary in SKOS (Turtle serialization) should be loaded even in case of lacking language tags Hi! I've noticed some potentially inconsistent behaviour of the annif loadvoc command when loading voacabulary in ttl SKOS without language tags. We've currently switched in our project from simple tsv vocabulary format to SKOS. I assumed that since we do not provide any information about language in tsv file, we don't necessarily have to add appropriate language tags in SKOS either. But it turned out, that loading vocabulary in SKOS without language tags prevents annif from creating the subject index (though original ttl file is being copied and gzipped file is being dumped). It seems, that when annif converts tsv to SKOS, it adds language tags (they're based upon language configuration in projects.cfg), but when it loads vocabulary directly from SKOS format, it checks if language tag for a label is the same as language code in projects.cfg, and when it's not **or if there is no language tag at all** it skips the whole concept: ``` def get_concept_labels(self, concept, label_types, language): return [str(label) for label_type in label_types for label in self.graph.objects(concept, label_type) if label.language == language] ``` ``` @property def subjects(self): for concept in self.concepts: labels = self.get_concept_labels( concept, [SKOS.prefLabel, RDFS.label], self.language) notation = self.graph.value(concept, SKOS.notation, None, any=True) if not labels: continue label = labels[0] if notation is not None: notation = str(notation) yield Subject(uri=str(concept), label=label, notation=notation, text=None) ``` I think, that maybe it would be safer to assume, that when there is no explicit information about the language in SKOS file (there is a label without the language tag), its language corresponds with the language defined in projects.cfg and skip a concept (or label from the concept) only when the language tag truly exists and is not equal to the language from projects.cfg. If this change is not possible for some reasons, it would be nice to provide some information about this behaviour in annif wiki (it took me some time to find this ""bug""). Maciej Sagata, National Library of Poland Merge pull request #594 from NatLibFi/upgrade-simplemma-0.7 Upgrade Simplemma to version 0.7 Include labels without language tag and concepts without labels in vocabulary. Fixes #556 Include labels without language tag and concepts without labels in vocabulary. Fixes #556",bug,0.85
342,Annif,https://github.com/NatLibFi/Annif/issues/342,--cached option to reuse preprocessed training data,"A large proportion of training time is typically spent on preprocessing the training data into a format suitable for the backend algorithm. This is particularly evident for trainable ensemble backends (`pav`, `vw_ensemble`, `nn_ensemble`) which have to pass all the training documents to source projects. We could support a `--cached` option that reuses the already preprocessed training data from the previous train run. This would make it a lot faster to experiment with different hyperparameters. For example: annif train nn-ensemble-fi my-corpus/train/ # initial training run annif eval nn-ensemble-fi my-corpus/test/ # evaluate on test documents # not happy with the result, let's adjust the hyperparameters $EDITOR projects.cfg annif train --cached nn-ensemble-fi # retrain using previous train data (note: no corpus given) annif eval nn-ensemble-fi my-corpus/test/ # reevaluate Implementing this requires changes to some backends: * fasttext, vw_multi and vw_ensemble already create training files which are stored in the project data directory; the option would simply skip creating a new one before retraining * pav and nn_ensemble only collect the training data into NumPy arrays held in memory; they would need to store the arrays in the data directory (e.g. as an LMDB database) so they can be reused later * tfidf also collects training data only in memory, but since it has no parameters to tune, there is probably no need for a `--cached` option (it could just give an error instead)",curl is needed for Docker healthcheck,"Implement --cached option for train command in fasttext, omikuji and vw_multi backends (#342)",annif/backend/fasttext.py | annif/backend/nn_ensemble.py | annif/backend/omikuji.py | annif/backend/pav.py | annif/backend/tfidf.py | annif/backend/vw_multi.py | annif/cli.py | annif/project.py | tests/test_backend_fasttext.py | tests/test_backend_omikuji.py | tests/test_backend_vw_multi.py | tests/test_cli.py,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file,"--cached option to reuse preprocessed training data A large proportion of training time is typically spent on preprocessing the training data into a format suitable for the backend algorithm. This is particularly evident for trainable ensemble backends (`pav`, `vw_ensemble`, `nn_ensemble`) which have to pass all the training documents to source projects. We could support a `--cached` option that reuses the already preprocessed training data from the previous train run. This would make it a lot faster to experiment with different hyperparameters. For example: annif train nn-ensemble-fi my-corpus/train/ # initial training run annif eval nn-ensemble-fi my-corpus/test/ # evaluate on test documents # not happy with the result, let's adjust the hyperparameters $EDITOR projects.cfg annif train --cached nn-ensemble-fi # retrain using previous train data (note: no corpus given) annif eval nn-ensemble-fi my-corpus/test/ # reevaluate Implementing this requires changes to some backends: * fasttext, vw_multi and vw_ensemble already create training files which are stored in the project data directory; the option would simply skip creating a new one before retraining * pav and nn_ensemble only collect the training data into NumPy arrays held in memory; they would need to store the arrays in the data directory (e.g. as an LMDB database) so they can be reused later * tfidf also collects training data only in memory, but since it has no parameters to tune, there is probably no need for a `--cached` option (it could just give an error instead) curl is needed for Docker healthcheck Implement --cached option for train command in fasttext, omikuji and vw_multi backends (#342)",no-bug,0.95
401,Annif,https://github.com/NatLibFi/Annif/issues/401,Maui Server errors are not shown by Annif,"I have an rdf vocabulary and loaded it for the maui backend. But when I try to train it with txt en tsv file, it gives this error. > (annif046) enrico@ubupiet:~/Programs/annif046$ bin/annif train -v DEBUG maui-nl data/annif-corpora/fulltext/train_maui debug: creating app with configuration annif.default_config.Config debug: loading subjects from data/vocabs/maui-nl/subjects Backend maui: Initializing Maui Server tagger 'maui-nl' debug: Backend maui: Trying to delete tagger maui-nl returned status code 204 debug: Backend maui: Trying to create tagger maui-nl returned status code 200 Backend maui: Uploading vocabulary Error: Operation failed: 400 Client Error: for url: http://localhost:8080/mauiserver/maui-nl/vocab There is a subjects file generated but it does recognize a vocabulary. http://localhost:8080/mauiserver/maui-nl {""title"":""maui-nl"",""id"":""maui-nl"",""is_trained"":false,""has_vocabulary"":false,""links"":{""home"":""/mauiserver/"",""tagger"":""/mauiserver/maui-nl"",""config"":""/mauiserver/maui-nl/config"",""vocab"":""/mauiserver/maui-nl/vocab"",""train"":""/mauiserver/maui-nl/train"",""suggest"":""/mauiserver/maui-nl/suggest"",""xvalidate"":""/mauiserver/maui-nl/xvalidate""}} This is my project setup. > [maui-nl] > name=Maui Dutch > language=nl > backend=maui > endpoint=http://localhost:8080/mauiserver/ > tagger=maui-nl > vocab=maui-nl > limit=5",Merge pull request #397 from NatLibFi/issue390-show-notations-in-web-ui-results-list Show notations in web UI results list,Show Maui Server errors when uploading vocabulary fails. Fixes #401,annif/backend/maui.py | tests/test_backend_maui.py,source-file | test-file,"Maui Server errors are not shown by Annif I have an rdf vocabulary and loaded it for the maui backend. But when I try to train it with txt en tsv file, it gives this error. > (annif046) enrico@ubupiet:~/Programs/annif046$ bin/annif train -v DEBUG maui-nl data/annif-corpora/fulltext/train_maui debug: creating app with configuration annif.default_config.Config debug: loading subjects from data/vocabs/maui-nl/subjects Backend maui: Initializing Maui Server tagger 'maui-nl' debug: Backend maui: Trying to delete tagger maui-nl returned status code 204 debug: Backend maui: Trying to create tagger maui-nl returned status code 200 Backend maui: Uploading vocabulary Error: Operation failed: 400 Client Error: for url: http://localhost:8080/mauiserver/maui-nl/vocab There is a subjects file generated but it does recognize a vocabulary. http://localhost:8080/mauiserver/maui-nl {""title"":""maui-nl"",""id"":""maui-nl"",""is_trained"":false,""has_vocabulary"":false,""links"":{""home"":""/mauiserver/"",""tagger"":""/mauiserver/maui-nl"",""config"":""/mauiserver/maui-nl/config"",""vocab"":""/mauiserver/maui-nl/vocab"",""train"":""/mauiserver/maui-nl/train"",""suggest"":""/mauiserver/maui-nl/suggest"",""xvalidate"":""/mauiserver/maui-nl/xvalidate""}} This is my project setup. > [maui-nl] > name=Maui Dutch > language=nl > backend=maui > endpoint=http://localhost:8080/mauiserver/ > tagger=maui-nl > vocab=maui-nl > limit=5 Merge pull request #397 from NatLibFi/issue390-show-notations-in-web-ui-results-list Show notations in web UI results list Show Maui Server errors when uploading vocabulary fails. Fixes #401",no-bug,0.7
533,Annif,https://github.com/NatLibFi/Annif/issues/533,"Flask, Connexion, Click Dependency Mismatches","I observed a dependency mismatch in `annif==0.54.*` In fact I got this also for older versions. This leads to an error exit code when using `pipenv`. I think you don't support `pipenv` at the moment. I still wanted to report this as other projects may want to use annif as dependency when using `pipenv`. Additionally the dependency conflict is still there even if it is not reported via exit code when using `pip`. Steps to reproduce: ``` mkdir /tmp/pipenv_test cd /tmp/pipenv_test pipenv --python 3.8 pipenv install ""annif==0.54.*"" ``` This threw an error with respect to the version of `Werkzeug`: `Could not find a version that matches werkzeug<2.0,>=1.0,>=2.0` Turns out that the most recent published version of `Connexion` requires `Flask<2.0` But Pipenv installed `Flask 2.0.2` I tried to install `Connexion` first. This would install `flask 1.1.4` which has a dependency `click<8.0,>=5.1`. This conflicts with the annif dependency specification `'click==8.0.*',` Since the pinning is probably on purpose, I hand this over to you. **Hint**: The current master of Connexion sets `'flask>=1.0.4,<3'` So this will probably be resolved in the future. When installing using `pip` without `pipenv`, as done for the Docker container, this will print an error and install `click==8.0.3`. The exit code will indicate a success. As a workaround with `pipenv` you can do the following: ``` pipenv shell pip install ""annif==0.54.*"" ``` But is is not possible to add annif to a Pipfile.",Merge pull request #528 from NatLibFi/fix-dateutil-dependency Declare dateutil dependency,Adjust flask and click versions to avoid dependency mismatches. Fixes #533,setup.py,source-file,"Flask, Connexion, Click Dependency Mismatches I observed a dependency mismatch in `annif==0.54.*` In fact I got this also for older versions. This leads to an error exit code when using `pipenv`. I think you don't support `pipenv` at the moment. I still wanted to report this as other projects may want to use annif as dependency when using `pipenv`. Additionally the dependency conflict is still there even if it is not reported via exit code when using `pip`. Steps to reproduce: ``` mkdir /tmp/pipenv_test cd /tmp/pipenv_test pipenv --python 3.8 pipenv install ""annif==0.54.*"" ``` This threw an error with respect to the version of `Werkzeug`: `Could not find a version that matches werkzeug<2.0,>=1.0,>=2.0` Turns out that the most recent published version of `Connexion` requires `Flask<2.0` But Pipenv installed `Flask 2.0.2` I tried to install `Connexion` first. This would install `flask 1.1.4` which has a dependency `click<8.0,>=5.1`. This conflicts with the annif dependency specification `'click==8.0.*',` Since the pinning is probably on purpose, I hand this over to you. **Hint**: The current master of Connexion sets `'flask>=1.0.4,<3'` So this will probably be resolved in the future. When installing using `pip` without `pipenv`, as done for the Docker container, this will print an error and install `click==8.0.3`. The exit code will indicate a success. As a workaround with `pipenv` you can do the following: ``` pipenv shell pip install ""annif==0.54.*"" ``` But is is not possible to add annif to a Pipfile. Merge pull request #528 from NatLibFi/fix-dateutil-dependency Declare dateutil dependency Adjust flask and click versions to avoid dependency mismatches. Fixes #533",no-bug,0.95
362,Annif,https://github.com/NatLibFi/Annif/issues/362,Remove vw_ensemble backend,"I'd like to remove the `vw_ensemble` backend. The neural network ensemble (`nn_ensemble`) has essentially the same features (e.g. incremental learning) and works much better. It doesn't make sense to maintain two backends for the same purpose and it would take a significant amount of work to get good quality results from `vw_ensemble`, if it's even possible.",Merge pull request #361 from NatLibFi/issue360-launching-gunicorn Pin gunicorn version to exclude the one that doesnt support used star…,Remove vw_ensemble backend. Fixes #362,annif/backend/__init__.py | annif/backend/vw_ensemble.py | tests/test_backend_vw_ensemble.py,source-file | source-file | test-file,"Remove vw_ensemble backend I'd like to remove the `vw_ensemble` backend. The neural network ensemble (`nn_ensemble`) has essentially the same features (e.g. incremental learning) and works much better. It doesn't make sense to maintain two backends for the same purpose and it would take a significant amount of work to get good quality results from `vw_ensemble`, if it's even possible. Merge pull request #361 from NatLibFi/issue360-launching-gunicorn Pin gunicorn version to exclude the one that doesnt support used star… Remove vw_ensemble backend. Fixes #362",no-bug,0.9
108,Annif,https://github.com/NatLibFi/Annif/issues/108,Basic analyzer (no stemming),"We should have an analyzer that only does the minimum, e.g. fold to lower case but no stemming. Similar to SimpleAnalyzer in Lucene.",Add Maui projects and backends,Add Simple analyzer. Fixes #108 | Merge pull request #109 from NatLibFi/issue108-simple-analyzer Add Simple analyzer. Fixes #108,annif/analyzer/__init__.py | annif/analyzer/simple.py | tests/test_analyzer.py | annif/analyzer/__init__.py | annif/analyzer/simple.py | tests/test_analyzer.py,source-file | source-file | test-file | source-file | source-file | test-file,"Basic analyzer (no stemming) We should have an analyzer that only does the minimum, e.g. fold to lower case but no stemming. Similar to SimpleAnalyzer in Lucene. Add Maui projects and backends Add Simple analyzer. Fixes #108 Merge pull request #109 from NatLibFi/issue108-simple-analyzer Add Simple analyzer. Fixes #108",no-bug,0.9
81,Annif,https://github.com/NatLibFi/Annif/issues/81,Use sklearn feature extractors when possible,"The gensim dictionary, vectorized corpus and TF-IDF building is pretty slow and specific to Gensim. Instead we could use sklearn functionality, which should be faster and would enable also sklearn based backends.",Merge pull request #83 from NatLibFi/project-feature-extraction Move feature extraction from TF-IDF backend to project. Fixes #80,Use sklearn TfidfVectorizer instead of gensim dictionary and tf-idf model. Fixes #81 | Merge pull request #84 from NatLibFi/sklearn-vectorizer Use sklearn TfidfVectorizer instead of gensim dictionary and tf-idf model. Fixes #81,annif/backend/tfidf.py | annif/corpus/__init__.py | annif/corpus/subject.py | annif/project.py | annif/util.py | requirements.txt | tests/test_backend_tfidf.py | tests/test_cli.py | annif/backend/tfidf.py | annif/corpus/__init__.py | annif/corpus/subject.py | annif/project.py | annif/util.py | requirements.txt | tests/test_backend_tfidf.py | tests/test_cli.py,source-file | source-file | source-file | source-file | source-file | other-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | other-file | test-file | test-file,"Use sklearn feature extractors when possible The gensim dictionary, vectorized corpus and TF-IDF building is pretty slow and specific to Gensim. Instead we could use sklearn functionality, which should be faster and would enable also sklearn based backends. Merge pull request #83 from NatLibFi/project-feature-extraction Move feature extraction from TF-IDF backend to project. Fixes #80 Use sklearn TfidfVectorizer instead of gensim dictionary and tf-idf model. Fixes #81 Merge pull request #84 from NatLibFi/sklearn-vectorizer Use sklearn TfidfVectorizer instead of gensim dictionary and tf-idf model. Fixes #81",no-bug,0.9
93,Annif,https://github.com/NatLibFi/Annif/issues/93,Scores above 1.0 when combining backends,"This shouldn't happen: ``` $ echo ""kissa"" | annif analyze fasttext-tfidf-fi 1.0553042152709962 <http://www.yso.fi/onto/yso/p19378> kissa 0.6740380641807556 <http://www.yso.fi/onto/yso/p864> kissaeläimet 0.23148740828037262 <http://www.yso.fi/onto/yso/p12160> koreankielinen kirjallisuus 0.23045319318771362 <http://www.yso.fi/onto/yso/p17532> jaguaari 0.22833362221717834 <http://www.yso.fi/onto/yso/p21153> kissankello 0.21811979768543244 <http://www.yso.fi/onto/yso/p15329> eläinrunot 0.2107375519641876 <http://www.yso.fi/onto/yso/p675> lemmikkieläimet 0.20556555688381195 <http://www.yso.fi/onto/yso/p16549> vatsakalvontulehdus 0.20084334909915924 <http://www.yso.fi/onto/yso/p24992> kulkukissat 0.1995008951379776 <http://www.yso.fi/onto/yso/p8324> uskonnolliset ohjelmat ```",Merge pull request #95 from NatLibFi/analyzedir-command Analyzedir command,Fix invalid scores when merging results from multiple backends. Fixes #93 | Divide hit weights by sum of backend weights. Fixes #93 | Merge pull request #99 from NatLibFi/issue93-merge-hits-take2 Divide hit weights by sum of backend weights. Fixes #93,annif/project.py | tests/projects.cfg | tests/test_project.py | annif/project.py | tests/projects.cfg | tests/test_cli.py | tests/test_project.py | annif/project.py | tests/projects.cfg | tests/test_cli.py | tests/test_project.py,source-file | test-file | test-file | source-file | test-file | test-file | test-file | source-file | test-file | test-file | test-file,"Scores above 1.0 when combining backends This shouldn't happen: ``` $ echo ""kissa"" | annif analyze fasttext-tfidf-fi 1.0553042152709962 <http://www.yso.fi/onto/yso/p19378> kissa 0.6740380641807556 <http://www.yso.fi/onto/yso/p864> kissaeläimet 0.23148740828037262 <http://www.yso.fi/onto/yso/p12160> koreankielinen kirjallisuus 0.23045319318771362 <http://www.yso.fi/onto/yso/p17532> jaguaari 0.22833362221717834 <http://www.yso.fi/onto/yso/p21153> kissankello 0.21811979768543244 <http://www.yso.fi/onto/yso/p15329> eläinrunot 0.2107375519641876 <http://www.yso.fi/onto/yso/p675> lemmikkieläimet 0.20556555688381195 <http://www.yso.fi/onto/yso/p16549> vatsakalvontulehdus 0.20084334909915924 <http://www.yso.fi/onto/yso/p24992> kulkukissat 0.1995008951379776 <http://www.yso.fi/onto/yso/p8324> uskonnolliset ohjelmat ``` Merge pull request #95 from NatLibFi/analyzedir-command Analyzedir command Fix invalid scores when merging results from multiple backends. Fixes #93 Divide hit weights by sum of backend weights. Fixes #93 Merge pull request #99 from NatLibFi/issue93-merge-hits-take2 Divide hit weights by sum of backend weights. Fixes #93",no-bug,0.8
429,Annif,https://github.com/NatLibFi/Annif/issues/429,Parallelize suggest operations during nn_ensemble training,"Both the `eval` and `hyperopt` commands can now perform `suggest` operations in parallel on multiple CPUs. When training the nn_ensemble, running the documents through the source projects is the main bottleneck. We could speed it up by implementing parallel suggest operations there as well. There should probably be a new `jobs` parameter for the `train` CLI command specifying the number of parallel jobs, just like for `eval` and `hyperopt`.",Merge pull request #567 from NatLibFi/issue526-loadvoc-force-param Add --force option to loadvoc CLI command,Perform suggest operations in parallel using multiprocessing in nn_ensemble. Fixes #429,annif/backend/nn_ensemble.py,source-file,"Parallelize suggest operations during nn_ensemble training Both the `eval` and `hyperopt` commands can now perform `suggest` operations in parallel on multiple CPUs. When training the nn_ensemble, running the documents through the source projects is the main bottleneck. We could speed it up by implementing parallel suggest operations there as well. There should probably be a new `jobs` parameter for the `train` CLI command specifying the number of parallel jobs, just like for `eval` and `hyperopt`. Merge pull request #567 from NatLibFi/issue526-loadvoc-force-param Add --force option to loadvoc CLI command Perform suggest operations in parallel using multiprocessing in nn_ensemble. Fixes #429",no-bug,0.9
470,Annif,https://github.com/NatLibFi/Annif/issues/470,NN ensemble may return scores above 1.0,"The NN ensemble doesn't always return scores in the range 0.0-1.0. For example, the `yso-sv` model currently available in Finto AI returns this for the input text `historia`: ```js { ""results"": [ { ""label"": ""historia"", ""notation"": null, ""score"": 1.3140300512313843, ""uri"": ""http://www.yso.fi/onto/yso/p1780"" }, [...] } ``` This should be avoided, for example by capping the scores to 1.0.",Bump version: 0.51.0 → 0.52.0-dev,Make sure NN ensemble scores are in the range 0.0-1.0. Fixes #470 | Make sure suggestion scores are in the range 0.0-1.0. Fixes #470,annif/backend/nn_ensemble.py | annif/suggestion.py | tests/test_suggestion.py,source-file | source-file | test-file,"NN ensemble may return scores above 1.0 The NN ensemble doesn't always return scores in the range 0.0-1.0. For example, the `yso-sv` model currently available in Finto AI returns this for the input text `historia`: ```js { ""results"": [ { ""label"": ""historia"", ""notation"": null, ""score"": 1.3140300512313843, ""uri"": ""http://www.yso.fi/onto/yso/p1780"" }, [...] } ``` This should be avoided, for example by capping the scores to 1.0. Bump version: 0.51.0 → 0.52.0-dev Make sure NN ensemble scores are in the range 0.0-1.0. Fixes #470 Make sure suggestion scores are in the range 0.0-1.0. Fixes #470",bug,0.9
269,Annif,https://github.com/NatLibFi/Annif/issues/269,"Maui Server backend, including training support","The [Maui Server API](https://github.com/TopQuadrant/MauiServer/blob/master/API.md) provides all the important Maui functionality over REST. Annif should have a backend that works with this - either by enhancing the `http` backend or by creating a new `maui` backend. The latter is probably easier, though even the `http` backend could be quite easily made to support at least the basic analyze/suggest case just by making the response handling more robust so it will accept Maui Server responses as well. All the configuration for the Maui Server tagger should go in the Annif `projects.cfg` configuration. There could be a new Annif command `init` (#251) that creates the tagger on the Maui server end, based on the configuration. Possibly it would upload the vocabulary to Maui as well, though then `loadvoc` needs to be executed first. The other (probably better) option would be to add a hook for notifying backends about loading the vocabulary, which would trigger the upload.",Store vocabulary as SKOS when loading it with loadvoc command,Initial implementation of Maui Server backend (#269),annif/backend/__init__.py | annif/backend/maui.py | annif/exception.py | annif/vocab.py,source-file | source-file | source-file | source-file,"Maui Server backend, including training support The [Maui Server API](https://github.com/TopQuadrant/MauiServer/blob/master/API.md) provides all the important Maui functionality over REST. Annif should have a backend that works with this - either by enhancing the `http` backend or by creating a new `maui` backend. The latter is probably easier, though even the `http` backend could be quite easily made to support at least the basic analyze/suggest case just by making the response handling more robust so it will accept Maui Server responses as well. All the configuration for the Maui Server tagger should go in the Annif `projects.cfg` configuration. There could be a new Annif command `init` (#251) that creates the tagger on the Maui server end, based on the configuration. Possibly it would upload the vocabulary to Maui as well, though then `loadvoc` needs to be executed first. The other (probably better) option would be to add a hook for notifying backends about loading the vocabulary, which would trigger the upload. Store vocabulary as SKOS when loading it with loadvoc command Initial implementation of Maui Server backend (#269)",no-bug,0.9
181,Annif,https://github.com/NatLibFi/Annif/issues/181,Support gzipped document corpora TSV files,"Some of the document corpora are quite large when expressed as document-oriented TSV files (e.g. yso-finna-fi.tsv is 171MB), and thus difficult to store in GitHub which has a 100MB hard limit on file sizes. Annif should accept gzip-compressed document files as well.",fix: v0.31.0 version never got saved into setup.cfg and setup.py,Support document corpora as gzipped TSV files. Fixes #181 | Merge pull request #182 from NatLibFi/issue181-gzipped-docfile Support document corpora as gzipped TSV files. Fixes #181,annif/corpus/document.py | tests/test_corpus.py | annif/corpus/document.py | tests/test_corpus.py,source-file | test-file | source-file | test-file,"Support gzipped document corpora TSV files Some of the document corpora are quite large when expressed as document-oriented TSV files (e.g. yso-finna-fi.tsv is 171MB), and thus difficult to store in GitHub which has a 100MB hard limit on file sizes. Annif should accept gzip-compressed document files as well. fix: v0.31.0 version never got saved into setup.cfg and setup.py Support document corpora as gzipped TSV files. Fixes #181 Merge pull request #182 from NatLibFi/issue181-gzipped-docfile Support document corpora as gzipped TSV files. Fixes #181",no-bug,0.9
545,Annif,https://github.com/NatLibFi/Annif/issues/545,Select metrics for eval command using an option,"Currently the `annif eval` command produces more than 20 different metrics. Some of these require non-trivial calculation and often a smaller set would be enough (e.g. F1@5 and NDCG). There should be an option for choosing the metrics to calculate. We could use the same command line option (`-m`, `--metric`) that is already used for the `annif hyperopt` command to select the metric to target. Something like: annif eval my-project -m ""F1@5,NDCG"" /path/to/my-corpus As an alternative it could be possible to repeat the option as well: annif eval my-project -m ""F1@5"" -m ""NDCG"" /path/to/my-corpus",Merge pull request #557 from NatLibFi/issue546-eval-metrics-file Output eval metrics as a JSON file compatible with DVC,Add --metric/-m option to eval command to select metric(s). Fixes #545,annif/cli.py | annif/eval.py | tests/test_cli.py,source-file | source-file | test-file,"Select metrics for eval command using an option Currently the `annif eval` command produces more than 20 different metrics. Some of these require non-trivial calculation and often a smaller set would be enough (e.g. F1@5 and NDCG). There should be an option for choosing the metrics to calculate. We could use the same command line option (`-m`, `--metric`) that is already used for the `annif hyperopt` command to select the metric to target. Something like: annif eval my-project -m ""F1@5,NDCG"" /path/to/my-corpus As an alternative it could be possible to repeat the option as well: annif eval my-project -m ""F1@5"" -m ""NDCG"" /path/to/my-corpus Merge pull request #557 from NatLibFi/issue546-eval-metrics-file Output eval metrics as a JSON file compatible with DVC Add --metric/-m option to eval command to select metric(s). Fixes #545",no-bug,0.9
211,Annif,https://github.com/NatLibFi/Annif/issues/211,Make it possible to set the path to projects.cfg using an environment variable,"As noted in #195, it should be possible to set the path to `projects.cfg` using an environment variable, e.g. export ANNIF_PROJECTS=/etc/annif/projects.cfg annif analyze tfidf-fi <doc.txt",Bump version: 0.36.0 → 0.36.1,Make it possible to set ANNIF_DATADIR and ANNIF_PROJECTS using environment variables. Fixes #211,annif/default_config.py,source-file,"Make it possible to set the path to projects.cfg using an environment variable As noted in #195, it should be possible to set the path to `projects.cfg` using an environment variable, e.g. export ANNIF_PROJECTS=/etc/annif/projects.cfg annif analyze tfidf-fi <doc.txt Bump version: 0.36.0 → 0.36.1 Make it possible to set ANNIF_DATADIR and ANNIF_PROJECTS using environment variables. Fixes #211",no-bug,0.9
74,Annif,https://github.com/NatLibFi/Annif/issues/74,fastText backend,"Using the fasttext package from PyPI. Gensim also has a fastText module but it is focused on the skipgram and cbow models, not supervised classification.",Merge pull request #91 from NatLibFi/eliminate-chunking Eliminate useless chunking from TF-IDF backend. Fixes #85,initial version of fastText backend (#74),.travis.yml | README.md | annif/backend/__init__.py | annif/backend/backend.py | annif/backend/fasttext.py | annif/backend/tfidf.py | annif/project.py | backends.cfg | projects.cfg | requirements.txt | tests/test_backend_fasttext.py,config-file | documentation-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | test-file,"fastText backend Using the fasttext package from PyPI. Gensim also has a fastText module but it is focused on the skipgram and cbow models, not supervised classification. Merge pull request #91 from NatLibFi/eliminate-chunking Eliminate useless chunking from TF-IDF backend. Fixes #85 initial version of fastText backend (#74)",no-bug,0.9
150,Annif,https://github.com/NatLibFi/Annif/issues/150,Use click.File or click.Path type arguments for CLI,"The click docs [recommend](http://click.pocoo.org/5/arguments/) that for file arguments, either click.File or click.Path types are used instead of plain strings. This helps portability and brings some additional checks with nicer error messages.",Merge pull request #151 from NatLibFi/issue149-load-multiple Support loading multiple document corpora in a single operation. Fixes #149,use click.Path type arguments in CLI. Fixes #150 | Merge pull request #152 from NatLibFi/issue150-use-click-file use click.Path type arguments in CLI. Fixes #150,annif/cli.py | annif/cli.py,source-file | source-file,"Use click.File or click.Path type arguments for CLI The click docs [recommend](http://click.pocoo.org/5/arguments/) that for file arguments, either click.File or click.Path types are used instead of plain strings. This helps portability and brings some additional checks with nicer error messages. Merge pull request #151 from NatLibFi/issue149-load-multiple Support loading multiple document corpora in a single operation. Fixes #149 use click.Path type arguments in CLI. Fixes #150 Merge pull request #152 from NatLibFi/issue150-use-click-file use click.Path type arguments in CLI. Fixes #150",no-bug,0.9
145,Annif,https://github.com/NatLibFi/Annif/issues/145,make DocumentDirectory into a DocumentCorpus,"After #136 it would be possible to use a DocumentDirectory (directory with txt + tsv files) as a training corpus. It would need to implement the DocumentCorpus interface (ABC). This in itself is very simple (preliminary code already exists) but actually using it from annif.cli requires more work on the interfaces, in particular for the analyzedir command which needs to know file names of the documents so it can write the analysis results into .annif files.",Merge pull request #143 from NatLibFi/issue136-subject-to-document-corpus-mixin Use a mixin for converting a SubjectCorpus into a DocumentCorpus. Par…,Implement DocumentCorpus interface in DocumentDirectory. Part of #145 | Implement DocumentCorpus interface in DocumentDirectory. Part of #145 | Add unit tests and fixup code for converting DocumentCorpus to DocumentDirectory. #145,annif/corpus/document.py | annif/corpus/document.py | annif/corpus/document.py | tests/test_corpus.py,source-file | source-file | source-file | test-file,"make DocumentDirectory into a DocumentCorpus After #136 it would be possible to use a DocumentDirectory (directory with txt + tsv files) as a training corpus. It would need to implement the DocumentCorpus interface (ABC). This in itself is very simple (preliminary code already exists) but actually using it from annif.cli requires more work on the interfaces, in particular for the analyzedir command which needs to know file names of the documents so it can write the analysis results into .annif files. Merge pull request #143 from NatLibFi/issue136-subject-to-document-corpus-mixin Use a mixin for converting a SubjectCorpus into a DocumentCorpus. Par… Implement DocumentCorpus interface in DocumentDirectory. Part of #145 Implement DocumentCorpus interface in DocumentDirectory. Part of #145 Add unit tests and fixup code for converting DocumentCorpus to DocumentDirectory. #145",no-bug,0.9
56,Annif,https://github.com/NatLibFi/Annif/issues/56,Toy subject and document corpus,"Based on YSO archaeology group, Finna metadata and selected questions from the Ask a librarian corpus",fix: threshold should be inclusive,Add toy archaeology corpus. Fixes #56,tests/corpora/archaeology/README.md | tests/corpora/archaeology/fulltext/385445.key | tests/corpora/archaeology/fulltext/385445.tsv | tests/corpora/archaeology/fulltext/385445.txt | tests/corpora/archaeology/fulltext/388607.key | tests/corpora/archaeology/fulltext/388607.tsv | tests/corpora/archaeology/fulltext/388607.txt | tests/corpora/archaeology/fulltext/389200.key | tests/corpora/archaeology/fulltext/389200.tsv | tests/corpora/archaeology/fulltext/389200.txt | tests/corpora/archaeology/fulltext/389239.key | tests/corpora/archaeology/fulltext/389239.tsv | tests/corpora/archaeology/fulltext/389239.txt | tests/corpora/archaeology/fulltext/390199.key | tests/corpora/archaeology/fulltext/390199.tsv | tests/corpora/archaeology/fulltext/390199.txt | tests/corpora/archaeology/fulltext/390676.key | tests/corpora/archaeology/fulltext/390676.tsv | tests/corpora/archaeology/fulltext/390676.txt | tests/corpora/archaeology/fulltext/392470.key | tests/corpora/archaeology/fulltext/392470.tsv | tests/corpora/archaeology/fulltext/392470.txt | tests/corpora/archaeology/fulltext/411330.key | tests/corpora/archaeology/fulltext/411330.tsv | tests/corpora/archaeology/fulltext/411330.txt | tests/corpora/archaeology/fulltext/414526.key | tests/corpora/archaeology/fulltext/414526.tsv | tests/corpora/archaeology/fulltext/414526.txt | tests/corpora/archaeology/fulltext/416446.key | tests/corpora/archaeology/fulltext/416446.tsv | tests/corpora/archaeology/fulltext/416446.txt | tests/corpora/archaeology/fulltext/416646.key | tests/corpora/archaeology/fulltext/416646.tsv | tests/corpora/archaeology/fulltext/416646.txt | tests/corpora/archaeology/fulltext/416810.key | tests/corpora/archaeology/fulltext/416810.tsv | tests/corpora/archaeology/fulltext/416810.txt | tests/corpora/archaeology/fulltext/419534.key | tests/corpora/archaeology/fulltext/419534.tsv | tests/corpora/archaeology/fulltext/419534.txt | tests/corpora/archaeology/fulltext/422913.key | tests/corpora/archaeology/fulltext/422913.tsv | tests/corpora/archaeology/fulltext/422913.txt | tests/corpora/archaeology/fulltext/423799.key | tests/corpora/archaeology/fulltext/423799.tsv | tests/corpora/archaeology/fulltext/423799.txt | tests/corpora/archaeology/fulltext/424092.key | tests/corpora/archaeology/fulltext/424092.tsv | tests/corpora/archaeology/fulltext/424092.txt | tests/corpora/archaeology/fulltext/424540.key | tests/corpora/archaeology/fulltext/424540.tsv | tests/corpora/archaeology/fulltext/424540.txt | tests/corpora/archaeology/fulltext/426772.key | tests/corpora/archaeology/fulltext/426772.tsv | tests/corpora/archaeology/fulltext/426772.txt | tests/corpora/archaeology/fulltext/428011.key | tests/corpora/archaeology/fulltext/428011.tsv | tests/corpora/archaeology/fulltext/428011.txt | tests/corpora/archaeology/fulltext/428487.key | tests/corpora/archaeology/fulltext/428487.tsv | tests/corpora/archaeology/fulltext/428487.txt | tests/corpora/archaeology/fulltext/431914.key | tests/corpora/archaeology/fulltext/431914.tsv | tests/corpora/archaeology/fulltext/431914.txt | tests/corpora/archaeology/fulltext/432870.key | tests/corpora/archaeology/fulltext/432870.tsv | tests/corpora/archaeology/fulltext/432870.txt | tests/corpora/archaeology/fulltext/435213.key | tests/corpora/archaeology/fulltext/435213.tsv | tests/corpora/archaeology/fulltext/435213.txt | tests/corpora/archaeology/fulltext/435478.key | tests/corpora/archaeology/fulltext/435478.tsv | tests/corpora/archaeology/fulltext/435478.txt | tests/corpora/archaeology/fulltext/437503.key | tests/corpora/archaeology/fulltext/437503.tsv | tests/corpora/archaeology/fulltext/437503.txt | tests/corpora/archaeology/fulltext/439582.key | tests/corpora/archaeology/fulltext/439582.tsv | tests/corpora/archaeology/fulltext/439582.txt | tests/corpora/archaeology/fulltext/440866.key | tests/corpora/archaeology/fulltext/440866.tsv | tests/corpora/archaeology/fulltext/440866.txt | tests/corpora/archaeology/fulltext/441563.key | tests/corpora/archaeology/fulltext/441563.tsv | tests/corpora/archaeology/fulltext/441563.txt | tests/corpora/archaeology/subjects/p10073-fi.txt | tests/corpora/archaeology/subjects/p10174-fi.txt | tests/corpora/archaeology/subjects/p10295-fi.txt | tests/corpora/archaeology/subjects/p10415-fi.txt | tests/corpora/archaeology/subjects/p10416-fi.txt | tests/corpora/archaeology/subjects/p10417-fi.txt | tests/corpora/archaeology/subjects/p10826-fi.txt | tests/corpora/archaeology/subjects/p10849-fi.txt | tests/corpora/archaeology/subjects/p10986-fi.txt | tests/corpora/archaeology/subjects/p11052-fi.txt | tests/corpora/archaeology/subjects/p11111-fi.txt | tests/corpora/archaeology/subjects/p11348-fi.txt | tests/corpora/archaeology/subjects/p1209-fi.txt | tests/corpora/archaeology/subjects/p12179-fi.txt | tests/corpora/archaeology/subjects/p12463-fi.txt | tests/corpora/archaeology/subjects/p12484-fi.txt | tests/corpora/archaeology/subjects/p12627-fi.txt | tests/corpora/archaeology/subjects/p1264-fi.txt | tests/corpora/archaeology/subjects/p1265-fi.txt | tests/corpora/archaeology/subjects/p12651-fi.txt | tests/corpora/archaeology/subjects/p12738-fi.txt | tests/corpora/archaeology/subjects/p12897-fi.txt | tests/corpora/archaeology/subjects/p13027-fi.txt | tests/corpora/archaeology/subjects/p13489-fi.txt | tests/corpora/archaeology/subjects/p13564-fi.txt | tests/corpora/archaeology/subjects/p13721-fi.txt | tests/corpora/archaeology/subjects/p14173-fi.txt | tests/corpora/archaeology/subjects/p14174-fi.txt | tests/corpora/archaeology/subjects/p1419-fi.txt | tests/corpora/archaeology/subjects/p1421-fi.txt | tests/corpora/archaeology/subjects/p14303-fi.txt | tests/corpora/archaeology/subjects/p14374-fi.txt | tests/corpora/archaeology/subjects/p14588-fi.txt | tests/corpora/archaeology/subjects/p14800-fi.txt | tests/corpora/archaeology/subjects/p15031-fi.txt | tests/corpora/archaeology/subjects/p16323-fi.txt | tests/corpora/archaeology/subjects/p16476-fi.txt | tests/corpora/archaeology/subjects/p1747-fi.txt | tests/corpora/archaeology/subjects/p17863-fi.txt | tests/corpora/archaeology/subjects/p18211-fi.txt | tests/corpora/archaeology/subjects/p18569-fi.txt | tests/corpora/archaeology/subjects/p18838-fi.txt | tests/corpora/archaeology/subjects/p1894-fi.txt | tests/corpora/archaeology/subjects/p19077-fi.txt | tests/corpora/archaeology/subjects/p19180-fi.txt | tests/corpora/archaeology/subjects/p19258-fi.txt | tests/corpora/archaeology/subjects/p19353-fi.txt | tests/corpora/archaeology/subjects/p19740-fi.txt | tests/corpora/archaeology/subjects/p20096-fi.txt | tests/corpora/archaeology/subjects/p20280-fi.txt | tests/corpora/archaeology/subjects/p20339-fi.txt | tests/corpora/archaeology/subjects/p20471-fi.txt | tests/corpora/archaeology/subjects/p20619-fi.txt | tests/corpora/archaeology/subjects/p21084-fi.txt | tests/corpora/archaeology/subjects/p21412-fi.txt | tests/corpora/archaeology/subjects/p21482-fi.txt | tests/corpora/archaeology/subjects/p21820-fi.txt | tests/corpora/archaeology/subjects/p2192-fi.txt | tests/corpora/archaeology/subjects/p2193-fi.txt | tests/corpora/archaeology/subjects/p2194-fi.txt | tests/corpora/archaeology/subjects/p2195-fi.txt | tests/corpora/archaeology/subjects/p22768-fi.txt | tests/corpora/archaeology/subjects/p23386-fi.txt | tests/corpora/archaeology/subjects/p23677-fi.txt | tests/corpora/archaeology/subjects/p24443-fi.txt | tests/corpora/archaeology/subjects/p2557-fi.txt | tests/corpora/archaeology/subjects/p25576-fi.txt | tests/corpora/archaeology/subjects/p2558-fi.txt | tests/corpora/archaeology/subjects/p26858-fi.txt | tests/corpora/archaeology/subjects/p2714-fi.txt | tests/corpora/archaeology/subjects/p27358-fi.txt | tests/corpora/archaeology/subjects/p27547-fi.txt | tests/corpora/archaeology/subjects/p27963-fi.txt | tests/corpora/archaeology/subjects/p27964-fi.txt | tests/corpora/archaeology/subjects/p28252-fi.txt | tests/corpora/archaeology/subjects/p28955-fi.txt | tests/corpora/archaeology/subjects/p2932-fi.txt | tests/corpora/archaeology/subjects/p29406-fi.txt | tests/corpora/archaeology/subjects/p29433-fi.txt | tests/corpora/archaeology/subjects/p3973-fi.txt | tests/corpora/archaeology/subjects/p4622-fi.txt | tests/corpora/archaeology/subjects/p4624-fi.txt | tests/corpora/archaeology/subjects/p4625-fi.txt | tests/corpora/archaeology/subjects/p4626-fi.txt | tests/corpora/archaeology/subjects/p4739-fi.txt | tests/corpora/archaeology/subjects/p4740-fi.txt | tests/corpora/archaeology/subjects/p4791-fi.txt | tests/corpora/archaeology/subjects/p4831-fi.txt | tests/corpora/archaeology/subjects/p5337-fi.txt | tests/corpora/archaeology/subjects/p5338-fi.txt | tests/corpora/archaeology/subjects/p5340-fi.txt | tests/corpora/archaeology/subjects/p5713-fi.txt | tests/corpora/archaeology/subjects/p5714-fi.txt | tests/corpora/archaeology/subjects/p580-fi.txt | tests/corpora/archaeology/subjects/p5842-fi.txt | tests/corpora/archaeology/subjects/p6074-fi.txt | tests/corpora/archaeology/subjects/p6218-fi.txt | tests/corpora/archaeology/subjects/p6289-fi.txt | tests/corpora/archaeology/subjects/p6436-fi.txt | tests/corpora/archaeology/subjects/p6477-fi.txt | tests/corpora/archaeology/subjects/p6479-fi.txt | tests/corpora/archaeology/subjects/p6780-fi.txt | tests/corpora/archaeology/subjects/p7141-fi.txt | tests/corpora/archaeology/subjects/p7148-fi.txt | tests/corpora/archaeology/subjects/p7346-fi.txt | tests/corpora/archaeology/subjects/p7347-fi.txt | tests/corpora/archaeology/subjects/p7428-fi.txt | tests/corpora/archaeology/subjects/p7429-fi.txt | tests/corpora/archaeology/subjects/p7751-fi.txt | tests/corpora/archaeology/subjects/p7784-fi.txt | tests/corpora/archaeology/subjects/p7785-fi.txt | tests/corpora/archaeology/subjects/p7804-fi.txt | tests/corpora/archaeology/subjects/p8307-fi.txt | tests/corpora/archaeology/subjects/p8506-fi.txt | tests/corpora/archaeology/subjects/p8508-fi.txt | tests/corpora/archaeology/subjects/p8712-fi.txt | tests/corpora/archaeology/subjects/p8713-fi.txt | tests/corpora/archaeology/subjects/p8714-fi.txt | tests/corpora/archaeology/subjects/p8810-fi.txt | tests/corpora/archaeology/subjects/p8867-fi.txt | tests/corpora/archaeology/subjects/p8868-fi.txt | tests/corpora/archaeology/subjects/p8869-fi.txt | tests/corpora/archaeology/subjects/p8888-fi.txt | tests/corpora/archaeology/subjects/p8993-fi.txt | tests/corpora/archaeology/subjects/p9285-fi.txt,test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file,"Toy subject and document corpus Based on YSO archaeology group, Finna metadata and selected questions from the Ask a librarian corpus fix: threshold should be inclusive Add toy archaeology corpus. Fixes #56",no-bug,0.9
199,Annif,https://github.com/NatLibFi/Annif/issues/199,Swagger spec not included in installed package,"The `swagger/annif.yaml` file is not included, so after install the package can't be used.","move config.py inside package, to annif/config.py, so it's available after install. Fixes #196",Make sure annif.yaml is included in installed package. Fixes #199 | Make sure annif.yaml is included in installed package. Fixes #199,MANIFEST.in | annif/__init__.py | setup.py | swagger/annif.yaml | MANIFEST.in | annif/__init__.py | annif/swagger/annif.yaml | setup.py,other-file | source-file | source-file | documentation-file | other-file | source-file | documentation-file | source-file,"Swagger spec not included in installed package The `swagger/annif.yaml` file is not included, so after install the package can't be used. move config.py inside package, to annif/config.py, so it's available after install. Fixes #196 Make sure annif.yaml is included in installed package. Fixes #199 Make sure annif.yaml is included in installed package. Fixes #199",no-bug,0.8
187,Annif,https://github.com/NatLibFi/Annif/issues/187,Improved error handling,"There are many ways to trigger an error using Annif. These include * defining a project with missing settings (e.g. vocab is now practically mandatory) * trying to load documents before loading a vocabulary * trying to analyze documents before loading a vocabulary or training the model Some of these may also be triggered via the REST API, especially the last one. In these situations Annif should output a helpful error message instead of crashing with a traceback.",remove unused class variables,"Handle some error scenarios using a custom exception class. Part of #187 | Handle the error when no vocab has been set for a project. Part of #187 | Error handling for missing vocabulary case. Part of #187 | Handle error when tfidf similarity index doesn't exist. Part of #187 | Catch and report exceptions in analyzedir, eval and optimize CLI commands. Part of #187 | Handle errors in REST API. Part of #187",annif/backend/fasttext.py | annif/cli.py | annif/exception.py | annif/project.py | annif/cli.py | annif/exception.py | annif/project.py | annif/cli.py | annif/project.py | annif/vocab.py | annif/backend/tfidf.py | annif/cli.py | annif/rest.py | swagger/annif.yaml,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file,"Improved error handling There are many ways to trigger an error using Annif. These include * defining a project with missing settings (e.g. vocab is now practically mandatory) * trying to load documents before loading a vocabulary * trying to analyze documents before loading a vocabulary or training the model Some of these may also be triggered via the REST API, especially the last one. In these situations Annif should output a helpful error message instead of crashing with a traceback. remove unused class variables Handle some error scenarios using a custom exception class. Part of #187 Handle the error when no vocab has been set for a project. Part of #187 Error handling for missing vocabulary case. Part of #187 Handle error when tfidf similarity index doesn't exist. Part of #187 Catch and report exceptions in analyzedir, eval and optimize CLI commands. Part of #187 Handle errors in REST API. Part of #187",bug,0.8
125,Annif,https://github.com/NatLibFi/Annif/issues/125,Also initialize projects when starting WSGI server,"After #111 / #124 the backends are now initialized, but not the projects themselves. So the vocabulary, vectorizer etc. are only initialized on the first request, which makes it slow.",cleanup unnecessary type parameters from config files,Initialize also projects when running under WSGI. Fixes #125 | Merge pull request #128 from NatLibFi/issue125-initialize-project Initialize also projects when running under WSGI. Fixes #125,annif/project.py | tests/test_project.py | annif/project.py | tests/test_project.py,source-file | test-file | source-file | test-file,"Also initialize projects when starting WSGI server After #111 / #124 the backends are now initialized, but not the projects themselves. So the vocabulary, vectorizer etc. are only initialized on the first request, which makes it slow. cleanup unnecessary type parameters from config files Initialize also projects when running under WSGI. Fixes #125 Merge pull request #128 from NatLibFi/issue125-initialize-project Initialize also projects when running under WSGI. Fixes #125",no-bug,0.8
431,Annif,https://github.com/NatLibFi/Annif/issues/431,Problem parsing timestamps from Maui Server,"When starting up the Web UI (`annif run`) I encountered this error: ``` File ""/home/local/oisuomin/git/Annif/annif/backend/maui.py"", line 30, in modification_time return datetime.strptime(mtime, '%Y-%m-%dT%H:%M:%S.%fZ') File ""/usr/lib/python3.7/_strptime.py"", line 577, in _strptime_datetime tt, fraction, gmtoff_fraction = _strptime(data_string, format) File ""/usr/lib/python3.7/_strptime.py"", line 359, in _strptime (data_string, format)) ValueError: time data '2020-05-27T08:02:55.222+03:00' does not match format '%Y-%m-%dT%H:%M:%S.%fZ' ``` The problem is that the `maui` backend expects timestamps to have the UTC (""zulu"") designator Z, but Maui Server can also produce date strings formatted with ISO 8601 timezone offsets such as `+03:00`. PR follows...",Merge pull request #430 from NatLibFi/feature-cli-short-form-options Define short form for CLI options and fix some of their docstrings,Make modification timestamps timezone-aware. Fixes #431,annif/backend/backend.py | annif/backend/http.py | annif/backend/maui.py | tests/test_backend_http.py | tests/test_backend_maui.py | tests/test_backend_pav.py | tests/test_project.py,source-file | source-file | source-file | test-file | test-file | test-file | test-file,"Problem parsing timestamps from Maui Server When starting up the Web UI (`annif run`) I encountered this error: ``` File ""/home/local/oisuomin/git/Annif/annif/backend/maui.py"", line 30, in modification_time return datetime.strptime(mtime, '%Y-%m-%dT%H:%M:%S.%fZ') File ""/usr/lib/python3.7/_strptime.py"", line 577, in _strptime_datetime tt, fraction, gmtoff_fraction = _strptime(data_string, format) File ""/usr/lib/python3.7/_strptime.py"", line 359, in _strptime (data_string, format)) ValueError: time data '2020-05-27T08:02:55.222+03:00' does not match format '%Y-%m-%dT%H:%M:%S.%fZ' ``` The problem is that the `maui` backend expects timestamps to have the UTC (""zulu"") designator Z, but Maui Server can also produce date strings formatted with ISO 8601 timezone offsets such as `+03:00`. PR follows... Merge pull request #430 from NatLibFi/feature-cli-short-form-options Define short form for CLI options and fix some of their docstrings Make modification timestamps timezone-aware. Fixes #431",no-bug,0.9
114,Annif,https://github.com/NatLibFi/Annif/issues/114,Load vocabulary and metadata separately,"Currently the only supported subject corpus format is one that is organized by subject and contains both the vocabulary (URI + label) and metadata (lines of text, e.g. document titles). But most existing metadata is not in this subject-centric form but as individual documents. Also fastText (and probably many other ML models) requires document-centric input. Currently we do an awkward transformation that takes some time and memory and may lose some information. We should have a command for loading a vocabulary in SKOS or TSV format, e.g. annif loadvoc yso-fi yso-skos.ttl annif loadvoc ykl-fi ykl.tsv Then documents could be loaded separately in TSV format: annif loaddocs yso-fi yso-finna-fi.tsv This should be the default (possibly the only?) subject corpus format.",Bump version: 0.24.0 → 0.25.0,Support loading subjects from a TSV file. Part of #114 | Merge pull request #129 from NatLibFi/issue114-loadvoc-tsv Support loading subjects from a TSV file. Part of #114 | Support loading subjects from a SKOS file. Part of #114 | Initial support for loading train documents as TSV files. Not yet implemented for tfidf backend. Part of #114,annif/cli.py | annif/project.py | tests/corpora/archaeology/subjects.tsv | tests/test_cli.py | annif/cli.py | annif/project.py | tests/corpora/archaeology/subjects.tsv | tests/test_cli.py | Pipfile | annif/cli.py | annif/corpus/__init__.py | annif/corpus/subject.py | setup.py | tests/corpora/archaeology/README.md | tests/corpora/archaeology/extract-yso-archaeology.rq | tests/corpora/archaeology/yso-archaeology.rdf | tests/test_cli.py | annif/backend/backend.py | annif/backend/fasttext.py | annif/backend/tfidf.py | annif/cli.py | annif/corpus/__init__.py | annif/corpus/subject.py | annif/project.py | tests/corpora/archaeology/documents.tsv | tests/projects.cfg | tests/test_cli.py,source-file | source-file | test-file | test-file | source-file | source-file | test-file | test-file | other-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file,"Load vocabulary and metadata separately Currently the only supported subject corpus format is one that is organized by subject and contains both the vocabulary (URI + label) and metadata (lines of text, e.g. document titles). But most existing metadata is not in this subject-centric form but as individual documents. Also fastText (and probably many other ML models) requires document-centric input. Currently we do an awkward transformation that takes some time and memory and may lose some information. We should have a command for loading a vocabulary in SKOS or TSV format, e.g. annif loadvoc yso-fi yso-skos.ttl annif loadvoc ykl-fi ykl.tsv Then documents could be loaded separately in TSV format: annif loaddocs yso-fi yso-finna-fi.tsv This should be the default (possibly the only?) subject corpus format. Bump version: 0.24.0 → 0.25.0 Support loading subjects from a TSV file. Part of #114 Merge pull request #129 from NatLibFi/issue114-loadvoc-tsv Support loading subjects from a TSV file. Part of #114 Support loading subjects from a SKOS file. Part of #114 Initial support for loading train documents as TSV files. Not yet implemented for tfidf backend. Part of #114",no-bug,0.9
173,Annif,https://github.com/NatLibFi/Annif/issues/173,Missing and badly formatted CLI help texts,"In Annif v0.31, `annif --help` shows this: ``` Usage: annif [OPTIONS] COMMAND [ARGS]... Options: --version Show the flask version --help Show this message and exit. Commands: analyze "" Analyze a document. analyzedir "" Analyze a directory with documents. eval "" Evaluate the analysis result for a document against a... evaldir "" Evaluate the analysis results for a directory with... list-projects List available projects. load loaddocs loadvoc optimize "" Evaluate the analysis results for a directory with... routes Show the routes for the app. run Runs a development server. shell Runs a shell in the app context. show-project Show project information. ``` Some of these are OK but for some the help text is missing or badly formatted.",Merge pull request #183 from NatLibFi/issue176-remove-subject-corpus-format Remove CLI load command and support for old subject corpus format. Fixes #176,Fix CLI help texts. Fixes #173 | Merge pull request #184 from NatLibFi/issue173-cli-help Fix CLI help texts. Fixes #173,annif/cli.py | annif/cli.py,source-file | source-file,"Missing and badly formatted CLI help texts In Annif v0.31, `annif --help` shows this: ``` Usage: annif [OPTIONS] COMMAND [ARGS]... Options: --version Show the flask version --help Show this message and exit. Commands: analyze "" Analyze a document. analyzedir "" Analyze a directory with documents. eval "" Evaluate the analysis result for a document against a... evaldir "" Evaluate the analysis results for a directory with... list-projects List available projects. load loaddocs loadvoc optimize "" Evaluate the analysis results for a directory with... routes Show the routes for the app. run Runs a development server. shell Runs a shell in the app context. show-project Show project information. ``` Some of these are OK but for some the help text is missing or badly formatted. Merge pull request #183 from NatLibFi/issue176-remove-subject-corpus-format Remove CLI load command and support for old subject corpus format. Fixes #176 Fix CLI help texts. Fixes #173 Merge pull request #184 from NatLibFi/issue173-cli-help Fix CLI help texts. Fixes #173",no-bug,0.9
158,Annif,https://github.com/NatLibFi/Annif/issues/158,Refactor the way analysis results are returned,"Related to #141 The way results are returned from backends should be re-architected. Currently the results are returned as sequences of AnalysisHit objects, but this makes it impossible to use e.g. sklearn metrics or any other vector based processing. Instead hits should be returned as objects that implement an ABC, which could be called AnalysisHits. The ABC should have methods (or properties) that give the results either as a sequence of AnalysisHit objects (as currently used) or as vectors of size N, where N is the number of subjects in the vocabulary.",Merge pull request #156 from NatLibFi/issue155-example-config Rename projects.cfg into projects.cfg.dist so deployments can use their own copy. Fixes #155,Return hits from backends and projects as AnalysisHits instead of plain list. Fixes #158,annif/backend/dummy.py | annif/backend/fasttext.py | annif/backend/tfidf.py | annif/hit.py | annif/util.py,source-file | source-file | source-file | source-file | source-file,"Refactor the way analysis results are returned Related to #141 The way results are returned from backends should be re-architected. Currently the results are returned as sequences of AnalysisHit objects, but this makes it impossible to use e.g. sklearn metrics or any other vector based processing. Instead hits should be returned as objects that implement an ABC, which could be called AnalysisHits. The ABC should have methods (or properties) that give the results either as a sequence of AnalysisHit objects (as currently used) or as vectors of size N, where N is the number of subjects in the vocabulary. Merge pull request #156 from NatLibFi/issue155-example-config Rename projects.cfg into projects.cfg.dist so deployments can use their own copy. Fixes #155 Return hits from backends and projects as AnalysisHits instead of plain list. Fixes #158",no-bug,0.8
389,Annif,https://github.com/NatLibFi/Annif/issues/389,Annif breaks when MauiServer returns malformed URIs for topic IDs,"### Steps to reproduce ``` annif loadvoc rula-maui-en Annif-corpora/vocab/lcsh/lcsh.ttl annif train rula-maui-en Annif-corpora/fulltext/rula/validate/ ``` https://github.com/mjsuhonos/Annif-corpora/blob/master/vocab/lcsh/lcsh.ttl https://github.com/mjsuhonos/Annif-corpora/tree/master/fulltext/rula/validate ``` annif eval rula-maui-en Annif-corpora/fulltext/rula/test/ -v DEBUG ``` ```python … warning: Unknown subject URI <http://id.loc.gov/authorities/subjects/http://id.loc.gov/authorities/genreForms/gf2011026450> Traceback (most recent call last): File ""/usr/local/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/flask/cli.py"", line 586, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/flask/cli.py"", line 426, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/Annif/annif/cli.py"", line 305, in run_eval results = project.suggest(doc.text, backend_params) File ""/Annif/annif/project.py"", line 161, in suggest hits = self._suggest_with_backend(text, backend_params) File ""/Annif/annif/project.py"", line 105, in _suggest_with_backend hits = self.backend.suggest(text, beparams) File ""/Annif/annif/backend/backend.py"", line 67, in suggest return self._suggest(text, params=beparams) File ""/Annif/annif/backend/maui.py"", line 155, in _suggest return self._response_to_result(response) File ""/Annif/annif/backend/maui.py"", line 150, in _response_to_result self.project.subjects) File ""/Annif/annif/suggestion.py"", line 169, in create_from_index subject = subject_index[subject_index.by_uri(hit.uri)] File ""/Annif/annif/corpus/subject.py"", line 55, in __getitem__ return (self._uris[subject_id], self._labels[subject_id], TypeError: list indices must be integers or slices, not NoneType ``` ### Malformed response Document source (1126 bytes) > Key findings: The survey results for both countries were similar in terms of the percentage of respondents who reported working in smaller newsrooms and working longer hours compared to two years ago Respondents in both countries said that the perception of local newspapers as a dying industry deters advertisers and makes it challenging to recruit new staff Use of metrics to measure engagement and shape the production of stories is about the same in both countries Respondents in Canada and the United States both reported that few employers provided training courses to assist with learning about new technologies While approximately half of the participants in both surveys felt slightly or very secure in their jobs, almost twice as many Canadians felt slightly or very insecure in their jobs American respondents overall tended to be more positive about the future of local newspapers Respondents from American newspapers were more likely to use video reporting, live video and **and podcasts than their Canadian counterparts Researchers who compare the state of local journalism across** ```json { ""title"": ""10 recommendations from rula-maui-en"", ""topics"": [ { ""id"": ""http://id.loc.gov/authorities/subjects/sh85004368"", ""label"": ""American newspapers"", ""probability"": 0.06058101652075777 }, { ""id"": ""http://id.loc.gov/authorities/subjects/http://id.loc.gov/authorities/genreForms/gf2011026450"", ""label"": ""http://id.loc.gov/authorities/subjects/http://id.loc.gov/authorities/genreForms/gf2011026450"", ""probability"": 0.03634347847356808 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85143204"", ""label"": ""Video recordings"", ""probability"": 0.02480501693510654 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85070585"", ""label"": ""Job security"", ""probability"": 0.022298487879186563 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2007001518"", ""label"": ""Podcasts"", ""probability"": 0.021532180099457447 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2006006472"", ""label"": ""Podcasting"", ""probability"": 0.021532180099457447 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2012001802"", ""label"": ""Podcasters"", ""probability"": 0.021532180099457447 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85091588"", ""label"": ""Newspapers"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh99001641"", ""label"": ""Newspapers"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2007008878"", ""label"": ""First responders"", ""probability"": 0.01622784151074123 } ] } ``` ### Correct response Document source (1126 bytes) > Key findings: The survey results for both countries were similar in terms of the percentage of respondents who reported working in smaller newsrooms and working longer hours compared to two years ago Respondents in both countries said that the perception of local newspapers as a dying industry deters advertisers and makes it challenging to recruit new staff Use of metrics to measure engagement and shape the production of stories is about the same in both countries Respondents in Canada and the United States both reported that few employers provided training courses to assist with learning about new technologies While approximately half of the participants in both surveys felt slightly or very secure in their jobs, almost twice as many Canadians felt slightly or very insecure in their jobs American respondents overall tended to be more positive about the future of local newspapers Respondents from American newspapers were more likely to use video reporting, live video and **common questions revealed two notable differences between the countries. The first had to do with sentiments** ```json { ""title"": ""10 recommendations from rula-maui-en"", ""topics"": [ { ""id"": ""http://id.loc.gov/authorities/subjects/sh85004368"", ""label"": ""American newspapers"", ""probability"": 0.06058101652075777 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85143204"", ""label"": ""Video recordings"", ""probability"": 0.02480501693510654 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85070585"", ""label"": ""Job security"", ""probability"": 0.022298487879186563 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85091588"", ""label"": ""Newspapers"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh99001641"", ""label"": ""Newspapers"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2007008878"", ""label"": ""First responders"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh93009373"", ""label"": ""Advertisers"", ""probability"": 0.01382364849909128 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85001086"", ""label"": ""Advertising"", ""probability"": 0.01382364849909128 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2001009077"", ""label"": ""Supplementary employment"", ""probability"": 0.01382364849909128 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2005004875"", ""label"": ""Employability"", ""probability"": 0.01382364849909128 } ] } ``` ### Suspected cause This vocabulary contains two `skos:prefLabel` statements with identical object literals: ``` <http://id.loc.gov/authorities/genreForms/gf2011026450> <http://www.w3.org/2004/02/skos/core#prefLabel> ""Podcasts""@en . <http://id.loc.gov/authorities/subjects/sh2007001518> <http://www.w3.org/2004/02/skos/core#prefLabel> ""Podcasts""@en . ``` It seems plausible that due to its lexical approach, Maui uses the object literal as a unique value, which would match two topic URIs, given the above statements. The (albeit strangely truncated) concatenation of these two URI values are then returned in the response. This theory is currently being tested. ### Proposed resolution Ideally, Annif could extract valid URIs from the invalid response, but this may be too much overhead if each response URI must be validated. At a minimum, Annif should ignore the malformed response and continue with eg. a warning statement on STDERR.",Modify unit test to exercise all code paths,Robustness fix: Don't break if Maui returns an unknown URI. Fixes #389,annif/suggestion.py | tests/test_backend_maui.py,source-file | test-file,"Annif breaks when MauiServer returns malformed URIs for topic IDs ### Steps to reproduce ``` annif loadvoc rula-maui-en Annif-corpora/vocab/lcsh/lcsh.ttl annif train rula-maui-en Annif-corpora/fulltext/rula/validate/ ``` https://github.com/mjsuhonos/Annif-corpora/blob/master/vocab/lcsh/lcsh.ttl https://github.com/mjsuhonos/Annif-corpora/tree/master/fulltext/rula/validate ``` annif eval rula-maui-en Annif-corpora/fulltext/rula/test/ -v DEBUG ``` ```python … warning: Unknown subject URI <http://id.loc.gov/authorities/subjects/http://id.loc.gov/authorities/genreForms/gf2011026450> Traceback (most recent call last): File ""/usr/local/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/flask/cli.py"", line 586, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/flask/cli.py"", line 426, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/usr/local/lib/python3.7/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/Annif/annif/cli.py"", line 305, in run_eval results = project.suggest(doc.text, backend_params) File ""/Annif/annif/project.py"", line 161, in suggest hits = self._suggest_with_backend(text, backend_params) File ""/Annif/annif/project.py"", line 105, in _suggest_with_backend hits = self.backend.suggest(text, beparams) File ""/Annif/annif/backend/backend.py"", line 67, in suggest return self._suggest(text, params=beparams) File ""/Annif/annif/backend/maui.py"", line 155, in _suggest return self._response_to_result(response) File ""/Annif/annif/backend/maui.py"", line 150, in _response_to_result self.project.subjects) File ""/Annif/annif/suggestion.py"", line 169, in create_from_index subject = subject_index[subject_index.by_uri(hit.uri)] File ""/Annif/annif/corpus/subject.py"", line 55, in __getitem__ return (self._uris[subject_id], self._labels[subject_id], TypeError: list indices must be integers or slices, not NoneType ``` ### Malformed response Document source (1126 bytes) > Key findings: The survey results for both countries were similar in terms of the percentage of respondents who reported working in smaller newsrooms and working longer hours compared to two years ago Respondents in both countries said that the perception of local newspapers as a dying industry deters advertisers and makes it challenging to recruit new staff Use of metrics to measure engagement and shape the production of stories is about the same in both countries Respondents in Canada and the United States both reported that few employers provided training courses to assist with learning about new technologies While approximately half of the participants in both surveys felt slightly or very secure in their jobs, almost twice as many Canadians felt slightly or very insecure in their jobs American respondents overall tended to be more positive about the future of local newspapers Respondents from American newspapers were more likely to use video reporting, live video and **and podcasts than their Canadian counterparts Researchers who compare the state of local journalism across** ```json { ""title"": ""10 recommendations from rula-maui-en"", ""topics"": [ { ""id"": ""http://id.loc.gov/authorities/subjects/sh85004368"", ""label"": ""American newspapers"", ""probability"": 0.06058101652075777 }, { ""id"": ""http://id.loc.gov/authorities/subjects/http://id.loc.gov/authorities/genreForms/gf2011026450"", ""label"": ""http://id.loc.gov/authorities/subjects/http://id.loc.gov/authorities/genreForms/gf2011026450"", ""probability"": 0.03634347847356808 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85143204"", ""label"": ""Video recordings"", ""probability"": 0.02480501693510654 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85070585"", ""label"": ""Job security"", ""probability"": 0.022298487879186563 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2007001518"", ""label"": ""Podcasts"", ""probability"": 0.021532180099457447 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2006006472"", ""label"": ""Podcasting"", ""probability"": 0.021532180099457447 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2012001802"", ""label"": ""Podcasters"", ""probability"": 0.021532180099457447 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85091588"", ""label"": ""Newspapers"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh99001641"", ""label"": ""Newspapers"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2007008878"", ""label"": ""First responders"", ""probability"": 0.01622784151074123 } ] } ``` ### Correct response Document source (1126 bytes) > Key findings: The survey results for both countries were similar in terms of the percentage of respondents who reported working in smaller newsrooms and working longer hours compared to two years ago Respondents in both countries said that the perception of local newspapers as a dying industry deters advertisers and makes it challenging to recruit new staff Use of metrics to measure engagement and shape the production of stories is about the same in both countries Respondents in Canada and the United States both reported that few employers provided training courses to assist with learning about new technologies While approximately half of the participants in both surveys felt slightly or very secure in their jobs, almost twice as many Canadians felt slightly or very insecure in their jobs American respondents overall tended to be more positive about the future of local newspapers Respondents from American newspapers were more likely to use video reporting, live video and **common questions revealed two notable differences between the countries. The first had to do with sentiments** ```json { ""title"": ""10 recommendations from rula-maui-en"", ""topics"": [ { ""id"": ""http://id.loc.gov/authorities/subjects/sh85004368"", ""label"": ""American newspapers"", ""probability"": 0.06058101652075777 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85143204"", ""label"": ""Video recordings"", ""probability"": 0.02480501693510654 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85070585"", ""label"": ""Job security"", ""probability"": 0.022298487879186563 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85091588"", ""label"": ""Newspapers"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh99001641"", ""label"": ""Newspapers"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2007008878"", ""label"": ""First responders"", ""probability"": 0.01622784151074123 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh93009373"", ""label"": ""Advertisers"", ""probability"": 0.01382364849909128 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh85001086"", ""label"": ""Advertising"", ""probability"": 0.01382364849909128 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2001009077"", ""label"": ""Supplementary employment"", ""probability"": 0.01382364849909128 }, { ""id"": ""http://id.loc.gov/authorities/subjects/sh2005004875"", ""label"": ""Employability"", ""probability"": 0.01382364849909128 } ] } ``` ### Suspected cause This vocabulary contains two `skos:prefLabel` statements with identical object literals: ``` <http://id.loc.gov/authorities/genreForms/gf2011026450> <http://www.w3.org/2004/02/skos/core#prefLabel> ""Podcasts""@en . <http://id.loc.gov/authorities/subjects/sh2007001518> <http://www.w3.org/2004/02/skos/core#prefLabel> ""Podcasts""@en . ``` It seems plausible that due to its lexical approach, Maui uses the object literal as a unique value, which would match two topic URIs, given the above statements. The (albeit strangely truncated) concatenation of these two URI values are then returned in the response. This theory is currently being tested. ### Proposed resolution Ideally, Annif could extract valid URIs from the invalid response, but this may be too much overhead if each response URI must be validated. At a minimum, Annif should ignore the malformed response and continue with eg. a warning statement on STDERR. Modify unit test to exercise all code paths Robustness fix: Don't break if Maui returns an unknown URI. Fixes #389",bug,0.9
176,Annif,https://github.com/NatLibFi/Annif/issues/176,remove support for subject corpus format,"The subject corpus format (directory of *.txt files, one per subject) that was used in the Annif prototype is not very well thought out and there are few sources from which generating such a corpus is easy. Instead the available corpora are mostly document-oriented. I think support for this corpus format should be dropped from the CLI (currently the `load` command accepts this format). Instead we should support both a simple `.tsv` format (as `loaddocs` already does) as well as the Maui style directory of `.txt`+`.tsv` (or `.key`) files (#145). The subject corpus format may still be used internally, when transforming from document-oriented to subject-oriented corpora, for example for the `tfidf` backend.",Merge pull request #182 from NatLibFi/issue181-gzipped-docfile Support document corpora as gzipped TSV files. Fixes #181,Remove CLI load command and support for old subject corpus format. Fixes #176 | Merge pull request #183 from NatLibFi/issue176-remove-subject-corpus-format Remove CLI load command and support for old subject corpus format. Fixes #176 | remove dead code (project.load_subjects) left after #176 | Merge pull request #185 from NatLibFi/issue176-cleanup remove dead code (project.load_subjects) left after #176,annif/cli.py | tests/conftest.py | tests/corpora/archaeology/subjects/p10073-fi.txt | tests/corpora/archaeology/subjects/p10174-fi.txt | tests/corpora/archaeology/subjects/p10295-fi.txt | tests/corpora/archaeology/subjects/p10415-fi.txt | tests/corpora/archaeology/subjects/p10416-fi.txt | tests/corpora/archaeology/subjects/p10417-fi.txt | tests/corpora/archaeology/subjects/p10826-fi.txt | tests/corpora/archaeology/subjects/p10849-fi.txt | tests/corpora/archaeology/subjects/p10986-fi.txt | tests/corpora/archaeology/subjects/p11052-fi.txt | tests/corpora/archaeology/subjects/p11111-fi.txt | tests/corpora/archaeology/subjects/p11348-fi.txt | tests/corpora/archaeology/subjects/p1209-fi.txt | tests/corpora/archaeology/subjects/p12179-fi.txt | tests/corpora/archaeology/subjects/p12463-fi.txt | tests/corpora/archaeology/subjects/p12484-fi.txt | tests/corpora/archaeology/subjects/p12627-fi.txt | tests/corpora/archaeology/subjects/p1264-fi.txt | tests/corpora/archaeology/subjects/p1265-fi.txt | tests/corpora/archaeology/subjects/p12651-fi.txt | tests/corpora/archaeology/subjects/p12738-fi.txt | tests/corpora/archaeology/subjects/p12897-fi.txt | tests/corpora/archaeology/subjects/p13027-fi.txt | tests/corpora/archaeology/subjects/p13489-fi.txt | tests/corpora/archaeology/subjects/p13564-fi.txt | tests/corpora/archaeology/subjects/p13721-fi.txt | tests/corpora/archaeology/subjects/p14173-fi.txt | tests/corpora/archaeology/subjects/p14174-fi.txt | tests/corpora/archaeology/subjects/p1419-fi.txt | tests/corpora/archaeology/subjects/p1421-fi.txt | tests/corpora/archaeology/subjects/p14303-fi.txt | tests/corpora/archaeology/subjects/p14374-fi.txt | tests/corpora/archaeology/subjects/p14588-fi.txt | tests/corpora/archaeology/subjects/p14800-fi.txt | tests/corpora/archaeology/subjects/p15031-fi.txt | tests/corpora/archaeology/subjects/p16323-fi.txt | tests/corpora/archaeology/subjects/p16476-fi.txt | tests/corpora/archaeology/subjects/p1747-fi.txt | tests/corpora/archaeology/subjects/p17863-fi.txt | tests/corpora/archaeology/subjects/p18211-fi.txt | tests/corpora/archaeology/subjects/p18569-fi.txt | tests/corpora/archaeology/subjects/p18838-fi.txt | tests/corpora/archaeology/subjects/p1894-fi.txt | tests/corpora/archaeology/subjects/p19077-fi.txt | tests/corpora/archaeology/subjects/p19180-fi.txt | tests/corpora/archaeology/subjects/p19258-fi.txt | tests/corpora/archaeology/subjects/p19353-fi.txt | tests/corpora/archaeology/subjects/p19740-fi.txt | tests/corpora/archaeology/subjects/p20096-fi.txt | tests/corpora/archaeology/subjects/p20280-fi.txt | tests/corpora/archaeology/subjects/p20339-fi.txt | tests/corpora/archaeology/subjects/p20471-fi.txt | tests/corpora/archaeology/subjects/p20619-fi.txt | tests/corpora/archaeology/subjects/p21084-fi.txt | tests/corpora/archaeology/subjects/p21412-fi.txt | tests/corpora/archaeology/subjects/p21482-fi.txt | tests/corpora/archaeology/subjects/p21820-fi.txt | tests/corpora/archaeology/subjects/p2192-fi.txt | tests/corpora/archaeology/subjects/p2193-fi.txt | tests/corpora/archaeology/subjects/p2194-fi.txt | tests/corpora/archaeology/subjects/p2195-fi.txt | tests/corpora/archaeology/subjects/p22768-fi.txt | tests/corpora/archaeology/subjects/p23386-fi.txt | tests/corpora/archaeology/subjects/p23677-fi.txt | tests/corpora/archaeology/subjects/p24443-fi.txt | tests/corpora/archaeology/subjects/p2557-fi.txt | tests/corpora/archaeology/subjects/p25576-fi.txt | tests/corpora/archaeology/subjects/p2558-fi.txt | tests/corpora/archaeology/subjects/p26858-fi.txt | tests/corpora/archaeology/subjects/p2714-fi.txt | tests/corpora/archaeology/subjects/p27358-fi.txt | tests/corpora/archaeology/subjects/p27547-fi.txt | tests/corpora/archaeology/subjects/p27963-fi.txt | tests/corpora/archaeology/subjects/p27964-fi.txt | tests/corpora/archaeology/subjects/p28252-fi.txt | tests/corpora/archaeology/subjects/p28955-fi.txt | tests/corpora/archaeology/subjects/p2932-fi.txt | tests/corpora/archaeology/subjects/p29406-fi.txt | tests/corpora/archaeology/subjects/p29433-fi.txt | tests/corpora/archaeology/subjects/p3973-fi.txt | tests/corpora/archaeology/subjects/p4622-fi.txt | tests/corpora/archaeology/subjects/p4624-fi.txt | tests/corpora/archaeology/subjects/p4625-fi.txt | tests/corpora/archaeology/subjects/p4626-fi.txt | tests/corpora/archaeology/subjects/p4739-fi.txt | tests/corpora/archaeology/subjects/p4740-fi.txt | tests/corpora/archaeology/subjects/p4791-fi.txt | tests/corpora/archaeology/subjects/p4831-fi.txt | tests/corpora/archaeology/subjects/p5337-fi.txt | tests/corpora/archaeology/subjects/p5338-fi.txt | tests/corpora/archaeology/subjects/p5340-fi.txt | tests/corpora/archaeology/subjects/p5713-fi.txt | tests/corpora/archaeology/subjects/p5714-fi.txt | tests/corpora/archaeology/subjects/p580-fi.txt | tests/corpora/archaeology/subjects/p5842-fi.txt | tests/corpora/archaeology/subjects/p6074-fi.txt | tests/corpora/archaeology/subjects/p6218-fi.txt | tests/corpora/archaeology/subjects/p6289-fi.txt | tests/corpora/archaeology/subjects/p6436-fi.txt | tests/corpora/archaeology/subjects/p6477-fi.txt | tests/corpora/archaeology/subjects/p6479-fi.txt | tests/corpora/archaeology/subjects/p6780-fi.txt | tests/corpora/archaeology/subjects/p7141-fi.txt | tests/corpora/archaeology/subjects/p7148-fi.txt | tests/corpora/archaeology/subjects/p7346-fi.txt | tests/corpora/archaeology/subjects/p7347-fi.txt | tests/corpora/archaeology/subjects/p7428-fi.txt | tests/corpora/archaeology/subjects/p7429-fi.txt | tests/corpora/archaeology/subjects/p7751-fi.txt | tests/corpora/archaeology/subjects/p7784-fi.txt | tests/corpora/archaeology/subjects/p7785-fi.txt | tests/corpora/archaeology/subjects/p7804-fi.txt | tests/corpora/archaeology/subjects/p8307-fi.txt | tests/corpora/archaeology/subjects/p8506-fi.txt | tests/corpora/archaeology/subjects/p8508-fi.txt | tests/corpora/archaeology/subjects/p8712-fi.txt | tests/corpora/archaeology/subjects/p8713-fi.txt | tests/corpora/archaeology/subjects/p8714-fi.txt | tests/corpora/archaeology/subjects/p8810-fi.txt | tests/corpora/archaeology/subjects/p8867-fi.txt | tests/corpora/archaeology/subjects/p8868-fi.txt | tests/corpora/archaeology/subjects/p8869-fi.txt | tests/corpora/archaeology/subjects/p8888-fi.txt | tests/corpora/archaeology/subjects/p8993-fi.txt | tests/corpora/archaeology/subjects/p9285-fi.txt | tests/test_backend_fasttext.py | tests/test_backend_tfidf.py | tests/test_cli.py | tests/test_hit.py | tests/test_project.py | annif/cli.py | tests/conftest.py | tests/corpora/archaeology/subjects/p10073-fi.txt | tests/corpora/archaeology/subjects/p10174-fi.txt | tests/corpora/archaeology/subjects/p10295-fi.txt | tests/corpora/archaeology/subjects/p10415-fi.txt | tests/corpora/archaeology/subjects/p10416-fi.txt | tests/corpora/archaeology/subjects/p10417-fi.txt | tests/corpora/archaeology/subjects/p10826-fi.txt | tests/corpora/archaeology/subjects/p10849-fi.txt | tests/corpora/archaeology/subjects/p10986-fi.txt | tests/corpora/archaeology/subjects/p11052-fi.txt | tests/corpora/archaeology/subjects/p11111-fi.txt | tests/corpora/archaeology/subjects/p11348-fi.txt | tests/corpora/archaeology/subjects/p1209-fi.txt | tests/corpora/archaeology/subjects/p12179-fi.txt | tests/corpora/archaeology/subjects/p12463-fi.txt | tests/corpora/archaeology/subjects/p12484-fi.txt | tests/corpora/archaeology/subjects/p12627-fi.txt | tests/corpora/archaeology/subjects/p1264-fi.txt | tests/corpora/archaeology/subjects/p1265-fi.txt | tests/corpora/archaeology/subjects/p12651-fi.txt | tests/corpora/archaeology/subjects/p12738-fi.txt | tests/corpora/archaeology/subjects/p12897-fi.txt | tests/corpora/archaeology/subjects/p13027-fi.txt | tests/corpora/archaeology/subjects/p13489-fi.txt | tests/corpora/archaeology/subjects/p13564-fi.txt | tests/corpora/archaeology/subjects/p13721-fi.txt | tests/corpora/archaeology/subjects/p14173-fi.txt | tests/corpora/archaeology/subjects/p14174-fi.txt | tests/corpora/archaeology/subjects/p1419-fi.txt | tests/corpora/archaeology/subjects/p1421-fi.txt | tests/corpora/archaeology/subjects/p14303-fi.txt | tests/corpora/archaeology/subjects/p14374-fi.txt | tests/corpora/archaeology/subjects/p14588-fi.txt | tests/corpora/archaeology/subjects/p14800-fi.txt | tests/corpora/archaeology/subjects/p15031-fi.txt | tests/corpora/archaeology/subjects/p16323-fi.txt | tests/corpora/archaeology/subjects/p16476-fi.txt | tests/corpora/archaeology/subjects/p1747-fi.txt | tests/corpora/archaeology/subjects/p17863-fi.txt | tests/corpora/archaeology/subjects/p18211-fi.txt | tests/corpora/archaeology/subjects/p18569-fi.txt | tests/corpora/archaeology/subjects/p18838-fi.txt | tests/corpora/archaeology/subjects/p1894-fi.txt | tests/corpora/archaeology/subjects/p19077-fi.txt | tests/corpora/archaeology/subjects/p19180-fi.txt | tests/corpora/archaeology/subjects/p19258-fi.txt | tests/corpora/archaeology/subjects/p19353-fi.txt | tests/corpora/archaeology/subjects/p19740-fi.txt | tests/corpora/archaeology/subjects/p20096-fi.txt | tests/corpora/archaeology/subjects/p20280-fi.txt | tests/corpora/archaeology/subjects/p20339-fi.txt | tests/corpora/archaeology/subjects/p20471-fi.txt | tests/corpora/archaeology/subjects/p20619-fi.txt | tests/corpora/archaeology/subjects/p21084-fi.txt | tests/corpora/archaeology/subjects/p21412-fi.txt | tests/corpora/archaeology/subjects/p21482-fi.txt | tests/corpora/archaeology/subjects/p21820-fi.txt | tests/corpora/archaeology/subjects/p2192-fi.txt | tests/corpora/archaeology/subjects/p2193-fi.txt | tests/corpora/archaeology/subjects/p2194-fi.txt | tests/corpora/archaeology/subjects/p2195-fi.txt | tests/corpora/archaeology/subjects/p22768-fi.txt | tests/corpora/archaeology/subjects/p23386-fi.txt | tests/corpora/archaeology/subjects/p23677-fi.txt | tests/corpora/archaeology/subjects/p24443-fi.txt | tests/corpora/archaeology/subjects/p2557-fi.txt | tests/corpora/archaeology/subjects/p25576-fi.txt | tests/corpora/archaeology/subjects/p2558-fi.txt | tests/corpora/archaeology/subjects/p26858-fi.txt | tests/corpora/archaeology/subjects/p2714-fi.txt | tests/corpora/archaeology/subjects/p27358-fi.txt | tests/corpora/archaeology/subjects/p27547-fi.txt | tests/corpora/archaeology/subjects/p27963-fi.txt | tests/corpora/archaeology/subjects/p27964-fi.txt | tests/corpora/archaeology/subjects/p28252-fi.txt | tests/corpora/archaeology/subjects/p28955-fi.txt | tests/corpora/archaeology/subjects/p2932-fi.txt | tests/corpora/archaeology/subjects/p29406-fi.txt | tests/corpora/archaeology/subjects/p29433-fi.txt | tests/corpora/archaeology/subjects/p3973-fi.txt | tests/corpora/archaeology/subjects/p4622-fi.txt | tests/corpora/archaeology/subjects/p4624-fi.txt | tests/corpora/archaeology/subjects/p4625-fi.txt | tests/corpora/archaeology/subjects/p4626-fi.txt | tests/corpora/archaeology/subjects/p4739-fi.txt | tests/corpora/archaeology/subjects/p4740-fi.txt | tests/corpora/archaeology/subjects/p4791-fi.txt | tests/corpora/archaeology/subjects/p4831-fi.txt | tests/corpora/archaeology/subjects/p5337-fi.txt | tests/corpora/archaeology/subjects/p5338-fi.txt | tests/corpora/archaeology/subjects/p5340-fi.txt | tests/corpora/archaeology/subjects/p5713-fi.txt | tests/corpora/archaeology/subjects/p5714-fi.txt | tests/corpora/archaeology/subjects/p580-fi.txt | tests/corpora/archaeology/subjects/p5842-fi.txt | tests/corpora/archaeology/subjects/p6074-fi.txt | tests/corpora/archaeology/subjects/p6218-fi.txt | tests/corpora/archaeology/subjects/p6289-fi.txt | tests/corpora/archaeology/subjects/p6436-fi.txt | tests/corpora/archaeology/subjects/p6477-fi.txt | tests/corpora/archaeology/subjects/p6479-fi.txt | tests/corpora/archaeology/subjects/p6780-fi.txt | tests/corpora/archaeology/subjects/p7141-fi.txt | tests/corpora/archaeology/subjects/p7148-fi.txt | tests/corpora/archaeology/subjects/p7346-fi.txt | tests/corpora/archaeology/subjects/p7347-fi.txt | tests/corpora/archaeology/subjects/p7428-fi.txt | tests/corpora/archaeology/subjects/p7429-fi.txt | tests/corpora/archaeology/subjects/p7751-fi.txt | tests/corpora/archaeology/subjects/p7784-fi.txt | tests/corpora/archaeology/subjects/p7785-fi.txt | tests/corpora/archaeology/subjects/p7804-fi.txt | tests/corpora/archaeology/subjects/p8307-fi.txt | tests/corpora/archaeology/subjects/p8506-fi.txt | tests/corpora/archaeology/subjects/p8508-fi.txt | tests/corpora/archaeology/subjects/p8712-fi.txt | tests/corpora/archaeology/subjects/p8713-fi.txt | tests/corpora/archaeology/subjects/p8714-fi.txt | tests/corpora/archaeology/subjects/p8810-fi.txt | tests/corpora/archaeology/subjects/p8867-fi.txt | tests/corpora/archaeology/subjects/p8868-fi.txt | tests/corpora/archaeology/subjects/p8869-fi.txt | tests/corpora/archaeology/subjects/p8888-fi.txt | tests/corpora/archaeology/subjects/p8993-fi.txt | tests/corpora/archaeology/subjects/p9285-fi.txt | tests/test_backend_fasttext.py | tests/test_backend_tfidf.py | tests/test_cli.py | tests/test_corpus.py | tests/test_hit.py | tests/test_project.py | annif/project.py | tests/test_backend_fasttext.py | tests/test_backend_tfidf.py | tests/test_project.py | annif/project.py | tests/test_backend_fasttext.py | tests/test_backend_tfidf.py | tests/test_project.py,source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | test-file | test-file | test-file | source-file | test-file | test-file | test-file,"remove support for subject corpus format The subject corpus format (directory of *.txt files, one per subject) that was used in the Annif prototype is not very well thought out and there are few sources from which generating such a corpus is easy. Instead the available corpora are mostly document-oriented. I think support for this corpus format should be dropped from the CLI (currently the `load` command accepts this format). Instead we should support both a simple `.tsv` format (as `loaddocs` already does) as well as the Maui style directory of `.txt`+`.tsv` (or `.key`) files (#145). The subject corpus format may still be used internally, when transforming from document-oriented to subject-oriented corpora, for example for the `tfidf` backend. Merge pull request #182 from NatLibFi/issue181-gzipped-docfile Support document corpora as gzipped TSV files. Fixes #181 Remove CLI load command and support for old subject corpus format. Fixes #176 Merge pull request #183 from NatLibFi/issue176-remove-subject-corpus-format Remove CLI load command and support for old subject corpus format. Fixes #176 remove dead code (project.load_subjects) left after #176 Merge pull request #185 from NatLibFi/issue176-cleanup remove dead code (project.load_subjects) left after #176",no-bug,0.9
67,Annif,https://github.com/NatLibFi/Annif/issues/67,Verbose mode and logging,Should add logging messages (INFO & DEBUG) throughout important code paths (especially load and analyze) and create verbose and debug flags that can be used to see more detailed log messages.,switch to click.echo() instead of print statements in CLI,Add logging messages and verbosity option using click-log. Fixes #67,annif/__init__.py | annif/backend/backend.py | annif/backend/tfidf.py | annif/cli.py | annif/project.py | projects.cfg | requirements.txt,source-file | source-file | source-file | source-file | source-file | other-file | other-file,Verbose mode and logging Should add logging messages (INFO & DEBUG) throughout important code paths (especially load and analyze) and create verbose and debug flags that can be used to see more detailed log messages. switch to click.echo() instead of print statements in CLI Add logging messages and verbosity option using click-log. Fixes #67,no-bug,0.9
196,Annif,https://github.com/NatLibFi/Annif/issues/196,Doesn't work after install due to configuration handling issue,"After installing Annif using `python setup.py install` (within a pipenv shell) I cannot run Annif anymore but get this error message: ``` ImportError: No module named 'config' ``` The problem is that `config.py` is not included in the installed package. It could probably be overridden using an environment variable, but there should be a sane default. This blocks the PyPI release (#195) as the same situation will happen when installing a package from PyPI.",Merge pull request #198 from NatLibFi/issue188-lazy-result-conversion Issue188 lazy result conversion,"move config.py inside package, to annif/config.py, so it's available after install. Fixes #196",annif/__init__.py | annif/default_config.py | tests/conftest.py | tests/test_cli.py,source-file | source-file | test-file | test-file,"Doesn't work after install due to configuration handling issue After installing Annif using `python setup.py install` (within a pipenv shell) I cannot run Annif anymore but get this error message: ``` ImportError: No module named 'config' ``` The problem is that `config.py` is not included in the installed package. It could probably be overridden using an environment variable, but there should be a sane default. This blocks the PyPI release (#195) as the same situation will happen when installing a package from PyPI. Merge pull request #198 from NatLibFi/issue188-lazy-result-conversion Issue188 lazy result conversion move config.py inside package, to annif/config.py, so it's available after install. Fixes #196",no-bug,0.9
146,Annif,https://github.com/NatLibFi/Annif/issues/146,make eval and optimize CLI commands accept a TSV file instead of a directory,After #136 it would be possible to use TSV files as input for evaldir and optimize commands,Merge pull request #178 from NatLibFi/issue145-documentdirectory-documentcorpus Implement DocumentCorpus interface in DocumentDirectory. Fixes #145,Make the eval CLI command also accept a TSV file as input. Part of #146 | Make optimize CLI command accept a TSV document file as input. Fixes #146 | Merge pull request #179 from NatLibFi/issue146-eval-optimize-docfile TSV file input for eval and optimize. Fixes #146,annif/cli.py | annif/corpus/convert.py | annif/corpus/document.py | annif/corpus/subject.py | annif/corpus/types.py | tests/test_cli.py | annif/cli.py | tests/test_cli.py | annif/cli.py | annif/corpus/convert.py | annif/corpus/document.py | annif/corpus/subject.py | annif/corpus/types.py | tests/test_cli.py,source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file,make eval and optimize CLI commands accept a TSV file instead of a directory After #136 it would be possible to use TSV files as input for evaldir and optimize commands Merge pull request #178 from NatLibFi/issue145-documentdirectory-documentcorpus Implement DocumentCorpus interface in DocumentDirectory. Fixes #145 Make the eval CLI command also accept a TSV file as input. Part of #146 Make optimize CLI command accept a TSV document file as input. Fixes #146 Merge pull request #179 from NatLibFi/issue146-eval-optimize-docfile TSV file input for eval and optimize. Fixes #146,no-bug,0.9
377,Annif,https://github.com/NatLibFi/Annif/issues/377,Use sparse arrays for subject vectors,"Currently subject vectors (wrapped by VectorSuggestionResult and ListSuggestionResult objects) are basic, dense NumPy vectors. These take up a lot of RAM, for example a single YSO vector takes about 40,000 subjects * 4 bytes (float32) = 160kB and these add up especially for ensemble backends (pav and nn_ensemble) that need to keep many such vectors in memory. SciPy sparse vectors would likely be much more space-efficient so we should (try to) switch to them. (related to #339)",Merge pull request #376 from NatLibFi/issue342-train-cached-option Implement --cached option for train command,"Store returned scores as sparse vectors in PAV backend, saving RAM (part of #377) | Store also true labels as sparse vectors in PAV backend, saving RAM (part of #377)",annif/backend/pav.py | annif/backend/pav.py,source-file | source-file,"Use sparse arrays for subject vectors Currently subject vectors (wrapped by VectorSuggestionResult and ListSuggestionResult objects) are basic, dense NumPy vectors. These take up a lot of RAM, for example a single YSO vector takes about 40,000 subjects * 4 bytes (float32) = 160kB and these add up especially for ensemble backends (pav and nn_ensemble) that need to keep many such vectors in memory. SciPy sparse vectors would likely be much more space-efficient so we should (try to) switch to them. (related to #339) Merge pull request #376 from NatLibFi/issue342-train-cached-option Implement --cached option for train command Store returned scores as sparse vectors in PAV backend, saving RAM (part of #377) Store also true labels as sparse vectors in PAV backend, saving RAM (part of #377)",no-bug,0.9
357,Annif,https://github.com/NatLibFi/Annif/issues/357,fastText training file incorrectly generated,"While looking at ways to optimize the `fasttext` backend code, I noticed that the code that generates the training file is inconsistent, in particular on [this line](https://github.com/NatLibFi/Annif/blob/master/annif/backend/fasttext.py#L101): doc_subjects[text] = [project.subjects.by_uri(uri) for uri in doc.uris] Here `doc_subjects` is a defaultdict where values are initialized to empty set objects. But in the above code the set gets overwritten by a list. The consequence is that if there are several documents in the training data having the same title (or nearly so), only the subjects of the last one of them will end up in the train file while others are silently discarded. The obvious fix (and the original intent of the code) is to use `.update()` to collect the union of the subjects into the set, but I will have to verify that it doesn't adversely affect the quality of the fastText model before making the change. Another possibility is to keep all the documents with the same title as separate entries in the train file, so that each of them has (potentially) their own set of subjects.",Merge pull request #409 from NatLibFi/CSCfi-issue290-upgrade-fasttext Upgrade fastText to official version 0.9.2,Don't attempt to merge similar documents when creating fasttext train file. Fixes #357,annif/backend/fasttext.py,source-file,"fastText training file incorrectly generated While looking at ways to optimize the `fasttext` backend code, I noticed that the code that generates the training file is inconsistent, in particular on [this line](https://github.com/NatLibFi/Annif/blob/master/annif/backend/fasttext.py#L101): doc_subjects[text] = [project.subjects.by_uri(uri) for uri in doc.uris] Here `doc_subjects` is a defaultdict where values are initialized to empty set objects. But in the above code the set gets overwritten by a list. The consequence is that if there are several documents in the training data having the same title (or nearly so), only the subjects of the last one of them will end up in the train file while others are silently discarded. The obvious fix (and the original intent of the code) is to use `.update()` to collect the union of the subjects into the set, but I will have to verify that it doesn't adversely affect the quality of the fastText model before making the change. Another possibility is to keep all the documents with the same title as separate entries in the train file, so that each of them has (potentially) their own set of subjects. Merge pull request #409 from NatLibFi/CSCfi-issue290-upgrade-fasttext Upgrade fastText to official version 0.9.2 Don't attempt to merge similar documents when creating fasttext train file. Fixes #357",no-bug,0.9
372,Annif,https://github.com/NatLibFi/Annif/issues/372,Maui: TypeError: train() takes 2 positional arguments but 3 were given,"As [reported](https://groups.google.com/d/msg/annif-users/SaPb3tRkEbg/cvqCNRUwAwAJ) by Claudia on annif-users: > both with Annif 0.45.0 and 0.45.1, we face the following error during training with the Maui backend using the 'annif train' command with and without the new backend-param option: > > ``` > [...] > File ""<path_to_annif>/lib/python3.6/site-packages/annif/project.py"", line 171, in train > self.backend.train(corpus, beparams) > TypeError: train() takes 2 positional arguments but 3 were given > ``` > > DEBUG mode does not help seeing the actual train call. This seems likely to be a regression caused by the backend-param feature addition.",Moved docker-compose-portainer.yml to api-instances branch,Adapt the Maui backend for backend parameter overriding. Fixes #372 | Adapt the Maui backend for backend parameter overriding. Fixes #372,annif/backend/maui.py | tests/test_backend_maui.py | annif/backend/maui.py | tests/test_backend_maui.py,source-file | test-file | source-file | test-file,"Maui: TypeError: train() takes 2 positional arguments but 3 were given As [reported](https://groups.google.com/d/msg/annif-users/SaPb3tRkEbg/cvqCNRUwAwAJ) by Claudia on annif-users: > both with Annif 0.45.0 and 0.45.1, we face the following error during training with the Maui backend using the 'annif train' command with and without the new backend-param option: > > ``` > [...] > File ""<path_to_annif>/lib/python3.6/site-packages/annif/project.py"", line 171, in train > self.backend.train(corpus, beparams) > TypeError: train() takes 2 positional arguments but 3 were given > ``` > > DEBUG mode does not help seeing the actual train call. This seems likely to be a regression caused by the backend-param feature addition. Moved docker-compose-portainer.yml to api-instances branch Adapt the Maui backend for backend parameter overriding. Fixes #372 Adapt the Maui backend for backend parameter overriding. Fixes #372",no-bug,0.9
247,Annif,https://github.com/NatLibFi/Annif/issues/247,"eval command sometimes reports precision as ""nan""","For example when using `annif eval` with the 20news dataset, the Precision@K values are reported as `nan`: ``` $ annif eval vw 20news100.tsv Precision (doc avg): 0.09399999999999999 Recall (doc avg): 0.94 F1 score (doc avg): 0.170909090909091 Precision (conc avg): 0.09934443130487655 Recall (conc avg): 0.93 F1 score (conc avg): 0.17739629326278103 Precision (microavg): 0.09494949494949495 Recall (microavg): 0.94 F1 score (microavg): 0.1724770642201835 NDCG: 0.7578547650886536 NDCG@5: 0.7387738112464632 NDCG@10: 0.7578547650886536 Precision@1: nan Precision@3: nan Precision@5: nan LRAP: 0.7025119047619048 True positives: 94 False positives: 896 False negatives: 6 Documents evaluated: 100 ``` PR coming up soon...",Merge pull request #246 from NatLibFi/issue237-access-levels Implement access levels for projects,Avoid returnin nan values for Precision@K. Fixes #247,annif/eval.py,source-file,"eval command sometimes reports precision as ""nan"" For example when using `annif eval` with the 20news dataset, the Precision@K values are reported as `nan`: ``` $ annif eval vw 20news100.tsv Precision (doc avg): 0.09399999999999999 Recall (doc avg): 0.94 F1 score (doc avg): 0.170909090909091 Precision (conc avg): 0.09934443130487655 Recall (conc avg): 0.93 F1 score (conc avg): 0.17739629326278103 Precision (microavg): 0.09494949494949495 Recall (microavg): 0.94 F1 score (microavg): 0.1724770642201835 NDCG: 0.7578547650886536 NDCG@5: 0.7387738112464632 NDCG@10: 0.7578547650886536 Precision@1: nan Precision@3: nan Precision@5: nan LRAP: 0.7025119047619048 True positives: 94 False positives: 896 False negatives: 6 Documents evaluated: 100 ``` PR coming up soon... Merge pull request #246 from NatLibFi/issue237-access-levels Implement access levels for projects Avoid returnin nan values for Precision@K. Fixes #247",no-bug,0.9
453,Annif,https://github.com/NatLibFi/Annif/issues/453,Parallelized eval of nn_ensemble projects hangs,"When running evaluations for new models with four parallel jobs I noticed that evaluation of nn_ensemble projects never finished. Without multiprocessing there was no problem. Minimal example: ``` # projects.cfg: [arch-fasttext] name=FastText language=fi backend=fasttext limit=100 vocab=arch analyzer=snowball(finnish) [arch-nn] name=YSO NN ensemble Finnish language=fi backend=nn_ensemble sources=arch-fasttext limit=100 vocab=arch nodes=100 dropout_rate=0.2 epochs=2 # Testing: annif loadvoc arch-fasttext tests/corpora/archaeology/subjects.tsv annif train arch-fasttext tests/corpora/archaeology/documents.tsv annif train arch-nn tests/corpora/archaeology/fulltext/ time annif eval arch-nn tests/corpora/archaeology/documents.tsv --jobs 1 # finishes in 3 min time annif eval arch-nn tests/corpora/archaeology/documents.tsv --jobs 2 # won't finish ``` This seems to be a common problem, there's many search results for ""python multiprocess hangs when calling a tensorflow model"". The problem occurs at least with TF versions 2.2.0 and 2.3.1. A quick fix could be to throw a `NotSupportedException` instead of indefinite freeze. Parallelized eval was not promised to work with nn_ensemble when the feature was implemented in #418.",Avoid initializing project twice,Avoid loading TF models just before parallel execution in eval. Fixes #453,annif/backend/backend.py | annif/backend/dummy.py | annif/backend/ensemble.py | annif/backend/fasttext.py | annif/backend/mllm.py | annif/backend/nn_ensemble.py | annif/backend/omikuji.py | annif/backend/pav.py | annif/backend/stwfsa.py | annif/backend/svc.py | annif/backend/tfidf.py | annif/backend/vw_multi.py | annif/backend/yake.py | annif/cli.py | annif/project.py,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Parallelized eval of nn_ensemble projects hangs When running evaluations for new models with four parallel jobs I noticed that evaluation of nn_ensemble projects never finished. Without multiprocessing there was no problem. Minimal example: ``` # projects.cfg: [arch-fasttext] name=FastText language=fi backend=fasttext limit=100 vocab=arch analyzer=snowball(finnish) [arch-nn] name=YSO NN ensemble Finnish language=fi backend=nn_ensemble sources=arch-fasttext limit=100 vocab=arch nodes=100 dropout_rate=0.2 epochs=2 # Testing: annif loadvoc arch-fasttext tests/corpora/archaeology/subjects.tsv annif train arch-fasttext tests/corpora/archaeology/documents.tsv annif train arch-nn tests/corpora/archaeology/fulltext/ time annif eval arch-nn tests/corpora/archaeology/documents.tsv --jobs 1 # finishes in 3 min time annif eval arch-nn tests/corpora/archaeology/documents.tsv --jobs 2 # won't finish ``` This seems to be a common problem, there's many search results for ""python multiprocess hangs when calling a tensorflow model"". The problem occurs at least with TF versions 2.2.0 and 2.3.1. A quick fix could be to throw a `NotSupportedException` instead of indefinite freeze. Parallelized eval was not promised to work with nn_ensemble when the feature was implemented in #418. Avoid initializing project twice Avoid loading TF models just before parallel execution in eval. Fixes #453",no-bug,0.9
48,Annif,https://github.com/NatLibFi/Annif/issues/48,HTTP/REST client backend,"We need a backend that can make a call to a REST service, e.g. api.annif.org or the upcoming MauiService.",better dummy backend + fix bug in project.analyze,Implement HTTP backend. Fixes #48 | Implement HTTP backend. Fixes #48 | Merge pull request #49 from NatLibFi/http-backend Implement HTTP backend. Fixes #48,annif/backend/__init__.py | backends.cfg | projects.cfg | requirements.txt | annif/backend/__init__.py | annif/backend/http.py | backends.cfg | projects.cfg | requirements.txt | tests/test_backend_http.py | annif/backend/__init__.py | annif/backend/http.py | backends.cfg | projects.cfg | requirements.txt | tests/test_backend_http.py,source-file | other-file | other-file | other-file | source-file | source-file | other-file | other-file | other-file | test-file | source-file | source-file | other-file | other-file | other-file | test-file,"HTTP/REST client backend We need a backend that can make a call to a REST service, e.g. api.annif.org or the upcoming MauiService. better dummy backend + fix bug in project.analyze Implement HTTP backend. Fixes #48 Implement HTTP backend. Fixes #48 Merge pull request #49 from NatLibFi/http-backend Implement HTTP backend. Fixes #48",no-bug,0.9
374,Annif,https://github.com/NatLibFi/Annif/issues/374,spaCy analyzer,"We could add an analyzer based on spaCy. It would enable support for some new languages and possibly also give better results for eg English and German than the current snowball analyzer. Getting the full benefit of spaCy may require some internal API changes because it is more object oriented than NLTK and processes whole sentences instead of just individual words, taking some of the context into account. This would be an optional feature as spaCy is implemented as a native code extension, not just pure Python.",Merge pull request #525 from NatLibFi/fix-loadvoc-update-contains-uri-performance Much faster updating of existing large vocabulary,Initial version of spaCy analyzer (#374) | Initial version of spaCy analyzer (#374) | Initial version of spaCy analyzer (#374),annif/analyzer/__init__.py | annif/analyzer/spacy.py | setup.py | tests/test_analyzer_spacy.py | annif/analyzer/__init__.py | annif/analyzer/spacy.py | setup.py | tests/test_analyzer_spacy.py | annif/analyzer/__init__.py | annif/analyzer/spacy.py | setup.py | tests/test_analyzer_spacy.py,source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file,"spaCy analyzer We could add an analyzer based on spaCy. It would enable support for some new languages and possibly also give better results for eg English and German than the current snowball analyzer. Getting the full benefit of spaCy may require some internal API changes because it is more object oriented than NLTK and processes whole sentences instead of just individual words, taking some of the context into account. This would be an optional feature as spaCy is implemented as a native code extension, not just pure Python. Merge pull request #525 from NatLibFi/fix-loadvoc-update-contains-uri-performance Much faster updating of existing large vocabulary Initial version of spaCy analyzer (#374) Initial version of spaCy analyzer (#374) Initial version of spaCy analyzer (#374)",no-bug,0.9
72,Annif,https://github.com/NatLibFi/Annif/issues/72,nDCG should consider number of subjects,I think the current nDCG measure is a bit wrong in situations where the number of predicted subjects is different from the number of gold standard subjects (i.e. very often). This should be taken into account somehow - perhaps by specifying that we always use nDCG@K where K is e.g. 5.,Merge pull request #71 from NatLibFi/more-eval-measures More eval measures. Fixes #64,"Implement NDCG@K measure (K=5,10). Fixes #72 | Merge pull request #73 from NatLibFi/ndcg-at-k Implement NDCG@K measure (K=5,10). Fixes #72",annif/eval.py | tests/test_eval.py | annif/eval.py | tests/test_eval.py,source-file | test-file | source-file | test-file,"nDCG should consider number of subjects I think the current nDCG measure is a bit wrong in situations where the number of predicted subjects is different from the number of gold standard subjects (i.e. very often). This should be taken into account somehow - perhaps by specifying that we always use nDCG@K where K is e.g. 5. Merge pull request #71 from NatLibFi/more-eval-measures More eval measures. Fixes #64 Implement NDCG@K measure (K=5,10). Fixes #72 Merge pull request #73 from NatLibFi/ndcg-at-k Implement NDCG@K measure (K=5,10). Fixes #72",no-bug,0.9
97,Annif,https://github.com/NatLibFi/Annif/issues/97,Align analyze and analyzedir output formats,"The analyze and analyzedir TSV outputs are in different order. Should use uri, label, score for both",Merge pull request #99 from NatLibFi/issue93-merge-hits-take2 Divide hit weights by sum of backend weights. Fixes #93,Align analyze and analyzedir output formats. Fixes #97 | Merge pull request #100 from NatLibFi/issue97-align-analyze-output Align analyze and analyzedir output formats. Fixes #97,annif/cli.py | tests/test_cli.py | annif/cli.py | tests/test_cli.py,source-file | test-file | source-file | test-file,"Align analyze and analyzedir output formats The analyze and analyzedir TSV outputs are in different order. Should use uri, label, score for both Merge pull request #99 from NatLibFi/issue93-merge-hits-take2 Divide hit weights by sum of backend weights. Fixes #93 Align analyze and analyzedir output formats. Fixes #97 Merge pull request #100 from NatLibFi/issue97-align-analyze-output Align analyze and analyzedir output formats. Fixes #97",no-bug,0.7
237,Annif,https://github.com/NatLibFi/Annif/issues/237,Access levels for projects,"Often you have many projects and only some of them are useful to expose. A per-project access level setting could control visibility. Levels public, hidden, private",Adjust columns for list-project to account for longer project IDs and names,Implement access levels for projects. Fixes #237,annif/cli.py | annif/project.py | annif/rest.py | tests/projects.cfg | tests/test_cli.py | tests/test_project.py | tests/test_rest.py,source-file | source-file | source-file | test-file | test-file | test-file | test-file,"Access levels for projects Often you have many projects and only some of them are useful to expose. A per-project access level setting could control visibility. Levels public, hidden, private Adjust columns for list-project to account for longer project IDs and names Implement access levels for projects. Fixes #237",no-bug,0.9
321,Annif,https://github.com/NatLibFi/Annif/issues/321,Automate results in optional weights in ensemble/PAV/VW,"There is a lot of options when using optional weights in ensemble/PAV/VW. it would be good if there could be some way to automate testing of eval in these different weights, for example in optimize-command Annif could go through different weigh and suggest the best combination to user. backend1:1,backend2:1,backend2:1 -> backend1:1,backend2:1,backend2:2 -> backend1:1,backend2:2,backend2:2 etc.",Merge pull request #412 from NatLibFi/fasttext-version-0.9.2 Pin fasttext version to 0.9.2 and fix fasttext version in Dockerfile,Initial implementation: hyperparameter optimization of ensemble weights. Fixes #321 | Initial implementation: hyperparameter optimization of ensemble weights. Fixes #321,annif/backend/ensemble.py | annif/cli.py | annif/project.py | setup.py | annif/backend/ensemble.py | annif/backend/hyperopt.py | annif/cli.py | annif/project.py | setup.py,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Automate results in optional weights in ensemble/PAV/VW There is a lot of options when using optional weights in ensemble/PAV/VW. it would be good if there could be some way to automate testing of eval in these different weights, for example in optimize-command Annif could go through different weigh and suggest the best combination to user. backend1:1,backend2:1,backend2:1 -> backend1:1,backend2:1,backend2:2 -> backend1:1,backend2:2,backend2:2 etc. Merge pull request #412 from NatLibFi/fasttext-version-0.9.2 Pin fasttext version to 0.9.2 and fix fasttext version in Dockerfile Initial implementation: hyperparameter optimization of ensemble weights. Fixes #321 Initial implementation: hyperparameter optimization of ensemble weights. Fixes #321",no-bug,0.9
205,Annif,https://github.com/NatLibFi/Annif/issues/205,Invalid conversion from list to vector,I noticed that conversion of ListAnalysisResult to vector breaks if the list of URIs contains an unknown URI. In that case the vector will be set to all ones.,Bump version: 0.35.0 → 0.36.0,Fix bug when unknown subject URIs caused invalid conversion from list to vector. Fixes #205,annif/hit.py | tests/test_hit.py,source-file | test-file,Invalid conversion from list to vector I noticed that conversion of ListAnalysisResult to vector breaks if the list of URIs contains an unknown URI. In that case the vector will be set to all ones. Bump version: 0.35.0 → 0.36.0 Fix bug when unknown subject URIs caused invalid conversion from list to vector. Fixes #205,no-bug,0.7
667,Annif,https://github.com/NatLibFi/Annif/issues/667,Support batch suggest in SVC backend,PR #663 is going to bring support for batch suggest operations. The SVC backend could benefit from implementing _suggest_batch instead of _suggest. It could process a batch of texts with parallel and/or vector operations.,Merge pull request #669 from NatLibFi/issue663-suggest-batch-omikuji Batch suggest in Omikuji backend,Implement batched suggest in SVC backend. Fixes #667 | Implement batched suggest in SVC backend. Fixes #667,annif/backend/svc.py | annif/backend/svc.py,source-file | source-file,Support batch suggest in SVC backend PR #663 is going to bring support for batch suggest operations. The SVC backend could benefit from implementing _suggest_batch instead of _suggest. It could process a batch of texts with parallel and/or vector operations. Merge pull request #669 from NatLibFi/issue663-suggest-batch-omikuji Batch suggest in Omikuji backend Implement batched suggest in SVC backend. Fixes #667 Implement batched suggest in SVC backend. Fixes #667,no-bug,0.8
235,Annif,https://github.com/NatLibFi/Annif/issues/235,Vowpal Wabbit ensemble backend,Separated out from #230 : Create a `vw_ensemble` backend that can combine results from multiple projects; similar to `pav` but using a VW classifier/regression model that can be updated later on.,Make sure all projects are initialized when they are used for suggesting,Initial implementation of vw_ensemble backend. Fixes #235,annif/backend/__init__.py | annif/backend/ensemble.py | annif/backend/mixins.py | annif/backend/vw_ensemble.py | annif/backend/vw_multi.py | tests/conftest.py | tests/test_backend_vw_ensemble.py,source-file | source-file | source-file | source-file | source-file | test-file | test-file,Vowpal Wabbit ensemble backend Separated out from #230 : Create a `vw_ensemble` backend that can combine results from multiple projects; similar to `pav` but using a VW classifier/regression model that can be updated later on. Make sure all projects are initialized when they are used for suggesting Initial implementation of vw_ensemble backend. Fixes #235,no-bug,0.9
3,Annif,https://github.com/NatLibFi/Annif/issues/3,Initial framework with Elasticsearch,"The first version of the framework should have * a Flask app that can be started using ""flask run"" * a command ""flask init"" that creates the repository for projects in Elasticsearch * tests for the above, running within Travis CI",Add project type,Implement createProject and dropProject. Fixes #3. | Merge pull request #3 from NatLibFi/master Forward to 0.51,annif/annif.py | tests/test_annif.py | annif/backend/maui.py | annif/backend/nn_ensemble.py | annif/cli.py | annif/corpus/__init__.py | annif/corpus/document.py | annif/util.py | setup.cfg | setup.py | tests/test_backend_maui.py | tests/test_cli.py | tests/test_corpus.py,source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | test-file | test-file | test-file,"Initial framework with Elasticsearch The first version of the framework should have * a Flask app that can be started using ""flask run"" * a command ""flask init"" that creates the repository for projects in Elasticsearch * tests for the above, running within Travis CI Add project type Implement createProject and dropProject. Fixes #3. Merge pull request #3 from NatLibFi/master Forward to 0.51",no-bug,0.9
547,Annif,https://github.com/NatLibFi/Annif/issues/547,Configuration file format compatible with DVC,"To make it possible to use Annif productively in a [DVC](https://dvc.org/) workflow, it would be helpful if DVC tools could read parameters directly from the Annif configuration file. DVC can currently read parameters from YAML 1.2, JSON, TOML and Python files (see documentation for [dvc params](https://dvc.org/doc/command-reference/params)). Annif uses INI-style syntax (supported by [configparser](https://docs.python.org/3/library/configparser.html) Python standard library module) in the `projects.cfg` configuration file. This is similar to TOML, but not identical. I can think of at least these options for making the Annif configuration file DVC-compatible: 1. Support YAML configuration files as an alternative to the current format. 2. Support JSON configuration files as an alternative to the current format. 3. Support TOML configuration files as an alternative to the current format. 4. Adjust the current format slightly so that it becomes a valid subset of TOML. I think we can rule out 2., because JSON is not very nice as a configuration language because of its strict syntax and lack of support for comments. If we want a new configuration format, either YAML (option 1) or TOML (option 3) is better. For 4., AFAICT the main difference between the current syntax and TOML is that TOML requires string values to be quoted. So instead of this: ``` [tfidf-en] language=en backend=tfidf analyzer=snowball(english) limit=100 vocab=yso-en ``` the syntax must be ``` [tfidf-en] language=""en"" backend=""tfidf"" analyzer=""snowball(english)"" limit=100 vocab=""yso-en"" ``` (note that `limit` can be left as-is, as the value 100 is an integer, not a string) This syntax doesn't work with ConfigParser currently, because it includes the quotes as part of the value. But it would be simple to change the `optionxform` so that it drops any quotes from the value. The file name `projects.cfg` could still be a problem for DVC, which would probably expect the extension `.toml` so that it recognizes which syntax to use.",Merge pull request #558 from NatLibFi/issue545-eval-metric-option Add --metric/-m option to eval command to select metric(s),"Allow string values to be quoted in the config file, similar to TOML syntax. Related to #547 | Support TOML as a configuration file format alongside CFG/INI. Fixes #547 | Support TOML as a configuration file format alongside CFG/INI. Fixes #547 | Support TOML as a configuration file format alongside CFG/INI. Fixes #547",annif/registry.py | tests/projects.cfg | annif/cli.py | annif/default_config.py | annif/registry.py | setup.py | tests/test_project.py | annif/cli.py | annif/default_config.py | annif/registry.py | setup.py | tests/projects.toml | tests/test_project.py | annif/cli.py | annif/default_config.py | annif/registry.py | setup.py | tests/projects.toml | tests/test_project.py,source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | test-file | test-file,"Configuration file format compatible with DVC To make it possible to use Annif productively in a [DVC](https://dvc.org/) workflow, it would be helpful if DVC tools could read parameters directly from the Annif configuration file. DVC can currently read parameters from YAML 1.2, JSON, TOML and Python files (see documentation for [dvc params](https://dvc.org/doc/command-reference/params)). Annif uses INI-style syntax (supported by [configparser](https://docs.python.org/3/library/configparser.html) Python standard library module) in the `projects.cfg` configuration file. This is similar to TOML, but not identical. I can think of at least these options for making the Annif configuration file DVC-compatible: 1. Support YAML configuration files as an alternative to the current format. 2. Support JSON configuration files as an alternative to the current format. 3. Support TOML configuration files as an alternative to the current format. 4. Adjust the current format slightly so that it becomes a valid subset of TOML. I think we can rule out 2., because JSON is not very nice as a configuration language because of its strict syntax and lack of support for comments. If we want a new configuration format, either YAML (option 1) or TOML (option 3) is better. For 4., AFAICT the main difference between the current syntax and TOML is that TOML requires string values to be quoted. So instead of this: ``` [tfidf-en] language=en backend=tfidf analyzer=snowball(english) limit=100 vocab=yso-en ``` the syntax must be ``` [tfidf-en] language=""en"" backend=""tfidf"" analyzer=""snowball(english)"" limit=100 vocab=""yso-en"" ``` (note that `limit` can be left as-is, as the value 100 is an integer, not a string) This syntax doesn't work with ConfigParser currently, because it includes the quotes as part of the value. But it would be simple to change the `optionxform` so that it drops any quotes from the value. The file name `projects.cfg` could still be a problem for DVC, which would probably expect the extension `.toml` so that it recognizes which syntax to use. Merge pull request #558 from NatLibFi/issue545-eval-metric-option Add --metric/-m option to eval command to select metric(s) Allow string values to be quoted in the config file, similar to TOML syntax. Related to #547 Support TOML as a configuration file format alongside CFG/INI. Fixes #547 Support TOML as a configuration file format alongside CFG/INI. Fixes #547 Support TOML as a configuration file format alongside CFG/INI. Fixes #547",no-bug,0.9
236,Annif,https://github.com/NatLibFi/Annif/issues/236,Optimize command is really slow,"There is something wrong with the optimize command. It used to be fast, but now it can take several minutes just to produce the table of results. I suspect this has to do with converting analysis results from lists to vectors (or vice versa) when evaluating different limit and threshold settings.",Merge pull request #234 from NatLibFi/rename-load-to-train Rename load_documents and load_corpus methods to train,Make HitFilter lazy. Helps to conserve a lot of RAM especially in optimize command. Part of #236 | Fix (again) high memory usage in optimize command. Fixes #236,annif/cli.py | annif/eval.py | annif/hit.py | annif/rest.py | tests/test_hit.py | annif/cli.py,source-file | source-file | source-file | source-file | test-file | source-file,"Optimize command is really slow There is something wrong with the optimize command. It used to be fast, but now it can take several minutes just to produce the table of results. I suspect this has to do with converting analysis results from lists to vectors (or vice versa) when evaluating different limit and threshold settings. Merge pull request #234 from NatLibFi/rename-load-to-train Rename load_documents and load_corpus methods to train Make HitFilter lazy. Helps to conserve a lot of RAM especially in optimize command. Part of #236 Fix (again) high memory usage in optimize command. Fixes #236",no-bug,0.9
53,Annif,https://github.com/NatLibFi/Annif/issues/53,Analyzers with parameters,"Currently we have three analyzers (fi, sv, en) all based on NLTK SnowballStemmer. This leads to duplicated code. Adding more languages would imply adding more analyzers. We could instead have just one SnowballAnalyzer that takes a language parameter. Then it could be configured like this: ``` analyzer=snowball(finnish) ``` or why not ``` analyzer=snowball(french) ``` A similar approach would work for libvoikko (#37) which supports several languages: ``` analyzer=voikko(fi) ``` The parameter would be passed directly to the algorithm so all languages supported by the stemmers/lemmatizers would be available.",Merge pull request #58 from NatLibFi/subject-corpus Subject corpus functionality,Combine Snowball analyzers into one parametrized analyzer. Fixes #53,annif/analyzer/__init__.py | annif/analyzer/english.py | annif/analyzer/finnish.py | annif/analyzer/snowball.py | annif/analyzer/swedish.py | projects.cfg | tests/test_analyzer.py | tests/test_project.py,source-file | source-file | source-file | source-file | source-file | other-file | test-file | test-file,"Analyzers with parameters Currently we have three analyzers (fi, sv, en) all based on NLTK SnowballStemmer. This leads to duplicated code. Adding more languages would imply adding more analyzers. We could instead have just one SnowballAnalyzer that takes a language parameter. Then it could be configured like this: ``` analyzer=snowball(finnish) ``` or why not ``` analyzer=snowball(french) ``` A similar approach would work for libvoikko (#37) which supports several languages: ``` analyzer=voikko(fi) ``` The parameter would be passed directly to the algorithm so all languages supported by the stemmers/lemmatizers would be available. Merge pull request #58 from NatLibFi/subject-corpus Subject corpus functionality Combine Snowball analyzers into one parametrized analyzer. Fixes #53",no-bug,0.9
590,Annif,https://github.com/NatLibFi/Annif/issues/590,Simplemma analyzer,"Just like with spaCy (see #374) we could add an analyzer that uses [simplemma](https://github.com/adbar/simplemma/) for lemmatization. This is a very fast and lightweight multilingual lemmatizer which currently supports 38 languages. The lemmatization accuracy may not be as high as with e.g. Stanza (see #539) but in practice that doesn't seem to matter much based on experiments I've performed. Simplemma is implemented in pure Python without external dependencies so I think it should be possible to include this as a core feature, not an optional one, unless there are any unexpected problems with e.g. supported Python versions.",Delete .coveragerc (#588) This file seems to be unnecessary nowdays.,"initial version of simplemma analyzer, fixes #590",annif/analyzer/__init__.py | annif/analyzer/simplemma.py | setup.py,source-file | source-file | source-file,"Simplemma analyzer Just like with spaCy (see #374) we could add an analyzer that uses [simplemma](https://github.com/adbar/simplemma/) for lemmatization. This is a very fast and lightweight multilingual lemmatizer which currently supports 38 languages. The lemmatization accuracy may not be as high as with e.g. Stanza (see #539) but in practice that doesn't seem to matter much based on experiments I've performed. Simplemma is implemented in pure Python without external dependencies so I think it should be possible to include this as a core feature, not an optional one, unless there are any unexpected problems with e.g. supported Python versions. Delete .coveragerc (#588) This file seems to be unnecessary nowdays. initial version of simplemma analyzer, fixes #590",no-bug,0.95
21,Annif,https://github.com/NatLibFi/Annif/issues/21,Evaluation against a gold standard,"We could support a command for evaluating how well Annif performs when compared against a gold standard (one or more manually created subject sets per document). The CLI command for a single document could be: annif eval <projectid> <subjectfile> <document.txt and the corresponding REST API operation would be POST /projects/<projectid>/evaluate with the subjects and document text passed in the body. The result should be metrics including precision, recall, F-measure and Rolling similarity. A batch operation for directories could be annif evaldir <projectid> <directory> --maxdocs 10 The maxdocs parameter would limit the evaluation to a random sample of the given number of documents. The reported metrics would be averaged over the sampled documents.",evaluation metric functions,Basic evaluation support (one document at a time via CLI). Part of #21,annif/cli.py | annif/corpus/__init__.py | tests/test_cli.py | tests/test_corpus.py,source-file | source-file | test-file | test-file,"Evaluation against a gold standard We could support a command for evaluating how well Annif performs when compared against a gold standard (one or more manually created subject sets per document). The CLI command for a single document could be: annif eval <projectid> <subjectfile> <document.txt and the corresponding REST API operation would be POST /projects/<projectid>/evaluate with the subjects and document text passed in the body. The result should be metrics including precision, recall, F-measure and Rolling similarity. A batch operation for directories could be annif evaldir <projectid> <directory> --maxdocs 10 The maxdocs parameter would limit the evaluation to a random sample of the given number of documents. The reported metrics would be averaged over the sampled documents. evaluation metric functions Basic evaluation support (one document at a time via CLI). Part of #21",no-bug,0.8
546,Annif,https://github.com/NatLibFi/Annif/issues/546,Eval metrics file output compatible with DVC,"To make it possible to use Annif in [DVC](https://dvc.org/) workflows, Annif should be able to produce a metrics file in a format that DVC understands, i.e. either JSON or YAML 1.2 (see documentation for [dvc metrics](https://dvc.org/doc/command-reference/metrics)). Example command: annif eval my-project --metrics-file metrics.json /path/to/my-test-corpus/ and the created `metrics.json` file would look something like this: ``` { ""Precision (doc avg)"": 0.1560, ""Recall (doc avg)"": 0.2333, ... ""F1@5"": 0.1789, ... ""Documents evaluated"": 300 } ``` The option could be named `-M` or `--metrics-file`. It's possible that the selection of metrics should be reduced - the default set is quite large and this may be cumbersome to deal with in DVC. It would be helpful to implement also an option to select which metrics to calculate (see #545). Also, DVC may not like the current naming of the metrics which includes capital letters, spaces and parentheses (e.g. `F1 score (doc avg)`) and perhaps it would be better to use names like `f1_score_doc_avg`.",Merge pull request #527 from NatLibFi/issue374-spacy-analyzer Add spaCy analyzer,Output eval metrics as a JSON file. Fixes #546,annif/cli.py | annif/eval.py | tests/test_cli.py,source-file | source-file | test-file,"Eval metrics file output compatible with DVC To make it possible to use Annif in [DVC](https://dvc.org/) workflows, Annif should be able to produce a metrics file in a format that DVC understands, i.e. either JSON or YAML 1.2 (see documentation for [dvc metrics](https://dvc.org/doc/command-reference/metrics)). Example command: annif eval my-project --metrics-file metrics.json /path/to/my-test-corpus/ and the created `metrics.json` file would look something like this: ``` { ""Precision (doc avg)"": 0.1560, ""Recall (doc avg)"": 0.2333, ... ""F1@5"": 0.1789, ... ""Documents evaluated"": 300 } ``` The option could be named `-M` or `--metrics-file`. It's possible that the selection of metrics should be reduced - the default set is quite large and this may be cumbersome to deal with in DVC. It would be helpful to implement also an option to select which metrics to calculate (see #545). Also, DVC may not like the current naming of the metrics which includes capital letters, spaces and parentheses (e.g. `F1 score (doc avg)`) and perhaps it would be better to use names like `f1_score_doc_avg`. Merge pull request #527 from NatLibFi/issue374-spacy-analyzer Add spaCy analyzer Output eval metrics as a JSON file. Fixes #546",no-bug,0.9
355,Annif,https://github.com/NatLibFi/Annif/issues/355,Epoch-parameter for nn_ensemble learn-command,"Maybe it would be useful to add epoch-parameter to the nn_ensemble learn-command. This could be used, if there is lot of data for learn-command, 1000 documents or more. Default value would be 1 like now, because when there is only one or few additional data to learn, additional learning cycles would likely cause only harm.",Merge pull request #354 from NatLibFi/feature-eval-f1-at-5 Add F1@5 evaluation metric,Add learn-epochs parameter for nn_ensemble backend. Fixes #355,annif/backend/nn_ensemble.py,source-file,"Epoch-parameter for nn_ensemble learn-command Maybe it would be useful to add epoch-parameter to the nn_ensemble learn-command. This could be used, if there is lot of data for learn-command, 1000 documents or more. Default value would be 1 like now, because when there is only one or few additional data to learn, additional learning cycles would likely cause only harm. Merge pull request #354 from NatLibFi/feature-eval-f1-at-5 Add F1@5 evaluation metric Add learn-epochs parameter for nn_ensemble backend. Fixes #355",no-bug,0.9
188,Annif,https://github.com/NatLibFi/Annif/issues/188,Merge results using NumPy operations,Currently Annif merges hits using annif.util.merge_hits. It is used both by AnnifProject and the ensemble backend. The current implementation is unnecessarily complex. Nowadays we can use as_vector and from_vector to turn hits (AnalysisResult objects) into a NumPy array and back. The merging should be done with NumPy operations.,"Set Markdown content type and add Trove classifiers, to help with eventual PyPI release (#195)","Merge results using NumPy operations. Part of #188 | Merge pull request #197 from NatLibFi/issue188-numpy-merge-results Merge results using NumPy operations. Part of #188 | Initial code which lazily converts between vectors and lists-of-hits. Part of #188 | Different representation of list-based and vector-based AnalysisResults and efficient operations on them, including conversion. Fixes #188",annif/backend/ensemble.py | annif/hit.py | annif/project.py | annif/util.py | tests/test_cli.py | tests/test_project.py | annif/backend/ensemble.py | annif/hit.py | annif/project.py | annif/util.py | tests/conftest.py | tests/corpora/dummy-subjects.tsv | tests/projects.cfg | tests/test_cli.py | annif/hit.py | annif/backend/dummy.py | annif/backend/fasttext.py | annif/backend/http.py | annif/backend/tfidf.py | annif/eval.py | annif/hit.py | annif/util.py | tests/conftest.py | tests/test_backend.py | tests/test_backend_fasttext.py | tests/test_backend_http.py | tests/test_eval.py | tests/test_hit.py,source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file,"Merge results using NumPy operations Currently Annif merges hits using annif.util.merge_hits. It is used both by AnnifProject and the ensemble backend. The current implementation is unnecessarily complex. Nowadays we can use as_vector and from_vector to turn hits (AnalysisResult objects) into a NumPy array and back. The merging should be done with NumPy operations. Set Markdown content type and add Trove classifiers, to help with eventual PyPI release (#195) Merge results using NumPy operations. Part of #188 Merge pull request #197 from NatLibFi/issue188-numpy-merge-results Merge results using NumPy operations. Part of #188 Initial code which lazily converts between vectors and lists-of-hits. Part of #188 Different representation of list-based and vector-based AnalysisResults and efficient operations on them, including conversion. Fixes #188",no-bug,0.9
155,Annif,https://github.com/NatLibFi/Annif/issues/155,Make projects.cfg into an example file,Rename projects.cfg to projects.cfg.dist so that deployments may use their own configuration files.,Remove unused imports,Rename projects.cfg into projects.cfg.dist so deployments can use their own copy. Fixes #155 | Merge pull request #156 from NatLibFi/issue155-example-config Rename projects.cfg into projects.cfg.dist so deployments can use their own copy. Fixes #155,.gitignore | projects.cfg.dist | .gitignore | projects.cfg.dist,other-file | other-file | other-file | other-file,Make projects.cfg into an example file Rename projects.cfg to projects.cfg.dist so that deployments may use their own configuration files. Remove unused imports Rename projects.cfg into projects.cfg.dist so deployments can use their own copy. Fixes #155 Merge pull request #156 from NatLibFi/issue155-example-config Rename projects.cfg into projects.cfg.dist so deployments can use their own copy. Fixes #155,no-bug,0.9
8,Annif,https://github.com/NatLibFi/Annif/issues/8,Implement project administration commands,"CLI implementation of: * create-project * list-projects * show-project * drop-project With unit tests, naturally","remove Code Climate config, doesn't seem to work",Implement project admin commands. Fixes #8 | Merge pull request #26 from NatLibFi/issue8 Implement project admin commands. Fixes #8,annif/annif.py | tests/test_annif.py | annif/annif.py | tests/test_annif.py,source-file | test-file | source-file | test-file,"Implement project administration commands CLI implementation of: * create-project * list-projects * show-project * drop-project With unit tests, naturally remove Code Climate config, doesn't seem to work Implement project admin commands. Fixes #8 Merge pull request #26 from NatLibFi/issue8 Implement project admin commands. Fixes #8",no-bug,0.9
268,Annif,https://github.com/NatLibFi/Annif/issues/268,Rename REST analyze method to suggest,"Similar to #267, I'd like to rename the REST method `analyze` to `suggest`, following the example of the [Maui Server API](https://github.com/TopQuadrant/MauiServer/blob/master/API.md). The wiki documentation needs to be updated and probably there should be some transition mechanism in place on api.annif.org so that existing clients don't suddenly break.",Merge pull request #270 from NatLibFi/issue267-cli-analyze-to-suggest Rename CLI command analyze to suggest and refactor method names,"Rename REST ""analyze"" method to ""suggest"". Fixes #268",annif/rest.py | annif/swagger/annif.yaml | annif/templates/home.html | tests/test_rest.py,source-file | documentation-file | other-file | test-file,"Rename REST analyze method to suggest Similar to #267, I'd like to rename the REST method `analyze` to `suggest`, following the example of the [Maui Server API](https://github.com/TopQuadrant/MauiServer/blob/master/API.md). The wiki documentation needs to be updated and probably there should be some transition mechanism in place on api.annif.org so that existing clients don't suddenly break. Merge pull request #270 from NatLibFi/issue267-cli-analyze-to-suggest Rename CLI command analyze to suggest and refactor method names Rename REST ""analyze"" method to ""suggest"". Fixes #268",no-bug,0.9
216,Annif,https://github.com/NatLibFi/Annif/issues/216,Helpful warning about missing projects.cfg,"Currently when executing `annif` after a fresh PyPI install I get this: ``` Traceback (most recent call last): File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/flask/cli.py"", line 529, in list_commands rv.update(info.load_app().cli.list_commands(ctx)) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/flask/cli.py"", line 367, in load_app app = call_factory(self, self.create_app) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/flask/cli.py"", line 110, in call_factory return app_factory(*arguments, script_info=script_info) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/annif/__init__.py"", line 36, in create_app annif.project.initialize_projects(cxapp.app) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/annif/project.py"", line 219, in initialize_projects projects_file, datadir, init_projects) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/annif/project.py"", line 200, in _create_projects with open(projects_file) as projf: FileNotFoundError: [Errno 2] No such file or directory: 'projects.cfg' ``` We should avoid displaying a traceback and instead explain that `projects.cfg` is missing and that `ANNIF_PROJECTS` can be used to specify where to look for it.",Bump version: 0.36.4 → 0.36.5,Helpful warning when projects.cfg file is missing. Fixes #216 | Add unit test that checks for how missing projects.cfg is handled (#216) | Merge pull request #217 from NatLibFi/issue216-missing-projects-cfg Helpful warning when projects.cfg file is missing. Fixes #216,annif/project.py | annif/default_config.py | tests/test_project.py | annif/default_config.py | annif/project.py | tests/test_project.py,source-file | source-file | test-file | source-file | source-file | test-file,"Helpful warning about missing projects.cfg Currently when executing `annif` after a fresh PyPI install I get this: ``` Traceback (most recent call last): File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/flask/cli.py"", line 529, in list_commands rv.update(info.load_app().cli.list_commands(ctx)) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/flask/cli.py"", line 367, in load_app app = call_factory(self, self.create_app) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/flask/cli.py"", line 110, in call_factory return app_factory(*arguments, script_info=script_info) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/annif/__init__.py"", line 36, in create_app annif.project.initialize_projects(cxapp.app) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/annif/project.py"", line 219, in initialize_projects projects_file, datadir, init_projects) File ""/home/oisuomin/tmp/annif-pypi/annif-venv/lib/python3.5/site-packages/annif/project.py"", line 200, in _create_projects with open(projects_file) as projf: FileNotFoundError: [Errno 2] No such file or directory: 'projects.cfg' ``` We should avoid displaying a traceback and instead explain that `projects.cfg` is missing and that `ANNIF_PROJECTS` can be used to specify where to look for it. Bump version: 0.36.4 → 0.36.5 Helpful warning when projects.cfg file is missing. Fixes #216 Add unit test that checks for how missing projects.cfg is handled (#216) Merge pull request #217 from NatLibFi/issue216-missing-projects-cfg Helpful warning when projects.cfg file is missing. Fixes #216",no-bug,0.9
2,Annif,https://github.com/NatLibFi/Annif/issues/2,CLI specification,"We need a specification of the CLI commands (with REST equivalents when applicable), for example as a Markdown file or a Wiki page. This should be written in a form that will serve as user documentation later on.",First draft of Swagger/OpenAPI spec. Fixes #1,First part of CLI specification. Part of #2 | Merge pull request #2 from NatLibFi/master Update to current master 20200814,doc/commands.md | Dockerfile | README.md | annif/__init__.py | annif/backend/backend.py | annif/backend/dummy.py | annif/backend/ensemble.py | annif/backend/fasttext.py | annif/backend/http.py | annif/backend/hyperopt.py | annif/backend/maui.py | annif/backend/mixins.py | annif/backend/nn_ensemble.py | annif/backend/omikuji.py | annif/backend/pav.py | annif/backend/tfidf.py | annif/backend/vw_multi.py | annif/cli.py | annif/corpus/subject.py | annif/datadir.py | annif/eval.py | annif/parallel.py | annif/project.py | annif/registry.py | annif/rest.py | annif/static/css/bootstrap.min.css | annif/static/css/bootstrap.min.css.map | annif/static/css/fonts.css | annif/static/css/style.css | annif/static/favicon.ico | annif/static/fonts/Jost-400-Book.otf | annif/static/fonts/Jost-400-Book.ttf | annif/static/fonts/Jost-500-Medium.otf | annif/static/fonts/Jost-500-Medium.ttf | annif/static/img/annif-RGB.svg | annif/static/img/arrow-white.svg | annif/static/js/bootstrap.min.js | annif/static/js/bootstrap.min.js.map | annif/static/js/jquery-3.3.1.min.js | annif/static/js/jquery-3.3.1.min.map | annif/static/js/jquery-3.5.1.min.js | annif/static/js/jquery-3.5.1.min.map | annif/suggestion.py | annif/templates/home.html | annif/util.py | setup.cfg | setup.py | tests/conftest.py | tests/test_backend.py | tests/test_backend_ensemble.py | tests/test_backend_fasttext.py | tests/test_backend_http.py | tests/test_backend_maui.py | tests/test_backend_nn_ensemble.py | tests/test_backend_omikuji.py | tests/test_backend_pav.py | tests/test_backend_tfidf.py | tests/test_backend_vw_multi.py | tests/test_cli.py | tests/test_corpus.py | tests/test_eval.py | tests/test_parallel.py | tests/test_project.py | tests/test_suggestion.py,documentation-file | container-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file,"CLI specification We need a specification of the CLI commands (with REST equivalents when applicable), for example as a Markdown file or a Wiki page. This should be written in a form that will serve as user documentation later on. First draft of Swagger/OpenAPI spec. Fixes #1 First part of CLI specification. Part of #2 Merge pull request #2 from NatLibFi/master Update to current master 20200814",no-bug,0.9
136,Annif,https://github.com/NatLibFi/Annif/issues/136,Refactor corpus classes,"Right now the `annif.corpus` classes are a bit of a mess. They are trying to support different kinds of corpora: * SubjectIndex: subjects only as a TSV file + lookup and save functionality * SubjectIndexSKOS: subjects only as a SKOS file * SubjectDirectory: subjects with texts as a directory of TXT files * DocumentFile: documents with subjects as a TSV file * DocumentDirectory: documents with subjects as a directory of TXT + TSV files Some conversions / views are supported, for example SubjectDirectory.from_documents allows converting a DocumentFile into a SubjectDirectory and FastTextBackend knows how to convert a SubjectDirectory into the fastText train file format which resembles DocumentFile. But this makes for messy code in AnnifProject. Instead the classes should be seen as interfaces which provide access to the data in a uniform way regardless of the underlying storage. There could be a common abstract base class AnnifCorpus which provides methods/properties such as `subjects` (iterate through the available subjects as Subject objects, which are actually named tuples) and `documents` (iterate through the available documents, which could also be named tuples with text and subjects). These methods could perform the conversion behind the scenes, using temporary files or directories when necessary. The index functionality (lookup by ID or URI) of SubjectIndex should be separated from the loading/saving part, which could be implemented by a class called SubjectFileTSV.",Bump version: 0.26.0 → 0.27.0,"Split off index functionality (SubjectIndex) from subject file access. Part of #136 | refactor document corpora, adding a DocumentCorpus abstract base class. Part of #136 | Use a mixin for converting a DocumentCorpus to a SubjectCorpus. Part of #136 | Use a mixin for converting a SubjectCorpus into a DocumentCorpus. Part of #136",annif/backend/fasttext.py | annif/backend/tfidf.py | annif/cli.py | annif/corpus/__init__.py | annif/corpus/skos.py | annif/corpus/subject.py | annif/project.py | tests/test_backend_tfidf.py | tests/test_corpus.py | tests/test_vocab_skos.py | annif/backend/backend.py | annif/backend/fasttext.py | annif/corpus/document.py | annif/corpus/subject.py | annif/corpus/convert.py | annif/corpus/document.py | annif/corpus/subject.py | annif/project.py | tests/conftest.py | annif/backend/backend.py | annif/backend/fasttext.py | annif/backend/tfidf.py | annif/corpus/convert.py | annif/corpus/document.py | annif/corpus/subject.py | annif/corpus/types.py | annif/project.py | tests/test_backend_fasttext.py | tests/test_backend_tfidf.py,source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file,"Refactor corpus classes Right now the `annif.corpus` classes are a bit of a mess. They are trying to support different kinds of corpora: * SubjectIndex: subjects only as a TSV file + lookup and save functionality * SubjectIndexSKOS: subjects only as a SKOS file * SubjectDirectory: subjects with texts as a directory of TXT files * DocumentFile: documents with subjects as a TSV file * DocumentDirectory: documents with subjects as a directory of TXT + TSV files Some conversions / views are supported, for example SubjectDirectory.from_documents allows converting a DocumentFile into a SubjectDirectory and FastTextBackend knows how to convert a SubjectDirectory into the fastText train file format which resembles DocumentFile. But this makes for messy code in AnnifProject. Instead the classes should be seen as interfaces which provide access to the data in a uniform way regardless of the underlying storage. There could be a common abstract base class AnnifCorpus which provides methods/properties such as `subjects` (iterate through the available subjects as Subject objects, which are actually named tuples) and `documents` (iterate through the available documents, which could also be named tuples with text and subjects). These methods could perform the conversion behind the scenes, using temporary files or directories when necessary. The index functionality (lookup by ID or URI) of SubjectIndex should be separated from the loading/saving part, which could be implemented by a class called SubjectFileTSV. Bump version: 0.26.0 → 0.27.0 Split off index functionality (SubjectIndex) from subject file access. Part of #136 refactor document corpora, adding a DocumentCorpus abstract base class. Part of #136 Use a mixin for converting a DocumentCorpus to a SubjectCorpus. Part of #136 Use a mixin for converting a SubjectCorpus into a DocumentCorpus. Part of #136",no-bug,0.9
218,Annif,https://github.com/NatLibFi/Annif/issues/218,Simplify backend configuration,"At the moment, a project may have multiple backends. In the current situation this seems unnecessary and makes it more complicated than necessary to understand the relationship between projects and backends. Projects should be limited to a single backend and the configuration setting should be changed from plural `backends` to singular `backend`.",Merge pull request #231 from NatLibFi/issue37-voikko Voikko analyzer,Simplify project configuration by allowing only one backend per project. Fixes #218,annif/project.py | annif/swagger/annif.yaml | projects.cfg.dist | tests/projects.cfg | tests/test_project.py,source-file | documentation-file | other-file | test-file | test-file,"Simplify backend configuration At the moment, a project may have multiple backends. In the current situation this seems unnecessary and makes it more complicated than necessary to understand the relationship between projects and backends. Projects should be limited to a single backend and the configuration setting should be changed from plural `backends` to singular `backend`. Merge pull request #231 from NatLibFi/issue37-voikko Voikko analyzer Simplify project configuration by allowing only one backend per project. Fixes #218",no-bug,0.9
348,Annif,https://github.com/NatLibFi/Annif/issues/348,Learning doesn't work in nn_ensemble backend,"The `nn_ensemble` backend is intended to support the `learn` operation, i.e. performing additional (online) learning after initial training. However, in practice this doesn't work: $ annif learn nn-ensemble-fi ../Annif-corpora/fulltext/kirjastonhoitaja/maui-train/ Error: Not supported project 'nn-ensemble-fi': Learning not supported by backend The backend has a `learn` method, and there are unit tests for it, but it's not recognized as being capable of learning. Credit to Pekka K. for reporting the issue",fix typo in DOI link,Enable learning in nn_ensemble backend. Fixes #348 | Merge pull request #349 from NatLibFi/issue348-nn-ensemble-enable-learn Enable learning in nn_ensemble backend. Fixes #348,annif/backend/nn_ensemble.py | annif/backend/nn_ensemble.py,source-file | source-file,"Learning doesn't work in nn_ensemble backend The `nn_ensemble` backend is intended to support the `learn` operation, i.e. performing additional (online) learning after initial training. However, in practice this doesn't work: $ annif learn nn-ensemble-fi ../Annif-corpora/fulltext/kirjastonhoitaja/maui-train/ Error: Not supported project 'nn-ensemble-fi': Learning not supported by backend The backend has a `learn` method, and there are unit tests for it, but it's not recognized as being capable of learning. Credit to Pekka K. for reporting the issue fix typo in DOI link Enable learning in nn_ensemble backend. Fixes #348 Merge pull request #349 from NatLibFi/issue348-nn-ensemble-enable-learn Enable learning in nn_ensemble backend. Fixes #348",no-bug,0.9
98,Annif,https://github.com/NatLibFi/Annif/issues/98,Project name,"For the UI we need to show human understandable project names. These should be part of the data model for projects, defined in projects.cfg, retrieved via CLI and REST",Merge pull request #99 from NatLibFi/issue93-merge-hits-take2 Divide hit weights by sum of backend weights. Fixes #93,Add name field for projects. Fixes #98 | Merge pull request #101 from NatLibFi/issue98-project-name Add name field for projects. Fixes #98,annif/cli.py | annif/project.py | projects.cfg | tests/projects.cfg | tests/test_project.py | annif/cli.py | annif/project.py | projects.cfg | tests/projects.cfg | tests/test_project.py,source-file | source-file | other-file | test-file | test-file | source-file | source-file | other-file | test-file | test-file,"Project name For the UI we need to show human understandable project names. These should be part of the data model for projects, defined in projects.cfg, retrieved via CLI and REST Merge pull request #99 from NatLibFi/issue93-merge-hits-take2 Divide hit weights by sum of backend weights. Fixes #93 Add name field for projects. Fixes #98 Merge pull request #101 from NatLibFi/issue98-project-name Add name field for projects. Fixes #98",no-bug,0.7
350,Annif,https://github.com/NatLibFi/Annif/issues/350,Eval command on empty corpus error: Samplewise metrics are not available outside of multilabel classification.,"I noticed that the `eval` command gives a non-obvious error when given an empty corpus: ``` $ touch empty.tsv $ annif eval tfidf-fi empty.tsv Traceback (most recent call last): File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/flask/cli.py"", line 586, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/flask/cli.py"", line 426, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/git/Annif/annif/cli.py"", line 276, in run_eval for metric, score in eval_batch.results().items(): File ""/home/oisuomin/git/Annif/annif/eval.py"", line 144, in results y_true, y_pred, metrics) File ""/home/oisuomin/git/Annif/annif/eval.py"", line 93, in _evaluate_samples y_true, y_pred_binary, average='samples') File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/sklearn/metrics/classification.py"", line 1569, in precision_score sample_weight=sample_weight) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/sklearn/metrics/classification.py"", line 1421, in precision_recall_fscore_support labels=labels, samplewise=samplewise) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/sklearn/metrics/classification.py"", line 415, in multilabel_confusion_matrix raise ValueError(""Samplewise metrics are not available outside of "" ValueError: Samplewise metrics are not available outside of multilabel classification. ``` This case should be caught in the code and result in a more intuitive error message.",Merge pull request #344 from NatLibFi/issue269-mauiserver-backend Add Maui Server backend,Fail gracefully when trying to evaluate an empty corpus. Fixes #350,annif/eval.py | tests/test_cli.py,source-file | test-file,"Eval command on empty corpus error: Samplewise metrics are not available outside of multilabel classification. I noticed that the `eval` command gives a non-obvious error when given an empty corpus: ``` $ touch empty.tsv $ annif eval tfidf-fi empty.tsv Traceback (most recent call last): File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/bin/annif"", line 11, in <module> load_entry_point('annif', 'console_scripts', 'annif')() File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 764, in __call__ return self.main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/flask/cli.py"", line 586, in main return super(FlaskGroup, self).main(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 717, in main rv = self.invoke(ctx) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 1137, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 956, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/decorators.py"", line 17, in new_func return f(get_current_context(), *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/flask/cli.py"", line 426, in decorator return __ctx.invoke(f, *args, **kwargs) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/click/core.py"", line 555, in invoke return callback(*args, **kwargs) File ""/home/oisuomin/git/Annif/annif/cli.py"", line 276, in run_eval for metric, score in eval_batch.results().items(): File ""/home/oisuomin/git/Annif/annif/eval.py"", line 144, in results y_true, y_pred, metrics) File ""/home/oisuomin/git/Annif/annif/eval.py"", line 93, in _evaluate_samples y_true, y_pred_binary, average='samples') File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/sklearn/metrics/classification.py"", line 1569, in precision_score sample_weight=sample_weight) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/sklearn/metrics/classification.py"", line 1421, in precision_recall_fscore_support labels=labels, samplewise=samplewise) File ""/home/oisuomin/.local/share/virtualenvs/Annif-OYFUWV2R/lib/python3.5/site-packages/sklearn/metrics/classification.py"", line 415, in multilabel_confusion_matrix raise ValueError(""Samplewise metrics are not available outside of "" ValueError: Samplewise metrics are not available outside of multilabel classification. ``` This case should be caught in the code and result in a more intuitive error message. Merge pull request #344 from NatLibFi/issue269-mauiserver-backend Add Maui Server backend Fail gracefully when trying to evaluate an empty corpus. Fixes #350",no-bug,0.9
61,Annif,https://github.com/NatLibFi/Annif/issues/61,Backend specific data directory,We need a directory structure where backends may place data files. Needed for the Gensim backend (#46),Iterate subject corpus as lists of tokens. Fixes #60,Support backend specific data directories. Fixes #61,annif/backend/backend.py | config.py | tests/test_backend.py,source-file | source-file | test-file,Backend specific data directory We need a directory structure where backends may place data files. Needed for the Gensim backend (#46) Iterate subject corpus as lists of tokens. Fixes #60 Support backend specific data directories. Fixes #61,no-bug,0.8
11,Annif,https://github.com/NatLibFi/Annif/issues/11,Define project model in Swagger spec,Currently the Swagger spec doesn't have any data model information. We should define the data model for projects,Add Slack notification for Travis CI status messages,"Draft definition of project model/schema using Swagger. #11 | Define a ProjectList schema so we have a top-level object instead of plain array as the response, allowing for extensibility. #11",swagger/annif.yaml | swagger/annif.yaml,documentation-file | documentation-file,"Define project model in Swagger spec Currently the Swagger spec doesn't have any data model information. We should define the data model for projects Add Slack notification for Travis CI status messages Draft definition of project model/schema using Swagger. #11 Define a ProjectList schema so we have a top-level object instead of plain array as the response, allowing for extensibility. #11",no-bug,0.8
628,Annif,https://github.com/NatLibFi/Annif/issues/628,Allow selecting label language in suggest operations,"The suggest operation (both CLI and REST) always returns the subject labels in the configured vocabulary language, even though the vocabulary could include labels in other languages. For example, YSO is trilingual (fi, sv, en) and thus the subject labels could be given in any of these languages. We could make it possible to select the subject label language in suggest operations. In the CLI, it could be a parameter `-L` / `--language`: annif suggest -L en yso-mllm-fi <document.txt # return English language subject labels annif suggest --language en yso-mllm-fi <document.txt # same but with long option In the REST API, it could be a parameter `lang` or `language` that works similarly to the current `limit` and `threshold` parameters. Currently the Finto AI user interface has similar functionality, but it relies on the Finto REST API to fetch labels in non-default languages. Having this available in the Annif API would simplify the implementation.",Merge pull request #627 from NatLibFi/upgrade-joblib-1.2 Upgrade to joblib 1.2.x,Allow overriding subject label language in CLI and REST suggest operations. Fixes #628,annif/cli.py | annif/rest.py | annif/swagger/annif.yaml | tests/test_cli.py | tests/test_rest.py,source-file | source-file | documentation-file | test-file | test-file,"Allow selecting label language in suggest operations The suggest operation (both CLI and REST) always returns the subject labels in the configured vocabulary language, even though the vocabulary could include labels in other languages. For example, YSO is trilingual (fi, sv, en) and thus the subject labels could be given in any of these languages. We could make it possible to select the subject label language in suggest operations. In the CLI, it could be a parameter `-L` / `--language`: annif suggest -L en yso-mllm-fi <document.txt # return English language subject labels annif suggest --language en yso-mllm-fi <document.txt # same but with long option In the REST API, it could be a parameter `lang` or `language` that works similarly to the current `limit` and `threshold` parameters. Currently the Finto AI user interface has similar functionality, but it relies on the Finto REST API to fetch labels in non-default languages. Having this available in the Annif API would simplify the implementation. Merge pull request #627 from NatLibFi/upgrade-joblib-1.2 Upgrade to joblib 1.2.x Allow overriding subject label language in CLI and REST suggest operations. Fixes #628",no-bug,0.8
60,Annif,https://github.com/NatLibFi/Annif/issues/60,Ability to iterate subject corpus as lists of tokens,The SubjectDirectory need a method that returns an iterator which iterates through the subjects and each item is a list of tokens. Needed for Gensim compatibility (#46),Filter and normalize words when tokenizing. Fixes #59,Iterate subject corpus as lists of tokens. Fixes #60,annif/corpus/subject.py | tests/test_corpus.py,source-file | test-file,Ability to iterate subject corpus as lists of tokens The SubjectDirectory need a method that returns an iterator which iterates through the subjects and each item is a list of tokens. Needed for Gensim compatibility (#46) Filter and normalize words when tokenizing. Fixes #59 Iterate subject corpus as lists of tokens. Fixes #60,no-bug,0.9
174,Annif,https://github.com/NatLibFi/Annif/issues/174,Remove eval CLI command and rename evaldir to eval,The `eval` CLI command is pretty useless as evaluation is usually (always?) performed on a relatively large number of documents in order to get accurate results. It should be removed. The `evaldir` command can then be renamed simply `eval`.,"Merge pull request #172 from NatLibFi/scrutinizer-fixes replace unused variables with underscores, per the common convention",Remove eval CLI command. Part of #174 | Rename evaldir command to eval. Fixes #174,annif/cli.py | tests/test_cli.py | annif/cli.py | tests/test_cli.py,source-file | test-file | source-file | test-file,"Remove eval CLI command and rename evaldir to eval The `eval` CLI command is pretty useless as evaluation is usually (always?) performed on a relatively large number of documents in order to get accurate results. It should be removed. The `evaldir` command can then be renamed simply `eval`. Merge pull request #172 from NatLibFi/scrutinizer-fixes replace unused variables with underscores, per the common convention Remove eval CLI command. Part of #174 Rename evaldir command to eval. Fixes #174",no-bug,0.95
86,Annif,https://github.com/NatLibFi/Annif/issues/86,Evaluate different limits all at once,"The evaldir command should try different limit settings all in one run (analysis is expensive, limiting is cheap), and report the values which maximize F-measure and/or other metrics",add EvaluationBatch class for evaluating batches of documents with subjects,Add optimize CLI command for determining best limit/threshold parameters. Fixes #86,annif/cli.py,source-file,"Evaluate different limits all at once The evaldir command should try different limit settings all in one run (analysis is expensive, limiting is cheap), and report the values which maximize F-measure and/or other metrics add EvaluationBatch class for evaluating batches of documents with subjects Add optimize CLI command for determining best limit/threshold parameters. Fixes #86",no-bug,0.9
