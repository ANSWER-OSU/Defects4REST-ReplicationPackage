issue_no,repo,issue_url,title,description,patched_file_types,text_for_topic_modeling,prediction,confidence
3513,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3513,[volume] DATA RACE on MaybeAdjustVolumeMax,https://github.com/seaweedfs/seaweedfs/issues/3507  volume_1 |  volume_1 | WARNING: DATA RACE volume_1 | Read at 0x00c00018b180 by goroutine 143: volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Store).MaybeAdjustVolumeMax() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:542 +0x13c volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).doHeartbeat() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:214 +0x1c19 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).heartbeat() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:69 +0x449 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.NewVolumeServer.func1() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server.go:123 +0x39 volume_1 | volume_1 | Previous write at 0x00c00018b180 by goroutine 165: volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Store).MaybeAdjustVolumeMax() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:551 +0x209 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).doHeartbeat.func1() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:135 +0x2c6 volume_1 | volume_1 | Goroutine 143 (running) created at: volume_1 | github.com/seaweedfs/seaweedfs/weed/server.NewVolumeServer() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server.go:123 +0x104b volume_1 | github.com/seaweedfs/seaweedfs/weed/command.VolumeServerOptions.startVolumeServer() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/volume.go:235 +0x1646 volume_1 | github.com/seaweedfs/seaweedfs/weed/command.runVolume() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/volume.go:133 +0x432 volume_1 | main.main() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 volume_1 | volume_1 | Goroutine 165 (running) created at: volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).doHeartbeat() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:114 +0x7d9 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).heartbeat() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:69 +0x449 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.NewVolumeServer.func1() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server.go:123 +0x39 volume_1 |  s3tests_1 | s3tests_boto3.functional.test_s3.test_bucket_list_empty  ok volume_1 | I0825 10:40:32.912680 store.go:143 In dir /data adds volume:1 collection:yournamehere-ndnlnnt6gnh6x06j-2 replicaPlacement:000 ttl: volume_1 | I0825 10:40:32.913928 volume_loading.go:140 loading memory index /data/yournamehere-ndnlnnt6gnh6x06j-2_1.idx to memory volume_1 | I0825 10:40:32.917846 store.go:147 add volume 1 volume_1 | I0825 10:40:32.918257 volume_grpc_client_to_master.go:172 volume server volume:8080 adds volume 1 master_1 | I0825 10:40:32.920073 volume_layout.go:391 Volume 1 becomes writable master_1 | I0825 10:40:32.920163 volume_growth.go:245 Created Volume 1 on topo:DefaultDataCenter:DefaultRack:volume:8080 s3tests_1 | s3tests_boto3.functiona ,source-file | source-file,[volume] DATA RACE on MaybeAdjustVolumeMax https://github.com/seaweedfs/seaweedfs/issues/3507  volume_1 |  volume_1 | WARNING: DATA RACE volume_1 | Read at 0x00c00018b180 by goroutine 143: volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Store).MaybeAdjustVolumeMax() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:542 +0x13c volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).doHeartbeat() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:214 +0x1c19 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).heartbeat() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:69 +0x449 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.NewVolumeServer.func1() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server.go:123 +0x39 volume_1 | volume_1 | Previous write at 0x00c00018b180 by goroutine 165: volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Store).MaybeAdjustVolumeMax() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:551 +0x209 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).doHeartbeat.func1() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:135 +0x2c6 volume_1 | volume_1 | Goroutine 143 (running) created at: volume_1 | github.com/seaweedfs/seaweedfs/weed/server.NewVolumeServer() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server.go:123 +0x104b volume_1 | github.com/seaweedfs/seaweedfs/weed/command.VolumeServerOptions.startVolumeServer() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/volume.go:235 +0x1646 volume_1 | github.com/seaweedfs/seaweedfs/weed/command.runVolume() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/volume.go:133 +0x432 volume_1 | main.main() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 volume_1 | volume_1 | Goroutine 165 (running) created at: volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).doHeartbeat() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:114 +0x7d9 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).heartbeat() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_client_to_master.go:69 +0x449 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.NewVolumeServer.func1() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server.go:123 +0x39 volume_1 |  s3tests_1 | s3tests_boto3.functional.test_s3.test_bucket_list_empty  ok volume_1 | I0825 10:40:32.912680 store.go:143 In dir /data adds volume:1 collection:yournamehere-ndnlnnt6gnh6x06j-2 replicaPlacement:000 ttl: volume_1 | I0825 10:40:32.913928 volume_loading.go:140 loading memory index /data/yournamehere-ndnlnnt6gnh6x06j-2_1.idx to memory volume_1 | I0825 10:40:32.917846 store.go:147 add volume 1 volume_1 | I0825 10:40:32.918257 volume_grpc_client_to_master.go:172 volume server volume:8080 adds volume 1 master_1 | I0825 10:40:32.920073 volume_layout.go:391 Volume 1 becomes writable master_1 | I0825 10:40:32.920163 volume_growth.go:245 Created Volume 1 on topo:DefaultDataCenter:DefaultRack:volume:8080 s3tests_1 | s3tests_boto3.functiona  source-file source-file,no-bug,0.95
6579,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6579,Client certificate unnecessarily mounted in master and volume,"In the seaweedfs helm chart, the client-cert, which is the certificate used to make the S3 service TLS enabled, is mounted into the Volume and Master pods, even though it is unused by these pods. The problem here is when coupled with tooling that restarts pods when a mounted secret changes (for example a Kyverno policy or https://github.com/stakater/Reloader), ALL pods are restarted, when only the pods that run the S3 service need be restarted. This would either be the S3 Deployment, or the Filer (in the case that S3 is bundled with the Filer).",documentation-file | documentation-file | documentation-file | documentation-file,"Client certificate unnecessarily mounted in master and volume In the seaweedfs helm chart, the client-cert, which is the certificate used to make the S3 service TLS enabled, is mounted into the Volume and Master pods, even though it is unused by these pods. The problem here is when coupled with tooling that restarts pods when a mounted secret changes (for example a Kyverno policy or https://github.com/stakater/Reloader), ALL pods are restarted, when only the pods that run the S3 service need be restarted. This would either be the S3 Deployment, or the Filer (in the case that S3 is bundled with the Filer). documentation-file documentation-file documentation-file documentation-file",no-bug,0.9
85,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/85,"Losts of ""volume_server_handlers.go:155] response write error"" errors in our production server log files",Is this a problem? how could be happened? any suggestions? Here is details(logs are on both two volume servers): (master server internal ip : 10.252.130.159) volume server 1 :(v0.68)  I0211 18:50:06 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:46065: i/o timeout I0211 18:50:21 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:46137: i/o timeout I0211 18:50:37 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:46205: i/o timeout I0211 19:00:18 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:48455: i/o timeout I0211 19:00:54 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:48597: i/o timeout I0211 19:56:01 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33519: connection reset by peer I0211 20:26:39 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:42285: connection reset by peer I0211 20:37:20 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:45272: connection reset by peer I0211 21:34:19 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:58623: connection reset by peer I0212 08:53:58 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:36510: connection reset by peer I0212 09:44:07 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:48289: connection reset by peer I0212 11:00:59 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:37052: connection reset by peer I0212 11:01:32 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:37280: connection reset by peer I0212 14:35:10 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33136: broken pipe I0212 14:36:09 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33423: broken pipe I0212 14:36:30 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33530: connection reset by peer I0212 14:36:30 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33532: connection reset by peer I0212 14:36:58 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33629: connection reset by peer I0212 15:15:47 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:43678: connection reset by peer I0212 16:07:28 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:56089: connection reset by peer I0212 16:07:28 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:56084: connection reset by peer I0212 18:21:45 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:38085: broken pipe I0212 18:34:32 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:40850: broken pipe I0212 18:35:39 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:41118: connection reset by peer I0212 21:13:23 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:53229: connection reset by peer I0212 21:51:14 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33695: connection reset by peer I0212 21:51:14 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33701: broken pipe I0212 21:53:17 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:34297: broken pipe I0212 21:54:11 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:34514: connection reset by peer I0212 22:00:14 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:36014: broken pipe I0212 22:05:46 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:37219: connection reset by peer I0212 22:18:07 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:40511: broken pipe I0213 14:20:49 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:32919: connection reset by peer I0213 14:23:39 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:34039: broken pipe I0213 14:23:39 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:34037: broken pipe I0213 14:45:19 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:48873: broken pipe I0213 14:51:17 21828 volume_server_handlers.go:196] response write error: write tcp 10.252.130.159:50847: i/o timeout I0213 14:51:17 21828 volume_server_handlers.go:196] response write error: write tcp 10.252.130.159:50845: i/o timeout I0213 15:09:31 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:55504: connection reset by peer ,source-file | source-file | source-file,"Losts of ""volume_server_handlers.go:155] response write error"" errors in our production server log files Is this a problem? how could be happened? any suggestions? Here is details(logs are on both two volume servers): (master server internal ip : 10.252.130.159) volume server 1 :(v0.68)  I0211 18:50:06 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:46065: i/o timeout I0211 18:50:21 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:46137: i/o timeout I0211 18:50:37 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:46205: i/o timeout I0211 19:00:18 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:48455: i/o timeout I0211 19:00:54 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:48597: i/o timeout I0211 19:56:01 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33519: connection reset by peer I0211 20:26:39 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:42285: connection reset by peer I0211 20:37:20 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:45272: connection reset by peer I0211 21:34:19 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:58623: connection reset by peer I0212 08:53:58 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:36510: connection reset by peer I0212 09:44:07 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:48289: connection reset by peer I0212 11:00:59 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:37052: connection reset by peer I0212 11:01:32 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:37280: connection reset by peer I0212 14:35:10 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33136: broken pipe I0212 14:36:09 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33423: broken pipe I0212 14:36:30 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33530: connection reset by peer I0212 14:36:30 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33532: connection reset by peer I0212 14:36:58 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33629: connection reset by peer I0212 15:15:47 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:43678: connection reset by peer I0212 16:07:28 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:56089: connection reset by peer I0212 16:07:28 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:56084: connection reset by peer I0212 18:21:45 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:38085: broken pipe I0212 18:34:32 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:40850: broken pipe I0212 18:35:39 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:41118: connection reset by peer I0212 21:13:23 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:53229: connection reset by peer I0212 21:51:14 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33695: connection reset by peer I0212 21:51:14 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:33701: broken pipe I0212 21:53:17 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:34297: broken pipe I0212 21:54:11 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:34514: connection reset by peer I0212 22:00:14 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:36014: broken pipe I0212 22:05:46 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:37219: connection reset by peer I0212 22:18:07 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:40511: broken pipe I0213 14:20:49 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:32919: connection reset by peer I0213 14:23:39 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:34039: broken pipe I0213 14:23:39 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:34037: broken pipe I0213 14:45:19 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:48873: broken pipe I0213 14:51:17 21828 volume_server_handlers.go:196] response write error: write tcp 10.252.130.159:50847: i/o timeout I0213 14:51:17 21828 volume_server_handlers.go:196] response write error: write tcp 10.252.130.159:50845: i/o timeout I0213 15:09:31 21828 volume_server_handlers.go:155] response write error: write tcp 10.252.130.159:55504: connection reset by peer  source-file source-file source-file",no-bug,0.8
5135,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5135,Slow Assign with a large number of volumes,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** [GetActiveVolumeCount](https://github.com/seaweedfs/seaweedfs/blob/3.59/weed/topology/volume_layout.go#L347) function has high complexity when dc/rack/node topology is enabled. Master-leader makes this complex calculation every time `Assign` called, thus every write has O(2*n^3) difficulty just to count active volumes. https://github.com/seaweedfs/seaweedfs/blob/7eafa3420b8e5ae83c8873cddd03ded90a0fc921/weed/topology/volume_layout.go#L347-L372 With a large number of volumes (~50000) it takes up to 1000ms to pick needed volume and [a lot of CPU resources](https://github.com/seaweedfs/seaweedfs/issues/3886#issuecomment-1846849439). **Expected behavior** Seems, that master can keep active/crowded volumes in memory since all needed information already exist in topology. We need some mapping, so the needed info about active/crowded volumes could be taken faster.",source-file,"Slow Assign with a large number of volumes Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** [GetActiveVolumeCount](https://github.com/seaweedfs/seaweedfs/blob/3.59/weed/topology/volume_layout.go#L347) function has high complexity when dc/rack/node topology is enabled. Master-leader makes this complex calculation every time `Assign` called, thus every write has O(2*n^3) difficulty just to count active volumes. https://github.com/seaweedfs/seaweedfs/blob/7eafa3420b8e5ae83c8873cddd03ded90a0fc921/weed/topology/volume_layout.go#L347-L372 With a large number of volumes (~50000) it takes up to 1000ms to pick needed volume and [a lot of CPU resources](https://github.com/seaweedfs/seaweedfs/issues/3886#issuecomment-1846849439). **Expected behavior** Seems, that master can keep active/crowded volumes in memory since all needed information already exist in topology. We need some mapping, so the needed info about active/crowded volumes could be taken faster. source-file",no-bug,0.95
1163,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1163,filer ,Filer  404 Cassandra Cassandra filemeta meta   Volume  ,source-file,filer  Filer  404 Cassandra Cassandra filemeta meta   Volume   source-file,no-bug,0.3
86,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/86,how to build weed-fs binaries,"I'd like to build the latest from master, but not sure of a simple way to do that. I had hoped I could do something like this (in the docker registry [here](https://registry.hub.docker.com/u/library/golang/)):  git clone https://github.com/chrislusf/weed-fs.git cd weed-fs docker run --rm -it -v ""$PWD"":/usr/src/weed -w /usr/src/weed golang:1.4.1-cross bash $ for GOOS in darwin linux; do > for GOARCH in 386 amd64; do > go build -v -o myapp-$GOOS-$GOARCH > done > done  But it fails I think due to the directory structure of the Go files for this project. Any guidance on how to build my own binaries from master would be greatly appreciated!",source-file | source-file,"how to build weed-fs binaries I'd like to build the latest from master, but not sure of a simple way to do that. I had hoped I could do something like this (in the docker registry [here](https://registry.hub.docker.com/u/library/golang/)):  git clone https://github.com/chrislusf/weed-fs.git cd weed-fs docker run --rm -it -v ""$PWD"":/usr/src/weed -w /usr/src/weed golang:1.4.1-cross bash $ for GOOS in darwin linux; do > for GOARCH in 386 amd64; do > go build -v -o myapp-$GOOS-$GOARCH > done > done  But it fails I think due to the directory structure of the Go files for this project. Any guidance on how to build my own binaries from master would be greatly appreciated! source-file source-file",no-bug,0.95
1841,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1841,[master] gRPC TLS authentication by CN,"It is not difficult for k8s to write out a valid certificate. Therefore, additional protection is required in the form of authorization by CN in client certificate links https://medium.com/utility-warehouse-technology/grpc-client-authentication-bf899ac8ada8 https://grpc.io/docs/guides/auth/ https://dev.to/living_syn/validating-client-certificate-sans-in-go-i5p https://dev.to/techschoolguru/how-to-secure-grpc-connection-with-ssl-tls-in-go-4ph https://jbrandhorst.com/post/grpc-auth/",source-file | source-file,"[master] gRPC TLS authentication by CN It is not difficult for k8s to write out a valid certificate. Therefore, additional protection is required in the form of authorization by CN in client certificate links https://medium.com/utility-warehouse-technology/grpc-client-authentication-bf899ac8ada8 https://grpc.io/docs/guides/auth/ https://dev.to/living_syn/validating-client-certificate-sans-in-go-i5p https://dev.to/techschoolguru/how-to-secure-grpc-connection-with-ssl-tls-in-go-4ph https://jbrandhorst.com/post/grpc-auth/ source-file source-file",no-bug,0.9
13,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/13,Missing build instructions for Mac OSX 10.9.4,"I can't find the precompiled binary release for my OS platform (Mac OSX 10.9.4) on your linked page. When I `git clone` this repo, I find a bunch of *.go files in some subfolders. Is there a Makefile to compile all of these into a `weed` binary myself?",documentation-file | documentation-file | other-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file,"Missing build instructions for Mac OSX 10.9.4 I can't find the precompiled binary release for my OS platform (Mac OSX 10.9.4) on your linked page. When I `git clone` this repo, I find a bunch of *.go files in some subfolders. Is there a Makefile to compile all of these into a `weed` binary myself? documentation-file documentation-file other-file test-file test-file source-file source-file source-file source-file source-file source-file test-file test-file source-file source-file source-file source-file source-file source-file test-file test-file source-file source-file test-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file",no-bug,0.95
1391,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1391,panic: runtime error: invalid memory address or nil pointer dereference while trying to mount directory using FUSE,"**Describe the bug** Seaweed is giving a runtime error whenever I'm trying to mount a folder using FUSE. **System Setup** - Started seaweed with weed server -filer=true. The related logs are as follows: <pre>I0716 23:45:55 6308 master.go:151] current: 192.168.0.107:9333 peers: I0716 23:45:55 6308 file_util.go:20] Folder /tmp Permission: -rwxrwxrwx I0716 23:45:55 6308 master.go:151] current: 192.168.0.107:9333 peers:192.168.0.107:9333 I0716 23:45:55 6308 master_server.go:108] Volume Size Limit is 30000 MB I0716 23:45:55 6308 file_util.go:20] Folder /tmp Permission: -rwxrwxrwx I0716 23:45:55 6308 master_server.go:196] adminScripts: I0716 23:45:55 6308 master.go:114] Start Seaweed Master 30GB 1.85 5a4f258 at 0.0.0.0:9333 I0716 23:45:55 6308 raft_server.go:47] Starting RaftServer with 192.168.0.107:9333 I0716 23:45:55 6308 raft_server.go:55] Peers Change: [] => [192.168.0.107:9333] I0716 23:45:55 6308 disk_location.go:123] Store started on dir: /tmp with 0 volumes max 8 I0716 23:45:55 6308 disk_location.go:126] Store started on dir: /tmp with 0 ec shards I0716 23:45:55 6308 volume_grpc_client_to_master.go:27] Volume server start with seed master nodes: [192.168.0.107:9333] I0716 23:45:55 6308 volume.go:319] Start Seaweed volume server 30GB 1.85 5a4f258 at 0.0.0.0:8080 I0716 23:45:55 6308 volume_grpc_client_to_master.go:71] SendHeartbeat to 192.168.0.107:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.0.107:19333: connect: connection refused"" I0716 23:45:55 6308 volume_grpc_client_to_master.go:51] heartbeat error: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.0.107:19333: connect: connection refused"" I0716 23:45:55 6308 raft_server.go:75] Initializing new cluster I0716 23:45:55 6308 raft_server.go:88] current cluster leader: 192.168.0.107:9333 I0716 23:45:55 6308 master_server.go:151] [ 192.168.0.107:9333 ] I am the leader! I0716 23:45:55 6308 master.go:138] Start Seaweed Master 30GB 1.85 5a4f258 grpc server at 0.0.0.0:19333 I0716 23:45:55 6308 master_grpc_server.go:253] + client master@192.168.0.107:56862 I0716 23:45:56 6308 master_grpc_server.go:253] + client filer@192.168.0.107:8888 I0716 23:45:56 6308 leveldb_store.go:41] filer store dir: . I0716 23:45:56 6308 file_util.go:20] Folder . Permission: -rwxrwxr-x I0716 23:45:56 6308 configuration.go:25] Configure filer for leveldb I0716 23:45:56 6308 filer.go:144] Start Seaweed Filer 30GB 1.85 5a4f258 at 192.168.0.107:8888 I0716 23:45:56 6308 filer_grpc_server_sub_meta.go:130] + listener filer@192.168.0.107:45336 I0716 23:45:56 6308 filer_grpc_server_sub_meta.go:60] filer@192.168.0.107:45336 local subscribe / from 2020-07-16 23:45:56.559028587 +0530 IST I0716 23:46:00 6308 volume_grpc_client_to_master.go:74] Heartbeat to: 192.168.0.107:9333 I0716 23:46:00 6308 node.go:278] topo adds child DefaultDataCenter I0716 23:46:00 6308 node.go:278] topo:DefaultDataCenter adds child DefaultRack I0716 23:46:00 6308 node.go:278] topo:DefaultDataCenter:DefaultRack adds child 192.168.0.107:8080 I0716 23:46:00 6308 master_grpc_server.go:74] added volume server 192.168.0.107:8080 </pre> - Then tried to mount a directory with `weed mount -filer=localhost:8888 -dir=~/seaweed/dir1 -filer.path=/` This gave the error : <pre> This is SeaweedFS version 30GB 1.85 5a4f258 linux amd64 current uid=1000 gid=1000 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0x177ba95] goroutine 1 [running]: github.com/chrislusf/seaweedfs/weed/command.RunMount(0x2ff4c40, 0x12, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/mount_std.go:169 +0xa15 github.com/chrislusf/seaweedfs/weed/command.runMount(0x2fdd8a0, 0xc00003a0e0, 0x0, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/mount_std.go:41 +0xc3 main.main() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/weed.go:66 +0x2f9 </pre> - OS version <pre> Distributor ID: Ubuntu Description: Ubuntu 20.04 LTS Release: 20.04 Codename: focal </pre> - output of `weed version` : `version 30GB 1.85 5a4f258 linux amd64` - if using filer, show the content of `filer.toml` <pre> [leveldb] enabled = true dir = ""."" </pre> **Expected behavior** The directory should get mounted.",source-file,"panic: runtime error: invalid memory address or nil pointer dereference while trying to mount directory using FUSE **Describe the bug** Seaweed is giving a runtime error whenever I'm trying to mount a folder using FUSE. **System Setup** - Started seaweed with weed server -filer=true. The related logs are as follows: <pre>I0716 23:45:55 6308 master.go:151] current: 192.168.0.107:9333 peers: I0716 23:45:55 6308 file_util.go:20] Folder /tmp Permission: -rwxrwxrwx I0716 23:45:55 6308 master.go:151] current: 192.168.0.107:9333 peers:192.168.0.107:9333 I0716 23:45:55 6308 master_server.go:108] Volume Size Limit is 30000 MB I0716 23:45:55 6308 file_util.go:20] Folder /tmp Permission: -rwxrwxrwx I0716 23:45:55 6308 master_server.go:196] adminScripts: I0716 23:45:55 6308 master.go:114] Start Seaweed Master 30GB 1.85 5a4f258 at 0.0.0.0:9333 I0716 23:45:55 6308 raft_server.go:47] Starting RaftServer with 192.168.0.107:9333 I0716 23:45:55 6308 raft_server.go:55] Peers Change: [] => [192.168.0.107:9333] I0716 23:45:55 6308 disk_location.go:123] Store started on dir: /tmp with 0 volumes max 8 I0716 23:45:55 6308 disk_location.go:126] Store started on dir: /tmp with 0 ec shards I0716 23:45:55 6308 volume_grpc_client_to_master.go:27] Volume server start with seed master nodes: [192.168.0.107:9333] I0716 23:45:55 6308 volume.go:319] Start Seaweed volume server 30GB 1.85 5a4f258 at 0.0.0.0:8080 I0716 23:45:55 6308 volume_grpc_client_to_master.go:71] SendHeartbeat to 192.168.0.107:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.0.107:19333: connect: connection refused"" I0716 23:45:55 6308 volume_grpc_client_to_master.go:51] heartbeat error: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.0.107:19333: connect: connection refused"" I0716 23:45:55 6308 raft_server.go:75] Initializing new cluster I0716 23:45:55 6308 raft_server.go:88] current cluster leader: 192.168.0.107:9333 I0716 23:45:55 6308 master_server.go:151] [ 192.168.0.107:9333 ] I am the leader! I0716 23:45:55 6308 master.go:138] Start Seaweed Master 30GB 1.85 5a4f258 grpc server at 0.0.0.0:19333 I0716 23:45:55 6308 master_grpc_server.go:253] + client master@192.168.0.107:56862 I0716 23:45:56 6308 master_grpc_server.go:253] + client filer@192.168.0.107:8888 I0716 23:45:56 6308 leveldb_store.go:41] filer store dir: . I0716 23:45:56 6308 file_util.go:20] Folder . Permission: -rwxrwxr-x I0716 23:45:56 6308 configuration.go:25] Configure filer for leveldb I0716 23:45:56 6308 filer.go:144] Start Seaweed Filer 30GB 1.85 5a4f258 at 192.168.0.107:8888 I0716 23:45:56 6308 filer_grpc_server_sub_meta.go:130] + listener filer@192.168.0.107:45336 I0716 23:45:56 6308 filer_grpc_server_sub_meta.go:60] filer@192.168.0.107:45336 local subscribe / from 2020-07-16 23:45:56.559028587 +0530 IST I0716 23:46:00 6308 volume_grpc_client_to_master.go:74] Heartbeat to: 192.168.0.107:9333 I0716 23:46:00 6308 node.go:278] topo adds child DefaultDataCenter I0716 23:46:00 6308 node.go:278] topo:DefaultDataCenter adds child DefaultRack I0716 23:46:00 6308 node.go:278] topo:DefaultDataCenter:DefaultRack adds child 192.168.0.107:8080 I0716 23:46:00 6308 master_grpc_server.go:74] added volume server 192.168.0.107:8080 </pre> - Then tried to mount a directory with `weed mount -filer=localhost:8888 -dir=~/seaweed/dir1 -filer.path=/` This gave the error : <pre> This is SeaweedFS version 30GB 1.85 5a4f258 linux amd64 current uid=1000 gid=1000 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0x177ba95] goroutine 1 [running]: github.com/chrislusf/seaweedfs/weed/command.RunMount(0x2ff4c40, 0x12, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/mount_std.go:169 +0xa15 github.com/chrislusf/seaweedfs/weed/command.runMount(0x2fdd8a0, 0xc00003a0e0, 0x0, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/mount_std.go:41 +0xc3 main.main() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/weed.go:66 +0x2f9 </pre> - OS version <pre> Distributor ID: Ubuntu Description: Ubuntu 20.04 LTS Release: 20.04 Codename: focal </pre> - output of `weed version` : `version 30GB 1.85 5a4f258 linux amd64` - if using filer, show the content of `filer.toml` <pre> [leveldb] enabled = true dir = ""."" </pre> **Expected behavior** The directory should get mounted. source-file",no-bug,0.9
1752,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1752,mount: data inconsistencies between multiple hosts,"**Describe the bug** Mount SeaweedFS on two hosts. Modify the contents of the file on the first host. Data cannot be synchronized to the second host. But by changing the contents of the file on the second host, the data can be synchronized to the first host.  # 1. init seaweedfs root@192.168.1.1# weed server -filer=true root@192.168.1.2# weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t1 -dir=./t1 -filer.path=/ root@192.168.1.3# weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t2 -dir=./t2 -filer.path=/ # 2. init test data root@192.168.1.2# echo ""1"" > ./t1/1 root@192.168.1.2# cat ./t1/1 1 root@192.168.1.3# cat ./t2/1 1 # 3. host2 => host3 root@192.168.1.2# echo ""2"" >> ./t1/1 root@192.168.1.2# cat ./t1/1 1 2 root@192.168.1.3# cat ./t2/1 1 # 4. host3 => host2 root@192.168.1.3# echo ""3"" >> ./t2/1 root@192.168.1.3# cat ./t2/1 1 3 root@192.168.1.2# cat ./t1/1 1 3  **System Setup** - root@192.168.1.1# `weed server -filer=true` - root@192.168.1.2# `weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t1 -dir=./t1 -filer.path=/` - root@192.168.1.3# `weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t2 -dir=./t2 -filer.path=/` - linux amd64 - version 30GB 2.11 linux amd64 **Expected behavior** The data on the two hosts are consistent **Additional context** When the three commands are run on the same host, the data is consistent  root@192.168.1.1# weed server -filer=true root@192.168.1.1# weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t1 -dir=./t1 -filer.path=/ root@192.168.1.1# weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t2 -dir=./t2 -filer.path=/ ",source-file,"mount: data inconsistencies between multiple hosts **Describe the bug** Mount SeaweedFS on two hosts. Modify the contents of the file on the first host. Data cannot be synchronized to the second host. But by changing the contents of the file on the second host, the data can be synchronized to the first host.  # 1. init seaweedfs root@192.168.1.1# weed server -filer=true root@192.168.1.2# weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t1 -dir=./t1 -filer.path=/ root@192.168.1.3# weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t2 -dir=./t2 -filer.path=/ # 2. init test data root@192.168.1.2# echo ""1"" > ./t1/1 root@192.168.1.2# cat ./t1/1 1 root@192.168.1.3# cat ./t2/1 1 # 3. host2 => host3 root@192.168.1.2# echo ""2"" >> ./t1/1 root@192.168.1.2# cat ./t1/1 1 2 root@192.168.1.3# cat ./t2/1 1 # 4. host3 => host2 root@192.168.1.3# echo ""3"" >> ./t2/1 root@192.168.1.3# cat ./t2/1 1 3 root@192.168.1.2# cat ./t1/1 1 3  **System Setup** - root@192.168.1.1# `weed server -filer=true` - root@192.168.1.2# `weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t1 -dir=./t1 -filer.path=/` - root@192.168.1.3# `weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t2 -dir=./t2 -filer.path=/` - linux amd64 - version 30GB 2.11 linux amd64 **Expected behavior** The data on the two hosts are consistent **Additional context** When the three commands are run on the same host, the data is consistent  root@192.168.1.1# weed server -filer=true root@192.168.1.1# weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t1 -dir=./t1 -filer.path=/ root@192.168.1.1# weed mount -filer=192.168.1.1:8888 -cacheDir=./cache/t2 -dir=./t2 -filer.path=/  source-file",no-bug,0.9
4559,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4559,[data lost][shell] cmd `volume.deleteEmpty` occasionally deletes non-empty volume,"**Describe the bug** Occasionally some files are corrupted, if the `volume.deleteEmpty` maintenance command is executed when putting files to filer. **System Setup** - weed version: 3.51 - include `volume.deleteEmpty` command in `master.maintenance`, like [the default `master.maintenance`](https://github.com/seaweedfs/seaweedfs/blob/5ee04d20fac54daf3ceba7469adce824f30dc678/weed/command/scaffold/master.toml#L14) **Scene** - Put some files to filer when the maintenance script is about to be executed(which is unnoticed) - `volume.deleteEmpty` maintenance command is executed when putting files - Put finished - Some of these files are unreadable(`stream.go:97 operation LookupFileId 32,017966854c964a failed, err: urls not found` error in log), although in the filer's file list **Expected behavior** All the files newly put to the filer are readable. **Additional context** Real scene `weed.INFO` logs (see `volume 32`, `32,` and `volume.deleteEmpty`):  Log file created at: 2023/06/05 03:17:52 Running on machine: 720cf4b7c503 Binary: Built with gc go1.20.4 for linux/amd64 Log line format: [IWEF]mmdd hh:mm:ss threadid file:line] msg I0605 03:17:52.268844 master.go:269 current: 172.17.0.8:9333 peers: I0605 03:17:52.269008 file_util.go:23 Folder /data_master_meta Permission: -rwx I0605 03:17:52.269139 file_util.go:23 Folder /data Permission: -rwx I0605 03:17:52.269181 s3_backend.go:60 created backend storage s3.storage1 for region cn-east-1 bucket seaweedfs1storage1 I0605 03:17:52.269189 master.go:269 current: 172.17.0.8:9333 peers:172.17.0.8:9333 I0605 03:17:52.269304 master_server.go:127 Volume Size Limit is 1024 MB I0605 03:17:52.269443 master_server.go:265 adminScripts: lock volume.deleteEmpty -quietFor=24h -force volume.balance -force volume.fix.replication s3.clean.uploads -timeAgo=24h unlock I0605 03:17:52.269486 master.go:150 Start Seaweed Master 30GB 3.51 4310e1fac at 172.17.0.8:9333 I0605 03:17:52.269704 volume_grpc_client_to_master.go:43 checkWithMaster 172.17.0.8:9333: get master 172.17.0.8:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.8:19333: connect: connection refused"" I0605 03:17:52.269723 raft_server.go:118 Starting RaftServer with 172.17.0.8:9333 I0605 03:17:52.273131 raft_server.go:167 current cluster leader: I0605 03:17:54.061095 volume_grpc_client_to_master.go:43 checkWithMaster 172.17.0.8:9333: get master 172.17.0.8:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.8:19333: connect: connection refused"" skip I0605 07:22:22.313206 master_server.go:323 executing: lock [] I0605 07:22:22.313584 master_server.go:323 executing: volume.deleteEmpty [-quietFor=24h -force] I0605 07:22:22.313852 master_server.go:323 executing: volume.balance [-force] I0605 07:22:37.314914 master_server.go:323 executing: volume.fix.replication [] I0605 07:22:52.315764 master_server.go:323 executing: s3.clean.uploads [-timeAgo=24h] I0605 07:22:52.316443 master_server.go:323 executing: unlock [] I0605 07:39:18.051688 store.go:166 In dir /data adds volume:31 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:39:18.051787 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_31.idx to memory I0605 07:39:18.055494 store.go:170 add volume 31 I0605 07:39:18.055517 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 31 I0605 07:39:18.055553 volume_growth.go:244 Created Volume 31 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:18.055567 volume_layout.go:393 Volume 31 becomes writable I0605 07:39:18.055576 volume_growth.go:257 Registered Volume 31 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:24.019433 volume_layout.go:380 Volume 30 becomes unwritable I0605 07:39:24.019442 volume_layout.go:472 Volume 30 reaches full capacity. I0605 07:39:51.358467 store.go:166 In dir /data adds volume:32 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:39:51.358584 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_32.idx to memory I0605 07:39:51.369318 store.go:170 add volume 32 I0605 07:39:51.369359 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 32 I0605 07:39:51.369392 volume_growth.go:244 Created Volume 32 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:51.369409 volume_layout.go:393 Volume 32 becomes writable I0605 07:39:51.369420 volume_growth.go:257 Registered Volume 32 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:52.316741 master_server.go:323 executing: lock [] I0605 07:39:52.317054 master_server.go:323 executing: volume.deleteEmpty [-quietFor=24h -force] I0605 07:39:52.338801 store.go:526 DeleteVolume 32 I0605 07:39:52.338852 volume_grpc_client_to_master.go:210 volume server 172.17.0.8:8080 deletes volume 32 I0605 07:39:52.338949 master_server.go:323 executing: volume.balance [-force] I0605 07:39:52.338976 topology.go:258 removing volume info: Id:32, Size:0, ReplicaPlacement:000, Collection:juicefs4, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from 172.17.0.8:8080 I0605 07:39:52.338994 volume_layout.go:223 volume 32 does not have enough copies I0605 07:39:52.338996 volume_layout.go:228 volume 32 remove from writable I0605 07:39:52.338998 volume_layout.go:380 Volume 32 becomes unwritable I0605 07:39:52.369975 store.go:166 In dir /data adds volume:33 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:39:52.370081 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_33.idx to memory I0605 07:39:52.373846 store.go:170 add volume 33 I0605 07:39:52.373864 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 33 I0605 07:39:52.373908 volume_growth.go:244 Created Volume 33 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:52.373919 volume_layout.go:393 Volume 33 becomes writable I0605 07:39:52.373923 volume_growth.go:257 Registered Volume 33 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:56.650085 volume_layout.go:380 Volume 31 becomes unwritable I0605 07:39:56.650097 volume_layout.go:472 Volume 31 reaches full capacity. I0605 07:40:07.339434 master_server.go:323 executing: volume.fix.replication [] I0605 07:40:22.340328 master_server.go:323 executing: s3.clean.uploads [-timeAgo=24h] I0605 07:40:22.340933 master_server.go:323 executing: unlock [] I0605 07:40:26.247358 volume_layout.go:484 Volume 33 becomes crowded I0605 07:40:26.360142 store.go:166 In dir /data adds volume:34 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:40:26.360245 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_34.idx to memory I0605 07:40:26.366895 store.go:170 add volume 34 I0605 07:40:26.366924 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 34 I0605 07:40:26.366957 volume_growth.go:244 Created Volume 34 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:40:26.366972 volume_layout.go:393 Volume 34 becomes writable I0605 07:40:26.366977 volume_growth.go:257 Registered Volume 34 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:40:33.908426 volume_layout.go:380 Volume 33 becomes unwritable I0605 07:40:33.908437 volume_layout.go:472 Volume 33 reaches full capacity. I0605 07:41:06.249505 store.go:166 In dir /data adds volume:35 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:41:06.249648 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_35.idx to memory I0605 07:41:06.260440 store.go:170 add volume 35 I0605 07:41:06.260471 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 35 I0605 07:41:06.260544 volume_growth.go:244 Created Volume 35 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:41:06.260562 volume_layout.go:393 Volume 35 becomes writable I0605 07:41:06.260570 volume_growth.go:257 Registered Volume 35 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:41:13.770598 volume_layout.go:380 Volume 34 becomes unwritable I0605 07:41:13.770616 volume_layout.go:472 Volume 34 reaches full capacity. E0605 07:42:14.301994 stream.go:97 operation LookupFileId 32,017965c5ce6d4e failed, err: urls not found E0605 07:42:14.302183 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs4/juicefs4/chunks/0/1/1035_11_4194304: operation LookupFileId 32,017965c5ce6d4e failed, err: urls not found E0605 07:42:14.302199 common.go:297 processRangeRequest: operation LookupFileId 32,017965c5ce6d4e failed, err: urls not found E0605 07:42:15.513498 stream.go:97 operation LookupFileId 32,017966854c964a failed, err: urls not found E0605 07:42:15.513521 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs4/juicefs4/chunks/0/1/1036_2_4194304: operation LookupFileId 32,017966854c964a failed, err: urls not found E0605 07:42:15.513531 common.go:297 processRangeRequest: operation LookupFileId 32,017966854c964a failed, err: urls not found E0605 07:42:15.513501 stream.go:97 operation LookupFileId 32,0179643b8a24c7 failed, err: urls not found E0605 07:42:15.513588 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs4/juicefs4/chunks/0/1/1036_1_4194304: operation LookupFileId 32,0179643b8a24c7 failed, err: urls not found E0605 07:42:15.513595 common.go:297 processRangeRequest: operation LookupFileId 32,0179643b8a24c7 failed, err: urls not found skip I0605 08:22:38.321250 common.go:75 response method:GET URL:/dir/lookup?fileId=32,0179643b8a24c7 with httpStatus:404 and JSON:{""volumeOrFileId"":""32"",""error"":""volume id 32 not found""} I0605 08:23:49.336870 common.go:75 response method:GET URL:/dir/lookup?fileId=32,0179643b8a24c7&collection=juicefs4 with httpStatus:404 and JSON:{""volumeOrFileId"":""32"",""error"":""volume id 32 not found""}  Test for this issue scene `weed.INFO` logs (see `volume 59`, `2778_4_4194304` and `volume.deleteEmpty`):  Log file created at: 2023/06/10 01:46:10 Running on machine: 25901906dec2 Binary: Built with gc go1.20.4 for linux/amd64 Log line format: [IWEF]mmdd hh:mm:ss threadid file:line] msg I0610 01:46:10.113090 config.go:46 Reading : Config File ""security"" Not Found in ""[/data /root/.seaweedfs /usr/local/etc/seaweedfs /etc/seaweedfs]"" I0610 01:46:10.113421 config.go:59 Reading master.toml from /etc/seaweedfs/master.toml I0610 01:46:10.113431 master.go:269 current: 172.17.0.16:9333 peers: I0610 01:46:10.113446 file_util.go:23 Folder /data_master_meta Permission: -rwx I0610 01:46:10.113558 file_util.go:23 Folder /data Permission: -rwx I0610 01:46:10.113654 s3_backend.go:60 created backend storage s3.storage1 for region cn-east-1 bucket seaweedfs1storage1 I0610 01:46:10.113663 master.go:269 current: 172.17.0.16:9333 peers:172.17.0.16:9333 I0610 01:46:10.113718 master_server.go:335 [master.sequencer.type] : [] I0610 01:46:10.113730 master_server.go:127 Volume Size Limit is 128 MB I0610 01:46:10.113882 master_server.go:265 adminScripts: lock volume.vacuum -garbageThreshold=0.000001 -collection=juicefs5 volume.deleteEmpty -quietFor=1s -force volume.balance -force volume.fix.replication s3.clean.uploads -timeAgo=24h unlock I0610 01:46:10.113917 master.go:150 Start Seaweed Master 30GB 3.51 4310e1fac at 172.17.0.16:9333 I0610 01:46:10.113941 masterclient.go:127 .adminShell masterClient bootstraps with masters map[172.17.0.16:9333:172.17.0.16:9333] I0610 01:46:10.113956 masterclient.go:172 .adminShell masterClient Connecting to master 172.17.0.16:9333 I0610 01:46:10.114055 volume_grpc_client_to_master.go:43 checkWithMaster 172.17.0.16:9333: get master 172.17.0.16:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:10.114147 masterclient.go:180 .adminShell masterClient failed to keep connected to 172.17.0.16:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:10.114167 masterclient.go:260 .adminShell masterClient failed to connect with master 172.17.0.16:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:10.114190 raft_server.go:118 Starting RaftServer with 172.17.0.16:9333 I0610 01:46:10.126603 raft_server.go:167 current cluster leader: I0610 01:46:11.114567 masterclient.go:172 .adminShell masterClient Connecting to master 172.17.0.16:9333 I0610 01:46:11.115288 masterclient.go:180 .adminShell masterClient failed to keep connected to 172.17.0.16:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:11.115325 masterclient.go:260 .adminShell masterClient failed to connect with master 172.17.0.16:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:11.904728 volume_grpc_client_to_master.go:43 checkWithMaster 172.17.0.16:9333: get master 172.17.0.16:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" skip I0610 02:02:10.255037 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_2_4194304 I0610 02:02:10.255163 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.297570 volume_grpc_client_to_master.go:232 volume server 172.17.0.16:8080 heartbeat I0610 02:02:10.297610 store.go:589 disk /data max 11943 unclaimedSpace:1528003MB, unused:17592186043623MB volumeSizeLimit:128MB I0610 02:02:10.297618 volume.go:273 collectStatus volume 53 I0610 02:02:10.297623 volume.go:273 collectStatus volume 56 I0610 02:02:10.297626 volume.go:273 collectStatus volume 57 I0610 02:02:10.297628 volume.go:273 collectStatus volume 55 I0610 02:02:10.297630 volume.go:273 collectStatus volume 2 I0610 02:02:10.297632 volume.go:273 collectStatus volume 58 I0610 02:02:10.297634 volume.go:273 collectStatus volume 54 I0610 02:02:10.297798 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 public_url:""seaweedfs-lab5-volume1.xxx.io"" max_file_key:8820 data_center:""dc1"" rack:""rack1"" volumes:{id:53 size:351311008 collection:""juicefs5"" file_count:98 version:3 modified_at_second:1686362507} volumes:{id:56 size:364910720 collection:""juicefs5"" file_count:87 version:3 modified_at_second:1686362527} volumes:{id:57 size:213913184 collection:""juicefs5"" file_count:51 version:3 modified_at_second:1686362526} volumes:{id:55 size:356523472 collection:""juicefs5"" file_count:86 version:3 modified_at_second:1686362516} volumes:{id:2 size:4789384 file_count:28 version:3 modified_at_second:1686362291} volumes:{id:58 size:297800704 collection:""juicefs5"" file_count:71 version:3 modified_at_second:1686362530} volumes:{id:54 size:181406824 collection:""juicefs5"" file_count:44 version:3 modified_at_second:1686362507} max_volume_counts:{key:"""" value:11943} grpc_port:18080 location_uuids:""5d846bf0-9b0c-4178-9301-ec200e3c84b1"" I0610 02:02:10.300708 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.300888 master_grpc_server_volume.go:54 starting automatic volume grow I0610 02:02:10.300980 cluster_commands.go:32 max volume id 58 ==> 59 I0610 02:02:10.301138 store.go:166 In dir /data adds volume:59 collection:juicefs5 replicaPlacement:000 ttl: I0610 02:02:10.301160 volume_info.go:21 maybeLoadVolumeInfo checks /data/juicefs5_59.vif I0610 02:02:10.301265 volume_loading.go:121 open to write file /data_volume_index/juicefs5_59.idx I0610 02:02:10.301297 volume_loading.go:142 loading memory index /data_volume_index/juicefs5_59.idx to memory I0610 02:02:10.301311 needle_map_memory.go:54 max file key: 0 for file: /data_volume_index/juicefs5_59.idx I0610 02:02:10.311008 filer_server_handlers_write_upload.go:123 uploaded 2778_2_4194304 chunk 1 to 58,2275ad7334fb [0,4194304) I0610 02:02:10.311039 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_2_4194304 I0610 02:02:10.311053 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.311076 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_2_4194304: new entry: 2778_2_4194304 I0610 02:02:10.311126 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_2_4194304: created I0610 02:02:10.311222 error_handler.go:96 status 200 : I0610 02:02:10.313978 store.go:170 add volume 59 I0610 02:02:10.313991 volume_grpc_admin.go:60 assign volume volume_id:59 collection:""juicefs5"" replication:""000"" I0610 02:02:10.314030 volume_grpc_client_to_master.go:179 volume server 172.17.0.16:8080 adds volume 59 I0610 02:02:10.314113 volume_growth.go:244 Created Volume 59 on topo:dc1:rack1:172.17.0.16:8080 I0610 02:02:10.314132 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 data_center:""dc1"" rack:""rack1"" new_volumes:{id:59 collection:""juicefs5"" version:3} I0610 02:02:10.314132 volume_layout.go:393 Volume 59 becomes writable I0610 02:02:10.314141 volume_growth.go:257 Registered Volume 59 on topo:dc1:rack1:172.17.0.16:8080 I0610 02:02:10.314148 master_grpc_server_volume.go:57 finished automatic volume grow, cost 13.253062ms I0610 02:02:10.314212 masterclient.go:278 .master: 172.17.0.16:8080 masterClient adds volume 59 I0610 02:02:10.314224 vid_map.go:160 + volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:10.314235 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:10.314245 masterclient.go:278 .master: 172.17.0.16:8080 masterClient adds volume 59 I0610 02:02:10.314245 masterclient.go:278 .filer: 172.17.0.16:8080 masterClient adds volume 59 I0610 02:02:10.314252 vid_map.go:160 + volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:10.314254 vid_map.go:160 + volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:10.314259 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:10.314261 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:10.314271 masterclient.go:278 .filer: 172.17.0.16:8080 masterClient adds volume 59 I0610 02:02:10.314278 vid_map.go:160 + volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:10.314284 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:10.335126 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_3_4194304 I0610 02:02:10.335226 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.381414 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.391830 filer_server_handlers_write_upload.go:123 uploaded 2778_3_4194304 chunk 1 to 58,2276f615a530 [0,4194304) I0610 02:02:10.391859 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_3_4194304 I0610 02:02:10.391880 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.391910 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_3_4194304: new entry: 2778_3_4194304 I0610 02:02:10.391972 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_3_4194304: created I0610 02:02:10.392068 error_handler.go:96 status 200 : I0610 02:02:10.415360 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_4_4194304 I0610 02:02:10.415484 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.461860 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.473749 filer_server_handlers_write_upload.go:123 uploaded 2778_4_4194304 chunk 1 to 59,2277719b1e43 [0,4194304) I0610 02:02:10.473777 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304 I0610 02:02:10.473790 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.473819 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304: new entry: 2778_4_4194304 I0610 02:02:10.473867 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304: created I0610 02:02:10.473958 error_handler.go:96 status 200 : I0610 02:02:10.494892 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_5_4194304 I0610 02:02:10.494996 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.541004 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.551757 filer_server_handlers_write_upload.go:123 uploaded 2778_5_4194304 chunk 1 to 59,2278b138056e [0,4194304) I0610 02:02:10.551796 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304 I0610 02:02:10.551817 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.551854 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304: new entry: 2778_5_4194304 I0610 02:02:10.551932 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304: created I0610 02:02:10.552023 error_handler.go:96 status 200 : I0610 02:02:10.575416 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_6_4194304 I0610 02:02:10.575546 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.621928 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.632082 filer_server_handlers_write_upload.go:123 uploaded 2778_6_4194304 chunk 1 to 58,227905727806 [0,4194304) I0610 02:02:10.632105 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_6_4194304 I0610 02:02:10.632119 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.632140 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_6_4194304: new entry: 2778_6_4194304 I0610 02:02:10.632199 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_6_4194304: created I0610 02:02:10.632288 error_handler.go:96 status 200 : I0610 02:02:10.654974 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_7_4194304 I0610 02:02:10.655092 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.703499 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.715016 filer_server_handlers_write_upload.go:123 uploaded 2778_7_4194304 chunk 1 to 59,227af658f241 [0,4194304) I0610 02:02:10.715054 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304 I0610 02:02:10.715068 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.715096 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304: new entry: 2778_7_4194304 I0610 02:02:10.715160 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304: created I0610 02:02:10.715279 error_handler.go:96 status 200 : I0610 02:02:10.735581 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_8_4194304 I0610 02:02:10.735706 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.782947 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.793441 filer_server_handlers_write_upload.go:123 uploaded 2778_8_4194304 chunk 1 to 58,227b66ca4947 [0,4194304) I0610 02:02:10.793471 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_8_4194304 I0610 02:02:10.793491 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.793509 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_8_4194304: new entry: 2778_8_4194304 I0610 02:02:10.793557 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_8_4194304: created I0610 02:02:10.793667 error_handler.go:96 status 200 : I0610 02:02:10.815333 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_9_4194304 I0610 02:02:10.815451 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.863066 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.873599 filer_server_handlers_write_upload.go:123 uploaded 2778_9_4194304 chunk 1 to 58,227cac005e0c [0,4194304) I0610 02:02:10.873626 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_9_4194304 I0610 02:02:10.873640 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.873662 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_9_4194304: new entry: 2778_9_4194304 I0610 02:02:10.873713 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_9_4194304: created I0610 02:02:10.873799 error_handler.go:96 status 200 : I0610 02:02:10.895645 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_10_4194304 I0610 02:02:10.895767 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.941907 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.952838 filer_server_handlers_write_upload.go:123 uploaded 2778_10_4194304 chunk 1 to 59,227d582687c5 [0,4194304) I0610 02:02:10.952869 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304 I0610 02:02:10.952886 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.952908 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304: new entry: 2778_10_4194304 I0610 02:02:10.952970 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304: created I0610 02:02:10.953062 error_handler.go:96 status 200 : I0610 02:02:10.957717 webdav_server.go:382 WebDavFileSystem.Stat / I0610 02:02:10.957867 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.957981 webdav_server.go:209 WebDavFileSystem.OpenFile / 0 I0610 02:02:10.958065 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.958126 webdav_server.go:615 WebDavFile.Stat / I0610 02:02:10.958203 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.958263 webdav_server.go:498 WebDavFileSystem.Close / I0610 02:02:10.958272 webdav_server.go:209 WebDavFileSystem.OpenFile / 0 I0610 02:02:10.958334 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.958389 webdav_server.go:615 WebDavFile.Stat / I0610 02:02:10.958454 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.958499 webdav_server.go:498 WebDavFileSystem.Close / I0610 02:02:10.975310 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_11_4194304 I0610 02:02:10.975440 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.022860 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.034451 filer_server_handlers_write_upload.go:123 uploaded 2778_11_4194304 chunk 1 to 58,227e9f9e0643 [0,4194304) I0610 02:02:11.034486 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_11_4194304 I0610 02:02:11.034501 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.034537 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_11_4194304: new entry: 2778_11_4194304 I0610 02:02:11.034593 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_11_4194304: created I0610 02:02:11.034691 error_handler.go:96 status 200 : I0610 02:02:11.055623 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_12_4194304 I0610 02:02:11.055742 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.102900 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.113771 filer_server_handlers_write_upload.go:123 uploaded 2778_12_4194304 chunk 1 to 58,227f4768efcb [0,4194304) I0610 02:02:11.113800 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_12_4194304 I0610 02:02:11.113815 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.113836 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_12_4194304: new entry: 2778_12_4194304 I0610 02:02:11.113881 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_12_4194304: created I0610 02:02:11.113986 error_handler.go:96 status 200 : I0610 02:02:11.126210 filer.go:236 find uncached directory: /topics/.system/log/2023-06-10 I0610 02:02:11.126225 filer.go:200 InsertEntry /topics/.system/log/2023-06-10/02-01.67ac9a39: new entry: 02-01.67ac9a39 I0610 02:02:11.126252 filer.go:221 CreateEntry /topics/.system/log/2023-06-10/02-01.67ac9a39: created I0610 02:02:11.136760 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_13_4194304 I0610 02:02:11.136863 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.185153 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.195553 filer_server_handlers_write_upload.go:123 uploaded 2778_13_4194304 chunk 1 to 59,22819cb0460c [0,4194304) I0610 02:02:11.195580 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_13_4194304 I0610 02:02:11.195596 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.195617 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_13_4194304: new entry: 2778_13_4194304 I0610 02:02:11.195680 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_13_4194304: created I0610 02:02:11.195778 error_handler.go:96 status 200 : I0610 02:02:11.215147 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_14_4194304 I0610 02:02:11.215269 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.262501 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.273419 filer_server_handlers_write_upload.go:123 uploaded 2778_14_4194304 chunk 1 to 58,22827cca16dd [0,4194304) I0610 02:02:11.273448 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_14_4194304 I0610 02:02:11.273466 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.273496 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_14_4194304: new entry: 2778_14_4194304 I0610 02:02:11.273565 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_14_4194304: created I0610 02:02:11.273645 error_handler.go:96 status 200 : I0610 02:02:11.295644 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_15_4194304 I0610 02:02:11.295774 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.336342 master_server.go:323 executing: lock [] I0610 02:02:11.336629 master_server.go:323 executing: volume.vacuum [-garbageThreshold=0.000001 -collection=juicefs5] I0610 02:02:11.336751 master_grpc_server_admin.go:93 isLocked 172.17.0.16: I0610 02:02:11.336760 master_grpc_server_admin.go:135 LeaseAdminToken 172.17.0.16 I0610 02:02:11.336775 topology_vacuum.go:225 Start vacuum on demand with threshold: 0.000001 collection: juicefs5 volumeId: 0 I0610 02:02:11.336792 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:58 I0610 02:02:11.336899 store_vacuum.go:13 volume 58 garbage level: 0.000000 I0610 02:02:11.336951 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:59 I0610 02:02:11.337021 store_vacuum.go:13 volume 59 garbage level: 0.000000 I0610 02:02:11.337074 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:53 I0610 02:02:11.337148 store_vacuum.go:13 volume 53 garbage level: 0.000000 I0610 02:02:11.337199 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:54 I0610 02:02:11.337277 store_vacuum.go:13 volume 54 garbage level: 0.000000 I0610 02:02:11.337343 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:55 I0610 02:02:11.337420 store_vacuum.go:13 volume 55 garbage level: 0.000000 I0610 02:02:11.337484 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:56 I0610 02:02:11.337550 store_vacuum.go:13 volume 56 garbage level: 0.000000 I0610 02:02:11.337604 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:57 I0610 02:02:11.337693 store_vacuum.go:13 volume 57 garbage level: 0.000000 I0610 02:02:11.337796 master_server.go:323 executing: volume.deleteEmpty [-quietFor=1s -force] I0610 02:02:11.346417 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.369826 store.go:526 DeleteVolume 59 I0610 02:02:11.369855 volume_grpc_client_to_master.go:210 volume server 172.17.0.16:8080 deletes volume 59 I0610 02:02:11.369841 volume_grpc_admin.go:108 volume delete volume_id:59 I0610 02:02:11.370036 master_server.go:323 executing: volume.balance [-force] I0610 02:02:11.370051 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 data_center:""dc1"" rack:""rack1"" deleted_volumes:{id:59 collection:""juicefs5"" version:3} I0610 02:02:11.370072 topology.go:258 removing volume info: Id:59, Size:0, ReplicaPlacement:000, Collection:juicefs5, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from 172.17.0.16:8080 I0610 02:02:11.370092 volume_layout.go:223 volume 59 does not have enough copies I0610 02:02:11.370101 volume_layout.go:228 volume 59 remove from writable I0610 02:02:11.370106 volume_layout.go:380 Volume 59 becomes unwritable I0610 02:02:11.370193 masterclient.go:282 .master: 172.17.0.16:8080 masterClient removes volume 59 I0610 02:02:11.370204 vid_map.go:208 - volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.370211 vid_map.go:208 - volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.370219 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 0, del: 1, add ec: 0 del ec: 0 I0610 02:02:11.370194 masterclient.go:282 .filer: 172.17.0.16:8080 masterClient removes volume 59 I0610 02:02:11.370228 vid_map.go:208 - volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.370234 vid_map.go:208 - volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.370240 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 0, del: 1, add ec: 0 del ec: 0 I0610 02:02:11.372032 filer_server_handlers_write_upload.go:123 uploaded 2778_15_4194304 chunk 1 to 58,22833375ffc4 [0,4194304) I0610 02:02:11.372061 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_15_4194304 I0610 02:02:11.372078 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.372098 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_15_4194304: new entry: 2778_15_4194304 I0610 02:02:11.372155 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_15_4194304: created I0610 02:02:11.372236 error_handler.go:96 status 200 : I0610 02:02:11.378169 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2779_0_4194304 I0610 02:02:11.378280 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.424544 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.424721 master_grpc_server_volume.go:54 starting automatic volume grow I0610 02:02:11.424792 cluster_commands.go:32 max volume id 59 ==> 60 I0610 02:02:11.424906 store.go:166 In dir /data adds volume:60 collection:juicefs5 replicaPlacement:000 ttl: I0610 02:02:11.424927 volume_info.go:21 maybeLoadVolumeInfo checks /data/juicefs5_60.vif I0610 02:02:11.425000 volume_loading.go:121 open to write file /data_volume_index/juicefs5_60.idx I0610 02:02:11.425026 volume_loading.go:142 loading memory index /data_volume_index/juicefs5_60.idx to memory I0610 02:02:11.425047 needle_map_memory.go:54 max file key: 0 for file: /data_volume_index/juicefs5_60.idx I0610 02:02:11.428584 store.go:170 add volume 60 I0610 02:02:11.428594 volume_grpc_admin.go:60 assign volume volume_id:60 collection:""juicefs5"" replication:""000"" I0610 02:02:11.428629 volume_grpc_client_to_master.go:179 volume server 172.17.0.16:8080 adds volume 60 I0610 02:02:11.428697 volume_growth.go:244 Created Volume 60 on topo:dc1:rack1:172.17.0.16:8080 I0610 02:02:11.428712 volume_layout.go:393 Volume 60 becomes writable I0610 02:02:11.428719 volume_growth.go:257 Registered Volume 60 on topo:dc1:rack1:172.17.0.16:8080 I0610 02:02:11.428719 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 data_center:""dc1"" rack:""rack1"" new_volumes:{id:60 collection:""juicefs5"" version:3} I0610 02:02:11.428723 master_grpc_server_volume.go:57 finished automatic volume grow, cost 3.995524ms I0610 02:02:11.428816 masterclient.go:278 .filer: 172.17.0.16:8080 masterClient adds volume 60 I0610 02:02:11.428819 masterclient.go:278 .master: 172.17.0.16:8080 masterClient adds volume 60 I0610 02:02:11.428825 vid_map.go:160 + volume id 60: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.428827 vid_map.go:160 + volume id 60: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.428835 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:11.428838 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:11.428843 masterclient.go:278 .filer: 172.17.0.16:8080 masterClient adds volume 60 I0610 02:02:11.428846 vid_map.go:160 + volume id 60: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.428849 masterclient.go:278 .master: 172.17.0.16:8080 masterClient adds volume 60 I0610 02:02:11.428853 vid_map.go:160 + volume id 60: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.428853 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:11.428857 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:11.434899 filer_server_handlers_write_upload.go:123 uploaded 2779_0_4194304 chunk 1 to 58,22843c35dc98 [0,4194304) I0610 02:02:11.434929 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2779_0_4194304 I0610 02:02:11.434949 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.434981 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2779_0_4194304: new entry: 2779_0_4194304 I0610 02:02:11.435052 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2779_0_4194304: created I0610 02:02:11.435134 error_handler.go:96 status 200 : skip I0610 02:02:41.371853 master_server.go:323 executing: s3.clean.uploads [-timeAgo=24h] I0610 02:02:41.371993 filer_grpc_server_admin.go:104 GetFilerConfiguration: masters:""172.17.0.16:9333"" max_mb:4 dir_buckets:""/buckets"" cipher:true signature:-1177174368 metrics_interval_sec:15 version:""30GB 3.51 4310e1fac"" I0610 02:02:41.372100 filer_client.go:120 read directory: directory:""/buckets"" limit:2147483647 I0610 02:02:41.372218 filer_grpc_server.go:40 ListEntries directory:""/buckets"" limit:2147483647 I0610 02:02:41.372354 filer_client.go:120 read directory: directory:""/buckets/juicefs5/.uploads"" limit:2147483647 I0610 02:02:41.372439 filer_grpc_server.go:40 ListEntries directory:""/buckets/juicefs5/.uploads"" limit:2147483647 I0610 02:02:41.372538 master_server.go:323 executing: unlock [] I0610 02:02:42.340022 volume_layout.go:380 Volume 64 becomes unwritable I0610 02:02:42.340040 volume_layout.go:472 Volume 64 reaches full capacity. I0610 02:02:45.298013 volume_grpc_client_to_master.go:232 volume server 172.17.0.16:8080 heartbeat I0610 02:02:45.298074 store.go:589 disk /data max 11943 unclaimedSpace:1527235MB, unused:17592186042872MB volumeSizeLimit:128MB I0610 02:02:45.298085 volume.go:273 collectStatus volume 56 I0610 02:02:45.298092 volume.go:273 collectStatus volume 60 I0610 02:02:45.298096 volume.go:273 collectStatus volume 57 I0610 02:02:45.298099 volume.go:273 collectStatus volume 61 I0610 02:02:45.298103 volume.go:273 collectStatus volume 62 I0610 02:02:45.298109 volume.go:273 collectStatus volume 63 I0610 02:02:45.298112 volume.go:273 collectStatus volume 64 I0610 02:02:45.298114 volume.go:273 collectStatus volume 54 I0610 02:02:45.298117 volume.go:273 collectStatus volume 55 I0610 02:02:45.298121 volume.go:273 collectStatus volume 2 I0610 02:02:45.298124 volume.go:273 collectStatus volume 58 I0610 02:02:45.298127 volume.go:273 collectStatus volume 65 I0610 02:02:45.298130 volume.go:273 collectStatus volume 53 I0610 02:02:45.298369 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 public_url:""seaweedfs-lab5-volume1.xxx.io"" max_file_key:9206 data_center:""dc1"" rack:""rack1"" volumes:{id:56 size:364910720 collection:""juicefs5"" file_count:87 version:3 modified_at_second:1686362527} volumes:{id:60 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362538} volumes:{id:57 size:213913184 collection:""juicefs5"" file_count:51 version:3 modified_at_second:1686362526} volumes:{id:61 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362547} volumes:{id:62 size:209718808 collection:""juicefs5"" file_count:50 version:3 modified_at_second:1686362547} volumes:{id:63 size:327161336 collection:""juicefs5"" file_count:78 version:3 modified_at_second:1686362555} volumes:{id:64 size:397417152 collection:""juicefs5"" file_count:95 version:3 modified_at_second:1686362560} volumes:{id:54 size:181406824 collection:""juicefs5"" file_count:44 version:3 modified_at_second:1686362507} volumes:{id:55 size:356523472 collection:""juicefs5"" file_count:86 version:3 modified_at_second:1686362516} volumes:{id:2 size:4929760 file_count:29 version:3 modified_at_second:1686362531} volumes:{id:58 size:356521968 collection:""juicefs5"" file_count:85 version:3 modified_at_second:1686362532} volumes:{id:65 size:12583136 collection:""juicefs5"" file_count:3 version:3 modified_at_second:1686362560} volumes:{id:53 size:351311008 collection:""juicefs5"" file_count:98 version:3 modified_at_second:1686362507} max_volume_counts:{key:"""" value:11943} grpc_port:18080 location_uuids:""5d846bf0-9b0c-4178-9301-ec200e3c84b1"" I0610 02:02:50.298447 volume_grpc_client_to_master.go:232 volume server 172.17.0.16:8080 heartbeat I0610 02:02:50.298518 store.go:589 disk /data max 11943 unclaimedSpace:1527235MB, unused:17592186042872MB volumeSizeLimit:128MB I0610 02:02:50.298531 volume.go:273 collectStatus volume 53 I0610 02:02:50.298540 volume.go:273 collectStatus volume 60 I0610 02:02:50.298545 volume.go:273 collectStatus volume 56 I0610 02:02:50.298549 volume.go:273 collectStatus volume 61 I0610 02:02:50.298552 volume.go:273 collectStatus volume 62 I0610 02:02:50.298558 volume.go:273 collectStatus volume 63 I0610 02:02:50.298562 volume.go:273 collectStatus volume 64 I0610 02:02:50.298565 volume.go:273 collectStatus volume 57 I0610 02:02:50.298569 volume.go:273 collectStatus volume 55 I0610 02:02:50.298572 volume.go:273 collectStatus volume 2 I0610 02:02:50.298577 volume.go:273 collectStatus volume 58 I0610 02:02:50.298582 volume.go:273 collectStatus volume 65 I0610 02:02:50.298588 volume.go:273 collectStatus volume 54 I0610 02:02:50.298826 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 public_url:""seaweedfs-lab5-volume1.xxx.io"" max_file_key:9206 data_center:""dc1"" rack:""rack1"" volumes:{id:53 size:351311008 collection:""juicefs5"" file_count:98 version:3 modified_at_second:1686362507} volumes:{id:60 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362538} volumes:{id:56 size:364910720 collection:""juicefs5"" file_count:87 version:3 modified_at_second:1686362527} volumes:{id:61 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362547} volumes:{id:62 size:209718808 collection:""juicefs5"" file_count:50 version:3 modified_at_second:1686362547} volumes:{id:63 size:327161336 collection:""juicefs5"" file_count:78 version:3 modified_at_second:1686362555} volumes:{id:64 size:397417152 collection:""juicefs5"" file_count:95 version:3 modified_at_second:1686362560} volumes:{id:57 size:213913184 collection:""juicefs5"" file_count:51 version:3 modified_at_second:1686362526} volumes:{id:55 size:356523472 collection:""juicefs5"" file_count:86 version:3 modified_at_second:1686362516} volumes:{id:2 size:4929760 file_count:29 version:3 modified_at_second:1686362531} volumes:{id:58 size:356521968 collection:""juicefs5"" file_count:85 version:3 modified_at_second:1686362532} volumes:{id:65 size:12583136 collection:""juicefs5"" file_count:3 version:3 modified_at_second:1686362560} volumes:{id:54 size:181406824 collection:""juicefs5"" file_count:44 version:3 modified_at_second:1686362507} max_volume_counts:{key:"""" value:11943} grpc_port:18080 location_uuids:""5d846bf0-9b0c-4178-9301-ec200e3c84b1"" skip I0610 02:03:19.231519 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_0_4194304 I0610 02:03:19.231543 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_0_4194304 I0610 02:03:19.231737 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.265913 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_2_4194304 I0610 02:03:19.265937 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_2_4194304 I0610 02:03:19.266090 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.362210 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_3_4194304 I0610 02:03:19.362232 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_3_4194304 I0610 02:03:19.362378 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.370622 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_1_4194304 I0610 02:03:19.370638 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_1_4194304 I0610 02:03:19.370758 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.379584 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:19.379606 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:19.379812 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.380124 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:19.472238 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:19.472254 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:19.472428 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.472671 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:19.480845 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_6_4194304 I0610 02:03:19.480859 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_6_4194304 I0610 02:03:19.480979 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.481813 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_7_4194304 I0610 02:03:19.481825 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304 I0610 02:03:19.481942 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.482105 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:19.507197 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_8_4194304 I0610 02:03:19.507213 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_8_4194304 I0610 02:03:19.507343 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.530024 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_9_4194304 I0610 02:03:19.530043 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_9_4194304 I0610 02:03:19.530186 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.530428 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:19.568549 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_10_4194304 I0610 02:03:19.568572 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304 I0610 02:03:19.568549 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_11_4194304 I0610 02:03:19.568610 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_11_4194304 I0610 02:03:19.568704 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.568706 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.569001 stream.go:89 waiting for chunk: 59,227d582687c5 I0610 02:03:19.593964 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_12_4194304 I0610 02:03:19.593986 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_12_4194304 I0610 02:03:19.594144 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.623503 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:19.632820 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:19.719809 stream.go:89 waiting for chunk: 59,227d582687c5 I0610 02:03:20.131116 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:20.223830 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:20.233399 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:20.297937 volume_grpc_client_to_master.go:232 volume server 172.17.0.16:8080 heartbeat I0610 02:03:20.297988 store.go:589 disk /data max 11943 unclaimedSpace:1527235MB, unused:17592186042872MB volumeSizeLimit:128MB I0610 02:03:20.297998 volume.go:273 collectStatus volume 56 I0610 02:03:20.298004 volume.go:273 collectStatus volume 60 I0610 02:03:20.298008 volume.go:273 collectStatus volume 63 I0610 02:03:20.298010 volume.go:273 collectStatus volume 64 I0610 02:03:20.298013 volume.go:273 collectStatus volume 57 I0610 02:03:20.298015 volume.go:273 collectStatus volume 61 I0610 02:03:20.298017 volume.go:273 collectStatus volume 62 I0610 02:03:20.298022 volume.go:273 collectStatus volume 58 I0610 02:03:20.298024 volume.go:273 collectStatus volume 65 I0610 02:03:20.298027 volume.go:273 collectStatus volume 54 I0610 02:03:20.298029 volume.go:273 collectStatus volume 55 I0610 02:03:20.298031 volume.go:273 collectStatus volume 2 I0610 02:03:20.298033 volume.go:273 collectStatus volume 53 I0610 02:03:20.298242 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 public_url:""seaweedfs-lab5-volume1.xxx.io"" max_file_key:9207 data_center:""dc1"" rack:""rack1"" volumes:{id:56 size:364910720 collection:""juicefs5"" file_count:87 version:3 modified_at_second:1686362527} volumes:{id:60 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362538} volumes:{id:63 size:327161336 collection:""juicefs5"" file_count:78 version:3 modified_at_second:1686362555} volumes:{id:64 size:397417152 collection:""juicefs5"" file_count:95 version:3 modified_at_second:1686362560} volumes:{id:57 size:213913184 collection:""juicefs5"" file_count:51 version:3 modified_at_second:1686362526} volumes:{id:61 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362547} volumes:{id:62 size:209718808 collection:""juicefs5"" file_count:50 version:3 modified_at_second:1686362547} volumes:{id:58 size:356521968 collection:""juicefs5"" file_count:85 version:3 modified_at_second:1686362532} volumes:{id:65 size:12583136 collection:""juicefs5"" file_count:3 version:3 modified_at_second:1686362560} volumes:{id:54 size:181406824 collection:""juicefs5"" file_count:44 version:3 modified_at_second:1686362507} volumes:{id:55 size:356523472 collection:""juicefs5"" file_count:86 version:3 modified_at_second:1686362516} volumes:{id:2 size:5047368 file_count:30 version:3 modified_at_second:1686362591} volumes:{id:53 size:351311008 collection:""juicefs5"" file_count:98 version:3 modified_at_second:1686362507} max_volume_counts:{key:"""" value:11943} grpc_port:18080 location_uuids:""5d846bf0-9b0c-4178-9301-ec200e3c84b1"" I0610 02:03:20.320520 stream.go:89 waiting for chunk: 59,227d582687c5 E0610 02:03:21.931464 stream.go:97 operation LookupFileId 59,2277719b1e43 failed, err: urls not found E0610 02:03:21.931719 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304: operation LookupFileId 59,2277719b1e43 failed, err: urls not found E0610 02:03:21.931734 common.go:297 processRangeRequest: operation LookupFileId 59,2277719b1e43 failed, err: urls not found I0610 02:03:21.931886 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:21.977787 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:21.977808 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:21.977974 stream.go:75 start to stream content for chunks: 1 I0610 02:03:21.978197 stream.go:89 waiting for chunk: 59,2277719b1e43 E0610 02:03:22.024472 stream.go:97 operation LookupFileId 59,2278b138056e failed, err: urls not found E0610 02:03:22.024485 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304: operation LookupFileId 59,2278b138056e failed, err: urls not found E0610 02:03:22.024492 common.go:297 processRangeRequest: operation LookupFileId 59,2278b138056e failed, err: urls not found I0610 02:03:22.024590 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF E0610 02:03:22.033660 stream.go:97 operation LookupFileId 59,227af658f241 failed, err: urls not found E0610 02:03:22.033671 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304: operation LookupFileId 59,227af658f241 failed, err: urls not found E0610 02:03:22.033677 common.go:297 processRangeRequest: operation LookupFileId 59,227af658f241 failed, err: urls not found I0610 02:03:22.033768 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:22.068682 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:22.068693 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:22.068786 stream.go:75 start to stream content for chunks: 1 I0610 02:03:22.068991 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:22.080083 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_7_4194304 I0610 02:03:22.080093 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304 I0610 02:03:22.080210 stream.go:75 start to stream content for chunks: 1 I0610 02:03:22.080381 stream.go:89 waiting for chunk: 59,227af658f241 E0610 02:03:22.121560 stream.go:97 operation LookupFileId 59,227d582687c5 failed, err: urls not found E0610 02:03:22.121578 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304: operation LookupFileId 59,227d582687c5 failed, err: urls not found E0610 02:03:22.121586 common.go:297 processRangeRequest: operation LookupFileId 59,227d582687c5 failed, err: urls not found I0610 02:03:22.121664 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:22.128904 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:22.162302 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_10_4194304 I0610 02:03:22.162317 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304 I0610 02:03:22.162426 stream.go:75 start to stream content for chunks: 1 I0610 02:03:22.162616 stream.go:89 waiting for chunk: 59,227d582687c5 I0610 02:03:22.219153 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:22.230544 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:22.313054 stream.go:89 waiting for chunk: 59,227d582687c5 I0610 02:03:22.729968 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:22.819452 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:22.830716 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:22.914313 stream.go:89 waiting for chunk: 59,227d582687c5 E0610 02:03:24.530581 stream.go:97 operation LookupFileId 59,2277719b1e43 failed, err: urls not found E0610 02:03:24.530607 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304: operation LookupFileId 59,2277719b1e43 failed, err: urls not found E0610 02:03:24.530619 common.go:297 processRangeRequest: operation LookupFileId 59,2277719b1e43 failed, err: urls not found I0610 02:03:24.530758 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF E0610 02:03:24.619885 stream.go:97 operation LookupFileId 59,2278b138056e failed, err: urls not found E0610 02:03:24.619899 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304: operation LookupFileId 59,2278b138056e failed, err: urls not found E0610 02:03:24.619906 common.go:297 processRangeRequest: operation LookupFileId 59,2278b138056e failed, err: urls not found I0610 02:03:24.620003 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:24.630463 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:24.630479 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:24.630625 stream.go:75 start to stream content for chunks: 1 E0610 02:03:24.630835 stream.go:97 operation LookupFileId 59,227af658f241 failed, err: urls not found E0610 02:03:24.630847 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304: operation LookupFileId 59,227af658f241 failed, err: urls not found E0610 02:03:24.630859 common.go:297 processRangeRequest: operation LookupFileId 59,227af658f241 failed, err: urls not found I0610 02:03:24.630876 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:24.630935 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:24.702655 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:24.702670 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:24.702880 stream.go:75 start to stream content for chunks: 1 I0610 02:03:24.703050 stream.go:89 waiting for chunk: 59,2278b138056e E0610 02:03:24.715283 stream.go:97 operation LookupFileId 59,227d582687c5 failed, err: urls not found E0610 02:03:24.715296 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304: operation LookupFileId 59,227d582687c5 failed, err: urls not found E0610 02:03:24.715303 common.go:297 processRangeRequest: operation LookupFileId 59,227d582687c5 failed, err: urls not found I0610 02:03:24.715396 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF skip  `volume.deleteEmpty` triggers `DeleteVolume 59`, but volume 59 is not empty(already have chunks been uploaded to volume 59) when `volume.deleteEmpty` is executed.",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[data lost][shell] cmd `volume.deleteEmpty` occasionally deletes non-empty volume **Describe the bug** Occasionally some files are corrupted, if the `volume.deleteEmpty` maintenance command is executed when putting files to filer. **System Setup** - weed version: 3.51 - include `volume.deleteEmpty` command in `master.maintenance`, like [the default `master.maintenance`](https://github.com/seaweedfs/seaweedfs/blob/5ee04d20fac54daf3ceba7469adce824f30dc678/weed/command/scaffold/master.toml#L14) **Scene** - Put some files to filer when the maintenance script is about to be executed(which is unnoticed) - `volume.deleteEmpty` maintenance command is executed when putting files - Put finished - Some of these files are unreadable(`stream.go:97 operation LookupFileId 32,017966854c964a failed, err: urls not found` error in log), although in the filer's file list **Expected behavior** All the files newly put to the filer are readable. **Additional context** Real scene `weed.INFO` logs (see `volume 32`, `32,` and `volume.deleteEmpty`):  Log file created at: 2023/06/05 03:17:52 Running on machine: 720cf4b7c503 Binary: Built with gc go1.20.4 for linux/amd64 Log line format: [IWEF]mmdd hh:mm:ss threadid file:line] msg I0605 03:17:52.268844 master.go:269 current: 172.17.0.8:9333 peers: I0605 03:17:52.269008 file_util.go:23 Folder /data_master_meta Permission: -rwx I0605 03:17:52.269139 file_util.go:23 Folder /data Permission: -rwx I0605 03:17:52.269181 s3_backend.go:60 created backend storage s3.storage1 for region cn-east-1 bucket seaweedfs1storage1 I0605 03:17:52.269189 master.go:269 current: 172.17.0.8:9333 peers:172.17.0.8:9333 I0605 03:17:52.269304 master_server.go:127 Volume Size Limit is 1024 MB I0605 03:17:52.269443 master_server.go:265 adminScripts: lock volume.deleteEmpty -quietFor=24h -force volume.balance -force volume.fix.replication s3.clean.uploads -timeAgo=24h unlock I0605 03:17:52.269486 master.go:150 Start Seaweed Master 30GB 3.51 4310e1fac at 172.17.0.8:9333 I0605 03:17:52.269704 volume_grpc_client_to_master.go:43 checkWithMaster 172.17.0.8:9333: get master 172.17.0.8:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.8:19333: connect: connection refused"" I0605 03:17:52.269723 raft_server.go:118 Starting RaftServer with 172.17.0.8:9333 I0605 03:17:52.273131 raft_server.go:167 current cluster leader: I0605 03:17:54.061095 volume_grpc_client_to_master.go:43 checkWithMaster 172.17.0.8:9333: get master 172.17.0.8:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.8:19333: connect: connection refused"" skip I0605 07:22:22.313206 master_server.go:323 executing: lock [] I0605 07:22:22.313584 master_server.go:323 executing: volume.deleteEmpty [-quietFor=24h -force] I0605 07:22:22.313852 master_server.go:323 executing: volume.balance [-force] I0605 07:22:37.314914 master_server.go:323 executing: volume.fix.replication [] I0605 07:22:52.315764 master_server.go:323 executing: s3.clean.uploads [-timeAgo=24h] I0605 07:22:52.316443 master_server.go:323 executing: unlock [] I0605 07:39:18.051688 store.go:166 In dir /data adds volume:31 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:39:18.051787 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_31.idx to memory I0605 07:39:18.055494 store.go:170 add volume 31 I0605 07:39:18.055517 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 31 I0605 07:39:18.055553 volume_growth.go:244 Created Volume 31 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:18.055567 volume_layout.go:393 Volume 31 becomes writable I0605 07:39:18.055576 volume_growth.go:257 Registered Volume 31 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:24.019433 volume_layout.go:380 Volume 30 becomes unwritable I0605 07:39:24.019442 volume_layout.go:472 Volume 30 reaches full capacity. I0605 07:39:51.358467 store.go:166 In dir /data adds volume:32 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:39:51.358584 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_32.idx to memory I0605 07:39:51.369318 store.go:170 add volume 32 I0605 07:39:51.369359 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 32 I0605 07:39:51.369392 volume_growth.go:244 Created Volume 32 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:51.369409 volume_layout.go:393 Volume 32 becomes writable I0605 07:39:51.369420 volume_growth.go:257 Registered Volume 32 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:52.316741 master_server.go:323 executing: lock [] I0605 07:39:52.317054 master_server.go:323 executing: volume.deleteEmpty [-quietFor=24h -force] I0605 07:39:52.338801 store.go:526 DeleteVolume 32 I0605 07:39:52.338852 volume_grpc_client_to_master.go:210 volume server 172.17.0.8:8080 deletes volume 32 I0605 07:39:52.338949 master_server.go:323 executing: volume.balance [-force] I0605 07:39:52.338976 topology.go:258 removing volume info: Id:32, Size:0, ReplicaPlacement:000, Collection:juicefs4, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from 172.17.0.8:8080 I0605 07:39:52.338994 volume_layout.go:223 volume 32 does not have enough copies I0605 07:39:52.338996 volume_layout.go:228 volume 32 remove from writable I0605 07:39:52.338998 volume_layout.go:380 Volume 32 becomes unwritable I0605 07:39:52.369975 store.go:166 In dir /data adds volume:33 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:39:52.370081 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_33.idx to memory I0605 07:39:52.373846 store.go:170 add volume 33 I0605 07:39:52.373864 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 33 I0605 07:39:52.373908 volume_growth.go:244 Created Volume 33 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:52.373919 volume_layout.go:393 Volume 33 becomes writable I0605 07:39:52.373923 volume_growth.go:257 Registered Volume 33 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:39:56.650085 volume_layout.go:380 Volume 31 becomes unwritable I0605 07:39:56.650097 volume_layout.go:472 Volume 31 reaches full capacity. I0605 07:40:07.339434 master_server.go:323 executing: volume.fix.replication [] I0605 07:40:22.340328 master_server.go:323 executing: s3.clean.uploads [-timeAgo=24h] I0605 07:40:22.340933 master_server.go:323 executing: unlock [] I0605 07:40:26.247358 volume_layout.go:484 Volume 33 becomes crowded I0605 07:40:26.360142 store.go:166 In dir /data adds volume:34 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:40:26.360245 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_34.idx to memory I0605 07:40:26.366895 store.go:170 add volume 34 I0605 07:40:26.366924 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 34 I0605 07:40:26.366957 volume_growth.go:244 Created Volume 34 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:40:26.366972 volume_layout.go:393 Volume 34 becomes writable I0605 07:40:26.366977 volume_growth.go:257 Registered Volume 34 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:40:33.908426 volume_layout.go:380 Volume 33 becomes unwritable I0605 07:40:33.908437 volume_layout.go:472 Volume 33 reaches full capacity. I0605 07:41:06.249505 store.go:166 In dir /data adds volume:35 collection:juicefs4 replicaPlacement:000 ttl: I0605 07:41:06.249648 volume_loading.go:142 loading memory index /data_volume_index/juicefs4_35.idx to memory I0605 07:41:06.260440 store.go:170 add volume 35 I0605 07:41:06.260471 volume_grpc_client_to_master.go:179 volume server 172.17.0.8:8080 adds volume 35 I0605 07:41:06.260544 volume_growth.go:244 Created Volume 35 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:41:06.260562 volume_layout.go:393 Volume 35 becomes writable I0605 07:41:06.260570 volume_growth.go:257 Registered Volume 35 on topo:dc1:rack1:172.17.0.8:8080 I0605 07:41:13.770598 volume_layout.go:380 Volume 34 becomes unwritable I0605 07:41:13.770616 volume_layout.go:472 Volume 34 reaches full capacity. E0605 07:42:14.301994 stream.go:97 operation LookupFileId 32,017965c5ce6d4e failed, err: urls not found E0605 07:42:14.302183 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs4/juicefs4/chunks/0/1/1035_11_4194304: operation LookupFileId 32,017965c5ce6d4e failed, err: urls not found E0605 07:42:14.302199 common.go:297 processRangeRequest: operation LookupFileId 32,017965c5ce6d4e failed, err: urls not found E0605 07:42:15.513498 stream.go:97 operation LookupFileId 32,017966854c964a failed, err: urls not found E0605 07:42:15.513521 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs4/juicefs4/chunks/0/1/1036_2_4194304: operation LookupFileId 32,017966854c964a failed, err: urls not found E0605 07:42:15.513531 common.go:297 processRangeRequest: operation LookupFileId 32,017966854c964a failed, err: urls not found E0605 07:42:15.513501 stream.go:97 operation LookupFileId 32,0179643b8a24c7 failed, err: urls not found E0605 07:42:15.513588 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs4/juicefs4/chunks/0/1/1036_1_4194304: operation LookupFileId 32,0179643b8a24c7 failed, err: urls not found E0605 07:42:15.513595 common.go:297 processRangeRequest: operation LookupFileId 32,0179643b8a24c7 failed, err: urls not found skip I0605 08:22:38.321250 common.go:75 response method:GET URL:/dir/lookup?fileId=32,0179643b8a24c7 with httpStatus:404 and JSON:{""volumeOrFileId"":""32"",""error"":""volume id 32 not found""} I0605 08:23:49.336870 common.go:75 response method:GET URL:/dir/lookup?fileId=32,0179643b8a24c7&collection=juicefs4 with httpStatus:404 and JSON:{""volumeOrFileId"":""32"",""error"":""volume id 32 not found""}  Test for this issue scene `weed.INFO` logs (see `volume 59`, `2778_4_4194304` and `volume.deleteEmpty`):  Log file created at: 2023/06/10 01:46:10 Running on machine: 25901906dec2 Binary: Built with gc go1.20.4 for linux/amd64 Log line format: [IWEF]mmdd hh:mm:ss threadid file:line] msg I0610 01:46:10.113090 config.go:46 Reading : Config File ""security"" Not Found in ""[/data /root/.seaweedfs /usr/local/etc/seaweedfs /etc/seaweedfs]"" I0610 01:46:10.113421 config.go:59 Reading master.toml from /etc/seaweedfs/master.toml I0610 01:46:10.113431 master.go:269 current: 172.17.0.16:9333 peers: I0610 01:46:10.113446 file_util.go:23 Folder /data_master_meta Permission: -rwx I0610 01:46:10.113558 file_util.go:23 Folder /data Permission: -rwx I0610 01:46:10.113654 s3_backend.go:60 created backend storage s3.storage1 for region cn-east-1 bucket seaweedfs1storage1 I0610 01:46:10.113663 master.go:269 current: 172.17.0.16:9333 peers:172.17.0.16:9333 I0610 01:46:10.113718 master_server.go:335 [master.sequencer.type] : [] I0610 01:46:10.113730 master_server.go:127 Volume Size Limit is 128 MB I0610 01:46:10.113882 master_server.go:265 adminScripts: lock volume.vacuum -garbageThreshold=0.000001 -collection=juicefs5 volume.deleteEmpty -quietFor=1s -force volume.balance -force volume.fix.replication s3.clean.uploads -timeAgo=24h unlock I0610 01:46:10.113917 master.go:150 Start Seaweed Master 30GB 3.51 4310e1fac at 172.17.0.16:9333 I0610 01:46:10.113941 masterclient.go:127 .adminShell masterClient bootstraps with masters map[172.17.0.16:9333:172.17.0.16:9333] I0610 01:46:10.113956 masterclient.go:172 .adminShell masterClient Connecting to master 172.17.0.16:9333 I0610 01:46:10.114055 volume_grpc_client_to_master.go:43 checkWithMaster 172.17.0.16:9333: get master 172.17.0.16:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:10.114147 masterclient.go:180 .adminShell masterClient failed to keep connected to 172.17.0.16:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:10.114167 masterclient.go:260 .adminShell masterClient failed to connect with master 172.17.0.16:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:10.114190 raft_server.go:118 Starting RaftServer with 172.17.0.16:9333 I0610 01:46:10.126603 raft_server.go:167 current cluster leader: I0610 01:46:11.114567 masterclient.go:172 .adminShell masterClient Connecting to master 172.17.0.16:9333 I0610 01:46:11.115288 masterclient.go:180 .adminShell masterClient failed to keep connected to 172.17.0.16:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:11.115325 masterclient.go:260 .adminShell masterClient failed to connect with master 172.17.0.16:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" I0610 01:46:11.904728 volume_grpc_client_to_master.go:43 checkWithMaster 172.17.0.16:9333: get master 172.17.0.16:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 172.17.0.16:19333: connect: connection refused"" skip I0610 02:02:10.255037 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_2_4194304 I0610 02:02:10.255163 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.297570 volume_grpc_client_to_master.go:232 volume server 172.17.0.16:8080 heartbeat I0610 02:02:10.297610 store.go:589 disk /data max 11943 unclaimedSpace:1528003MB, unused:17592186043623MB volumeSizeLimit:128MB I0610 02:02:10.297618 volume.go:273 collectStatus volume 53 I0610 02:02:10.297623 volume.go:273 collectStatus volume 56 I0610 02:02:10.297626 volume.go:273 collectStatus volume 57 I0610 02:02:10.297628 volume.go:273 collectStatus volume 55 I0610 02:02:10.297630 volume.go:273 collectStatus volume 2 I0610 02:02:10.297632 volume.go:273 collectStatus volume 58 I0610 02:02:10.297634 volume.go:273 collectStatus volume 54 I0610 02:02:10.297798 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 public_url:""seaweedfs-lab5-volume1.xxx.io"" max_file_key:8820 data_center:""dc1"" rack:""rack1"" volumes:{id:53 size:351311008 collection:""juicefs5"" file_count:98 version:3 modified_at_second:1686362507} volumes:{id:56 size:364910720 collection:""juicefs5"" file_count:87 version:3 modified_at_second:1686362527} volumes:{id:57 size:213913184 collection:""juicefs5"" file_count:51 version:3 modified_at_second:1686362526} volumes:{id:55 size:356523472 collection:""juicefs5"" file_count:86 version:3 modified_at_second:1686362516} volumes:{id:2 size:4789384 file_count:28 version:3 modified_at_second:1686362291} volumes:{id:58 size:297800704 collection:""juicefs5"" file_count:71 version:3 modified_at_second:1686362530} volumes:{id:54 size:181406824 collection:""juicefs5"" file_count:44 version:3 modified_at_second:1686362507} max_volume_counts:{key:"""" value:11943} grpc_port:18080 location_uuids:""5d846bf0-9b0c-4178-9301-ec200e3c84b1"" I0610 02:02:10.300708 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.300888 master_grpc_server_volume.go:54 starting automatic volume grow I0610 02:02:10.300980 cluster_commands.go:32 max volume id 58 ==> 59 I0610 02:02:10.301138 store.go:166 In dir /data adds volume:59 collection:juicefs5 replicaPlacement:000 ttl: I0610 02:02:10.301160 volume_info.go:21 maybeLoadVolumeInfo checks /data/juicefs5_59.vif I0610 02:02:10.301265 volume_loading.go:121 open to write file /data_volume_index/juicefs5_59.idx I0610 02:02:10.301297 volume_loading.go:142 loading memory index /data_volume_index/juicefs5_59.idx to memory I0610 02:02:10.301311 needle_map_memory.go:54 max file key: 0 for file: /data_volume_index/juicefs5_59.idx I0610 02:02:10.311008 filer_server_handlers_write_upload.go:123 uploaded 2778_2_4194304 chunk 1 to 58,2275ad7334fb [0,4194304) I0610 02:02:10.311039 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_2_4194304 I0610 02:02:10.311053 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.311076 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_2_4194304: new entry: 2778_2_4194304 I0610 02:02:10.311126 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_2_4194304: created I0610 02:02:10.311222 error_handler.go:96 status 200 : I0610 02:02:10.313978 store.go:170 add volume 59 I0610 02:02:10.313991 volume_grpc_admin.go:60 assign volume volume_id:59 collection:""juicefs5"" replication:""000"" I0610 02:02:10.314030 volume_grpc_client_to_master.go:179 volume server 172.17.0.16:8080 adds volume 59 I0610 02:02:10.314113 volume_growth.go:244 Created Volume 59 on topo:dc1:rack1:172.17.0.16:8080 I0610 02:02:10.314132 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 data_center:""dc1"" rack:""rack1"" new_volumes:{id:59 collection:""juicefs5"" version:3} I0610 02:02:10.314132 volume_layout.go:393 Volume 59 becomes writable I0610 02:02:10.314141 volume_growth.go:257 Registered Volume 59 on topo:dc1:rack1:172.17.0.16:8080 I0610 02:02:10.314148 master_grpc_server_volume.go:57 finished automatic volume grow, cost 13.253062ms I0610 02:02:10.314212 masterclient.go:278 .master: 172.17.0.16:8080 masterClient adds volume 59 I0610 02:02:10.314224 vid_map.go:160 + volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:10.314235 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:10.314245 masterclient.go:278 .master: 172.17.0.16:8080 masterClient adds volume 59 I0610 02:02:10.314245 masterclient.go:278 .filer: 172.17.0.16:8080 masterClient adds volume 59 I0610 02:02:10.314252 vid_map.go:160 + volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:10.314254 vid_map.go:160 + volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:10.314259 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:10.314261 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:10.314271 masterclient.go:278 .filer: 172.17.0.16:8080 masterClient adds volume 59 I0610 02:02:10.314278 vid_map.go:160 + volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:10.314284 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:10.335126 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_3_4194304 I0610 02:02:10.335226 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.381414 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.391830 filer_server_handlers_write_upload.go:123 uploaded 2778_3_4194304 chunk 1 to 58,2276f615a530 [0,4194304) I0610 02:02:10.391859 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_3_4194304 I0610 02:02:10.391880 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.391910 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_3_4194304: new entry: 2778_3_4194304 I0610 02:02:10.391972 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_3_4194304: created I0610 02:02:10.392068 error_handler.go:96 status 200 : I0610 02:02:10.415360 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_4_4194304 I0610 02:02:10.415484 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.461860 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.473749 filer_server_handlers_write_upload.go:123 uploaded 2778_4_4194304 chunk 1 to 59,2277719b1e43 [0,4194304) I0610 02:02:10.473777 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304 I0610 02:02:10.473790 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.473819 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304: new entry: 2778_4_4194304 I0610 02:02:10.473867 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304: created I0610 02:02:10.473958 error_handler.go:96 status 200 : I0610 02:02:10.494892 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_5_4194304 I0610 02:02:10.494996 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.541004 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.551757 filer_server_handlers_write_upload.go:123 uploaded 2778_5_4194304 chunk 1 to 59,2278b138056e [0,4194304) I0610 02:02:10.551796 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304 I0610 02:02:10.551817 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.551854 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304: new entry: 2778_5_4194304 I0610 02:02:10.551932 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304: created I0610 02:02:10.552023 error_handler.go:96 status 200 : I0610 02:02:10.575416 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_6_4194304 I0610 02:02:10.575546 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.621928 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.632082 filer_server_handlers_write_upload.go:123 uploaded 2778_6_4194304 chunk 1 to 58,227905727806 [0,4194304) I0610 02:02:10.632105 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_6_4194304 I0610 02:02:10.632119 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.632140 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_6_4194304: new entry: 2778_6_4194304 I0610 02:02:10.632199 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_6_4194304: created I0610 02:02:10.632288 error_handler.go:96 status 200 : I0610 02:02:10.654974 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_7_4194304 I0610 02:02:10.655092 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.703499 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.715016 filer_server_handlers_write_upload.go:123 uploaded 2778_7_4194304 chunk 1 to 59,227af658f241 [0,4194304) I0610 02:02:10.715054 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304 I0610 02:02:10.715068 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.715096 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304: new entry: 2778_7_4194304 I0610 02:02:10.715160 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304: created I0610 02:02:10.715279 error_handler.go:96 status 200 : I0610 02:02:10.735581 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_8_4194304 I0610 02:02:10.735706 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.782947 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.793441 filer_server_handlers_write_upload.go:123 uploaded 2778_8_4194304 chunk 1 to 58,227b66ca4947 [0,4194304) I0610 02:02:10.793471 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_8_4194304 I0610 02:02:10.793491 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.793509 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_8_4194304: new entry: 2778_8_4194304 I0610 02:02:10.793557 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_8_4194304: created I0610 02:02:10.793667 error_handler.go:96 status 200 : I0610 02:02:10.815333 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_9_4194304 I0610 02:02:10.815451 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.863066 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.873599 filer_server_handlers_write_upload.go:123 uploaded 2778_9_4194304 chunk 1 to 58,227cac005e0c [0,4194304) I0610 02:02:10.873626 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_9_4194304 I0610 02:02:10.873640 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.873662 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_9_4194304: new entry: 2778_9_4194304 I0610 02:02:10.873713 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_9_4194304: created I0610 02:02:10.873799 error_handler.go:96 status 200 : I0610 02:02:10.895645 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_10_4194304 I0610 02:02:10.895767 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:10.941907 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:10.952838 filer_server_handlers_write_upload.go:123 uploaded 2778_10_4194304 chunk 1 to 59,227d582687c5 [0,4194304) I0610 02:02:10.952869 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304 I0610 02:02:10.952886 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:10.952908 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304: new entry: 2778_10_4194304 I0610 02:02:10.952970 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304: created I0610 02:02:10.953062 error_handler.go:96 status 200 : I0610 02:02:10.957717 webdav_server.go:382 WebDavFileSystem.Stat / I0610 02:02:10.957867 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.957981 webdav_server.go:209 WebDavFileSystem.OpenFile / 0 I0610 02:02:10.958065 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.958126 webdav_server.go:615 WebDavFile.Stat / I0610 02:02:10.958203 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.958263 webdav_server.go:498 WebDavFileSystem.Close / I0610 02:02:10.958272 webdav_server.go:209 WebDavFileSystem.OpenFile / 0 I0610 02:02:10.958334 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.958389 webdav_server.go:615 WebDavFile.Stat / I0610 02:02:10.958454 filer_grpc_server.go:22 LookupDirectoryEntry / I0610 02:02:10.958499 webdav_server.go:498 WebDavFileSystem.Close / I0610 02:02:10.975310 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_11_4194304 I0610 02:02:10.975440 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.022860 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.034451 filer_server_handlers_write_upload.go:123 uploaded 2778_11_4194304 chunk 1 to 58,227e9f9e0643 [0,4194304) I0610 02:02:11.034486 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_11_4194304 I0610 02:02:11.034501 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.034537 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_11_4194304: new entry: 2778_11_4194304 I0610 02:02:11.034593 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_11_4194304: created I0610 02:02:11.034691 error_handler.go:96 status 200 : I0610 02:02:11.055623 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_12_4194304 I0610 02:02:11.055742 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.102900 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.113771 filer_server_handlers_write_upload.go:123 uploaded 2778_12_4194304 chunk 1 to 58,227f4768efcb [0,4194304) I0610 02:02:11.113800 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_12_4194304 I0610 02:02:11.113815 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.113836 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_12_4194304: new entry: 2778_12_4194304 I0610 02:02:11.113881 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_12_4194304: created I0610 02:02:11.113986 error_handler.go:96 status 200 : I0610 02:02:11.126210 filer.go:236 find uncached directory: /topics/.system/log/2023-06-10 I0610 02:02:11.126225 filer.go:200 InsertEntry /topics/.system/log/2023-06-10/02-01.67ac9a39: new entry: 02-01.67ac9a39 I0610 02:02:11.126252 filer.go:221 CreateEntry /topics/.system/log/2023-06-10/02-01.67ac9a39: created I0610 02:02:11.136760 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_13_4194304 I0610 02:02:11.136863 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.185153 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.195553 filer_server_handlers_write_upload.go:123 uploaded 2778_13_4194304 chunk 1 to 59,22819cb0460c [0,4194304) I0610 02:02:11.195580 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_13_4194304 I0610 02:02:11.195596 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.195617 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_13_4194304: new entry: 2778_13_4194304 I0610 02:02:11.195680 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_13_4194304: created I0610 02:02:11.195778 error_handler.go:96 status 200 : I0610 02:02:11.215147 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_14_4194304 I0610 02:02:11.215269 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.262501 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.273419 filer_server_handlers_write_upload.go:123 uploaded 2778_14_4194304 chunk 1 to 58,22827cca16dd [0,4194304) I0610 02:02:11.273448 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_14_4194304 I0610 02:02:11.273466 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.273496 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_14_4194304: new entry: 2778_14_4194304 I0610 02:02:11.273565 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_14_4194304: created I0610 02:02:11.273645 error_handler.go:96 status 200 : I0610 02:02:11.295644 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_15_4194304 I0610 02:02:11.295774 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.336342 master_server.go:323 executing: lock [] I0610 02:02:11.336629 master_server.go:323 executing: volume.vacuum [-garbageThreshold=0.000001 -collection=juicefs5] I0610 02:02:11.336751 master_grpc_server_admin.go:93 isLocked 172.17.0.16: I0610 02:02:11.336760 master_grpc_server_admin.go:135 LeaseAdminToken 172.17.0.16 I0610 02:02:11.336775 topology_vacuum.go:225 Start vacuum on demand with threshold: 0.000001 collection: juicefs5 volumeId: 0 I0610 02:02:11.336792 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:58 I0610 02:02:11.336899 store_vacuum.go:13 volume 58 garbage level: 0.000000 I0610 02:02:11.336951 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:59 I0610 02:02:11.337021 store_vacuum.go:13 volume 59 garbage level: 0.000000 I0610 02:02:11.337074 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:53 I0610 02:02:11.337148 store_vacuum.go:13 volume 53 garbage level: 0.000000 I0610 02:02:11.337199 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:54 I0610 02:02:11.337277 store_vacuum.go:13 volume 54 garbage level: 0.000000 I0610 02:02:11.337343 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:55 I0610 02:02:11.337420 store_vacuum.go:13 volume 55 garbage level: 0.000000 I0610 02:02:11.337484 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:56 I0610 02:02:11.337550 store_vacuum.go:13 volume 56 garbage level: 0.000000 I0610 02:02:11.337604 topology_vacuum.go:275 check vacuum on collection:juicefs5 volume:57 I0610 02:02:11.337693 store_vacuum.go:13 volume 57 garbage level: 0.000000 I0610 02:02:11.337796 master_server.go:323 executing: volume.deleteEmpty [-quietFor=1s -force] I0610 02:02:11.346417 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.369826 store.go:526 DeleteVolume 59 I0610 02:02:11.369855 volume_grpc_client_to_master.go:210 volume server 172.17.0.16:8080 deletes volume 59 I0610 02:02:11.369841 volume_grpc_admin.go:108 volume delete volume_id:59 I0610 02:02:11.370036 master_server.go:323 executing: volume.balance [-force] I0610 02:02:11.370051 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 data_center:""dc1"" rack:""rack1"" deleted_volumes:{id:59 collection:""juicefs5"" version:3} I0610 02:02:11.370072 topology.go:258 removing volume info: Id:59, Size:0, ReplicaPlacement:000, Collection:juicefs5, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from 172.17.0.16:8080 I0610 02:02:11.370092 volume_layout.go:223 volume 59 does not have enough copies I0610 02:02:11.370101 volume_layout.go:228 volume 59 remove from writable I0610 02:02:11.370106 volume_layout.go:380 Volume 59 becomes unwritable I0610 02:02:11.370193 masterclient.go:282 .master: 172.17.0.16:8080 masterClient removes volume 59 I0610 02:02:11.370204 vid_map.go:208 - volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.370211 vid_map.go:208 - volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.370219 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 0, del: 1, add ec: 0 del ec: 0 I0610 02:02:11.370194 masterclient.go:282 .filer: 172.17.0.16:8080 masterClient removes volume 59 I0610 02:02:11.370228 vid_map.go:208 - volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.370234 vid_map.go:208 - volume id 59: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.370240 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 0, del: 1, add ec: 0 del ec: 0 I0610 02:02:11.372032 filer_server_handlers_write_upload.go:123 uploaded 2778_15_4194304 chunk 1 to 58,22833375ffc4 [0,4194304) I0610 02:02:11.372061 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2778_15_4194304 I0610 02:02:11.372078 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.372098 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_15_4194304: new entry: 2778_15_4194304 I0610 02:02:11.372155 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2778_15_4194304: created I0610 02:02:11.372236 error_handler.go:96 status 200 : I0610 02:02:11.378169 s3api_object_handlers.go:50 PutObjectHandler juicefs5 /juicefs5/chunks/0/2/2779_0_4194304 I0610 02:02:11.378280 filer_server_handlers_write_upload.go:68 received byte buffer 1 I0610 02:02:11.424544 filer_server_handlers_write_upload.go:68 received byte buffer 2 I0610 02:02:11.424721 master_grpc_server_volume.go:54 starting automatic volume grow I0610 02:02:11.424792 cluster_commands.go:32 max volume id 59 ==> 60 I0610 02:02:11.424906 store.go:166 In dir /data adds volume:60 collection:juicefs5 replicaPlacement:000 ttl: I0610 02:02:11.424927 volume_info.go:21 maybeLoadVolumeInfo checks /data/juicefs5_60.vif I0610 02:02:11.425000 volume_loading.go:121 open to write file /data_volume_index/juicefs5_60.idx I0610 02:02:11.425026 volume_loading.go:142 loading memory index /data_volume_index/juicefs5_60.idx to memory I0610 02:02:11.425047 needle_map_memory.go:54 max file key: 0 for file: /data_volume_index/juicefs5_60.idx I0610 02:02:11.428584 store.go:170 add volume 60 I0610 02:02:11.428594 volume_grpc_admin.go:60 assign volume volume_id:60 collection:""juicefs5"" replication:""000"" I0610 02:02:11.428629 volume_grpc_client_to_master.go:179 volume server 172.17.0.16:8080 adds volume 60 I0610 02:02:11.428697 volume_growth.go:244 Created Volume 60 on topo:dc1:rack1:172.17.0.16:8080 I0610 02:02:11.428712 volume_layout.go:393 Volume 60 becomes writable I0610 02:02:11.428719 volume_growth.go:257 Registered Volume 60 on topo:dc1:rack1:172.17.0.16:8080 I0610 02:02:11.428719 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 data_center:""dc1"" rack:""rack1"" new_volumes:{id:60 collection:""juicefs5"" version:3} I0610 02:02:11.428723 master_grpc_server_volume.go:57 finished automatic volume grow, cost 3.995524ms I0610 02:02:11.428816 masterclient.go:278 .filer: 172.17.0.16:8080 masterClient adds volume 60 I0610 02:02:11.428819 masterclient.go:278 .master: 172.17.0.16:8080 masterClient adds volume 60 I0610 02:02:11.428825 vid_map.go:160 + volume id 60: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.428827 vid_map.go:160 + volume id 60: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.428835 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:11.428838 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:11.428843 masterclient.go:278 .filer: 172.17.0.16:8080 masterClient adds volume 60 I0610 02:02:11.428846 vid_map.go:160 + volume id 60: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.428849 masterclient.go:278 .master: 172.17.0.16:8080 masterClient adds volume 60 I0610 02:02:11.428853 vid_map.go:160 + volume id 60: {Url:172.17.0.16:8080 PublicUrl:seaweedfs-lab5-volume1.xxx.io DataCenter:dc1 GrpcPort:0} I0610 02:02:11.428853 masterclient.go:293 updateVidMap(dc1) .filer: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:11.428857 masterclient.go:293 updateVidMap(dc1) .master: 172.17.0.16:8080 volume add: 1, del: 0, add ec: 0 del ec: 0 I0610 02:02:11.434899 filer_server_handlers_write_upload.go:123 uploaded 2779_0_4194304 chunk 1 to 58,22843c35dc98 [0,4194304) I0610 02:02:11.434929 filer_server_handlers_write_autochunk.go:202 saving /buckets/juicefs5/juicefs5/chunks/0/2/2779_0_4194304 I0610 02:02:11.434949 filer.go:236 find uncached directory: /buckets/juicefs5/juicefs5/chunks/0/2 I0610 02:02:11.434981 filer.go:200 InsertEntry /buckets/juicefs5/juicefs5/chunks/0/2/2779_0_4194304: new entry: 2779_0_4194304 I0610 02:02:11.435052 filer.go:221 CreateEntry /buckets/juicefs5/juicefs5/chunks/0/2/2779_0_4194304: created I0610 02:02:11.435134 error_handler.go:96 status 200 : skip I0610 02:02:41.371853 master_server.go:323 executing: s3.clean.uploads [-timeAgo=24h] I0610 02:02:41.371993 filer_grpc_server_admin.go:104 GetFilerConfiguration: masters:""172.17.0.16:9333"" max_mb:4 dir_buckets:""/buckets"" cipher:true signature:-1177174368 metrics_interval_sec:15 version:""30GB 3.51 4310e1fac"" I0610 02:02:41.372100 filer_client.go:120 read directory: directory:""/buckets"" limit:2147483647 I0610 02:02:41.372218 filer_grpc_server.go:40 ListEntries directory:""/buckets"" limit:2147483647 I0610 02:02:41.372354 filer_client.go:120 read directory: directory:""/buckets/juicefs5/.uploads"" limit:2147483647 I0610 02:02:41.372439 filer_grpc_server.go:40 ListEntries directory:""/buckets/juicefs5/.uploads"" limit:2147483647 I0610 02:02:41.372538 master_server.go:323 executing: unlock [] I0610 02:02:42.340022 volume_layout.go:380 Volume 64 becomes unwritable I0610 02:02:42.340040 volume_layout.go:472 Volume 64 reaches full capacity. I0610 02:02:45.298013 volume_grpc_client_to_master.go:232 volume server 172.17.0.16:8080 heartbeat I0610 02:02:45.298074 store.go:589 disk /data max 11943 unclaimedSpace:1527235MB, unused:17592186042872MB volumeSizeLimit:128MB I0610 02:02:45.298085 volume.go:273 collectStatus volume 56 I0610 02:02:45.298092 volume.go:273 collectStatus volume 60 I0610 02:02:45.298096 volume.go:273 collectStatus volume 57 I0610 02:02:45.298099 volume.go:273 collectStatus volume 61 I0610 02:02:45.298103 volume.go:273 collectStatus volume 62 I0610 02:02:45.298109 volume.go:273 collectStatus volume 63 I0610 02:02:45.298112 volume.go:273 collectStatus volume 64 I0610 02:02:45.298114 volume.go:273 collectStatus volume 54 I0610 02:02:45.298117 volume.go:273 collectStatus volume 55 I0610 02:02:45.298121 volume.go:273 collectStatus volume 2 I0610 02:02:45.298124 volume.go:273 collectStatus volume 58 I0610 02:02:45.298127 volume.go:273 collectStatus volume 65 I0610 02:02:45.298130 volume.go:273 collectStatus volume 53 I0610 02:02:45.298369 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 public_url:""seaweedfs-lab5-volume1.xxx.io"" max_file_key:9206 data_center:""dc1"" rack:""rack1"" volumes:{id:56 size:364910720 collection:""juicefs5"" file_count:87 version:3 modified_at_second:1686362527} volumes:{id:60 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362538} volumes:{id:57 size:213913184 collection:""juicefs5"" file_count:51 version:3 modified_at_second:1686362526} volumes:{id:61 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362547} volumes:{id:62 size:209718808 collection:""juicefs5"" file_count:50 version:3 modified_at_second:1686362547} volumes:{id:63 size:327161336 collection:""juicefs5"" file_count:78 version:3 modified_at_second:1686362555} volumes:{id:64 size:397417152 collection:""juicefs5"" file_count:95 version:3 modified_at_second:1686362560} volumes:{id:54 size:181406824 collection:""juicefs5"" file_count:44 version:3 modified_at_second:1686362507} volumes:{id:55 size:356523472 collection:""juicefs5"" file_count:86 version:3 modified_at_second:1686362516} volumes:{id:2 size:4929760 file_count:29 version:3 modified_at_second:1686362531} volumes:{id:58 size:356521968 collection:""juicefs5"" file_count:85 version:3 modified_at_second:1686362532} volumes:{id:65 size:12583136 collection:""juicefs5"" file_count:3 version:3 modified_at_second:1686362560} volumes:{id:53 size:351311008 collection:""juicefs5"" file_count:98 version:3 modified_at_second:1686362507} max_volume_counts:{key:"""" value:11943} grpc_port:18080 location_uuids:""5d846bf0-9b0c-4178-9301-ec200e3c84b1"" I0610 02:02:50.298447 volume_grpc_client_to_master.go:232 volume server 172.17.0.16:8080 heartbeat I0610 02:02:50.298518 store.go:589 disk /data max 11943 unclaimedSpace:1527235MB, unused:17592186042872MB volumeSizeLimit:128MB I0610 02:02:50.298531 volume.go:273 collectStatus volume 53 I0610 02:02:50.298540 volume.go:273 collectStatus volume 60 I0610 02:02:50.298545 volume.go:273 collectStatus volume 56 I0610 02:02:50.298549 volume.go:273 collectStatus volume 61 I0610 02:02:50.298552 volume.go:273 collectStatus volume 62 I0610 02:02:50.298558 volume.go:273 collectStatus volume 63 I0610 02:02:50.298562 volume.go:273 collectStatus volume 64 I0610 02:02:50.298565 volume.go:273 collectStatus volume 57 I0610 02:02:50.298569 volume.go:273 collectStatus volume 55 I0610 02:02:50.298572 volume.go:273 collectStatus volume 2 I0610 02:02:50.298577 volume.go:273 collectStatus volume 58 I0610 02:02:50.298582 volume.go:273 collectStatus volume 65 I0610 02:02:50.298588 volume.go:273 collectStatus volume 54 I0610 02:02:50.298826 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 public_url:""seaweedfs-lab5-volume1.xxx.io"" max_file_key:9206 data_center:""dc1"" rack:""rack1"" volumes:{id:53 size:351311008 collection:""juicefs5"" file_count:98 version:3 modified_at_second:1686362507} volumes:{id:60 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362538} volumes:{id:56 size:364910720 collection:""juicefs5"" file_count:87 version:3 modified_at_second:1686362527} volumes:{id:61 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362547} volumes:{id:62 size:209718808 collection:""juicefs5"" file_count:50 version:3 modified_at_second:1686362547} volumes:{id:63 size:327161336 collection:""juicefs5"" file_count:78 version:3 modified_at_second:1686362555} volumes:{id:64 size:397417152 collection:""juicefs5"" file_count:95 version:3 modified_at_second:1686362560} volumes:{id:57 size:213913184 collection:""juicefs5"" file_count:51 version:3 modified_at_second:1686362526} volumes:{id:55 size:356523472 collection:""juicefs5"" file_count:86 version:3 modified_at_second:1686362516} volumes:{id:2 size:4929760 file_count:29 version:3 modified_at_second:1686362531} volumes:{id:58 size:356521968 collection:""juicefs5"" file_count:85 version:3 modified_at_second:1686362532} volumes:{id:65 size:12583136 collection:""juicefs5"" file_count:3 version:3 modified_at_second:1686362560} volumes:{id:54 size:181406824 collection:""juicefs5"" file_count:44 version:3 modified_at_second:1686362507} max_volume_counts:{key:"""" value:11943} grpc_port:18080 location_uuids:""5d846bf0-9b0c-4178-9301-ec200e3c84b1"" skip I0610 02:03:19.231519 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_0_4194304 I0610 02:03:19.231543 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_0_4194304 I0610 02:03:19.231737 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.265913 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_2_4194304 I0610 02:03:19.265937 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_2_4194304 I0610 02:03:19.266090 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.362210 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_3_4194304 I0610 02:03:19.362232 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_3_4194304 I0610 02:03:19.362378 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.370622 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_1_4194304 I0610 02:03:19.370638 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_1_4194304 I0610 02:03:19.370758 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.379584 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:19.379606 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:19.379812 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.380124 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:19.472238 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:19.472254 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:19.472428 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.472671 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:19.480845 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_6_4194304 I0610 02:03:19.480859 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_6_4194304 I0610 02:03:19.480979 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.481813 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_7_4194304 I0610 02:03:19.481825 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304 I0610 02:03:19.481942 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.482105 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:19.507197 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_8_4194304 I0610 02:03:19.507213 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_8_4194304 I0610 02:03:19.507343 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.530024 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_9_4194304 I0610 02:03:19.530043 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_9_4194304 I0610 02:03:19.530186 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.530428 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:19.568549 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_10_4194304 I0610 02:03:19.568572 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304 I0610 02:03:19.568549 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_11_4194304 I0610 02:03:19.568610 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_11_4194304 I0610 02:03:19.568704 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.568706 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.569001 stream.go:89 waiting for chunk: 59,227d582687c5 I0610 02:03:19.593964 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_12_4194304 I0610 02:03:19.593986 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_12_4194304 I0610 02:03:19.594144 stream.go:75 start to stream content for chunks: 1 I0610 02:03:19.623503 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:19.632820 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:19.719809 stream.go:89 waiting for chunk: 59,227d582687c5 I0610 02:03:20.131116 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:20.223830 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:20.233399 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:20.297937 volume_grpc_client_to_master.go:232 volume server 172.17.0.16:8080 heartbeat I0610 02:03:20.297988 store.go:589 disk /data max 11943 unclaimedSpace:1527235MB, unused:17592186042872MB volumeSizeLimit:128MB I0610 02:03:20.297998 volume.go:273 collectStatus volume 56 I0610 02:03:20.298004 volume.go:273 collectStatus volume 60 I0610 02:03:20.298008 volume.go:273 collectStatus volume 63 I0610 02:03:20.298010 volume.go:273 collectStatus volume 64 I0610 02:03:20.298013 volume.go:273 collectStatus volume 57 I0610 02:03:20.298015 volume.go:273 collectStatus volume 61 I0610 02:03:20.298017 volume.go:273 collectStatus volume 62 I0610 02:03:20.298022 volume.go:273 collectStatus volume 58 I0610 02:03:20.298024 volume.go:273 collectStatus volume 65 I0610 02:03:20.298027 volume.go:273 collectStatus volume 54 I0610 02:03:20.298029 volume.go:273 collectStatus volume 55 I0610 02:03:20.298031 volume.go:273 collectStatus volume 2 I0610 02:03:20.298033 volume.go:273 collectStatus volume 53 I0610 02:03:20.298242 master_grpc_server.go:162 master received heartbeat ip:""172.17.0.16"" port:8080 public_url:""seaweedfs-lab5-volume1.xxx.io"" max_file_key:9207 data_center:""dc1"" rack:""rack1"" volumes:{id:56 size:364910720 collection:""juicefs5"" file_count:87 version:3 modified_at_second:1686362527} volumes:{id:60 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362538} volumes:{id:63 size:327161336 collection:""juicefs5"" file_count:78 version:3 modified_at_second:1686362555} volumes:{id:64 size:397417152 collection:""juicefs5"" file_count:95 version:3 modified_at_second:1686362560} volumes:{id:57 size:213913184 collection:""juicefs5"" file_count:51 version:3 modified_at_second:1686362526} volumes:{id:61 size:293606328 collection:""juicefs5"" file_count:70 version:3 modified_at_second:1686362547} volumes:{id:62 size:209718808 collection:""juicefs5"" file_count:50 version:3 modified_at_second:1686362547} volumes:{id:58 size:356521968 collection:""juicefs5"" file_count:85 version:3 modified_at_second:1686362532} volumes:{id:65 size:12583136 collection:""juicefs5"" file_count:3 version:3 modified_at_second:1686362560} volumes:{id:54 size:181406824 collection:""juicefs5"" file_count:44 version:3 modified_at_second:1686362507} volumes:{id:55 size:356523472 collection:""juicefs5"" file_count:86 version:3 modified_at_second:1686362516} volumes:{id:2 size:5047368 file_count:30 version:3 modified_at_second:1686362591} volumes:{id:53 size:351311008 collection:""juicefs5"" file_count:98 version:3 modified_at_second:1686362507} max_volume_counts:{key:"""" value:11943} grpc_port:18080 location_uuids:""5d846bf0-9b0c-4178-9301-ec200e3c84b1"" I0610 02:03:20.320520 stream.go:89 waiting for chunk: 59,227d582687c5 E0610 02:03:21.931464 stream.go:97 operation LookupFileId 59,2277719b1e43 failed, err: urls not found E0610 02:03:21.931719 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304: operation LookupFileId 59,2277719b1e43 failed, err: urls not found E0610 02:03:21.931734 common.go:297 processRangeRequest: operation LookupFileId 59,2277719b1e43 failed, err: urls not found I0610 02:03:21.931886 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:21.977787 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:21.977808 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:21.977974 stream.go:75 start to stream content for chunks: 1 I0610 02:03:21.978197 stream.go:89 waiting for chunk: 59,2277719b1e43 E0610 02:03:22.024472 stream.go:97 operation LookupFileId 59,2278b138056e failed, err: urls not found E0610 02:03:22.024485 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304: operation LookupFileId 59,2278b138056e failed, err: urls not found E0610 02:03:22.024492 common.go:297 processRangeRequest: operation LookupFileId 59,2278b138056e failed, err: urls not found I0610 02:03:22.024590 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF E0610 02:03:22.033660 stream.go:97 operation LookupFileId 59,227af658f241 failed, err: urls not found E0610 02:03:22.033671 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304: operation LookupFileId 59,227af658f241 failed, err: urls not found E0610 02:03:22.033677 common.go:297 processRangeRequest: operation LookupFileId 59,227af658f241 failed, err: urls not found I0610 02:03:22.033768 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:22.068682 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:22.068693 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:22.068786 stream.go:75 start to stream content for chunks: 1 I0610 02:03:22.068991 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:22.080083 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_7_4194304 I0610 02:03:22.080093 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304 I0610 02:03:22.080210 stream.go:75 start to stream content for chunks: 1 I0610 02:03:22.080381 stream.go:89 waiting for chunk: 59,227af658f241 E0610 02:03:22.121560 stream.go:97 operation LookupFileId 59,227d582687c5 failed, err: urls not found E0610 02:03:22.121578 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304: operation LookupFileId 59,227d582687c5 failed, err: urls not found E0610 02:03:22.121586 common.go:297 processRangeRequest: operation LookupFileId 59,227d582687c5 failed, err: urls not found I0610 02:03:22.121664 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:22.128904 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:22.162302 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_10_4194304 I0610 02:03:22.162317 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304 I0610 02:03:22.162426 stream.go:75 start to stream content for chunks: 1 I0610 02:03:22.162616 stream.go:89 waiting for chunk: 59,227d582687c5 I0610 02:03:22.219153 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:22.230544 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:22.313054 stream.go:89 waiting for chunk: 59,227d582687c5 I0610 02:03:22.729968 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:22.819452 stream.go:89 waiting for chunk: 59,2278b138056e I0610 02:03:22.830716 stream.go:89 waiting for chunk: 59,227af658f241 I0610 02:03:22.914313 stream.go:89 waiting for chunk: 59,227d582687c5 E0610 02:03:24.530581 stream.go:97 operation LookupFileId 59,2277719b1e43 failed, err: urls not found E0610 02:03:24.530607 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304: operation LookupFileId 59,2277719b1e43 failed, err: urls not found E0610 02:03:24.530619 common.go:297 processRangeRequest: operation LookupFileId 59,2277719b1e43 failed, err: urls not found I0610 02:03:24.530758 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF E0610 02:03:24.619885 stream.go:97 operation LookupFileId 59,2278b138056e failed, err: urls not found E0610 02:03:24.619899 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304: operation LookupFileId 59,2278b138056e failed, err: urls not found E0610 02:03:24.619906 common.go:297 processRangeRequest: operation LookupFileId 59,2278b138056e failed, err: urls not found I0610 02:03:24.620003 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:24.630463 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:24.630479 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_4_4194304 I0610 02:03:24.630625 stream.go:75 start to stream content for chunks: 1 E0610 02:03:24.630835 stream.go:97 operation LookupFileId 59,227af658f241 failed, err: urls not found E0610 02:03:24.630847 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_7_4194304: operation LookupFileId 59,227af658f241 failed, err: urls not found E0610 02:03:24.630859 common.go:297 processRangeRequest: operation LookupFileId 59,227af658f241 failed, err: urls not found I0610 02:03:24.630876 stream.go:89 waiting for chunk: 59,2277719b1e43 I0610 02:03:24.630935 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF I0610 02:03:24.702655 s3api_object_handlers.go:177 GetObjectHandler juicefs5 /juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:24.702670 s3api_object_handlers.go:357 s3 proxying GET to http://172.17.0.16:8888/buckets/juicefs5/juicefs5/chunks/0/2/2778_5_4194304 I0610 02:03:24.702880 stream.go:75 start to stream content for chunks: 1 I0610 02:03:24.703050 stream.go:89 waiting for chunk: 59,2278b138056e E0610 02:03:24.715283 stream.go:97 operation LookupFileId 59,227d582687c5 failed, err: urls not found E0610 02:03:24.715296 filer_server_handlers_read.go:257 failed to stream content /buckets/juicefs5/juicefs5/chunks/0/2/2778_10_4194304: operation LookupFileId 59,227d582687c5 failed, err: urls not found E0610 02:03:24.715303 common.go:297 processRangeRequest: operation LookupFileId 59,227d582687c5 failed, err: urls not found I0610 02:03:24.715396 s3api_object_handlers.go:455 passthrough response read 67 bytes: unexpected EOF skip  `volume.deleteEmpty` triggers `DeleteVolume 59`, but volume 59 is not empty(already have chunks been uploaded to volume 59) when `volume.deleteEmpty` is executed. other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
4838,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4838,how to deploy a high-availability cluster,"**System Setup** - seaweedfs helm chart (3 master ,3 volume ,2 filer) - kubernetes 1.26 **Expected behavior** deploy the cluster in kubernetes 1.26;use s3cmd to make bucket and upload file <img width=""480"" alt=""image"" src=""https://github.com/seaweedfs/seaweedfs/assets/132719524/498298a7-cde6-4550-a153-8c01de2985f6""> <img width=""503"" alt=""image"" src=""https://github.com/seaweedfs/seaweedfs/assets/132719524/57014a0c-0f5b-4673-a1b6-502e2c79cbee""> when i stop a master pod ,i can't upload file to filer <img width=""588"" alt=""image"" src=""https://github.com/seaweedfs/seaweedfs/assets/132719524/a517be1d-eeba-4332-b7e3-148fecd2cf31""> <img width=""465"" alt=""image"" src=""https://github.com/seaweedfs/seaweedfs/assets/132719524/cc11c4ec-9d88-44b4-94ee-2b8659ec4e97""> **Additional context** my question is how to deploy the high-availability cluster, even if one node goes down, the cluster should still work normally",source-file | source-file,"how to deploy a high-availability cluster **System Setup** - seaweedfs helm chart (3 master ,3 volume ,2 filer) - kubernetes 1.26 **Expected behavior** deploy the cluster in kubernetes 1.26;use s3cmd to make bucket and upload file <img width=""480"" alt=""image"" src=""https://github.com/seaweedfs/seaweedfs/assets/132719524/498298a7-cde6-4550-a153-8c01de2985f6""> <img width=""503"" alt=""image"" src=""https://github.com/seaweedfs/seaweedfs/assets/132719524/57014a0c-0f5b-4673-a1b6-502e2c79cbee""> when i stop a master pod ,i can't upload file to filer <img width=""588"" alt=""image"" src=""https://github.com/seaweedfs/seaweedfs/assets/132719524/a517be1d-eeba-4332-b7e3-148fecd2cf31""> <img width=""465"" alt=""image"" src=""https://github.com/seaweedfs/seaweedfs/assets/132719524/cc11c4ec-9d88-44b4-94ee-2b8659ec4e97""> **Additional context** my question is how to deploy the high-availability cluster, even if one node goes down, the cluster should still work normally source-file source-file",no-bug,0.9
88,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/88,invalid character '<' looking for beginning of value,"I installed the darwin 0.68 binary and on assign i get following error in the logs. I0220 11:41:19 97016 volume_growth.go:206] Failed to assign 7 to [NodeImpl:topo:DefaultDataCenter:DefaultRack:127.0.0.1:8080 ,volumes:map[], Ip:127.0.0.1, Port:8080, PublicUrl:localhost:8080, Dead:false] error invalid character '<' looking for beginning of value",config-file | config-file | config-file | config-file | config-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | documentation-file | documentation-file | documentation-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file,"invalid character '<' looking for beginning of value I installed the darwin 0.68 binary and on assign i get following error in the logs. I0220 11:41:19 97016 volume_growth.go:206] Failed to assign 7 to [NodeImpl:topo:DefaultDataCenter:DefaultRack:127.0.0.1:8080 ,volumes:map[], Ip:127.0.0.1, Port:8080, PublicUrl:localhost:8080, Dead:false] error invalid character '<' looking for beginning of value config-file config-file config-file config-file config-file container-file container-file container-file container-file container-file container-file documentation-file documentation-file documentation-file documentation-file source-file source-file other-file source-file source-file source-file source-file source-file source-file",no-bug,0.7
1776,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1776,S3 should return 204 on DELETE to nonexistent file (not 404),"**Describe the bug** The Amazon S3 api specification states that a DELETE request to a non-existing file should return HTTP status `HTTP/1.1 204 No Content`, as described [here](https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObject.html). Currently, seaweedfs S3 implementation returns `404 Not Found`. **System Setup** - List the command line to start: `./weed server -s3 -s3.config=config.json -dir=""/minio/weed"" -volume.max=100` - OS version: `CentOS 8` - output of `weed version`: `version 30GB 2.23 318a3d2 linux amd64` **Expected behavior** Seaweedfs should follow the Amazon S3 API specification and return HTTP 204 status-code when issuing a DELETE request to a non-existing file. This is important for compatibility with applications expecting S3 behavior. **Additional context** I stumbled upon this problem when attempting to use [pgbackrest](https://pgbackrest.org/) postgres backup software configured with seaweedfs S3 API as storage. When performing a regular backup, pgbackrest would almost finish but at the end run into an exception:  2021-02-02 16:04:39.364 P00 DEBUG: common/io/http/request::httpRequestResponse: => {code: 404, reason: Not Found, header: {accept-ranges: 'bytes', content-length: '234', content-type: 'application/xml', date: 'Tue, 02 Feb 2021 15:04:39 GMT', server: 'SeaweedFS S3 30GB 2.23', x-amz-request-id: '1612278279364142795'}, contentChunked: false, contentSize: 234, contentRemaining: 0, closeOnContentEof: false, contentExists: true, contentEof: true, contentCached: true} 2021-02-02 16:04:39.365 P00 DEBUG: common/exit::exitSafe: (result: 0, error: true, signalType: 0) ERROR: [039]: HTTP request failed with 404 (Not Found):  URI/Query : /dev-pgbackrest/backup/dev-pg-f3c001/latest  Request Headers : authorization: <redacted> content-length: 0 host: dev-seaweed-backup001-vip.<redacted> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 x-amz-date: <redacted>  Response Headers : accept-ranges: bytes content-length: 234 content-type: application/xml date: Tue, 02 Feb 2021 15:04:39 GMT server: SeaweedFS S3 30GB 2.23 x-amz-request-id: 1612278279364142795  Response Content : <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Resource>/dev-pgbackrest/backup/dev-pg-f3c001/latest</Resource><RequestId>1612278279364119515</RequestId></Error>  Searching for this error came up with this pgbackrest bug; https://github.com/pgbackrest/pgbackrest/issues/985 which details the same problem of an S3 implementation returning 404 for DELETE. I think this problem stems from issue #1160 where it was incorrectly stated that the API should return 404 in this case. Please let me know if I can provide additional information!",source-file,"S3 should return 204 on DELETE to nonexistent file (not 404) **Describe the bug** The Amazon S3 api specification states that a DELETE request to a non-existing file should return HTTP status `HTTP/1.1 204 No Content`, as described [here](https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObject.html). Currently, seaweedfs S3 implementation returns `404 Not Found`. **System Setup** - List the command line to start: `./weed server -s3 -s3.config=config.json -dir=""/minio/weed"" -volume.max=100` - OS version: `CentOS 8` - output of `weed version`: `version 30GB 2.23 318a3d2 linux amd64` **Expected behavior** Seaweedfs should follow the Amazon S3 API specification and return HTTP 204 status-code when issuing a DELETE request to a non-existing file. This is important for compatibility with applications expecting S3 behavior. **Additional context** I stumbled upon this problem when attempting to use [pgbackrest](https://pgbackrest.org/) postgres backup software configured with seaweedfs S3 API as storage. When performing a regular backup, pgbackrest would almost finish but at the end run into an exception:  2021-02-02 16:04:39.364 P00 DEBUG: common/io/http/request::httpRequestResponse: => {code: 404, reason: Not Found, header: {accept-ranges: 'bytes', content-length: '234', content-type: 'application/xml', date: 'Tue, 02 Feb 2021 15:04:39 GMT', server: 'SeaweedFS S3 30GB 2.23', x-amz-request-id: '1612278279364142795'}, contentChunked: false, contentSize: 234, contentRemaining: 0, closeOnContentEof: false, contentExists: true, contentEof: true, contentCached: true} 2021-02-02 16:04:39.365 P00 DEBUG: common/exit::exitSafe: (result: 0, error: true, signalType: 0) ERROR: [039]: HTTP request failed with 404 (Not Found):  URI/Query : /dev-pgbackrest/backup/dev-pg-f3c001/latest  Request Headers : authorization: <redacted> content-length: 0 host: dev-seaweed-backup001-vip.<redacted> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 x-amz-date: <redacted>  Response Headers : accept-ranges: bytes content-length: 234 content-type: application/xml date: Tue, 02 Feb 2021 15:04:39 GMT server: SeaweedFS S3 30GB 2.23 x-amz-request-id: 1612278279364142795  Response Content : <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Resource>/dev-pgbackrest/backup/dev-pg-f3c001/latest</Resource><RequestId>1612278279364119515</RequestId></Error>  Searching for this error came up with this pgbackrest bug; https://github.com/pgbackrest/pgbackrest/issues/985 which details the same problem of an S3 implementation returning 404 for DELETE. I think this problem stems from issue #1160 where it was incorrectly stated that the API should return 404 in this case. Please let me know if I can provide additional information! source-file",bug,0.95
3404,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3404,[filler] prefers for upload and download volume servers url from his datacentre,"**Describe the bug** **System Setup**  3.19 /usr/bin/weed -logtostderr=true -v=1 filer -port=9090 -dataCenter=predcix  **Additional context**  I0804 11:01:20.898073 filer_server_handlers_write_upload.go:192 doUpload fileId: 630,12846e28e51581 to urlLocation http://fast-volume-0.predc:8080/630,12846e28e51581?fsync=true I0804 11:02:44.408780 http_util.go:291 ReadUrlAsStream(): http://fast-volume-0.predc:8080/848,1275fba60c9ac6?readDeleted=true I0804 11:02:45.985648 http_util.go:291 ReadUrlAsStream(): http://fast-volume-1.predcix:8080/564,1266e0b73aa183?readDeleted=true ",source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[filler] prefers for upload and download volume servers url from his datacentre **Describe the bug** **System Setup**  3.19 /usr/bin/weed -logtostderr=true -v=1 filer -port=9090 -dataCenter=predcix  **Additional context**  I0804 11:01:20.898073 filer_server_handlers_write_upload.go:192 doUpload fileId: 630,12846e28e51581 to urlLocation http://fast-volume-0.predc:8080/630,12846e28e51581?fsync=true I0804 11:02:44.408780 http_util.go:291 ReadUrlAsStream(): http://fast-volume-0.predc:8080/848,1275fba60c9ac6?readDeleted=true I0804 11:02:45.985648 http_util.go:291 ReadUrlAsStream(): http://fast-volume-1.predcix:8080/564,1266e0b73aa183?readDeleted=true  source-file source-file other-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
83,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/83,Master and Volume don't see each other.,"I tried to run a new version (0.68) on openstack and it doesn't work. Servers don't see each other. No logs, it looks like the volume doesn't even try to join master. Here are the run instructions I used. BTW 0.45 version works. $OPENSHIFT_REPO_DIR/diy/weed volume -max=100 -ip=$OPENSHIFT_DIY_IP -port=$OPENSHIFT_DIY_PORT -ip.bind=$OPENSHIFT_DIY_IP -mserver=storage-master.domain.com:80 -publicIp=""storage-volume02.domain.com:80"" -dir=""$OPENSHIFT_DATA_DIR"" > $OPENSHIFT_DIY_DIR/logs/volume.log 2>&1 & $OPENSHIFT_REPO_DIR/diy/weed master -mdir=""$OPENSHIFT_DATA_DIR"" -port=8080 -ip=$OPENSHIFT_DIY_IP -ip.bind=$OPENSHIFT_DIY_IP > $OPENSHIFT_DIY_DIR/logs/master.log 2>&1 &",config-file | config-file | documentation-file | config-file | other-file | config-file | source-file | source-file | other-file | test-file | config-file | config-file | config-file | config-file | config-file | test-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | test-file | source-file | source-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | test-file,"Master and Volume don't see each other. I tried to run a new version (0.68) on openstack and it doesn't work. Servers don't see each other. No logs, it looks like the volume doesn't even try to join master. Here are the run instructions I used. BTW 0.45 version works. $OPENSHIFT_REPO_DIR/diy/weed volume -max=100 -ip=$OPENSHIFT_DIY_IP -port=$OPENSHIFT_DIY_PORT -ip.bind=$OPENSHIFT_DIY_IP -mserver=storage-master.domain.com:80 -publicIp=""storage-volume02.domain.com:80"" -dir=""$OPENSHIFT_DATA_DIR"" > $OPENSHIFT_DIY_DIR/logs/volume.log 2>&1 & $OPENSHIFT_REPO_DIR/diy/weed master -mdir=""$OPENSHIFT_DATA_DIR"" -port=8080 -ip=$OPENSHIFT_DIY_IP -ip.bind=$OPENSHIFT_DIY_IP > $OPENSHIFT_DIY_DIR/logs/master.log 2>&1 & config-file config-file documentation-file config-file other-file config-file source-file source-file other-file test-file config-file config-file config-file config-file config-file test-file source-file source-file source-file source-file source-file other-file source-file source-file test-file source-file source-file test-file test-file test-file test-file source-file source-file source-file test-file test-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file source-file source-file test-file test-file test-file source-file source-file source-file source-file test-file",no-bug,0.9
1988,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1988,Upload file fail via filer WebUI,"**Describe the bug** When ""window.location.href"" is a directory and without ending of ""/"",upload file will get a reponse {""error"":""update entry /xxx/yyy: existing /xxx/yyy is a directory""} directory url like /xxx/yyy/ can be uploaded successfully **Expected behavior** File uploaded. **Additional context** https://github.com/chrislusf/seaweedfs/blob/c42b95c596f762dcca2bc9c7e7a918ab8ca8b206/weed/server/filer_ui/templates.go#L185",source-file,"Upload file fail via filer WebUI **Describe the bug** When ""window.location.href"" is a directory and without ending of ""/"",upload file will get a reponse {""error"":""update entry /xxx/yyy: existing /xxx/yyy is a directory""} directory url like /xxx/yyy/ can be uploaded successfully **Expected behavior** File uploaded. **Additional context** https://github.com/chrislusf/seaweedfs/blob/c42b95c596f762dcca2bc9c7e7a918ab8ca8b206/weed/server/filer_ui/templates.go#L185 source-file",bug,0.9
320,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/320,"benchmark crash just once, and I failed to reproduce","Chris, There is a crash problem when I run the benchmark tool to reconfirm performance of the 110 replication policy. The command is: ./weed benchmark -server=100.106.21.3:9333 -size=500000 -c=10 -n=10000 -deletePercent=30 Crash log has been attached,please have a review If below code(lookup_vid_cache.go line:44) is not goroutine safe, RWLock should be added for the struct VidCache, how about you opinion? vc.cache = append(vc.cache, VidInfo{}) [benchmark_crash_201606131427_CST.log.zip](https://github.com/chrislusf/seaweedfs/files/311300/benchmark_crash_201606131427_CST.log.zip)",container-file | container-file | other-file | config-file | other-file | other-file | config-file,"benchmark crash just once, and I failed to reproduce Chris, There is a crash problem when I run the benchmark tool to reconfirm performance of the 110 replication policy. The command is: ./weed benchmark -server=100.106.21.3:9333 -size=500000 -c=10 -n=10000 -deletePercent=30 Crash log has been attached,please have a review If below code(lookup_vid_cache.go line:44) is not goroutine safe, RWLock should be added for the struct VidCache, how about you opinion? vc.cache = append(vc.cache, VidInfo{}) [benchmark_crash_201606131427_CST.log.zip](https://github.com/chrislusf/seaweedfs/files/311300/benchmark_crash_201606131427_CST.log.zip) container-file container-file other-file config-file other-file other-file config-file",no-bug,0.9
2041,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2041,[Feature request] Delete a specific Filer tag,"It would be nice to have an ability to delete specific ""Seaweed-"" tags on files, not all of them at once",source-file,"[Feature request] Delete a specific Filer tag It would be nice to have an ability to delete specific ""Seaweed-"" tags on files, not all of them at once source-file",no-bug,0.9
3427,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3427,"ARM7 - Creating a folder in the filer web interface causes ""unaligned 64-bit atomic operation -""","When creating a folder in the filer web interface the server fails with the error: > 2022/08/10 22:59:32 http: panic serving 192.168.1.102:1098: unaligned 64-bit atomic operation goroutine 850 [running]: net/http.(*conn).serve.func1() /usr/local/go/src/net/http/server.go:1850 +0xec panic({0x198e948, 0x2278328}) /usr/local/go/src/runtime/panic.go:890 +0x2ac runtime/internal/atomic.panicUnaligned() /usr/local/go/src/runtime/internal/atomic/unaligned.go:8 +0x24 runtime/internal/atomic.Load64(0x34d0314) /usr/local/go/src/runtime/internal/atomic/atomic_arm.s:280 +0x14 github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler(0x34d02d0, {0x22894a0, 0x10fec0a0}, 0x353b680) **/go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:66 +0xa60** net/http.HandlerFunc.ServeHTTP(0x4dfeda0, {0x22894a0, 0x10fec0a0}, 0x353b680) /usr/local/go/src/net/http/server.go:2109 +0x34 net/http.(*ServeMux).ServeHTTP(0x39c6690, {0x22894a0, 0x10fec0a0}, 0x353b680) /usr/local/go/src/net/http/server.go:2487 +0x164 net/http.serverHandler.ServeHTTP({0x35488c0}, {0x22894a0, 0x10fec0a0}, 0x353b680) /usr/local/go/src/net/http/server.go:2947 +0x2f0 net/http.(*conn).serve(0x4b8c0c0, {0x228a298, 0x4f90bb8}) /usr/local/go/src/net/http/server.go:1991 +0x654 created by net/http.(*Server).Serve /usr/local/go/src/net/http/server.go:3102 +0x4e0 **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - Docker Container on ARM7 - version 30GB 3.20 0854171d linux arm",source-file | source-file | source-file,"ARM7 - Creating a folder in the filer web interface causes ""unaligned 64-bit atomic operation -"" When creating a folder in the filer web interface the server fails with the error: > 2022/08/10 22:59:32 http: panic serving 192.168.1.102:1098: unaligned 64-bit atomic operation goroutine 850 [running]: net/http.(*conn).serve.func1() /usr/local/go/src/net/http/server.go:1850 +0xec panic({0x198e948, 0x2278328}) /usr/local/go/src/runtime/panic.go:890 +0x2ac runtime/internal/atomic.panicUnaligned() /usr/local/go/src/runtime/internal/atomic/unaligned.go:8 +0x24 runtime/internal/atomic.Load64(0x34d0314) /usr/local/go/src/runtime/internal/atomic/atomic_arm.s:280 +0x14 github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler(0x34d02d0, {0x22894a0, 0x10fec0a0}, 0x353b680) **/go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:66 +0xa60** net/http.HandlerFunc.ServeHTTP(0x4dfeda0, {0x22894a0, 0x10fec0a0}, 0x353b680) /usr/local/go/src/net/http/server.go:2109 +0x34 net/http.(*ServeMux).ServeHTTP(0x39c6690, {0x22894a0, 0x10fec0a0}, 0x353b680) /usr/local/go/src/net/http/server.go:2487 +0x164 net/http.serverHandler.ServeHTTP({0x35488c0}, {0x22894a0, 0x10fec0a0}, 0x353b680) /usr/local/go/src/net/http/server.go:2947 +0x2f0 net/http.(*conn).serve(0x4b8c0c0, {0x228a298, 0x4f90bb8}) /usr/local/go/src/net/http/server.go:1991 +0x654 created by net/http.(*Server).Serve /usr/local/go/src/net/http/server.go:3102 +0x4e0 **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - Docker Container on ARM7 - version 30GB 3.20 0854171d linux arm source-file source-file source-file",no-bug,0.9
4968,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4968,loss of mount point at high load (fuse mount),"# SeaWeedFS all-in-one storage server on ubuntu LTS 20.04 , weed v3.57 from binary releases @github ## Services start options:  ExecStart=/usr/local/sbin/weed master -mdir=/data/seaweedfs/master -ip=192.168.0.12 -defaultReplication=000 ExecStart=/usr/local/sbin/weed volume -dir=/data/seaweedfs/volume -dataCenter=one -rack=rack1 -mserver=192.168.0.12:9333 -ip=192.168.0.12 -max=0 ExecStart=/usr/local/sbin/weed filer -s3 -dataCenter=one -rack=rack1 -master=192.168.0.12:9333 -ip=192.168.0.12 ExecStart=/usr/local/sbin/weed mount -filer=192.168.0.12:8888 -dir=""/data/mnt""  ## `> cluster.ps`  * filers 1 * 192.168.0.12:8888 (30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559) 2023-10-30 22:06:42.881127352 +0000 UTC DataCenter: one signature: 779212908 * filer 192.168.0.12:8888 metadata sync time * volume servers 1 * data center: one * rack: rack1 * 192.168.0.12:8080 (30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559)  ## `> cluster.check`  Topology volumeSizeLimit:30000 MB hdd(volume:7/7 active:7 free:0 remote:0) the cluster has 1 filers: [192.168.0.12:8888] the cluster has 1 volume servers: [192.168.0.12:8080] checking master localhost:9333 to volume server 192.168.0.12:8080  ok round trip 0.679ms clock delta 0.076ms checking volume server 192.168.0.12:8080 to master localhost:9333  ok round trip 31.303ms clock delta 15.374ms checking filer 192.168.0.12:8888 to master localhost:9333  ok round trip 16.578ms clock delta 7.773ms checking filer 192.168.0.12:8888 to volume server 192.168.0.12:8080  ok round trip 0.632ms clock delta 0.064ms checking filer 192.168.0.12:8888 to 192.168.0.12:8888  ok round trip 0.511ms clock delta 0.103ms  # Load zimbra mail server creates a significant load on the file system, the utilization of HDD disk speeds according to iostat -x is close to 100% # BUG (crash fuse mount server) I tried different types of zimbra server connection: via NFS from client to storage server and weedfiler + weedmount on client, the result is the same # the crutch script ;)  while true ; do crash_fs=""`journalctl -n 3 -u seaweedmount | cat | grep ""status=255/EXCEPTION"" |wc -l`"" ; if (( $(echo $crash_fs) == '1' )) ; then echo ""`date`, status=crash"" ; umount -f -l /opt/zimbra/store && systemctl restart seaweedmount ; fi ; sleep 10 ; done  # LOGS   31  2023 09:21:24 MSK, status=crash  31  2023 11:30:16 MSK, status=crash    31 08:50:08 zimbra-store systemd[1]: Started SeaweedFS mount.  31 08:50:10 zimbra-store seaweedfs-mount[40135]: mount point owner uid=0 gid=0 mode=drwxr-xr-x  31 08:50:10 zimbra-store seaweedfs-mount[40135]: current uid=0 gid=0  31 08:50:10 zimbra-store seaweedfs-mount[40135]: I1031 08:50:10.678303 leveldb_store.go:47 filer store dir: /tmp/eaeae2ae/meta  31 08:50:10 zimbra-store seaweedfs-mount[40135]: I1031 08:50:10.679837 file_util.go:23 Folder /tmp/eaeae2ae/meta Permission: -rwxr-xr-x  31 08:50:10 zimbra-store seaweedfs-mount[40135]: I1031 08:50:10.857621 mount_std.go:268 mounted 192.168.0.12:8888/ to /data/mnt  31 08:50:10 zimbra-store seaweedfs-mount[40135]: I1031 08:50:10.858152 mount_std.go:269 This is SeaweedFS version 30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559 linux amd64  31 09:21:19 zimbra-store seaweedfs-mount[40135]: F1031 09:21:19.224273 inode_to_path.go:153 MarkChildrenCached not found inode /0/124/msg/0  31 09:21:19 zimbra-store seaweedfs-mount[40135]: goroutine 121533 [running]:  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/glog.stacks(0x0)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/glog/glog.go:768 +0x85  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).output(0x517bce0, 0x3, 0xc0005360e0, {0x4058547?, 0xc00143faf0?}, 0x1?, 0x0)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/glog/glog.go:719 +0x38a  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).printf(0xc004429cc0?, 0xc?, {0x3069b4c, 0x25}, {0xc00143faf0, 0x1, 0x1})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/glog/glog.go:657 +0x10a  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/glog.Fatalf()  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/glog/glog.go:1154  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.(*InodeToPath).MarkChildrenCached(0xc00081c2a0, {0xc004429cc0, 0xc})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/inode_to_path.go:153 +0x110  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.NewSeaweedFileSystem.func1({0xc004429cc0?, 0x11?})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/weedfs.go:104 +0x2c  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount/meta_cache.doEnsureVisited(0xc000459080, {0x37db418, 0xc0008b49a0}, {0xc004429cc0, 0xc})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/meta_cache/meta_cache_init.go:63 +0x1e9  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount/meta_cache.EnsureVisited(0xc000459080, {0x37db418, 0xc0008b49a0}, {0xc004429cc0?, 0x2617b17?})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/meta_cache/meta_cache_init.go:25 +0x7b  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).maybeLoadEntry(0xc0008b49a0, {0xc004429cc0, 0x19})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/weedfs.go:174 +0x218  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).maybeReadEntry(0xc0008b49a0, 0xc0007d3a40?)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/weedfs.go:148 +0xa7  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).GetXAttr(0x47d8ca?, 0xc001dca240?, 0xc00143fe10?, {0xc01c95b9c8, 0x17}, {0xc00bbf3000, 0x1000, 0x28d9480?})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/weedfs_xattr.go:40 +0x7f  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/hanwen/go-fuse/v2/fuse.doGetXAttr(0xc0008b4580, 0xc001dca240)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/opcode.go:289 +0x1cc  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/hanwen/go-fuse/v2/fuse.(*Server).handleRequest(0xc0008b4580, 0xc001dca240)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:526 +0x267  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/hanwen/go-fuse/v2/fuse.(*Server).loop(0xc0008b4580, 0x65?)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:499 +0x110  31 09:21:19 zimbra-store seaweedfs-mount[40135]: created by github.com/hanwen/go-fuse/v2/fuse.(*Server).readRequest in goroutine 121530  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:366 +0x53f  31 09:21:20 zimbra-store systemd[1]: seaweedmount.service: Main process exited, code=exited, status=255/EXCEPTION  31 09:21:20 zimbra-store systemd[1]: seaweedmount.service: Failed with result 'exit-code'.  31 09:21:24 zimbra-store systemd[1]: Started SeaweedFS mount.  31 09:21:27 zimbra-store seaweedfs-mount[41711]: mount point owner uid=0 gid=0 mode=drwxr-xr-x  31 09:21:27 zimbra-store seaweedfs-mount[41711]: current uid=0 gid=0  31 09:21:27 zimbra-store seaweedfs-mount[41711]: I1031 09:21:27.408835 leveldb_store.go:47 filer store dir: /tmp/eaeae2ae/meta  31 09:21:27 zimbra-store seaweedfs-mount[41711]: I1031 09:21:27.410256 file_util.go:23 Folder /tmp/eaeae2ae/meta Permission: -rwxr-xr-x  31 09:21:27 zimbra-store seaweedfs-mount[41711]: I1031 09:21:27.612762 mount_std.go:268 mounted 192.168.0.12:8888/ to /data/mnt  31 09:21:27 zimbra-store seaweedfs-mount[41711]: I1031 09:21:27.612796 mount_std.go:269 This is SeaweedFS version 30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559 linux amd64  31 11:30:13 zimbra-store seaweedfs-mount[41711]: F1031 11:30:13.050032 inode_to_path.go:153 MarkChildrenCached not found inode /0/40/msg/7  31 11:30:13 zimbra-store seaweedfs-mount[41711]: goroutine 247971 [running]:  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/glog.stacks(0x0)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/glog/glog.go:768 +0x85  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).output(0x517bce0, 0x3, 0xc0005b80e0, {0x4058547?, 0xc001099af0?}, 0x1?, 0x0)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/glog/glog.go:719 +0x38a  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).printf(0xc00790aae0?, 0xb?, {0x3069b4c, 0x25}, {0xc001099af0, 0x1, 0x1})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/glog/glog.go:657 +0x10a  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/glog.Fatalf()  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/glog/glog.go:1154  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.(*InodeToPath).MarkChildrenCached(0xc00088b650, {0xc00790aae0, 0xb})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/inode_to_path.go:153 +0x110  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.NewSeaweedFileSystem.func1({0xc00790aae0?, 0x11?})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/weedfs.go:104 +0x2c  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount/meta_cache.doEnsureVisited(0xc00046f5c0, {0x37db418, 0xc000760580}, {0xc00790aae0, 0xb})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/meta_cache/meta_cache_init.go:63 +0x1e9  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount/meta_cache.EnsureVisited(0xc00046f5c0, {0x37db418, 0xc000760580}, {0xc00790aae0?, 0x2617b17?})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/meta_cache/meta_cache_init.go:25 +0x7b  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).maybeLoadEntry(0xc000760580, {0xc00790aae0, 0x1b})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/weedfs.go:174 +0x218  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).maybeReadEntry(0xc000760580, 0xc0007eef90?)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/weedfs.go:148 +0xa7  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).GetXAttr(0x47d8ca?, 0xc0030c6900?, 0xc001099e10?, {0xc01eef8678, 0x17}, {0xc002584000, 0x1000, 0x28d9480?})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/weedfs_xattr.go:40 +0x7f  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/hanwen/go-fuse/v2/fuse.doGetXAttr(0xc00045a420, 0xc0030c6900)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/opcode.go:289 +0x1cc  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/hanwen/go-fuse/v2/fuse.(*Server).handleRequest(0xc00045a420, 0xc0030c6900)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:526 +0x267  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/hanwen/go-fuse/v2/fuse.(*Server).loop(0xc00045a420, 0x80?)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:499 +0x110  31 11:30:13 zimbra-store seaweedfs-mount[41711]: created by github.com/hanwen/go-fuse/v2/fuse.(*Server).readRequest in goroutine 247759  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:366 +0x53f  31 11:30:13 zimbra-store systemd[1]: seaweedmount.service: Main process exited, code=exited, status=255/EXCEPTION  31 11:30:13 zimbra-store systemd[1]: seaweedmount.service: Failed with result 'exit-code'.  ## P.S. dmesg in he same time is clean (HDD not have any hardware problems)",source-file | source-file | source-file,"loss of mount point at high load (fuse mount) # SeaWeedFS all-in-one storage server on ubuntu LTS 20.04 , weed v3.57 from binary releases @github ## Services start options:  ExecStart=/usr/local/sbin/weed master -mdir=/data/seaweedfs/master -ip=192.168.0.12 -defaultReplication=000 ExecStart=/usr/local/sbin/weed volume -dir=/data/seaweedfs/volume -dataCenter=one -rack=rack1 -mserver=192.168.0.12:9333 -ip=192.168.0.12 -max=0 ExecStart=/usr/local/sbin/weed filer -s3 -dataCenter=one -rack=rack1 -master=192.168.0.12:9333 -ip=192.168.0.12 ExecStart=/usr/local/sbin/weed mount -filer=192.168.0.12:8888 -dir=""/data/mnt""  ## `> cluster.ps`  * filers 1 * 192.168.0.12:8888 (30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559) 2023-10-30 22:06:42.881127352 +0000 UTC DataCenter: one signature: 779212908 * filer 192.168.0.12:8888 metadata sync time * volume servers 1 * data center: one * rack: rack1 * 192.168.0.12:8080 (30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559)  ## `> cluster.check`  Topology volumeSizeLimit:30000 MB hdd(volume:7/7 active:7 free:0 remote:0) the cluster has 1 filers: [192.168.0.12:8888] the cluster has 1 volume servers: [192.168.0.12:8080] checking master localhost:9333 to volume server 192.168.0.12:8080  ok round trip 0.679ms clock delta 0.076ms checking volume server 192.168.0.12:8080 to master localhost:9333  ok round trip 31.303ms clock delta 15.374ms checking filer 192.168.0.12:8888 to master localhost:9333  ok round trip 16.578ms clock delta 7.773ms checking filer 192.168.0.12:8888 to volume server 192.168.0.12:8080  ok round trip 0.632ms clock delta 0.064ms checking filer 192.168.0.12:8888 to 192.168.0.12:8888  ok round trip 0.511ms clock delta 0.103ms  # Load zimbra mail server creates a significant load on the file system, the utilization of HDD disk speeds according to iostat -x is close to 100% # BUG (crash fuse mount server) I tried different types of zimbra server connection: via NFS from client to storage server and weedfiler + weedmount on client, the result is the same # the crutch script ;)  while true ; do crash_fs=""`journalctl -n 3 -u seaweedmount | cat | grep ""status=255/EXCEPTION"" |wc -l`"" ; if (( $(echo $crash_fs) == '1' )) ; then echo ""`date`, status=crash"" ; umount -f -l /opt/zimbra/store && systemctl restart seaweedmount ; fi ; sleep 10 ; done  # LOGS   31  2023 09:21:24 MSK, status=crash  31  2023 11:30:16 MSK, status=crash    31 08:50:08 zimbra-store systemd[1]: Started SeaweedFS mount.  31 08:50:10 zimbra-store seaweedfs-mount[40135]: mount point owner uid=0 gid=0 mode=drwxr-xr-x  31 08:50:10 zimbra-store seaweedfs-mount[40135]: current uid=0 gid=0  31 08:50:10 zimbra-store seaweedfs-mount[40135]: I1031 08:50:10.678303 leveldb_store.go:47 filer store dir: /tmp/eaeae2ae/meta  31 08:50:10 zimbra-store seaweedfs-mount[40135]: I1031 08:50:10.679837 file_util.go:23 Folder /tmp/eaeae2ae/meta Permission: -rwxr-xr-x  31 08:50:10 zimbra-store seaweedfs-mount[40135]: I1031 08:50:10.857621 mount_std.go:268 mounted 192.168.0.12:8888/ to /data/mnt  31 08:50:10 zimbra-store seaweedfs-mount[40135]: I1031 08:50:10.858152 mount_std.go:269 This is SeaweedFS version 30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559 linux amd64  31 09:21:19 zimbra-store seaweedfs-mount[40135]: F1031 09:21:19.224273 inode_to_path.go:153 MarkChildrenCached not found inode /0/124/msg/0  31 09:21:19 zimbra-store seaweedfs-mount[40135]: goroutine 121533 [running]:  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/glog.stacks(0x0)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/glog/glog.go:768 +0x85  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).output(0x517bce0, 0x3, 0xc0005360e0, {0x4058547?, 0xc00143faf0?}, 0x1?, 0x0)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/glog/glog.go:719 +0x38a  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).printf(0xc004429cc0?, 0xc?, {0x3069b4c, 0x25}, {0xc00143faf0, 0x1, 0x1})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/glog/glog.go:657 +0x10a  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/glog.Fatalf()  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/glog/glog.go:1154  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.(*InodeToPath).MarkChildrenCached(0xc00081c2a0, {0xc004429cc0, 0xc})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/inode_to_path.go:153 +0x110  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.NewSeaweedFileSystem.func1({0xc004429cc0?, 0x11?})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/weedfs.go:104 +0x2c  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount/meta_cache.doEnsureVisited(0xc000459080, {0x37db418, 0xc0008b49a0}, {0xc004429cc0, 0xc})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/meta_cache/meta_cache_init.go:63 +0x1e9  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount/meta_cache.EnsureVisited(0xc000459080, {0x37db418, 0xc0008b49a0}, {0xc004429cc0?, 0x2617b17?})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/meta_cache/meta_cache_init.go:25 +0x7b  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).maybeLoadEntry(0xc0008b49a0, {0xc004429cc0, 0x19})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/weedfs.go:174 +0x218  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).maybeReadEntry(0xc0008b49a0, 0xc0007d3a40?)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/weedfs.go:148 +0xa7  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).GetXAttr(0x47d8ca?, 0xc001dca240?, 0xc00143fe10?, {0xc01c95b9c8, 0x17}, {0xc00bbf3000, 0x1000, 0x28d9480?})  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /github/workspace/weed/mount/weedfs_xattr.go:40 +0x7f  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/hanwen/go-fuse/v2/fuse.doGetXAttr(0xc0008b4580, 0xc001dca240)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/opcode.go:289 +0x1cc  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/hanwen/go-fuse/v2/fuse.(*Server).handleRequest(0xc0008b4580, 0xc001dca240)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:526 +0x267  31 09:21:19 zimbra-store seaweedfs-mount[40135]: github.com/hanwen/go-fuse/v2/fuse.(*Server).loop(0xc0008b4580, 0x65?)  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:499 +0x110  31 09:21:19 zimbra-store seaweedfs-mount[40135]: created by github.com/hanwen/go-fuse/v2/fuse.(*Server).readRequest in goroutine 121530  31 09:21:19 zimbra-store seaweedfs-mount[40135]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:366 +0x53f  31 09:21:20 zimbra-store systemd[1]: seaweedmount.service: Main process exited, code=exited, status=255/EXCEPTION  31 09:21:20 zimbra-store systemd[1]: seaweedmount.service: Failed with result 'exit-code'.  31 09:21:24 zimbra-store systemd[1]: Started SeaweedFS mount.  31 09:21:27 zimbra-store seaweedfs-mount[41711]: mount point owner uid=0 gid=0 mode=drwxr-xr-x  31 09:21:27 zimbra-store seaweedfs-mount[41711]: current uid=0 gid=0  31 09:21:27 zimbra-store seaweedfs-mount[41711]: I1031 09:21:27.408835 leveldb_store.go:47 filer store dir: /tmp/eaeae2ae/meta  31 09:21:27 zimbra-store seaweedfs-mount[41711]: I1031 09:21:27.410256 file_util.go:23 Folder /tmp/eaeae2ae/meta Permission: -rwxr-xr-x  31 09:21:27 zimbra-store seaweedfs-mount[41711]: I1031 09:21:27.612762 mount_std.go:268 mounted 192.168.0.12:8888/ to /data/mnt  31 09:21:27 zimbra-store seaweedfs-mount[41711]: I1031 09:21:27.612796 mount_std.go:269 This is SeaweedFS version 30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559 linux amd64  31 11:30:13 zimbra-store seaweedfs-mount[41711]: F1031 11:30:13.050032 inode_to_path.go:153 MarkChildrenCached not found inode /0/40/msg/7  31 11:30:13 zimbra-store seaweedfs-mount[41711]: goroutine 247971 [running]:  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/glog.stacks(0x0)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/glog/glog.go:768 +0x85  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).output(0x517bce0, 0x3, 0xc0005b80e0, {0x4058547?, 0xc001099af0?}, 0x1?, 0x0)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/glog/glog.go:719 +0x38a  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).printf(0xc00790aae0?, 0xb?, {0x3069b4c, 0x25}, {0xc001099af0, 0x1, 0x1})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/glog/glog.go:657 +0x10a  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/glog.Fatalf()  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/glog/glog.go:1154  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.(*InodeToPath).MarkChildrenCached(0xc00088b650, {0xc00790aae0, 0xb})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/inode_to_path.go:153 +0x110  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.NewSeaweedFileSystem.func1({0xc00790aae0?, 0x11?})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/weedfs.go:104 +0x2c  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount/meta_cache.doEnsureVisited(0xc00046f5c0, {0x37db418, 0xc000760580}, {0xc00790aae0, 0xb})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/meta_cache/meta_cache_init.go:63 +0x1e9  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount/meta_cache.EnsureVisited(0xc00046f5c0, {0x37db418, 0xc000760580}, {0xc00790aae0?, 0x2617b17?})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/meta_cache/meta_cache_init.go:25 +0x7b  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).maybeLoadEntry(0xc000760580, {0xc00790aae0, 0x1b})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/weedfs.go:174 +0x218  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).maybeReadEntry(0xc000760580, 0xc0007eef90?)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/weedfs.go:148 +0xa7  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).GetXAttr(0x47d8ca?, 0xc0030c6900?, 0xc001099e10?, {0xc01eef8678, 0x17}, {0xc002584000, 0x1000, 0x28d9480?})  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /github/workspace/weed/mount/weedfs_xattr.go:40 +0x7f  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/hanwen/go-fuse/v2/fuse.doGetXAttr(0xc00045a420, 0xc0030c6900)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/opcode.go:289 +0x1cc  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/hanwen/go-fuse/v2/fuse.(*Server).handleRequest(0xc00045a420, 0xc0030c6900)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:526 +0x267  31 11:30:13 zimbra-store seaweedfs-mount[41711]: github.com/hanwen/go-fuse/v2/fuse.(*Server).loop(0xc00045a420, 0x80?)  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:499 +0x110  31 11:30:13 zimbra-store seaweedfs-mount[41711]: created by github.com/hanwen/go-fuse/v2/fuse.(*Server).readRequest in goroutine 247759  31 11:30:13 zimbra-store seaweedfs-mount[41711]: /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.4.0/fuse/server.go:366 +0x53f  31 11:30:13 zimbra-store systemd[1]: seaweedmount.service: Main process exited, code=exited, status=255/EXCEPTION  31 11:30:13 zimbra-store systemd[1]: seaweedmount.service: Failed with result 'exit-code'.  ## P.S. dmesg in he same time is clean (HDD not have any hardware problems) source-file source-file source-file",no-bug,0.9
1111,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1111,ec.balance not working,"**Describe the bug** After recompiling the weed binary with the actual snapshot the binary fixes the last issues (problem with redirect, problem with some ec encoded files) but now i could see some of the ec.shards are not distributed in the right way (5 volume servers). for example volume 59:  bm6: 59 3146776576 Bytes [0 1 2 3] 06 Nov 19 11:08 +0100 bm8: 59 3146776576 Bytes [0 1 2 3 4 5 6 7 8 9 10] 06 Nov 19 11:06 +0100 bm9: 59 3146776576 Bytes [4] 06 Nov 19 11:08 +0100 bm2: 59 3146776576 Bytes [11 12 13] 06 Nov 19 10:29 +0100 bm7: 59 3146776576 Bytes [5 6 7] 06 Nov 19 11:08 +0100  i dont know why those shards had been created this way (when doing ec.encode all volume servers had been up and those should be distributed equally) but i wanted to fix it with weed shell - ec.balance -force but ec.balance -force only says:  balanceEcVolumes collections 1 balanceEcVolumes collection balanceEcVolumes bm7:8280 has 1 overlimit, moving ec shard 15.4 bm7:8280 has 1 overlimit, moving ec shard 60.6 bm2:8280 has 2 overlimit, moving ec shard 56.0 bm2:8280 has 1 overlimit, moving ec shard 56.1 bm6:8280 has 1 overlimit, moving ec shard 59.0  and seems to be doing nothing. weed master is also configured to do:  [master.maintenance] # periodically run these scripts are the same as running them from 'weed shell' scripts =  ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force ec.balance -force volume.balance -force  sleep_minutes = 17 # sleep minutes between each script execution  is balancing maybe running currently in the background ? how to check this ? i did not see anything in the logfiles  **System Setup** weed version: version 30GB 1.44 linux amd64 but as stated recompiled with the latest git snapshot OS Version - mixed Ubuntu Server 14.04 and 18.04 **Expected behavior** - doing a rebalance - some sort of status message if something is running in the background - either in `weed shell` or in the web status screen - or in both ;) additionally ec.rebuild says: error: disk space is not enough but on all (weed) disks there is plenty of storage free - or is here another path used - for example /tmp ?",source-file | source-file | source-file | source-file | source-file | source-file,"ec.balance not working **Describe the bug** After recompiling the weed binary with the actual snapshot the binary fixes the last issues (problem with redirect, problem with some ec encoded files) but now i could see some of the ec.shards are not distributed in the right way (5 volume servers). for example volume 59:  bm6: 59 3146776576 Bytes [0 1 2 3] 06 Nov 19 11:08 +0100 bm8: 59 3146776576 Bytes [0 1 2 3 4 5 6 7 8 9 10] 06 Nov 19 11:06 +0100 bm9: 59 3146776576 Bytes [4] 06 Nov 19 11:08 +0100 bm2: 59 3146776576 Bytes [11 12 13] 06 Nov 19 10:29 +0100 bm7: 59 3146776576 Bytes [5 6 7] 06 Nov 19 11:08 +0100  i dont know why those shards had been created this way (when doing ec.encode all volume servers had been up and those should be distributed equally) but i wanted to fix it with weed shell - ec.balance -force but ec.balance -force only says:  balanceEcVolumes collections 1 balanceEcVolumes collection balanceEcVolumes bm7:8280 has 1 overlimit, moving ec shard 15.4 bm7:8280 has 1 overlimit, moving ec shard 60.6 bm2:8280 has 2 overlimit, moving ec shard 56.0 bm2:8280 has 1 overlimit, moving ec shard 56.1 bm6:8280 has 1 overlimit, moving ec shard 59.0  and seems to be doing nothing. weed master is also configured to do:  [master.maintenance] # periodically run these scripts are the same as running them from 'weed shell' scripts =  ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force ec.balance -force volume.balance -force  sleep_minutes = 17 # sleep minutes between each script execution  is balancing maybe running currently in the background ? how to check this ? i did not see anything in the logfiles  **System Setup** weed version: version 30GB 1.44 linux amd64 but as stated recompiled with the latest git snapshot OS Version - mixed Ubuntu Server 14.04 and 18.04 **Expected behavior** - doing a rebalance - some sort of status message if something is running in the background - either in `weed shell` or in the web status screen - or in both ;) additionally ec.rebuild says: error: disk space is not enough but on all (weed) disks there is plenty of storage free - or is here another path used - for example /tmp ? source-file source-file source-file source-file source-file source-file",no-bug,0.8
2483,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2483,"deploy seaweedfs use seaweedfs-compose.yml, but cronjob service not start",**Describe the bug** I use [docker-compose](https://github.com/chrislusf/seaweedfs/blob/master/docker/seaweedfs-compose.yml) to start SeaweedFS. but `cronjob` service not start successfully. others start successfully. **Expected behavior** cronjob start successfully. **Screenshots** ![image](https://user-images.githubusercontent.com/22998204/144028831-de957b09-e870-4dec-a22d-2f354f274bb5.png) is there something wrong?,container-file | config-file | config-file | other-file | documentation-file | documentation-file,"deploy seaweedfs use seaweedfs-compose.yml, but cronjob service not start **Describe the bug** I use [docker-compose](https://github.com/chrislusf/seaweedfs/blob/master/docker/seaweedfs-compose.yml) to start SeaweedFS. but `cronjob` service not start successfully. others start successfully. **Expected behavior** cronjob start successfully. **Screenshots** ![image](https://user-images.githubusercontent.com/22998204/144028831-de957b09-e870-4dec-a22d-2f354f274bb5.png) is there something wrong? container-file config-file config-file other-file documentation-file documentation-file",no-bug,0.9
4639,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4639,Second Filer first start bootstrap stuck,"**Describe the bug** When running the filer services on a 3-node cluster, the first filer server starts perfectly (port 8888 and 8889 are reachable in read-only mode). However, when I try to start an additional filer service, it gets stuck during startup, and the required ports (8888, 18888, etc.) are not being listened to, and nothing happens. The live filer server continuously throws the following error messages: `7300884 Jul 4 15:57:36 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:36.908767 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused"" Jul 4 15:57:38 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:38.641958 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.40.45:8888 start from 2023-07-04 15:44:57.107300884 +0200 CEST 1688478297107300884 Jul 4 15:57:38 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:38.642976 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused"" Jul 4 15:57:40 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:40.376985 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.40.45:8888 start from 2023-07-04 15:44:57.107300884 +0200 CEST 1688478297107300884 Jul 4 15:57:40 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:40.377856 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused"" Jul 4 15:57:42 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:42.111475 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.40.45:8888 start from 2023-07-04 15:44:57.107300884 +0200 CEST 1688478297107300884 Jul 4 15:57:42 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:42.112280 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused"" Jul 4 15:57:43 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:43.846429 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.40.45:8888 start from 2023-07-04 15:44:57.107300884 +0200 CEST 1688478297107300884 Jul 4 15:57:43 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:43.847666 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused""` The second filer, which I'm trying to start, gets stuck at this point: `root@sofalvin-seaweedfs-b:~# /usr/local/bin/weed filer -debug -port=8888 -port.readonly=8899 -master=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -dataCenter=datacenter-01 -defaultStoreDir=/opt/filer_store I0704 15:44:57.043401 filer_server.go:141 default to create filer store dir in /opt/filer_store/filerldb2 I0704 15:44:57.046496 leveldb2_store.go:42 filer store leveldb2 dir: /opt/filer_store/filerldb2 I0704 15:44:57.046624 file_util.go:23 Folder /opt/filer_store/filerldb2 Permission: -rwxr-xr-x I0704 15:44:57.111770 filer.go:163 create filer.store.id to 1700974077 I0704 15:44:57.111850 configuration.go:28 configured filer store to leveldb2 I0704 15:44:57.112903 master_client.go:20 the cluster has 2 filer I0704 15:44:57.112932 filer_server.go:169 192.168.40.45:8888 bootstrap from peers [node_type:""filer"" address:""192.168.40.44:8888"" is_add:true created_at_ns:1688478167862760066 node_type:""filer"" address:""192.168.40.45:8888"" is_add:true created_at_ns:1688478297106983724] I0704 15:44:57.113000 filer.go:91 bootstrap from 192.168.40.44:8888 clientId:501074952` Restarting or restarting the second filer server resolves the issue and everything runs smoothly. What could be causing this? **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". /usr/local/bin/weed master -ip=192.168.40.44 -port=9333 -mdir=/opt/seaweedfs -peers=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -defaultReplication=001 /usr/local/bin/weed volume -dir=/mnt/vol1 -port=8080 -mserver=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -dataCenter datacenter-01 -rack rack-01 -fileSizeLimitMB 1000 /usr/local/bin/weed filer -debug -port=8888 -port.readonly=8899 -master=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -dataCenter=datacenter-01 -defaultStoreDir=/opt/filer_store - OS version Debian 11 - output of `weed version` version 30GB 3.53 linux amd64 - if using filer, show the content of `filer.toml` /usr/local/bin/weed filer -debug -port=8888 -port.readonly=8899 -master=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -dataCenter=datacenter-01 -defaultStoreDir=/opt/filer_store",source-file | source-file,"Second Filer first start bootstrap stuck **Describe the bug** When running the filer services on a 3-node cluster, the first filer server starts perfectly (port 8888 and 8889 are reachable in read-only mode). However, when I try to start an additional filer service, it gets stuck during startup, and the required ports (8888, 18888, etc.) are not being listened to, and nothing happens. The live filer server continuously throws the following error messages: `7300884 Jul 4 15:57:36 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:36.908767 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused"" Jul 4 15:57:38 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:38.641958 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.40.45:8888 start from 2023-07-04 15:44:57.107300884 +0200 CEST 1688478297107300884 Jul 4 15:57:38 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:38.642976 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused"" Jul 4 15:57:40 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:40.376985 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.40.45:8888 start from 2023-07-04 15:44:57.107300884 +0200 CEST 1688478297107300884 Jul 4 15:57:40 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:40.377856 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused"" Jul 4 15:57:42 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:42.111475 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.40.45:8888 start from 2023-07-04 15:44:57.107300884 +0200 CEST 1688478297107300884 Jul 4 15:57:42 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:42.112280 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused"" Jul 4 15:57:43 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:43.846429 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.40.45:8888 start from 2023-07-04 15:44:57.107300884 +0200 CEST 1688478297107300884 Jul 4 15:57:43 sofalvin-seaweedfs-a seaweedfs-volume[30449]: I0704 15:57:43.847666 meta_aggregator.go:103 subscribing remote 192.168.40.45:8888 meta change: connecting to peer filer 192.168.40.45:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp 192.168.40.45:18888: connect: connection refused""` The second filer, which I'm trying to start, gets stuck at this point: `root@sofalvin-seaweedfs-b:~# /usr/local/bin/weed filer -debug -port=8888 -port.readonly=8899 -master=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -dataCenter=datacenter-01 -defaultStoreDir=/opt/filer_store I0704 15:44:57.043401 filer_server.go:141 default to create filer store dir in /opt/filer_store/filerldb2 I0704 15:44:57.046496 leveldb2_store.go:42 filer store leveldb2 dir: /opt/filer_store/filerldb2 I0704 15:44:57.046624 file_util.go:23 Folder /opt/filer_store/filerldb2 Permission: -rwxr-xr-x I0704 15:44:57.111770 filer.go:163 create filer.store.id to 1700974077 I0704 15:44:57.111850 configuration.go:28 configured filer store to leveldb2 I0704 15:44:57.112903 master_client.go:20 the cluster has 2 filer I0704 15:44:57.112932 filer_server.go:169 192.168.40.45:8888 bootstrap from peers [node_type:""filer"" address:""192.168.40.44:8888"" is_add:true created_at_ns:1688478167862760066 node_type:""filer"" address:""192.168.40.45:8888"" is_add:true created_at_ns:1688478297106983724] I0704 15:44:57.113000 filer.go:91 bootstrap from 192.168.40.44:8888 clientId:501074952` Restarting or restarting the second filer server resolves the issue and everything runs smoothly. What could be causing this? **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". /usr/local/bin/weed master -ip=192.168.40.44 -port=9333 -mdir=/opt/seaweedfs -peers=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -defaultReplication=001 /usr/local/bin/weed volume -dir=/mnt/vol1 -port=8080 -mserver=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -dataCenter datacenter-01 -rack rack-01 -fileSizeLimitMB 1000 /usr/local/bin/weed filer -debug -port=8888 -port.readonly=8899 -master=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -dataCenter=datacenter-01 -defaultStoreDir=/opt/filer_store - OS version Debian 11 - output of `weed version` version 30GB 3.53 linux amd64 - if using filer, show the content of `filer.toml` /usr/local/bin/weed filer -debug -port=8888 -port.readonly=8899 -master=192.168.40.44:9333,192.168.40.45:9333,192.168.40.62:9333 -dataCenter=datacenter-01 -defaultStoreDir=/opt/filer_store source-file source-file",no-bug,0.9
936,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/936,weed mount samba,sambawindows /home/wwwrootsamba/home/wwwroot/home/wwwroot/subdir weed mountsamba,source-file,weed mount samba sambawindows /home/wwwrootsamba/home/wwwroot/home/wwwroot/subdir weed mountsamba source-file,no-bug,0.9
2630,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2630,[volume_loading] volumeDataIntegrityChecking failed verifyNeedleIntegrity size mismatch,"weed version  2.87  I unexpectedly massively (more than 20 volumes) received volume loading errors after another update with restarting volumes  Jan 28, 2022 @ 13:00:59.912 I0128 08:00:53 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_210.idx failed: read data [24264,32) : size mismatch Jan 28, 2022 @ 13:00:59.917 I0128 08:00:53 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_258.idx failed: read data [179803856,32) : size mismatch Jan 28, 2022 @ 13:00:59.917 I0128 08:00:53 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:00:59.917 I0128 08:00:53 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_256.idx failed: read data [257705480,32) : size mismatch Jan 28, 2022 @ 13:04:21.699 I0128 08:04:13 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_210.idx failed: read data [24264,32) : size mismatch Jan 28, 2022 @ 13:04:21.702 I0128 08:04:13 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_256.idx failed: read data [257705480,32) : size mismatch Jan 28, 2022 @ 13:07:42.939 I0128 08:07:33 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_94.idx failed: read data [1384568,32) : size mismatch Jan 28, 2022 @ 13:07:42.945 I0128 08:07:33 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_118.idx failed: read data [38372008,32) : size mismatch Jan 28, 2022 @ 13:07:42.946 I0128 08:07:33 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:07:42.947 I0128 08:07:33 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:11:10.969 I0128 08:11:03 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_95.idx failed: read data [1709848,32) : size mismatch Jan 28, 2022 @ 13:11:10.977 I0128 08:11:03 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:11:10.977 I0128 08:11:03 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:11:10.978 I0128 08:11:03 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:28:50.993 I0128 08:28:44 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_95.idx failed: read data [1709848,32) : size mismatch Jan 28, 2022 @ 13:28:50.999 I0128 08:28:44 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:28:51.000 I0128 08:28:44 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:28:51.001 I0128 08:28:44 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:30:22.946 I0128 08:30:17 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_94.idx failed: read data [1384568,32) : size mismatch Jan 28, 2022 @ 13:30:22.954 I0128 08:30:17 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_118.idx failed: read data [38372008,32) : size mismatch Jan 28, 2022 @ 13:30:22.955 I0128 08:30:17 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:30:22.957 I0128 08:30:17 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:32:41.690 I0128 08:32:34 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_210.idx failed: read data [24264,32) : size mismatch Jan 28, 2022 @ 13:32:41.694 I0128 08:32:34 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_256.idx failed: read data [257705480,32) : size mismatch Jan 28, 2022 @ 13:34:30.976 I0128 08:34:25 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_95.idx failed: read data [1709848,32) : size mismatch Jan 28, 2022 @ 13:34:30.983 I0128 08:34:25 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:34:30.984 I0128 08:34:25 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:34:30.985 I0128 08:34:25 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:38:40.985 I0128 08:38:35 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_95.idx failed: read data [1709848,32) : size mismatch Jan 28, 2022 @ 13:38:40.995 I0128 08:38:35 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:38:40.995 I0128 08:38:35 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:38:40.996 I0128 08:38:35 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch  https://github.com/chrislusf/seaweedfs/blob/master/weed/storage/volume_checking.go#L57",documentation-file,"[volume_loading] volumeDataIntegrityChecking failed verifyNeedleIntegrity size mismatch weed version  2.87  I unexpectedly massively (more than 20 volumes) received volume loading errors after another update with restarting volumes  Jan 28, 2022 @ 13:00:59.912 I0128 08:00:53 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_210.idx failed: read data [24264,32) : size mismatch Jan 28, 2022 @ 13:00:59.917 I0128 08:00:53 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_258.idx failed: read data [179803856,32) : size mismatch Jan 28, 2022 @ 13:00:59.917 I0128 08:00:53 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:00:59.917 I0128 08:00:53 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_256.idx failed: read data [257705480,32) : size mismatch Jan 28, 2022 @ 13:04:21.699 I0128 08:04:13 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_210.idx failed: read data [24264,32) : size mismatch Jan 28, 2022 @ 13:04:21.702 I0128 08:04:13 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_256.idx failed: read data [257705480,32) : size mismatch Jan 28, 2022 @ 13:07:42.939 I0128 08:07:33 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_94.idx failed: read data [1384568,32) : size mismatch Jan 28, 2022 @ 13:07:42.945 I0128 08:07:33 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_118.idx failed: read data [38372008,32) : size mismatch Jan 28, 2022 @ 13:07:42.946 I0128 08:07:33 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:07:42.947 I0128 08:07:33 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:11:10.969 I0128 08:11:03 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_95.idx failed: read data [1709848,32) : size mismatch Jan 28, 2022 @ 13:11:10.977 I0128 08:11:03 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:11:10.977 I0128 08:11:03 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:11:10.978 I0128 08:11:03 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:28:50.993 I0128 08:28:44 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_95.idx failed: read data [1709848,32) : size mismatch Jan 28, 2022 @ 13:28:50.999 I0128 08:28:44 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:28:51.000 I0128 08:28:44 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:28:51.001 I0128 08:28:44 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:30:22.946 I0128 08:30:17 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_94.idx failed: read data [1384568,32) : size mismatch Jan 28, 2022 @ 13:30:22.954 I0128 08:30:17 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_118.idx failed: read data [38372008,32) : size mismatch Jan 28, 2022 @ 13:30:22.955 I0128 08:30:17 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:30:22.957 I0128 08:30:17 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:32:41.690 I0128 08:32:34 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_210.idx failed: read data [24264,32) : size mismatch Jan 28, 2022 @ 13:32:41.694 I0128 08:32:34 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_256.idx failed: read data [257705480,32) : size mismatch Jan 28, 2022 @ 13:34:30.976 I0128 08:34:25 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_95.idx failed: read data [1709848,32) : size mismatch Jan 28, 2022 @ 13:34:30.983 I0128 08:34:25 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:34:30.984 I0128 08:34:25 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:34:30.985 I0128 08:34:25 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch Jan 28, 2022 @ 13:38:40.985 I0128 08:38:35 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_95.idx failed: read data [1709848,32) : size mismatch Jan 28, 2022 @ 13:38:40.995 I0128 08:38:35 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_146.idx failed: read data [4988464,32) : size mismatch Jan 28, 2022 @ 13:38:40.995 I0128 08:38:35 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_257.idx failed: read data [223556776,32) : size mismatch Jan 28, 2022 @ 13:38:40.996 I0128 08:38:35 1 volume_loading.go:126] volumeDataIntegrityChecking failed verifyNeedleIntegrity /data/_123.idx failed: read data [3327824,32) : size mismatch  https://github.com/chrislusf/seaweedfs/blob/master/weed/storage/volume_checking.go#L57 documentation-file",no-bug,0.9
3623,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3623,[aligo] optimization storage structs," aligo check . -- {GOPATH}  Struct Store (store.go:43) fields order can be optimized (193  186) type Store struct { Locations []*DiskLocation // - MasterAddress pb.ServerAddress // - grpcDialOption grpc.DialOption // - Ip string // - PublicUrl string // - dataCenter string // optional informaton, overwriting master setting if exists rack string // optional information, overwriting master setting if exists volumeSizeLimit uint64 // read from the master Port int // - GrpcPort int // - NeedleMapKind NeedleMapKind // - NewVolumesChan chan pb/master_pb.VolumeShortIn // - DeletedVolumesChan chan master_pb.VolumeShortInfor // - NewEcShardsChan chan master_pb.VolumeEcShardInf // - DeletedEcShardsChan chan master_pb.VolumeEcShardInf // - connected bool // - isStopping bool // - } Struct Volume (volume.go:21) fields order can be optimized (304  287) type Volume struct { SuperBlock super_block.SuperBlock // - dir string // - dirIdx string // - Collection string // - DataBackend backend.BackendStorageFile // - nm NeedleMapper // - tmpNm TempNeedleMapper // - lastIoError error // - needleMapKind NeedleMapKind // - asyncRequestsChan chan *needle.AsyncRequest // - lastModifiedTsSeconds uint64 // unix time in seconds lastAppendAtNs uint64 // unix time in nanoseconds lastCompactIndexOffset uint64 // - volumeInfo *pb/volume_server_pb.VolumeInfo // - location *DiskLocation // - noWriteLock sync.RWMutex // - dataFileAccessLock sync.RWMutex // - superBlockAccessLock sync.Mutex // - Id needle.VolumeId // - MemoryMapMaxSizeMb uint32 // - lastCompactRevision uint16 // - noWriteOrDelete bool // if readonly, either noWriteOrDelete or noWriteCanDelete noWriteCanDelete bool // if readonly, either noWriteOrDelete or noWriteCanDelete hasRemoteFile bool // if the volume has a remote file isCompacting bool // - isCommitCompacting bool // - } Struct VolumeInfo (volume_info.go:12) fields order can be optimized (144  130) type VolumeInfo struct { DiskType string Collection string RemoteStorageName string RemoteStorageKey string Size uint64 ReplicaPlacement *super_block.ReplicaPlacement Ttl *needle.TTL FileCount int DeleteCount int DeletedByteCount uint64 ModifiedAtSecond int64 Id needle.VolumeId CompactRevision uint32 Version needle.Version ReadOnly bool } Struct VolumeFileScanner4Vacuum (volume_vacuum.go:355) fields order can be optimized (64  57) type VolumeFileScanner4Vacuum struct { dstBackend backend.BackendStorageFile v *Volume nm *needle_map.MemDb newOffset int64 now uint64 writeThrottler *util.WriteThrottler version needle.Version }  ",source-file | source-file | source-file | source-file,"[aligo] optimization storage structs  aligo check . -- {GOPATH}  Struct Store (store.go:43) fields order can be optimized (193  186) type Store struct { Locations []*DiskLocation // - MasterAddress pb.ServerAddress // - grpcDialOption grpc.DialOption // - Ip string // - PublicUrl string // - dataCenter string // optional informaton, overwriting master setting if exists rack string // optional information, overwriting master setting if exists volumeSizeLimit uint64 // read from the master Port int // - GrpcPort int // - NeedleMapKind NeedleMapKind // - NewVolumesChan chan pb/master_pb.VolumeShortIn // - DeletedVolumesChan chan master_pb.VolumeShortInfor // - NewEcShardsChan chan master_pb.VolumeEcShardInf // - DeletedEcShardsChan chan master_pb.VolumeEcShardInf // - connected bool // - isStopping bool // - } Struct Volume (volume.go:21) fields order can be optimized (304  287) type Volume struct { SuperBlock super_block.SuperBlock // - dir string // - dirIdx string // - Collection string // - DataBackend backend.BackendStorageFile // - nm NeedleMapper // - tmpNm TempNeedleMapper // - lastIoError error // - needleMapKind NeedleMapKind // - asyncRequestsChan chan *needle.AsyncRequest // - lastModifiedTsSeconds uint64 // unix time in seconds lastAppendAtNs uint64 // unix time in nanoseconds lastCompactIndexOffset uint64 // - volumeInfo *pb/volume_server_pb.VolumeInfo // - location *DiskLocation // - noWriteLock sync.RWMutex // - dataFileAccessLock sync.RWMutex // - superBlockAccessLock sync.Mutex // - Id needle.VolumeId // - MemoryMapMaxSizeMb uint32 // - lastCompactRevision uint16 // - noWriteOrDelete bool // if readonly, either noWriteOrDelete or noWriteCanDelete noWriteCanDelete bool // if readonly, either noWriteOrDelete or noWriteCanDelete hasRemoteFile bool // if the volume has a remote file isCompacting bool // - isCommitCompacting bool // - } Struct VolumeInfo (volume_info.go:12) fields order can be optimized (144  130) type VolumeInfo struct { DiskType string Collection string RemoteStorageName string RemoteStorageKey string Size uint64 ReplicaPlacement *super_block.ReplicaPlacement Ttl *needle.TTL FileCount int DeleteCount int DeletedByteCount uint64 ModifiedAtSecond int64 Id needle.VolumeId CompactRevision uint32 Version needle.Version ReadOnly bool } Struct VolumeFileScanner4Vacuum (volume_vacuum.go:355) fields order can be optimized (64  57) type VolumeFileScanner4Vacuum struct { dstBackend backend.BackendStorageFile v *Volume nm *needle_map.MemDb newOffset int64 now uint64 writeThrottler *util.WriteThrottler version needle.Version }   source-file source-file source-file source-file",no-bug,0.9
1064,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1064,seaweed s3 list_buckets,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** I'm using s3 gateway and python boto3 and while trying to list all buckets I'm getting the error:   kwrgs = {'endpoint_url': 'http://seaweedfs-s3.default.svc.cluster.local:8333', 'aws_access_key_id': 'accessKey1', 'aws_secret_access_key': 'secretKey1'}  import boto3  cli = boto3.client('s3', **kwrgs)  cli.list_buckets() Traceback (most recent call last): File ""<stdin>"", line 1, in <module> File ""/usr/local/lib/python3.7/site-packages/botocore/client.py"", line 357, in _api_call return self._make_api_call(operation_name, kwargs) File ""/usr/local/lib/python3.7/site-packages/botocore/client.py"", line 661, in _make_api_call raise error_class(parsed_response, operation_name) botocore.exceptions.ClientError: An error occurred (InternalError) when calling the ListBuckets operation (reached max retries: 4): We encountered an internal error, please try again.  I Found only Errors in the s3 gateway:  I0916 09:49:36 1 config.go:25] Reading security.toml from I0916 09:49:36 1 config.go:28] Reading : Config File ""security"" Not Found in ""[/ /root/.seaweedfs /etc/seaweedfs]"" I0916 09:49:36 1 s3.go:92] Start Seaweed S3 API Server 30GB 1.43 at http port 8333 I0916 09:50:58 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:51:18 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627478252701334</RequestId></Error> I0916 09:51:19 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:51:39 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627499203098406</RequestId></Error> I0916 09:51:40 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:00 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627520693419381</RequestId></Error> I0916 09:52:02 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:22 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627542703114894</RequestId></Error> I0916 09:52:30 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:50 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627570429772055</RequestId></Error  FYI : The weed shell can return the colletion.list and fs.tree without any issue The s3cmd can't list buckets too put file is working: cli.put_object(Bucket='test', Key='test', Body='test'). output:  {'ResponseMetadata': {'RequestId': '1568620869872887033', 'HostId': '', 'HTTPStatusCode': 200, 'HTTPHeaders': {'accept-ranges': 'bytes', 'etag': '""098f6bcd4621d373cade4e832627b4f6""', 'x-amz-request-id': '1568620869872887033', 'date': 'Mon, 16 Sep 2019 08:01:09 GMT', 'content-length': '0'}, 'RetryAttempts': 0}, 'ETag': '""098f6bcd4621d373cade4e832627b4f6""'}  **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"":  /usr/bin/weed -v=4 s3 -port=8333 -filer.dir.buckets=/buckets -filer=seaweedfs-filer.default:8888 /usr/bin/weed -v=4 master -port=9333 -mdir=/data -ip.bind=0.0.0.0 -volumeSizeLimitMB=30000 -defaultReplication=000 -ip=seaweedfs-master-0.seaweedfs-master -peers=seaweedfs-master-0.seaweedfs-master:9333 /usr/bin/weed -v=4 volume -port=8080 -dir=/data -max=1000 -ip.bind=0.0.0.0 -read.redirect=true -ip=10.244.83.158 -mserver=seaweedfs-master-0.seaweedfs-master:9333 /usr/bin/weed -v=4 filer -port=8888 -dirListLimit=100000 -ip=10.244.83.155 -master=seaweedfs-master-0.seaweedfs-master:9333  - OS version: Ubuntu 18.04.2 LTS - output of `weed version`: version 30GB 1.43 linux amd64 - if using filer, show the content of `filer.toml`  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" [memory] # local in memory, mostly for testing purpose enabled = false [leveldb] # local on disk, mostly for simple single-machine setup, fairly scalable enabled = false dir = ""/data"" # directory to store level db files [leveldb2] # local on disk, mostly for simple single-machine setup, fairly scalable enabled = true dir = ""/data/filerldb2"" # directory to store level db 2 files  # multiple filers on shared storage, fairly scalable  [mysql] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT COMMENT 'first 64 bits of MD5 hash value of directory field', # name VARCHAR(1000) COMMENT 'directory or file name', # directory TEXT COMMENT 'full path to parent directory', # meta BLOB, # PRIMARY KEY (dirhash, name) # ) DEFAULT CHARSET=utf8; enabled = false hostname = ""localhost"" port = 3306 username = ""root"" password = """" database = """" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 [postgres] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT, # name VARCHAR(65535), # directory VARCHAR(65535), # meta bytea, # PRIMARY KEY (dirhash, name) # ); enabled = false hostname = ""localhost"" port = 5432 username = ""postgres"" password = """" database = """" # create or use an existing database sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 [cassandra] # CREATE TABLE filemeta ( # directory varchar, # name varchar, # meta blob, # PRIMARY KEY (directory, name) # ) WITH CLUSTERING ORDER BY (name ASC); enabled = false keyspace=""seaweedfs"" hosts=[ ""localhost:9042"", ] [redis] enabled = false address = ""localhost:6379"" password = """" db = 0 [redis_cluster] enabled = false addresses = [ ""localhost:30001"", ""localhost:30002"", ""localhost:30003"", ""localhost:30004"", ""localhost:30005"", ""localhost:30006"", ]  **Expected behavior** List all buckets when has only 1 bucket using python boto3",source-file,"seaweed s3 list_buckets Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** I'm using s3 gateway and python boto3 and while trying to list all buckets I'm getting the error:   kwrgs = {'endpoint_url': 'http://seaweedfs-s3.default.svc.cluster.local:8333', 'aws_access_key_id': 'accessKey1', 'aws_secret_access_key': 'secretKey1'}  import boto3  cli = boto3.client('s3', **kwrgs)  cli.list_buckets() Traceback (most recent call last): File ""<stdin>"", line 1, in <module> File ""/usr/local/lib/python3.7/site-packages/botocore/client.py"", line 357, in _api_call return self._make_api_call(operation_name, kwargs) File ""/usr/local/lib/python3.7/site-packages/botocore/client.py"", line 661, in _make_api_call raise error_class(parsed_response, operation_name) botocore.exceptions.ClientError: An error occurred (InternalError) when calling the ListBuckets operation (reached max retries: 4): We encountered an internal error, please try again.  I Found only Errors in the s3 gateway:  I0916 09:49:36 1 config.go:25] Reading security.toml from I0916 09:49:36 1 config.go:28] Reading : Config File ""security"" Not Found in ""[/ /root/.seaweedfs /etc/seaweedfs]"" I0916 09:49:36 1 s3.go:92] Start Seaweed S3 API Server 30GB 1.43 at http port 8333 I0916 09:50:58 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:51:18 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627478252701334</RequestId></Error> I0916 09:51:19 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:51:39 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627499203098406</RequestId></Error> I0916 09:51:40 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:00 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627520693419381</RequestId></Error> I0916 09:52:02 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:22 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627542703114894</RequestId></Error> I0916 09:52:30 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:50 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627570429772055</RequestId></Error  FYI : The weed shell can return the colletion.list and fs.tree without any issue The s3cmd can't list buckets too put file is working: cli.put_object(Bucket='test', Key='test', Body='test'). output:  {'ResponseMetadata': {'RequestId': '1568620869872887033', 'HostId': '', 'HTTPStatusCode': 200, 'HTTPHeaders': {'accept-ranges': 'bytes', 'etag': '""098f6bcd4621d373cade4e832627b4f6""', 'x-amz-request-id': '1568620869872887033', 'date': 'Mon, 16 Sep 2019 08:01:09 GMT', 'content-length': '0'}, 'RetryAttempts': 0}, 'ETag': '""098f6bcd4621d373cade4e832627b4f6""'}  **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"":  /usr/bin/weed -v=4 s3 -port=8333 -filer.dir.buckets=/buckets -filer=seaweedfs-filer.default:8888 /usr/bin/weed -v=4 master -port=9333 -mdir=/data -ip.bind=0.0.0.0 -volumeSizeLimitMB=30000 -defaultReplication=000 -ip=seaweedfs-master-0.seaweedfs-master -peers=seaweedfs-master-0.seaweedfs-master:9333 /usr/bin/weed -v=4 volume -port=8080 -dir=/data -max=1000 -ip.bind=0.0.0.0 -read.redirect=true -ip=10.244.83.158 -mserver=seaweedfs-master-0.seaweedfs-master:9333 /usr/bin/weed -v=4 filer -port=8888 -dirListLimit=100000 -ip=10.244.83.155 -master=seaweedfs-master-0.seaweedfs-master:9333  - OS version: Ubuntu 18.04.2 LTS - output of `weed version`: version 30GB 1.43 linux amd64 - if using filer, show the content of `filer.toml`  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" [memory] # local in memory, mostly for testing purpose enabled = false [leveldb] # local on disk, mostly for simple single-machine setup, fairly scalable enabled = false dir = ""/data"" # directory to store level db files [leveldb2] # local on disk, mostly for simple single-machine setup, fairly scalable enabled = true dir = ""/data/filerldb2"" # directory to store level db 2 files  # multiple filers on shared storage, fairly scalable  [mysql] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT COMMENT 'first 64 bits of MD5 hash value of directory field', # name VARCHAR(1000) COMMENT 'directory or file name', # directory TEXT COMMENT 'full path to parent directory', # meta BLOB, # PRIMARY KEY (dirhash, name) # ) DEFAULT CHARSET=utf8; enabled = false hostname = ""localhost"" port = 3306 username = ""root"" password = """" database = """" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 [postgres] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT, # name VARCHAR(65535), # directory VARCHAR(65535), # meta bytea, # PRIMARY KEY (dirhash, name) # ); enabled = false hostname = ""localhost"" port = 5432 username = ""postgres"" password = """" database = """" # create or use an existing database sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 [cassandra] # CREATE TABLE filemeta ( # directory varchar, # name varchar, # meta blob, # PRIMARY KEY (directory, name) # ) WITH CLUSTERING ORDER BY (name ASC); enabled = false keyspace=""seaweedfs"" hosts=[ ""localhost:9042"", ] [redis] enabled = false address = ""localhost:6379"" password = """" db = 0 [redis_cluster] enabled = false addresses = [ ""localhost:30001"", ""localhost:30002"", ""localhost:30003"", ""localhost:30004"", ""localhost:30005"", ""localhost:30006"", ]  **Expected behavior** List all buckets when has only 1 bucket using python boto3 source-file",bug,0.95
2046,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2046,HEAD memory usage for large files is insane,"**Describe the bug** Currently I'm using [minio/mc](https://github.com/minio/mc) as command shell, when I'm downloading large files from server, like `mc cp s3/mybucket/large10g.txt 10g.txt` mc will send HEAD request first to s3 api, then proxy to filer the memory usage is about 2 times of the file size, for example, a 10 GB file will cost like 20GB memory. After debug for a while, it appears to me that has something to do with #1913",other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"HEAD memory usage for large files is insane **Describe the bug** Currently I'm using [minio/mc](https://github.com/minio/mc) as command shell, when I'm downloading large files from server, like `mc cp s3/mybucket/large10g.txt 10g.txt` mc will send HEAD request first to s3 api, then proxy to filer the memory usage is about 2 times of the file size, for example, a 10 GB file will cost like 20GB memory. After debug for a while, it appears to me that has something to do with #1913 other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
1838,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1838,[s3] http: superfluous response.WriteHeader,"**Describe the bug** [s3] http: superfluous response.WriteHeader after `raft.Server: Not current leader` per request  I0225 09:43:38 1 masterclient.go:120] filer masterClient failed to receive from fast-master-0.s3-fast-master-direct.service.dcix.consul:9333: rpc error: code = Unavailable desc = transport is closing 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283) E0225 09:43:38 1 filer_server_handlers_write.go:42] failing to assign a file id: failed to parse master : server should have hostname:port format: I0225 09:43:38 1 common.go:53] response method:PUT URL:/buckets/registry/docker/registry/v2/repositories/b2c/credits-admin/_uploads/71e12cb4-5c6e-405e-a6ca-1d491ec79441/hashstates/sha256/15728640 with httpStatus:500 and JSON:{""error"":""failed to parse master : server should have hostname:port format: ""} E0225 09:43:38 1 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283) 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283)  https://github.com/chrislusf/seaweedfs/blob/master/weed/server/common.go#L284 **Expected behavior** automatic recovery after loss of master If there is no content, the S3 API returns 200 and 206 codes, need return 500",other-file | other-file | source-file | source-file | source-file | source-file,"[s3] http: superfluous response.WriteHeader **Describe the bug** [s3] http: superfluous response.WriteHeader after `raft.Server: Not current leader` per request  I0225 09:43:38 1 masterclient.go:120] filer masterClient failed to receive from fast-master-0.s3-fast-master-direct.service.dcix.consul:9333: rpc error: code = Unavailable desc = transport is closing 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283) E0225 09:43:38 1 filer_server_handlers_write.go:42] failing to assign a file id: failed to parse master : server should have hostname:port format: I0225 09:43:38 1 common.go:53] response method:PUT URL:/buckets/registry/docker/registry/v2/repositories/b2c/credits-admin/_uploads/71e12cb4-5c6e-405e-a6ca-1d491ec79441/hashstates/sha256/15728640 with httpStatus:500 and JSON:{""error"":""failed to parse master : server should have hostname:port format: ""} E0225 09:43:38 1 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283) 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283)  https://github.com/chrislusf/seaweedfs/blob/master/weed/server/common.go#L284 **Expected behavior** automatic recovery after loss of master If there is no content, the S3 API returns 200 and 206 codes, need return 500 other-file other-file source-file source-file source-file source-file",bug,0.9
23,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/23,Volume server keep wanting only to talk to localhost:9333,"I am trying to get volume servers to talk to a master but no mater what I say on the command arguments for mserver it starts sticking trying to connect to localhost: Starting volume server(on IP 10.150.14.80): /usr/local/bin/weed/weed -log_dir=/var/log/weed -v=4 -alsologtostderr=true volume -dir=/data -mserver=""10.150.14.89:9333"" Starting master server(ON IP 10.150.14.89) /usr/local/bin/weed/weed -v=4 master -mdir=/data The log on the volume server keeps saying: I1106 22:00:14 04343 file_util.go:20] Folder /data Permission: -rwxr-xr-x I1106 22:00:14 04343 store.go:220] Store started on dir: /data with 0 volumes max 7 I1106 22:00:14 04343 volume.go:91] Start Seaweed volume server 0.65 at 0.0.0.0:8080 I1106 22:00:14 04343 list_masters.go:18] list masters result :{""IsLeader"":true,""Leader"":""localhost:9333""} I1106 22:00:14 04343 store.go:57] current master node is :localhost:9333 I1106 22:00:14 04343 volume_server.go:65] Volume Server Failed to talk with master: Post http://localhost:9333/dir/join: dial tcp 127.0.0.1:9333: connection refused Any ideas ?",config-file | documentation-file | config-file | other-file | other-file | documentation-file | documentation-file | config-file | other-file | config-file | config-file | config-file | source-file | config-file | config-file | documentation-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file,"Volume server keep wanting only to talk to localhost:9333 I am trying to get volume servers to talk to a master but no mater what I say on the command arguments for mserver it starts sticking trying to connect to localhost: Starting volume server(on IP 10.150.14.80): /usr/local/bin/weed/weed -log_dir=/var/log/weed -v=4 -alsologtostderr=true volume -dir=/data -mserver=""10.150.14.89:9333"" Starting master server(ON IP 10.150.14.89) /usr/local/bin/weed/weed -v=4 master -mdir=/data The log on the volume server keeps saying: I1106 22:00:14 04343 file_util.go:20] Folder /data Permission: -rwxr-xr-x I1106 22:00:14 04343 store.go:220] Store started on dir: /data with 0 volumes max 7 I1106 22:00:14 04343 volume.go:91] Start Seaweed volume server 0.65 at 0.0.0.0:8080 I1106 22:00:14 04343 list_masters.go:18] list masters result :{""IsLeader"":true,""Leader"":""localhost:9333""} I1106 22:00:14 04343 store.go:57] current master node is :localhost:9333 I1106 22:00:14 04343 volume_server.go:65] Volume Server Failed to talk with master: Post http://localhost:9333/dir/join: dial tcp 127.0.0.1:9333: connection refused Any ideas ? config-file documentation-file config-file other-file other-file documentation-file documentation-file config-file other-file config-file config-file config-file source-file config-file config-file documentation-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file",no-bug,0.8
1724,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1724,One of the two volume servers that contain data returns error: invalid character '\x1f' and MIME type error,"Hi, I have 3 volume servers and 1 master node, I've created a collection name ""Animated_2tacopy_count"" with count=1 and replication=001 I upload my file with following command:  sweed@dev10:~$./weedfs/weed upload -collection=Animated_2tacopy_count=1 -dir=""/home/sweed/animate.mp4 [{""fileName"":""animate.mp4"",""fileUrl"":""192.168.200.23:8081/22,1d9ff15aa7"",""fid"":""22,1d9ff15aa7"",""size"":178481324}]  when I'm asking Master for my file, it return volume servers randomly:  sweed@dev10:~$ curl -I 192.168.200.20:9333/22,24dbfea5ed HTTP/1.1 308 Permanent Redirect Content-Type: text/html; charset=utf-8 Location: http://192.168.200.21:8081/22,24dbfea5ed Date: Thu, 31 Dec 2020 15:06:08 GMT sweed@dev10:~$ curl -I 192.168.200.20:9333/22,24dbfea5ed HTTP/1.1 308 Permanent Redirect Content-Type: text/html; charset=utf-8 Location: http://192.168.200.22:8081/22,24dbfea5ed Date: Thu, 31 Dec 2020 15:06:09 GMT  But in browser I can't see my file from volume serevr 192.168.200.21 but In another volume server ""192.168.200.22"" everything is ok, actully when browser returns the ip address of 200.22 I can see my file but when it return 200.21 I have mime type error: ![image](https://user-images.githubusercontent.com/43205944/103415573-0111fb80-4b98-11eb-9c53-568dab440166.png) And in journalctl of server 200.21 I have this error:  Dec 31 18:23:50 dev11 seaweedfs-volume[20791]: I1231 18:23:50 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:30 dev11 seaweedfs-volume[20791]: I1231 18:25:30 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:37 dev11 seaweedfs-volume[20791]: I1231 18:25:37 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:48 dev11 seaweedfs-volume[20791]: I1231 18:25:48 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:29 dev11 seaweedfs-volume[20791]: I1231 18:26:29 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:40 dev11 seaweedfs-volume[20791]: I1231 18:26:40 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:42 dev11 seaweedfs-volume[20791]: I1231 18:26:42 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:43 dev11 seaweedfs-volume[20791]: I1231 18:26:43 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:27:03 dev11 seaweedfs-volume[20791]: I1231 18:27:03 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value ",source-file | source-file,"One of the two volume servers that contain data returns error: invalid character '\x1f' and MIME type error Hi, I have 3 volume servers and 1 master node, I've created a collection name ""Animated_2tacopy_count"" with count=1 and replication=001 I upload my file with following command:  sweed@dev10:~$./weedfs/weed upload -collection=Animated_2tacopy_count=1 -dir=""/home/sweed/animate.mp4 [{""fileName"":""animate.mp4"",""fileUrl"":""192.168.200.23:8081/22,1d9ff15aa7"",""fid"":""22,1d9ff15aa7"",""size"":178481324}]  when I'm asking Master for my file, it return volume servers randomly:  sweed@dev10:~$ curl -I 192.168.200.20:9333/22,24dbfea5ed HTTP/1.1 308 Permanent Redirect Content-Type: text/html; charset=utf-8 Location: http://192.168.200.21:8081/22,24dbfea5ed Date: Thu, 31 Dec 2020 15:06:08 GMT sweed@dev10:~$ curl -I 192.168.200.20:9333/22,24dbfea5ed HTTP/1.1 308 Permanent Redirect Content-Type: text/html; charset=utf-8 Location: http://192.168.200.22:8081/22,24dbfea5ed Date: Thu, 31 Dec 2020 15:06:09 GMT  But in browser I can't see my file from volume serevr 192.168.200.21 but In another volume server ""192.168.200.22"" everything is ok, actully when browser returns the ip address of 200.22 I can see my file but when it return 200.21 I have mime type error: ![image](https://user-images.githubusercontent.com/43205944/103415573-0111fb80-4b98-11eb-9c53-568dab440166.png) And in journalctl of server 200.21 I have this error:  Dec 31 18:23:50 dev11 seaweedfs-volume[20791]: I1231 18:23:50 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:30 dev11 seaweedfs-volume[20791]: I1231 18:25:30 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:37 dev11 seaweedfs-volume[20791]: I1231 18:25:37 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:48 dev11 seaweedfs-volume[20791]: I1231 18:25:48 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:29 dev11 seaweedfs-volume[20791]: I1231 18:26:29 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:40 dev11 seaweedfs-volume[20791]: I1231 18:26:40 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:42 dev11 seaweedfs-volume[20791]: I1231 18:26:42 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:43 dev11 seaweedfs-volume[20791]: I1231 18:26:43 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:27:03 dev11 seaweedfs-volume[20791]: I1231 18:27:03 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value  source-file source-file",bug,0.9
4115,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4115,volume and filer data mismatch,"**Describe the bug** E0106 18:57:53.688989 reader_at.go:147 fetching chunk &{FileId:4247,5d91ed630532c810 Offset:0 Size:7119 LogicOffset:0 ChunkSize:7119 CipherKey:[] IsGzipped:true}: http://10.17.100.30:8081/4247,5d91ed630532c810?readDeleted=true: 404 Not Found My cluster seems to be missing a lot of filesIs it possible to fix it Why did this error occur? `volume.fsck` looks dangerousI don't know how to use it safely. @chrislusf @kmlebedev **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - weed -logdir=/export/logs/seaweedfs/log/master2 master -mdir=/export/data/seaweedfs/master/mdir2 -peers=10.17.100.27:9333,10.17.100.29:9333,10.17.100.30:9333 -port=9333 -volumeSizeLimitMB=5000 -defaultReplication=001 -metricsPort=1234 -electionTimeout=3s - weed -logdir=/export/logs/seaweedfs/log/volume2 volume -dir=/export/data/seaweedfs/volume/data2 -dataCenter=ihuman-datacenter -rack=ihuman-rack1 -max=2000 -mserver=10.17.100.27:9333,10.17.100.29:9333,10.17.100.30:9333 -port=8081 -metricsPort=1236 - weed -logdir=/export/logs/seaweedfs/log/filer filer -master=10.17.100.27:9333,10.17.100.29:9333,10.17.100.30:9333 -port=8888 -metricsPort=1235 -disableDirListing=true - OS version - output of `weed version` version 30GB 3.34 linux amd64 - if using filer, show the content of `filer.toml` use mysql **Expected behavior** A clear and concise description of what you expected to happen. **Additional context**  > volume.fsck -findMissingChunksInFiler Failed to search for last valid index on volume 3594 with error to read needle meta with id 559593113 from volume 3594 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 136 with error to read needle meta with id 24070706 from volume 136 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3920 with error to read needle meta with id 1003664128 from volume 3920 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 24 with error to read needle meta with id 24060775 from volume 24 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3196 with error to read needle meta with id 28262524 from volume 3196 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3484 with error to read needle meta with id 0 from volume 3484 with error rpc error: code = Unknown desc = panic occurred: runtime error: slice bounds out of range [:19] with capacity 16 Failed to search for last valid index on volume 47 with error to read needle meta with id 61469970 from volume 47 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3829 with error to read needle meta with id 838563609 from volume 3829 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3389 with error to read needle meta with id 319189011 from volume 3389 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3592 with error to read needle meta with id 745925603 from volume 3592 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3915 with error to read needle meta with id 1003689513 from volume 3915 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3174 with error to read needle meta with id 52457224 from volume 3174 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 134 with error to read needle meta with id 24070697 from volume 134 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3173 with error to read needle meta with id 52457496 from volume 3173 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3194 with error to read needle meta with id 28263309 from volume 3194 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 120 with error to read needle meta with id 24071760 from volume 120 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 46 with error to read needle meta with id 61412043 from volume 46 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 23 with error to read needle meta with id 24068890 from volume 23 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3919 with error to read needle meta with id 1003641892 from volume 3919 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3277 with error to read needle meta with id 62978653 from volume 3277 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 20 with error to read needle meta with id 24053021 from volume 20 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3468 with error to read needle meta with id 747685956 from volume 3468 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 119 with error to read needle meta with id 24079718 from volume 119 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 135 with error to read needle meta with id 24070713 from volume 135 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3102 with error to read needle meta with id 732280017 from volume 3102 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3199 with error to read needle meta with id 28260854 from volume 3199 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 271 with error to read needle meta with id 24103496 from volume 271 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 115 with error to read needle meta with id 24071812 from volume 115 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3918 with error to read needle meta with id 1003664941 from volume 3918 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 118 with error to read needle meta with id 24079712 from volume 118 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3464 with error to read needle meta with id 847887517 from volume 3464 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3170 with error to read needle meta with id 52457325 from volume 3170 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3596 with error to read needle meta with id 897246367 from volume 3596 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3916 with error to read needle meta with id 1003664888 from volume 3916 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3555 with error to read needle meta with id 1064035495 from volume 3555 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 137 with error to read needle meta with id 24070695 from volume 137 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3948 with error to read needle meta with id 991219813 from volume 3948 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3386 with error to read needle meta with id 279227918 from volume 3386 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3430 with error to read needle meta with id 838702791 from volume 3430 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 116 with error to read needle meta with id 24071811 from volume 116 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3171 with error to read needle meta with id 52457406 from volume 3171 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3428 with error to read needle meta with id 899399493 from volume 3428 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3270 with error to read needle meta with id 345861650 from volume 3270 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3387 with error to read needle meta with id 290956173 from volume 3387 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 274 with error to read needle meta with id 24103512 from volume 274 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3388 with error to read needle meta with id 319189001 from volume 3388 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3427 with error to read needle meta with id 426841619 from volume 3427 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3269 with error to read needle meta with id 357107148 from volume 3269 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 21 with error to read needle meta with id 24066909 from volume 21 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 111 with error to read needle meta with id 24069582 from volume 111 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3385 with error to read needle meta with id 280524485 from volume 3385 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3596 with error to read needle meta with id 897159628 from volume 3596 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3595 with error to read needle meta with id 354093485 from volume 3595 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3554 with error to read needle meta with id 1065286842 from volume 3554 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 272 with error to read needle meta with id 24103526 from volume 272 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3592 with error to read needle meta with id 899927738 from volume 3592 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 117 with error to read needle meta with id 24071788 from volume 117 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3277 with error to read needle meta with id 62978653 from volume 3277 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3197 with error to read needle meta with id 28263207 from volume 3197 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3195 with error to read needle meta with id 28260506 from volume 3195 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3198 with error to read needle meta with id 28260379 from volume 3198 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3266 with error to read needle meta with id 345731882 from volume 3266 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3945 with error to read needle meta with id 992329923 from volume 3945 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 270 with error to read needle meta with id 24103516 from volume 270 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 138 with error to read needle meta with id 24071732 from volume 138 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3555 with error to read needle meta with id 1054866792 from volume 3555 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 269 with error to read needle meta with id 24103513 from volume 269 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3594 with error to read needle meta with id 864605294 from volume 3594 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3196 with error to read needle meta with id 28262524 from volume 3196 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3465 with error to read needle meta with id 847734979 from volume 3465 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3427 with error to read needle meta with id 426841619 from volume 3427 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 118 with error to read needle meta with id 24079712 from volume 118 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3917 with error to read needle meta with id 1003552725 from volume 3917 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3186 with error to read needle meta with id 1065285866 from volume 3186 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3915 with error to read needle meta with id 1003689513 from volume 3915 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3170 with error to read needle meta with id 52457325 from volume 3170 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 43 with error to read needle meta with id 61470221 from volume 43 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 48 with error to read needle meta with id 61469780 from volume 48 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 44 with error to read needle meta with id 28145882 from volume 44 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 273 with error to read needle meta with id 24103528 from volume 273 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3551 with error to read needle meta with id 1065287110 from volume 3551 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3553 with error to read needle meta with id 1063875149 from volume 3553 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 271 with error to read needle meta with id 24103496 from volume 271 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3781 with error to read needle meta with id 905390423 from volume 3781 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 19 with error to read needle meta with id 24060748 from volume 19 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 133 with error to read needle meta with id 24071727 from volume 133 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3387 with error to read needle meta with id 290956173 from volume 3387 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3187 with error to read needle meta with id 1054742100 from volume 3187 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3829 with error to read needle meta with id 838563609 from volume 3829 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3920 with error to read needle meta with id 1003664128 from volume 3920 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3783 with error to read needle meta with id 991859259 from volume 3783 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3191 with error to read needle meta with id 407461431 from volume 3191 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3919 with error to read needle meta with id 1003641892 from volume 3919 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3552 with error to read needle meta with id 1064035719 from volume 3552 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 137 with error to read needle meta with id 24070695 from volume 137 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3199 with error to read needle meta with id 28260854 from volume 3199 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 45 with error to read needle meta with id 61411704 from volume 45 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3916 with error to read needle meta with id 1003664888 from volume 3916 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3464 with error to read needle meta with id 847887517 from volume 3464 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3437 with error to read needle meta with id 899389303 from volume 3437 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 119 with error to read needle meta with id 24079718 from volume 119 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3190 with error to read needle meta with id 407461272 from volume 3190 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3269 with error to read needle meta with id 357107148 from volume 3269 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 134 with error to read needle meta with id 24070697 from volume 134 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 22 with error to read needle meta with id 24068892 from volume 22 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 4444 with error to read needle meta with id 1712633163 from volume 4444 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3175 with error to read needle meta with id 52457144 from volume 3175 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 111 with error to read needle meta with id 24069582 from volume 111 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3943 with error to read needle meta with id 978863811 from volume 3943 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 20 with error to read needle meta with id 24053021 from volume 20 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3182 with error to read needle meta with id 1054866270 from volume 3182 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3268 with error to read needle meta with id 357097589 from volume 3268 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 23 with error to read needle meta with id 24068890 from volume 23 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3102 with error to read needle meta with id 732280017 from volume 3102 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 45 with error to read needle meta with id 61411704 from volume 45 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3270 with error to read needle meta with id 345861650 from volume 3270 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 48 with error to read needle meta with id 61469780 from volume 48 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 22 with error to read needle meta with id 24068892 from volume 22 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3187 with error to read needle meta with id 1054742100 from volume 3187 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3197 with error to read needle meta with id 28263207 from volume 3197 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3468 with error to read needle meta with id 747685956 from volume 3468 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3437 with error to read needle meta with id 899389303 from volume 3437 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3173 with error to read needle meta with id 52457496 from volume 3173 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3385 with error to read needle meta with id 280524485 from volume 3385 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3182 with error to read needle meta with id 1054866270 from volume 3182 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 43 with error to read needle meta with id 61470221 from volume 43 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3465 with error to read needle meta with id 847734979 from volume 3465 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3595 with error to read needle meta with id 899330853 from volume 3595 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 120 with error to read needle meta with id 24071760 from volume 120 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3190 with error to read needle meta with id 28029738 from volume 3190 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 46 with error to read needle meta with id 61412043 from volume 46 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3783 with error to read needle meta with id 991859259 from volume 3783 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3945 with error to read needle meta with id 992329923 from volume 3945 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3918 with error to read needle meta with id 1003664941 from volume 3918 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3198 with error to read needle meta with id 28260379 from volume 3198 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 117 with error to read needle meta with id 24071788 from volume 117 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 47 with error to read needle meta with id 61469970 from volume 47 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3195 with error to read needle meta with id 28260506 from volume 3195 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 136 with error to read needle meta with id 24070706 from volume 136 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 273 with error to read needle meta with id 24103528 from volume 273 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3386 with error to read needle meta with id 279227918 from volume 3386 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3552 with error to read needle meta with id 1065286875 from volume 3552 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 24 with error to read needle meta with id 24060775 from volume 24 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 272 with error to read needle meta with id 24103526 from volume 272 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3388 with error to read needle meta with id 319189001 from volume 3388 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 133 with error to read needle meta with id 24071727 from volume 133 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 269 with error to read needle meta with id 24103513 from volume 269 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3943 with error to read needle meta with id 978863811 from volume 3943 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3268 with error to read needle meta with id 357097589 from volume 3268 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3191 with error to read needle meta with id 28029877 from volume 3191 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3428 with error to read needle meta with id 899399493 from volume 3428 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 270 with error to read needle meta with id 24103516 from volume 270 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3266 with error to read needle meta with id 345731882 from volume 3266 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3171 with error to read needle meta with id 52457406 from volume 3171 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 135 with error to read needle meta with id 24070713 from volume 135 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 44 with error to read needle meta with id 28145882 from volume 44 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3174 with error to read needle meta with id 52457224 from volume 3174 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 274 with error to read needle meta with id 24103512 from volume 274 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3186 with error to read needle meta with id 1065285866 from volume 3186 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3917 with error to read needle meta with id 1003552725 from volume 3917 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 138 with error to read needle meta with id 24071732 from volume 138 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 19 with error to read needle meta with id 24060748 from volume 19 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3389 with error to read needle meta with id 319189011 from volume 3389 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3194 with error to read needle meta with id 28260281 from volume 3194 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3430 with error to read needle meta with id 838702791 from volume 3430 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 21 with error to read needle meta with id 24066909 from volume 21 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3175 with error to read needle meta with id 52457144 from volume 3175 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3781 with error to read needle meta with id 905390423 from volume 3781 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 116 with error to read needle meta with id 24071811 from volume 116 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3948 with error to read needle meta with id 991219813 from volume 3948 with error rpc error: code = Unknown desc = index out of range 2395f1aa186b04743 /buckets/1231221212/coupon_upload_pic.jpg volume not found 4198,569e229b5bdfe310 /buckets/androidBuild/master.zip volume not found 4198,569e22be4a505c35 /buckets/androidBuild/master.zip volume not found 4198,569e22edd66a2a90 /buckets/androidBuild/master.zip volume not found 4197,569e232647b74956 /buckets/androidBuild/master.zip volume not found 4197,569e2335b61c7c62 /buckets/androidBuild/master.zip volume not found 4049,46ad0940b1fcc945 /buckets/go/date.log volume not found   A lot of volumes can't be found",source-file,"volume and filer data mismatch **Describe the bug** E0106 18:57:53.688989 reader_at.go:147 fetching chunk &{FileId:4247,5d91ed630532c810 Offset:0 Size:7119 LogicOffset:0 ChunkSize:7119 CipherKey:[] IsGzipped:true}: http://10.17.100.30:8081/4247,5d91ed630532c810?readDeleted=true: 404 Not Found My cluster seems to be missing a lot of filesIs it possible to fix it Why did this error occur? `volume.fsck` looks dangerousI don't know how to use it safely. @chrislusf @kmlebedev **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - weed -logdir=/export/logs/seaweedfs/log/master2 master -mdir=/export/data/seaweedfs/master/mdir2 -peers=10.17.100.27:9333,10.17.100.29:9333,10.17.100.30:9333 -port=9333 -volumeSizeLimitMB=5000 -defaultReplication=001 -metricsPort=1234 -electionTimeout=3s - weed -logdir=/export/logs/seaweedfs/log/volume2 volume -dir=/export/data/seaweedfs/volume/data2 -dataCenter=ihuman-datacenter -rack=ihuman-rack1 -max=2000 -mserver=10.17.100.27:9333,10.17.100.29:9333,10.17.100.30:9333 -port=8081 -metricsPort=1236 - weed -logdir=/export/logs/seaweedfs/log/filer filer -master=10.17.100.27:9333,10.17.100.29:9333,10.17.100.30:9333 -port=8888 -metricsPort=1235 -disableDirListing=true - OS version - output of `weed version` version 30GB 3.34 linux amd64 - if using filer, show the content of `filer.toml` use mysql **Expected behavior** A clear and concise description of what you expected to happen. **Additional context**  > volume.fsck -findMissingChunksInFiler Failed to search for last valid index on volume 3594 with error to read needle meta with id 559593113 from volume 3594 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 136 with error to read needle meta with id 24070706 from volume 136 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3920 with error to read needle meta with id 1003664128 from volume 3920 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 24 with error to read needle meta with id 24060775 from volume 24 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3196 with error to read needle meta with id 28262524 from volume 3196 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3484 with error to read needle meta with id 0 from volume 3484 with error rpc error: code = Unknown desc = panic occurred: runtime error: slice bounds out of range [:19] with capacity 16 Failed to search for last valid index on volume 47 with error to read needle meta with id 61469970 from volume 47 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3829 with error to read needle meta with id 838563609 from volume 3829 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3389 with error to read needle meta with id 319189011 from volume 3389 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3592 with error to read needle meta with id 745925603 from volume 3592 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3915 with error to read needle meta with id 1003689513 from volume 3915 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3174 with error to read needle meta with id 52457224 from volume 3174 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 134 with error to read needle meta with id 24070697 from volume 134 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3173 with error to read needle meta with id 52457496 from volume 3173 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3194 with error to read needle meta with id 28263309 from volume 3194 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 120 with error to read needle meta with id 24071760 from volume 120 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 46 with error to read needle meta with id 61412043 from volume 46 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 23 with error to read needle meta with id 24068890 from volume 23 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3919 with error to read needle meta with id 1003641892 from volume 3919 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3277 with error to read needle meta with id 62978653 from volume 3277 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 20 with error to read needle meta with id 24053021 from volume 20 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3468 with error to read needle meta with id 747685956 from volume 3468 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 119 with error to read needle meta with id 24079718 from volume 119 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 135 with error to read needle meta with id 24070713 from volume 135 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3102 with error to read needle meta with id 732280017 from volume 3102 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3199 with error to read needle meta with id 28260854 from volume 3199 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 271 with error to read needle meta with id 24103496 from volume 271 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 115 with error to read needle meta with id 24071812 from volume 115 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3918 with error to read needle meta with id 1003664941 from volume 3918 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 118 with error to read needle meta with id 24079712 from volume 118 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3464 with error to read needle meta with id 847887517 from volume 3464 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3170 with error to read needle meta with id 52457325 from volume 3170 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3596 with error to read needle meta with id 897246367 from volume 3596 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3916 with error to read needle meta with id 1003664888 from volume 3916 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3555 with error to read needle meta with id 1064035495 from volume 3555 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 137 with error to read needle meta with id 24070695 from volume 137 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3948 with error to read needle meta with id 991219813 from volume 3948 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3386 with error to read needle meta with id 279227918 from volume 3386 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3430 with error to read needle meta with id 838702791 from volume 3430 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 116 with error to read needle meta with id 24071811 from volume 116 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3171 with error to read needle meta with id 52457406 from volume 3171 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3428 with error to read needle meta with id 899399493 from volume 3428 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3270 with error to read needle meta with id 345861650 from volume 3270 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3387 with error to read needle meta with id 290956173 from volume 3387 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 274 with error to read needle meta with id 24103512 from volume 274 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3388 with error to read needle meta with id 319189001 from volume 3388 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3427 with error to read needle meta with id 426841619 from volume 3427 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3269 with error to read needle meta with id 357107148 from volume 3269 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 21 with error to read needle meta with id 24066909 from volume 21 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 111 with error to read needle meta with id 24069582 from volume 111 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3385 with error to read needle meta with id 280524485 from volume 3385 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3596 with error to read needle meta with id 897159628 from volume 3596 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3595 with error to read needle meta with id 354093485 from volume 3595 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3554 with error to read needle meta with id 1065286842 from volume 3554 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 272 with error to read needle meta with id 24103526 from volume 272 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3592 with error to read needle meta with id 899927738 from volume 3592 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 117 with error to read needle meta with id 24071788 from volume 117 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3277 with error to read needle meta with id 62978653 from volume 3277 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3197 with error to read needle meta with id 28263207 from volume 3197 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3195 with error to read needle meta with id 28260506 from volume 3195 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3198 with error to read needle meta with id 28260379 from volume 3198 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3266 with error to read needle meta with id 345731882 from volume 3266 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3945 with error to read needle meta with id 992329923 from volume 3945 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 270 with error to read needle meta with id 24103516 from volume 270 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 138 with error to read needle meta with id 24071732 from volume 138 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3555 with error to read needle meta with id 1054866792 from volume 3555 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 269 with error to read needle meta with id 24103513 from volume 269 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3594 with error to read needle meta with id 864605294 from volume 3594 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3196 with error to read needle meta with id 28262524 from volume 3196 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3465 with error to read needle meta with id 847734979 from volume 3465 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3427 with error to read needle meta with id 426841619 from volume 3427 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 118 with error to read needle meta with id 24079712 from volume 118 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3917 with error to read needle meta with id 1003552725 from volume 3917 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3186 with error to read needle meta with id 1065285866 from volume 3186 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3915 with error to read needle meta with id 1003689513 from volume 3915 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3170 with error to read needle meta with id 52457325 from volume 3170 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 43 with error to read needle meta with id 61470221 from volume 43 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 48 with error to read needle meta with id 61469780 from volume 48 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 44 with error to read needle meta with id 28145882 from volume 44 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 273 with error to read needle meta with id 24103528 from volume 273 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3551 with error to read needle meta with id 1065287110 from volume 3551 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3553 with error to read needle meta with id 1063875149 from volume 3553 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 271 with error to read needle meta with id 24103496 from volume 271 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3781 with error to read needle meta with id 905390423 from volume 3781 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 19 with error to read needle meta with id 24060748 from volume 19 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 133 with error to read needle meta with id 24071727 from volume 133 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3387 with error to read needle meta with id 290956173 from volume 3387 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3187 with error to read needle meta with id 1054742100 from volume 3187 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3829 with error to read needle meta with id 838563609 from volume 3829 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3920 with error to read needle meta with id 1003664128 from volume 3920 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3783 with error to read needle meta with id 991859259 from volume 3783 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3191 with error to read needle meta with id 407461431 from volume 3191 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3919 with error to read needle meta with id 1003641892 from volume 3919 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3552 with error to read needle meta with id 1064035719 from volume 3552 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 137 with error to read needle meta with id 24070695 from volume 137 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3199 with error to read needle meta with id 28260854 from volume 3199 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 45 with error to read needle meta with id 61411704 from volume 45 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3916 with error to read needle meta with id 1003664888 from volume 3916 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3464 with error to read needle meta with id 847887517 from volume 3464 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3437 with error to read needle meta with id 899389303 from volume 3437 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 119 with error to read needle meta with id 24079718 from volume 119 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3190 with error to read needle meta with id 407461272 from volume 3190 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3269 with error to read needle meta with id 357107148 from volume 3269 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 134 with error to read needle meta with id 24070697 from volume 134 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 22 with error to read needle meta with id 24068892 from volume 22 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 4444 with error to read needle meta with id 1712633163 from volume 4444 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3175 with error to read needle meta with id 52457144 from volume 3175 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 111 with error to read needle meta with id 24069582 from volume 111 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3943 with error to read needle meta with id 978863811 from volume 3943 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 20 with error to read needle meta with id 24053021 from volume 20 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3182 with error to read needle meta with id 1054866270 from volume 3182 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3268 with error to read needle meta with id 357097589 from volume 3268 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 23 with error to read needle meta with id 24068890 from volume 23 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3102 with error to read needle meta with id 732280017 from volume 3102 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 45 with error to read needle meta with id 61411704 from volume 45 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3270 with error to read needle meta with id 345861650 from volume 3270 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 48 with error to read needle meta with id 61469780 from volume 48 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 22 with error to read needle meta with id 24068892 from volume 22 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3187 with error to read needle meta with id 1054742100 from volume 3187 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3197 with error to read needle meta with id 28263207 from volume 3197 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3468 with error to read needle meta with id 747685956 from volume 3468 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3437 with error to read needle meta with id 899389303 from volume 3437 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3173 with error to read needle meta with id 52457496 from volume 3173 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3385 with error to read needle meta with id 280524485 from volume 3385 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3182 with error to read needle meta with id 1054866270 from volume 3182 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 43 with error to read needle meta with id 61470221 from volume 43 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3465 with error to read needle meta with id 847734979 from volume 3465 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3595 with error to read needle meta with id 899330853 from volume 3595 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 120 with error to read needle meta with id 24071760 from volume 120 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3190 with error to read needle meta with id 28029738 from volume 3190 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 46 with error to read needle meta with id 61412043 from volume 46 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3783 with error to read needle meta with id 991859259 from volume 3783 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3945 with error to read needle meta with id 992329923 from volume 3945 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3918 with error to read needle meta with id 1003664941 from volume 3918 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3198 with error to read needle meta with id 28260379 from volume 3198 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 117 with error to read needle meta with id 24071788 from volume 117 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 47 with error to read needle meta with id 61469970 from volume 47 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3195 with error to read needle meta with id 28260506 from volume 3195 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 136 with error to read needle meta with id 24070706 from volume 136 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 273 with error to read needle meta with id 24103528 from volume 273 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3386 with error to read needle meta with id 279227918 from volume 3386 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3552 with error to read needle meta with id 1065286875 from volume 3552 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 24 with error to read needle meta with id 24060775 from volume 24 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 272 with error to read needle meta with id 24103526 from volume 272 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3388 with error to read needle meta with id 319189001 from volume 3388 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 133 with error to read needle meta with id 24071727 from volume 133 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 269 with error to read needle meta with id 24103513 from volume 269 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3943 with error to read needle meta with id 978863811 from volume 3943 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3268 with error to read needle meta with id 357097589 from volume 3268 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3191 with error to read needle meta with id 28029877 from volume 3191 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3428 with error to read needle meta with id 899399493 from volume 3428 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 270 with error to read needle meta with id 24103516 from volume 270 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3266 with error to read needle meta with id 345731882 from volume 3266 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3171 with error to read needle meta with id 52457406 from volume 3171 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 135 with error to read needle meta with id 24070713 from volume 135 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 44 with error to read needle meta with id 28145882 from volume 44 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3174 with error to read needle meta with id 52457224 from volume 3174 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 274 with error to read needle meta with id 24103512 from volume 274 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3186 with error to read needle meta with id 1065285866 from volume 3186 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3917 with error to read needle meta with id 1003552725 from volume 3917 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 138 with error to read needle meta with id 24071732 from volume 138 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 19 with error to read needle meta with id 24060748 from volume 19 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3389 with error to read needle meta with id 319189011 from volume 3389 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3194 with error to read needle meta with id 28260281 from volume 3194 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3430 with error to read needle meta with id 838702791 from volume 3430 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 21 with error to read needle meta with id 24066909 from volume 21 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3175 with error to read needle meta with id 52457144 from volume 3175 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3781 with error to read needle meta with id 905390423 from volume 3781 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 116 with error to read needle meta with id 24071811 from volume 116 with error rpc error: code = Unknown desc = index out of range 2 Failed to search for last valid index on volume 3948 with error to read needle meta with id 991219813 from volume 3948 with error rpc error: code = Unknown desc = index out of range 2395f1aa186b04743 /buckets/1231221212/coupon_upload_pic.jpg volume not found 4198,569e229b5bdfe310 /buckets/androidBuild/master.zip volume not found 4198,569e22be4a505c35 /buckets/androidBuild/master.zip volume not found 4198,569e22edd66a2a90 /buckets/androidBuild/master.zip volume not found 4197,569e232647b74956 /buckets/androidBuild/master.zip volume not found 4197,569e2335b61c7c62 /buckets/androidBuild/master.zip volume not found 4049,46ad0940b1fcc945 /buckets/go/date.log volume not found   A lot of volumes can't be found source-file",no-bug,0.8
5155,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5155,s3api v3.60: Missing VersionConfiguration node in get-bucket-versioning response,"Feature introduced in: https://github.com/seaweedfs/seaweedfs/pull/4998 **Describe the bug** When using aws-cli get-bucket-versioning will return no results; this is due to the malformed response. When running with debug, we can see that the response body is missing the VersionConfiguration node.  aws --endpoint-url http://localhost:8333 s3api get-bucket-versioning --bucket mybucket --debug  2024-01-03 01:11:43,611 - MainThread - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:8333 2024-01-03 01:11:43,618 - MainThread - urllib3.connectionpool - DEBUG - http://localhost:8333 ""GET /mybucket?versioning HTTP/1.1"" 200 26 2024-01-03 01:11:43,619 - MainThread - botocore.parsers - DEBUG - Response headers: {'Accept-Ranges': 'bytes', 'Content-Length': '26', 'Content-Type': 'application/xml', 'Server': 'SeaweedFS S3', 'X-Amz-Request-Id': '1704244303617654225' , 'Date': 'Wed, 03 Jan 2024 01:11:43 GMT'} 2024-01-03 01:11:43,619 - MainThread - botocore.parsers - DEBUG - Response body: b'<Status>Suspended</Status>'   **System Setup** - running seaweedfs:3.60_large_disk container image - command: weed server -s3 -iam - `# weed version: version 8000GB 3.60 d4e91b6ad linux amd64` **Expected behavior** Default response **""Status"":""Suspended""**:  aws --endpoint-url http://localhost:8333 s3api get-bucket-versioning --bucket mybucket { ""Status"": ""Suspended"" } ",source-file | source-file | source-file,"s3api v3.60: Missing VersionConfiguration node in get-bucket-versioning response Feature introduced in: https://github.com/seaweedfs/seaweedfs/pull/4998 **Describe the bug** When using aws-cli get-bucket-versioning will return no results; this is due to the malformed response. When running with debug, we can see that the response body is missing the VersionConfiguration node.  aws --endpoint-url http://localhost:8333 s3api get-bucket-versioning --bucket mybucket --debug  2024-01-03 01:11:43,611 - MainThread - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:8333 2024-01-03 01:11:43,618 - MainThread - urllib3.connectionpool - DEBUG - http://localhost:8333 ""GET /mybucket?versioning HTTP/1.1"" 200 26 2024-01-03 01:11:43,619 - MainThread - botocore.parsers - DEBUG - Response headers: {'Accept-Ranges': 'bytes', 'Content-Length': '26', 'Content-Type': 'application/xml', 'Server': 'SeaweedFS S3', 'X-Amz-Request-Id': '1704244303617654225' , 'Date': 'Wed, 03 Jan 2024 01:11:43 GMT'} 2024-01-03 01:11:43,619 - MainThread - botocore.parsers - DEBUG - Response body: b'<Status>Suspended</Status>'   **System Setup** - running seaweedfs:3.60_large_disk container image - command: weed server -s3 -iam - `# weed version: version 8000GB 3.60 d4e91b6ad linux amd64` **Expected behavior** Default response **""Status"":""Suspended""**:  aws --endpoint-url http://localhost:8333 s3api get-bucket-versioning --bucket mybucket { ""Status"": ""Suspended"" }  source-file source-file source-file",bug,0.95
603,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/603,filer.copy error with weed filer setup with redis&cassandra,"## Question I setup seaweedfs filer with cassandra, I can upload file to seaweedfs by command curl ,but when I use **filer.copy** to upload lots of files , I got errors, see bellow. I got the same result when using redis. **test with curl** shell # curl -F ""file=@/etc/resolv.conf"" ""http://10.110.200.37:8888/abc/def/"" {""name"":""resolv.conf"",""size"":74,""fid"":""2,3d185d9b1b"",""url"":""http://10.110.200.175:9080/2,3d185  **test with filer.copy** BTW when I use the id (2,3e6e533926) from command filer.copy, seaweedfs cluster got file actually. shell # weed filer.copy -master 10.110.200.175:9333 /root/ceph-cluster http://10.110.200.37:8888/1011020037/etc/ Failed to register file /root/ceph-cluster/ceph-deploy-ceph.log on 10.110.200.37:8888: Failed to register path:/1011020037/etc/ceph-cluster/ceph-deploy-ceph.log on filer:10.110.200.37:8888 to file id:2,3e6e533926 Example: weed filer.copy file_or_dir1 [file_or_dir2 file_or_dir3] http://localhost:8888/path/to/a/folder/ Default Usage: -collection string optional collection name  [root@ceph-adm ~]# curl http://10.110.200.175:9333/2,3e6e533926 <a href=""http://10.110.200.177:9080/2,3e6e533926"">Moved Permanently</a>. [root@ceph-adm ~]# curl http://10.110.200.175:9333/**2,3e6e533926** -L [2017-03-04 14:34:42,315][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf [2017-03-04 14:34:42,316][ceph_deploy.cli][INFO ] Invoked (1.5.37): /usr/bin/ceph-deploy new ceph-mon1.skyinno.com ceph-mon2.skyinno.com ceph-mon3.skyinno.com [2017-03-04 14:34:42,316][ceph_deploy.cli][INFO ] ceph-deploy options: [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] username : None [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] func : <function new at 0x1422410> [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] verbose : False [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] overwrite_conf : False [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] quiet : False   ## version OS: centos7 latest seaweedfs: 0.76 cassandra: 3.11.1 redis: 3.2.1 ## Setup **seaweedfs cluster** - node1 10.110.200.175 shell # /usr/bin/weed -log_dir=/weed/master/log master -defaultReplication=020 -port=9333 -mdir=/weed/master/mdir -ip=10.110.200.175 # /usr/bin/weed -log_dir=/weed/volume1/log volume -port=9080 -dir=/weed/volume1/dir -mserver=10.110.200.175:9333 -ip=10.110.200.175 -dataCenter=dc1 -rack=rack1  - node2 10.110.200.176 shell # /usr/bin/weed -log_dir=/weed/master/log master -defaultReplication=020 -port=9333 -mdir=/weed/master/mdir -ip=10.110.200.176 -peers=10.110.200.175:9333 # /usr/bin/weed -log_dir=/weed/volume1/log volume -port=9080 -dir=/weed/volume1/dir -mserver=10.110.200.175:9333 -ip=10.110.200.176 -dataCenter=dc1 -rack=rack2  - node3 10.110.200.177 shell # /usr/bin/weed -log_dir=/weed/master/log master -defaultReplication=020 -port=9333 -mdir=/weed/master/mdir -ip=10.110.200.177 -peers=10.110.200.175:9333 # /usr/bin/weed -log_dir=/weed/volume1/log volume -port=9080 -dir=/weed/volume1/dir -mserver=10.110.200.175:9333 -ip=10.110.200.177 -dataCenter=dc1 -rack=rack3  **cassandra** follow this https://www.howtoforge.com/tutorial/how-to-install-apache-cassandra-on-centos-7/ **filer** - filer 10.110.200.37 shell # weed -log_dir=/weed/filer/log filer -dir=/weed/filer/dir -master=10.110.200.175:9333 -ip=10.110.200.37 -port=8888 -defaultReplicaPlacement=020 -cassandra.server=127.0.0.1 ",source-file,"filer.copy error with weed filer setup with redis&cassandra ## Question I setup seaweedfs filer with cassandra, I can upload file to seaweedfs by command curl ,but when I use **filer.copy** to upload lots of files , I got errors, see bellow. I got the same result when using redis. **test with curl** shell # curl -F ""file=@/etc/resolv.conf"" ""http://10.110.200.37:8888/abc/def/"" {""name"":""resolv.conf"",""size"":74,""fid"":""2,3d185d9b1b"",""url"":""http://10.110.200.175:9080/2,3d185  **test with filer.copy** BTW when I use the id (2,3e6e533926) from command filer.copy, seaweedfs cluster got file actually. shell # weed filer.copy -master 10.110.200.175:9333 /root/ceph-cluster http://10.110.200.37:8888/1011020037/etc/ Failed to register file /root/ceph-cluster/ceph-deploy-ceph.log on 10.110.200.37:8888: Failed to register path:/1011020037/etc/ceph-cluster/ceph-deploy-ceph.log on filer:10.110.200.37:8888 to file id:2,3e6e533926 Example: weed filer.copy file_or_dir1 [file_or_dir2 file_or_dir3] http://localhost:8888/path/to/a/folder/ Default Usage: -collection string optional collection name  [root@ceph-adm ~]# curl http://10.110.200.175:9333/2,3e6e533926 <a href=""http://10.110.200.177:9080/2,3e6e533926"">Moved Permanently</a>. [root@ceph-adm ~]# curl http://10.110.200.175:9333/**2,3e6e533926** -L [2017-03-04 14:34:42,315][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf [2017-03-04 14:34:42,316][ceph_deploy.cli][INFO ] Invoked (1.5.37): /usr/bin/ceph-deploy new ceph-mon1.skyinno.com ceph-mon2.skyinno.com ceph-mon3.skyinno.com [2017-03-04 14:34:42,316][ceph_deploy.cli][INFO ] ceph-deploy options: [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] username : None [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] func : <function new at 0x1422410> [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] verbose : False [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] overwrite_conf : False [2017-03-04 14:34:42,317][ceph_deploy.cli][INFO ] quiet : False   ## version OS: centos7 latest seaweedfs: 0.76 cassandra: 3.11.1 redis: 3.2.1 ## Setup **seaweedfs cluster** - node1 10.110.200.175 shell # /usr/bin/weed -log_dir=/weed/master/log master -defaultReplication=020 -port=9333 -mdir=/weed/master/mdir -ip=10.110.200.175 # /usr/bin/weed -log_dir=/weed/volume1/log volume -port=9080 -dir=/weed/volume1/dir -mserver=10.110.200.175:9333 -ip=10.110.200.175 -dataCenter=dc1 -rack=rack1  - node2 10.110.200.176 shell # /usr/bin/weed -log_dir=/weed/master/log master -defaultReplication=020 -port=9333 -mdir=/weed/master/mdir -ip=10.110.200.176 -peers=10.110.200.175:9333 # /usr/bin/weed -log_dir=/weed/volume1/log volume -port=9080 -dir=/weed/volume1/dir -mserver=10.110.200.175:9333 -ip=10.110.200.176 -dataCenter=dc1 -rack=rack2  - node3 10.110.200.177 shell # /usr/bin/weed -log_dir=/weed/master/log master -defaultReplication=020 -port=9333 -mdir=/weed/master/mdir -ip=10.110.200.177 -peers=10.110.200.175:9333 # /usr/bin/weed -log_dir=/weed/volume1/log volume -port=9080 -dir=/weed/volume1/dir -mserver=10.110.200.175:9333 -ip=10.110.200.177 -dataCenter=dc1 -rack=rack3  **cassandra** follow this https://www.howtoforge.com/tutorial/how-to-install-apache-cassandra-on-centos-7/ **filer** - filer 10.110.200.37 shell # weed -log_dir=/weed/filer/log filer -dir=/weed/filer/dir -master=10.110.200.175:9333 -ip=10.110.200.37 -port=8888 -defaultReplicaPlacement=020 -cassandra.server=127.0.0.1  source-file",no-bug,0.8
3457,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3457,weedfs-3.22 S3 reports a directory as a file,"**Describe the bug** we run weedfs to set up an S3 service, used by Aapche Flink, replace the former Minio. when upgrade to weedfs-3.22, flink jobmanager start up fail, and report s3://flink/recovery/flink/blob is a file  But actually It is a directory. ![image](https://user-images.githubusercontent.com/3582423/185061458-661565ff-9b70-4df9-a762-06798b574bf8.png) Roll back to weedfs-3.19, everything is OK `Caused by: org.apache.hadoop.fs.FileAlreadyExistsException: Path is a file: s3://flink/recovery/flink/blob at org.apache.hadoop.fs.s3a.S3AFileSystem.innerMkdirs(S3AFileSystem.java:2042) ~[?:?] at org.apache.hadoop.fs.s3a.S3AFileSystem.mkdirs(S3AFileSystem.java:2007) ~[?:?] at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275) ~[hadoop-common-3.3.4.jar:?] at org.apache.flink.fs.s3hadoop.common.HadoopFileSystem.mkdirs(HadoopFileSystem.java:183) ~[?:?] at org.apache.flink.core.fs.PluginFileSystemFactory$ClassLoaderFixingFileSystem.mkdirs(PluginFileSystemFactory.java:162) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.blob.FileSystemBlobStore.<init>(FileSystemBlobStore.java:64) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.blob.BlobUtils.createFileSystemBlobStore(BlobUtils.java:98) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.blob.BlobUtils.createBlobStoreFromConfig(BlobUtils.java:76) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.highavailability.HighAvailabilityServicesUtils.createHighAvailabilityServices(HighAvailabilityServicesUtils.java:115) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.createHaServices(ClusterEntrypoint.java:338) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.initializeServices(ClusterEntrypoint.java:296) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.runCluster(ClusterEntrypoint.java:224) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.lambda$startCluster$1(ClusterEntrypoint.java:178) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at java.security.AccessController.doPrivileged(Native Method) ~[?:?] at javax.security.auth.Subject.doAs(Unknown Source) ~[?:?] at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-common-3.3.4.jar:?] at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.startCluster(ClusterEntrypoint.java:175) ~[flink-dist_2.11-1.12.4.jar:1.12.4]  2 more` **System Setup** Linux CentOS 7 weedfs version 30GB 3.22 fa4d0093e17f710c3da00545022646cb96a6fd98 linux amd64 weed -v 1 server -volume.port 38080 -dir=/data/seaweedfs/data -s3 -s3.config /data/seaweedfs/config.json",source-file | source-file | source-file | source-file | source-file | source-file,"weedfs-3.22 S3 reports a directory as a file **Describe the bug** we run weedfs to set up an S3 service, used by Aapche Flink, replace the former Minio. when upgrade to weedfs-3.22, flink jobmanager start up fail, and report s3://flink/recovery/flink/blob is a file  But actually It is a directory. ![image](https://user-images.githubusercontent.com/3582423/185061458-661565ff-9b70-4df9-a762-06798b574bf8.png) Roll back to weedfs-3.19, everything is OK `Caused by: org.apache.hadoop.fs.FileAlreadyExistsException: Path is a file: s3://flink/recovery/flink/blob at org.apache.hadoop.fs.s3a.S3AFileSystem.innerMkdirs(S3AFileSystem.java:2042) ~[?:?] at org.apache.hadoop.fs.s3a.S3AFileSystem.mkdirs(S3AFileSystem.java:2007) ~[?:?] at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275) ~[hadoop-common-3.3.4.jar:?] at org.apache.flink.fs.s3hadoop.common.HadoopFileSystem.mkdirs(HadoopFileSystem.java:183) ~[?:?] at org.apache.flink.core.fs.PluginFileSystemFactory$ClassLoaderFixingFileSystem.mkdirs(PluginFileSystemFactory.java:162) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.blob.FileSystemBlobStore.<init>(FileSystemBlobStore.java:64) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.blob.BlobUtils.createFileSystemBlobStore(BlobUtils.java:98) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.blob.BlobUtils.createBlobStoreFromConfig(BlobUtils.java:76) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.highavailability.HighAvailabilityServicesUtils.createHighAvailabilityServices(HighAvailabilityServicesUtils.java:115) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.createHaServices(ClusterEntrypoint.java:338) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.initializeServices(ClusterEntrypoint.java:296) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.runCluster(ClusterEntrypoint.java:224) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.lambda$startCluster$1(ClusterEntrypoint.java:178) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at java.security.AccessController.doPrivileged(Native Method) ~[?:?] at javax.security.auth.Subject.doAs(Unknown Source) ~[?:?] at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-common-3.3.4.jar:?] at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) ~[flink-dist_2.11-1.12.4.jar:1.12.4] at org.apache.flink.runtime.entrypoint.ClusterEntrypoint.startCluster(ClusterEntrypoint.java:175) ~[flink-dist_2.11-1.12.4.jar:1.12.4]  2 more` **System Setup** Linux CentOS 7 weedfs version 30GB 3.22 fa4d0093e17f710c3da00545022646cb96a6fd98 linux amd64 weed -v 1 server -volume.port 38080 -dir=/data/seaweedfs/data -s3 -s3.config /data/seaweedfs/config.json source-file source-file source-file source-file source-file source-file",no-bug,0.8
1942,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1942,[server] set GOMAXPROCS from environment,"For Go 1.5, we propose to change the default to the number of CPUs available. GOMAXPROCS sets the maximum number of CPUs that can be executing simultaneously and returns the previous setting. **It defaults to the value of runtime.NumCPU**. If n < 1, it does not change the current setting. This call will go away when the scheduler improves. https://golang.org/pkg/runtime/#GOMAXPROCS",source-file | source-file | source-file,"[server] set GOMAXPROCS from environment For Go 1.5, we propose to change the default to the number of CPUs available. GOMAXPROCS sets the maximum number of CPUs that can be executing simultaneously and returns the previous setting. **It defaults to the value of runtime.NumCPU**. If n < 1, it does not change the current setting. This call will go away when the scheduler improves. https://golang.org/pkg/runtime/#GOMAXPROCS source-file source-file source-file",no-bug,0.95
2593,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2593,"When ""X-Amz-Copy-Source"" a folder, weed create a new file with ""Filer listing Html"" result.","The response of ""CopyObject"" should be 40x.",source-file,"When ""X-Amz-Copy-Source"" a folder, weed create a new file with ""Filer listing Html"" result. The response of ""CopyObject"" should be 40x. source-file",bug,0.9
814,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/814,Seaweedfs client core dump when calling DeleteFiles,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** When seaweedfs client calls DeleteFiles (e.g. fileId=123,xxx, volume 123 not exist), it ALWAYS crashes. **Screenshots** goroutine 89 [running]: github.com/chrislusf/seaweedfs/weed/operation.DeleteFilesWithLookupVolumeId(0xc42061d578, 0x1, 0x1, 0xc4206a4160, 0x20, 0x20, 0xc4206a4140, 0x7fbfd979d1e0, 0x0) github.com/chrislusf/seaweedfs/weed/operation/delete_content.go:74 +0xce9 github.com/chrislusf/seaweedfs/weed/operation.DeleteFiles(0xc420286090, 0xe, 0xc42061d578, 0x1, 0x1, 0xc42061d538, 0x4126c8, 0x20, 0x9b9ca0, 0x725201) github.com/chrislusf/seaweedfs/weed/operation/delete_content.go:36 +0x8a",source-file,"Seaweedfs client core dump when calling DeleteFiles Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** When seaweedfs client calls DeleteFiles (e.g. fileId=123,xxx, volume 123 not exist), it ALWAYS crashes. **Screenshots** goroutine 89 [running]: github.com/chrislusf/seaweedfs/weed/operation.DeleteFilesWithLookupVolumeId(0xc42061d578, 0x1, 0x1, 0xc4206a4160, 0x20, 0x20, 0xc4206a4140, 0x7fbfd979d1e0, 0x0) github.com/chrislusf/seaweedfs/weed/operation/delete_content.go:74 +0xce9 github.com/chrislusf/seaweedfs/weed/operation.DeleteFiles(0xc420286090, 0xe, 0xc42061d578, 0x1, 0x1, 0xc42061d538, 0x4126c8, 0x20, 0x9b9ca0, 0x725201) github.com/chrislusf/seaweedfs/weed/operation/delete_content.go:36 +0x8a source-file",bug,0.9
4256,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4256,local-replicate-compose.yml doesn't seem to work,"**Describe the bug**  cd docker/compose/; docker-compose -f local-replicate-compose.yml up  doesn't seem to work after creating the swexchange and swqueue and the binding exchange to queue in rabbit. First issue is to access s3 container an additional command line option is needed '-ip.bind=0.0.0.0'. When creating s3 objects rabbit never seems to be called. Standing up replicate while the other containers are running doesn't seem to do anything  docker-compose -f local-replicate-compose.yml up replicate Attaching to compose-replicate-1 compose-replicate-1 | I0227 22:58:43.034388 config.go:46 Reading : Config File ""security"" Not Found in ""[/data /root/.seaweedfs /usr/local/etc/seaweedfs /etc/seaweedfs]"" compose-replicate-1 | I0227 22:58:43.037443 config.go:59 Reading replication.toml from /etc/seaweedfs/replication.toml compose-replicate-1 | I0227 22:58:43.038275 config.go:59 Reading notification.toml from /etc/seaweedfs/notification.toml compose-replicate-1 | No notification is defined in notification.toml file. compose-replicate-1 | Please follow 'weed scaffold -config=notification' to see example notification configurations. compose-replicate-1 exited with code 0  **System Setup** MacOS M1 cpu **Expected behavior** I expect rabbit to have queue count information to go up and replication to populate the /data folder",other-file | other-file,"local-replicate-compose.yml doesn't seem to work **Describe the bug**  cd docker/compose/; docker-compose -f local-replicate-compose.yml up  doesn't seem to work after creating the swexchange and swqueue and the binding exchange to queue in rabbit. First issue is to access s3 container an additional command line option is needed '-ip.bind=0.0.0.0'. When creating s3 objects rabbit never seems to be called. Standing up replicate while the other containers are running doesn't seem to do anything  docker-compose -f local-replicate-compose.yml up replicate Attaching to compose-replicate-1 compose-replicate-1 | I0227 22:58:43.034388 config.go:46 Reading : Config File ""security"" Not Found in ""[/data /root/.seaweedfs /usr/local/etc/seaweedfs /etc/seaweedfs]"" compose-replicate-1 | I0227 22:58:43.037443 config.go:59 Reading replication.toml from /etc/seaweedfs/replication.toml compose-replicate-1 | I0227 22:58:43.038275 config.go:59 Reading notification.toml from /etc/seaweedfs/notification.toml compose-replicate-1 | No notification is defined in notification.toml file. compose-replicate-1 | Please follow 'weed scaffold -config=notification' to see example notification configurations. compose-replicate-1 exited with code 0  **System Setup** MacOS M1 cpu **Expected behavior** I expect rabbit to have queue count information to go up and replication to populate the /data folder other-file other-file",no-bug,0.9
650,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/650,preallocate volume is deleted by grpc,"In master log, preallocated volume is deleted immediately. I0515 11:37:54 07428 volume_growth.go:205] Created Volume 720954 on topo:kr:DefaultRack:adata01.nova.nfra.io:8080 I0515 11:37:54 07428 data_node.go:58] Deleting volume id: 720954 I0515 11:37:54 07428 topology.go:133] removing volume info:Id:720954, Size:0, ReplicaPlacement:001, Collection:, Version:2, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false I guess new volume is deleted by heartbeat. Before processing previous heartbeat( new volume information is not included ), new volume is assigned. So, master server deletes new volume. How can I handle this?",source-file,"preallocate volume is deleted by grpc In master log, preallocated volume is deleted immediately. I0515 11:37:54 07428 volume_growth.go:205] Created Volume 720954 on topo:kr:DefaultRack:adata01.nova.nfra.io:8080 I0515 11:37:54 07428 data_node.go:58] Deleting volume id: 720954 I0515 11:37:54 07428 topology.go:133] removing volume info:Id:720954, Size:0, ReplicaPlacement:001, Collection:, Version:2, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false I guess new volume is deleted by heartbeat. Before processing previous heartbeat( new volume information is not included ), new volume is assigned. So, master server deletes new volume. How can I handle this? source-file",no-bug,0.9
4337,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4337,Touch()'ing a file should update its last modified time,"**Describe the bug** While copying a file ""over itself"" via the S3 protocol, I discovered that SeaweedFS didn't update its last modified time. **Expected behavior** The last modified time should be be updated, just like the regular `touch` shell command. I am not really familiar with the SeaweedFS codebase, but a quick try with the following change seemed to work: golang // weed/pb/filer_pb/filer_client.go func Touch(filerClient FilerClient, parentDirectoryPath string, entryName string, entry *Entry) (err error) { return filerClient.WithFilerClient(false, func(client SeaweedFilerClient) error { entry.Attributes.Mtime = time.Now().Unix() // < update mtime to current time request := &UpdateEntryRequest{ Directory: parentDirectoryPath, Entry: entry, } ",source-file,"Touch()'ing a file should update its last modified time **Describe the bug** While copying a file ""over itself"" via the S3 protocol, I discovered that SeaweedFS didn't update its last modified time. **Expected behavior** The last modified time should be be updated, just like the regular `touch` shell command. I am not really familiar with the SeaweedFS codebase, but a quick try with the following change seemed to work: golang // weed/pb/filer_pb/filer_client.go func Touch(filerClient FilerClient, parentDirectoryPath string, entryName string, entry *Entry) (err error) { return filerClient.WithFilerClient(false, func(client SeaweedFilerClient) error { entry.Attributes.Mtime = time.Now().Unix() // < update mtime to current time request := &UpdateEntryRequest{ Directory: parentDirectoryPath, Entry: entry, }  source-file",no-bug,0.9
1382,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1382,fuse,192.168.10.11seaweedfs1.451.84fuse  ![image](https://user-images.githubusercontent.com/23493734/86690763-cdb44100-c03a-11ea-8c8e-6a5691b2cc9c.png) 192.168.10.10seweedfsfuse  ![image](https://user-images.githubusercontent.com/23493734/86691316-4adfb600-c03b-11ea-95ef-e521d46cbff4.png)  1110seaweed aaa.jpg  ![image](https://user-images.githubusercontent.com/23493734/86692150-18828880-c03c-11ea-9cc2-d3d25efe2fd6.png) ![image](https://user-images.githubusercontent.com/23493734/86692249-2cc68580-c03c-11ea-92da-bfa551307faf.png) 192.168.10.10  ![image](https://user-images.githubusercontent.com/23493734/86692352-4667cd00-c03c-11ea-95cd-c9ce699834ec.png)   ![image](https://user-images.githubusercontent.com/23493734/86692847-bc6c3400-c03c-11ea-9969-42818478ca30.png) 112e ![image](https://user-images.githubusercontent.com/23493734/86693659-6fd52880-c03d-11ea-8397-02bc35e5b586.png) 10.10 ![image](https://user-images.githubusercontent.com/23493734/86693766-8bd8ca00-c03d-11ea-8919-2c04ef45de29.png) ,source-file,fuse 192.168.10.11seaweedfs1.451.84fuse  ![image](https://user-images.githubusercontent.com/23493734/86690763-cdb44100-c03a-11ea-8c8e-6a5691b2cc9c.png) 192.168.10.10seweedfsfuse  ![image](https://user-images.githubusercontent.com/23493734/86691316-4adfb600-c03b-11ea-95ef-e521d46cbff4.png)  1110seaweed aaa.jpg  ![image](https://user-images.githubusercontent.com/23493734/86692150-18828880-c03c-11ea-9cc2-d3d25efe2fd6.png) ![image](https://user-images.githubusercontent.com/23493734/86692249-2cc68580-c03c-11ea-92da-bfa551307faf.png) 192.168.10.10  ![image](https://user-images.githubusercontent.com/23493734/86692352-4667cd00-c03c-11ea-95cd-c9ce699834ec.png)   ![image](https://user-images.githubusercontent.com/23493734/86692847-bc6c3400-c03c-11ea-9969-42818478ca30.png) 112e ![image](https://user-images.githubusercontent.com/23493734/86693659-6fd52880-c03d-11ea-8397-02bc35e5b586.png) 10.10 ![image](https://user-images.githubusercontent.com/23493734/86693766-8bd8ca00-c03d-11ea-8919-2c04ef45de29.png)  source-file,no-bug,0.9
2084,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2084,Filer.backup does not work as expected,"I am trying to test a backup to local disk (both on Windows and Linux) of files that are stored with Filer (MySQL), but it doesn't seem to work properly - it just doesn't copy all the files, only specific files and folders, not even full sizes. Maybe it's just getting stuck for whatever reason? I also tried to change the directory on Filer in replication.toml, but it does no effect. It also makes two folders of different dates, but I've configured it to ""is_incremental = false"". **System Setup** Weed cluster is started with Docker compose ([Docker.zip](https://github.com/chrislusf/seaweedfs/files/6539293/Docker.zip); it contains filer.toml as well). OS version: - Windows 10 Pro 20H2 19042.985 - Linux mx 4.19.0-6-amd64 #1 SMP Debian 4.19.67-2+deb10u2 (2019-11-11) x86_64 GNU/Linux Weed version: - version 30GB 2.49 42fb03a windows amd64 - version 30GB 2.49 42fb03a linux amd64 FIler.backup start command: .\weed.exe filer.backup -filerProxy Replication.toml: [replication(.toml).txt](https://github.com/chrislusf/seaweedfs/files/6539325/replication.toml.txt) **Expected behavior** A full copy of files stored with Filer on a local disk. **Screenshots** Filer ![image](https://user-images.githubusercontent.com/17049504/119495375-05b79600-bd6b-11eb-8124-c9ba3110f943.png) ![image](https://user-images.githubusercontent.com/17049504/119495436-149e4880-bd6b-11eb-843e-b161daf55197.png) ![image](https://user-images.githubusercontent.com/17049504/119495607-40213300-bd6b-11eb-8b7d-95344f34aa38.png) ![image](https://user-images.githubusercontent.com/17049504/119495679-50d1a900-bd6b-11eb-82d5-3d3dd8c7ab3e.png) ![image](https://user-images.githubusercontent.com/17049504/119495646-4a433180-bd6b-11eb-8cfe-e41270d528e6.png) Windows backup ![image](https://user-images.githubusercontent.com/17049504/119496680-672c3480-bd6c-11eb-838c-cb50fe294259.png) ![image](https://user-images.githubusercontent.com/17049504/119496471-321fe200-bd6c-11eb-8fdc-3b4a324e4fed.png) ![image](https://user-images.githubusercontent.com/17049504/119496503-38ae5980-bd6c-11eb-9f14-a25a5854abb0.png) ![image](https://user-images.githubusercontent.com/17049504/119496530-3fd56780-bd6c-11eb-91c0-b4d3d1f268a2.png) ![image](https://user-images.githubusercontent.com/17049504/119496563-47950c00-bd6c-11eb-90b1-7ae249db9c59.png) ![image](https://user-images.githubusercontent.com/17049504/119496648-5f6c9000-bd6c-11eb-9357-a33eca5a581e.png) Linux backup Same picture as on Windows. **Additional context** File.backup output from Windows: [win filer.backup log.txt](https://github.com/chrislusf/seaweedfs/files/6539218/win.filer.backup.log.txt). File.backup output from Linux: [linux filer.backup log.txt](https://github.com/chrislusf/seaweedfs/files/6539249/linux.filer.backup.log.txt).",source-file | source-file | source-file | source-file,"Filer.backup does not work as expected I am trying to test a backup to local disk (both on Windows and Linux) of files that are stored with Filer (MySQL), but it doesn't seem to work properly - it just doesn't copy all the files, only specific files and folders, not even full sizes. Maybe it's just getting stuck for whatever reason? I also tried to change the directory on Filer in replication.toml, but it does no effect. It also makes two folders of different dates, but I've configured it to ""is_incremental = false"". **System Setup** Weed cluster is started with Docker compose ([Docker.zip](https://github.com/chrislusf/seaweedfs/files/6539293/Docker.zip); it contains filer.toml as well). OS version: - Windows 10 Pro 20H2 19042.985 - Linux mx 4.19.0-6-amd64 #1 SMP Debian 4.19.67-2+deb10u2 (2019-11-11) x86_64 GNU/Linux Weed version: - version 30GB 2.49 42fb03a windows amd64 - version 30GB 2.49 42fb03a linux amd64 FIler.backup start command: .\weed.exe filer.backup -filerProxy Replication.toml: [replication(.toml).txt](https://github.com/chrislusf/seaweedfs/files/6539325/replication.toml.txt) **Expected behavior** A full copy of files stored with Filer on a local disk. **Screenshots** Filer ![image](https://user-images.githubusercontent.com/17049504/119495375-05b79600-bd6b-11eb-8124-c9ba3110f943.png) ![image](https://user-images.githubusercontent.com/17049504/119495436-149e4880-bd6b-11eb-843e-b161daf55197.png) ![image](https://user-images.githubusercontent.com/17049504/119495607-40213300-bd6b-11eb-8b7d-95344f34aa38.png) ![image](https://user-images.githubusercontent.com/17049504/119495679-50d1a900-bd6b-11eb-82d5-3d3dd8c7ab3e.png) ![image](https://user-images.githubusercontent.com/17049504/119495646-4a433180-bd6b-11eb-8cfe-e41270d528e6.png) Windows backup ![image](https://user-images.githubusercontent.com/17049504/119496680-672c3480-bd6c-11eb-838c-cb50fe294259.png) ![image](https://user-images.githubusercontent.com/17049504/119496471-321fe200-bd6c-11eb-8fdc-3b4a324e4fed.png) ![image](https://user-images.githubusercontent.com/17049504/119496503-38ae5980-bd6c-11eb-9f14-a25a5854abb0.png) ![image](https://user-images.githubusercontent.com/17049504/119496530-3fd56780-bd6c-11eb-91c0-b4d3d1f268a2.png) ![image](https://user-images.githubusercontent.com/17049504/119496563-47950c00-bd6c-11eb-90b1-7ae249db9c59.png) ![image](https://user-images.githubusercontent.com/17049504/119496648-5f6c9000-bd6c-11eb-9357-a33eca5a581e.png) Linux backup Same picture as on Windows. **Additional context** File.backup output from Windows: [win filer.backup log.txt](https://github.com/chrislusf/seaweedfs/files/6539218/win.filer.backup.log.txt). File.backup output from Linux: [linux filer.backup log.txt](https://github.com/chrislusf/seaweedfs/files/6539249/linux.filer.backup.log.txt). source-file source-file source-file source-file",no-bug,0.9
2001,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2001,Possible data loss on migration between tiers.,"**Describe the bug** While playing with migrations I had several abrupt terminations of the migrations process because of volume servers' timeouts. Seems like at least a couple of times the volume was actually copied to a new tier, but because of the terminated migration, originals where left intact on the previous tier. After several reboots of the volume servers, some of my volumes eventually had 3 replicas, instead of 2 as of 010 policy. When I tried to do a migration next time, I got this:  moving volume 6384 from 192.168.65.59:8080 to 192.168.65.57:8080 with disk type hdd  markVolumeReadonly 6384 on 192.168.65.63:8080  markVolumeReadonly 6384 on 192.168.65.62:8080  markVolumeReadonly 6384 on 192.168.65.59:8080  2021/04/14 01:51:58 copying volume 6384 from 192.168.65.59:8080 to 192.168.65.57:8080 2021/04/14 01:53:00 tailing volume 6384 from 192.168.65.59:8080 to 192.168.65.57:8080 2021/04/14 01:53:12 deleting volume 6384 from 192.168.65.59:8080 2021/04/14 01:53:13 moved volume 6384 from 192.168.65.59:8080 to 192.168.65.57:8080  The problem is, `192.168.65.59` and `192.168.65.57` are HDD tier servers, while `192.168.65.63` and `192.168.65.62` are from SSD tier. The end result is that volume 6384 was just deleted from everywhere, without any single copy left! **System Setup** - OS version: Debian 10.9 - output of `weed version`: version 30GB 2.39 742ab1e linux amd64 - if using filer, show the content of `filer.toml`  [leveldb2] # local on disk, mostly for simple single-machine setup, fairly scalable # faster than previous leveldb, recommended. enabled = true dir = ""/var/lib/weed/filer"" # directory to store level db files ",source-file,"Possible data loss on migration between tiers. **Describe the bug** While playing with migrations I had several abrupt terminations of the migrations process because of volume servers' timeouts. Seems like at least a couple of times the volume was actually copied to a new tier, but because of the terminated migration, originals where left intact on the previous tier. After several reboots of the volume servers, some of my volumes eventually had 3 replicas, instead of 2 as of 010 policy. When I tried to do a migration next time, I got this:  moving volume 6384 from 192.168.65.59:8080 to 192.168.65.57:8080 with disk type hdd  markVolumeReadonly 6384 on 192.168.65.63:8080  markVolumeReadonly 6384 on 192.168.65.62:8080  markVolumeReadonly 6384 on 192.168.65.59:8080  2021/04/14 01:51:58 copying volume 6384 from 192.168.65.59:8080 to 192.168.65.57:8080 2021/04/14 01:53:00 tailing volume 6384 from 192.168.65.59:8080 to 192.168.65.57:8080 2021/04/14 01:53:12 deleting volume 6384 from 192.168.65.59:8080 2021/04/14 01:53:13 moved volume 6384 from 192.168.65.59:8080 to 192.168.65.57:8080  The problem is, `192.168.65.59` and `192.168.65.57` are HDD tier servers, while `192.168.65.63` and `192.168.65.62` are from SSD tier. The end result is that volume 6384 was just deleted from everywhere, without any single copy left! **System Setup** - OS version: Debian 10.9 - output of `weed version`: version 30GB 2.39 742ab1e linux amd64 - if using filer, show the content of `filer.toml`  [leveldb2] # local on disk, mostly for simple single-machine setup, fairly scalable # faster than previous leveldb, recommended. enabled = true dir = ""/var/lib/weed/filer"" # directory to store level db files  source-file",no-bug,0.9
1983,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1983,"""lock"" command would hang out the shell for using ""volume.fix.replication""","Hi, I've 5 volume servers with 3 disk and 8TB each of them Last night I format one 8 TB disk and use volume.fix.replication to repair deleted volumes, it worked good for repairing half of the volumes but after that it started to show following error and exited the shell continuously when I commit volume.fix.replication:  error: copying from weed-volume-005.s02.test.local:8080 => weed-volume-002.s02.test.local:8080 : rpc error: code = Unknown desc = failed to copy /srv/node/sdb/Group_40_208.dat file: receiving /srv/node/sdb/Group_40_208.dat: rpc error: code = Unknown desc = read /srv/node/sdd/Group_40_208.dat: input/output error  I entered again volume.fix.replication but it shows error and exit from shell again:  error: copying from weed-volume-005.s02.test.local:8080 => weed-volume-002.s02.test.local:8080 : rpc error: code = Unknown desc = failed to copy /srv/node/sdb/User_10_124.dat file: receiving /srv/node/sdb/User_10_124.dat: rpc error: code = Unknown desc = read /srv/node/sdd/User_10_124.dat: input/output error  today when I wanted to repair it again it couldn't lock the shell and it waits for lock command without donig anything: ![image](https://user-images.githubusercontent.com/43205944/114296403-81fa6080-9ac0-11eb-9b98-e5d27340b483.png) I restart all masters but still it is not working What should I do?",other-file | source-file | source-file | source-file | source-file,"""lock"" command would hang out the shell for using ""volume.fix.replication"" Hi, I've 5 volume servers with 3 disk and 8TB each of them Last night I format one 8 TB disk and use volume.fix.replication to repair deleted volumes, it worked good for repairing half of the volumes but after that it started to show following error and exited the shell continuously when I commit volume.fix.replication:  error: copying from weed-volume-005.s02.test.local:8080 => weed-volume-002.s02.test.local:8080 : rpc error: code = Unknown desc = failed to copy /srv/node/sdb/Group_40_208.dat file: receiving /srv/node/sdb/Group_40_208.dat: rpc error: code = Unknown desc = read /srv/node/sdd/Group_40_208.dat: input/output error  I entered again volume.fix.replication but it shows error and exit from shell again:  error: copying from weed-volume-005.s02.test.local:8080 => weed-volume-002.s02.test.local:8080 : rpc error: code = Unknown desc = failed to copy /srv/node/sdb/User_10_124.dat file: receiving /srv/node/sdb/User_10_124.dat: rpc error: code = Unknown desc = read /srv/node/sdd/User_10_124.dat: input/output error  today when I wanted to repair it again it couldn't lock the shell and it waits for lock command without donig anything: ![image](https://user-images.githubusercontent.com/43205944/114296403-81fa6080-9ac0-11eb-9b98-e5d27340b483.png) I restart all masters but still it is not working What should I do? other-file source-file source-file source-file source-file",no-bug,0.9
2262,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2262,The Filer service not resizing image,**Describe the bug** The Filer service not resize image if the file extension isn't lowercase. Ex: http://localhost:8888/images/foo.PNG?width=200&height=100 **Expected behavior** The image should be resized **Additional context** I found that the **ext** parameter not has been lowercased before passing it to **shouldResizeImages** function: https://github.com/chrislusf/seaweedfs/blob/8109594c6e01bc5a9b412e105f003a325858a1fc/weed/server/filer_server_handlers_read.go#L145,source-file,The Filer service not resizing image **Describe the bug** The Filer service not resize image if the file extension isn't lowercase. Ex: http://localhost:8888/images/foo.PNG?width=200&height=100 **Expected behavior** The image should be resized **Additional context** I found that the **ext** parameter not has been lowercased before passing it to **shouldResizeImages** function: https://github.com/chrislusf/seaweedfs/blob/8109594c6e01bc5a9b412e105f003a325858a1fc/weed/server/filer_server_handlers_read.go#L145 source-file,no-bug,0.9
5412,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5412,git clone into fuse mount fails with `inflate: data stream error`,"**Describe the bug** A `git clone` of large remote repositories into a SeaweedFS FUSE mount reliably fails with this error:  error: inflate: data stream error (unknown compression method) fatal: serious inflate inconsistency  Here are a few repos I've found that fail: - https://gitlab.gnome.org/GNOME/glib.git - https://github.com/u-boot/u-boot.git - git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - `weed server -dir=/srv/data/weedvol -master.port=9333 -volume.port=8080 -master.volumeSizeLimitMB=4096 -s3 -filer=true -volume.minFreeSpace=10 -volume.max=0` - `weed mount -filer=weedserver:8888 -dir=/home/satwell/mnt/tmp -filer.path=/` - OS version: Debian 12 on both server and client - output of `weed version`: `version 30GB 3.64 b74e8082bac408138be99e128b8c28fd19eca7a6 linux amd64` - if using filer, show the content of `filer.toml`  [filer.options] recursive_delete = false [leveldb2] enabled = true dir = ""/srv/data/filerldb2""  **Expected behavior** Expected `git clone` to complete successfully. This works fine for smaller git repos that I've tried cloning. **Screenshots** Full git command and output:  halo:~/mnt/tmp% git clone --bare https://gitlab.gnome.org/GNOME/glib.git Cloning into bare repository 'glib.git' remote: Enumerating objects: 211140, done. remote: Counting objects: 100% (2144/2144), done. remote: Compressing objects: 100% (271/271), done. remote: Total 211140 (delta 1941), reused 2064 (delta 1873), pack-reused 208996 Receiving objects: 100% (211140/211140), 92.15 MiB | 6.06 MiB/s, done. error: inflate: data stream error (unknown compression method) fatal: serious inflate inconsistency error: inflate: data stream error (unknown compression method) error: inflate: data stream error (unknown compression method) fatal: fetch-pack: invalid index-pack output ",source-file | source-file | source-file | source-file,"git clone into fuse mount fails with `inflate: data stream error` **Describe the bug** A `git clone` of large remote repositories into a SeaweedFS FUSE mount reliably fails with this error:  error: inflate: data stream error (unknown compression method) fatal: serious inflate inconsistency  Here are a few repos I've found that fail: - https://gitlab.gnome.org/GNOME/glib.git - https://github.com/u-boot/u-boot.git - git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - `weed server -dir=/srv/data/weedvol -master.port=9333 -volume.port=8080 -master.volumeSizeLimitMB=4096 -s3 -filer=true -volume.minFreeSpace=10 -volume.max=0` - `weed mount -filer=weedserver:8888 -dir=/home/satwell/mnt/tmp -filer.path=/` - OS version: Debian 12 on both server and client - output of `weed version`: `version 30GB 3.64 b74e8082bac408138be99e128b8c28fd19eca7a6 linux amd64` - if using filer, show the content of `filer.toml`  [filer.options] recursive_delete = false [leveldb2] enabled = true dir = ""/srv/data/filerldb2""  **Expected behavior** Expected `git clone` to complete successfully. This works fine for smaller git repos that I've tried cloning. **Screenshots** Full git command and output:  halo:~/mnt/tmp% git clone --bare https://gitlab.gnome.org/GNOME/glib.git Cloning into bare repository 'glib.git' remote: Enumerating objects: 211140, done. remote: Counting objects: 100% (2144/2144), done. remote: Compressing objects: 100% (271/271), done. remote: Total 211140 (delta 1941), reused 2064 (delta 1873), pack-reused 208996 Receiving objects: 100% (211140/211140), 92.15 MiB | 6.06 MiB/s, done. error: inflate: data stream error (unknown compression method) fatal: serious inflate inconsistency error: inflate: data stream error (unknown compression method) error: inflate: data stream error (unknown compression method) fatal: fetch-pack: invalid index-pack output  source-file source-file source-file source-file",no-bug,0.9
2177,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2177,Volume on ARMv7 throws,"**Describe the bug** Volume on ARM32 throws an ""unaligned 64-bit atomic operation"" error on upload of a file **System Setup** - /usr/bin/weed volume -ip=odroid3.node.dc1.consul -port=9444 -mserver=seaweedfsmaster0.service.dc1.consul:9333,seaweedfsmaster1.service.dc1.consul:9333,seaweedfsmaster2.service.dc1.consul:9333 -dir=/data/vol - OS version = Ubuntu 5.4.118-221 armv7l armv7l armv7l GNU/Linux - `weed version' = version 30GB 2.56 a2979aa linux arm - hardware = Odroid HC1 (Samsung Exynos5422 Cortex-A15 2Ghz and Cortex-A7 Octa cores) **Expected behavior** Not to crash **Additional context** 2021/07/02 15:46:52 http: panic serving 192.168.1.238:40226: unaligned 64-bit atomic operation goroutine 101 [running]: net/http.(*conn).serve.func1(0x32244e0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:1824 +0x104 panic(0x171c1b8, 0x1e1dca8) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/panic.go:971 +0x4b4 runtime/internal/atomic.panicUnaligned() /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/internal/atomic/unaligned.go:8 +0x24 runtime/internal/atomic.Load64(0x31473e4, 0xe5b38, 0x0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/internal/atomic/asm_arm.s:263 +0x14 github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler(0x3147380, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/volume_server_handlers.go:49 +0x4bc net/http.HandlerFunc.ServeHTTP(0x300fa88, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2069 +0x34 net/http.(*ServeMux).ServeHTTP(0x325b440, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2448 +0x16c net/http.serverHandler.ServeHTTP(0x30ec360, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2887 +0x88 net/http.(*conn).serve(0x32244e0, 0x1e59564, 0x31c09c0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:1952 +0x7f0 created by net/http.(*Server).Serve /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:3013 +0x318",source-file,"Volume on ARMv7 throws **Describe the bug** Volume on ARM32 throws an ""unaligned 64-bit atomic operation"" error on upload of a file **System Setup** - /usr/bin/weed volume -ip=odroid3.node.dc1.consul -port=9444 -mserver=seaweedfsmaster0.service.dc1.consul:9333,seaweedfsmaster1.service.dc1.consul:9333,seaweedfsmaster2.service.dc1.consul:9333 -dir=/data/vol - OS version = Ubuntu 5.4.118-221 armv7l armv7l armv7l GNU/Linux - `weed version' = version 30GB 2.56 a2979aa linux arm - hardware = Odroid HC1 (Samsung Exynos5422 Cortex-A15 2Ghz and Cortex-A7 Octa cores) **Expected behavior** Not to crash **Additional context** 2021/07/02 15:46:52 http: panic serving 192.168.1.238:40226: unaligned 64-bit atomic operation goroutine 101 [running]: net/http.(*conn).serve.func1(0x32244e0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:1824 +0x104 panic(0x171c1b8, 0x1e1dca8) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/panic.go:971 +0x4b4 runtime/internal/atomic.panicUnaligned() /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/internal/atomic/unaligned.go:8 +0x24 runtime/internal/atomic.Load64(0x31473e4, 0xe5b38, 0x0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/internal/atomic/asm_arm.s:263 +0x14 github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler(0x3147380, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/volume_server_handlers.go:49 +0x4bc net/http.HandlerFunc.ServeHTTP(0x300fa88, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2069 +0x34 net/http.(*ServeMux).ServeHTTP(0x325b440, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2448 +0x16c net/http.serverHandler.ServeHTTP(0x30ec360, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2887 +0x88 net/http.(*conn).serve(0x32244e0, 0x1e59564, 0x31c09c0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:1952 +0x7f0 created by net/http.(*Server).Serve /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:3013 +0x318 source-file",bug,0.9
1808,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1808,Jwt issue - wrong jwt,"**Describe the bug** Getting wrong jwt code from master.  C:\Users\lennie>curl -i ""http://172.16.100.1:9351/dir/lookup?volumeId=1,18ee7f3466&read=yes"" HTTP/1.1 200 OK Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTI0NDN9.AxGUN17e_RZ5g4tSZLFWfzqnIuYQqxDCMBPTxvnFpdk Content-Type: application/json Date: Tue, 16 Feb 2021 21:52:03 GMT Content-Length: 90 {""volumeId"":""1"",""locations"":[{""url"":""172.16.100.1:9831"",""publicUrl"":""172.16.100.1:9831""}]}  And then volume query.  C:\Users\lennie>curl -i ""http://172.16.100.1:9831/1,18ee7f3466"" -H ""Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTI0NDN9.AxGUN17e_RZ5g4tSZLFWfzqnIuYQqxDCMBPTxvnFpdk"" HTTP/1.1 401 Unauthorized Content-Type: application/json Server: SeaweedFS Volume 30GB 2.26 Date: Tue, 16 Feb 2021 21:52:27 GMT Content-Length: 21 {""error"":""wrong jwt""}  I Have read issue https://github.com/chrislusf/seaweedfs/issues/1399 But i only have one server and the time is correct on the system. When i do some request to the master to get the jwt token i can se this.  curl -i ""http://172.16.100.1:9351/dir/lookup?volumeId=1,18ee7f3466&read=yes""  Jwt response.  Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MTN9.VfbCVHEhBMHMxWZrTpzOTYSU8DqWtKGs5_vaopdLiwY Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MTd9.9yPL3dNuW3J4p68KARMWIAp_XlqDYkAN-NHHnYUrY4Q Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MjB9.crUaZYFBCEDu57dOKAE-rJPw5nS-fpJP11Oz6Bv0Pok Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MjF9.mRJQ0WtXu5JNfPAKIGiJP0CGrodiM_i8tOws9H7PRdA  There should not be underscore or dash in the base64 encoded values? So the question is. Why do I get underscores? I am running: OS: Ubuntu 18.04.4 LTS And weed version : version 30GB 2.26 b9b5b932 linux amd64 The Master is starting whit this command.  weed master -mdir=""/home/raid6/seaweed/mastershare"" -ip=""172.16.100.1"" -ip.bind=""172.16.100.1"" -port=9351  Log  I0216 22:42:56 19422 file_util.go:23] Folder /home/raid6/seaweed/mastershare Permission: -rwxr-xr-x I0216 22:42:56 19422 master.go:168] current: 172.16.100.1:9351 peers: I0216 22:42:56 19422 master_server.go:107] Volume Size Limit is 30000 MB I0216 22:42:56 19422 master_server.go:192] adminScripts: I0216 22:42:56 19422 master.go:122] Start Seaweed Master 30GB 2.26 b9b5b932 at 172.16.100.1:9351 I0216 22:42:56 19422 raft_server.go:70] Starting RaftServer with 172.16.100.1:9351 I0216 22:42:56 19422 raft_server.go:129] current cluster leader: I0216 22:42:56 19422 master.go:146] Start Seaweed Master 30GB 2.26 b9b5b932 grpc server at 172.16.100.1:19351 I0216 22:42:57 19422 masterclient.go:78] No existing leader found! I0216 22:42:57 19422 raft_server.go:154] Initializing new cluster I0216 22:42:57 19422 master_server.go:141] leader change event: => 172.16.100.1:9351 I0216 22:42:57 19422 master_server.go:143] [ 172.16.100.1:9351 ] 172.16.100.1:9351 becomes leader. I0216 22:43:00 19422 master_grpc_server.go:252] + client filer@172.16.100.1:8888 I0216 22:43:01 19422 masterclient.go:126] redirected to leader 172.16.100.1:9351 I0216 22:43:01 19422 master_grpc_server.go:252] + client master@172.16.100.1:37496 I0216 22:43:04 19422 node.go:322] topo adds child soder I0216 22:43:04 19422 node.go:322] topo:soder adds child r1u1 I0216 22:43:04 19422 node.go:322] topo:soder:r1u1 adds child 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:71] added volume server 172.16.100.1:9831 I0216 22:43:04 19422 volume_layout.go:354] Volume 13 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 10 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 8 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 7 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 6 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 3 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 1 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 11 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 2 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 12 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 5 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 4 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 9 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 14 becomes writable I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 13 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 10 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 8 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 7 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 6 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 3 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 1 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 11 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 2 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 12 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 5 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 4 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 9 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 14 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:157] master send to filer@172.16.100.1:8888: url:""172.16.100.1:9831"" public_url:""172.16.100.1:9831"" new_vids:13 new_vids:10 new_vids:8 new_vids:7 new_vids:6 new_vids:3 new_vids:1 new_vids:11 new_vids:2 new_vids:12 new_vids:5 new_vids:4 new_vids:9 new_vids:14 data_center:""soder"" I0216 22:43:04 19422 master_grpc_server.go:157] master send to master@172.16.100.1:37496: url:""172.16.100.1:9831"" public_url:""172.16.100.1:9831"" new_vids:13 new_vids:10 new_vids:8 new_vids:7 new_vids:6 new_vids:3 new_vids:1 new_vids:11 new_vids:2 new_vids:12 new_vids:5 new_vids:4 new_vids:9 new_vids:14 data_center:""soder""  The volume is starting whit this command.  root@spinky:/home/raid6/seaweed# weed volume -max=100 -ip=""172.16.100.1"" -ip.bind=""172.16.100.1"" -port=9831 -mserver=""172.16.100.1:9351"" -dir=""/home/raid6/seaweed/voltesting"" -dataCenter=""soder"" -rack=""r1u1""  Log  I0216 22:25:09 9983 file_util.go:23] Folder /home/raid6/seaweed/voltesting Permission: -rwxr-xr-x I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/2.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_12.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/5.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/3.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/1.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/7.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/6.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/4.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/2.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/3.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_10.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/7.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_12.dat, replicaPlacement=000 v=3 size=1864 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_13.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_11.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_8.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_14.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/4.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_9.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/1.dat, replicaPlacement=000 v=3 size=112 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/5.dat, replicaPlacement=000 v=3 size=104 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/6.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_10.dat, replicaPlacement=000 v=3 size=7900832 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_13.dat, replicaPlacement=000 v=3 size=720 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_9.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_11.dat, replicaPlacement=000 v=3 size=664 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_8.dat, replicaPlacement=000 v=3 size=1600 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_14.dat, replicaPlacement=000 v=3 size=30789912 ttl= I0216 22:25:09 9983 disk_location.go:175] Store started on dir: /home/raid6/seaweed/voltesting with 14 volumes max 100 I0216 22:25:09 9983 disk_location.go:178] Store started on dir: /home/raid6/seaweed/voltesting with 0 ec shards I0216 22:25:09 9983 volume_grpc_client_to_master.go:52] Volume server start with seed master nodes: [172.16.100.1:9351] I0216 22:25:09 9983 volume.go:351] Start Seaweed volume server 30GB 2.26 b9b5b932 at 172.16.100.1:9831 I0216 22:25:09 9983 volume_grpc_client_to_master.go:114] Heartbeat to: 172.16.100.1:9351  This is the Log in volume when wrong jwt  I0216 22:27:26 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:27:27 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:28:32 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:28:34 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""}  Security.toml file syntax:  # Put this file to one of the location, with descending priority # ./security.toml # $HOME/.seaweedfs/security.toml # /etc/seaweedfs/security.toml # this file is read by master, volume server, and filer # the jwt signing key is read by master and volume server. # a jwt defaults to expire after 10 seconds. [jwt.signing] key = ""NotShownToThePublic"" expires_after_seconds = 120 # seconds 10 default # jwt for read is only supported with master+volume setup. Filer does not support this mode. [jwt.signing.read] key = ""NotShownToThePublic"" expires_after_seconds = 120 # seconds # volume server also uses grpc that should be secured. # all grpc tls authentications are mutual # the values for the following ca, cert, and key are paths to the PERM files. # the host name is not checked, so the PERM files can be shared. [grpc] ca = ""/home/certstrap/certstrap/out/smtCertAuth.crt"" [grpc.volume] cert = ""/home/certstrap/certstrap/out/volume01.crt"" key = ""/home/certstrap/certstrap/out/volume01.key"" [grpc.master] cert = ""/home/certstrap/certstrap/out/master01.crt"" key = ""/home/certstrap/certstrap/out/master01.key"" [grpc.filer] cert = ""/home/certstrap/certstrap/out/filer01.crt"" key = ""/home/certstrap/certstrap/out/filer01.key"" # use this for any place needs a grpc client # i.e., ""weed backup|benchmark|filer.copy|filer.replicate|mount|s3|upload"" [grpc.client] cert = ""/home/certstrap/certstrap/out/client01.crt"" key = ""/home/certstrap/certstrap/out/client01.key""  If I turn of the security (jwt). The server is working perfect. I can save, show, delete object",source-file,"Jwt issue - wrong jwt **Describe the bug** Getting wrong jwt code from master.  C:\Users\lennie>curl -i ""http://172.16.100.1:9351/dir/lookup?volumeId=1,18ee7f3466&read=yes"" HTTP/1.1 200 OK Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTI0NDN9.AxGUN17e_RZ5g4tSZLFWfzqnIuYQqxDCMBPTxvnFpdk Content-Type: application/json Date: Tue, 16 Feb 2021 21:52:03 GMT Content-Length: 90 {""volumeId"":""1"",""locations"":[{""url"":""172.16.100.1:9831"",""publicUrl"":""172.16.100.1:9831""}]}  And then volume query.  C:\Users\lennie>curl -i ""http://172.16.100.1:9831/1,18ee7f3466"" -H ""Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTI0NDN9.AxGUN17e_RZ5g4tSZLFWfzqnIuYQqxDCMBPTxvnFpdk"" HTTP/1.1 401 Unauthorized Content-Type: application/json Server: SeaweedFS Volume 30GB 2.26 Date: Tue, 16 Feb 2021 21:52:27 GMT Content-Length: 21 {""error"":""wrong jwt""}  I Have read issue https://github.com/chrislusf/seaweedfs/issues/1399 But i only have one server and the time is correct on the system. When i do some request to the master to get the jwt token i can se this.  curl -i ""http://172.16.100.1:9351/dir/lookup?volumeId=1,18ee7f3466&read=yes""  Jwt response.  Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MTN9.VfbCVHEhBMHMxWZrTpzOTYSU8DqWtKGs5_vaopdLiwY Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MTd9.9yPL3dNuW3J4p68KARMWIAp_XlqDYkAN-NHHnYUrY4Q Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MjB9.crUaZYFBCEDu57dOKAE-rJPw5nS-fpJP11Oz6Bv0Pok Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MjF9.mRJQ0WtXu5JNfPAKIGiJP0CGrodiM_i8tOws9H7PRdA  There should not be underscore or dash in the base64 encoded values? So the question is. Why do I get underscores? I am running: OS: Ubuntu 18.04.4 LTS And weed version : version 30GB 2.26 b9b5b932 linux amd64 The Master is starting whit this command.  weed master -mdir=""/home/raid6/seaweed/mastershare"" -ip=""172.16.100.1"" -ip.bind=""172.16.100.1"" -port=9351  Log  I0216 22:42:56 19422 file_util.go:23] Folder /home/raid6/seaweed/mastershare Permission: -rwxr-xr-x I0216 22:42:56 19422 master.go:168] current: 172.16.100.1:9351 peers: I0216 22:42:56 19422 master_server.go:107] Volume Size Limit is 30000 MB I0216 22:42:56 19422 master_server.go:192] adminScripts: I0216 22:42:56 19422 master.go:122] Start Seaweed Master 30GB 2.26 b9b5b932 at 172.16.100.1:9351 I0216 22:42:56 19422 raft_server.go:70] Starting RaftServer with 172.16.100.1:9351 I0216 22:42:56 19422 raft_server.go:129] current cluster leader: I0216 22:42:56 19422 master.go:146] Start Seaweed Master 30GB 2.26 b9b5b932 grpc server at 172.16.100.1:19351 I0216 22:42:57 19422 masterclient.go:78] No existing leader found! I0216 22:42:57 19422 raft_server.go:154] Initializing new cluster I0216 22:42:57 19422 master_server.go:141] leader change event: => 172.16.100.1:9351 I0216 22:42:57 19422 master_server.go:143] [ 172.16.100.1:9351 ] 172.16.100.1:9351 becomes leader. I0216 22:43:00 19422 master_grpc_server.go:252] + client filer@172.16.100.1:8888 I0216 22:43:01 19422 masterclient.go:126] redirected to leader 172.16.100.1:9351 I0216 22:43:01 19422 master_grpc_server.go:252] + client master@172.16.100.1:37496 I0216 22:43:04 19422 node.go:322] topo adds child soder I0216 22:43:04 19422 node.go:322] topo:soder adds child r1u1 I0216 22:43:04 19422 node.go:322] topo:soder:r1u1 adds child 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:71] added volume server 172.16.100.1:9831 I0216 22:43:04 19422 volume_layout.go:354] Volume 13 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 10 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 8 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 7 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 6 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 3 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 1 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 11 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 2 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 12 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 5 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 4 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 9 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 14 becomes writable I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 13 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 10 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 8 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 7 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 6 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 3 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 1 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 11 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 2 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 12 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 5 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 4 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 9 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 14 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:157] master send to filer@172.16.100.1:8888: url:""172.16.100.1:9831"" public_url:""172.16.100.1:9831"" new_vids:13 new_vids:10 new_vids:8 new_vids:7 new_vids:6 new_vids:3 new_vids:1 new_vids:11 new_vids:2 new_vids:12 new_vids:5 new_vids:4 new_vids:9 new_vids:14 data_center:""soder"" I0216 22:43:04 19422 master_grpc_server.go:157] master send to master@172.16.100.1:37496: url:""172.16.100.1:9831"" public_url:""172.16.100.1:9831"" new_vids:13 new_vids:10 new_vids:8 new_vids:7 new_vids:6 new_vids:3 new_vids:1 new_vids:11 new_vids:2 new_vids:12 new_vids:5 new_vids:4 new_vids:9 new_vids:14 data_center:""soder""  The volume is starting whit this command.  root@spinky:/home/raid6/seaweed# weed volume -max=100 -ip=""172.16.100.1"" -ip.bind=""172.16.100.1"" -port=9831 -mserver=""172.16.100.1:9351"" -dir=""/home/raid6/seaweed/voltesting"" -dataCenter=""soder"" -rack=""r1u1""  Log  I0216 22:25:09 9983 file_util.go:23] Folder /home/raid6/seaweed/voltesting Permission: -rwxr-xr-x I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/2.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_12.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/5.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/3.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/1.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/7.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/6.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/4.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/2.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/3.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_10.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/7.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_12.dat, replicaPlacement=000 v=3 size=1864 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_13.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_11.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_8.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_14.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/4.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_9.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/1.dat, replicaPlacement=000 v=3 size=112 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/5.dat, replicaPlacement=000 v=3 size=104 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/6.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_10.dat, replicaPlacement=000 v=3 size=7900832 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_13.dat, replicaPlacement=000 v=3 size=720 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_9.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_11.dat, replicaPlacement=000 v=3 size=664 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_8.dat, replicaPlacement=000 v=3 size=1600 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_14.dat, replicaPlacement=000 v=3 size=30789912 ttl= I0216 22:25:09 9983 disk_location.go:175] Store started on dir: /home/raid6/seaweed/voltesting with 14 volumes max 100 I0216 22:25:09 9983 disk_location.go:178] Store started on dir: /home/raid6/seaweed/voltesting with 0 ec shards I0216 22:25:09 9983 volume_grpc_client_to_master.go:52] Volume server start with seed master nodes: [172.16.100.1:9351] I0216 22:25:09 9983 volume.go:351] Start Seaweed volume server 30GB 2.26 b9b5b932 at 172.16.100.1:9831 I0216 22:25:09 9983 volume_grpc_client_to_master.go:114] Heartbeat to: 172.16.100.1:9351  This is the Log in volume when wrong jwt  I0216 22:27:26 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:27:27 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:28:32 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:28:34 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""}  Security.toml file syntax:  # Put this file to one of the location, with descending priority # ./security.toml # $HOME/.seaweedfs/security.toml # /etc/seaweedfs/security.toml # this file is read by master, volume server, and filer # the jwt signing key is read by master and volume server. # a jwt defaults to expire after 10 seconds. [jwt.signing] key = ""NotShownToThePublic"" expires_after_seconds = 120 # seconds 10 default # jwt for read is only supported with master+volume setup. Filer does not support this mode. [jwt.signing.read] key = ""NotShownToThePublic"" expires_after_seconds = 120 # seconds # volume server also uses grpc that should be secured. # all grpc tls authentications are mutual # the values for the following ca, cert, and key are paths to the PERM files. # the host name is not checked, so the PERM files can be shared. [grpc] ca = ""/home/certstrap/certstrap/out/smtCertAuth.crt"" [grpc.volume] cert = ""/home/certstrap/certstrap/out/volume01.crt"" key = ""/home/certstrap/certstrap/out/volume01.key"" [grpc.master] cert = ""/home/certstrap/certstrap/out/master01.crt"" key = ""/home/certstrap/certstrap/out/master01.key"" [grpc.filer] cert = ""/home/certstrap/certstrap/out/filer01.crt"" key = ""/home/certstrap/certstrap/out/filer01.key"" # use this for any place needs a grpc client # i.e., ""weed backup|benchmark|filer.copy|filer.replicate|mount|s3|upload"" [grpc.client] cert = ""/home/certstrap/certstrap/out/client01.crt"" key = ""/home/certstrap/certstrap/out/client01.key""  If I turn of the security (jwt). The server is working perfect. I can save, show, delete object source-file",bug,0.9
2802,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2802,[bug:volume] SendHeartbeat to sw-master-direct.query.consul:9333: rpc error: code = Unavailable desc = connection closed (Critical),"At the time of the update by the master server from 2.88 to 2.90 with a restart after the change of leader, all volumes of the server stopped sending heartbeats restarts or rollback statefulsets sw-master did not help After restarting all volume servers, sending heartbeats started working  volume_grpc_client_to_master.go:129] Volume Server found a new master newLeader: master-0.sw-master-direct.service.consul:9333 instead of sw-master-direct.query.consul volume_grpc_client_to_master.go:107] Heartbeat to: master-0.sw-master-direct.service.consul:9333  weed version  2.88  weed volume cmd with TLS grpc  weed -logtostderr=true -v=1 volume -port=8080 -dir=/data -max=900 -rack=node14 -dataCenter=dcix -ip.bind=0.0.0.0 -preStopSeconds=15 -index=memory -minFreeSpacePercent=11 -compactionMBps=2000 -concurrentDownloadLimitMB=2048 -concurrentUploadLimitMB=2048 -metricsPort=9327 -ip=sw-volume-15.service.consul -mserver=sw-master-direct.query.consul  nslookup sw-master-direct.query.consul  Name: sw-master-direct.query.consul Address: 10.103.3.14 Name: sw-master-direct.query.consul Address: 10.103.5.212 Name: sw-master-direct.query.consul Address: 10.103.3.245  env:  WEED_GRPC_ALLOWED_WILDCARD_DOMAIN=.s3.stage  tls files secret sw-cert  kind: Secret metadata: annotations: cert-manager.io/certificate-name: sw-cert cert-manager.io/common-name: sw-master.s3.stage cert-manager.io/ip-sans: """" cert-manager.io/issuer-group: """" cert-manager.io/issuer-kind: ClusterIssuer cert-manager.io/issuer-name: vault-issuer cert-manager.io/uri-sans: """" creationTimestamp: ""2020-12-18T21:16:57Z"" name: sw-cert namespace: s3 resourceVersion: ""876598070"" uid: 7274a063-7c73-431c-a22e-e1bbc481229f type: kubernetes.io/tls  security.toml:  # this file is read by master, volume server, and filer # the jwt signing key is read by master and volume server # a jwt expires in 10 seconds [jwt.signing] # key = """" expires_after_seconds = 10 # seconds [jwt.signing.read] key = """" expires_after_seconds = 10 # seconds # all grpc tls authentications are mutual # the values for the following ca, cert, and key are paths to the PERM files. [grpc] ca = ""/usr/local/share/ca-certificates/ca.crt"" [grpc.volume] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" [grpc.master] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" [grpc.filer] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" [grpc.msg_broker] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" # use this for any place needs a grpc client # i.e., ""weed backup|benchmark|filer.copy|filer.replicate|mount|s3|upload"" [grpc.client] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" # volume server https options # Note: work in progress! # this does not work with other clients, e.g., ""weed filer|mount"" etc, yet. [https.client] enabled = false [https.volume] cert = """"  volume logs  Mar 22, 2022 @ 02:07:34.979 | I0321 21:07:34 1 volume_grpc_client_to_master.go:104] SendHeartbeat to sw-master-direct.query.consul: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:29.978 | I0321 21:07:29 1 volume_grpc_client_to_master.go:104] SendHeartbeat to sw-master-direct.query.consul: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:29.978 | I0321 21:07:29 1 volume_grpc_client_to_master.go:69] heartbeat error: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:24.978 | I0321 21:07:24 1 volume_grpc_client_to_master.go:69] heartbeat error: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:24.978 | I0321 21:07:24 1 volume_grpc_client_to_master.go:104] SendHeartbeat to sw-master-direct.query.consul: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:19.978 | I0321 21:07:19 1 volume_grpc_client_to_master.go:104] SendHeartbeat to sw-master-direct.query.consul: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:19.978 | I0321 21:07:19 1 volume_grpc_client_to_master.go:69] heartbeat error: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:14.978 | I0321 21:07:14 1 volume_grpc_client_to_master.go:69] heartbeat error: rpc error: code = Unavailable desc = connection closed ",source-file | source-file | source-file,"[bug:volume] SendHeartbeat to sw-master-direct.query.consul:9333: rpc error: code = Unavailable desc = connection closed (Critical) At the time of the update by the master server from 2.88 to 2.90 with a restart after the change of leader, all volumes of the server stopped sending heartbeats restarts or rollback statefulsets sw-master did not help After restarting all volume servers, sending heartbeats started working  volume_grpc_client_to_master.go:129] Volume Server found a new master newLeader: master-0.sw-master-direct.service.consul:9333 instead of sw-master-direct.query.consul volume_grpc_client_to_master.go:107] Heartbeat to: master-0.sw-master-direct.service.consul:9333  weed version  2.88  weed volume cmd with TLS grpc  weed -logtostderr=true -v=1 volume -port=8080 -dir=/data -max=900 -rack=node14 -dataCenter=dcix -ip.bind=0.0.0.0 -preStopSeconds=15 -index=memory -minFreeSpacePercent=11 -compactionMBps=2000 -concurrentDownloadLimitMB=2048 -concurrentUploadLimitMB=2048 -metricsPort=9327 -ip=sw-volume-15.service.consul -mserver=sw-master-direct.query.consul  nslookup sw-master-direct.query.consul  Name: sw-master-direct.query.consul Address: 10.103.3.14 Name: sw-master-direct.query.consul Address: 10.103.5.212 Name: sw-master-direct.query.consul Address: 10.103.3.245  env:  WEED_GRPC_ALLOWED_WILDCARD_DOMAIN=.s3.stage  tls files secret sw-cert  kind: Secret metadata: annotations: cert-manager.io/certificate-name: sw-cert cert-manager.io/common-name: sw-master.s3.stage cert-manager.io/ip-sans: """" cert-manager.io/issuer-group: """" cert-manager.io/issuer-kind: ClusterIssuer cert-manager.io/issuer-name: vault-issuer cert-manager.io/uri-sans: """" creationTimestamp: ""2020-12-18T21:16:57Z"" name: sw-cert namespace: s3 resourceVersion: ""876598070"" uid: 7274a063-7c73-431c-a22e-e1bbc481229f type: kubernetes.io/tls  security.toml:  # this file is read by master, volume server, and filer # the jwt signing key is read by master and volume server # a jwt expires in 10 seconds [jwt.signing] # key = """" expires_after_seconds = 10 # seconds [jwt.signing.read] key = """" expires_after_seconds = 10 # seconds # all grpc tls authentications are mutual # the values for the following ca, cert, and key are paths to the PERM files. [grpc] ca = ""/usr/local/share/ca-certificates/ca.crt"" [grpc.volume] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" [grpc.master] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" [grpc.filer] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" [grpc.msg_broker] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" # use this for any place needs a grpc client # i.e., ""weed backup|benchmark|filer.copy|filer.replicate|mount|s3|upload"" [grpc.client] cert = ""/usr/local/share/ca-certificates/tls.crt"" key = ""/usr/local/share/ca-certificates/tls.key"" ca = ""/usr/local/share/ca-certificates/ca.crt"" # volume server https options # Note: work in progress! # this does not work with other clients, e.g., ""weed filer|mount"" etc, yet. [https.client] enabled = false [https.volume] cert = """"  volume logs  Mar 22, 2022 @ 02:07:34.979 | I0321 21:07:34 1 volume_grpc_client_to_master.go:104] SendHeartbeat to sw-master-direct.query.consul: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:29.978 | I0321 21:07:29 1 volume_grpc_client_to_master.go:104] SendHeartbeat to sw-master-direct.query.consul: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:29.978 | I0321 21:07:29 1 volume_grpc_client_to_master.go:69] heartbeat error: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:24.978 | I0321 21:07:24 1 volume_grpc_client_to_master.go:69] heartbeat error: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:24.978 | I0321 21:07:24 1 volume_grpc_client_to_master.go:104] SendHeartbeat to sw-master-direct.query.consul: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:19.978 | I0321 21:07:19 1 volume_grpc_client_to_master.go:104] SendHeartbeat to sw-master-direct.query.consul: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:19.978 | I0321 21:07:19 1 volume_grpc_client_to_master.go:69] heartbeat error: rpc error: code = Unavailable desc = connection closed Mar 22, 2022 @ 02:07:14.978 | I0321 21:07:14 1 volume_grpc_client_to_master.go:69] heartbeat error: rpc error: code = Unavailable desc = connection closed  source-file source-file source-file",no-bug,0.9
4647,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4647,"[shell] volume 1415 replication 100, but over replicated +3 (critical)","Delete extra replicas, taking into account the replication factor, so that the replicas remain in different DCs.  I0707 05:13:12.448756 master_grpc_server.go:199 master see new volume 1415 from fast-volume-0.s3-fast-volume.service.dcvcs.consul:8080 volume 1415 replication 100, but over replicated +3 deleting volume 1415 from fast-volume-4.s3-fast-volume.service.dcix.consul:8080  volume 1415 replication 100 is not well placed [0xc001bed030 0xc001beed00] deleting volume 1415 from fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080   It is also necessary to handle such a case and, if the number of replicas is temporarily exceeded, write files to all.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[shell] volume 1415 replication 100, but over replicated +3 (critical) Delete extra replicas, taking into account the replication factor, so that the replicas remain in different DCs.  I0707 05:13:12.448756 master_grpc_server.go:199 master see new volume 1415 from fast-volume-0.s3-fast-volume.service.dcvcs.consul:8080 volume 1415 replication 100, but over replicated +3 deleting volume 1415 from fast-volume-4.s3-fast-volume.service.dcix.consul:8080  volume 1415 replication 100 is not well placed [0xc001bed030 0xc001beed00] deleting volume 1415 from fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080   It is also necessary to handle such a case and, if the number of replicas is temporarily exceeded, write files to all. source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2039,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2039,Unexpected response to s3 GET call on non-existent bucket,"**Describe the bug** Running a ""GET /nonexistent-bucket?acl"" - which is what a number of libraries use for ""does this bucket exist"" call, returns a ListBucketResult. According to S3 api docs, it should return a 'AccessControlPolicy' or at least a 404 for the nonexistent resource. **System Setup** docker run -p 8333:8333 chrislusf/seaweedfs server -s3  nneul@optic:~ $ curl http://localhost:8333/nonexistent-bucket?acl <?xml version=""1.0"" encoding=""UTF-8""?> <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Name>nonexistent-bucket</Name><Prefix></Prefix><Marker></Marker><MaxKeys>10000</MaxKeys><IsTruncated>false</IsTruncated></ListBucketResult>  **Expected behavior** AccessControlPolicy in response - even if it's a dummy/empty policy document, or a 404 or other error indicating it couldn't handle the request due to the bucket not being there.",source-file,"Unexpected response to s3 GET call on non-existent bucket **Describe the bug** Running a ""GET /nonexistent-bucket?acl"" - which is what a number of libraries use for ""does this bucket exist"" call, returns a ListBucketResult. According to S3 api docs, it should return a 'AccessControlPolicy' or at least a 404 for the nonexistent resource. **System Setup** docker run -p 8333:8333 chrislusf/seaweedfs server -s3  nneul@optic:~ $ curl http://localhost:8333/nonexistent-bucket?acl <?xml version=""1.0"" encoding=""UTF-8""?> <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Name>nonexistent-bucket</Name><Prefix></Prefix><Marker></Marker><MaxKeys>10000</MaxKeys><IsTruncated>false</IsTruncated></ListBucketResult>  **Expected behavior** AccessControlPolicy in response - even if it's a dummy/empty policy document, or a 404 or other error indicating it couldn't handle the request due to the bucket not being there. source-file",bug,0.95
6217,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6217,Helm chart creates wrong match label selector for S3 ServiceMonitor,"**Describe the bug** ServiceMonitor labels in the helm chart for the S3 service are created with the wrong `matchLabels`. With S3 enabled, and the following global values set: yaml global: monitoring: enabled: true  The helm chart sets the following selector for the S3 ServiceMonitor: yaml spec: selector: matchLabels: app: seaweedfs component: s3  The following labels are applied to the S3 service created by the helm chart: yaml labels: app.kubernetes.io/component: s3 app.kubernetes.io/managed-by: Helm app.kubernetes.io/name: seaweedfs argocd.argoproj.io/instance: seaweedfs helm.sh/chart: seaweedfs-4.0.379  This results in the ServiceMonitor never picking up the target for metrics. **System Setup** - I tried the following chart versions and they were all affected - 4.0.377 - 4.0.379 **Expected behavior** The expected selector setting is below: yaml spec: selector: matchLabels: app.kubernetes.io/component: s3 app.kubernetes.io/name: seaweedfs  This would match the applied labels for the S3 service and pickup the endpoint with the name `seaweedfs`. **Additional context** Removing the non-fully-qualified version of the labels and adding in the fully qualified labels manually through a `kubectl edit` does allow the metrics endpoint to be picked up. I am using `IngoreDifferences` in ArgoCD to keep the manually applied labels for now. Other servicemonitors from the helm chart are created with fully qualified labels for selectors. The following work fine: - seaweedfs-filer - seaweedfs-master - seaweedfs-volume",documentation-file,"Helm chart creates wrong match label selector for S3 ServiceMonitor **Describe the bug** ServiceMonitor labels in the helm chart for the S3 service are created with the wrong `matchLabels`. With S3 enabled, and the following global values set: yaml global: monitoring: enabled: true  The helm chart sets the following selector for the S3 ServiceMonitor: yaml spec: selector: matchLabels: app: seaweedfs component: s3  The following labels are applied to the S3 service created by the helm chart: yaml labels: app.kubernetes.io/component: s3 app.kubernetes.io/managed-by: Helm app.kubernetes.io/name: seaweedfs argocd.argoproj.io/instance: seaweedfs helm.sh/chart: seaweedfs-4.0.379  This results in the ServiceMonitor never picking up the target for metrics. **System Setup** - I tried the following chart versions and they were all affected - 4.0.377 - 4.0.379 **Expected behavior** The expected selector setting is below: yaml spec: selector: matchLabels: app.kubernetes.io/component: s3 app.kubernetes.io/name: seaweedfs  This would match the applied labels for the S3 service and pickup the endpoint with the name `seaweedfs`. **Additional context** Removing the non-fully-qualified version of the labels and adding in the fully qualified labels manually through a `kubectl edit` does allow the metrics endpoint to be picked up. I am using `IngoreDifferences` in ArgoCD to keep the manually applied labels for now. Other servicemonitors from the helm chart are created with fully qualified labels for selectors. The following work fine: - seaweedfs-filer - seaweedfs-master - seaweedfs-volume documentation-file",no-bug,0.9
3521,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3521,[master] panic if use hashicorp with -race detect," master branch cd docker; make hashicorp_raft with -race   master2_1 | master2_1 | goroutine 1 [running]: master2_1 | runtime.throw({0x334f6b4?, 0x26ed401?}) master2_1 | /usr/local/go/src/runtime/panic.go:1047 +0x5d fp=0xc0008c6f88 sp=0xc0008c6f58 pc=0x47205d master2_1 | runtime.checkptrAlignment(0x4aa339?, 0x4840a5?, 0x5865a28?) master2_1 | /usr/local/go/src/runtime/checkptr.go:26 +0x6c fp=0xc0008c6fa8 sp=0xc0008c6f88 pc=0x43e7ac master2_1 | github.com/boltdb/bolt.(*Bucket).write(0xc0008c7140) master2_1 | /go/pkg/mod/github.com/boltdb/bolt@v1.3.1/bucket.go:626 +0x211 fp=0xc0008c7038 sp=0xc0008c6fa8 pc=0x26f13f1 master2_1 | github.com/boltdb/bolt.(*Bucket).CreateBucket(0xc000872018, {0x5865a28, 0x4, 0x4}) master2_1 | /go/pkg/mod/github.com/boltdb/bolt@v1.3.1/bucket.go:188 +0x3e9 fp=0xc0008c7228 sp=0xc0008c7038 pc=0x26ed409 master2_1 | github.com/boltdb/bolt.(*Bucket).CreateBucketIfNotExists(0x0?, {0x5865a28, 0x4, 0x4}) master2_1 | /go/pkg/mod/github.com/boltdb/bolt@v1.3.1/bucket.go:206 +0x4f fp=0xc0008c7278 sp=0xc0008c7228 pc=0x26ed6cf master2_1 | github.com/boltdb/bolt.(*Tx).CreateBucketIfNotExists() master2_1 | /go/pkg/mod/github.com/boltdb/bolt@v1.3.1/tx.go:115 master2_1 | github.com/hashicorp/raft-boltdb.(*BoltStore).initialize(0xc000012360) master2_1 | /go/pkg/mod/github.com/hashicorp/raft-boltdb@v0.0.0-20220329195025-15018e9b97e0/bolt_store.go:100 +0xeb fp=0xc0008c7320 sp=0xc0008c7278 pc=0x270f3eb master2_1 | github.com/hashicorp/raft-boltdb.New({{0xc0006cc3f0, 0x14}, 0x0, 0x0}) master2_1 | /go/pkg/mod/github.com/hashicorp/raft-boltdb@v0.0.0-20220329195025-15018e9b97e0/bolt_store.go:83 +0x19c fp=0xc0008c73a8 sp=0xc0008c7320 pc=0x270f23c master2_1 | github.com/hashicorp/raft-boltdb.NewBoltStore() master2_1 | /go/pkg/mod/github.com/hashicorp/raft-boltdb@v0.0.0-20220329195025-15018e9b97e0/bolt_store.go:62 master2_1 | github.com/seaweedfs/seaweedfs/weed/server.NewHashicorpRaftServer(0xc0008c7bf0) master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/raft_hashicorp.go:131 +0x8b8 fp=0xc0008c77f8 sp=0xc0008c73a8 pc=0x27b8b98 master2_1 | github.com/seaweedfs/seaweedfs/weed/command.startMaster({0xc000672ac8, 0xc000672af8, 0xc0004f0cc0, 0xc0004f0ce0, 0xc0004f0cf0, 0xc0004f0d10, 0xc000672bd8, 0xc000672c1f, 0xc0004f0d20, 0xc000672c48, }, ) master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/master.go:170 +0x999 fp=0xc0008c7c60 sp=0xc0008c77f8 pc=0x2cb4099 master2_1 | github.com/seaweedfs/seaweedfs/weed/command.runMaster(0x5927b58?, {0xc000000170?, 0x7?, 0x7?}) master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/master.go:122 +0x4b0 fp=0xc0008c7e40 sp=0xc0008c7c60 pc=0x2cb3650 master2_1 | main.main() master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x944 fp=0xc0008c7f80 sp=0xc0008c7e40 pc=0x2cd6504 master2_1 | runtime.main() master2_1 | /usr/local/go/src/runtime/proc.go:250 +0x212 fp=0xc0008c7fe0 sp=0xc0008c7f80 pc=0x4748b2 master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc0008c7fe8 sp=0xc0008c7fe0 pc=0x4a8ba1 master2_1 | master2_1 | goroutine 2 [force gc (idle)]: master2_1 | runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc000070fb0 sp=0xc000070f90 pc=0x474c76 master2_1 | runtime.goparkunlock() master2_1 | /usr/local/go/src/runtime/proc.go:369 master2_1 | runtime.forcegchelper() master2_1 | /usr/local/go/src/runtime/proc.go:302 +0xad fp=0xc000070fe0 sp=0xc000070fb0 pc=0x474b0d master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc000070fe8 sp=0xc000070fe0 pc=0x4a8ba1 master2_1 | created by runtime.init.6 master2_1 | /usr/local/go/src/runtime/proc.go:290 +0x25 master2_1 | master2_1 | goroutine 18 [GC sweep wait]: master2_1 | runtime.gopark(0x1?, 0x0?, 0x0?, 0x0?, 0x0?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc00006c790 sp=0xc00006c770 pc=0x474c76 master2_1 | runtime.goparkunlock() master2_1 | /usr/local/go/src/runtime/proc.go:369 master2_1 | runtime.bgsweep(0x0?) master2_1 | /usr/local/go/src/runtime/mgcsweep.go:297 +0xd7 fp=0xc00006c7c8 sp=0xc00006c790 pc=0x45ee97 master2_1 | runtime.gcenable.func1() master2_1 | /usr/local/go/src/runtime/mgc.go:178 +0x26 fp=0xc00006c7e0 sp=0xc00006c7c8 pc=0x453b06 master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc00006c7e8 sp=0xc00006c7e0 pc=0x4a8ba1 master2_1 | created by runtime.gcenable master2_1 | /usr/local/go/src/runtime/mgc.go:178 +0x6b master2_1 | master2_1 | goroutine 19 [GC scavenge wait]: master2_1 | runtime.gopark(0xc00010e000?, 0x46ba538?, 0x0?, 0x0?, 0x0?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc00006cf70 sp=0xc00006cf50 pc=0x474c76 master2_1 | runtime.goparkunlock() master2_1 | /usr/local/go/src/runtime/proc.go:369 master2_1 | runtime.(*scavengerState).park(0x5944e40) master2_1 | /usr/local/go/src/runtime/mgcscavenge.go:389 +0x53 fp=0xc00006cfa0 sp=0xc00006cf70 pc=0x45cf13 master2_1 | runtime.bgscavenge(0x0?) master2_1 | /usr/local/go/src/runtime/mgcscavenge.go:622 +0x65 fp=0xc00006cfc8 sp=0xc00006cfa0 pc=0x45d4e5 master2_1 | runtime.gcenable.func2() master2_1 | /usr/local/go/src/runtime/mgc.go:179 +0x26 fp=0xc00006cfe0 sp=0xc00006cfc8 pc=0x453aa6 master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc00006cfe8 sp=0xc00006cfe0 pc=0x4a8ba1 master2_1 | created by runtime.gcenable master2_1 | /usr/local/go/src/runtime/mgc.go:179 +0xaa master2_1 | master2_1 | goroutine 3 [finalizer wait]: master2_1 | runtime.gopark(0xc000007860?, 0x0?, 0x0?, 0x6?, 0xc000070770?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc000070628 sp=0xc000070608 pc=0x474c76 master2_1 | runtime.goparkunlock() master2_1 | /usr/local/go/src/runtime/proc.go:369 master2_1 | runtime.runfinq() master2_1 | /usr/local/go/src/runtime/mfinal.go:180 +0x145 fp=0xc0000707e0 sp=0xc000070628 pc=0x452c25 master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc0000707e8 sp=0xc0000707e0 pc=0x4a8ba1 master2_1 | created by runtime.createfing master2_1 | /usr/local/go/src/runtime/mfinal.go:157 +0x45 master2_1 | master2_1 | goroutine 4 [chan receive]: master2_1 | runtime.gopark(0xc000064f00?, 0xc0001b4008?, 0x9?, 0x61?, 0xc000074c00?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc0000716b8 sp=0xc000071698 pc=0x474c76 master2_1 | runtime.chanrecv(0xc0001b0000, 0xc000071798, 0x1) master2_1 | /usr/local/go/src/runtime/chan.go:583 +0x42c fp=0xc000071748 sp=0xc0000716b8 pc=0x43df8c master2_1 | runtime.chanrecv2(0x6fc23ac00?, 0x0?) master2_1 | /usr/local/go/src/runtime/chan.go:447 +0x18 fp=0xc000071770 sp=0xc000071748 pc=0x43db38 master2_1 | github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).flushDaemon(0x0?) master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/glog/glog.go:882 +0x8b fp=0xc0000717c0 sp=0xc000071770 pc=0xc75b0b master2_1 | github.com/seaweedfs/seaweedfs/weed/glog.init.0.func1() master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/glog/glog.go:410 +0x3a fp=0xc0000717e0 sp=0xc0000717c0 pc=0xc72b7a  https://github.com/seaweedfs/seaweedfs/issues/3507",other-file | other-file | source-file,"[master] panic if use hashicorp with -race detect  master branch cd docker; make hashicorp_raft with -race   master2_1 | master2_1 | goroutine 1 [running]: master2_1 | runtime.throw({0x334f6b4?, 0x26ed401?}) master2_1 | /usr/local/go/src/runtime/panic.go:1047 +0x5d fp=0xc0008c6f88 sp=0xc0008c6f58 pc=0x47205d master2_1 | runtime.checkptrAlignment(0x4aa339?, 0x4840a5?, 0x5865a28?) master2_1 | /usr/local/go/src/runtime/checkptr.go:26 +0x6c fp=0xc0008c6fa8 sp=0xc0008c6f88 pc=0x43e7ac master2_1 | github.com/boltdb/bolt.(*Bucket).write(0xc0008c7140) master2_1 | /go/pkg/mod/github.com/boltdb/bolt@v1.3.1/bucket.go:626 +0x211 fp=0xc0008c7038 sp=0xc0008c6fa8 pc=0x26f13f1 master2_1 | github.com/boltdb/bolt.(*Bucket).CreateBucket(0xc000872018, {0x5865a28, 0x4, 0x4}) master2_1 | /go/pkg/mod/github.com/boltdb/bolt@v1.3.1/bucket.go:188 +0x3e9 fp=0xc0008c7228 sp=0xc0008c7038 pc=0x26ed409 master2_1 | github.com/boltdb/bolt.(*Bucket).CreateBucketIfNotExists(0x0?, {0x5865a28, 0x4, 0x4}) master2_1 | /go/pkg/mod/github.com/boltdb/bolt@v1.3.1/bucket.go:206 +0x4f fp=0xc0008c7278 sp=0xc0008c7228 pc=0x26ed6cf master2_1 | github.com/boltdb/bolt.(*Tx).CreateBucketIfNotExists() master2_1 | /go/pkg/mod/github.com/boltdb/bolt@v1.3.1/tx.go:115 master2_1 | github.com/hashicorp/raft-boltdb.(*BoltStore).initialize(0xc000012360) master2_1 | /go/pkg/mod/github.com/hashicorp/raft-boltdb@v0.0.0-20220329195025-15018e9b97e0/bolt_store.go:100 +0xeb fp=0xc0008c7320 sp=0xc0008c7278 pc=0x270f3eb master2_1 | github.com/hashicorp/raft-boltdb.New({{0xc0006cc3f0, 0x14}, 0x0, 0x0}) master2_1 | /go/pkg/mod/github.com/hashicorp/raft-boltdb@v0.0.0-20220329195025-15018e9b97e0/bolt_store.go:83 +0x19c fp=0xc0008c73a8 sp=0xc0008c7320 pc=0x270f23c master2_1 | github.com/hashicorp/raft-boltdb.NewBoltStore() master2_1 | /go/pkg/mod/github.com/hashicorp/raft-boltdb@v0.0.0-20220329195025-15018e9b97e0/bolt_store.go:62 master2_1 | github.com/seaweedfs/seaweedfs/weed/server.NewHashicorpRaftServer(0xc0008c7bf0) master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/raft_hashicorp.go:131 +0x8b8 fp=0xc0008c77f8 sp=0xc0008c73a8 pc=0x27b8b98 master2_1 | github.com/seaweedfs/seaweedfs/weed/command.startMaster({0xc000672ac8, 0xc000672af8, 0xc0004f0cc0, 0xc0004f0ce0, 0xc0004f0cf0, 0xc0004f0d10, 0xc000672bd8, 0xc000672c1f, 0xc0004f0d20, 0xc000672c48, }, ) master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/master.go:170 +0x999 fp=0xc0008c7c60 sp=0xc0008c77f8 pc=0x2cb4099 master2_1 | github.com/seaweedfs/seaweedfs/weed/command.runMaster(0x5927b58?, {0xc000000170?, 0x7?, 0x7?}) master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/master.go:122 +0x4b0 fp=0xc0008c7e40 sp=0xc0008c7c60 pc=0x2cb3650 master2_1 | main.main() master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x944 fp=0xc0008c7f80 sp=0xc0008c7e40 pc=0x2cd6504 master2_1 | runtime.main() master2_1 | /usr/local/go/src/runtime/proc.go:250 +0x212 fp=0xc0008c7fe0 sp=0xc0008c7f80 pc=0x4748b2 master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc0008c7fe8 sp=0xc0008c7fe0 pc=0x4a8ba1 master2_1 | master2_1 | goroutine 2 [force gc (idle)]: master2_1 | runtime.gopark(0x0?, 0x0?, 0x0?, 0x0?, 0x0?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc000070fb0 sp=0xc000070f90 pc=0x474c76 master2_1 | runtime.goparkunlock() master2_1 | /usr/local/go/src/runtime/proc.go:369 master2_1 | runtime.forcegchelper() master2_1 | /usr/local/go/src/runtime/proc.go:302 +0xad fp=0xc000070fe0 sp=0xc000070fb0 pc=0x474b0d master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc000070fe8 sp=0xc000070fe0 pc=0x4a8ba1 master2_1 | created by runtime.init.6 master2_1 | /usr/local/go/src/runtime/proc.go:290 +0x25 master2_1 | master2_1 | goroutine 18 [GC sweep wait]: master2_1 | runtime.gopark(0x1?, 0x0?, 0x0?, 0x0?, 0x0?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc00006c790 sp=0xc00006c770 pc=0x474c76 master2_1 | runtime.goparkunlock() master2_1 | /usr/local/go/src/runtime/proc.go:369 master2_1 | runtime.bgsweep(0x0?) master2_1 | /usr/local/go/src/runtime/mgcsweep.go:297 +0xd7 fp=0xc00006c7c8 sp=0xc00006c790 pc=0x45ee97 master2_1 | runtime.gcenable.func1() master2_1 | /usr/local/go/src/runtime/mgc.go:178 +0x26 fp=0xc00006c7e0 sp=0xc00006c7c8 pc=0x453b06 master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc00006c7e8 sp=0xc00006c7e0 pc=0x4a8ba1 master2_1 | created by runtime.gcenable master2_1 | /usr/local/go/src/runtime/mgc.go:178 +0x6b master2_1 | master2_1 | goroutine 19 [GC scavenge wait]: master2_1 | runtime.gopark(0xc00010e000?, 0x46ba538?, 0x0?, 0x0?, 0x0?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc00006cf70 sp=0xc00006cf50 pc=0x474c76 master2_1 | runtime.goparkunlock() master2_1 | /usr/local/go/src/runtime/proc.go:369 master2_1 | runtime.(*scavengerState).park(0x5944e40) master2_1 | /usr/local/go/src/runtime/mgcscavenge.go:389 +0x53 fp=0xc00006cfa0 sp=0xc00006cf70 pc=0x45cf13 master2_1 | runtime.bgscavenge(0x0?) master2_1 | /usr/local/go/src/runtime/mgcscavenge.go:622 +0x65 fp=0xc00006cfc8 sp=0xc00006cfa0 pc=0x45d4e5 master2_1 | runtime.gcenable.func2() master2_1 | /usr/local/go/src/runtime/mgc.go:179 +0x26 fp=0xc00006cfe0 sp=0xc00006cfc8 pc=0x453aa6 master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc00006cfe8 sp=0xc00006cfe0 pc=0x4a8ba1 master2_1 | created by runtime.gcenable master2_1 | /usr/local/go/src/runtime/mgc.go:179 +0xaa master2_1 | master2_1 | goroutine 3 [finalizer wait]: master2_1 | runtime.gopark(0xc000007860?, 0x0?, 0x0?, 0x6?, 0xc000070770?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc000070628 sp=0xc000070608 pc=0x474c76 master2_1 | runtime.goparkunlock() master2_1 | /usr/local/go/src/runtime/proc.go:369 master2_1 | runtime.runfinq() master2_1 | /usr/local/go/src/runtime/mfinal.go:180 +0x145 fp=0xc0000707e0 sp=0xc000070628 pc=0x452c25 master2_1 | runtime.goexit() master2_1 | /usr/local/go/src/runtime/asm_amd64.s:1594 +0x1 fp=0xc0000707e8 sp=0xc0000707e0 pc=0x4a8ba1 master2_1 | created by runtime.createfing master2_1 | /usr/local/go/src/runtime/mfinal.go:157 +0x45 master2_1 | master2_1 | goroutine 4 [chan receive]: master2_1 | runtime.gopark(0xc000064f00?, 0xc0001b4008?, 0x9?, 0x61?, 0xc000074c00?) master2_1 | /usr/local/go/src/runtime/proc.go:363 +0xd6 fp=0xc0000716b8 sp=0xc000071698 pc=0x474c76 master2_1 | runtime.chanrecv(0xc0001b0000, 0xc000071798, 0x1) master2_1 | /usr/local/go/src/runtime/chan.go:583 +0x42c fp=0xc000071748 sp=0xc0000716b8 pc=0x43df8c master2_1 | runtime.chanrecv2(0x6fc23ac00?, 0x0?) master2_1 | /usr/local/go/src/runtime/chan.go:447 +0x18 fp=0xc000071770 sp=0xc000071748 pc=0x43db38 master2_1 | github.com/seaweedfs/seaweedfs/weed/glog.(*loggingT).flushDaemon(0x0?) master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/glog/glog.go:882 +0x8b fp=0xc0000717c0 sp=0xc000071770 pc=0xc75b0b master2_1 | github.com/seaweedfs/seaweedfs/weed/glog.init.0.func1() master2_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/glog/glog.go:410 +0x3a fp=0xc0000717e0 sp=0xc0000717c0 pc=0xc72b7a  https://github.com/seaweedfs/seaweedfs/issues/3507 other-file other-file source-file",no-bug,0.95
3531,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3531,About async backups," Discussed in https://github.com/seaweedfs/seaweedfs/discussions/3529 <div type='discussions-op-text'> <sup>Originally posted by **lewisl9029** August 26, 2022</sup> I just set up async backups to S3 in my dev environment following the instructions here: https://github.com/seaweedfs/seaweedfs/wiki/Async-Backup A few things I wanted to discuss: 1. Seeing a bunch of logs with the error `completeMultipartUpload resources/JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE: EntityTooSmall: Your proposed upload is smaller than the minimum allowed size` at the end. Full log looks like this:  E0827 00:27:41.569969 filer_pb_tail.go:79 process directory:""/resources"" event_notification:{new_entry:{name:""JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE"" chunks:{file_id:""7,226b3fb24ef9"" size:4194304 mtime:1661135791927660085 e_tag:""Bpp6x011IEhwtTl6OWbgew=="" fid:{volume_id:7 file_key:8811 cookie:1068650233}} chunks:{file_id:""3,226ccbf95a37"" offset:4194304 size:525967 mtime:1661135791855596419 e_tag:""5hzWkEk2zhUhh/SKQaCm7w=="" fid:{volume_id:3 file_key:8812 cookie:3422116407}} attributes:{file_size:4720271 mtime:1661135791 file_mode:432 crtime:1661135791 mime:""application/json"" md5:"">T{[\xde4\xab\n\x8d\x0c\xf6T$\xd7""} extended:{key:""Seaweed-Meta"" value:""{\""headers\"":{\""cache-control\"":\""public, max-age=31536000, immutable\"",\""content-type\"":\""application/json\""}}""}} delete_chunks:true new_parent_path:""/resources"" signatures:-2011343073} ts_ns:1661135791928717585: [reflame-storage-backup-development] completeMultipartUpload resources/JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE: EntityTooSmall: Your proposed upload is smaller than the minimum allowed size  Here's a zip with the file in the log: [JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE.zip](https://github.com/seaweedfs/seaweedfs/files/9437048/JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE.zip) Happy to turn this into an issue if it looks like a valid bug? 2. In my seaweed cluster I'm using a `Seaweed-meta` header to store a bunch of json metadata for each file, but in the s3 backup, I'm not seeing anything in S3 metadata except Content-Type: ![image](https://user-images.githubusercontent.com/6934200/187008116-f6db44af-ed2a-4d38-90f0-e4fc73c11b0b.png) Are the Seaweed- headers backed up somewhere in s3 as well? 3. How should I go about testing a restore from the async s3 backup, to make sure it works as expected and document the process for when I need to do this in production? Haven't been able to find any docs around this. Cheers!</div>",source-file,"About async backups  Discussed in https://github.com/seaweedfs/seaweedfs/discussions/3529 <div type='discussions-op-text'> <sup>Originally posted by **lewisl9029** August 26, 2022</sup> I just set up async backups to S3 in my dev environment following the instructions here: https://github.com/seaweedfs/seaweedfs/wiki/Async-Backup A few things I wanted to discuss: 1. Seeing a bunch of logs with the error `completeMultipartUpload resources/JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE: EntityTooSmall: Your proposed upload is smaller than the minimum allowed size` at the end. Full log looks like this:  E0827 00:27:41.569969 filer_pb_tail.go:79 process directory:""/resources"" event_notification:{new_entry:{name:""JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE"" chunks:{file_id:""7,226b3fb24ef9"" size:4194304 mtime:1661135791927660085 e_tag:""Bpp6x011IEhwtTl6OWbgew=="" fid:{volume_id:7 file_key:8811 cookie:1068650233}} chunks:{file_id:""3,226ccbf95a37"" offset:4194304 size:525967 mtime:1661135791855596419 e_tag:""5hzWkEk2zhUhh/SKQaCm7w=="" fid:{volume_id:3 file_key:8812 cookie:3422116407}} attributes:{file_size:4720271 mtime:1661135791 file_mode:432 crtime:1661135791 mime:""application/json"" md5:"">T{[\xde4\xab\n\x8d\x0c\xf6T$\xd7""} extended:{key:""Seaweed-Meta"" value:""{\""headers\"":{\""cache-control\"":\""public, max-age=31536000, immutable\"",\""content-type\"":\""application/json\""}}""}} delete_chunks:true new_parent_path:""/resources"" signatures:-2011343073} ts_ns:1661135791928717585: [reflame-storage-backup-development] completeMultipartUpload resources/JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE: EntityTooSmall: Your proposed upload is smaller than the minimum allowed size  Here's a zip with the file in the log: [JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE.zip](https://github.com/seaweedfs/seaweedfs/files/9437048/JTLtLXSjjlP3nN4tjbNfpCYzrF08EcSVCHbpa8XrUJE.zip) Happy to turn this into an issue if it looks like a valid bug? 2. In my seaweed cluster I'm using a `Seaweed-meta` header to store a bunch of json metadata for each file, but in the s3 backup, I'm not seeing anything in S3 metadata except Content-Type: ![image](https://user-images.githubusercontent.com/6934200/187008116-f6db44af-ed2a-4d38-90f0-e4fc73c11b0b.png) Are the Seaweed- headers backed up somewhere in s3 as well? 3. How should I go about testing a restore from the async s3 backup, to make sure it works as expected and document the process for when I need to do this in production? Haven't been able to find any docs around this. Cheers!</div> source-file",no-bug,0.9
1118,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1118,WeedFS can't start normally caused by Raft Server fault.,"**Describe the bug** Some time server cannot start normally because of raft server may down? **System Setup** I started this server with docker-compose yaml version: '3' # weed/redis/'s exposed port is only for debug services: master: image: chrislusf/seaweedfs ports: - 9333:9333 # todo remove this port expose command: ""master -mdir /data"" volumes: - ""./data/meta/:/data/"" volume: image: chrislusf/seaweedfs ports: - 9301:9301 # todo remove this port expose command: 'volume -max=30 -mserver=""master:9333"" -port=9301' volumes: - ""./data/volume/:/data/"" depends_on: - master filer: image: chrislusf/seaweedfs ports: - 9401:9401 # todo remove this port expose command: 'filer -master=""master:9333"" -port=9401 -dirListLimit 1000000' volumes: - ""./data/filer/:/data/filerldb2/"" depends_on: - master - volume redis: image: redis:5.0 ports: - 6379:6379 # todo remove this port expose  I'm using default filer.toml, but I think this have no relationship with filer. **Expected behavior** Start normally **Screenshots** These are logs repeately printed:   volume_1 | I1114 08:21:11 1 volume_grpc_client_to_master.go:68] Heartbeat to: master:9333 master_1 | I1114 08:21:11 1 node.go:241] topo:DefaultDataCenter:DefaultRack adds child 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:72] added volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 1 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 2 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 6 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 3 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 5 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 7 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 4 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:24] unregister disconnected volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 3 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 3 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 3 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 5 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 5 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 5 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 7 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 7 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 7 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 4 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 4 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 4 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 1 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 1 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 1 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 2 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 2 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 2 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 6 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 6 has 0 replica, less than required 1 volume_1 | I1114 08:21:11 1 volume_grpc_client_to_master.go:45] heartbeat error: rpc error: code = Unknown desc = Raft Server not initialized! master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 6 becomes unwritable master_1 | I1114 08:21:11 1 node.go:256] topo:DefaultDataCenter:DefaultRack removes 172.22.0.4:9301 master_1 | E1114 08:21:12 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! master_1 | I1114 08:21:12 1 masterclient.go:88] master failed to receive from 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | I1114 08:21:12 1 masterclient.go:116] master failed to connect with master 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:12 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! filer_1 | I1114 08:21:12 1 masterclient.go:88] filer failed to receive from master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:12 1 masterclient.go:116] filer failed to connect with master master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:13 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! master_1 | I1114 08:21:13 1 masterclient.go:88] master failed to receive from 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | I1114 08:21:13 1 masterclient.go:116] master failed to connect with master 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:13 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! filer_1 | I1114 08:21:13 1 masterclient.go:88] filer failed to receive from master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:13 1 masterclient.go:116] filer failed to connect with master master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:14 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! master_1 | I1114 08:21:14 1 masterclient.go:88] master failed to receive from 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | I1114 08:21:14 1 masterclient.go:116] master failed to connect with master 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:14 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! filer_1 | I1114 08:21:14 1 masterclient.go:88] filer failed to receive from master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:14 1 masterclient.go:116] filer failed to connect with master master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:15 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! master_1 | I1114 08:21:15 1 masterclient.go:88] master failed to receive from 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | I1114 08:21:15 1 masterclient.go:116] master failed to connect with master 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:15 1 masterclient.go:88] filer failed to receive from master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:15 1 masterclient.go:116] filer failed to connect with master master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:15 1 master_grpc_server.go:252] topo leader: Raft Server not initialized!   **Additional context** None for now",config-file | config-file | config-file | source-file,"WeedFS can't start normally caused by Raft Server fault. **Describe the bug** Some time server cannot start normally because of raft server may down? **System Setup** I started this server with docker-compose yaml version: '3' # weed/redis/'s exposed port is only for debug services: master: image: chrislusf/seaweedfs ports: - 9333:9333 # todo remove this port expose command: ""master -mdir /data"" volumes: - ""./data/meta/:/data/"" volume: image: chrislusf/seaweedfs ports: - 9301:9301 # todo remove this port expose command: 'volume -max=30 -mserver=""master:9333"" -port=9301' volumes: - ""./data/volume/:/data/"" depends_on: - master filer: image: chrislusf/seaweedfs ports: - 9401:9401 # todo remove this port expose command: 'filer -master=""master:9333"" -port=9401 -dirListLimit 1000000' volumes: - ""./data/filer/:/data/filerldb2/"" depends_on: - master - volume redis: image: redis:5.0 ports: - 6379:6379 # todo remove this port expose  I'm using default filer.toml, but I think this have no relationship with filer. **Expected behavior** Start normally **Screenshots** These are logs repeately printed:   volume_1 | I1114 08:21:11 1 volume_grpc_client_to_master.go:68] Heartbeat to: master:9333 master_1 | I1114 08:21:11 1 node.go:241] topo:DefaultDataCenter:DefaultRack adds child 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:72] added volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 1 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 2 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 6 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 3 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 5 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 7 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:102] master see new volume 4 from 172.22.0.4:9301 master_1 | I1114 08:21:11 1 master_grpc_server.go:24] unregister disconnected volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 3 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 3 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 3 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 5 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 5 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 5 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 7 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 7 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 7 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 4 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 4 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 4 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 1 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 1 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 1 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 2 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 2 has 0 replica, less than required 1 master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 2 becomes unwritable master_1 | I1114 08:21:11 1 topology_event_handling.go:57] Removing Volume 6 from the dead volume server 172.22.0.4:9301 master_1 | I1114 08:21:11 1 volume_layout.go:261] Volume 6 has 0 replica, less than required 1 volume_1 | I1114 08:21:11 1 volume_grpc_client_to_master.go:45] heartbeat error: rpc error: code = Unknown desc = Raft Server not initialized! master_1 | I1114 08:21:11 1 volume_layout.go:237] Volume 6 becomes unwritable master_1 | I1114 08:21:11 1 node.go:256] topo:DefaultDataCenter:DefaultRack removes 172.22.0.4:9301 master_1 | E1114 08:21:12 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! master_1 | I1114 08:21:12 1 masterclient.go:88] master failed to receive from 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | I1114 08:21:12 1 masterclient.go:116] master failed to connect with master 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:12 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! filer_1 | I1114 08:21:12 1 masterclient.go:88] filer failed to receive from master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:12 1 masterclient.go:116] filer failed to connect with master master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:13 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! master_1 | I1114 08:21:13 1 masterclient.go:88] master failed to receive from 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | I1114 08:21:13 1 masterclient.go:116] master failed to connect with master 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:13 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! filer_1 | I1114 08:21:13 1 masterclient.go:88] filer failed to receive from master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:13 1 masterclient.go:116] filer failed to connect with master master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:14 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! master_1 | I1114 08:21:14 1 masterclient.go:88] master failed to receive from 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | I1114 08:21:14 1 masterclient.go:116] master failed to connect with master 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:14 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! filer_1 | I1114 08:21:14 1 masterclient.go:88] filer failed to receive from master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:14 1 masterclient.go:116] filer failed to connect with master master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:15 1 master_grpc_server.go:252] topo leader: Raft Server not initialized! master_1 | I1114 08:21:15 1 masterclient.go:88] master failed to receive from 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | I1114 08:21:15 1 masterclient.go:116] master failed to connect with master 172.22.0.3:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:15 1 masterclient.go:88] filer failed to receive from master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader filer_1 | I1114 08:21:15 1 masterclient.go:116] filer failed to connect with master master:9333: rpc error: code = Unknown desc = raft.Server: Not current leader master_1 | E1114 08:21:15 1 master_grpc_server.go:252] topo leader: Raft Server not initialized!   **Additional context** None for now config-file config-file config-file source-file",no-bug,0.9
2246,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2246,Filer is not working properly with cassandra cluster,I have 3 nodes Cassandra cluster and it's used by a filer server. I have configured filer for super large directories. If I take one of the Cassandra nodes down then sometimes read request on filer does not find the requested file until I restart the filer. After restarting the filer it works normally with the two Cassandra nodes and can find the file.,other-file | other-file,Filer is not working properly with cassandra cluster I have 3 nodes Cassandra cluster and it's used by a filer server. I have configured filer for super large directories. If I take one of the Cassandra nodes down then sometimes read request on filer does not find the requested file until I restart the filer. After restarting the filer it works normally with the two Cassandra nodes and can find the file. other-file other-file,no-bug,0.9
1802,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1802,Persistent connections to volume servers through FUSE,"I've got one question regarding FUSE mounts and connections to volume servers. As far as I could see on my server/s and from the code, retrieving or saving files to volume servers happens in dedicated HTTP requests. This is probably the case for all volume server operations. Would it not be possible to keep the connections alive all the time? Or have some kind of connection pooler that keeps a bunch of idle connections that can be reused? Making a new request each and every time is very expensive and adds a lot of overhead. It degrades the overall performance. Especially when the connections are also encrypted (TLS handshake..). Did I miss something or could this be a nice feature for SeaweedFS?",source-file | source-file | source-file | source-file | source-file | source-file,"Persistent connections to volume servers through FUSE I've got one question regarding FUSE mounts and connections to volume servers. As far as I could see on my server/s and from the code, retrieving or saving files to volume servers happens in dedicated HTTP requests. This is probably the case for all volume server operations. Would it not be possible to keep the connections alive all the time? Or have some kind of connection pooler that keeps a bunch of idle connections that can be reused? Making a new request each and every time is very expensive and adds a lot of overhead. It degrades the overall performance. Especially when the connections are also encrypted (TLS handshake..). Did I miss something or could this be a nice feature for SeaweedFS? source-file source-file source-file source-file source-file source-file",no-bug,0.9
6205,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6205,"""no space left"" when spreading ec shards leaves volume both sharded and normal","**Describe the bug** Sharding sometimes works and sometimes does not. I often see a single volume create the 14 shards and then try to spread them with a single volume server claiming there is no space even though the volume server has plenty of disk space. This one particular volume server is set to a max of 1 because I am planning on removing it. It currently has a single shard on it so maybe that makes it ""full"" but in that case why is another volume server trying to spread to it?  I1104 11:43:10.145247 master_server.go:321 executing: lock [] I1104 11:43:10.145705 master_server.go:321 executing: ec.encode [-fullPercent=95 -quietFor=1h] I1104 11:43:10.396301 volume_layout.go:232 volume 152 are not all writable I1104 11:43:10.396313 volume_layout.go:237 volume 152 remove from writable I1104 15:22:10.778653 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [6] I1104 15:22:26.611916 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [7] I1104 15:48:34.764194 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [5 13] I1104 15:48:35.749174 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [0 8] I1104 15:48:40.565509 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [1 9] I1104 15:49:57.006111 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [4 12] I1104 15:49:57.006668 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:16 DiskType: DestroyTime:0} I1104 15:49:57.021059 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:4096 DiskType: DestroyTime:0} I1104 15:49:57.022428 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:32 DiskType: DestroyTime:0} I1104 15:49:57.022588 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:8192 DiskType: DestroyTime:0} I1104 15:49:57.024654 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:64 DiskType: DestroyTime:0} I1104 15:49:57.026605 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:128 DiskType: DestroyTime:0} I1104 15:49:57.027818 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:1 DiskType: DestroyTime:0} I1104 15:49:57.028437 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:256 DiskType: DestroyTime:0} I1104 15:49:57.055166 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:2 DiskType: DestroyTime:0} I1104 15:49:57.055791 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:512 DiskType: DestroyTime:0} I1104 15:49:57.079995 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:8 DiskType: DestroyTime:0} I1104 15:49:57.080075 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:2048 DiskType: DestroyTime:0} I1104 15:49:57.108112 master_server.go:323 error: spread ec shards for volume 152 from weedvh8.bm:9334: copy 152.[2 10] weedvh8.bm:9334 => weedvd2.bm:9334 : rpc error: code = Unknown desc = no space left I1104 15:49:57.108146 master_server.go:321 executing: ec.rebuild [-force] I1104 15:49:57.109320 master_server.go:321 executing: ec.balance [-force] I1104 15:49:57.110767 master_server.go:321 executing: volume.deleteEmpty [-quietFor=24h -force] I1104 15:49:57.111379 master_server.go:321 executing: volume.balance [-force] I1104 15:50:12.113367 master_server.go:321 executing: volume.fix.replication [] I1104 15:50:27.119722 master_server.go:321 executing: s3.clean.uploads [-timeAgo=24h] I1104 15:50:27.121091 master_server.go:321 executing: unlock []  **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". `weed master -mdir=/root/weedmaster -ip=weedmb.bm -ip.bind=0.0.0.0 -port=9333 -metricsPort=9331 -volumeSizeLimitMB=250000 -volumePreallocate` `weed filer -master=weedmb.bm:9333 -ip=weedmb.bm -ip.bind=0.0.0.0 -port=9335 -metricsPort=9332 -defaultStoreDir=/root -ui.deleteDir=false` `weed volume -ip=weedvd2.bm -ip.bind=0.0.0.0 -mserver=weedmb.bm:9333 -port=9334 -metricsPort=9331 -disk hdd -dir=/mnt/weed -dir.idx=/root/weedvol -max 1` - OS version `6.8.12-3-pve #1 SMP PREEMPT_DYNAMIC PMX 6.8.12-3 (2024-10-23T11:41Z) x86_64 Linux` - output of weed version `version 8000GB 3.79 228946369cad29ee8edc07a42a2e0d218ba16d0b linux amd64` - if using filer, show the content of `filer.toml`  [filer.options] master = ""weedmb.bm:9333"" recursive_delete = false port = 9335 [filer.ui] deleteDir = false [leveldb2] enabled = true dir = ""/root/filerldb2"" ",source-file | source-file,"""no space left"" when spreading ec shards leaves volume both sharded and normal **Describe the bug** Sharding sometimes works and sometimes does not. I often see a single volume create the 14 shards and then try to spread them with a single volume server claiming there is no space even though the volume server has plenty of disk space. This one particular volume server is set to a max of 1 because I am planning on removing it. It currently has a single shard on it so maybe that makes it ""full"" but in that case why is another volume server trying to spread to it?  I1104 11:43:10.145247 master_server.go:321 executing: lock [] I1104 11:43:10.145705 master_server.go:321 executing: ec.encode [-fullPercent=95 -quietFor=1h] I1104 11:43:10.396301 volume_layout.go:232 volume 152 are not all writable I1104 11:43:10.396313 volume_layout.go:237 volume 152 remove from writable I1104 15:22:10.778653 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [6] I1104 15:22:26.611916 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [7] I1104 15:48:34.764194 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [5 13] I1104 15:48:35.749174 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [0 8] I1104 15:48:40.565509 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [1 9] I1104 15:49:57.006111 command_ec_common.go:98 weedvh8.bm:9334 ec volume 152 deletes shards [4 12] I1104 15:49:57.006668 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:16 DiskType: DestroyTime:0} I1104 15:49:57.021059 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:4096 DiskType: DestroyTime:0} I1104 15:49:57.022428 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:32 DiskType: DestroyTime:0} I1104 15:49:57.022588 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:8192 DiskType: DestroyTime:0} I1104 15:49:57.024654 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:64 DiskType: DestroyTime:0} I1104 15:49:57.026605 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:128 DiskType: DestroyTime:0} I1104 15:49:57.027818 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:1 DiskType: DestroyTime:0} I1104 15:49:57.028437 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:256 DiskType: DestroyTime:0} I1104 15:49:57.055166 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:2 DiskType: DestroyTime:0} I1104 15:49:57.055791 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:512 DiskType: DestroyTime:0} I1104 15:49:57.079995 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:8 DiskType: DestroyTime:0} I1104 15:49:57.080075 topology_ec.go:118 removing ec shard info:&{VolumeId:152 Collection: ShardBits:2048 DiskType: DestroyTime:0} I1104 15:49:57.108112 master_server.go:323 error: spread ec shards for volume 152 from weedvh8.bm:9334: copy 152.[2 10] weedvh8.bm:9334 => weedvd2.bm:9334 : rpc error: code = Unknown desc = no space left I1104 15:49:57.108146 master_server.go:321 executing: ec.rebuild [-force] I1104 15:49:57.109320 master_server.go:321 executing: ec.balance [-force] I1104 15:49:57.110767 master_server.go:321 executing: volume.deleteEmpty [-quietFor=24h -force] I1104 15:49:57.111379 master_server.go:321 executing: volume.balance [-force] I1104 15:50:12.113367 master_server.go:321 executing: volume.fix.replication [] I1104 15:50:27.119722 master_server.go:321 executing: s3.clean.uploads [-timeAgo=24h] I1104 15:50:27.121091 master_server.go:321 executing: unlock []  **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". `weed master -mdir=/root/weedmaster -ip=weedmb.bm -ip.bind=0.0.0.0 -port=9333 -metricsPort=9331 -volumeSizeLimitMB=250000 -volumePreallocate` `weed filer -master=weedmb.bm:9333 -ip=weedmb.bm -ip.bind=0.0.0.0 -port=9335 -metricsPort=9332 -defaultStoreDir=/root -ui.deleteDir=false` `weed volume -ip=weedvd2.bm -ip.bind=0.0.0.0 -mserver=weedmb.bm:9333 -port=9334 -metricsPort=9331 -disk hdd -dir=/mnt/weed -dir.idx=/root/weedvol -max 1` - OS version `6.8.12-3-pve #1 SMP PREEMPT_DYNAMIC PMX 6.8.12-3 (2024-10-23T11:41Z) x86_64 Linux` - output of weed version `version 8000GB 3.79 228946369cad29ee8edc07a42a2e0d218ba16d0b linux amd64` - if using filer, show the content of `filer.toml`  [filer.options] master = ""weedmb.bm:9333"" recursive_delete = false port = 9335 [filer.ui] deleteDir = false [leveldb2] enabled = true dir = ""/root/filerldb2""  source-file source-file",no-bug,0.9
4171,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4171,[shell] volume.check.disk loop on sync partially deleted files,"**Describe the bug** log script  volume.check.disk -v -syncDeleted -force: load collection bucket volume 2457 index size 1866976 from fast-volume-2:8080  load collection bucket volume 2457 index size 1874768 from fast-volume-0:8080  volume 2457 fast-volume-0:8080 has 110346 entries, fast-volume-2:8080 missed 0 and partially deleted 0 entries volume 2457 fast-volume-2:8080 has 110345 entries, fast-volume-0:8080 missed 0 and partially deleted 722 entries delete 2457,2a7a38009492a9ea00000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a380094928a8900000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a38009492823200000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a380094925b5f00000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a380094922d9c00000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a38009492047a00000000 fast-volume-2.:8080 => fast-volume-0.:8080  load collection trendyol-parser-bucket volume 2457 index size 1866976 from fast-volume-2:8080  load collection trendyol-parser-bucket volume 2457 index size 1874768 from fast-volume-0:8080  **System Setup**  weed v3.35  **Expected behavior** Synchronize once",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[shell] volume.check.disk loop on sync partially deleted files **Describe the bug** log script  volume.check.disk -v -syncDeleted -force: load collection bucket volume 2457 index size 1866976 from fast-volume-2:8080  load collection bucket volume 2457 index size 1874768 from fast-volume-0:8080  volume 2457 fast-volume-0:8080 has 110346 entries, fast-volume-2:8080 missed 0 and partially deleted 0 entries volume 2457 fast-volume-2:8080 has 110345 entries, fast-volume-0:8080 missed 0 and partially deleted 722 entries delete 2457,2a7a38009492a9ea00000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a380094928a8900000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a38009492823200000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a380094925b5f00000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a380094922d9c00000000 fast-volume-2.:8080 => fast-volume-0.:8080 delete 2457,2a7a38009492047a00000000 fast-volume-2.:8080 => fast-volume-0.:8080  load collection trendyol-parser-bucket volume 2457 index size 1866976 from fast-volume-2:8080  load collection trendyol-parser-bucket volume 2457 index size 1874768 from fast-volume-0:8080  **System Setup**  weed v3.35  **Expected behavior** Synchronize once source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
3607,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3607,[S3] SIGSEGV weed S3Options,"weed v 3.25 **Describe the bug**  /opt/seaweedfs/weed -v 5 -logdir=/var/log/seaweedfs/s3 s3 -filer=:8888 -allowEmptyFolder -config=/etc/seaweedfs/s3config.json I0906 11:30:12.359621 config.go:59 Reading security.toml from /etc/seaweedfs/security.toml I0906 11:30:12.365343 s3.go:172 S3 read filer buckets dir: /buckets I0906 11:30:12.365389 s3.go:179 connected to filer 10.152.2.45:8888 grpc address 10.152.2.45:18888 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1d36371] goroutine 1 [running]: github.com/seaweedfs/seaweedfs/weed/command.(*S3Options).startS3Server(0x3a835a0) /github/workspace/weed/command/s3.go:197 +0x551 github.com/seaweedfs/seaweedfs/weed/command.runS3(0x3a668f8?, {0xc000050150?, 0x3?, 0x3?}) /github/workspace/weed/command/s3.go:148 +0x69 main.main() /github/workspace/weed/weed.go:81 +0x38c  type S3Options.localFilerSocket not set",source-file | source-file,"[S3] SIGSEGV weed S3Options weed v 3.25 **Describe the bug**  /opt/seaweedfs/weed -v 5 -logdir=/var/log/seaweedfs/s3 s3 -filer=:8888 -allowEmptyFolder -config=/etc/seaweedfs/s3config.json I0906 11:30:12.359621 config.go:59 Reading security.toml from /etc/seaweedfs/security.toml I0906 11:30:12.365343 s3.go:172 S3 read filer buckets dir: /buckets I0906 11:30:12.365389 s3.go:179 connected to filer 10.152.2.45:8888 grpc address 10.152.2.45:18888 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1d36371] goroutine 1 [running]: github.com/seaweedfs/seaweedfs/weed/command.(*S3Options).startS3Server(0x3a835a0) /github/workspace/weed/command/s3.go:197 +0x551 github.com/seaweedfs/seaweedfs/weed/command.runS3(0x3a668f8?, {0xc000050150?, 0x3?, 0x3?}) /github/workspace/weed/command/s3.go:148 +0x69 main.main() /github/workspace/weed/weed.go:81 +0x38c  type S3Options.localFilerSocket not set source-file source-file",no-bug,0.9
830,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/830,"KeepConnected only checks once whether leader or not, causing rpc client get the outdated leader","Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Reproduce steps** 1. rpc client finds leader A through stream.Recv in masterclient.go > [seaweedfs/weed/wdclient/masterclient.go] > Line 66 in [masterclient.go](https://github.com/chrislusf/seaweedfs/blob/master/weed/wdclient/masterclient.go#L66)  if volumeLocation, err := stream.Recv(); err != nil {  2. instantly new leader B elected, however, rpc client is not aware of leader changing from A to B **Proposal** - Send heartbeat to rpc client in [master_grpc_server.go](https://github.com/chrislusf/seaweedfs/blob/master/weed/server/master_grpc_server.go#L175) to declare the leader.",source-file | source-file | source-file | source-file | source-file,"KeepConnected only checks once whether leader or not, causing rpc client get the outdated leader Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Reproduce steps** 1. rpc client finds leader A through stream.Recv in masterclient.go > [seaweedfs/weed/wdclient/masterclient.go] > Line 66 in [masterclient.go](https://github.com/chrislusf/seaweedfs/blob/master/weed/wdclient/masterclient.go#L66)  if volumeLocation, err := stream.Recv(); err != nil {  2. instantly new leader B elected, however, rpc client is not aware of leader changing from A to B **Proposal** - Send heartbeat to rpc client in [master_grpc_server.go](https://github.com/chrislusf/seaweedfs/blob/master/weed/server/master_grpc_server.go#L175) to declare the leader. source-file source-file source-file source-file source-file",no-bug,0.9
2023,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2023,[Feature Request] Excluded name patterns in Filer folder listing,"Currently there is only ""namePattern"" parameter in files listing under a directory. It would be nice to have an ""excludedNamePattern"" parameter to exclude some files/folders from listing. I am planning to store some custom meta files alongside normal files and I don't want to see them in folder listing sometimes. Also it's just extra data that is being sent over http and is adding some delay.",source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file,"[Feature Request] Excluded name patterns in Filer folder listing Currently there is only ""namePattern"" parameter in files listing under a directory. It would be nice to have an ""excludedNamePattern"" parameter to exclude some files/folders from listing. I am planning to store some custom meta files alongside normal files and I don't want to see them in folder listing sometimes. Also it's just extra data that is being sent over http and is adding some delay. source-file source-file source-file source-file test-file test-file test-file test-file source-file source-file source-file",no-bug,0.9
2514,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2514,"Error ""volId 0 err"" Volumes couldn't load after upgrading to 2.82_large_disk","Hi, I upgrade my cluster from 2.40_large_disk to 2.82_large_disk Now there are two types and with many errors logged by weed that volumes couldn't load properly!: Type 1 error:  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking MegaGroup_59.dat  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 0 err (0x282caa0,0xc008df62d0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking MegaGroup_59.idx  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 59 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking MegaGroup_59.vif  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 59 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking Profile_39.dat  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 0 err (0x282caa0,0xc008df62f0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking Profile_39.idx  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 39 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking Profile_39.vif  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 39 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_100_241.dat  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 0 err (0x282caa0,0xc008df6310) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_100_241.idx  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 241 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_100_241.vif  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 241 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_288.dat  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 0 err (0x282caa0,0xc00064c260) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_288.idx  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 288 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_288.vif  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 288 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_94.dat  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 0 err (0x282caa0,0xc00064c280) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_94.idx  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 94 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_94.vif  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 94 err (0x0,0x0)  Type 2 :  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_10_283.dat  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 0 err (0x282caa0,0xc008df6330) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_10_283.idx  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 283 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 volume_loading.go:89] readSuperBlock volume 283 version 3 Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 volume_loading.go:136] loading index /srv/node/sdb/UserCloud_10_283.idx to memory Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 disk_location.go:140] data file /srv/node/sdb/UserCloud_10_283.dat, replication=010 v=3 size=107386792320 ttl= Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 store.go:402] mount volume 283 Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 volume_grpc_client_to_master.go:158] volume server weed-volume-001:8080 adds volume 283 b: Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_95.dat  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 0 err (0x282caa0,0xc00064c2a0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_95.idx  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 95 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 volume_loading.go:89] readSuperBlock volume 95 version 3 Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 volume_loading.go:136] loading index /srv/node/sdk/UserCloud_10_95.idx to memory Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 disk_location.go:140] data file /srv/node/sdk/UserCloud_10_95.dat, replication=010 v=3 size=107380026088 ttl= Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 store.go:402] mount volume 95 Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 volume_grpc_client_to_master.go:158] volume server weed-volume-001:8089 adds volume 95  What do these errors mean? Why they couldn't be loaded properly?",source-file | source-file,"Error ""volId 0 err"" Volumes couldn't load after upgrading to 2.82_large_disk Hi, I upgrade my cluster from 2.40_large_disk to 2.82_large_disk Now there are two types and with many errors logged by weed that volumes couldn't load properly!: Type 1 error:  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking MegaGroup_59.dat  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 0 err (0x282caa0,0xc008df62d0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking MegaGroup_59.idx  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 59 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking MegaGroup_59.vif  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 59 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking Profile_39.dat  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 0 err (0x282caa0,0xc008df62f0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking Profile_39.idx  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 39 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking Profile_39.vif  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 39 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_100_241.dat  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 0 err (0x282caa0,0xc008df6310) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_100_241.idx  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 241 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_100_241.vif  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 241 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_288.dat  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 0 err (0x282caa0,0xc00064c260) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_288.idx  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 288 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_288.vif  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 288 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_94.dat  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 0 err (0x282caa0,0xc00064c280) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_94.idx  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 94 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_94.vif  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 94 err (0x0,0x0)  Type 2 :  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_10_283.dat  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 0 err (0x282caa0,0xc008df6330) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: checking UserCloud_10_283.idx  Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: volId 283 err (0x0,0x0) Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 volume_loading.go:89] readSuperBlock volume 283 version 3 Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 volume_loading.go:136] loading index /srv/node/sdb/UserCloud_10_283.idx to memory Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 disk_location.go:140] data file /srv/node/sdb/UserCloud_10_283.dat, replication=010 v=3 size=107386792320 ttl= Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 store.go:402] mount volume 283 Dec 16 00:25:47 weed-volume-001 seaweedfs-sdb-volume[1548]: I1216 00:25:47 1548 volume_grpc_client_to_master.go:158] volume server weed-volume-001:8080 adds volume 283 b: Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_95.dat  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 0 err (0x282caa0,0xc00064c2a0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: checking UserCloud_10_95.idx  Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: volId 95 err (0x0,0x0) Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 volume_loading.go:89] readSuperBlock volume 95 version 3 Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 volume_loading.go:136] loading index /srv/node/sdk/UserCloud_10_95.idx to memory Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 disk_location.go:140] data file /srv/node/sdk/UserCloud_10_95.dat, replication=010 v=3 size=107380026088 ttl= Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 store.go:402] mount volume 95 Dec 16 07:09:42 weed-volume-001 seaweedfs-sdk-volume[1541]: I1216 07:09:42 1541 volume_grpc_client_to_master.go:158] volume server weed-volume-001:8089 adds volume 95  What do these errors mean? Why they couldn't be loaded properly? source-file source-file",no-bug,0.8
3528,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3528,"How to fix ""fail to load vif"" during volume.configure.replication","I have all my 14 HDD on one machine. I initially set each of them as if it belongs to a separate rack, and I set the replication to 020. Later, under the assumption that it might hinder performance, I decided to move them all to a single rack. Then in an attempt to fix the replication, I executed volume.configure.replication -collectionPattern * -replication 002 Unfortunately, it ended in a particular error. error: volume configure volume_id:370 replication:""002"": volume 370 fail to load vif I cannot find much information about it. any ideas on how to fix it?",source-file | source-file | source-file | source-file | source-file,"How to fix ""fail to load vif"" during volume.configure.replication I have all my 14 HDD on one machine. I initially set each of them as if it belongs to a separate rack, and I set the replication to 020. Later, under the assumption that it might hinder performance, I decided to move them all to a single rack. Then in an attempt to fix the replication, I executed volume.configure.replication -collectionPattern * -replication 002 Unfortunately, it ended in a particular error. error: volume configure volume_id:370 replication:""002"": volume 370 fail to load vif I cannot find much information about it. any ideas on how to fix it? source-file source-file source-file source-file source-file",no-bug,0.9
4460,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4460,There is a problem with the master election,"**Describe the bug** bug introduced by https://github.com/seaweedfs/seaweedfs/commit/4511edc8717b1f54f23469ca0ad20d199c2db2eb <img width=""1317"" alt=""_aa59c0cc-81df-46df-8856-4fd3a564e9a3"" src=""https://user-images.githubusercontent.com/48707349/236995426-d74050ea-9068-4080-9feb-452c3839496d.png""> Since raft.GrpcServer is not anonymously nested weed_raft. RaftServer structure, so weed_raft. The RaftServer is no longer inherited to raft.GrpcServer. When called based on grpc, the error ""method xx not implemented"" is returned. <img width=""1049"" alt=""image"" src=""https://user-images.githubusercontent.com/48707349/236995650-e9c6ebfa-1ca0-46a5-9b6c-c0bda59f3b79.png"">",other-file | source-file,"There is a problem with the master election **Describe the bug** bug introduced by https://github.com/seaweedfs/seaweedfs/commit/4511edc8717b1f54f23469ca0ad20d199c2db2eb <img width=""1317"" alt=""_aa59c0cc-81df-46df-8856-4fd3a564e9a3"" src=""https://user-images.githubusercontent.com/48707349/236995426-d74050ea-9068-4080-9feb-452c3839496d.png""> Since raft.GrpcServer is not anonymously nested weed_raft. RaftServer structure, so weed_raft. The RaftServer is no longer inherited to raft.GrpcServer. When called based on grpc, the error ""method xx not implemented"" is returned. <img width=""1049"" alt=""image"" src=""https://user-images.githubusercontent.com/48707349/236995650-e9c6ebfa-1ca0-46a5-9b6c-c0bda59f3b79.png""> other-file source-file",no-bug,0.8
82,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/82,get content type error,"hi, I use weed-fs 1 years ago. It is an old version [0.45] of weed. I post an image to weedfs, then I get it from browser , It will display correctly. curl -F file=@/home/chris/myphoto.jpg http://localhost:9333/submit when I use 0.67 of weed. I do the same post, But the same images cannot display in the browser correctly. It cannot display then do download in the chrome. what is wrong about the weed version up? How can I config to this get header output ? please help me.",config-file | config-file | config-file | config-file | config-file | config-file | config-file | config-file | config-file | config-file | documentation-file | container-file | other-file | other-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | other-file | config-file | other-file | config-file | source-file | source-file | source-file | source-file | source-file | other-file | config-file | config-file | config-file | source-file | source-file | config-file | config-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | other-file | source-file | test-file | source-file | source-file | source-file,"get content type error hi, I use weed-fs 1 years ago. It is an old version [0.45] of weed. I post an image to weedfs, then I get it from browser , It will display correctly. curl -F file=@/home/chris/myphoto.jpg http://localhost:9333/submit when I use 0.67 of weed. I do the same post, But the same images cannot display in the browser correctly. It cannot display then do download in the chrome. what is wrong about the weed version up? How can I config to this get header output ? please help me. config-file config-file config-file config-file config-file config-file config-file config-file config-file config-file documentation-file container-file other-file other-file other-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file other-file config-file other-file config-file source-file source-file source-file source-file source-file other-file config-file config-file config-file source-file source-file config-file config-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file test-file test-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file other-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file test-file source-file source-file other-file source-file test-file source-file source-file source-file",bug,0.85
1108,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1108,timeouts from volume-server while doing GC,"**Describe the bug** Getting timeout over 10 seconds from volumeserver while doing GC **System Setup**  /usr/local/bin/weed -logtostderr master -mdir=/mnt/data01/meta -ip=10.1.21.17 -defaultReplication=010 -volumePreallocate -volumeSizeLimitMB 30000 -pulseSeconds 10 -peers=10.1.21.17:9333,10.1.21.18:9333,10.1.21.19:9333 /usr/local/bin/weed -logtostderr -v=1 volume -port=8080 -mserver=10.1.21.17:9333,10.1.21.18:9333,10.1.21.19:9333 -dir=/mnt/data01/data,/mnt/data02/data -index leveldb -max 3866,3866 -ip 10.1.21.17 -rack photol-107  - OS version: Ubuntu 16.04 - output of `weed version`: version 30GB 1.44 linux amd64 **Expected behavior** Do not get highly reduced performance while doing GC **Screenshots** https://www.jottacloud.com/s/006d6b606b06d544986b1cdd288d7a3524d **Logs** Logs from the volume server shows alot of log and a broken pipe in the periods of timeout: https://gist.github.com/roflmao/5f27a6944c8ab25deb521e65bde675b2 **Additional context** GC by:  $ curl ""http://localhost:9333/vol/vacuum?garbageThreshold=0.05"" ",source-file | source-file | source-file | source-file | test-file,"timeouts from volume-server while doing GC **Describe the bug** Getting timeout over 10 seconds from volumeserver while doing GC **System Setup**  /usr/local/bin/weed -logtostderr master -mdir=/mnt/data01/meta -ip=10.1.21.17 -defaultReplication=010 -volumePreallocate -volumeSizeLimitMB 30000 -pulseSeconds 10 -peers=10.1.21.17:9333,10.1.21.18:9333,10.1.21.19:9333 /usr/local/bin/weed -logtostderr -v=1 volume -port=8080 -mserver=10.1.21.17:9333,10.1.21.18:9333,10.1.21.19:9333 -dir=/mnt/data01/data,/mnt/data02/data -index leveldb -max 3866,3866 -ip 10.1.21.17 -rack photol-107  - OS version: Ubuntu 16.04 - output of `weed version`: version 30GB 1.44 linux amd64 **Expected behavior** Do not get highly reduced performance while doing GC **Screenshots** https://www.jottacloud.com/s/006d6b606b06d544986b1cdd288d7a3524d **Logs** Logs from the volume server shows alot of log and a broken pipe in the periods of timeout: https://gist.github.com/roflmao/5f27a6944c8ab25deb521e65bde675b2 **Additional context** GC by:  $ curl ""http://localhost:9333/vol/vacuum?garbageThreshold=0.05""  source-file source-file source-file source-file test-file",no-bug,0.9
2129,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2129,[volume.check.disk] terminates at EOF,"**Describe the bug**  volume.check.disk volume 443 slow-volume-4.dc2:8080 has 11702 entries, slow-volume-15.dc1:8080 missed 1 entries error: rpc error: code = Unknown desc = read needle blob offset 51138467160 size 8185007: EOF  **System Setup**  version 8000GB 2.50 f15d7a57 linux amd64  **Expected behavior** skip errors and check next volumes",source-file,"[volume.check.disk] terminates at EOF **Describe the bug**  volume.check.disk volume 443 slow-volume-4.dc2:8080 has 11702 entries, slow-volume-15.dc1:8080 missed 1 entries error: rpc error: code = Unknown desc = read needle blob offset 51138467160 size 8185007: EOF  **System Setup**  version 8000GB 2.50 f15d7a57 linux amd64  **Expected behavior** skip errors and check next volumes source-file",no-bug,0.9
5681,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5681,helm chart: resources should be a map,"**Describe the bug** `resources` should be maps, and not strings for the helm chart. You can verify this is the default and recommended by creating a default chart: console $ helm create testing123 Creating testing123 $ cd testing123 $ grep -A 7 resources values.yaml resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 100m # memory: 128Mi # requests: # cpu: 100m # memory: 128Mi  Here's an example in the values.yaml: https://github.com/seaweedfs/seaweedfs/blob/d87f88418696f72a752779b6ce776d216f5e61d1/k8s/charts/seaweedfs/values.yaml#L596 And here's the corresponding template: https://github.com/seaweedfs/seaweedfs/blob/d87f88418696f72a752779b6ce776d216f5e61d1/k8s/charts/seaweedfs/templates/filer-statefulset.yaml#L272-L275 But this is present for all of the following templates: - templates/filer-statefulset.yaml - templates/master-statefulset.yaml - templates/s3-deployment.yaml - templates/volume-statefulset.yaml We need to fix this, and I'll submit a PR to fix that to be consistent, but also because it breaks syntax highlighting to have them be strings. See example when using the string vs a map: yaml resources: |- limits: cpu: 100m memory: 128Mi requests: cpu: 100m memory: 128Mi  **System Setup** This is the helm chart version pushed out with this release: https://github.com/seaweedfs/seaweedfs/releases/tag/3.68 **Expected behavior** Resources should be declared as mentioned above as maps `{}` instead of strings `""""` or null. yaml resources: limits: cpu: 100m memory: 128Mi requests: cpu: 100m memory: 128Mi ",documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file,"helm chart: resources should be a map **Describe the bug** `resources` should be maps, and not strings for the helm chart. You can verify this is the default and recommended by creating a default chart: console $ helm create testing123 Creating testing123 $ cd testing123 $ grep -A 7 resources values.yaml resources: {} # We usually recommend not to specify default resources and to leave this as a conscious # choice for the user. This also increases chances charts run on environments with little # resources, such as Minikube. If you do want to specify resources, uncomment the following # lines, adjust them as necessary, and remove the curly braces after 'resources:'. # limits: # cpu: 100m # memory: 128Mi # requests: # cpu: 100m # memory: 128Mi  Here's an example in the values.yaml: https://github.com/seaweedfs/seaweedfs/blob/d87f88418696f72a752779b6ce776d216f5e61d1/k8s/charts/seaweedfs/values.yaml#L596 And here's the corresponding template: https://github.com/seaweedfs/seaweedfs/blob/d87f88418696f72a752779b6ce776d216f5e61d1/k8s/charts/seaweedfs/templates/filer-statefulset.yaml#L272-L275 But this is present for all of the following templates: - templates/filer-statefulset.yaml - templates/master-statefulset.yaml - templates/s3-deployment.yaml - templates/volume-statefulset.yaml We need to fix this, and I'll submit a PR to fix that to be consistent, but also because it breaks syntax highlighting to have them be strings. See example when using the string vs a map: yaml resources: |- limits: cpu: 100m memory: 128Mi requests: cpu: 100m memory: 128Mi  **System Setup** This is the helm chart version pushed out with this release: https://github.com/seaweedfs/seaweedfs/releases/tag/3.68 **Expected behavior** Resources should be declared as mentioned above as maps `{}` instead of strings `""""` or null. yaml resources: limits: cpu: 100m memory: 128Mi requests: cpu: 100m memory: 128Mi  documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file",no-bug,0.9
2242,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2242,[iam] error get update identity,"IAM identity is not updating on one instance version `2.53` before  I0811 03:40:22 1 meta_aggregator.go:152] subscribing remote 172.18.232.217:9090 meta change: rpc error: code = Unavailable desc = transport is closing E0811 03:40:22 1 auth_credentials_subscribe.go:66] subscribing filer meta change: rpc error: code = Unavailable desc = transport is closing I0811 03:40:23 1 filer_grpc_server_sub_meta.go:196] + listener s3@172.18.232.217:37708 I0811 03:40:23 1 filer_grpc_server_sub_meta.go:26] s3@172.18.232.217:37708 starts to subscribe /etc/iam/identity.json from 2021-08-09 06:57:45.508029017 +0000 UTC I0811 03:40:23 1 filer_grpc_server_sub_meta.go:196] + listener filer:172.18.232.217:9090@172.18.232.217:37708 I0811 03:40:23 1 filer_grpc_server_sub_meta.go:77] filer:172.18.232.217:9090@172.18.232.217:37708 local subscribe / from 2021-08-11 03:38:52.254300709 +0000 UTC I0811 03:40:35 1 filer_grpc_server_sub_meta.go:187] => client filer:172.18.232.217:9090@172.18.232.217:60564: rpc error: code = Unavailable desc = transport is closing E0811 03:40:35 1 filer_grpc_server_sub_meta.go:110] processed to 2021-08-11 03:40:35.126790442 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 03:40:38 1 filer_grpc_server_sub_meta.go:201] - listener filer:172.18.232.217:9090@172.18.232.217:60564  on update  I0811 05:26:11 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.232.217:45910: rpc error: code = Unavailable desc = transport is closing E0811 05:26:11 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-11 05:26:11.442961129 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 05:26:11 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.232.217:60564: rpc error: code = Unavailable desc = transport is closing E0811 05:26:11 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-11 05:26:11.442961129 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 05:26:11 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.232.217:41886: rpc error: code = Unavailable desc = transport is closing E0811 05:26:11 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-11 05:26:11.442961129 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 05:26:11 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.232.217:44356: rpc error: code = Unavailable desc = transport is closing E0811 05:26:11 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-11 05:26:11.442961129 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 05:26:11 1 auth_credentials_subscribe.go:31] updated /etc/iam/identity.json I0811 05:26:14 1 filer_grpc_server_sub_meta.go:201] - listener s3@172.18.232.217:45910 I0811 05:26:14 1 filer_grpc_server_sub_meta.go:201] - listener s3@172.18.232.217:60564 I0811 05:26:14 1 filer_grpc_server_sub_meta.go:201] - listener s3@172.18.232.217:41886 I0811 05:26:14 1 filer_grpc_server_sub_meta.go:201] - listener s3@172.18.232.217:44356  run weed shell s3.configure  0809 04:33:25 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-09 04:33:25.15237125 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0809 04:33:25 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.156.171:32922: rpc error: code = Unavailable desc = transport is closing E0809 04:33:25 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-09 04:33:25.15237125 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0809 04:33:25 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.156.171:51282: rpc error: code = Unavailable desc = transport is closing E0809 04:33:25 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-09 04:33:25.15237125 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0809 04:33:25 1 auth_credentials_subscribe.go:31] updated /etc/iam/identity.json  IP 172.18.232.217 is local address restart didn't help  I0809 06:57:42 1 meta_aggregator.go:67] connecting to peer filer 172.18.232.217:9090: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 172.18.232.217:19090: connect: connection refused""  diagnostic  nc -vz 172.18.232.217 19090 172.18.232.217 (172.18.232.217:19090) open ",source-file | source-file | source-file,"[iam] error get update identity IAM identity is not updating on one instance version `2.53` before  I0811 03:40:22 1 meta_aggregator.go:152] subscribing remote 172.18.232.217:9090 meta change: rpc error: code = Unavailable desc = transport is closing E0811 03:40:22 1 auth_credentials_subscribe.go:66] subscribing filer meta change: rpc error: code = Unavailable desc = transport is closing I0811 03:40:23 1 filer_grpc_server_sub_meta.go:196] + listener s3@172.18.232.217:37708 I0811 03:40:23 1 filer_grpc_server_sub_meta.go:26] s3@172.18.232.217:37708 starts to subscribe /etc/iam/identity.json from 2021-08-09 06:57:45.508029017 +0000 UTC I0811 03:40:23 1 filer_grpc_server_sub_meta.go:196] + listener filer:172.18.232.217:9090@172.18.232.217:37708 I0811 03:40:23 1 filer_grpc_server_sub_meta.go:77] filer:172.18.232.217:9090@172.18.232.217:37708 local subscribe / from 2021-08-11 03:38:52.254300709 +0000 UTC I0811 03:40:35 1 filer_grpc_server_sub_meta.go:187] => client filer:172.18.232.217:9090@172.18.232.217:60564: rpc error: code = Unavailable desc = transport is closing E0811 03:40:35 1 filer_grpc_server_sub_meta.go:110] processed to 2021-08-11 03:40:35.126790442 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 03:40:38 1 filer_grpc_server_sub_meta.go:201] - listener filer:172.18.232.217:9090@172.18.232.217:60564  on update  I0811 05:26:11 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.232.217:45910: rpc error: code = Unavailable desc = transport is closing E0811 05:26:11 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-11 05:26:11.442961129 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 05:26:11 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.232.217:60564: rpc error: code = Unavailable desc = transport is closing E0811 05:26:11 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-11 05:26:11.442961129 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 05:26:11 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.232.217:41886: rpc error: code = Unavailable desc = transport is closing E0811 05:26:11 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-11 05:26:11.442961129 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 05:26:11 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.232.217:44356: rpc error: code = Unavailable desc = transport is closing E0811 05:26:11 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-11 05:26:11.442961129 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0811 05:26:11 1 auth_credentials_subscribe.go:31] updated /etc/iam/identity.json I0811 05:26:14 1 filer_grpc_server_sub_meta.go:201] - listener s3@172.18.232.217:45910 I0811 05:26:14 1 filer_grpc_server_sub_meta.go:201] - listener s3@172.18.232.217:60564 I0811 05:26:14 1 filer_grpc_server_sub_meta.go:201] - listener s3@172.18.232.217:41886 I0811 05:26:14 1 filer_grpc_server_sub_meta.go:201] - listener s3@172.18.232.217:44356  run weed shell s3.configure  0809 04:33:25 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-09 04:33:25.15237125 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0809 04:33:25 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.156.171:32922: rpc error: code = Unavailable desc = transport is closing E0809 04:33:25 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-09 04:33:25.15237125 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0809 04:33:25 1 filer_grpc_server_sub_meta.go:187] => client s3@172.18.156.171:51282: rpc error: code = Unavailable desc = transport is closing E0809 04:33:25 1 filer_grpc_server_sub_meta.go:56] processed to 2021-08-09 04:33:25.15237125 +0000 UTC: rpc error: code = Unavailable desc = transport is closing I0809 04:33:25 1 auth_credentials_subscribe.go:31] updated /etc/iam/identity.json  IP 172.18.232.217 is local address restart didn't help  I0809 06:57:42 1 meta_aggregator.go:67] connecting to peer filer 172.18.232.217:9090: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 172.18.232.217:19090: connect: connection refused""  diagnostic  nc -vz 172.18.232.217 19090 172.18.232.217 (172.18.232.217:19090) open  source-file source-file source-file",no-bug,0.9
5710,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5710,Security Vulnerability Report,"Security Vulnerability Report I'm from Yunding Security Lab of Tencent. I have discovered a sql injection vulnerability in the SeaweedFS project. Given that I have posted the vulnerability details in a GitHub issue, I recommend that you fix it as soon as possible. SQL injection can be prevented by using parameterized queries, filtering, or restricting input. # Code The cause of the vulnerability is that the user input is spliced into the SQL statement. Affect SeaweedFS Filer Server, when use mysql as filemeta database. Affect File: `weed/filer/abstract_sql/abstract_sql_store.go` Affect Object: AbstractSqlStore Affect Method is below. `select` injection can cause serious issues, while `DROP`, `CREATE` and `DELETE` have relatively smaller impacts. - FindEntry go func (gen *SqlGenMysql) GetSqlFind(tableName string) string { return fmt.Sprintf(""SELECT `meta` FROM `%s` WHERE `dirhash` = ? AND `name` = ? AND `directory` = ?"", tableName) }  - ListDirectoryPrefixedEntries go func (gen *SqlGenMysql) GetSqlListExclusive(tableName string) string { return fmt.Sprintf(""SELECT `name`, `meta` FROM `%s` WHERE `dirhash` = ? AND `name` > ? AND `directory` = ? AND `name` LIKE ? ORDER BY `name` ASC LIMIT ?"", tableName) }  - CreateTable go func (gen *SqlGenMysql) GetSqlCreateTable(tableName string) string { return fmt.Sprintf(gen.CreateTableSqlTemplate, tableName) }  - DeleteEntry go func (gen *SqlGenMysql) GetSqlDelete(tableName string) string { return fmt.Sprintf(""DELETE FROM `%s` WHERE `dirhash` = ? AND `name` = ? AND `directory` = ?"", tableName) }  - deleteTable go func (gen *SqlGenMysql) GetSqlDropTable(tableName string) string { return fmt.Sprintf(gen.DropTableSqlTemplate, tableName) }  # Proof of Concept Next, I will demonstrate the existence of the vulnerability. The following proof targets the actual impact location, which is `AbstractSqlStore.ListDirectoryPrefixedEntries`. My `filer.toml` content is: toml [mysql2] # or memsql, tidb enabled = true createTable =  CREATE TABLE IF NOT EXISTS `%s` ( `dirhash` BIGINT NOT NULL, `name` VARCHAR(766) NOT NULL, `directory` TEXT NOT NULL, `meta` LONGBLOB, PRIMARY KEY (`dirhash`, `name`) ) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;  hostname = ""127.0.0.1"" port = 3309 username = ""root"" password = ""xxxxx"" database = ""seaweedfs"" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 connection_max_lifetime_seconds = 0 interpolateParams = false # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO `%s` (`dirhash`,`name`,`directory`,`meta`) VALUES (?,?,?,?) AS `new` ON DUPLICATE KEY UPDATE `meta` = `new`.`meta`  My test mysql database user is `root`, so `ascii(mid(user() from 1 for 1))=114`. Follow the steps below. 1. Create a new folder with name `poc` in `buckets`, this make database table `poc` is exist. 2. Create a new folder in `buckets` with name  poc` WHERE (IF(ascii(mid(user() from 1 for 1))=114, exp(710), 0)) and 1=? and 1=? and 1=? and 1=? and 1=?; #  3. Create a new folder in `buckets` with name  poc` WHERE (IF(ascii(mid(user() from 1 for 1))=124, exp(710), 0)) and 1=? and 1=? and 1=? and 1=? and 1=?; #  4. Visit folder below, it will return 404 with error, because `exp(710)`  poc` WHERE (IF(ascii(mid(user() from 1 for 1))=114, exp(710), 0)) and 1=? and 1=? and 1=? and 1=? and 1=?; #  5. Visit folder below, it will return 200.  poc` WHERE (IF(ascii(mid(user() from 1 for 1))=124, exp(710), 0)) and 1=? and 1=? and 1=? and 1=? and 1=?; #  ![_17192984751443](https://github.com/seaweedfs/seaweedfs/assets/16025404/fb37f4ac-0085-46dc-a4d3-6a0ccbd481a4) ![_17192987017146](https://github.com/seaweedfs/seaweedfs/assets/16025404/8276d49d-b884-4f65-b5d1-c2d0dfa22751) ![_17192987152401](https://github.com/seaweedfs/seaweedfs/assets/16025404/b9859974-a056-485c-bb9e-f454a02d70e1)",source-file,"Security Vulnerability Report Security Vulnerability Report I'm from Yunding Security Lab of Tencent. I have discovered a sql injection vulnerability in the SeaweedFS project. Given that I have posted the vulnerability details in a GitHub issue, I recommend that you fix it as soon as possible. SQL injection can be prevented by using parameterized queries, filtering, or restricting input. # Code The cause of the vulnerability is that the user input is spliced into the SQL statement. Affect SeaweedFS Filer Server, when use mysql as filemeta database. Affect File: `weed/filer/abstract_sql/abstract_sql_store.go` Affect Object: AbstractSqlStore Affect Method is below. `select` injection can cause serious issues, while `DROP`, `CREATE` and `DELETE` have relatively smaller impacts. - FindEntry go func (gen *SqlGenMysql) GetSqlFind(tableName string) string { return fmt.Sprintf(""SELECT `meta` FROM `%s` WHERE `dirhash` = ? AND `name` = ? AND `directory` = ?"", tableName) }  - ListDirectoryPrefixedEntries go func (gen *SqlGenMysql) GetSqlListExclusive(tableName string) string { return fmt.Sprintf(""SELECT `name`, `meta` FROM `%s` WHERE `dirhash` = ? AND `name` > ? AND `directory` = ? AND `name` LIKE ? ORDER BY `name` ASC LIMIT ?"", tableName) }  - CreateTable go func (gen *SqlGenMysql) GetSqlCreateTable(tableName string) string { return fmt.Sprintf(gen.CreateTableSqlTemplate, tableName) }  - DeleteEntry go func (gen *SqlGenMysql) GetSqlDelete(tableName string) string { return fmt.Sprintf(""DELETE FROM `%s` WHERE `dirhash` = ? AND `name` = ? AND `directory` = ?"", tableName) }  - deleteTable go func (gen *SqlGenMysql) GetSqlDropTable(tableName string) string { return fmt.Sprintf(gen.DropTableSqlTemplate, tableName) }  # Proof of Concept Next, I will demonstrate the existence of the vulnerability. The following proof targets the actual impact location, which is `AbstractSqlStore.ListDirectoryPrefixedEntries`. My `filer.toml` content is: toml [mysql2] # or memsql, tidb enabled = true createTable =  CREATE TABLE IF NOT EXISTS `%s` ( `dirhash` BIGINT NOT NULL, `name` VARCHAR(766) NOT NULL, `directory` TEXT NOT NULL, `meta` LONGBLOB, PRIMARY KEY (`dirhash`, `name`) ) DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin;  hostname = ""127.0.0.1"" port = 3309 username = ""root"" password = ""xxxxx"" database = ""seaweedfs"" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 connection_max_lifetime_seconds = 0 interpolateParams = false # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO `%s` (`dirhash`,`name`,`directory`,`meta`) VALUES (?,?,?,?) AS `new` ON DUPLICATE KEY UPDATE `meta` = `new`.`meta`  My test mysql database user is `root`, so `ascii(mid(user() from 1 for 1))=114`. Follow the steps below. 1. Create a new folder with name `poc` in `buckets`, this make database table `poc` is exist. 2. Create a new folder in `buckets` with name  poc` WHERE (IF(ascii(mid(user() from 1 for 1))=114, exp(710), 0)) and 1=? and 1=? and 1=? and 1=? and 1=?; #  3. Create a new folder in `buckets` with name  poc` WHERE (IF(ascii(mid(user() from 1 for 1))=124, exp(710), 0)) and 1=? and 1=? and 1=? and 1=? and 1=?; #  4. Visit folder below, it will return 404 with error, because `exp(710)`  poc` WHERE (IF(ascii(mid(user() from 1 for 1))=114, exp(710), 0)) and 1=? and 1=? and 1=? and 1=? and 1=?; #  5. Visit folder below, it will return 200.  poc` WHERE (IF(ascii(mid(user() from 1 for 1))=124, exp(710), 0)) and 1=? and 1=? and 1=? and 1=? and 1=?; #  ![_17192984751443](https://github.com/seaweedfs/seaweedfs/assets/16025404/fb37f4ac-0085-46dc-a4d3-6a0ccbd481a4) ![_17192987017146](https://github.com/seaweedfs/seaweedfs/assets/16025404/8276d49d-b884-4f65-b5d1-c2d0dfa22751) ![_17192987152401](https://github.com/seaweedfs/seaweedfs/assets/16025404/b9859974-a056-485c-bb9e-f454a02d70e1) source-file",no-bug,0.9
777,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/777,Filer  , weaweedfs  0.94 . Filer Cassandra BUG Cassandra feature?,source-file | source-file | source-file,Filer    weaweedfs  0.94 . Filer Cassandra BUG Cassandra feature? source-file source-file source-file,no-bug,0.3
2942,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2942,Support storage on YBD,https://ydb.tech/ https://github.com/ydb-platform/ydb-go-sdk,config-file | documentation-file | source-file | source-file | source-file,Support storage on YBD https://ydb.tech/ https://github.com/ydb-platform/ydb-go-sdk config-file documentation-file source-file source-file source-file,no-bug,0.8
1494,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1494,hadoop: filesystem cannot create file," spark-submithistoryseaweedfslogfiler  ./spark-submit \ --name spark-pi \ --class org.apache.spark.examples.SparkPi \ --conf spark.jars.ivy=/tmp/.ivy \ --conf spark.eventLog.enabled=true \ --conf spark.hadoop.fs.seaweedfs.impl=seaweed.hdfs.SeaweedFileSystem \ --conf spark.hadoop.fs.defaultFS=seaweedfs://10.0.13.210:8888 \ --conf spark.eventLog.dir=seaweedfs://10.0.13.210:8888/spark2-history/ \ file:home/spark-3.0.0-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.0.0.jar   spark3fs.create  hdfsseaweedfs  public static void main(String[] args) throws IOException { Configuration configuration = new Configuration(); // HDFS configuration.set(""fs.defaultFS"", ""hdfs://10.0.13.210:8020""); // seaweedfs // configuration.set(""fs.defaultFS"", ""seaweedfs://10.0.13.210:8888""); // configuration.set(""fs.seaweedfs.impl"", ""seaweed.hdfs.SeaweedFileSystem""); FileSystem fs = FileSystem.get(configuration); fs.create(new Path(""/spark2-history/local-1601049699528.inprogress"")); } ",source-file,"hadoop: filesystem cannot create file  spark-submithistoryseaweedfslogfiler  ./spark-submit \ --name spark-pi \ --class org.apache.spark.examples.SparkPi \ --conf spark.jars.ivy=/tmp/.ivy \ --conf spark.eventLog.enabled=true \ --conf spark.hadoop.fs.seaweedfs.impl=seaweed.hdfs.SeaweedFileSystem \ --conf spark.hadoop.fs.defaultFS=seaweedfs://10.0.13.210:8888 \ --conf spark.eventLog.dir=seaweedfs://10.0.13.210:8888/spark2-history/ \ file:home/spark-3.0.0-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.0.0.jar   spark3fs.create  hdfsseaweedfs  public static void main(String[] args) throws IOException { Configuration configuration = new Configuration(); // HDFS configuration.set(""fs.defaultFS"", ""hdfs://10.0.13.210:8020""); // seaweedfs // configuration.set(""fs.defaultFS"", ""seaweedfs://10.0.13.210:8888""); // configuration.set(""fs.seaweedfs.impl"", ""seaweed.hdfs.SeaweedFileSystem""); FileSystem fs = FileSystem.get(configuration); fs.create(new Path(""/spark2-history/local-1601049699528.inprogress"")); }  source-file",no-bug,0.8
1227,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1227,database option is ignored when Postgres filer store is used,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs seaweed with simple setup [docker/seaweedfs-compose.yml](https://github.com/chrislusf/seaweedfs/blob/master/docker/seaweedfs-compose.yml) example, new CockroachDB cluster with 3 nodes and default params in docker  roach1: container_name: roach1 image: cockroachdb/cockroach:v19.2.4 command: start --insecure --join=roach1,roach2,roach3 ports: - 26257:26257 - 18080:8080 volumes: - /mnt/var_f/cocroachdb/cockroach-data/roach1:/cockroach/cockroach-data networks: test: ipv4_address: 172.18.0.90 aliases: - roach1 roach2: container_name: roach2 image: cockroachdb/cockroach:v19.2.4 command: start --insecure --join=roach1,roach2,roach3 volumes: - /mnt/var_f/cocroachdb/cockroach-data/roach2:/cockroach/cockroach-data depends_on: - roach1 networks: test: ipv4_address: 172.18.0.91 aliases: - roach2 roach3: container_name: roach3 image: cockroachdb/cockroach:v19.2.4 command: start --insecure --join=roach1,roach2,roach3 volumes: - /mnt/var_f/cocroachdb/cockroach-data/roach3:/cockroach/cockroach-data depends_on: - roach1 networks: test: ipv4_address: 172.18.0.92 aliases: - roach3  **Describe the bug** Database option is ignored when Postgres filer store is used. Always get in filers logs `filer_server_handlers_read_dir.go:38] listDirectory / 100: list / : pq: relation ""filemeta"" does not exist` when try to access web-ui or copy files to filer and table ""filemeta"" didn't exists in default database ""defaultdb"". When table ""filemeta"" is created in defaultdb then all works **System Setup** - The default docker-compose setup from here: [docker/seaweedfs-compose.yml](https://github.com/chrislusf/seaweedfs/blob/master/docker/seaweedfs-compose.yml) - OS version Linux Mint 19.3 - output of `weed version` version 30GB 1.61 linux amd64 - CockroachDB CCL v19.2.4 (x86_64-unknown-linux-gnu, built 2020/02/06 21:55:19, go1.12.12) (same version as client)  cat /etc/seaweedfs/filer.toml [leveldb2] enabled = false dir = ""/data/filerldb2"" [postgres] # or cockroachdb enabled = true hostname = ""172.18.0.90"" port = 26257 username = ""weed"" password = """" database = ""weedfs"" # create or use an existing database sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100  **Expected behavior** database option should be honored",source-file,"database option is ignored when Postgres filer store is used Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs seaweed with simple setup [docker/seaweedfs-compose.yml](https://github.com/chrislusf/seaweedfs/blob/master/docker/seaweedfs-compose.yml) example, new CockroachDB cluster with 3 nodes and default params in docker  roach1: container_name: roach1 image: cockroachdb/cockroach:v19.2.4 command: start --insecure --join=roach1,roach2,roach3 ports: - 26257:26257 - 18080:8080 volumes: - /mnt/var_f/cocroachdb/cockroach-data/roach1:/cockroach/cockroach-data networks: test: ipv4_address: 172.18.0.90 aliases: - roach1 roach2: container_name: roach2 image: cockroachdb/cockroach:v19.2.4 command: start --insecure --join=roach1,roach2,roach3 volumes: - /mnt/var_f/cocroachdb/cockroach-data/roach2:/cockroach/cockroach-data depends_on: - roach1 networks: test: ipv4_address: 172.18.0.91 aliases: - roach2 roach3: container_name: roach3 image: cockroachdb/cockroach:v19.2.4 command: start --insecure --join=roach1,roach2,roach3 volumes: - /mnt/var_f/cocroachdb/cockroach-data/roach3:/cockroach/cockroach-data depends_on: - roach1 networks: test: ipv4_address: 172.18.0.92 aliases: - roach3  **Describe the bug** Database option is ignored when Postgres filer store is used. Always get in filers logs `filer_server_handlers_read_dir.go:38] listDirectory / 100: list / : pq: relation ""filemeta"" does not exist` when try to access web-ui or copy files to filer and table ""filemeta"" didn't exists in default database ""defaultdb"". When table ""filemeta"" is created in defaultdb then all works **System Setup** - The default docker-compose setup from here: [docker/seaweedfs-compose.yml](https://github.com/chrislusf/seaweedfs/blob/master/docker/seaweedfs-compose.yml) - OS version Linux Mint 19.3 - output of `weed version` version 30GB 1.61 linux amd64 - CockroachDB CCL v19.2.4 (x86_64-unknown-linux-gnu, built 2020/02/06 21:55:19, go1.12.12) (same version as client)  cat /etc/seaweedfs/filer.toml [leveldb2] enabled = false dir = ""/data/filerldb2"" [postgres] # or cockroachdb enabled = true hostname = ""172.18.0.90"" port = 26257 username = ""weed"" password = """" database = ""weedfs"" # create or use an existing database sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100  **Expected behavior** database option should be honored source-file",no-bug,0.9
825,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/825,brain split happened when network interrupts between dc,"weed vesion:1.15 1. weed master: deployed in 3 DC , 3 nodes in dc1 + 2 in dc2 +in 2 dc3 , 2. volumer server : 3 nodes in dc1 + 3 in dc2 + 3 in dc3 3. when the network between dc3 and dc2 interrupt , dc3 and dc1 also interrupt ,but network between dc1 and dc2 is ok , so dc3 is a network isolated island  4. the original leader in dc1 , but when network issue happened , the second leader selected in dc3 and dc3's volumer server connect to the dc3 new leader. Forming two clusters , dc1 and dc2 is a cluster ,dc3 is a cluster 5. when the network issue between dc3 and dc1dc2 solved , also two leader in whole cluster util restart the dc3's leader.",source-file | source-file,"brain split happened when network interrupts between dc weed vesion:1.15 1. weed master: deployed in 3 DC , 3 nodes in dc1 + 2 in dc2 +in 2 dc3 , 2. volumer server : 3 nodes in dc1 + 3 in dc2 + 3 in dc3 3. when the network between dc3 and dc2 interrupt , dc3 and dc1 also interrupt ,but network between dc1 and dc2 is ok , so dc3 is a network isolated island  4. the original leader in dc1 , but when network issue happened , the second leader selected in dc3 and dc3's volumer server connect to the dc3 new leader. Forming two clusters , dc1 and dc2 is a cluster ,dc3 is a cluster 5. when the network issue between dc3 and dc1dc2 solved , also two leader in whole cluster util restart the dc3's leader. source-file source-file",no-bug,0.9
74,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/74,single point of failure,"3 master server: mA mB mC 2 volume server: vA vB mA is the leader of (mA,mB,mC) cluster. and vA and vB are connected with mA; (replication is ""001"") If mA is down, mB become the leader of (mB,mC) as my expectation. But why don't vA and vB is still looking up for mA when writing replication? When vA and vB will realize to looking up for mB for writing replication? In this case, when mA is down and then I submit file to mB; it always returns e.g. `{""error"":""Failed to write to replicas for volume 3""}` How to solve this problem about SPOF?",config-file | documentation-file | documentation-file | container-file | container-file | other-file | other-file | config-file | config-file | other-file | other-file | config-file | other-file | other-file | documentation-file | documentation-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | other-file | other-file | other-file | config-file | other-file | config-file | source-file | config-file | config-file | config-file | config-file | config-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"single point of failure 3 master server: mA mB mC 2 volume server: vA vB mA is the leader of (mA,mB,mC) cluster. and vA and vB are connected with mA; (replication is ""001"") If mA is down, mB become the leader of (mB,mC) as my expectation. But why don't vA and vB is still looking up for mA when writing replication? When vA and vB will realize to looking up for mB for writing replication? In this case, when mA is down and then I submit file to mB; it always returns e.g. `{""error"":""Failed to write to replicas for volume 3""}` How to solve this problem about SPOF? config-file documentation-file documentation-file container-file container-file other-file other-file config-file config-file other-file other-file config-file other-file other-file documentation-file documentation-file other-file documentation-file documentation-file documentation-file documentation-file other-file other-file other-file config-file other-file config-file source-file config-file config-file config-file config-file config-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
3223,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3223,"Master logs cause panic in the program, resulting in abnormal services","panic stacks as follows: I0623 17:58:56 8 volume_growth.go:235] Created Volume 9050 on topo:idc1:rack1:172.24.10.131:32592 I0623 17:58:56 8 volume_layout.go:222] volume 9050 does not have enough copies I0623 17:58:56 8 volume_layout.go:227] volume 9050 remove from writable I0623 17:58:56 8 volume_layout.go:391] Volume 9050 becomes writable I0623 17:58:56 8 volume_growth.go:235] Created Volume 9050 on topo:idc1:rack2:172.24.10.132:32594 panic: runtime error: slice bounds out of range [18446744073709551615:200] goroutine 33054527 [running]: github.com/chrislusf/raft.(*Log).compact(0xc000534f50, 0x106c, 0x0) /Users/zhouzhuqun//soft/goworkspace/src/github.com/zhuqunzhou/seaweedfs/vendor/github.com/chrislusf/raft/log.go:592 +0x4a7 github.com/chrislusf/raft.(*server).TakeSnapshot(0xc000899c20) /Users/zhouzhuqun//soft/goworkspace/src/github.com/zhuqunzhou/seaweedfs/vendor/github.com/chrislusf/raft/server.go:1279 +0x591 github.com/chrislusf/raft.(*server).maybeTakeSnapshot.func1() /Users/zhouzhuqun//soft/goworkspace/src/github.com/zhuqunzhou/seaweedfs/vendor/github.com/chrislusf/raft/server.go:1221 +0x66 created by github.com/chrislusf/raft.(*server).maybeTakeSnapshot /Users/zhouzhuqun//soft/goworkspace/src/github.com/zhuqunzhou/seaweedfs/vendor/github.com/chrislusf/raft/server.go:1219 +0x96",other-file | other-file,"Master logs cause panic in the program, resulting in abnormal services panic stacks as follows: I0623 17:58:56 8 volume_growth.go:235] Created Volume 9050 on topo:idc1:rack1:172.24.10.131:32592 I0623 17:58:56 8 volume_layout.go:222] volume 9050 does not have enough copies I0623 17:58:56 8 volume_layout.go:227] volume 9050 remove from writable I0623 17:58:56 8 volume_layout.go:391] Volume 9050 becomes writable I0623 17:58:56 8 volume_growth.go:235] Created Volume 9050 on topo:idc1:rack2:172.24.10.132:32594 panic: runtime error: slice bounds out of range [18446744073709551615:200] goroutine 33054527 [running]: github.com/chrislusf/raft.(*Log).compact(0xc000534f50, 0x106c, 0x0) /Users/zhouzhuqun//soft/goworkspace/src/github.com/zhuqunzhou/seaweedfs/vendor/github.com/chrislusf/raft/log.go:592 +0x4a7 github.com/chrislusf/raft.(*server).TakeSnapshot(0xc000899c20) /Users/zhouzhuqun//soft/goworkspace/src/github.com/zhuqunzhou/seaweedfs/vendor/github.com/chrislusf/raft/server.go:1279 +0x591 github.com/chrislusf/raft.(*server).maybeTakeSnapshot.func1() /Users/zhouzhuqun//soft/goworkspace/src/github.com/zhuqunzhou/seaweedfs/vendor/github.com/chrislusf/raft/server.go:1221 +0x66 created by github.com/chrislusf/raft.(*server).maybeTakeSnapshot /Users/zhouzhuqun//soft/goworkspace/src/github.com/zhuqunzhou/seaweedfs/vendor/github.com/chrislusf/raft/server.go:1219 +0x96 other-file other-file",no-bug,0.9
17,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/17,Stability of master servers,"I'm using weed-fs in production now. Sometimes master server randomly respond with blank line or ""no more volumes"" error. (even when correct topology in /dir/status) I used 3 master-servers and it caused to even decrease overall stability of the system - sometimes master servers lost sync with each other / unable to promote the leader, and the only way fixing it was removing all master server files, shutting down all master servers and data nodes, then starting master servers and nodes. I'm not quite sure how to investigate this problem, because reproducibility is low - I have no idea how to force master server(s) into unavailable state. Maybe some hardcore unit/integration tests? This issue not allowing me to use weed-fs in production for my new projects and I'm currently migrating to cloud storage, but leaving possibility for migrating back.",source-file | source-file | source-file,"Stability of master servers I'm using weed-fs in production now. Sometimes master server randomly respond with blank line or ""no more volumes"" error. (even when correct topology in /dir/status) I used 3 master-servers and it caused to even decrease overall stability of the system - sometimes master servers lost sync with each other / unable to promote the leader, and the only way fixing it was removing all master server files, shutting down all master servers and data nodes, then starting master servers and nodes. I'm not quite sure how to investigate this problem, because reproducibility is low - I have no idea how to force master server(s) into unavailable state. Maybe some hardcore unit/integration tests? This issue not allowing me to use weed-fs in production for my new projects and I'm currently migrating to cloud storage, but leaving possibility for migrating back. source-file source-file source-file",no-bug,0.8
952,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/952,"shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused""","Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug**  root@Ubuntu-1804-bionic-64-minimal:~# /opt/go/bin/weed shell I0506 09:55:37 10573 filer_server.go:103] Reading : Config File ""security"" Not Found in ""[/root /root/.seaweedfs /etc/seaweedfs]"" I0506 09:55:37 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:37 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:38 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:38 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:39 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:39 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:40 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:40 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:41 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:41 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused""  **System Setup** Ubuntu 18.04 to start the shell  /opt/go/bin/weed shell  to start master filer  /opt/go/bin/weed -v=0 server -filer=true -ip=159.69.136.31 -dir=/storage/new_master -volume.max=3000 -volume.images.fix.orientation=false -pulseSeconds=5  **Expected behavior** It should start the weed shell. **Additional context** All ports are allowed and no firewall is enabled while doing this.",source-file,"shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug**  root@Ubuntu-1804-bionic-64-minimal:~# /opt/go/bin/weed shell I0506 09:55:37 10573 filer_server.go:103] Reading : Config File ""security"" Not Found in ""[/root /root/.seaweedfs /etc/seaweedfs]"" I0506 09:55:37 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:37 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:38 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:38 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:39 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:39 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:40 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:40 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:41 10573 masterclient.go:60] shell failed to keep connected to localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused"" I0506 09:55:41 10573 masterclient.go:97] shell failed to connect with master localhost:9333: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:19333: connect: connection refused""  **System Setup** Ubuntu 18.04 to start the shell  /opt/go/bin/weed shell  to start master filer  /opt/go/bin/weed -v=0 server -filer=true -ip=159.69.136.31 -dir=/storage/new_master -volume.max=3000 -volume.images.fix.orientation=false -pulseSeconds=5  **Expected behavior** It should start the weed shell. **Additional context** All ports are allowed and no firewall is enabled while doing this. source-file",no-bug,0.9
6139,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6139,[volume] avoid reset volume metrics after one volume unmoun/mount,"**Describe the bug**  > volume.unmount -node 192.168.131.2:8112 -volumeId 6227 > volume.mount -node 192.168.131.2:8112 -volumeId 6227   curl -s http://192.168.131.2:9533/metrics | grep -A 1 SeaweedFS_volumeServer_volumes SeaweedFS_volumeServer_volumes{collection=""my-collection"",type=""volume""} 1  volume.list  > volume.list -dataNode 192.168.131.2:8112 Rack rack1 hdd(volume:4136/7272 active:4130 free:3136 remote:0) DataNode 192.168.131.2:8112 hdd(volume:35/64 active:33 free:29 remote:0) Disk hdd(volume:35/64 active:33 free:29 remote:0) volume id:4227 size:524666641560 collection:""my-collection"" file_count:118552 delete_count:7289 deleted_byte_count:41575914268 replica_placement:100 version:3 modified_at_second:1725538853 volume id:6046 size:524522236696 collection:""my-collection-input"" file_count:6847 replica_placement:100 version:3 ttl:773 modified_at_second:1728384834 volume id:5547 size:524579140400 collection:""my-collection"" file_count:118413 delete_count:353 deleted_byte_count:2246319497 replica_placement:100 version:3 modified_at_second:1727111949 volume id:4694 size:525070612688 collection:""my-collection"" file_count:124936 delete_count:434 deleted_byte_count:2383978651 replica_placement:100 version:3 modified_at_second:1728491653 volume id:1627 size:524505885232 collection:""my-collection"" file_count:124123 delete_count:1719 deleted_byte_count:8356372944 replica_placement:100 version:3 modified_at_second:1716101128 volume id:3618 size:524370776344 collection:""my-collection"" file_count:125363 delete_count:193 deleted_byte_count:1065707659 replica_placement:100 version:3 modified_at_second:1723345341 volume id:1413 size:524291310736 collection:""my-collection"" file_count:116528 delete_count:1374 deleted_byte_count:5209549886 replica_placement:100 version:3 modified_at_second:1715198141 volume id:5032 size:524581322208 collection:""my-collection"" file_count:120317 delete_count:328 deleted_byte_count:1402831216 replica_placement:100 version:3 modified_at_second:1725943362 volume id:906 size:524292484128 collection:""my-collection"" file_count:111421 delete_count:1448 deleted_byte_count:5706539056 replica_placement:100 version:3 modified_at_second:1713102922 volume id:6687 size:70257581888 collection:""my-collection"" file_count:16714 delete_count:71 deleted_byte_count:333474260 replica_placement:100 version:3 modified_at_second:1729159438 volume id:4401 size:524350256200 collection:""my-collection"" file_count:112710 delete_count:1250 deleted_byte_count:5874601161 replica_placement:100 version:3 modified_at_second:1724676525 volume id:3862 size:524314982824 collection:""my-collection"" file_count:110262 delete_count:1449 deleted_byte_count:5674259268 replica_placement:100 version:3 modified_at_second:1724265140 volume id:6075 size:524606948000 collection:""my-collection"" file_count:125414 delete_count:45 deleted_byte_count:305243771 replica_placement:100 version:3 modified_at_second:1728816997 volume id:5949 size:524638812384 collection:""my-collection"" file_count:127395 delete_count:614 deleted_byte_count:3265396686 replica_placement:100 version:3 modified_at_second:1728666530 volume id:5605 size:524369813168 collection:""my-collection"" file_count:114716 delete_count:781 deleted_byte_count:3983525661 replica_placement:100 version:3 modified_at_second:1727265389 volume id:1333 size:524292265112 collection:""my-collection"" file_count:113512 delete_count:1140 deleted_byte_count:4500796599 replica_placement:100 version:3 modified_at_second:1714748274 volume id:796 size:524297707144 collection:""my-collection"" file_count:118024 delete_count:1242 deleted_byte_count:4845767135 replica_placement:100 version:3 modified_at_second:1711834937 volume id:1126 size:524303654824 collection:""my-collection"" file_count:115865 delete_count:1288 deleted_byte_count:4801031923 replica_placement:100 version:3 modified_at_second:1713827432 volume id:6227 size:525990556400 collection:""my-collection"" file_count:101742 delete_count:9047 deleted_byte_count:47840032756 replica_placement:100 version:3 modified_at_second:1729157963 volume id:3195 size:171930574160 collection:""my-collection-output"" file_count:55176 delete_count:2951 deleted_byte_count:7525746104 replica_placement:100 version:3 modified_at_second:1729159297 volume id:1830 size:524665121136 collection:""my-collection"" file_count:108666 delete_count:4241 deleted_byte_count:10842042380 replica_placement:100 version:3 modified_at_second:1717175079 volume id:5948 size:524570121152 collection:""my-collection"" file_count:110114 delete_count:6481 deleted_byte_count:33210132848 replica_placement:100 version:3 modified_at_second:1728658531 volume id:6305 size:401338127120 collection:""my-collection"" file_count:82598 delete_count:1181 deleted_byte_count:5698647056 replica_placement:100 version:3 modified_at_second:1729159408 volume id:1180 size:524305101960 collection:""my-collection"" file_count:112105 delete_count:1351 deleted_byte_count:4871534320 replica_placement:100 version:3 modified_at_second:1728997689 volume id:4778 size:524299679136 collection:""my-collection"" file_count:110091 delete_count:1996 deleted_byte_count:9301864062 replica_placement:100 version:3 modified_at_second:1728648117 volume id:3980 size:524786259744 collection:""my-collection"" file_count:124478 delete_count:517 deleted_byte_count:1859926130 replica_placement:100 version:3 modified_at_second:1728305454 volume id:5338 size:525228600024 collection:""my-collection"" file_count:117852 delete_count:1211 deleted_byte_count:6514592693 replica_placement:100 version:3 modified_at_second:1728995110 volume id:3822 size:524343632008 collection:""my-collection"" file_count:124290 delete_count:289 deleted_byte_count:988984636 replica_placement:100 version:3 modified_at_second:1728662585 volume id:3790 size:524290532424 collection:""my-collection"" file_count:110430 delete_count:1878 deleted_byte_count:8083825662 replica_placement:100 version:3 modified_at_second:1724239203 volume id:3891 size:524423173760 collection:""my-collection"" file_count:110449 delete_count:1345 deleted_byte_count:5273260971 replica_placement:100 version:3 modified_at_second:1724265784 volume id:1082 size:524297969664 collection:""my-collection"" file_count:116086 delete_count:1425 deleted_byte_count:5262847708 replica_placement:100 version:3 modified_at_second:1727695115 volume id:5927 size:525679650408 collection:""my-collection"" file_count:120318 delete_count:8909 deleted_byte_count:47747182390 replica_placement:100 version:3 modified_at_second:1729045960 volume id:197 size:524298443584 collection:""my-collection"" file_count:112403 delete_count:1331 deleted_byte_count:5209914081 replica_placement:100 version:3 modified_at_second:1728648320 volume id:1657 size:524356840576 collection:""my-collection"" file_count:116195 delete_count:1348 deleted_byte_count:5772579130 replica_placement:100 version:3 modified_at_second:1716304447 volume id:385 size:524299876832 collection:""my-collection"" file_count:114172 delete_count:1434 deleted_byte_count:5218008452 replica_placement:100 version:3 modified_at_second:1710141512 Disk hdd total size:17429416691624 file_count:3768277 deleted_file:67953 deleted_bytes:312752431020 DataNode 192.168.131.2:8112 total size:17429416691624 file_count:3768277 deleted_file:67953 deleted_bytes:312752431020 Rack rack1 total size:17429416691624 file_count:3768277 deleted_file:67953 deleted_bytes:312752431020  **System Setup**  version 8000GB 3.77 b28b1a34025a2f2ed80883e245250d00783bfea7 linux amd64  **Expected behavior** Metrics always shows the correct amount of volumes <img width=""1123"" alt=""image"" src=""https://github.com/user-attachments/assets/ce648fb2-2a45-40a8-a6a8-5a1378b6c08f"">",source-file,"[volume] avoid reset volume metrics after one volume unmoun/mount **Describe the bug**  > volume.unmount -node 192.168.131.2:8112 -volumeId 6227 > volume.mount -node 192.168.131.2:8112 -volumeId 6227   curl -s http://192.168.131.2:9533/metrics | grep -A 1 SeaweedFS_volumeServer_volumes SeaweedFS_volumeServer_volumes{collection=""my-collection"",type=""volume""} 1  volume.list  > volume.list -dataNode 192.168.131.2:8112 Rack rack1 hdd(volume:4136/7272 active:4130 free:3136 remote:0) DataNode 192.168.131.2:8112 hdd(volume:35/64 active:33 free:29 remote:0) Disk hdd(volume:35/64 active:33 free:29 remote:0) volume id:4227 size:524666641560 collection:""my-collection"" file_count:118552 delete_count:7289 deleted_byte_count:41575914268 replica_placement:100 version:3 modified_at_second:1725538853 volume id:6046 size:524522236696 collection:""my-collection-input"" file_count:6847 replica_placement:100 version:3 ttl:773 modified_at_second:1728384834 volume id:5547 size:524579140400 collection:""my-collection"" file_count:118413 delete_count:353 deleted_byte_count:2246319497 replica_placement:100 version:3 modified_at_second:1727111949 volume id:4694 size:525070612688 collection:""my-collection"" file_count:124936 delete_count:434 deleted_byte_count:2383978651 replica_placement:100 version:3 modified_at_second:1728491653 volume id:1627 size:524505885232 collection:""my-collection"" file_count:124123 delete_count:1719 deleted_byte_count:8356372944 replica_placement:100 version:3 modified_at_second:1716101128 volume id:3618 size:524370776344 collection:""my-collection"" file_count:125363 delete_count:193 deleted_byte_count:1065707659 replica_placement:100 version:3 modified_at_second:1723345341 volume id:1413 size:524291310736 collection:""my-collection"" file_count:116528 delete_count:1374 deleted_byte_count:5209549886 replica_placement:100 version:3 modified_at_second:1715198141 volume id:5032 size:524581322208 collection:""my-collection"" file_count:120317 delete_count:328 deleted_byte_count:1402831216 replica_placement:100 version:3 modified_at_second:1725943362 volume id:906 size:524292484128 collection:""my-collection"" file_count:111421 delete_count:1448 deleted_byte_count:5706539056 replica_placement:100 version:3 modified_at_second:1713102922 volume id:6687 size:70257581888 collection:""my-collection"" file_count:16714 delete_count:71 deleted_byte_count:333474260 replica_placement:100 version:3 modified_at_second:1729159438 volume id:4401 size:524350256200 collection:""my-collection"" file_count:112710 delete_count:1250 deleted_byte_count:5874601161 replica_placement:100 version:3 modified_at_second:1724676525 volume id:3862 size:524314982824 collection:""my-collection"" file_count:110262 delete_count:1449 deleted_byte_count:5674259268 replica_placement:100 version:3 modified_at_second:1724265140 volume id:6075 size:524606948000 collection:""my-collection"" file_count:125414 delete_count:45 deleted_byte_count:305243771 replica_placement:100 version:3 modified_at_second:1728816997 volume id:5949 size:524638812384 collection:""my-collection"" file_count:127395 delete_count:614 deleted_byte_count:3265396686 replica_placement:100 version:3 modified_at_second:1728666530 volume id:5605 size:524369813168 collection:""my-collection"" file_count:114716 delete_count:781 deleted_byte_count:3983525661 replica_placement:100 version:3 modified_at_second:1727265389 volume id:1333 size:524292265112 collection:""my-collection"" file_count:113512 delete_count:1140 deleted_byte_count:4500796599 replica_placement:100 version:3 modified_at_second:1714748274 volume id:796 size:524297707144 collection:""my-collection"" file_count:118024 delete_count:1242 deleted_byte_count:4845767135 replica_placement:100 version:3 modified_at_second:1711834937 volume id:1126 size:524303654824 collection:""my-collection"" file_count:115865 delete_count:1288 deleted_byte_count:4801031923 replica_placement:100 version:3 modified_at_second:1713827432 volume id:6227 size:525990556400 collection:""my-collection"" file_count:101742 delete_count:9047 deleted_byte_count:47840032756 replica_placement:100 version:3 modified_at_second:1729157963 volume id:3195 size:171930574160 collection:""my-collection-output"" file_count:55176 delete_count:2951 deleted_byte_count:7525746104 replica_placement:100 version:3 modified_at_second:1729159297 volume id:1830 size:524665121136 collection:""my-collection"" file_count:108666 delete_count:4241 deleted_byte_count:10842042380 replica_placement:100 version:3 modified_at_second:1717175079 volume id:5948 size:524570121152 collection:""my-collection"" file_count:110114 delete_count:6481 deleted_byte_count:33210132848 replica_placement:100 version:3 modified_at_second:1728658531 volume id:6305 size:401338127120 collection:""my-collection"" file_count:82598 delete_count:1181 deleted_byte_count:5698647056 replica_placement:100 version:3 modified_at_second:1729159408 volume id:1180 size:524305101960 collection:""my-collection"" file_count:112105 delete_count:1351 deleted_byte_count:4871534320 replica_placement:100 version:3 modified_at_second:1728997689 volume id:4778 size:524299679136 collection:""my-collection"" file_count:110091 delete_count:1996 deleted_byte_count:9301864062 replica_placement:100 version:3 modified_at_second:1728648117 volume id:3980 size:524786259744 collection:""my-collection"" file_count:124478 delete_count:517 deleted_byte_count:1859926130 replica_placement:100 version:3 modified_at_second:1728305454 volume id:5338 size:525228600024 collection:""my-collection"" file_count:117852 delete_count:1211 deleted_byte_count:6514592693 replica_placement:100 version:3 modified_at_second:1728995110 volume id:3822 size:524343632008 collection:""my-collection"" file_count:124290 delete_count:289 deleted_byte_count:988984636 replica_placement:100 version:3 modified_at_second:1728662585 volume id:3790 size:524290532424 collection:""my-collection"" file_count:110430 delete_count:1878 deleted_byte_count:8083825662 replica_placement:100 version:3 modified_at_second:1724239203 volume id:3891 size:524423173760 collection:""my-collection"" file_count:110449 delete_count:1345 deleted_byte_count:5273260971 replica_placement:100 version:3 modified_at_second:1724265784 volume id:1082 size:524297969664 collection:""my-collection"" file_count:116086 delete_count:1425 deleted_byte_count:5262847708 replica_placement:100 version:3 modified_at_second:1727695115 volume id:5927 size:525679650408 collection:""my-collection"" file_count:120318 delete_count:8909 deleted_byte_count:47747182390 replica_placement:100 version:3 modified_at_second:1729045960 volume id:197 size:524298443584 collection:""my-collection"" file_count:112403 delete_count:1331 deleted_byte_count:5209914081 replica_placement:100 version:3 modified_at_second:1728648320 volume id:1657 size:524356840576 collection:""my-collection"" file_count:116195 delete_count:1348 deleted_byte_count:5772579130 replica_placement:100 version:3 modified_at_second:1716304447 volume id:385 size:524299876832 collection:""my-collection"" file_count:114172 delete_count:1434 deleted_byte_count:5218008452 replica_placement:100 version:3 modified_at_second:1710141512 Disk hdd total size:17429416691624 file_count:3768277 deleted_file:67953 deleted_bytes:312752431020 DataNode 192.168.131.2:8112 total size:17429416691624 file_count:3768277 deleted_file:67953 deleted_bytes:312752431020 Rack rack1 total size:17429416691624 file_count:3768277 deleted_file:67953 deleted_bytes:312752431020  **System Setup**  version 8000GB 3.77 b28b1a34025a2f2ed80883e245250d00783bfea7 linux amd64  **Expected behavior** Metrics always shows the correct amount of volumes <img width=""1123"" alt=""image"" src=""https://github.com/user-attachments/assets/ce648fb2-2a45-40a8-a6a8-5a1378b6c08f""> source-file",no-bug,0.8
214,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/214,seaweedfs should check WhiteList before proxyToLeader,"` r.HandleFunc(""/"", ms.uiStatusHandler) r.HandleFunc(""/ui/index.html"", ms.uiStatusHandler) r.HandleFunc(""/dir/assign"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirAssignHandler r.HandleFunc(""/dir/lookup"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirLookupHandler r.HandleFunc(""/dir/join"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirJoinHandler r.HandleFunc(""/dir/status"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirStatusHandler r.HandleFunc(""/col/delete"", ms.proxyToLeader(ms.guard.WhiteList(ms.collectionDeleteHandler r.HandleFunc(""/vol/lookup"", ms.proxyToLeader(ms.guard.WhiteList(ms.volumeLookupHandler ` If a request not in whitelist is sent to a non-leader master, this request will be handled by leader, which is unexpected.",source-file | source-file,"seaweedfs should check WhiteList before proxyToLeader ` r.HandleFunc(""/"", ms.uiStatusHandler) r.HandleFunc(""/ui/index.html"", ms.uiStatusHandler) r.HandleFunc(""/dir/assign"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirAssignHandler r.HandleFunc(""/dir/lookup"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirLookupHandler r.HandleFunc(""/dir/join"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirJoinHandler r.HandleFunc(""/dir/status"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirStatusHandler r.HandleFunc(""/col/delete"", ms.proxyToLeader(ms.guard.WhiteList(ms.collectionDeleteHandler r.HandleFunc(""/vol/lookup"", ms.proxyToLeader(ms.guard.WhiteList(ms.volumeLookupHandler ` If a request not in whitelist is sent to a non-leader master, this request will be handled by leader, which is unexpected. source-file source-file",bug,0.85
1846,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1846,[shell] fixUnderReplicatedVolumes,"For a large cluster, the replication process can take hours And during this time, the state of the cluster can change more than once. Get actual information for each replication action  replicating volume 507 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 560 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 340 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 602 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 628 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 584 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 492 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 673 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 508 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 535 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 415 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 506 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 385 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 448 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 453 100 from fast-volume-1.dc1:8080 to dataNode fast-volume-5.dc2:8080  replicating volume 359 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 680 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 382 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 317 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 497 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 398 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 629 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 607 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 641 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 342 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 418 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 336 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 402 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 473 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 464 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 568 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 651 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 625 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 396 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 515 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 422 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 417 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 326 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 444 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 344 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 138 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 514 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 491 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 139 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 587 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 505 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 571 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 499 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 339 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 519 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 660 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 374 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 554 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 427 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 410 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 624 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 657 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 475 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 403 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 308 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 513 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 349 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 494 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 323 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 663 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 633 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 579 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 364 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 472 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 443 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 361 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 694 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 338 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 632 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 564 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 290 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 688 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 656 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 523 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 691 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 550 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 682 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 511 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 668 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 452 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 397 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 390 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 652 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 434 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 481 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 442 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 532 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 590 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 593 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 558 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 621 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 377 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 405 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  failed to place volume 407 replica as 100, existing:1 failed to place volume 640 replica as 100, existing:1 failed to place volume 645 replica as 100, existing:1 failed to place volume 544 replica as 100, existing:1 failed to place volume 605 replica as 100, existing:1 failed to place volume 27 replica as 010, existing:1 failed to place volume 531 replica as 100, existing:1 failed to place volume 493 replica as 100, existing:1 failed to place volume 432 replica as 100, existing:1 failed to place volume 466 replica as 100, existing:1 failed to place volume 627 replica as 100, existing:1 failed to place volume 421 replica as 100, existing:1 failed to place volume 341 replica as 100, existing:1 failed to place volume 363 replica as 100, existing:1 failed to place volume 462 replica as 100, existing:1 failed to place volume 404 replica as 100, existing:1 failed to place volume 479 replica as 100, existing:1 failed to place volume 580 replica as 100, existing:1 failed to place volume 597 replica as 100, existing:1 failed to place volume 591 replica as 100, existing:1 failed to place volume 555 replica as 100, existing:1 failed to place volume 18 replica as 010, existing:1 failed to place volume 569 replica as 100, existing:1 failed to place volume 615 replica as 100, existing:1 failed to place volume 22 replica as 010, existing:1 failed to place volume 313 replica as 100, existing:1 failed to place volume 261 replica as 100, existing:1 failed to place volume 522 replica as 100, existing:1 failed to place volume 263 replica as 100, existing:1 failed to place volume 520 replica as 100, existing:1 failed to place volume 420 replica as 100, existing:1 failed to place volume 379 replica as 100, existing:1 failed to place volume 144 replica as 010, existing:1 failed to place volume 578 replica as 100, existing:1 failed to place volume 646 replica as 100, existing:1 failed to place volume 525 replica as 100, existing:1 failed to place volume 581 replica as 100, existing:1 failed to place volume 463 replica as 100, existing:1 failed to place volume 696 replica as 100, existing:1 failed to place volume 563 replica as 100, existing:1 failed to place volume 357 replica as 100, existing:1 failed to place volume 365 replica as 100, existing:1 failed to place volume 260 replica as 100, existing:1 failed to place volume 527 replica as 100, existing:1 failed to place volume 373 replica as 100, existing:1 failed to place volume 316 replica as 100, existing:1 failed to place volume 604 replica as 100, existing:1 failed to place volume 529 replica as 100, existing:1 failed to place volume 408 replica as 100, existing:1 failed to place volume 423 replica as 100, existing:1 failed to place volume 565 replica as 100, existing:1 failed to place volume 351 replica as 100, existing:1 failed to place volume 140 replica as 100, existing:1 failed to place volume 388 replica as 100, existing:1 failed to place volume 510 replica as 100, existing:1 failed to place volume 146 replica as 010, existing:1 failed to place volume 23 replica as 010, existing:1 failed to place volume 501 replica as 100, existing:1 failed to place volume 329 replica as 100, existing:1 failed to place volume 517 replica as 100, existing:1 failed to place volume 661 replica as 100, existing:1 failed to place volume 467 replica as 100, existing:1 failed to place volume 380 replica as 100, existing:1 failed to place volume 588 replica as 100, existing:1 failed to place volume 468 replica as 100, existing:1 failed to place volume 658 replica as 100, existing:1 failed to place volume 647 replica as 100, existing:1 failed to place volume 332 replica as 100, existing:1 failed to place volume 360 replica as 100, existing:1 failed to place volume 353 replica as 100, existing:1 failed to place volume 343 replica as 100, existing:1 failed to place volume 667 replica as 100, existing:1 failed to place volume 387 replica as 100, existing:1 failed to place volume 618 replica as 100, existing:1 failed to place volume 488 replica as 100, existing:1 failed to place volume 533 replica as 100, existing:1 failed to place volume 616 replica as 100, existing:1 failed to place volume 474 replica as 100, existing:1 failed to place volume 6 replica as 010, existing:1 failed to place volume 690 replica as 100, existing:1 failed to place volume 476 replica as 100, existing:1 failed to place volume 686 replica as 100, existing:1 failed to place volume 498 replica as 100, existing:1 failed to place volume 391 replica as 100, existing:1 failed to place volume 376 replica as 100, existing:1 failed to place volume 543 replica as 100, existing:1 failed to place volume 419 replica as 100, existing:1  https://github.com/chrislusf/seaweedfs/blob/6a4546d2c088b5d71f8b2200b758a82f1aad08c6/weed/shell/command_volume_fix_replication.go#L184",source-file,"[shell] fixUnderReplicatedVolumes For a large cluster, the replication process can take hours And during this time, the state of the cluster can change more than once. Get actual information for each replication action  replicating volume 507 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 560 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 340 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 602 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 628 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 584 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 492 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 673 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 508 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 535 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 415 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 506 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 385 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 448 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 453 100 from fast-volume-1.dc1:8080 to dataNode fast-volume-5.dc2:8080  replicating volume 359 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 680 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 382 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 317 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 497 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 398 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 629 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 607 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 641 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 342 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 418 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 336 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 402 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 473 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 464 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 568 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 651 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 625 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 396 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 515 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 422 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 417 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 326 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 444 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 344 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 138 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 514 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 491 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 139 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 587 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 505 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 571 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 499 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 339 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 519 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 660 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 374 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 554 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 427 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 410 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 624 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 657 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 475 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 403 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 308 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 513 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 349 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 494 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 323 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 663 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 633 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 579 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 364 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 472 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 443 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 361 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 694 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 338 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 632 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 564 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 290 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 688 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 656 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 523 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 691 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 550 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 682 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 511 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 668 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 452 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 397 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 390 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 652 100 from fast-volume-7.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 434 100 from fast-volume-6.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 481 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 442 100 from fast-volume-4.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 532 100 from fast-volume-0.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 590 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 593 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 558 100 from fast-volume-1.dc2:8080 to dataNode fast-volume-1.dc1:8080  replicating volume 621 100 from fast-volume-2.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 377 100 from fast-volume-3.dc2:8080 to dataNode fast-volume-0.dc1:8080  replicating volume 405 100 from fast-volume-5.dc2:8080 to dataNode fast-volume-1.dc1:8080  failed to place volume 407 replica as 100, existing:1 failed to place volume 640 replica as 100, existing:1 failed to place volume 645 replica as 100, existing:1 failed to place volume 544 replica as 100, existing:1 failed to place volume 605 replica as 100, existing:1 failed to place volume 27 replica as 010, existing:1 failed to place volume 531 replica as 100, existing:1 failed to place volume 493 replica as 100, existing:1 failed to place volume 432 replica as 100, existing:1 failed to place volume 466 replica as 100, existing:1 failed to place volume 627 replica as 100, existing:1 failed to place volume 421 replica as 100, existing:1 failed to place volume 341 replica as 100, existing:1 failed to place volume 363 replica as 100, existing:1 failed to place volume 462 replica as 100, existing:1 failed to place volume 404 replica as 100, existing:1 failed to place volume 479 replica as 100, existing:1 failed to place volume 580 replica as 100, existing:1 failed to place volume 597 replica as 100, existing:1 failed to place volume 591 replica as 100, existing:1 failed to place volume 555 replica as 100, existing:1 failed to place volume 18 replica as 010, existing:1 failed to place volume 569 replica as 100, existing:1 failed to place volume 615 replica as 100, existing:1 failed to place volume 22 replica as 010, existing:1 failed to place volume 313 replica as 100, existing:1 failed to place volume 261 replica as 100, existing:1 failed to place volume 522 replica as 100, existing:1 failed to place volume 263 replica as 100, existing:1 failed to place volume 520 replica as 100, existing:1 failed to place volume 420 replica as 100, existing:1 failed to place volume 379 replica as 100, existing:1 failed to place volume 144 replica as 010, existing:1 failed to place volume 578 replica as 100, existing:1 failed to place volume 646 replica as 100, existing:1 failed to place volume 525 replica as 100, existing:1 failed to place volume 581 replica as 100, existing:1 failed to place volume 463 replica as 100, existing:1 failed to place volume 696 replica as 100, existing:1 failed to place volume 563 replica as 100, existing:1 failed to place volume 357 replica as 100, existing:1 failed to place volume 365 replica as 100, existing:1 failed to place volume 260 replica as 100, existing:1 failed to place volume 527 replica as 100, existing:1 failed to place volume 373 replica as 100, existing:1 failed to place volume 316 replica as 100, existing:1 failed to place volume 604 replica as 100, existing:1 failed to place volume 529 replica as 100, existing:1 failed to place volume 408 replica as 100, existing:1 failed to place volume 423 replica as 100, existing:1 failed to place volume 565 replica as 100, existing:1 failed to place volume 351 replica as 100, existing:1 failed to place volume 140 replica as 100, existing:1 failed to place volume 388 replica as 100, existing:1 failed to place volume 510 replica as 100, existing:1 failed to place volume 146 replica as 010, existing:1 failed to place volume 23 replica as 010, existing:1 failed to place volume 501 replica as 100, existing:1 failed to place volume 329 replica as 100, existing:1 failed to place volume 517 replica as 100, existing:1 failed to place volume 661 replica as 100, existing:1 failed to place volume 467 replica as 100, existing:1 failed to place volume 380 replica as 100, existing:1 failed to place volume 588 replica as 100, existing:1 failed to place volume 468 replica as 100, existing:1 failed to place volume 658 replica as 100, existing:1 failed to place volume 647 replica as 100, existing:1 failed to place volume 332 replica as 100, existing:1 failed to place volume 360 replica as 100, existing:1 failed to place volume 353 replica as 100, existing:1 failed to place volume 343 replica as 100, existing:1 failed to place volume 667 replica as 100, existing:1 failed to place volume 387 replica as 100, existing:1 failed to place volume 618 replica as 100, existing:1 failed to place volume 488 replica as 100, existing:1 failed to place volume 533 replica as 100, existing:1 failed to place volume 616 replica as 100, existing:1 failed to place volume 474 replica as 100, existing:1 failed to place volume 6 replica as 010, existing:1 failed to place volume 690 replica as 100, existing:1 failed to place volume 476 replica as 100, existing:1 failed to place volume 686 replica as 100, existing:1 failed to place volume 498 replica as 100, existing:1 failed to place volume 391 replica as 100, existing:1 failed to place volume 376 replica as 100, existing:1 failed to place volume 543 replica as 100, existing:1 failed to place volume 419 replica as 100, existing:1  https://github.com/chrislusf/seaweedfs/blob/6a4546d2c088b5d71f8b2200b758a82f1aad08c6/weed/shell/command_volume_fix_replication.go#L184 source-file",no-bug,0.9
4143,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4143,The bucket naming rules conflict when docking with minio,"When uploading buckets through java minio, minio prompts me that the buckets to be transferred do not conform to the naming rules of S3 buckets My bucket name is 10000_ test However, it cannot be used in the S3 naming specification_ To name it. aws-cli passed the name, but the seaweedfs server did not verify the bucket name So I suggest checking the incoming bucket name on the seeweedfs server to ensure that the system has stronger compatibility",source-file,"The bucket naming rules conflict when docking with minio When uploading buckets through java minio, minio prompts me that the buckets to be transferred do not conform to the naming rules of S3 buckets My bucket name is 10000_ test However, it cannot be used in the S3 naming specification_ To name it. aws-cli passed the name, but the seaweedfs server did not verify the bucket name So I suggest checking the incoming bucket name on the seeweedfs server to ensure that the system has stronger compatibility source-file",bug,0.85
1618,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1618,"2.10/master: ""too many open files"" during web-UI activity"," + ulimit -Sn 16384 + ulimit -n 16384 + weed master -ip=192.168.0.204 -port=9333 -peers=server1:9333,server2:9333 -defaultReplication=001 [] I1115 10:31:22 76619 master_server.go:192] adminScripts: lock volume.balance -force volume.fix.replication unlock I1115 10:31:22 76619 master.go:122] Start Seaweed Master 8000GB 2.10 at 0.0.0.0:9333 I1115 10:31:22 76619 raft_server.go:70] Starting RaftServer with 192.168.0.204:9333 I1115 10:31:22 76619 raft_server.go:129] current cluster leader: I1115 10:31:22 76619 master.go:146] Start Seaweed Master 8000GB 2.10 grpc server at 0.0.0.0:19333 I1115 10:31:23 76619 masterclient.go:74] existing leader is 192.168.0.3:9333 I1115 10:31:41 76619 masterclient.go:120] master masterClient failed to receive from 192.168.0.204:9333: EOF I1115 10:31:41 76619 masterclient.go:120] adminShell masterClient failed to receive from 192.168.0.204:9333: EOF 2020-11-15 10:31:49.426416 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 5ms 2020-11-15 10:31:49.431561 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 10ms 2020-11-15 10:31:49.441789 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 20ms 2020-11-15 10:31:49.461925 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 40ms 2020-11-15 10:31:49.502054 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 80ms 2020-11-15 10:31:49.582186 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 160ms 2020-11-15 10:31:49.742291 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 320ms 2020-11-15 10:31:50.062433 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 640ms 2020-11-15 10:31:50.702589 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:51.702726 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:52.702802 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:53.702942 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:54.703096 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:55.703252 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:56.703346 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:57.704009 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:58.704168 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:59.704321 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s I1115 10:32:00 76619 masterclient.go:120] adminShell masterClient failed to receive from 192.168.0.204:9333: EOF 2020-11-15 10:32:00.704509 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:01.704658 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:02.704792 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:03.704949 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:04.705086 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:05.705232 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:06.705346 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:07.705486 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:08.705621 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:09.705813 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:10.705973 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:11.706270 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:12.706451 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:13.706619 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:14.706780 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:15.706941 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:16.707079 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:17.707296 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:18.707450 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s I1115 10:32:19 76619 masterclient.go:120] adminShell masterClient failed to receive from 192.168.0.204:9333: EOF  To reproduce refresh http://localhost:9333/ui/index.html few times in browser.",other-file | other-file,"2.10/master: ""too many open files"" during web-UI activity  + ulimit -Sn 16384 + ulimit -n 16384 + weed master -ip=192.168.0.204 -port=9333 -peers=server1:9333,server2:9333 -defaultReplication=001 [] I1115 10:31:22 76619 master_server.go:192] adminScripts: lock volume.balance -force volume.fix.replication unlock I1115 10:31:22 76619 master.go:122] Start Seaweed Master 8000GB 2.10 at 0.0.0.0:9333 I1115 10:31:22 76619 raft_server.go:70] Starting RaftServer with 192.168.0.204:9333 I1115 10:31:22 76619 raft_server.go:129] current cluster leader: I1115 10:31:22 76619 master.go:146] Start Seaweed Master 8000GB 2.10 grpc server at 0.0.0.0:19333 I1115 10:31:23 76619 masterclient.go:74] existing leader is 192.168.0.3:9333 I1115 10:31:41 76619 masterclient.go:120] master masterClient failed to receive from 192.168.0.204:9333: EOF I1115 10:31:41 76619 masterclient.go:120] adminShell masterClient failed to receive from 192.168.0.204:9333: EOF 2020-11-15 10:31:49.426416 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 5ms 2020-11-15 10:31:49.431561 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 10ms 2020-11-15 10:31:49.441789 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 20ms 2020-11-15 10:31:49.461925 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 40ms 2020-11-15 10:31:49.502054 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 80ms 2020-11-15 10:31:49.582186 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 160ms 2020-11-15 10:31:49.742291 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 320ms 2020-11-15 10:31:50.062433 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 640ms 2020-11-15 10:31:50.702589 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:51.702726 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:52.702802 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:53.702942 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:54.703096 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:55.703252 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:56.703346 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:57.704009 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:58.704168 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:31:59.704321 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s I1115 10:32:00 76619 masterclient.go:120] adminShell masterClient failed to receive from 192.168.0.204:9333: EOF 2020-11-15 10:32:00.704509 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:01.704658 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:02.704792 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:03.704949 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:04.705086 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:05.705232 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:06.705346 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:07.705486 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:08.705621 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:09.705813 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:10.705973 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:11.706270 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:12.706451 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:13.706619 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:14.706780 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:15.706941 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:16.707079 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:17.707296 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s 2020-11-15 10:32:18.707450 I | http: Accept error: accept tcp [::]:9333: accept4: too many open files; retrying in 1s I1115 10:32:19 76619 masterclient.go:120] adminShell masterClient failed to receive from 192.168.0.204:9333: EOF  To reproduce refresh http://localhost:9333/ui/index.html few times in browser. other-file other-file",no-bug,0.9
3653,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3653,https://github.com/seaweedfs/goexif: `v2.0.0` must either not have `go.mod` file or be placed into `/v2` directory,"The version tagged `v2.0.0` must either not have `go.mod` file or be placed into `/v2` directory Currently, `seaweedfs` can be built only because cache on `proxy.golang.org` is incoherent and it cached previous version With Google's proxy is off (GONOPROXY='*') the build fails:  # GONOPROXY='*' go mod download -x github.com/seaweedfs/goexif@v2.0.0+incompatible go: github.com/seaweedfs/goexif@v2.0.0+incompatible: invalid version: module contains a go.mod file, so module path must match major version (""github.com/seaweedfs/goexif/v2"")  The issue makes troubles with packaging seaweedfs into Linux distros which perform reproducible package builds in sandboxes without access to cache sites like `proxy.golang.org`",other-file,"https://github.com/seaweedfs/goexif: `v2.0.0` must either not have `go.mod` file or be placed into `/v2` directory The version tagged `v2.0.0` must either not have `go.mod` file or be placed into `/v2` directory Currently, `seaweedfs` can be built only because cache on `proxy.golang.org` is incoherent and it cached previous version With Google's proxy is off (GONOPROXY='*') the build fails:  # GONOPROXY='*' go mod download -x github.com/seaweedfs/goexif@v2.0.0+incompatible go: github.com/seaweedfs/goexif@v2.0.0+incompatible: invalid version: module contains a go.mod file, so module path must match major version (""github.com/seaweedfs/goexif/v2"")  The issue makes troubles with packaging seaweedfs into Linux distros which perform reproducible package builds in sandboxes without access to cache sites like `proxy.golang.org` other-file",no-bug,0.95
2804,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2804,[bug:master] change of leader each time to the one who last started/restarted,"change of leader each time to the one who last started/restarted version  2.90  weed master run cmd:  /usr/bin/weed -logtostderr=true \ -v=1 \ master \ -mdir /data \ -port ""9333"" \ -defaultReplication=""100"" \ -metricsPort=9090 \ -volumeSizeLimitMB=1000 \ -resumeState=true \ -ip.bind=0.0.0.0 \ -ip ${POD_NAME}.$NAMESPACE-${SEAWEEDFS_FULLNAME}-master-direct.service.dc1.consul \ -peers sw-master-0.s3-sw-master-direct.service.dc1.consul:9333,sw-master-0.s3-sw-master-direct.service.dc2.consul:9333,sw-master-0.s3-sw-master-direct.service.dc3.consul:9333  logs:  I0324 14:37:48 1 config.go:44] Reading security.toml from /etc/seaweedfs/security.toml I0324 14:37:48 1 config.go:44] Reading master.toml from /etc/seaweedfs/master.toml I0324 14:37:48 1 file_util.go:23] Folder /data Permission: -rwxrwxr-x I0324 14:37:48 1 master.go:187] current: sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 peers:sw-master-0.s3-sw-master-direct.service.dc1.consul:9333,sw-master-0.s3-sw-master-direct.service.dc2.consul:9333,sw-master-0.s3-sw-master-direct.service.dc3.consul:9333 I0324 14:37:48 1 master_server.go:289] [master.sequencer.type] : [memory] I0324 14:37:48 1 master_server.go:122] Volume Size Limit is 1000 MB I0324 14:37:48 1 master.go:133] Start Seaweed Master 30GB 2.90 497ebbbd at 0.0.0.0:9333 I0324 14:37:48 1 raft_server.go:82] Starting RaftServer with sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 I0324 14:37:48 1 raft_server.go:61] Recovery raft state {MaxVolumeId:208} I0324 14:37:48 1 raft_server.go:143] current cluster leader: I0324 14:38:03 1 master_server.go:165] leader change event: => sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 I0324 14:38:03 1 master_server.go:168] [ sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 ] sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 becomes leader. I0324 14:38:03 1 cluster_commands.go:28] max volume id 208 ==> 209 I0324 14:38:03 1 cluster_commands.go:28] max volume id 209 ==> 210 I0324 14:38:03 1 cluster_commands.go:28] max volume id 210 ==> 211 I0324 14:38:03 1 cluster_commands.go:28] max volume id 211 ==> 212 I0324 14:38:03 1 cluster_commands.go:28] max volume id 212 ==> 213 I0324 14:38:03 1 cluster_commands.go:28] max volume id 213 ==> 214 I0324 14:38:03 1 cluster_commands.go:28] max volume id 214 ==> 215 I0324 14:38:03 1 cluster_commands.go:28] max volume id 215 ==> 216 I0324 14:38:03 1 cluster_commands.go:28] max volume id 216 ==> 217 I0324 14:38:03 1 cluster_commands.go:28] max volume id 217 ==> 218 I0324 14:38:03 1 cluster_commands.go:28] max volume id 218 ==> 219 I0324 14:38:06 1 master_server.go:175] [ sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 ] sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 is the leader. I0324 14:38:06 1 master.go:165] Start Seaweed Master 30GB 2.90 497ebbbd grpc server at 0.0.0.0:19333  ![  2022-03-24  19 52 04](https://user-images.githubusercontent.com/9497591/159943871-3af8a3f7-c484-4f4a-8e21-20725a57d911.png) ![  2022-03-24  19 57 52](https://user-images.githubusercontent.com/9497591/159945223-773e97aa-4743-4caf-be28-0f0d54f7b0f8.png)",source-file | source-file | source-file,"[bug:master] change of leader each time to the one who last started/restarted change of leader each time to the one who last started/restarted version  2.90  weed master run cmd:  /usr/bin/weed -logtostderr=true \ -v=1 \ master \ -mdir /data \ -port ""9333"" \ -defaultReplication=""100"" \ -metricsPort=9090 \ -volumeSizeLimitMB=1000 \ -resumeState=true \ -ip.bind=0.0.0.0 \ -ip ${POD_NAME}.$NAMESPACE-${SEAWEEDFS_FULLNAME}-master-direct.service.dc1.consul \ -peers sw-master-0.s3-sw-master-direct.service.dc1.consul:9333,sw-master-0.s3-sw-master-direct.service.dc2.consul:9333,sw-master-0.s3-sw-master-direct.service.dc3.consul:9333  logs:  I0324 14:37:48 1 config.go:44] Reading security.toml from /etc/seaweedfs/security.toml I0324 14:37:48 1 config.go:44] Reading master.toml from /etc/seaweedfs/master.toml I0324 14:37:48 1 file_util.go:23] Folder /data Permission: -rwxrwxr-x I0324 14:37:48 1 master.go:187] current: sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 peers:sw-master-0.s3-sw-master-direct.service.dc1.consul:9333,sw-master-0.s3-sw-master-direct.service.dc2.consul:9333,sw-master-0.s3-sw-master-direct.service.dc3.consul:9333 I0324 14:37:48 1 master_server.go:289] [master.sequencer.type] : [memory] I0324 14:37:48 1 master_server.go:122] Volume Size Limit is 1000 MB I0324 14:37:48 1 master.go:133] Start Seaweed Master 30GB 2.90 497ebbbd at 0.0.0.0:9333 I0324 14:37:48 1 raft_server.go:82] Starting RaftServer with sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 I0324 14:37:48 1 raft_server.go:61] Recovery raft state {MaxVolumeId:208} I0324 14:37:48 1 raft_server.go:143] current cluster leader: I0324 14:38:03 1 master_server.go:165] leader change event: => sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 I0324 14:38:03 1 master_server.go:168] [ sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 ] sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 becomes leader. I0324 14:38:03 1 cluster_commands.go:28] max volume id 208 ==> 209 I0324 14:38:03 1 cluster_commands.go:28] max volume id 209 ==> 210 I0324 14:38:03 1 cluster_commands.go:28] max volume id 210 ==> 211 I0324 14:38:03 1 cluster_commands.go:28] max volume id 211 ==> 212 I0324 14:38:03 1 cluster_commands.go:28] max volume id 212 ==> 213 I0324 14:38:03 1 cluster_commands.go:28] max volume id 213 ==> 214 I0324 14:38:03 1 cluster_commands.go:28] max volume id 214 ==> 215 I0324 14:38:03 1 cluster_commands.go:28] max volume id 215 ==> 216 I0324 14:38:03 1 cluster_commands.go:28] max volume id 216 ==> 217 I0324 14:38:03 1 cluster_commands.go:28] max volume id 217 ==> 218 I0324 14:38:03 1 cluster_commands.go:28] max volume id 218 ==> 219 I0324 14:38:06 1 master_server.go:175] [ sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 ] sw-master-0.s3-sw-master-direct.service.dc1.consul:9333 is the leader. I0324 14:38:06 1 master.go:165] Start Seaweed Master 30GB 2.90 497ebbbd grpc server at 0.0.0.0:19333  ![  2022-03-24  19 52 04](https://user-images.githubusercontent.com/9497591/159943871-3af8a3f7-c484-4f4a-8e21-20725a57d911.png) ![  2022-03-24  19 57 52](https://user-images.githubusercontent.com/9497591/159945223-773e97aa-4743-4caf-be28-0f0d54f7b0f8.png) source-file source-file source-file",no-bug,0.9
1782,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1782,"Error"" upload to filer error: rpc error"" occured when writing billions small files via s3 gateway","**update: The third error occured yesterday.I found a interesting thing. This error seems to happed on certain amount of files.** **The first error** [2021-02-03 09:26:55 070][INFO] Process: 11.96%(**1196347130**/10000000000), Ops: 6305/1s, Bandwidth: 23.25MB/1s(3.75TB), Error: 0.00%(34/10000000000) **The second error**[2021-02-05 03:53:51 071][INFO] Process: 22.70%(**2270023401**/10000000000), Ops: 1969/1s, Bandwidth: 8.13MB/1s(7.50TB), Error: 0.00%(113/10000000000) **The third error**[2021-02-07 01:40:36 070][INFO] Process: 33.44%(**3343713356**/10000000000), Ops: 5915/1s, Bandwidth: 21.70MB/1s(11.25TB), Error: 0.00%(200/10000000000) Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/chrislusf/seaweedfs/discussions example of a good issue report: https://github.com/chrislusf/seaweedfs/issues/1005 example of a bad issue report: https://github.com/chrislusf/seaweedfs/issues/1008 **Describe the bug** I am trying to test the performance of s3 gateway when uploading small files(filesize:1k,2k,4k.) Error"" upload to filer error: rpc error"" occured when writing billions small files via s3 gateway. The first error happend when 1196340762 files were uploaded. The second error happed when 2270023401 files were uploaded. Here are the logs of test tool: [2021-02-03 09:26:53 070][INFO] Process: 11.96%(1196340762/10000000000), Ops: 6248/1s, Bandwidth: 22.88MB/1s(3.75TB), Error: 0.00%(0/10000000000) [2021-02-03 09:26:54 070][INFO] Process: 11.96%(1196340825/10000000000), Ops: 63/1s, Bandwidth: 782.00KB/1s(3.75TB), Error: 0.00%(24/10000000000) [2021-02-03 09:26:55 070][INFO] Process: 11.96%(1196347130/10000000000), Ops: 6305/1s, Bandwidth: 23.25MB/1s(3.75TB), Error: 0.00%(34/10000000000) [2021-02-05 03:53:49 070][INFO] Process: 22.70%(2270016831/10000000000), Ops: 6841/1s, Bandwidth: 25.04MB/1s(7.50TB), Error: 0.00%(34/10000000000) [2021-02-05 03:53:50 072][INFO] Process: 22.70%(2270021432/10000000000), Ops: 4601/1s, Bandwidth: 17.51MB/1s(7.50TB), Error: 0.00%(37/10000000000) [2021-02-05 03:53:51 071][INFO] Process: 22.70%(2270023401/10000000000), Ops: 1969/1s, Bandwidth: 8.13MB/1s(7.50TB), Error: 0.00%(113/10000000000) [2021-02-05 03:53:52 070][INFO] Process: 22.70%(2270030654/10000000000), Ops: 7253/1s, Bandwidth: 26.68MB/1s(7.50TB), Error: 0.00%(113/10000000000 **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version :centos7.2 - output of `weed version` version 2.21 - if using filer, show the content of `filer.toml` **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: rpc error: code = Unavailable desc = transport is closing E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format:  E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: rpc error: code = Unavailable desc = transport is closing E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format:  2021-02-07 01:40:32 071][INFO] Process: 33.44%(3343695440/10000000000), Ops: 6098/1s, Bandwidth: 22.09MB/1s(11.25TB), Error: 0.00%(113/10000000000) [2021-02-07 01:40:33 070][INFO] Process: 33.44%(3343701204/10000000000), Ops: 5764/1s, Bandwidth: 21.19MB/1s(11.25TB), Error: 0.00%(113/10000000000) [2021-02-07 01:40:34 070][INFO] Process: 33.44%(3343701323/10000000000), Ops: 119/1s, Bandwidth: 1.69MB/1s(11.25TB), Error: 0.00%(196/10000000000) [2021-02-07 01:40:35 070][INFO] Process: 33.44%(3343707441/10000000000), Ops: 6118/1s, Bandwidth: 22.61MB/1s(11.25TB), Error: 0.00%(200/10000000000) [2021-02-07 01:40:36 070][INFO] Process: 33.44%(3343713356/10000000000), Ops: 5915/1s, Bandwidth: 21.70MB/1s(11.25TB), Error: 0.00%(200/10000000000)",source-file,"Error"" upload to filer error: rpc error"" occured when writing billions small files via s3 gateway **update: The third error occured yesterday.I found a interesting thing. This error seems to happed on certain amount of files.** **The first error** [2021-02-03 09:26:55 070][INFO] Process: 11.96%(**1196347130**/10000000000), Ops: 6305/1s, Bandwidth: 23.25MB/1s(3.75TB), Error: 0.00%(34/10000000000) **The second error**[2021-02-05 03:53:51 071][INFO] Process: 22.70%(**2270023401**/10000000000), Ops: 1969/1s, Bandwidth: 8.13MB/1s(7.50TB), Error: 0.00%(113/10000000000) **The third error**[2021-02-07 01:40:36 070][INFO] Process: 33.44%(**3343713356**/10000000000), Ops: 5915/1s, Bandwidth: 21.70MB/1s(11.25TB), Error: 0.00%(200/10000000000) Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/chrislusf/seaweedfs/discussions example of a good issue report: https://github.com/chrislusf/seaweedfs/issues/1005 example of a bad issue report: https://github.com/chrislusf/seaweedfs/issues/1008 **Describe the bug** I am trying to test the performance of s3 gateway when uploading small files(filesize:1k,2k,4k.) Error"" upload to filer error: rpc error"" occured when writing billions small files via s3 gateway. The first error happend when 1196340762 files were uploaded. The second error happed when 2270023401 files were uploaded. Here are the logs of test tool: [2021-02-03 09:26:53 070][INFO] Process: 11.96%(1196340762/10000000000), Ops: 6248/1s, Bandwidth: 22.88MB/1s(3.75TB), Error: 0.00%(0/10000000000) [2021-02-03 09:26:54 070][INFO] Process: 11.96%(1196340825/10000000000), Ops: 63/1s, Bandwidth: 782.00KB/1s(3.75TB), Error: 0.00%(24/10000000000) [2021-02-03 09:26:55 070][INFO] Process: 11.96%(1196347130/10000000000), Ops: 6305/1s, Bandwidth: 23.25MB/1s(3.75TB), Error: 0.00%(34/10000000000) [2021-02-05 03:53:49 070][INFO] Process: 22.70%(2270016831/10000000000), Ops: 6841/1s, Bandwidth: 25.04MB/1s(7.50TB), Error: 0.00%(34/10000000000) [2021-02-05 03:53:50 072][INFO] Process: 22.70%(2270021432/10000000000), Ops: 4601/1s, Bandwidth: 17.51MB/1s(7.50TB), Error: 0.00%(37/10000000000) [2021-02-05 03:53:51 071][INFO] Process: 22.70%(2270023401/10000000000), Ops: 1969/1s, Bandwidth: 8.13MB/1s(7.50TB), Error: 0.00%(113/10000000000) [2021-02-05 03:53:52 070][INFO] Process: 22.70%(2270030654/10000000000), Ops: 7253/1s, Bandwidth: 26.68MB/1s(7.50TB), Error: 0.00%(113/10000000000 **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version :centos7.2 - output of `weed version` version 2.21 - if using filer, show the content of `filer.toml` **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: rpc error: code = Unavailable desc = transport is closing E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0203 09:26:53 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format:  E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: rpc error: code = Unavailable desc = transport is closing E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: E0205 03:53:49 59074 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format:  2021-02-07 01:40:32 071][INFO] Process: 33.44%(3343695440/10000000000), Ops: 6098/1s, Bandwidth: 22.09MB/1s(11.25TB), Error: 0.00%(113/10000000000) [2021-02-07 01:40:33 070][INFO] Process: 33.44%(3343701204/10000000000), Ops: 5764/1s, Bandwidth: 21.19MB/1s(11.25TB), Error: 0.00%(113/10000000000) [2021-02-07 01:40:34 070][INFO] Process: 33.44%(3343701323/10000000000), Ops: 119/1s, Bandwidth: 1.69MB/1s(11.25TB), Error: 0.00%(196/10000000000) [2021-02-07 01:40:35 070][INFO] Process: 33.44%(3343707441/10000000000), Ops: 6118/1s, Bandwidth: 22.61MB/1s(11.25TB), Error: 0.00%(200/10000000000) [2021-02-07 01:40:36 070][INFO] Process: 33.44%(3343713356/10000000000), Ops: 5915/1s, Bandwidth: 21.70MB/1s(11.25TB), Error: 0.00%(200/10000000000) source-file",no-bug,0.9
26,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/26,File id assign with collection does not work,"File id assign with collection does not work on master server curl http://master:9333/dir/assign?collection=pictures returns {""fid"":""22,0139804a34"",""url"":""127.0.0.1:8080"",""publicUrl"":""172.17.42.1:8080"",""count"":1} But volume id 22 is not collection named volume id such as 22.dat 22.idx No new collection is created with above command. weed version is 0.65 linux amd64 Thanks in advance",documentation-file | documentation-file | config-file | other-file | config-file | config-file | config-file | config-file | config-file | config-file | test-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file,"File id assign with collection does not work File id assign with collection does not work on master server curl http://master:9333/dir/assign?collection=pictures returns {""fid"":""22,0139804a34"",""url"":""127.0.0.1:8080"",""publicUrl"":""172.17.42.1:8080"",""count"":1} But volume id 22 is not collection named volume id such as 22.dat 22.idx No new collection is created with above command. weed version is 0.65 linux amd64 Thanks in advance documentation-file documentation-file config-file other-file config-file config-file config-file config-file config-file config-file test-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file",bug,0.85
3320,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3320,[filer] duplicated local subscription detected,**Describe the bug** Persistent error background **System Setup**  version 8000GB 3.15 37578929 linux amd64  ![Screenshot 2022-07-15 at 17 53 26](https://user-images.githubusercontent.com/9497591/179227025-5a4b32c4-b83e-46fb-887a-6b2b66c0f82a.png) **Additional context**  I0715 12:40:02 1 meta_aggregator.go:102] subscribing remote 10.103.39.13:9090 meta change: rpc error: code = Unknown desc = duplicated local subscription detected for client filer:10.106.97.33:9090@10.106.97.33:41542 id 650053677 I0715 12:40:01 1 meta_aggregator.go:102] subscribing remote 10.103.39.35:9090 meta change: rpc error: code = Unknown desc = duplicated local subscription detected for client filer:10.106.97.2:9090@10.106.97.2:52844 id -1217481642  restarting api server does not help  kubectl -n s3 exec -it api-77db57df9b-5g4cn -- kill -s TERM 1 kubectl -n s3 get pods api-77db57df9b-5g4cn NAME READY STATUS RESTARTS AGE api-77db57df9b-5g4cn 1/1 Running 2 24h ,source-file | source-file,[filer] duplicated local subscription detected **Describe the bug** Persistent error background **System Setup**  version 8000GB 3.15 37578929 linux amd64  ![Screenshot 2022-07-15 at 17 53 26](https://user-images.githubusercontent.com/9497591/179227025-5a4b32c4-b83e-46fb-887a-6b2b66c0f82a.png) **Additional context**  I0715 12:40:02 1 meta_aggregator.go:102] subscribing remote 10.103.39.13:9090 meta change: rpc error: code = Unknown desc = duplicated local subscription detected for client filer:10.106.97.33:9090@10.106.97.33:41542 id 650053677 I0715 12:40:01 1 meta_aggregator.go:102] subscribing remote 10.103.39.35:9090 meta change: rpc error: code = Unknown desc = duplicated local subscription detected for client filer:10.106.97.2:9090@10.106.97.2:52844 id -1217481642  restarting api server does not help  kubectl -n s3 exec -it api-77db57df9b-5g4cn -- kill -s TERM 1 kubectl -n s3 get pods api-77db57df9b-5g4cn NAME READY STATUS RESTARTS AGE api-77db57df9b-5g4cn 1/1 Running 2 24h  source-file source-file,no-bug,0.8
4175,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4175,[shell] SIGSEV of the command filer.remote.sync on a S3 cloud mount,"**Describe the bug** The command `weed filer.remote.sync -dir=/media -filer localhost:8889` crash with a SIGSEV signal each time it's run. **System Setup** The system consists of 2 VM: - 1 weed master on the server1 - 2 weed volume on server1 and server 2 - 2 filer on server 1 and 2 - The filers use leveldb2 - the filers are replicated - Use of the Cloud drive functionality on /media, to synchronise files to an S3 storage - The remote storage is a S3 store by OVH The 2 servers run on Ubuntu 20.04, with the same patch level, updated 1 week ago Seaweed Version: version 30GB 3.40 2885ba0e508075762d732468334890c51f419aed linux amd64 The filer is configured from the command line without a file: `weed filer -port 8889 -ip.bind 0.0.0.0 -ip X.X.X.X -s3 -master X.X.X.X:9333 -dataCenter=XXXX -rack=XXX -metricsPort=9328` **Expected behavior** When using the command `weed filer.remote.sync -dir=/media -filer localhost:8889` the files were continuously synchronised to the S3 storage. This was working for 4 months I had to stop the sync process for a maintenance, when restarted the same command, it started to crash with SIGSEV, This is the output of the crash:  I0202 00:10:34.936962 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/b7b3/d9a0/CI_1-KKVQ2M_20230131102343081.b8ce.jpg I0202 00:10:34.946589 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/5cf2/4dc9/CR_CAM23004904_001.5402.pdf panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x28 pc=0x102f023] goroutine 444 [running]: github.com/seaweedfs/seaweedfs/weed/filer.(*ChunkStreamReader).prepareBufferFor(0x3c6d3a0?, 0xc000f7da08?) /github/workspace/weed/filer/stream.go:305 +0x43 github.com/seaweedfs/seaweedfs/weed/filer.(*ChunkStreamReader).ReadAt(0xc000a0e000, {0xc000fd8000, 0x2000, 0x2000}, 0x0) /github/workspace/weed/filer/stream.go:241 +0xc8 io.(*SectionReader).Read(0xc000ac8900, {0xc000fd8000?, 0xc000f7da30?, 0x3?}) /usr/local/go/src/io/io.go:513 +0x54 github.com/aws/aws-sdk-go/aws/request.(*offsetReader).Read(0x3c094c0?, {0xc000fd8000?, 0xc0006cfc00?, 0x7f3e7a30ba80?}) /go/pkg/mod/github.com/aws/aws-sdk-go@v1.44.175/aws/request/offset_reader.go:47 +0x129 io.discard.ReadFrom({}, {0x7f3e7a34e130, 0xc00013d6e0}) /usr/local/go/src/io/io.go:611 +0x72 io.copyBuffer({0x2a18380, 0x3c6a420}, {0x7f3e7a34e130, 0xc00013d6e0}, {0x0, 0x0, 0x0}) /usr/local/go/src/io/io.go:413 +0x14b io.Copy() /usr/local/go/src/io/io.go:386 net/http.(*transferWriter).doBodyCopy(0xc000001720, {0x2a18380?, 0x3c6a420?}, {0x7f3e7a34e130?, 0xc00013d6e0?}) /usr/local/go/src/net/http/transfer.go:412 +0x4d net/http.(*transferWriter).writeBody(0xc000001720, {0x2a0a420, 0xc0006eccc0}) /usr/local/go/src/net/http/transfer.go:375 +0x418 net/http.(*Request).write(0xc00047b500, {0x2a0a420, 0xc0006eccc0}, 0x0, 0xc000f519b0, 0x0) /usr/local/go/src/net/http/request.go:701 +0xb46 net/http.(*persistConn).writeLoop(0xc0004ed680) /usr/local/go/src/net/http/transport.go:2395 +0x174 created by net/http.(*Transport).dialConn /usr/local/go/src/net/http/transport.go:1752 +0x1791  When launching the command a second time, it seems to continue to process new files, but then crash later:  I0202 00:14:25.445717 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/f7ba/7a16/CI_1-KBIVC9_20230131091836485.0dcd.jpg I0202 00:14:25.455761 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/ae0b/37cc/CI_1-KCQ2RK_20230131155422324.89c4.jpg I0202 00:14:25.475629 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/4feb/dc60/CI_1-KCQ2RK_20230131155458711.2f07.jpg panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x28 pc=0x102f023] goroutine 454 [running]: github.com/seaweedfs/seaweedfs/weed/filer.(*ChunkStreamReader).prepareBufferFor(0x3c6d3a0?, 0xc000fb3a08?) /github/workspace/weed/filer/stream.go:305 +0x43 github.com/seaweedfs/seaweedfs/weed/filer.(*ChunkStreamReader).ReadAt(0xc000e66480, {0xc000836000, 0x2000, 0x2000}, 0x0) /github/workspace/weed/filer/stream.go:241 +0xc8 io.(*SectionReader).Read(0xc000f42510, {0xc000836000?, 0xc000fb3a30?, 0x3?}) /usr/local/go/src/io/io.go:513 +0x54 github.com/aws/aws-sdk-go/aws/request.(*offsetReader).Read(0x3c094c0?, {0xc000836000?, 0xc000d6a000?, 0x7fc4ccd0aa18?}) /go/pkg/mod/github.com/aws/aws-sdk-go@v1.44.175/aws/request/offset_reader.go:47 +0x129 io.discard.ReadFrom({}, {0x7fc4ccd4ba50, 0xc000f46140}) /usr/local/go/src/io/io.go:611 +0x72 io.copyBuffer({0x2a18380, 0x3c6a420}, {0x7fc4ccd4ba50, 0xc000f46140}, {0x0, 0x0, 0x0}) /usr/local/go/src/io/io.go:413 +0x14b io.Copy() /usr/local/go/src/io/io.go:386 net/http.(*transferWriter).doBodyCopy(0xc0005686e0, {0x2a18380?, 0x3c6a420?}, {0x7fc4ccd4ba50?, 0xc000f46140?}) /usr/local/go/src/net/http/transfer.go:412 +0x4d net/http.(*transferWriter).writeBody(0xc0005686e0, {0x2a0a420, 0xc000b182c0}) /usr/local/go/src/net/http/transfer.go:375 +0x418 net/http.(*Request).write(0xc000547000, {0x2a0a420, 0xc000b182c0}, 0x0, 0xc0008af890, 0x0) /usr/local/go/src/net/http/request.go:701 +0xb46 net/http.(*persistConn).writeLoop(0xc0003b9b00) /usr/local/go/src/net/http/transport.go:2395 +0x174 created by net/http.(*Transport).dialConn /usr/local/go/src/net/http/transport.go:1752 +0x1791  The command crash after synchronising multiples files. The number of files synchronised before the crash is not constant, sometimes it's 2 or 3 more or less than the last run.",source-file,"[shell] SIGSEV of the command filer.remote.sync on a S3 cloud mount **Describe the bug** The command `weed filer.remote.sync -dir=/media -filer localhost:8889` crash with a SIGSEV signal each time it's run. **System Setup** The system consists of 2 VM: - 1 weed master on the server1 - 2 weed volume on server1 and server 2 - 2 filer on server 1 and 2 - The filers use leveldb2 - the filers are replicated - Use of the Cloud drive functionality on /media, to synchronise files to an S3 storage - The remote storage is a S3 store by OVH The 2 servers run on Ubuntu 20.04, with the same patch level, updated 1 week ago Seaweed Version: version 30GB 3.40 2885ba0e508075762d732468334890c51f419aed linux amd64 The filer is configured from the command line without a file: `weed filer -port 8889 -ip.bind 0.0.0.0 -ip X.X.X.X -s3 -master X.X.X.X:9333 -dataCenter=XXXX -rack=XXX -metricsPort=9328` **Expected behavior** When using the command `weed filer.remote.sync -dir=/media -filer localhost:8889` the files were continuously synchronised to the S3 storage. This was working for 4 months I had to stop the sync process for a maintenance, when restarted the same command, it started to crash with SIGSEV, This is the output of the crash:  I0202 00:10:34.936962 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/b7b3/d9a0/CI_1-KKVQ2M_20230131102343081.b8ce.jpg I0202 00:10:34.946589 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/5cf2/4dc9/CR_CAM23004904_001.5402.pdf panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x28 pc=0x102f023] goroutine 444 [running]: github.com/seaweedfs/seaweedfs/weed/filer.(*ChunkStreamReader).prepareBufferFor(0x3c6d3a0?, 0xc000f7da08?) /github/workspace/weed/filer/stream.go:305 +0x43 github.com/seaweedfs/seaweedfs/weed/filer.(*ChunkStreamReader).ReadAt(0xc000a0e000, {0xc000fd8000, 0x2000, 0x2000}, 0x0) /github/workspace/weed/filer/stream.go:241 +0xc8 io.(*SectionReader).Read(0xc000ac8900, {0xc000fd8000?, 0xc000f7da30?, 0x3?}) /usr/local/go/src/io/io.go:513 +0x54 github.com/aws/aws-sdk-go/aws/request.(*offsetReader).Read(0x3c094c0?, {0xc000fd8000?, 0xc0006cfc00?, 0x7f3e7a30ba80?}) /go/pkg/mod/github.com/aws/aws-sdk-go@v1.44.175/aws/request/offset_reader.go:47 +0x129 io.discard.ReadFrom({}, {0x7f3e7a34e130, 0xc00013d6e0}) /usr/local/go/src/io/io.go:611 +0x72 io.copyBuffer({0x2a18380, 0x3c6a420}, {0x7f3e7a34e130, 0xc00013d6e0}, {0x0, 0x0, 0x0}) /usr/local/go/src/io/io.go:413 +0x14b io.Copy() /usr/local/go/src/io/io.go:386 net/http.(*transferWriter).doBodyCopy(0xc000001720, {0x2a18380?, 0x3c6a420?}, {0x7f3e7a34e130?, 0xc00013d6e0?}) /usr/local/go/src/net/http/transfer.go:412 +0x4d net/http.(*transferWriter).writeBody(0xc000001720, {0x2a0a420, 0xc0006eccc0}) /usr/local/go/src/net/http/transfer.go:375 +0x418 net/http.(*Request).write(0xc00047b500, {0x2a0a420, 0xc0006eccc0}, 0x0, 0xc000f519b0, 0x0) /usr/local/go/src/net/http/request.go:701 +0xb46 net/http.(*persistConn).writeLoop(0xc0004ed680) /usr/local/go/src/net/http/transport.go:2395 +0x174 created by net/http.(*Transport).dialConn /usr/local/go/src/net/http/transport.go:1752 +0x1791  When launching the command a second time, it seems to continue to process new files, but then crash later:  I0202 00:14:25.445717 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/f7ba/7a16/CI_1-KBIVC9_20230131091836485.0dcd.jpg I0202 00:14:25.455761 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/ae0b/37cc/CI_1-KCQ2RK_20230131155422324.89c4.jpg I0202 00:14:25.475629 filer_remote_sync_dir.go:193 create ovhMedia/media-prod/ged/4feb/dc60/CI_1-KCQ2RK_20230131155458711.2f07.jpg panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x28 pc=0x102f023] goroutine 454 [running]: github.com/seaweedfs/seaweedfs/weed/filer.(*ChunkStreamReader).prepareBufferFor(0x3c6d3a0?, 0xc000fb3a08?) /github/workspace/weed/filer/stream.go:305 +0x43 github.com/seaweedfs/seaweedfs/weed/filer.(*ChunkStreamReader).ReadAt(0xc000e66480, {0xc000836000, 0x2000, 0x2000}, 0x0) /github/workspace/weed/filer/stream.go:241 +0xc8 io.(*SectionReader).Read(0xc000f42510, {0xc000836000?, 0xc000fb3a30?, 0x3?}) /usr/local/go/src/io/io.go:513 +0x54 github.com/aws/aws-sdk-go/aws/request.(*offsetReader).Read(0x3c094c0?, {0xc000836000?, 0xc000d6a000?, 0x7fc4ccd0aa18?}) /go/pkg/mod/github.com/aws/aws-sdk-go@v1.44.175/aws/request/offset_reader.go:47 +0x129 io.discard.ReadFrom({}, {0x7fc4ccd4ba50, 0xc000f46140}) /usr/local/go/src/io/io.go:611 +0x72 io.copyBuffer({0x2a18380, 0x3c6a420}, {0x7fc4ccd4ba50, 0xc000f46140}, {0x0, 0x0, 0x0}) /usr/local/go/src/io/io.go:413 +0x14b io.Copy() /usr/local/go/src/io/io.go:386 net/http.(*transferWriter).doBodyCopy(0xc0005686e0, {0x2a18380?, 0x3c6a420?}, {0x7fc4ccd4ba50?, 0xc000f46140?}) /usr/local/go/src/net/http/transfer.go:412 +0x4d net/http.(*transferWriter).writeBody(0xc0005686e0, {0x2a0a420, 0xc000b182c0}) /usr/local/go/src/net/http/transfer.go:375 +0x418 net/http.(*Request).write(0xc000547000, {0x2a0a420, 0xc000b182c0}, 0x0, 0xc0008af890, 0x0) /usr/local/go/src/net/http/request.go:701 +0xb46 net/http.(*persistConn).writeLoop(0xc0003b9b00) /usr/local/go/src/net/http/transport.go:2395 +0x174 created by net/http.(*Transport).dialConn /usr/local/go/src/net/http/transport.go:1752 +0x1791  The command crash after synchronising multiples files. The number of files synchronised before the crash is not constant, sometimes it's 2 or 3 more or less than the last run. source-file",no-bug,0.9
4971,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4971,S3 gateway fails to connect to Filer on non-standard port when running together,"**Describe the bug** When Filer runs together with S3 and Filer has non-standard gRPC port, managed by third-party system (Nomad in my case), S3 cannot connect to Filer, assuming default gRPC port being 10000+port:  port ""filer"" { static = 8280 to = 8280 host_network = ""internal"" } // Static port for gRPC is set for illustrative purposes, usually it is allocated dynamically. port ""grpc"" { static = 18380 to = 18380 host_network = ""internal"" } I1101 15:47:51.437282 s3.go:203 wait to connect to filer 172.30.18.200:8280 grpc address 172.30.18.200:18280 I1101 15:47:52.439709 s3.go:203 wait to connect to filer 172.30.18.200:8280 grpc address 172.30.18.200:18280 I1101 15:47:53.442039 s3.go:203 wait to connect to filer 172.30.18.200:8280 grpc address 172.30.18.200:18280  **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # weed filer \ -master=seaweedfs-master.service.consul:9333 \ -ip=${NOMAD_IP_filer} \ -port=${NOMAD_PORT_filer} \ -port.grpc=${NOMAD_PORT_grpc} \ -ip.bind=0.0.0.0 \ -dataCenter=dc1 \ -rack=rack0 \ -metricsPort=${NOMAD_PORT_metrics} \ -s3=true \ -s3.port=${NOMAD_PORT_s3} \ -s3.port.grpc=${NOMAD_PORT_s3grpc} \ -s3.config=${NOMAD_ALLOC_DIR}/s3.conf \ -s3.dataCenter=dc1  - OS version  # uname -a Linux b94fda572829 5.15.0-86-generic #96-Ubuntu SMP Wed Sep 20 08:23:49 UTC 2023 x86_64 Linux  - output of `weed version`  # weed version version 30GB 3.58 d1e83a3b4 linux amd64  - if using filer, show the content of `filer.toml`  [leveldb2] enabled = true dir = ""."" # directory to store level db files  **Expected behavior** S3 gateway server connects to Filer's correct gRPC port.",source-file | source-file | source-file | source-file,"S3 gateway fails to connect to Filer on non-standard port when running together **Describe the bug** When Filer runs together with S3 and Filer has non-standard gRPC port, managed by third-party system (Nomad in my case), S3 cannot connect to Filer, assuming default gRPC port being 10000+port:  port ""filer"" { static = 8280 to = 8280 host_network = ""internal"" } // Static port for gRPC is set for illustrative purposes, usually it is allocated dynamically. port ""grpc"" { static = 18380 to = 18380 host_network = ""internal"" } I1101 15:47:51.437282 s3.go:203 wait to connect to filer 172.30.18.200:8280 grpc address 172.30.18.200:18280 I1101 15:47:52.439709 s3.go:203 wait to connect to filer 172.30.18.200:8280 grpc address 172.30.18.200:18280 I1101 15:47:53.442039 s3.go:203 wait to connect to filer 172.30.18.200:8280 grpc address 172.30.18.200:18280  **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # weed filer \ -master=seaweedfs-master.service.consul:9333 \ -ip=${NOMAD_IP_filer} \ -port=${NOMAD_PORT_filer} \ -port.grpc=${NOMAD_PORT_grpc} \ -ip.bind=0.0.0.0 \ -dataCenter=dc1 \ -rack=rack0 \ -metricsPort=${NOMAD_PORT_metrics} \ -s3=true \ -s3.port=${NOMAD_PORT_s3} \ -s3.port.grpc=${NOMAD_PORT_s3grpc} \ -s3.config=${NOMAD_ALLOC_DIR}/s3.conf \ -s3.dataCenter=dc1  - OS version  # uname -a Linux b94fda572829 5.15.0-86-generic #96-Ubuntu SMP Wed Sep 20 08:23:49 UTC 2023 x86_64 Linux  - output of `weed version`  # weed version version 30GB 3.58 d1e83a3b4 linux amd64  - if using filer, show the content of `filer.toml`  [leveldb2] enabled = true dir = ""."" # directory to store level db files  **Expected behavior** S3 gateway server connects to Filer's correct gRPC port. source-file source-file source-file source-file",no-bug,0.9
27,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/27,"New to this project, the readme page does not seem to have instructions on how to compile source locally",could you please provide more details? thanks! Shaoshan,source-file | test-file | source-file | source-file,"New to this project, the readme page does not seem to have instructions on how to compile source locally could you please provide more details? thanks! Shaoshan source-file test-file source-file source-file",no-bug,0.9
861,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/861,TTL marshal result is empty influencing /vol/status api result,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** because TTL's members are invisible out of package, so when json.Marshal is called, all the TTL info are empty, which influences the /vol/status api golang type TTL struct { count byte unit byte } ",source-file | source-file,"TTL marshal result is empty influencing /vol/status api result Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** because TTL's members are invisible out of package, so when json.Marshal is called, all the TTL info are empty, which influences the /vol/status api golang type TTL struct { count byte unit byte }  source-file source-file",bug,0.9
913,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/913,allocating all available volumes fails,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** I tried to allocate all available volumes (which was 6,400 volumes) and it allocated all but 42 of the volumes and then threw an error (then I was able to allocate the last 42 volumes successfully)  $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Failed to assign 6625: rpc error: code = Unknown desc = No more free space left""} $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Only 42 volumes left! Not enough for 6400""} $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=42"" {""count"":42}  (sorry, didn't get screen shots) after deleting all volumes and running again, I got got a different error and strangely I see 6,400 volumes allocated but it says 397 volumes free (which should be 0 volumes free)  $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Failed to assign 6669: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = \""transport: Error while dialing dial tcp 192.168.X.XXX:18080: connect: connection refused\""""}  and strangely it say 397 volumes are free ![image](https://user-images.githubusercontent.com/4112046/55459751-1b730b80-55a5-11e9-9bd8-7121623f067b.png) even though the volume servers show a total of 6400 volumes ![image](https://user-images.githubusercontent.com/4112046/55459802-3c3b6100-55a5-11e9-9249-359442fc9d19.png) **System Setup** `master` `filer` and `s3` on one machine and `volume` on 4 separate machines **Expected behavior** allocating all available volumes should succeed and counts should make sense **Screenshots** n/a **Additional context** n/a",source-file | source-file | source-file | source-file | source-file,"allocating all available volumes fails Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** I tried to allocate all available volumes (which was 6,400 volumes) and it allocated all but 42 of the volumes and then threw an error (then I was able to allocate the last 42 volumes successfully)  $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Failed to assign 6625: rpc error: code = Unknown desc = No more free space left""} $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Only 42 volumes left! Not enough for 6400""} $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=42"" {""count"":42}  (sorry, didn't get screen shots) after deleting all volumes and running again, I got got a different error and strangely I see 6,400 volumes allocated but it says 397 volumes free (which should be 0 volumes free)  $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Failed to assign 6669: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = \""transport: Error while dialing dial tcp 192.168.X.XXX:18080: connect: connection refused\""""}  and strangely it say 397 volumes are free ![image](https://user-images.githubusercontent.com/4112046/55459751-1b730b80-55a5-11e9-9bd8-7121623f067b.png) even though the volume servers show a total of 6400 volumes ![image](https://user-images.githubusercontent.com/4112046/55459802-3c3b6100-55a5-11e9-9249-359442fc9d19.png) **System Setup** `master` `filer` and `s3` on one machine and `volume` on 4 separate machines **Expected behavior** allocating all available volumes should succeed and counts should make sense **Screenshots** n/a **Additional context** n/a source-file source-file source-file source-file source-file",bug,0.9
1161,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1161,How do I create an empty directory?,"This is what I tried: curl -X PUT ""http://localhost:8888/test/"" => {""error"":""can not to write to folder /test/ without a file name""} curl -X POST ""http://localhost:8888/test/"" => {""error"":""request Content-Type isn't multipart/form-data""} curl -X PUT ""http://localhost:8888/test"" => creates a 0 byte file curl -X POST ""http://localhost:8888/test"" => {""error"":""request Content-Type isn't multipart/form-data""}",source-file,"How do I create an empty directory? This is what I tried: curl -X PUT ""http://localhost:8888/test/"" => {""error"":""can not to write to folder /test/ without a file name""} curl -X POST ""http://localhost:8888/test/"" => {""error"":""request Content-Type isn't multipart/form-data""} curl -X PUT ""http://localhost:8888/test"" => creates a 0 byte file curl -X POST ""http://localhost:8888/test"" => {""error"":""request Content-Type isn't multipart/form-data""} source-file",bug,0.9
8,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/8,Remove image-related features,"I think that weed-fs should be as simple as possible and do only one thing, but do it awesome.",test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | other-file | config-file | config-file | config-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file,"Remove image-related features I think that weed-fs should be as simple as possible and do only one thing, but do it awesome. test-file source-file source-file source-file source-file source-file source-file source-file source-file config-file other-file config-file config-file config-file source-file source-file source-file config-file config-file source-file source-file source-file",no-bug,0.9
2928,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2928,[vacuum] rename /data/logs_447.cpd /data/logs-prod_447.dat: no such file or directory,"**Describe the bug** logs master  topology_vacuum.go:134] Error when committing vacuum 447 on slow-volume-19:8080: rpc error: code = Unknown desc = rename /data/logs_447.cpd: rename /data/logs_447.cpd /data/logs_447.dat: no such file or directory topology_vacuum.go:134] Error when committing vacuum 447 on slow-volume-13.:8080: rpc error: code = Unknown desc = rename /data/logs_447.cpd: rename /data/logs_447.cpd /data/logs_447.dat: no such file or directory  panic logs slow-volume-19  Apr 17, 2022 @ 08:04:13.790 | I0417 03:04:13 1 volume_vacuum.go:95] Committing volume 447 vacuuming Apr 17, 2022 @ 08:04:13.790 | E0417 03:04:13 1 volume_grpc_vacuum.go:66] commit volume 447: rename /data/logs_447.cpd: rename /data/logs_447.cpd /data/logs-prod_447.dat: no such file or directory Apr 17, 2022 @ 08:04:14.795 | panic: runtime error: invalid memory address or nil pointer dereference Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/server/volume_grpc_client_to_master.go:67 +0x24c Apr 17, 2022 @ 08:04:14.795 | created by github.com/chrislusf/seaweedfs/weed/server.NewVolumeServer Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/storage.(*Volume).ToVolumeInformationMessage(0xc000b5c120) Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/server/volume_server.go:116 +0x985 Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/server/volume_grpc_client_to_master.go:201 +0x12e7 Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/storage/volume.go:270 +0x18e Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/storage/store.go:227 +0x82a Apr 17, 2022 @ 08:04:14.795 | - Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).doHeartbeat(0xc0003fa1e0, {0xc003c58180, 0x29a34fc}, {0x2fb0420, 0xc0002913a0}, 0x12a05f200) Apr 17, 2022 @ 08:04:14.795 | [signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0xee6e4e] Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/storage.(*Store).CollectHeartbeat(0xc0007a84e0) Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/storage.(*Volume).collectStatus(0xc000b5c120) Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/storage/volume.go:281 +0x33 Apr 17, 2022 @ 08:04:14.795 | goroutine 70 [running]: Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).heartbeat(0xc0003fa1e0)  ls  /data # ls -l *447* -rw-r--r-- 1 root 99 74004510256 Apr 17 04:12 logs_447.dat -rw-r--r-- 1 root 99 212466 Apr 17 04:12 logs_447.idx -rw-rw-r-- 1 root 99 57 Jun 21 2021 logs_447.vif  **System Setup** 2.98",source-file | source-file,"[vacuum] rename /data/logs_447.cpd /data/logs-prod_447.dat: no such file or directory **Describe the bug** logs master  topology_vacuum.go:134] Error when committing vacuum 447 on slow-volume-19:8080: rpc error: code = Unknown desc = rename /data/logs_447.cpd: rename /data/logs_447.cpd /data/logs_447.dat: no such file or directory topology_vacuum.go:134] Error when committing vacuum 447 on slow-volume-13.:8080: rpc error: code = Unknown desc = rename /data/logs_447.cpd: rename /data/logs_447.cpd /data/logs_447.dat: no such file or directory  panic logs slow-volume-19  Apr 17, 2022 @ 08:04:13.790 | I0417 03:04:13 1 volume_vacuum.go:95] Committing volume 447 vacuuming Apr 17, 2022 @ 08:04:13.790 | E0417 03:04:13 1 volume_grpc_vacuum.go:66] commit volume 447: rename /data/logs_447.cpd: rename /data/logs_447.cpd /data/logs-prod_447.dat: no such file or directory Apr 17, 2022 @ 08:04:14.795 | panic: runtime error: invalid memory address or nil pointer dereference Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/server/volume_grpc_client_to_master.go:67 +0x24c Apr 17, 2022 @ 08:04:14.795 | created by github.com/chrislusf/seaweedfs/weed/server.NewVolumeServer Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/storage.(*Volume).ToVolumeInformationMessage(0xc000b5c120) Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/server/volume_server.go:116 +0x985 Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/server/volume_grpc_client_to_master.go:201 +0x12e7 Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/storage/volume.go:270 +0x18e Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/storage/store.go:227 +0x82a Apr 17, 2022 @ 08:04:14.795 | - Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).doHeartbeat(0xc0003fa1e0, {0xc003c58180, 0x29a34fc}, {0x2fb0420, 0xc0002913a0}, 0x12a05f200) Apr 17, 2022 @ 08:04:14.795 | [signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0xee6e4e] Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/storage.(*Store).CollectHeartbeat(0xc0007a84e0) Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/storage.(*Volume).collectStatus(0xc000b5c120) Apr 17, 2022 @ 08:04:14.795 | /go/src/github.com/chrislusf/seaweedfs/weed/storage/volume.go:281 +0x33 Apr 17, 2022 @ 08:04:14.795 | goroutine 70 [running]: Apr 17, 2022 @ 08:04:14.795 | github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).heartbeat(0xc0003fa1e0)  ls  /data # ls -l *447* -rw-r--r-- 1 root 99 74004510256 Apr 17 04:12 logs_447.dat -rw-r--r-- 1 root 99 212466 Apr 17 04:12 logs_447.idx -rw-rw-r-- 1 root 99 57 Jun 21 2021 logs_447.vif  **System Setup** 2.98 source-file source-file",no-bug,0.9
512,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/512,master,"Hi Chris Lu: masterleadermasterleadervolume servermaster 0.76 windowsip10.0.0.95centosIP10.0.0.163  1.windowsmaster weed master -mdir=master -ip=10.0.0.95 ip.bind=10.0.0.95 2.centosmaster weed master -mdir=master -peers=10.0.0.95:9333 -ip=10.0.0.163 ip.bind=10.0.0.163 3.windowvolume server weed.exe volume -dir=data -port=""8081"" -mserver=10.0.0.95:9333 -ip=10.0.0.95 ip.bind=10.0.0.95 1.jpg http://10.0.0.163:9333/submit http://10.0.0.95:9333/http://10.0.0.163:9333/ 4. leader 95http://10.0.0.163:9333/submit { ""error"": ""Raft Server not initialized!"" } # **95masterlog** weed master -mdir=master -ip=10.0.0.95 ip.bind=10.0.0.95 I0615 17:27:50 5980 file_util.go:20] Folder master Permission: -rwxrwxrwx I0615 17:27:50 5980 master_server.go:62] Volume Size Limit is 30000 MB I0615 17:27:50 5980 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0615 17:27:50 5980 raft_server.go:56] Peers Change: [10.0.0.163:9333 10.0.0.95:9333] => [] I0615 17:27:50 5980 raft_server.go:98] Initializing new cluster I0615 17:27:50 5980 master_server.go:95] [ 10.0.0.95:9333 ] I am the leader! I0615 17:27:55 5980 raft_server_handlers.go:16] Processing incoming join. Current Leader 10.0.0.95:9333 Self 10.0.0.95:9333 Peers map[] I0615 17:27:55 5980 raft_server_handlers.go:20] Command:{""name"":""10.0.0.163:9333"",""connectionString"":""http://10.0.0.163:9333""} I0615 17:27:55 5980 raft_server_handlers.go:27] join command from Name 10.0.0.163:9333 Connection http://10.0.0.163:9333 I0615 17:28:08 5980 node.go:223] topo adds child DefaultDataCenter I0615 17:28:08 5980 node.go:223] topo:DefaultDataCenter adds child DefaultRack I0615 17:28:08 5980 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 10.0.0.95:8081 I0615 17:28:08 5980 master_grpc_server.go:36] added volume server 10.0.0.95:8081 # **95volume log** weed.exe volume -dir=data -port=""8081"" -mserver=10.0.0.95:9333 -ip=10.0.0.95 ip.bind=10.0.0.95 I0615 17:28:08 10076 file_util.go:20] Folder data Permission: -rwxrwxrwx I0615 17:28:08 10076 volume_loading.go:73] loading index data/6.idx to memory readonly false I0615 17:28:08 10076 volume_loading.go:73] loading index data/1.idx to memory readonly false I0615 17:28:08 10076 volume_loading.go:73] loading index data/5.idx to memory readonly false I0615 17:28:08 10076 volume_loading.go:73] loading index data/4.idx to memory readonly false I0615 17:28:08 10076 volume_loading.go:73] loading index data/2.idx to memory readonly false I0615 17:28:08 10076 disk_location.go:56] data file data/6.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 volume_loading.go:73] loading index data/7.idx to memory readonly false I0615 17:28:08 10076 disk_location.go:56] data file data/7.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 disk_location.go:56] data file data/2.dat, replicaPlacement=000 v=2 size=639800 ttl= I0615 17:28:08 10076 disk_location.go:56] data file data/1.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 disk_location.go:56] data file data/5.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 disk_location.go:56] data file data/4.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 volume_loading.go:73] loading index data/3.idx to memory readonly false I0615 17:28:08 10076 disk_location.go:56] data file data/3.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 disk_location.go:106] Store started on dir: data with 7 volumes max 7 I0615 17:28:08 10076 volume.go:143] Start Seaweed volume server 0.76 at 0.0.0.0:8081 I0615 17:28:08 10076 volume_grpc_client.go:17] Volume server bootstraps with master 10.0.0.95:9333 I0615 17:28:08 10076 volume_grpc_client.go:52] Heartbeat to 10.0.0.95:9333 2017/06/15 17:29:14 transport: http2Client.notifyError got notified that the client transport was broken read tcp 10.0.0.95:12367->10.0.0.95:9333: wsarecv: An existing connection was forcibly closed by the remote host.. I0615 17:29:14 10076 volume_grpc_client.go:95] Volume Server heart beat stops with rpc error: code = Internal desc = transport is closing I0615 17:29:14 10076 volume_grpc_client.go:25] heartbeat error: rpc error: code = Internal desc = transport is closing 2017/06/15 17:29:14 grpc: addrConn.resetTransport failed to create client transport: connection error: desc = ""transport: Error while dialing dial tcp 10.0.0.95:9333: operation was canceled""; Reconnecting to {10.0.0.95:9333 <nil>} 2017/06/15 17:29:14 grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing I0615 17:29:19 10076 store.go:35] Resetting master nodes: nodes:[10.0.0.163:9333 10.0.0.95:9333 10.0.0.95:9333], leader: I0615 17:29:21 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:28 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:35 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:42 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:49 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:56 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:03 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:10 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:17 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:24 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:31 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:38 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:45 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:52 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:59 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! # **163master log** weed master -mdir=master -peers=10.0.0.95:9333 -ip=10.0.0.163 ip.bind=10.0.0.163 I0615 17:28:01 9904 file_util.go:20] Folder master Permission: -rwxrwxr-x I0615 17:28:01 9904 master_server.go:62] Volume Size Limit is 30000 MB I0615 17:28:01 9904 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0615 17:28:01 9904 raft_server.go:56] Peers Change: [10.0.0.163:9333 10.0.0.95:9333] => [10.0.0.95:9333] I0615 17:28:01 9904 raft_server.go:78] Joining cluster: 10.0.0.95:9333 I0615 17:28:02 9904 raft_server.go:166] Attempting to connect to: http://10.0.0.95:9333/cluster/join I0615 17:28:02 9904 raft_server.go:211] Post returned status: 200",source-file | source-file,"master Hi Chris Lu: masterleadermasterleadervolume servermaster 0.76 windowsip10.0.0.95centosIP10.0.0.163  1.windowsmaster weed master -mdir=master -ip=10.0.0.95 ip.bind=10.0.0.95 2.centosmaster weed master -mdir=master -peers=10.0.0.95:9333 -ip=10.0.0.163 ip.bind=10.0.0.163 3.windowvolume server weed.exe volume -dir=data -port=""8081"" -mserver=10.0.0.95:9333 -ip=10.0.0.95 ip.bind=10.0.0.95 1.jpg http://10.0.0.163:9333/submit http://10.0.0.95:9333/http://10.0.0.163:9333/ 4. leader 95http://10.0.0.163:9333/submit { ""error"": ""Raft Server not initialized!"" } # **95masterlog** weed master -mdir=master -ip=10.0.0.95 ip.bind=10.0.0.95 I0615 17:27:50 5980 file_util.go:20] Folder master Permission: -rwxrwxrwx I0615 17:27:50 5980 master_server.go:62] Volume Size Limit is 30000 MB I0615 17:27:50 5980 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0615 17:27:50 5980 raft_server.go:56] Peers Change: [10.0.0.163:9333 10.0.0.95:9333] => [] I0615 17:27:50 5980 raft_server.go:98] Initializing new cluster I0615 17:27:50 5980 master_server.go:95] [ 10.0.0.95:9333 ] I am the leader! I0615 17:27:55 5980 raft_server_handlers.go:16] Processing incoming join. Current Leader 10.0.0.95:9333 Self 10.0.0.95:9333 Peers map[] I0615 17:27:55 5980 raft_server_handlers.go:20] Command:{""name"":""10.0.0.163:9333"",""connectionString"":""http://10.0.0.163:9333""} I0615 17:27:55 5980 raft_server_handlers.go:27] join command from Name 10.0.0.163:9333 Connection http://10.0.0.163:9333 I0615 17:28:08 5980 node.go:223] topo adds child DefaultDataCenter I0615 17:28:08 5980 node.go:223] topo:DefaultDataCenter adds child DefaultRack I0615 17:28:08 5980 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 10.0.0.95:8081 I0615 17:28:08 5980 master_grpc_server.go:36] added volume server 10.0.0.95:8081 # **95volume log** weed.exe volume -dir=data -port=""8081"" -mserver=10.0.0.95:9333 -ip=10.0.0.95 ip.bind=10.0.0.95 I0615 17:28:08 10076 file_util.go:20] Folder data Permission: -rwxrwxrwx I0615 17:28:08 10076 volume_loading.go:73] loading index data/6.idx to memory readonly false I0615 17:28:08 10076 volume_loading.go:73] loading index data/1.idx to memory readonly false I0615 17:28:08 10076 volume_loading.go:73] loading index data/5.idx to memory readonly false I0615 17:28:08 10076 volume_loading.go:73] loading index data/4.idx to memory readonly false I0615 17:28:08 10076 volume_loading.go:73] loading index data/2.idx to memory readonly false I0615 17:28:08 10076 disk_location.go:56] data file data/6.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 volume_loading.go:73] loading index data/7.idx to memory readonly false I0615 17:28:08 10076 disk_location.go:56] data file data/7.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 disk_location.go:56] data file data/2.dat, replicaPlacement=000 v=2 size=639800 ttl= I0615 17:28:08 10076 disk_location.go:56] data file data/1.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 disk_location.go:56] data file data/5.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 disk_location.go:56] data file data/4.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 volume_loading.go:73] loading index data/3.idx to memory readonly false I0615 17:28:08 10076 disk_location.go:56] data file data/3.dat, replicaPlacement=000 v=2 size=8 ttl= I0615 17:28:08 10076 disk_location.go:106] Store started on dir: data with 7 volumes max 7 I0615 17:28:08 10076 volume.go:143] Start Seaweed volume server 0.76 at 0.0.0.0:8081 I0615 17:28:08 10076 volume_grpc_client.go:17] Volume server bootstraps with master 10.0.0.95:9333 I0615 17:28:08 10076 volume_grpc_client.go:52] Heartbeat to 10.0.0.95:9333 2017/06/15 17:29:14 transport: http2Client.notifyError got notified that the client transport was broken read tcp 10.0.0.95:12367->10.0.0.95:9333: wsarecv: An existing connection was forcibly closed by the remote host.. I0615 17:29:14 10076 volume_grpc_client.go:95] Volume Server heart beat stops with rpc error: code = Internal desc = transport is closing I0615 17:29:14 10076 volume_grpc_client.go:25] heartbeat error: rpc error: code = Internal desc = transport is closing 2017/06/15 17:29:14 grpc: addrConn.resetTransport failed to create client transport: connection error: desc = ""transport: Error while dialing dial tcp 10.0.0.95:9333: operation was canceled""; Reconnecting to {10.0.0.95:9333 <nil>} 2017/06/15 17:29:14 grpc: addrConn.transportMonitor exits due to: grpc: the connection is closing I0615 17:29:19 10076 store.go:35] Resetting master nodes: nodes:[10.0.0.163:9333 10.0.0.95:9333 10.0.0.95:9333], leader: I0615 17:29:21 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:28 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:35 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:42 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:49 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:29:56 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:03 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:10 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:17 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:24 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:31 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:38 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:45 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:52 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! I0615 17:30:59 10076 volume_grpc_client.go:25] heartbeat error: No master found: No master node available! # **163master log** weed master -mdir=master -peers=10.0.0.95:9333 -ip=10.0.0.163 ip.bind=10.0.0.163 I0615 17:28:01 9904 file_util.go:20] Folder master Permission: -rwxrwxr-x I0615 17:28:01 9904 master_server.go:62] Volume Size Limit is 30000 MB I0615 17:28:01 9904 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0615 17:28:01 9904 raft_server.go:56] Peers Change: [10.0.0.163:9333 10.0.0.95:9333] => [10.0.0.95:9333] I0615 17:28:01 9904 raft_server.go:78] Joining cluster: 10.0.0.95:9333 I0615 17:28:02 9904 raft_server.go:166] Attempting to connect to: http://10.0.0.95:9333/cluster/join I0615 17:28:02 9904 raft_server.go:211] Post returned status: 200 source-file source-file",no-bug,0.9
5082,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5082,[mount] Increasing RSS memory usage on long term run until killed by OOM ( Possible memory leak ),"**Describe the bug** I have long-term running weed mount server-wide. The mount has a high intensity usage of creating and deleting files, and the total filesystem size is not big ( 12 GB ) Last month I had a server memory problem, tracked down to the weed mount occupying over 70GB of resident memory, then being killed by the OOM The more a server has a turnover of files, the faster resident memory increases. Currently, on server (A) I restarted the mount @ 2023-11-28 16:54:08 UTC and it reached at the moment of posting 17.8 GB of resident memory, still increasing. The same command, running on another server (B) with no files turnover, restarted @ 2023-11-28 16:54:10 UTC is currently occupying 82 MB Both are connected to the same filer cluster, receiving thus the same metadata updates, which means (B) sees the files that (A) writes Seems that when files are added and deleted, the weed mount process of the server that is writing/deleting data keeps some reference that increases over time Another main difference between (A) and (B) is that the writing server (A) has a continuous loading of .ldb cache:  Dec 06 15:53:05 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:53:05.845692 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb, watermark 0, num of entries:0 Dec 06 15:53:05 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:53:05.846792 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb , watermark: 0 Dec 06 15:54:06 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:54:06.653019 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb, watermark 0, num of entries:0 Dec 06 15:54:06 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:54:06.654767 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb , watermark: 0 Dec 06 15:55:55 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:55:55.970502 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb, watermark 0, num of entries:0 Dec 06 15:55:55 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:55:55.971889 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb , watermark: 0 Dec 06 15:56:11 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:56:11.819742 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb, watermark 0, num of entries:0 Dec 06 15:56:11 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:56:11.822162 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb , watermark: 0 Dec 06 15:57:47 gpu05.nash01.usa.katapy.io bash[736103]: read old data1 2021617 ns Dec 06 15:58:29 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:58:29.477750 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb, watermark 0, num of entries:0 Dec 06 15:58:29 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:58:29.479641 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb , watermark: 0 Dec 06 15:58:50 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:58:50.064610 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb, watermark 0, num of entries:0 Dec 06 15:58:50 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:58:50.065699 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb , watermark: 0 Dec 06 15:59:55 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:59:55.289314 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb, watermark 0, num of entries:0 Dec 06 15:59:55 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:59:55.291024 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb , watermark: 0 Dec 06 16:01:54 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:01:54.130863 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb, watermark 0, num of entries:0 Dec 06 16:01:54 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:01:54.133372 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb , watermark: 0 Dec 06 16:01:56 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:01:56.315398 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb, watermark 0, num of entries:0 Dec 06 16:01:56 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:01:56.319372 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb , watermark: 0 Dec 06 16:03:57 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:03:57.908344 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb, watermark 0, num of entries:0 Dec 06 16:03:57 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:03:57.909444 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb , watermark: 0 Dec 06 16:05:02 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:05:02.483789 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb, watermark 0, num of entries:0 Dec 06 16:05:02 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:05:02.485513 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb , watermark: 0 Dec 06 16:05:44 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:05:44.096002 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb, watermark 0, num of entries:0 Dec 06 16:05:44 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:05:44.097322 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb , watermark: 0 Dec 06 16:07:30 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:07:30.590859 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb, watermark 0, num of entries:0 Dec 06 16:07:30 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:07:30.592525 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb , watermark: 0 Dec 06 16:08:00 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:08:00.332572 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb, watermark 0, num of entries:0 Dec 06 16:08:00 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:08:00.333664 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb , watermark: 0 Dec 06 16:09:18 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:09:18.080407 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb, watermark 0, num of entries:0 Dec 06 16:09:18 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:09:18.082657 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb , watermark: 0  **System Setup** - Command: /opt/weed/bin/weed mount -filer=katapy.io:8889,ns1.katapy.io:8889,ns2.katapy.io:8889,ns3.katapy.io:8889 -dir=/mnt/seaweedfs/cache -cacheDir=/mnt/KTCACHE/.docker/cache_edge -cacheCapacityMB=9625 -chunkSizeLimitMB=30 -concurrentWriters=128 -volumeServerAccess=publicUrl -dirAutoCreate=true - OS version: Ubuntu 22 LTS, kernel 5.15.0-50-generic x86_64 - output of `weed version`: version 30GB 3.59 - if using filer, show the content of `filer.toml`:  [filer.options] recursive_delete = true [leveldb2] enabled = true dir = ""./filerldb2"" # directory to store level db files  **Expected behavior** Weed mount RSS memory should not increase over time without boundaries until crashing **Screenshots** If applicable, add screenshots to help explain your problem. Server (A) ![image](https://github.com/seaweedfs/seaweedfs/assets/3657228/a7a8f261-a06e-453e-ada8-f95c1dd979d9) Server (B) ![image](https://github.com/seaweedfs/seaweedfs/assets/3657228/1cc468ee-8d8a-459a-b285-ba5a4efb375e) **Additional context** Add any other context about the problem here.",source-file,"[mount] Increasing RSS memory usage on long term run until killed by OOM ( Possible memory leak ) **Describe the bug** I have long-term running weed mount server-wide. The mount has a high intensity usage of creating and deleting files, and the total filesystem size is not big ( 12 GB ) Last month I had a server memory problem, tracked down to the weed mount occupying over 70GB of resident memory, then being killed by the OOM The more a server has a turnover of files, the faster resident memory increases. Currently, on server (A) I restarted the mount @ 2023-11-28 16:54:08 UTC and it reached at the moment of posting 17.8 GB of resident memory, still increasing. The same command, running on another server (B) with no files turnover, restarted @ 2023-11-28 16:54:10 UTC is currently occupying 82 MB Both are connected to the same filer cluster, receiving thus the same metadata updates, which means (B) sees the files that (A) writes Seems that when files are added and deleted, the weed mount process of the server that is writing/deleting data keeps some reference that increases over time Another main difference between (A) and (B) is that the writing server (A) has a continuous loading of .ldb cache:  Dec 06 15:53:05 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:53:05.845692 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb, watermark 0, num of entries:0 Dec 06 15:53:05 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:53:05.846792 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb , watermark: 0 Dec 06 15:54:06 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:54:06.653019 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb, watermark 0, num of entries:0 Dec 06 15:54:06 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:54:06.654767 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb , watermark: 0 Dec 06 15:55:55 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:55:55.970502 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb, watermark 0, num of entries:0 Dec 06 15:55:55 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:55:55.971889 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb , watermark: 0 Dec 06 15:56:11 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:56:11.819742 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb, watermark 0, num of entries:0 Dec 06 15:56:11 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:56:11.822162 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb , watermark: 0 Dec 06 15:57:47 gpu05.nash01.usa.katapy.io bash[736103]: read old data1 2021617 ns Dec 06 15:58:29 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:58:29.477750 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb, watermark 0, num of entries:0 Dec 06 15:58:29 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:58:29.479641 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb , watermark: 0 Dec 06 15:58:50 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:58:50.064610 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb, watermark 0, num of entries:0 Dec 06 15:58:50 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:58:50.065699 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb , watermark: 0 Dec 06 15:59:55 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:59:55.289314 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb, watermark 0, num of entries:0 Dec 06 15:59:55 gpu05.nash01.usa.katapy.io bash[736103]: I1206 15:59:55.291024 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb , watermark: 0 Dec 06 16:01:54 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:01:54.130863 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb, watermark 0, num of entries:0 Dec 06 16:01:54 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:01:54.133372 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb , watermark: 0 Dec 06 16:01:56 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:01:56.315398 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb, watermark 0, num of entries:0 Dec 06 16:01:56 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:01:56.319372 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb , watermark: 0 Dec 06 16:03:57 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:03:57.908344 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb, watermark 0, num of entries:0 Dec 06 16:03:57 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:03:57.909444 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb , watermark: 0 Dec 06 16:05:02 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:05:02.483789 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb, watermark 0, num of entries:0 Dec 06 16:05:02 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:05:02.485513 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_1.ldb , watermark: 0 Dec 06 16:05:44 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:05:44.096002 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb, watermark 0, num of entries:0 Dec 06 16:05:44 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:05:44.097322 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_1.ldb , watermark: 0 Dec 06 16:07:30 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:07:30.590859 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb, watermark 0, num of entries:0 Dec 06 16:07:30 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:07:30.592525 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_2.ldb , watermark: 0 Dec 06 16:08:00 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:08:00.332572 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb, watermark 0, num of entries:0 Dec 06 16:08:00 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:08:00.333664 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c0_2_0.ldb , watermark: 0 Dec 06 16:09:18 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:09:18.080407 needle_map_leveldb.go:122 generateLevelDbFile /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb, watermark 0, num of entries:0 Dec 06 16:09:18 gpu05.nash01.usa.katapy.io bash[736103]: I1206 16:09:18.082657 needle_map_leveldb.go:66 Loading /mnt/KTCACHE/.docker/cache_edge/bc0fc5c1/c1_3_0.ldb , watermark: 0  **System Setup** - Command: /opt/weed/bin/weed mount -filer=katapy.io:8889,ns1.katapy.io:8889,ns2.katapy.io:8889,ns3.katapy.io:8889 -dir=/mnt/seaweedfs/cache -cacheDir=/mnt/KTCACHE/.docker/cache_edge -cacheCapacityMB=9625 -chunkSizeLimitMB=30 -concurrentWriters=128 -volumeServerAccess=publicUrl -dirAutoCreate=true - OS version: Ubuntu 22 LTS, kernel 5.15.0-50-generic x86_64 - output of `weed version`: version 30GB 3.59 - if using filer, show the content of `filer.toml`:  [filer.options] recursive_delete = true [leveldb2] enabled = true dir = ""./filerldb2"" # directory to store level db files  **Expected behavior** Weed mount RSS memory should not increase over time without boundaries until crashing **Screenshots** If applicable, add screenshots to help explain your problem. Server (A) ![image](https://github.com/seaweedfs/seaweedfs/assets/3657228/a7a8f261-a06e-453e-ada8-f95c1dd979d9) Server (B) ![image](https://github.com/seaweedfs/seaweedfs/assets/3657228/1cc468ee-8d8a-459a-b285-ba5a4efb375e) **Additional context** Add any other context about the problem here. source-file",no-bug,0.95
80,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/80,-filer.dir perms,"I'm trying to start the server without filer by adding ""-filer=false"" but it still asks for the permissions. is that logical issue?  Check Mapping Meta Folder (-filer.dir="""") Writable: stat : no such file or directory goroutine 16 [running]: ",config-file | documentation-file | other-file | other-file | other-file | documentation-file | documentation-file | documentation-file | other-file | config-file | other-file | config-file | source-file | source-file | source-file | source-file | other-file | config-file | config-file | config-file | config-file | config-file | documentation-file | test-file | test-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file,"-filer.dir perms I'm trying to start the server without filer by adding ""-filer=false"" but it still asks for the permissions. is that logical issue?  Check Mapping Meta Folder (-filer.dir="""") Writable: stat : no such file or directory goroutine 16 [running]:  config-file documentation-file other-file other-file other-file documentation-file documentation-file documentation-file other-file config-file other-file config-file source-file source-file source-file source-file other-file config-file config-file config-file config-file config-file documentation-file test-file test-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file other-file other-file other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file other-file source-file source-file source-file source-file source-file source-file test-file source-file other-file source-file source-file source-file source-file source-file other-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file",no-bug,0.8
2156,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2156,Can't play mp4 video on chrome,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/chrislusf/seaweedfs/discussions **Describe the bug** step1: upload mp4 video with filer; step2: click file on filer page; video can't play. But I try to play with nginx, and success. **System Setup** - docker run --name weed -d -p 9333:9333 -p 8080:8080 -p 18080:8080 -v /home/data/weedfs:/data chrislusf/seaweedfs server -dir=""/data"" - docker run -d -p 8888:8888 --name filer chrislusf/seaweedfs filer -master=""172.17.0.6:9333"" - CentOS7.6 - 2.53 - `filer.toml` -- run with docker **Expected behavior** play video normally. **Screenshots** ![image](https://user-images.githubusercontent.com/10275564/123411360-f4201300-d5e2-11eb-8edd-3ed928931e34.png) ![image](https://user-images.githubusercontent.com/10275564/123411396-fedaa800-d5e2-11eb-9297-16e98f58214b.png)",source-file,"Can't play mp4 video on chrome Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/chrislusf/seaweedfs/discussions **Describe the bug** step1: upload mp4 video with filer; step2: click file on filer page; video can't play. But I try to play with nginx, and success. **System Setup** - docker run --name weed -d -p 9333:9333 -p 8080:8080 -p 18080:8080 -v /home/data/weedfs:/data chrislusf/seaweedfs server -dir=""/data"" - docker run -d -p 8888:8888 --name filer chrislusf/seaweedfs filer -master=""172.17.0.6:9333"" - CentOS7.6 - 2.53 - `filer.toml` -- run with docker **Expected behavior** play video normally. **Screenshots** ![image](https://user-images.githubusercontent.com/10275564/123411360-f4201300-d5e2-11eb-8edd-3ed928931e34.png) ![image](https://user-images.githubusercontent.com/10275564/123411396-fedaa800-d5e2-11eb-9297-16e98f58214b.png) source-file",no-bug,0.9
3593,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3593,[master] data race on AvailableSpaceFor,"https://github.com/seaweedfs/seaweedfs/issues/3507  ""Sep 3, 2022 @ 21:34:16.197"",""Write at 0x00c000730930 by goroutine 4862045:"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta()"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).handleStream()"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_Assign_Handler()"" ""Sep 3, 2022 @ 21:34:16.197"","" sync/atomic.AddInt64()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x118"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae"" ""Sep 3, 2022 @ 21:34:16.197"","" /usr/local/go/src/runtime/race_amd64.s:289 +0xb"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*Rack).GetOrCreateDataNode()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:142 +0xc4"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders()"" ""Sep 3, 2022 @ 21:34:16.197"","" sync/atomic.AddInt64()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1295 +0x11c9"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat()"" ""Sep 3, 2022 @ 21:34:16.197"",""-"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).handleStream()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x187"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:113 +0x530"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1636 +0xff8"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:214 +0xa8"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:426 +0x25a"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x187"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).serveStreams.func1.2()"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).processUnaryRPC()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec"" ""Sep 3, 2022 @ 21:34:16.197"","""" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x187"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).Assign()"" ""Sep 3, 2022 @ 21:34:16.197"",""WARNING: DATA RACE"" ""Sep 3, 2022 @ 21:34:16.197"","" <autogenerated>:1 +0x1b"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:220 +0x16b"" ""Sep 3, 2022 @ 21:34:16.197"",""Goroutine 4862045 (running) created at:"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams()"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).LinkChildNode()"" ""Sep 3, 2022 @ 21:34:16.197"",""Previous read at 0x00c000730930 by goroutine 4862047:"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).serveStreams.func1()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler()"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).AvailableSpaceFor()"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).serveStreams.func1.2()"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).serveStreams()"" ""Sep 3, 2022 @ 21:34:16.197"",""I0903 16:34:16.184525 node.go:223 topo:stagedc:stage-paas-k8s-node48-dcix adds child fast-volume-2.s3-fast-volume.service.stagedc.consul:8080"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).doLinkChildNode()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/rack.go:52 +0x592"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).processStreamingRPC()"" ""Sep 3, 2022 @ 21:34:16.197"",""-"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:146 +0xa24"" ",source-file | source-file,"[master] data race on AvailableSpaceFor https://github.com/seaweedfs/seaweedfs/issues/3507  ""Sep 3, 2022 @ 21:34:16.197"",""Write at 0x00c000730930 by goroutine 4862045:"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta()"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).handleStream()"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_Assign_Handler()"" ""Sep 3, 2022 @ 21:34:16.197"","" sync/atomic.AddInt64()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x118"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae"" ""Sep 3, 2022 @ 21:34:16.197"","" /usr/local/go/src/runtime/race_amd64.s:289 +0xb"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*Rack).GetOrCreateDataNode()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:142 +0xc4"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders()"" ""Sep 3, 2022 @ 21:34:16.197"","" sync/atomic.AddInt64()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1295 +0x11c9"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat()"" ""Sep 3, 2022 @ 21:34:16.197"",""-"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).handleStream()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x187"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:113 +0x530"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1636 +0xff8"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:214 +0xa8"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:426 +0x25a"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x187"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).serveStreams.func1.2()"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).processUnaryRPC()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec"" ""Sep 3, 2022 @ 21:34:16.197"","""" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x187"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).Assign()"" ""Sep 3, 2022 @ 21:34:16.197"",""WARNING: DATA RACE"" ""Sep 3, 2022 @ 21:34:16.197"","" <autogenerated>:1 +0x1b"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:220 +0x16b"" ""Sep 3, 2022 @ 21:34:16.197"",""Goroutine 4862045 (running) created at:"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams()"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).LinkChildNode()"" ""Sep 3, 2022 @ 21:34:16.197"",""Previous read at 0x00c000730930 by goroutine 4862047:"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).serveStreams.func1()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler()"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).AvailableSpaceFor()"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).serveStreams.func1.2()"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).serveStreams()"" ""Sep 3, 2022 @ 21:34:16.197"",""I0903 16:34:16.184525 node.go:223 topo:stagedc:stage-paas-k8s-node48-dcix adds child fast-volume-2.s3-fast-volume.service.stagedc.consul:8080"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275"" ""Sep 3, 2022 @ 21:34:16.197"","" github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).doLinkChildNode()"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/topology/rack.go:52 +0x592"" ""Sep 3, 2022 @ 21:34:16.197"","" google.golang.org/grpc.(*Server).processStreamingRPC()"" ""Sep 3, 2022 @ 21:34:16.197"",""-"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01"" ""Sep 3, 2022 @ 21:34:16.197"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:146 +0xa24""  source-file source-file",no-bug,0.9
543,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/543,benchmark report 404 on /dir/assign,"Hi, I need some help here. I set up a seaweadfs cluster, which works fine. Passed all my reads/writes tests. But when I run ./weed benchmark command, it reports 100% 404 Not Found on /dir/assign request: ./weed benchmark -server=127.0.0.1:9333 -n=100  Writing Benchmark  writing file error: http://127.0.0.1:9333/dir/assign: 404 Not Found writing file error: http://127.0.0.1:9333/dir/assign: 404 Not Found 98 more of this I tested http://127.0.0.1:9333/dir/assign with both curl and browser, it works well: curl http://127.0.0.1:9333/dir/assign {""fid"":""9,07a4983afa"",""url"":""someurl:8080"",""publicUrl"":""someurl:18080"",""count"":1} I use version 0.76, linux_arm64.tar.gz my machine runs on Centos7, kernel 4.4.36-1.el7.elrepo.x86_64 thanks in advance",source-file | source-file | source-file,"benchmark report 404 on /dir/assign Hi, I need some help here. I set up a seaweadfs cluster, which works fine. Passed all my reads/writes tests. But when I run ./weed benchmark command, it reports 100% 404 Not Found on /dir/assign request: ./weed benchmark -server=127.0.0.1:9333 -n=100  Writing Benchmark  writing file error: http://127.0.0.1:9333/dir/assign: 404 Not Found writing file error: http://127.0.0.1:9333/dir/assign: 404 Not Found 98 more of this I tested http://127.0.0.1:9333/dir/assign with both curl and browser, it works well: curl http://127.0.0.1:9333/dir/assign {""fid"":""9,07a4983afa"",""url"":""someurl:8080"",""publicUrl"":""someurl:18080"",""count"":1} I use version 0.76, linux_arm64.tar.gz my machine runs on Centos7, kernel 4.4.36-1.el7.elrepo.x86_64 thanks in advance source-file source-file source-file",bug,0.9
18,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/18,publish container @ cydev/weed,As per https://github.com/chrislusf/weed-fs/blob/master/docs/gettingstarted.rst,source-file | source-file | source-file | source-file,publish container @ cydev/weed As per https://github.com/chrislusf/weed-fs/blob/master/docs/gettingstarted.rst source-file source-file source-file source-file,no-bug,0.7
1676,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1676,master got a panic,"**Describe the bug** panic **System Setup** `version=2.13` **Additional context**  panic: interface conversion: topology.Node is nil, not *topology.NodeImpl goroutine 279 [running]: github.com/chrislusf/seaweedfs/weed/topology.(*DataNode).GetDataCenter() /go/src/github.com/chrislusf/seaweedfs/weed/topology/data_node.go:154 github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).SendHeartbeat(0xc0002bfc80, 0x26b6360, 0xc000700010, 0x0, 0x0) /go/src/github.com/chrislusf/seaweedfs/weed/server/master_grpc_server.go:91 +0x20d0 github.com/chrislusf/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler(0x20dcca0, 0xc0002bfc80, 0x26ac760, 0xc000ac4000, 0x37e3c70, 0xc00018cf00) /go/src/github.com/chrislusf/seaweedfs/weed/pb/master_pb/master.pb.go:4329 +0xad google.golang.org/grpc.(*Server).processStreamingRPC(0xc000735040, 0x26b96c0, 0xc000adbe00, 0xc00018cf00, 0xc000786990, 0x3719fa0, 0x0, 0x0, 0x0) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:1329 +0xb2e google.golang.org/grpc.(*Server).handleStream(0xc000735040, 0x26b96c0, 0xc000adbe00, 0xc00018cf00, 0x0) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:1409 +0xcc0 google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc0006d19d0, 0xc000735040, 0x26b96c0, 0xc000adbe00, 0xc00018cf00) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:746 +0xbb created by google.golang.org/grpc.(*Server).serveStreams.func1 /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:744 +0xa1 ",source-file,"master got a panic **Describe the bug** panic **System Setup** `version=2.13` **Additional context**  panic: interface conversion: topology.Node is nil, not *topology.NodeImpl goroutine 279 [running]: github.com/chrislusf/seaweedfs/weed/topology.(*DataNode).GetDataCenter() /go/src/github.com/chrislusf/seaweedfs/weed/topology/data_node.go:154 github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).SendHeartbeat(0xc0002bfc80, 0x26b6360, 0xc000700010, 0x0, 0x0) /go/src/github.com/chrislusf/seaweedfs/weed/server/master_grpc_server.go:91 +0x20d0 github.com/chrislusf/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler(0x20dcca0, 0xc0002bfc80, 0x26ac760, 0xc000ac4000, 0x37e3c70, 0xc00018cf00) /go/src/github.com/chrislusf/seaweedfs/weed/pb/master_pb/master.pb.go:4329 +0xad google.golang.org/grpc.(*Server).processStreamingRPC(0xc000735040, 0x26b96c0, 0xc000adbe00, 0xc00018cf00, 0xc000786990, 0x3719fa0, 0x0, 0x0, 0x0) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:1329 +0xb2e google.golang.org/grpc.(*Server).handleStream(0xc000735040, 0x26b96c0, 0xc000adbe00, 0xc00018cf00, 0x0) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:1409 +0xcc0 google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc0006d19d0, 0xc000735040, 0x26b96c0, 0xc000adbe00, 0xc00018cf00) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:746 +0xbb created by google.golang.org/grpc.(*Server).serveStreams.func1 /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:744 +0xa1  source-file",no-bug,0.9
5213,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5213,Master timeouts during dirAssign volume growth,"**Describe the bug** Timeouts when requesting a /dir/assign at the master(s). **System Setup** - master(s) 3 of them, but I get the same issues when I only start one: - `/usr/local/bin/weed -v=3 -logdir=/var/log/seaweedfs master -mdir=/etc/seaweedfs -ip=10.0.9.15 -port=9333 -metrics.address=10.0.9.17:9091 -defaultReplication=010 -volumePreallocate -garbageThreshold=0.3 -volumeSizeLimitMB=20000 -peers=10.0.9.17:9333,10.0.9.14:9333,10.0.9.15:9333` - volume(s) 7 of them, I use different IP's, racks, and volumes. - `/usr/local/bin/weed -v=3 -logdir=/var/log/seaweedfs volume -index=leveldb -mserver=10.0.9.17:9333,10.0.9.14:9333,10.0.9.15:9333 -dir=/volumes/98fb3388c280,/volumes/LHHGS,/volumes/e000c055cbe4,/volumes/c5a9aff45527,/volumes/619c9a0827f4,/volumes/f8c44345756f,/volumes/eeedca023938,/volumes/cae089cd2dd9,/volumes/20F30GRVRD,/volumes/KWEGS,/volumes/3d5638f4fd34,/volumes/18f39b04390d,/volumes/6a9e8c97ba2a,/volumes/LDTGS,/volumes/a9a6e2d048de,/volumes/20F308T27D,/volumes/19641ea6d6c5,/volumes/20F30JB3JE,/volumes/6e19dd8da77b,/volumes/3d1614841bcc,/volumes/372cb7e5ac18,/volumes/152d865d39ce,/volumes/20F305249D,/volumes/1289675b7f03,/volumes/222079443d03,/volumes/cc66d284719d,/volumes/ca6f98cd3c16,/volumes/6611045c7cf2,/volumes/381ee044d930,/volumes/ff81968af32c,/volumes/9d611128cfed,/volumes/21F306AD4F,/volumes/595892cb8709,/volumes/0553ccb52b90 -max=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 -concurrentDownloadLimitMB=20000 -concurrentUploadLimitMB=20000 -hasSlowRead=true -readBufferSizeMB=8 -compactionMBps=10 -rack=store02 -ip=10.0.9.2` - - OS version - `Debian GNU/Linux 12 (bookworm) / Linux store02 6.1.0-17-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.69-1 (2023-12-30) x86_64 GNU/Linux` - output of `weed version` - version `30GB 3.62 59b8af99b0aca1b9e88fec7b5f27c7d15e5e8604 linux amd64` - no filer only masters & volume servers, we have an own metadata store. **Expected behavior** When we assign/request multiple keys or a single key at the Leader master, we don't expect timeouts. Normally we get an instant response. But sometimes (every x minutes) we get a timeout on the a request like: http://10.0.9.17:9333/dir/assign?collection=nntp&count=10000&replication=001. Also when we lower the count. We sadly don't get an error at this request, but I noticed when this happens I see the following log entry: ` seaweedfs-master[459769]: I0116 14:50:10.468052 master_server_handlers.go:125 dirAssign volume growth {""collection"":""nntp"",""replication"":{""node"":1},""ttl"":{""Count"":0,""Unit"":0}} from 10.0.9.12:40308` It looks that this always happens when there is a dirAssign volume growth. In parallel there are constantly POST requests directly to the volume servers to store data. I thought a work-around was to use replication 010 or 002, but working only for a while. We just started testing SeaweedFS and started with 3.60, but also after the upgrades to 3.62 we still see this issue. ( I didn't tested older versions ) **Additional context** How I test/reproduce it: `while true; do curl --max-time 3 'http://localhost:9333/dir/assign?collection=nntp&replication=001'; echo """" ; done` I get once in a couple of seconds/minutes a timeout (also when I increase the max-time): `curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received` at that moment I see always a volume growth message in the logging: `seaweedfs-master[459769]: I0116 14:50:10.468052 master_server_handlers.go:125 dirAssign volume growth {""collection"":""nntp"",""replication"":{""node"":1},""ttl"":{""Count"":0,""Unit"":0}} from 10.0.9.12:40308` **Screen shot** ![b13912075ec83a54736ed1da4a98b5fcbe](https://github.com/seaweedfs/seaweedfs/assets/11386125/f6dec3c3-c6ae-40cf-a018-3e27fb7f4760) <img width=""1770"" alt=""Screenshot 2024-01-17 at 23 09 24"" src=""https://github.com/seaweedfs/seaweedfs/assets/11386125/e142a531-b314-442e-938e-c49925f41007"">",source-file | source-file | source-file,"Master timeouts during dirAssign volume growth **Describe the bug** Timeouts when requesting a /dir/assign at the master(s). **System Setup** - master(s) 3 of them, but I get the same issues when I only start one: - `/usr/local/bin/weed -v=3 -logdir=/var/log/seaweedfs master -mdir=/etc/seaweedfs -ip=10.0.9.15 -port=9333 -metrics.address=10.0.9.17:9091 -defaultReplication=010 -volumePreallocate -garbageThreshold=0.3 -volumeSizeLimitMB=20000 -peers=10.0.9.17:9333,10.0.9.14:9333,10.0.9.15:9333` - volume(s) 7 of them, I use different IP's, racks, and volumes. - `/usr/local/bin/weed -v=3 -logdir=/var/log/seaweedfs volume -index=leveldb -mserver=10.0.9.17:9333,10.0.9.14:9333,10.0.9.15:9333 -dir=/volumes/98fb3388c280,/volumes/LHHGS,/volumes/e000c055cbe4,/volumes/c5a9aff45527,/volumes/619c9a0827f4,/volumes/f8c44345756f,/volumes/eeedca023938,/volumes/cae089cd2dd9,/volumes/20F30GRVRD,/volumes/KWEGS,/volumes/3d5638f4fd34,/volumes/18f39b04390d,/volumes/6a9e8c97ba2a,/volumes/LDTGS,/volumes/a9a6e2d048de,/volumes/20F308T27D,/volumes/19641ea6d6c5,/volumes/20F30JB3JE,/volumes/6e19dd8da77b,/volumes/3d1614841bcc,/volumes/372cb7e5ac18,/volumes/152d865d39ce,/volumes/20F305249D,/volumes/1289675b7f03,/volumes/222079443d03,/volumes/cc66d284719d,/volumes/ca6f98cd3c16,/volumes/6611045c7cf2,/volumes/381ee044d930,/volumes/ff81968af32c,/volumes/9d611128cfed,/volumes/21F306AD4F,/volumes/595892cb8709,/volumes/0553ccb52b90 -max=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 -concurrentDownloadLimitMB=20000 -concurrentUploadLimitMB=20000 -hasSlowRead=true -readBufferSizeMB=8 -compactionMBps=10 -rack=store02 -ip=10.0.9.2` - - OS version - `Debian GNU/Linux 12 (bookworm) / Linux store02 6.1.0-17-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.69-1 (2023-12-30) x86_64 GNU/Linux` - output of `weed version` - version `30GB 3.62 59b8af99b0aca1b9e88fec7b5f27c7d15e5e8604 linux amd64` - no filer only masters & volume servers, we have an own metadata store. **Expected behavior** When we assign/request multiple keys or a single key at the Leader master, we don't expect timeouts. Normally we get an instant response. But sometimes (every x minutes) we get a timeout on the a request like: http://10.0.9.17:9333/dir/assign?collection=nntp&count=10000&replication=001. Also when we lower the count. We sadly don't get an error at this request, but I noticed when this happens I see the following log entry: ` seaweedfs-master[459769]: I0116 14:50:10.468052 master_server_handlers.go:125 dirAssign volume growth {""collection"":""nntp"",""replication"":{""node"":1},""ttl"":{""Count"":0,""Unit"":0}} from 10.0.9.12:40308` It looks that this always happens when there is a dirAssign volume growth. In parallel there are constantly POST requests directly to the volume servers to store data. I thought a work-around was to use replication 010 or 002, but working only for a while. We just started testing SeaweedFS and started with 3.60, but also after the upgrades to 3.62 we still see this issue. ( I didn't tested older versions ) **Additional context** How I test/reproduce it: `while true; do curl --max-time 3 'http://localhost:9333/dir/assign?collection=nntp&replication=001'; echo """" ; done` I get once in a couple of seconds/minutes a timeout (also when I increase the max-time): `curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received` at that moment I see always a volume growth message in the logging: `seaweedfs-master[459769]: I0116 14:50:10.468052 master_server_handlers.go:125 dirAssign volume growth {""collection"":""nntp"",""replication"":{""node"":1},""ttl"":{""Count"":0,""Unit"":0}} from 10.0.9.12:40308` **Screen shot** ![b13912075ec83a54736ed1da4a98b5fcbe](https://github.com/seaweedfs/seaweedfs/assets/11386125/f6dec3c3-c6ae-40cf-a018-3e27fb7f4760) <img width=""1770"" alt=""Screenshot 2024-01-17 at 23 09 24"" src=""https://github.com/seaweedfs/seaweedfs/assets/11386125/e142a531-b314-442e-938e-c49925f41007""> source-file source-file source-file",bug,0.9
6483,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6483,Anyone using filer.backup to Backblaze?,"I've only run a few tests, and it doesn't work at all: `rclone copy check-mk-agent_2.2.0p7-1_all.deb swfs://fusion/jojo123.deb ` creates in SeaweedFS S3: `4014608 fusion/jojo123.deb/check-mk-agent_2.2.0p7-1_all.deb ` However, this is not transferred to Backblaze at all, and filer.backup runs in an endless loop without actually transferring any files. In the Backblaze web interface, new versions appear, but with 0 bytes. A regular folder with a few files is transferred correctly, but as soon as it is deleted:  I0129 06:35:53.566797 filer_sync.go:400 received directory:""/buckets/fusion/test"" event_notification:{old_entry:{name:""Makefile"" chunks:{file_id:""27,0ee10df041af"" size:386 modified_ts_ns:1738131080610984468 e_tag:""qkbIClPKS/CL6xsneBiEtQ=="" fid:{volume_id:27 file_key:3809 cookie:233849263} is_compressed:true} attributes:{file_size:386 mtime:1738131080 file_mode:432 crtime:1738131080 md5:""\xaaF\xc8\nS\xcaK\xf0\x8b\xeb\x1b'x\x18\x84\xb5""} extended:{key:""X-Amz-Meta-Mtime"" value:""1677147934.399210909""}} signatures:69815396} ts_ns:1738132501654339938 E0129 06:35:53.672744 filer_pb_tail.go:97 process directory:""/buckets/fusion/test"" event_notification:{old_entry:{name:""Makefile"" chunks:{file_id:""27,0ee10df041af"" size:386 modified_ts_ns:1738131080610984468 e_tag:""qkbIClPKS/CL6xsneBiEtQ=="" fid:{volume_id:27 file_key:3809 cookie:233849263} is_compressed:true} attributes:{file_size:386 mtime:1738131080 file_mode:432 crtime:1738131080 md5:""\xaaF\xc8\nS\xcaK\xf0\x8b\xeb\x1b'x\x18\x84\xb5""} extended:{key:""X-Amz-Meta-Mtime"" value:""1677147934.399210909""}} signatures:69815396} ts_ns:1738132501654339938: b2_download_file_by_name: 404: File with such name does not exist.  And nothing gets deleted at all. Why are such features implemented if they are apparently not tested at all? How is this supposed to be used in a production environment to store serious data? Please don't take this the wrong waySeaweedFS is a very interesting project, but anything related to file handling should be extremely robust.",source-file,"Anyone using filer.backup to Backblaze? I've only run a few tests, and it doesn't work at all: `rclone copy check-mk-agent_2.2.0p7-1_all.deb swfs://fusion/jojo123.deb ` creates in SeaweedFS S3: `4014608 fusion/jojo123.deb/check-mk-agent_2.2.0p7-1_all.deb ` However, this is not transferred to Backblaze at all, and filer.backup runs in an endless loop without actually transferring any files. In the Backblaze web interface, new versions appear, but with 0 bytes. A regular folder with a few files is transferred correctly, but as soon as it is deleted:  I0129 06:35:53.566797 filer_sync.go:400 received directory:""/buckets/fusion/test"" event_notification:{old_entry:{name:""Makefile"" chunks:{file_id:""27,0ee10df041af"" size:386 modified_ts_ns:1738131080610984468 e_tag:""qkbIClPKS/CL6xsneBiEtQ=="" fid:{volume_id:27 file_key:3809 cookie:233849263} is_compressed:true} attributes:{file_size:386 mtime:1738131080 file_mode:432 crtime:1738131080 md5:""\xaaF\xc8\nS\xcaK\xf0\x8b\xeb\x1b'x\x18\x84\xb5""} extended:{key:""X-Amz-Meta-Mtime"" value:""1677147934.399210909""}} signatures:69815396} ts_ns:1738132501654339938 E0129 06:35:53.672744 filer_pb_tail.go:97 process directory:""/buckets/fusion/test"" event_notification:{old_entry:{name:""Makefile"" chunks:{file_id:""27,0ee10df041af"" size:386 modified_ts_ns:1738131080610984468 e_tag:""qkbIClPKS/CL6xsneBiEtQ=="" fid:{volume_id:27 file_key:3809 cookie:233849263} is_compressed:true} attributes:{file_size:386 mtime:1738131080 file_mode:432 crtime:1738131080 md5:""\xaaF\xc8\nS\xcaK\xf0\x8b\xeb\x1b'x\x18\x84\xb5""} extended:{key:""X-Amz-Meta-Mtime"" value:""1677147934.399210909""}} signatures:69815396} ts_ns:1738132501654339938: b2_download_file_by_name: 404: File with such name does not exist.  And nothing gets deleted at all. Why are such features implemented if they are apparently not tested at all? How is this supposed to be used in a production environment to store serious data? Please don't take this the wrong waySeaweedFS is a very interesting project, but anything related to file handling should be extremely robust. source-file",no-bug,0.8
4640,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4640,Volumes crash when run vacuum,"**Describe the bug** runtime error: invalid memory address or nil pointer dereference **System Setup**  weed master -mdir=""E:\Seaweedfs"" -peers=10.1.11.7:2323 -ip=10.1.11.7 -port=2323 -defaultReplication=100 -volumeSizeLimitMB=500 weed volume -mserver=10.1.11.7:2323 -dataCenter=GPS1 -rack=DATA -dir=""D:\Seaweedfs1"" -ip=10.1.11.7 -max=0 -port=8085 -dir.idx=""E:\Seaweedfs1"" weed volume -mserver=10.1.11.7:2323 -dataCenter=GPS -rack=DATA -dir=""D:\Seaweedfs"" -ip=10.1.11.7 -max=0 -port=8086 -dir.idx=""E:\Seaweedfs"" weed filer -defaultStoreDir=""E:\Seaweedfs"" -ip=10.1.11.7 -master=10.1.11.7:2323 -s3 -s3.config=""config.json"" -s3.port=8333  - OS version `Windows 10 ` - output of `weed version` `version 8000GB 3.53 2c4c2f0994604510631920f4d0d9ee817ec29224 windows amd64` - if using filer, show the content of `filer.toml`  [leveldb2] enabled = true dir = ""E:/Seaweedfs/filerldb2""  **Expected behavior** i try to overwrite files by filer and run vacuum (vol/vacuum?garbageThreshold=0). **Screenshots** ![image](https://github.com/seaweedfs/seaweedfs/assets/13940206/4a74c329-62ca-4270-87ee-5210b13f0699)",source-file | source-file,"Volumes crash when run vacuum **Describe the bug** runtime error: invalid memory address or nil pointer dereference **System Setup**  weed master -mdir=""E:\Seaweedfs"" -peers=10.1.11.7:2323 -ip=10.1.11.7 -port=2323 -defaultReplication=100 -volumeSizeLimitMB=500 weed volume -mserver=10.1.11.7:2323 -dataCenter=GPS1 -rack=DATA -dir=""D:\Seaweedfs1"" -ip=10.1.11.7 -max=0 -port=8085 -dir.idx=""E:\Seaweedfs1"" weed volume -mserver=10.1.11.7:2323 -dataCenter=GPS -rack=DATA -dir=""D:\Seaweedfs"" -ip=10.1.11.7 -max=0 -port=8086 -dir.idx=""E:\Seaweedfs"" weed filer -defaultStoreDir=""E:\Seaweedfs"" -ip=10.1.11.7 -master=10.1.11.7:2323 -s3 -s3.config=""config.json"" -s3.port=8333  - OS version `Windows 10 ` - output of `weed version` `version 8000GB 3.53 2c4c2f0994604510631920f4d0d9ee817ec29224 windows amd64` - if using filer, show the content of `filer.toml`  [leveldb2] enabled = true dir = ""E:/Seaweedfs/filerldb2""  **Expected behavior** i try to overwrite files by filer and run vacuum (vol/vacuum?garbageThreshold=0). **Screenshots** ![image](https://github.com/seaweedfs/seaweedfs/assets/13940206/4a74c329-62ca-4270-87ee-5210b13f0699) source-file source-file",no-bug,0.9
3468,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3468,Filer.backup saves no data if the file is saved in filer (saveToFilerLimit > 0),"**Describe the bug** When uploading files to filer which are less then size x as defined in `saveToFilerLimit`, it will have 0 byte size while running filer.backup -filerProxy **System Setup** - `weed server -dataCenter=$HOSTNAME -ip=$HOSTNAME -master.dir=/meta -master.peers=""app1:9333,app2:9333,app3:9333"" -dir=/data -volume.dir.idx=/meta -volume.index=leveldbLarge -volume.max=0 -rack=1 -filer.encryptVolumeData -volume.fileSizeLimitMB=4096 -master.volumeSizeLimitMB=1024 -filer.defaultReplicaPlacement=100 -filer.saveToFilerLimit=4096 -filer` - `weed filer.backup --filerProxy` - Ubuntu server replicaiton.toml toml [sink.local] enabled = true directory = ""/data"" is_incremental = true  **Expected behavior** Filer should also backup that data, even though it's not stored on a volume server **Screenshots** <img width=""1224"" alt=""filer"" src=""https://user-images.githubusercontent.com/12692409/185657003-0b95a272-4aeb-4103-b89f-01a80031040d.png""> bash kb@host_dev1:/volume1/docker/filer.backup/2022-08-18$ ls -l total 15756 -rw-r 1 root root 332174 Aug 19 00:05 example Kopie.png -rw-r 1 root root 0 Aug 19 00:39 logo.svg -rw-r 1 root root 0 Aug 19 00:05 protection..xml -rw-r 1 root root 209510 Aug 19 00:05 qr-code.svg -rw-r 1 root root 12214695 Aug 19 00:05 sc.ogv -rw-r 1 root root 3365047 Aug 19 00:05 SvgConverter.app.zip  **Additional context** You can see that I have saveToFilerLimit set to 4KB, the files that are smaller than that are empty in the backup.",source-file | source-file | source-file | source-file | source-file | source-file,"Filer.backup saves no data if the file is saved in filer (saveToFilerLimit > 0) **Describe the bug** When uploading files to filer which are less then size x as defined in `saveToFilerLimit`, it will have 0 byte size while running filer.backup -filerProxy **System Setup** - `weed server -dataCenter=$HOSTNAME -ip=$HOSTNAME -master.dir=/meta -master.peers=""app1:9333,app2:9333,app3:9333"" -dir=/data -volume.dir.idx=/meta -volume.index=leveldbLarge -volume.max=0 -rack=1 -filer.encryptVolumeData -volume.fileSizeLimitMB=4096 -master.volumeSizeLimitMB=1024 -filer.defaultReplicaPlacement=100 -filer.saveToFilerLimit=4096 -filer` - `weed filer.backup --filerProxy` - Ubuntu server replicaiton.toml toml [sink.local] enabled = true directory = ""/data"" is_incremental = true  **Expected behavior** Filer should also backup that data, even though it's not stored on a volume server **Screenshots** <img width=""1224"" alt=""filer"" src=""https://user-images.githubusercontent.com/12692409/185657003-0b95a272-4aeb-4103-b89f-01a80031040d.png""> bash kb@host_dev1:/volume1/docker/filer.backup/2022-08-18$ ls -l total 15756 -rw-r 1 root root 332174 Aug 19 00:05 example Kopie.png -rw-r 1 root root 0 Aug 19 00:39 logo.svg -rw-r 1 root root 0 Aug 19 00:05 protection..xml -rw-r 1 root root 209510 Aug 19 00:05 qr-code.svg -rw-r 1 root root 12214695 Aug 19 00:05 sc.ogv -rw-r 1 root root 3365047 Aug 19 00:05 SvgConverter.app.zip  **Additional context** You can see that I have saveToFilerLimit set to 4KB, the files that are smaller than that are empty in the backup. source-file source-file source-file source-file source-file source-file",no-bug,0.9
441,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/441,!URGENT URGENT URGENT! Wrong volume size reported => upload error,"Since 0.73 volume sizes seem to be reported * 1024. So volume size exceeds max volume size and upload is denied but volume is marked as writeable. Unfortunately we cannot switch back to 0.7 or 0.72 as these throw other critical errors. Please fix this ASAP. Our production system with hundrets of millions of files is currently fucked. As a workaround we try to raise max_volume_size * 1024 but I don't know if there are any side effects. Example - uploaded files in collection have approx 1MB, not 1GB: https://cl.ly/3h0i0220032L",source-file | source-file,"!URGENT URGENT URGENT! Wrong volume size reported => upload error Since 0.73 volume sizes seem to be reported * 1024. So volume size exceeds max volume size and upload is denied but volume is marked as writeable. Unfortunately we cannot switch back to 0.7 or 0.72 as these throw other critical errors. Please fix this ASAP. Our production system with hundrets of millions of files is currently fucked. As a workaround we try to raise max_volume_size * 1024 but I don't know if there are any side effects. Example - uploaded files in collection have approx 1MB, not 1GB: https://cl.ly/3h0i0220032L source-file source-file",no-bug,0.9
1671,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1671,"2.13: With the same start parameters, the Linux version can start normally, but the Windows version cannot","**Describe the bug** With the same start parameters, the Linux version can start normally, but the Windows version cannot. **System Setup** on windows: .\weed.exe server --master.port=9333 --volume.port=9222 --volume.max=200 --filer --filer.port=9111 --dir=""D:\weed\seaweedfs"" on CentOS7.4: ./weed server -master.port=9333 -volume.port=9222 -volume.max=200 -filer -filer.port=9111 -dir=""./data"" - OS version version 30GB 2.13 0e99531 windows amd64 version 30GB 2.13 0e99531 linux amd64 - if using filer, show the content of `filer.toml` [mysql] # or tidb enabled = true hostname = ""localhost"" port = 3306 username = ""user1"" password = ""password1"" database = ""database1"" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 **Expected behavior** successfully visit http://127.0.0.1:9111 **Screenshots** on win10: ![image](https://user-images.githubusercontent.com/30383019/101905741-db29b480-3bf2-11eb-9e96-5e33db2a4561.png) ![image](https://user-images.githubusercontent.com/30383019/101906632-37d99f00-3bf4-11eb-88d4-6d5950f0da7d.png) on centos7.4: ![image](https://user-images.githubusercontent.com/30383019/101905945-2774f480-3bf3-11eb-8e97-e979164a56b5.png) ![image](https://user-images.githubusercontent.com/30383019/101906699-5770c780-3bf4-11eb-987c-21b02be616a3.png)",source-file,"2.13: With the same start parameters, the Linux version can start normally, but the Windows version cannot **Describe the bug** With the same start parameters, the Linux version can start normally, but the Windows version cannot. **System Setup** on windows: .\weed.exe server --master.port=9333 --volume.port=9222 --volume.max=200 --filer --filer.port=9111 --dir=""D:\weed\seaweedfs"" on CentOS7.4: ./weed server -master.port=9333 -volume.port=9222 -volume.max=200 -filer -filer.port=9111 -dir=""./data"" - OS version version 30GB 2.13 0e99531 windows amd64 version 30GB 2.13 0e99531 linux amd64 - if using filer, show the content of `filer.toml` [mysql] # or tidb enabled = true hostname = ""localhost"" port = 3306 username = ""user1"" password = ""password1"" database = ""database1"" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 **Expected behavior** successfully visit http://127.0.0.1:9111 **Screenshots** on win10: ![image](https://user-images.githubusercontent.com/30383019/101905741-db29b480-3bf2-11eb-9e96-5e33db2a4561.png) ![image](https://user-images.githubusercontent.com/30383019/101906632-37d99f00-3bf4-11eb-88d4-6d5950f0da7d.png) on centos7.4: ![image](https://user-images.githubusercontent.com/30383019/101905945-2774f480-3bf3-11eb-8e97-e979164a56b5.png) ![image](https://user-images.githubusercontent.com/30383019/101906699-5770c780-3bf4-11eb-987c-21b02be616a3.png) source-file",no-bug,0.8
65,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/65,Wrong HTTP verb semantics around file creation,"According to [the README](https://github.com/chrislusf/weed-fs#write-file), the /assign request is a ""GET"", but performing this ""GET"" _creates_ a space for a file. HTTP GET actions are supposed to only be used for actions that _do not modify state_ (ie. they can be cached, and a spider re-requesting them thousands of times a second won't have any effect other than a transient increase in server load). The /assign request should be a POST, as it _creates_ something. This avoids intermediate components breaking things by making assumptions about the behavior of GET requests (ie. a caching layer not forwarding the GET request to the server). (Reading [the further API documentation](https://github.com/chrislusf/weed-fs/blob/master/docs/api.rst), this also applies to `/vol/vacuum`, `/vol/grow`, and `/admin/assign_volume`. GET is an appropriate verb for `/dir/lookup`, `/cluster/status`, `/dir/status`, and `/status`.) Similarly, the requests to upload file content are ""POST"" requests, but they should be ""PUT"" requests, as they are replayable to _restore_ state.",documentation-file,"Wrong HTTP verb semantics around file creation According to [the README](https://github.com/chrislusf/weed-fs#write-file), the /assign request is a ""GET"", but performing this ""GET"" _creates_ a space for a file. HTTP GET actions are supposed to only be used for actions that _do not modify state_ (ie. they can be cached, and a spider re-requesting them thousands of times a second won't have any effect other than a transient increase in server load). The /assign request should be a POST, as it _creates_ something. This avoids intermediate components breaking things by making assumptions about the behavior of GET requests (ie. a caching layer not forwarding the GET request to the server). (Reading [the further API documentation](https://github.com/chrislusf/weed-fs/blob/master/docs/api.rst), this also applies to `/vol/vacuum`, `/vol/grow`, and `/admin/assign_volume`. GET is an appropriate verb for `/dir/lookup`, `/cluster/status`, `/dir/status`, and `/status`.) Similarly, the requests to upload file content are ""POST"" requests, but they should be ""PUT"" requests, as they are replayable to _restore_ state. documentation-file",no-bug,0.9
4950,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4950,Filer's tikv filestore's prefix query error,"Assuming I use the mini mc client. Add an mc config:  # mc config host add storage ""${S3_ENDPOINT}"" ${S3_ACCESSKEY} ${S3_SECRETKEY} --lookup path --api s3v4  Upload a file using the s3 API:  # mc cp /opt/go/bin/go storage/opt/go/bin/go  Test prefix query:  # mc ls storage/opt/go/  The above command output is empty. Test prefix query:  # mc ls storage/opt/go/bin/  The above command output is empty. Test prefix query:  # mc ls storage/opt/go/bin/g [2023-10-26 08:40:29 CST] 12MiB STANDARD go  The above command outputs normal results. Test prefix query:  # mc ls storage/opt/go/bin/go  The above command output is empty. Other implementations such as leveldb, sqlite, and rocksdb can all return correctly. I suspect it's the problem with this function: https://github.com/seaweedfs/seaweedfs/blob/master/weed/filer/tikv/tikv_store.go#L210",source-file | source-file | source-file,"Filer's tikv filestore's prefix query error Assuming I use the mini mc client. Add an mc config:  # mc config host add storage ""${S3_ENDPOINT}"" ${S3_ACCESSKEY} ${S3_SECRETKEY} --lookup path --api s3v4  Upload a file using the s3 API:  # mc cp /opt/go/bin/go storage/opt/go/bin/go  Test prefix query:  # mc ls storage/opt/go/  The above command output is empty. Test prefix query:  # mc ls storage/opt/go/bin/  The above command output is empty. Test prefix query:  # mc ls storage/opt/go/bin/g [2023-10-26 08:40:29 CST] 12MiB STANDARD go  The above command outputs normal results. Test prefix query:  # mc ls storage/opt/go/bin/go  The above command output is empty. Other implementations such as leveldb, sqlite, and rocksdb can all return correctly. I suspect it's the problem with this function: https://github.com/seaweedfs/seaweedfs/blob/master/weed/filer/tikv/tikv_store.go#L210 source-file source-file source-file",no-bug,0.8
4258,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4258,[Feature Request] Filer browser UI to support more than 100 files at a time,"**Describe the bug** The Filer UI displays by default 100 entries. Would like to request to customize that value There is already an option called `-filer.dirListLimit` but it doesn't seem this option applies to the browser UI We have directories that have thousands of files, and always going to the bottom and pressing `Load` is tedious. Would be nice to have some options to find specific files quicker. A few options I can think of: 1. add a search box to filter files based on name 2. add an option like dirListLimit that is customizable 3. add an option to list all files, instead of paginating 100 files at a time **System Setup**  > lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 22.10 Release: 22.10 Codename: kinetic > weed version version 30GB 3.42 linux amd64  **Screenshots** ![image](https://user-images.githubusercontent.com/1262715/221906753-81bb370f-dba7-4b2f-841a-bea72adb9000.png)",source-file,"[Feature Request] Filer browser UI to support more than 100 files at a time **Describe the bug** The Filer UI displays by default 100 entries. Would like to request to customize that value There is already an option called `-filer.dirListLimit` but it doesn't seem this option applies to the browser UI We have directories that have thousands of files, and always going to the bottom and pressing `Load` is tedious. Would be nice to have some options to find specific files quicker. A few options I can think of: 1. add a search box to filter files based on name 2. add an option like dirListLimit that is customizable 3. add an option to list all files, instead of paginating 100 files at a time **System Setup**  > lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 22.10 Release: 22.10 Codename: kinetic > weed version version 30GB 3.42 linux amd64  **Screenshots** ![image](https://user-images.githubusercontent.com/1262715/221906753-81bb370f-dba7-4b2f-841a-bea72adb9000.png) source-file",no-bug,0.9
3636,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3636,S3 connection to Cloudflare R2 generates error when attempting to sync from SeaweedFS to R2,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/seaweedfs/seaweedfs/discussions example of a good issue report: https://github.com/seaweedfs/seaweedfs/issues/1005 example of a bad issue report: https://github.com/seaweedfs/seaweedfs/issues/1008 **Describe the bug** S3 connection to Cloudflare R2 generates error when attempting to sync from SeaweedFS to R2 because of ""Header 'x-amz-storage-class' with value '' not implemented"" R2 api does not support x-amz-storage-class as per https://developers.cloudflare.com/r2/platform/s3-compatibility/api/ **System Setup** - Command to start is 'weed server -dir=/seaweed -s3 -volume.max=50' - OS version: Debian 11 x64 - output of `weed version` version 30GB 3.26 c07ab9c060eafe26cc0b4246d507d5b33f32f317 linux amd64 - if using filer, show the content of `filer.toml` Just the blank filer.toml, I have not customized this for the limited test. **Expected behavior** The ability to use the s3 api for r2 or to create a new option like we have for b2 for remote config for cloud storage. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** Example of error output from issuing filer sync E0909 19:55:09.629338 filer_sync_jobs.go:47 process directory:""/buckets/cloudflare1/.uploads/9893f4f49e373ee7f2dc110590bb758de0cc84bb"" event_notification:{new_entry:{name:""0038.part"" chunks:{file_id:""9,249792ab3c60"" size:4194304 mtime:1662778272520053410 e_tag:""HRVX+lxnmBczayn2mTB1GA=="" fid:{volume_id:9 file_key:9367 cookie:2460695648}} chunks:{file_id:""9,24a9e4b6e2fb"" offset:4194304 size:4194304 mtime:1662778273015395623 e_tag:""g+nJ6OX2HoX14OtlGcL88w=="" fid:{volume_id:9 file_key:9385 cookie:3837190907}} chunks:{file_id:""9,24ab42fa6467"" offset:8388608 size:2097152 mtime:1662778273440090068 e_tag:""77DHnTJcz1Nctg2rfOPGYA=="" fid:{volume_id:9 file_key:9387 cookie:1123705959}} attributes:{file_size:10485760 mtime:1662778273 file_mode:432 crtime:1662778273 md5:""\x97\xd0J\xdag\t9w\xbe\xb4_H\xc5\xea""}} delete_chunks:true new_parent_path:""/buckets/cloudflare1/.uploads/9893f4f49e373ee7f2dc110590bb758de0cc84bb"" signatures:-1336353119} ts_ns:1662778273440178234: upload to cloudflare1/testbucket/.uploads/9893f4f49e373ee7f2dc110590bb758de0cc84bb/0038.part: NotImplemented: Header 'x-amz-storage-class' with value '' not implemented",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"S3 connection to Cloudflare R2 generates error when attempting to sync from SeaweedFS to R2 Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/seaweedfs/seaweedfs/discussions example of a good issue report: https://github.com/seaweedfs/seaweedfs/issues/1005 example of a bad issue report: https://github.com/seaweedfs/seaweedfs/issues/1008 **Describe the bug** S3 connection to Cloudflare R2 generates error when attempting to sync from SeaweedFS to R2 because of ""Header 'x-amz-storage-class' with value '' not implemented"" R2 api does not support x-amz-storage-class as per https://developers.cloudflare.com/r2/platform/s3-compatibility/api/ **System Setup** - Command to start is 'weed server -dir=/seaweed -s3 -volume.max=50' - OS version: Debian 11 x64 - output of `weed version` version 30GB 3.26 c07ab9c060eafe26cc0b4246d507d5b33f32f317 linux amd64 - if using filer, show the content of `filer.toml` Just the blank filer.toml, I have not customized this for the limited test. **Expected behavior** The ability to use the s3 api for r2 or to create a new option like we have for b2 for remote config for cloud storage. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** Example of error output from issuing filer sync E0909 19:55:09.629338 filer_sync_jobs.go:47 process directory:""/buckets/cloudflare1/.uploads/9893f4f49e373ee7f2dc110590bb758de0cc84bb"" event_notification:{new_entry:{name:""0038.part"" chunks:{file_id:""9,249792ab3c60"" size:4194304 mtime:1662778272520053410 e_tag:""HRVX+lxnmBczayn2mTB1GA=="" fid:{volume_id:9 file_key:9367 cookie:2460695648}} chunks:{file_id:""9,24a9e4b6e2fb"" offset:4194304 size:4194304 mtime:1662778273015395623 e_tag:""g+nJ6OX2HoX14OtlGcL88w=="" fid:{volume_id:9 file_key:9385 cookie:3837190907}} chunks:{file_id:""9,24ab42fa6467"" offset:8388608 size:2097152 mtime:1662778273440090068 e_tag:""77DHnTJcz1Nctg2rfOPGYA=="" fid:{volume_id:9 file_key:9387 cookie:1123705959}} attributes:{file_size:10485760 mtime:1662778273 file_mode:432 crtime:1662778273 md5:""\x97\xd0J\xdag\t9w\xbe\xb4_H\xc5\xea""}} delete_chunks:true new_parent_path:""/buckets/cloudflare1/.uploads/9893f4f49e373ee7f2dc110590bb758de0cc84bb"" signatures:-1336353119} ts_ns:1662778273440178234: upload to cloudflare1/testbucket/.uploads/9893f4f49e373ee7f2dc110590bb758de0cc84bb/0038.part: NotImplemented: Header 'x-amz-storage-class' with value '' not implemented source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
3424,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3424,du outputs wrong size,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/seaweedfs/seaweedfs/discussions example of a good issue report: https://github.com/seaweedfs/seaweedfs/issues/1005 example of a bad issue report: https://github.com/seaweedfs/seaweedfs/issues/1008 Describe the bug If I place some files into a folder then copy the folder to a weed mount when I run `du -sk` on both the original folder and the copy I get different sizes e.g. original is 16K copy on weed mount reports 2K. weed mount is always under reporting by a long way. System Setup OS Ubuntu 22.04 for master, volume and filers. 3 x masters 3 x filers using CockroachDB or leveldb3 (2 different tests and not at the same time, both systems seem to take far too long to restore the meta data) 6 x volume servers filer.toml  [filer.options] recursive_delete = false [leveldb3] enabled = false dir = ""/var/seaweedfs/filer/filerldb3""   /usr/local/bin/weed -logtostderr volume \ -ip xxxx -ip.bind 0.0.0.0 \ -port 8080 -port.grpc 18080 \ -max 0 -index leveldb \ -dir /var/seaweedfs/volume \ -dataCenter=syd1 -rack=rack1 -mserver=xxxx:9333,xxxx:9333,xxxx:9333  Masters:  /usr/local/bin/weed -logtostderr master \ -ip xxxx -ip.bind 0.0.0.0 \ -port 9333 -port.grpc 19333 \ -mdir=/var/seaweedfs/master -defaultReplication=001 \ -volumeSizeLimitMB=30000 \ -peers=xxxx:9333,xxxx:9333,xxxx:9333  weed version version 30GB 3.20 0854171d228951b002efd72076c267f852f2cb15 linux amd64 Expected behavior The output of du should match. Thanks.",source-file,"du outputs wrong size Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/seaweedfs/seaweedfs/discussions example of a good issue report: https://github.com/seaweedfs/seaweedfs/issues/1005 example of a bad issue report: https://github.com/seaweedfs/seaweedfs/issues/1008 Describe the bug If I place some files into a folder then copy the folder to a weed mount when I run `du -sk` on both the original folder and the copy I get different sizes e.g. original is 16K copy on weed mount reports 2K. weed mount is always under reporting by a long way. System Setup OS Ubuntu 22.04 for master, volume and filers. 3 x masters 3 x filers using CockroachDB or leveldb3 (2 different tests and not at the same time, both systems seem to take far too long to restore the meta data) 6 x volume servers filer.toml  [filer.options] recursive_delete = false [leveldb3] enabled = false dir = ""/var/seaweedfs/filer/filerldb3""   /usr/local/bin/weed -logtostderr volume \ -ip xxxx -ip.bind 0.0.0.0 \ -port 8080 -port.grpc 18080 \ -max 0 -index leveldb \ -dir /var/seaweedfs/volume \ -dataCenter=syd1 -rack=rack1 -mserver=xxxx:9333,xxxx:9333,xxxx:9333  Masters:  /usr/local/bin/weed -logtostderr master \ -ip xxxx -ip.bind 0.0.0.0 \ -port 9333 -port.grpc 19333 \ -mdir=/var/seaweedfs/master -defaultReplication=001 \ -volumeSizeLimitMB=30000 \ -peers=xxxx:9333,xxxx:9333,xxxx:9333  weed version version 30GB 3.20 0854171d228951b002efd72076c267f852f2cb15 linux amd64 Expected behavior The output of du should match. Thanks. source-file",no-bug,0.9
851,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/851,Fail to start multi masters due to leader election problem,"Hi chrislusf, I tried to start three masters on the same machine with the commands:  nohup ~/weed -logdir $MDIR -alsologtostderr=false \ master -volumePreallocate -maxCpu 0 -mdir $MDIR -ip $IP -port 9333 \ -peers=$IP:9333,$IP:9334,$IP:9335 -defaultReplication=010 & nohup ~/weed -logdir $MDIR -alsologtostderr=false \ master -volumePreallocate -maxCpu 0 -mdir $MDIR -ip $IP -port 9334 \ -peers=$IP:9333,$IP:9334,$IP:9335 -defaultReplication=010 & nohup ~/weed -logdir $MDIR -alsologtostderr=false \ master -volumePreallocate -maxCpu 0 -mdir $MDIR -ip $IP -port 9335 \ -peers=$IP:9333,$IP:9334,$IP:9335 -defaultReplication=010 &  But I got a `panic: assertion failed: leader.elected.at.same.term.0`, and the full log is as below:  panic: assertion failed: leader.elected.at.same.term.0 goroutine 102 [running]: github.com/chrislusf/raft._assert() /home/travis/gopath/src/github.com/chrislusf/raft/util.go:60 github.com/chrislusf/raft.(*server).processAppendEntriesRequest(0xc000158d80, 0xc0003820a0, 0xc0003820a0, 0x0) /home/travis/gopath/src/github.com/chrislusf/raft/server.go:948 +0xea5 github.com/chrislusf/raft.(*server).leaderLoop(0xc000158d80) /home/travis/gopath/src/github.com/chrislusf/raft/server.go:849 +0x3b5 github.com/chrislusf/raft.(*server).loop(0xc000158d80) /home/travis/gopath/src/github.com/chrislusf/raft/server.go:609 +0x1be github.com/chrislusf/raft.(*server).Start.func1(0xc000158d80) /home/travis/gopath/src/github.com/chrislusf/raft/server.go:470 +0x5a created by github.com/chrislusf/raft.(*server).Start /home/travis/gopath/src/github.com/chrislusf/raft/server.go:468 +0x2ab  After viewing related codes, I find that each master sends a DefaultJoinCommand command to its raft server when it starts up. In the follower loop, when a raft server receives a JoinCommand and if the `log.currentIndex() == 0`, it becomes leader directly. I wonder if this could be a problem? Since all the servers has their log.currentIndex() equals to 0 when the system starts up. I also have rerun this test, and found that the problem occurs randomly, and if I set to sleep 1 second after each master starts up, it can be avoided. I also notice that there is a random timeout before each raft server performs the JoinCommand, but it seems not work for this problem. The weed version is 1.24.",source-file | source-file,"Fail to start multi masters due to leader election problem Hi chrislusf, I tried to start three masters on the same machine with the commands:  nohup ~/weed -logdir $MDIR -alsologtostderr=false \ master -volumePreallocate -maxCpu 0 -mdir $MDIR -ip $IP -port 9333 \ -peers=$IP:9333,$IP:9334,$IP:9335 -defaultReplication=010 & nohup ~/weed -logdir $MDIR -alsologtostderr=false \ master -volumePreallocate -maxCpu 0 -mdir $MDIR -ip $IP -port 9334 \ -peers=$IP:9333,$IP:9334,$IP:9335 -defaultReplication=010 & nohup ~/weed -logdir $MDIR -alsologtostderr=false \ master -volumePreallocate -maxCpu 0 -mdir $MDIR -ip $IP -port 9335 \ -peers=$IP:9333,$IP:9334,$IP:9335 -defaultReplication=010 &  But I got a `panic: assertion failed: leader.elected.at.same.term.0`, and the full log is as below:  panic: assertion failed: leader.elected.at.same.term.0 goroutine 102 [running]: github.com/chrislusf/raft._assert() /home/travis/gopath/src/github.com/chrislusf/raft/util.go:60 github.com/chrislusf/raft.(*server).processAppendEntriesRequest(0xc000158d80, 0xc0003820a0, 0xc0003820a0, 0x0) /home/travis/gopath/src/github.com/chrislusf/raft/server.go:948 +0xea5 github.com/chrislusf/raft.(*server).leaderLoop(0xc000158d80) /home/travis/gopath/src/github.com/chrislusf/raft/server.go:849 +0x3b5 github.com/chrislusf/raft.(*server).loop(0xc000158d80) /home/travis/gopath/src/github.com/chrislusf/raft/server.go:609 +0x1be github.com/chrislusf/raft.(*server).Start.func1(0xc000158d80) /home/travis/gopath/src/github.com/chrislusf/raft/server.go:470 +0x5a created by github.com/chrislusf/raft.(*server).Start /home/travis/gopath/src/github.com/chrislusf/raft/server.go:468 +0x2ab  After viewing related codes, I find that each master sends a DefaultJoinCommand command to its raft server when it starts up. In the follower loop, when a raft server receives a JoinCommand and if the `log.currentIndex() == 0`, it becomes leader directly. I wonder if this could be a problem? Since all the servers has their log.currentIndex() equals to 0 when the system starts up. I also have rerun this test, and found that the problem occurs randomly, and if I set to sleep 1 second after each master starts up, it can be avoided. I also notice that there is a random timeout before each raft server performs the JoinCommand, but it seems not work for this problem. The weed version is 1.24. source-file source-file",no-bug,0.9
2065,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2065,docker-registry with seaweedfs weed mount has error,"**Describe the bug** docker-registry with seaweedfs weed mount, push image error **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # setup master weed master -port=9333 -mdir=/tmp/master0 -defaultReplication=000 -ip=localhost # setup volume weed volume -port=8080 -dir=/tmp/volume0 -ip=localhost -mserver=localhost:9333 # setup filer weed filer -port=8888 -ip=localhost -master=localhost:9333 #weed mount weed mount -filer=localhost:8888 -cacheCapacityMB=0 -cacheDir=/tmp/cache001 -dir=/root/mnt #setup docker-registry docker run -p 5001:5000 --rm \ --name registry2 \ -v /root/config.yml:/etc/docker/registry/config.yml -v /root/mnt/data:/data registry:2 #push image root@qa-4:~# docker push 10.10.10.224:5001/ubuntu:16.04 The push refers to repository [10.10.10.224:5001/ubuntu] 1a1a19626b20: Pushing [>] 3.072kB 5b7dc8292d9b: Pushing 11.78kB bbc674332e2e: Pushing [>] 15.87kB da2785b7bb16: Pushing [> ] 525.3kB/130.7MB unknown blob  - OS version `Ubuntu 18.04.4 LTS` - output of `weed version` `version 30GB 2.41 8618526 linux amd64` - if using filer, show the content of `filer.toml` default /root/config.yaml(without cache)  version: 0.1 log: fields: service: registry storage: # cache: # blobdescriptor: inmemory filesystem: rootdirectory: /data http: addr: :5000 headers: X-Content-Type-Options: [nosniff] health: storagedriver: enabled: true interval: 10s threshold: 3  **Expected behavior** push & pull image successfully **Screenshots** ![image](https://user-images.githubusercontent.com/28077875/117948127-6abec500-b343-11eb-8a4e-c6a2e81281c0.png) **Additional context** mastervolumefiler and weed mount had no related warning and error log. if use local filesystem, everything is fine. if `/root/configy.yaml` enable cache:  version: 0.1 log: fields: service: registry storage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /data http: addr: :5000 headers: X-Content-Type-Options: [nosniff] health: storagedriver: enabled: true interval: 10s threshold: 3  then, push image can be successful, but pull image will error(some small images pull many times will eventually succeedbut large images will not): **pull big images**: btw, the test image can be pulled down from dockerhub(`docker pull jupyter/tensorflow-notebook:ubuntu-20.04`) ![image](https://user-images.githubusercontent.com/28077875/117952978-444f5880-b348-11eb-92f2-09cca527e42e.png) ![image](https://user-images.githubusercontent.com/28077875/117953890-0f8fd100-b349-11eb-846c-be53c01e471a.png) At this time, if stop registry and restart it, then pull image is ok. restart registry use same command:  docker run -p 5001:5000 --rm \ --name registry2 \ -v /root/config.yml:/etc/docker/registry/config.yml -v /root/mnt/data:/data registry:2  **pull small image**(pull many times, eventually succeed): ![image](https://user-images.githubusercontent.com/28077875/117951873-2c2b0980-b347-11eb-98f7-26cb4a7d8508.png) BTW, `version 30GB 2.28 37f104f linux amd64` version does not seem to have the above problem.",source-file,"docker-registry with seaweedfs weed mount has error **Describe the bug** docker-registry with seaweedfs weed mount, push image error **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # setup master weed master -port=9333 -mdir=/tmp/master0 -defaultReplication=000 -ip=localhost # setup volume weed volume -port=8080 -dir=/tmp/volume0 -ip=localhost -mserver=localhost:9333 # setup filer weed filer -port=8888 -ip=localhost -master=localhost:9333 #weed mount weed mount -filer=localhost:8888 -cacheCapacityMB=0 -cacheDir=/tmp/cache001 -dir=/root/mnt #setup docker-registry docker run -p 5001:5000 --rm \ --name registry2 \ -v /root/config.yml:/etc/docker/registry/config.yml -v /root/mnt/data:/data registry:2 #push image root@qa-4:~# docker push 10.10.10.224:5001/ubuntu:16.04 The push refers to repository [10.10.10.224:5001/ubuntu] 1a1a19626b20: Pushing [>] 3.072kB 5b7dc8292d9b: Pushing 11.78kB bbc674332e2e: Pushing [>] 15.87kB da2785b7bb16: Pushing [> ] 525.3kB/130.7MB unknown blob  - OS version `Ubuntu 18.04.4 LTS` - output of `weed version` `version 30GB 2.41 8618526 linux amd64` - if using filer, show the content of `filer.toml` default /root/config.yaml(without cache)  version: 0.1 log: fields: service: registry storage: # cache: # blobdescriptor: inmemory filesystem: rootdirectory: /data http: addr: :5000 headers: X-Content-Type-Options: [nosniff] health: storagedriver: enabled: true interval: 10s threshold: 3  **Expected behavior** push & pull image successfully **Screenshots** ![image](https://user-images.githubusercontent.com/28077875/117948127-6abec500-b343-11eb-8a4e-c6a2e81281c0.png) **Additional context** mastervolumefiler and weed mount had no related warning and error log. if use local filesystem, everything is fine. if `/root/configy.yaml` enable cache:  version: 0.1 log: fields: service: registry storage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /data http: addr: :5000 headers: X-Content-Type-Options: [nosniff] health: storagedriver: enabled: true interval: 10s threshold: 3  then, push image can be successful, but pull image will error(some small images pull many times will eventually succeedbut large images will not): **pull big images**: btw, the test image can be pulled down from dockerhub(`docker pull jupyter/tensorflow-notebook:ubuntu-20.04`) ![image](https://user-images.githubusercontent.com/28077875/117952978-444f5880-b348-11eb-92f2-09cca527e42e.png) ![image](https://user-images.githubusercontent.com/28077875/117953890-0f8fd100-b349-11eb-846c-be53c01e471a.png) At this time, if stop registry and restart it, then pull image is ok. restart registry use same command:  docker run -p 5001:5000 --rm \ --name registry2 \ -v /root/config.yml:/etc/docker/registry/config.yml -v /root/mnt/data:/data registry:2  **pull small image**(pull many times, eventually succeed): ![image](https://user-images.githubusercontent.com/28077875/117951873-2c2b0980-b347-11eb-98f7-26cb4a7d8508.png) BTW, `version 30GB 2.28 37f104f linux amd64` version does not seem to have the above problem. source-file",bug,0.9
1627,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1627,Feature Request: Simple Health Check Endpoint - Volume server,"Hi, when running seaweedfs in k8s env. (or any deployment in k8s) the [liveness probe](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command) is an important tool to keep your software healthy and restart pods if they are misbehaving. the master/filer/s3 have pretty easy HTTP routes that can be checked. the volume server only HTTP route is '/status' which checks ALL the volumes that exist and is pretty heavy can we add another route to the volume server (or even maybe to all?) something like '/hc' that will be a simple internal check ( filer example, can connect to backend db?, master he is the selected master or can connect to a master, volume server can see the disk usage?) and return 20X status code. Regards.",documentation-file,"Feature Request: Simple Health Check Endpoint - Volume server Hi, when running seaweedfs in k8s env. (or any deployment in k8s) the [liveness probe](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command) is an important tool to keep your software healthy and restart pods if they are misbehaving. the master/filer/s3 have pretty easy HTTP routes that can be checked. the volume server only HTTP route is '/status' which checks ALL the volumes that exist and is pretty heavy can we add another route to the volume server (or even maybe to all?) something like '/hc' that will be a simple internal check ( filer example, can connect to backend db?, master he is the selected master or can connect to a master, volume server can see the disk usage?) and return 20X status code. Regards. documentation-file",no-bug,0.9
2243,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2243,gRpc connection error on filer when no volume left,"After uploading a file by mounted volume when no more volumes can be created, the filer start to report multiple gRpc connection error and randomly error ""volume X not found"". **System Setup** **OS:** CentOS 7 - WSL2 on Windows 10 **Master**: /usr/sbin/weed master -mdir=/home/trogo/seaweed/masterData -volumeSizeLimitMB=10 -port=9333 -defaultReplication=000 **Volume**: /usr/sbin/weed volume -dir=/home/trogo/seaweed/volumeData -max=6 -mserver=127.0.0.1:9333 **Filer**: /usr/sbin/weed filer -port=8888 -master=127.0.0.1:9333 **MountPoint:** weed mount -filer=127.0.0.1:8888 -dir=/home/trogo/seaweed/filerMount This is the starting situation: only 1 volume has available space left (vol. 2) and no more volumes can be allocated. The volume 2 is ""crowded"".  > volume.list Topology volumeSizeLimit:10 MB hdd(volume:6/6 active:6 free:0 remote:0) DataCenter DefaultDataCenter hdd(volume:6/6 active:6 free:0 remote:0) Rack DefaultRack hdd(volume:6/6 active:6 free:0 remote:0) DataNode 192.168.225.128:8080 hdd(volume:6/6 active:6 free:0 remote:0) Disk hdd(volume:6/6 active:6 free:0 remote:0) volume id:1 size:10618872 file_count:12 delete_count:1 deleted_byte_count:1048594 version:3 modified_at_second:1628351965 volume id:2 size:9468216 file_count:14 version:3 compact_revision:1 modified_at_second:1628353537 volume id:3 size:10597896 file_count:17 delete_count:2 deleted_byte_count:1091827 version:3 modified_at_second:1628353500 volume id:4 size:10531264 file_count:13 delete_count:4 deleted_byte_count:3145857 version:3 modified_at_second:1628353500 volume id:5 size:10515352 file_count:8 delete_count:2 deleted_byte_count:3145765 version:3 modified_at_second:1628351976 volume id:6 size:11638272 file_count:11 delete_count:2 deleted_byte_count:3145764 version:3 modified_at_second:1628351655 Disk hdd total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807 DataNode 192.168.225.128:8080 total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807 Rack DefaultRack total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807 DataCenter DefaultDataCenter total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807 total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807  Trying to upload a new file result in an error even if there is available space in existing volume. When we try to upload by filer WebUI i can't upload, but no other error. When we try to create a new file in mounted folder (with ""weed mount""), we have an error same as above, but the filer service start to log continuous error:  0809 09:01:08 21 masterclient.go:121] filer masterClient failed to receive from 127.0.0.1:9333: rpc error: code = Canceled desc = grpc: the client connection is closing I0809 09:01:08 19 master_grpc_server.go:265] - client filer@127.0.0.1:8888 I0809 09:01:09 19 master_grpc_server.go:249] + client filer@127.0.0.1:8888 I0809 09:01:11 21 masterclient.go:121] filer masterClient failed to receive from 127.0.0.1:9333: rpc error: code = Canceled desc = grpc: the client connection is closing I0809 09:01:11 19 master_grpc_server.go:265] - client filer@127.0.0.1:8888 I0809 09:01:12 19 master_grpc_server.go:249] + client filer@127.0.0.1:8888 I0809 09:01:14 21 masterclient.go:121] filer masterClient failed to receive from 127.0.0.1:9333: rpc error: code = Canceled desc = grpc: the client connection is closing I0809 09:01:14 19 master_grpc_server.go:265] - client filer@127.0.0.1:8888 I0809 09:01:15 19 master_grpc_server.go:249] + client filer@127.0.0.1:8888  After this error we start having randomly error on access existing files by HTTP: `E0809 09:13:23 21 filer_server_handlers_read.go:168] failed to stream content /01.png: volume 6 not found`",source-file,"gRpc connection error on filer when no volume left After uploading a file by mounted volume when no more volumes can be created, the filer start to report multiple gRpc connection error and randomly error ""volume X not found"". **System Setup** **OS:** CentOS 7 - WSL2 on Windows 10 **Master**: /usr/sbin/weed master -mdir=/home/trogo/seaweed/masterData -volumeSizeLimitMB=10 -port=9333 -defaultReplication=000 **Volume**: /usr/sbin/weed volume -dir=/home/trogo/seaweed/volumeData -max=6 -mserver=127.0.0.1:9333 **Filer**: /usr/sbin/weed filer -port=8888 -master=127.0.0.1:9333 **MountPoint:** weed mount -filer=127.0.0.1:8888 -dir=/home/trogo/seaweed/filerMount This is the starting situation: only 1 volume has available space left (vol. 2) and no more volumes can be allocated. The volume 2 is ""crowded"".  > volume.list Topology volumeSizeLimit:10 MB hdd(volume:6/6 active:6 free:0 remote:0) DataCenter DefaultDataCenter hdd(volume:6/6 active:6 free:0 remote:0) Rack DefaultRack hdd(volume:6/6 active:6 free:0 remote:0) DataNode 192.168.225.128:8080 hdd(volume:6/6 active:6 free:0 remote:0) Disk hdd(volume:6/6 active:6 free:0 remote:0) volume id:1 size:10618872 file_count:12 delete_count:1 deleted_byte_count:1048594 version:3 modified_at_second:1628351965 volume id:2 size:9468216 file_count:14 version:3 compact_revision:1 modified_at_second:1628353537 volume id:3 size:10597896 file_count:17 delete_count:2 deleted_byte_count:1091827 version:3 modified_at_second:1628353500 volume id:4 size:10531264 file_count:13 delete_count:4 deleted_byte_count:3145857 version:3 modified_at_second:1628353500 volume id:5 size:10515352 file_count:8 delete_count:2 deleted_byte_count:3145765 version:3 modified_at_second:1628351976 volume id:6 size:11638272 file_count:11 delete_count:2 deleted_byte_count:3145764 version:3 modified_at_second:1628351655 Disk hdd total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807 DataNode 192.168.225.128:8080 total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807 Rack DefaultRack total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807 DataCenter DefaultDataCenter total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807 total size:63369872 file_count:75 deleted_file:11 deleted_bytes:11577807  Trying to upload a new file result in an error even if there is available space in existing volume. When we try to upload by filer WebUI i can't upload, but no other error. When we try to create a new file in mounted folder (with ""weed mount""), we have an error same as above, but the filer service start to log continuous error:  0809 09:01:08 21 masterclient.go:121] filer masterClient failed to receive from 127.0.0.1:9333: rpc error: code = Canceled desc = grpc: the client connection is closing I0809 09:01:08 19 master_grpc_server.go:265] - client filer@127.0.0.1:8888 I0809 09:01:09 19 master_grpc_server.go:249] + client filer@127.0.0.1:8888 I0809 09:01:11 21 masterclient.go:121] filer masterClient failed to receive from 127.0.0.1:9333: rpc error: code = Canceled desc = grpc: the client connection is closing I0809 09:01:11 19 master_grpc_server.go:265] - client filer@127.0.0.1:8888 I0809 09:01:12 19 master_grpc_server.go:249] + client filer@127.0.0.1:8888 I0809 09:01:14 21 masterclient.go:121] filer masterClient failed to receive from 127.0.0.1:9333: rpc error: code = Canceled desc = grpc: the client connection is closing I0809 09:01:14 19 master_grpc_server.go:265] - client filer@127.0.0.1:8888 I0809 09:01:15 19 master_grpc_server.go:249] + client filer@127.0.0.1:8888  After this error we start having randomly error on access existing files by HTTP: `E0809 09:13:23 21 filer_server_handlers_read.go:168] failed to stream content /01.png: volume 6 not found` source-file",no-bug,0.9
5649,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5649,[Mount] File changes are not propagated to other mounts if they are executing the file,"**Describe the bug** I had this bug for a while, but only now I was able to isolate and replicate it Consider 3 servers, each one has access to an executable file **script.sh** on SeaweedFS. The script is a long running process. Server 1 and Server 2 are running the script.sh Server 3 is not running the script.sh I want to update script.sh, and for testing I update a comment with a timestamp at the top of file. Step 1) I update the script from Server 3. Reading the same script from Server 1 or Server 2 show still the old version. - Server 1: `# 2024-06-05 02:07:25` - Server 2: `# 2024-06-05 02:07:25` - Server 3: `# 2024-06-05 02:18:05` Step 2) I update the script from Server 1. Server 3 sees the update, Server 2 is using the old version - Server 1: `# 2024-06-05 02:19:58` - Server 2: `# 2024-06-05 02:07:25` - Server 3: `# 2024-06-05 02:19:58` Similar effect is if I update from Server 2, then Server 2 and Server 3 match, but server 1 has the old version Step 3) I update again from Server 3. Now all 3 servers have 3 different versions of the same file - Server 1: `# 2024-06-05 02:19:58` - Server 2: `# 2024-06-05 02:07:25` - Server 3: `# 2024-06-05 02:25:23` However, only the last one updated is the real script.sh. I verified with weed sheel `fs.meta.cat script.sh` and `fs.cat script.sh`, connecting from both Server 1 and Server 2, that at every change, the fileId, timestamps etc are updated, and the data is the latest. Thus filer has the latest version always no matter which server updates the file. When a vacuum happens, the mounts with the older versions lose access to the file because they try to get a chunk that does not exists:  Jun 05 01:09:17.836133 reader_at.go:159 fetching chunk &{FileId:4,18f373f609487000a5da75fb OffsetInChunk:0 ViewSize:18130 ViewOffset:0 ChunkSize:18130 CipherKey:[] IsGzipped:true ModifiedTsNs:1717489687525686323}: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:17.836236 filehandle_read.go:65 file handle read /script.sh: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:17.836268 weedfs_file_read.go:51 file handle read /script.sh 0: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:17.837876 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:17.837919 http_util.go:488 retry reading in 1s Jun 05 01:09:18.840220 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:18.840263 http_util.go:488 retry reading in 1.5s Jun 05 01:09:20.341886 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:20.341911 http_util.go:488 retry reading in 2.25s Jun 05 01:09:22.594019 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:22.594053 http_util.go:488 retry reading in 3.375s Jun 05 01:09:25.971267 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:25.971304 http_util.go:488 retry reading in 5.0625s  The file is not available to the mounts on Server 1 and Server 2 until the mount is restarted. When the mount is restarted, the latest version becomes visibile, but once the script is executed, the file is not updated again if steps 1-3 are repeated. In my example I was using a bash script, but the same is true if a binary file is on SeaweedFS, being executed and then replaced with an updated version. When a file that is not being executed, like test.txt is updated in any server, the others see the latest version. I usually test that the mount sync works by executing a command like `date >> /mnt/seaweedfs/test.txt` on one server, and `less /mnt/seaweedfs/test.txt` on the others always shows the latest version. Also if I have a script which is not directly executed, like by using `python /mnt/seaweedfs/script.py` the updates to `/mnt/seaweedfs/script.py` are propagated correctly **Summary** Long story short, updates to scripts that are in a weed mount are not applied to other mounts if the file in these mounts is currently being **executed**. If the mount is not executing the file, it has always access to the latest version of the file **System Setup** - Command: /opt/weed/bin/weed-large-disk -v 0 mount -filer=vpn.katapy.io:8888,lh1.vpn.katapy.io:8888,lh2.vpn.katapy.io:8888,lh3.vpn.katapy.io:8888 -dir=/mnt/seaweedfs/cloud -cacheDir=/mnt/seaweedfs/.docker/cloud_edge -cacheCapacityMB=134995 -chunkSizeLimitMB=250 -concurrentWriters=128 -volumeServerAccess=publicUrl -dirAutoCreate=true - OS version: Ubuntu 22 LTS, kernel 5.15.0-76-generic x86_64 - output of `weed version`: version 8000GB 3.65 - if using filer, show the content of `filer.toml`:  [filer.options] recursive_delete = true [leveldb2] enabled = true dir = ""./filerldb2"" # directory to store level db files  **Expected behavior** The file should always be the latest version, even if it is executed. Linux for example supports modify/replate/delete executable files that are running, without impacting the running processes, because the version they are using is in memory. **Additional context** Minimal script.sh to reproduce the bug:  #!/usr/bin/env bash # -*- coding: utf-8 -*- # 2024-06-05 03:08:45 while(true); do sleep 10 done  - Create the script on a seaweedfs mount shared between 3 servers - Execute with `./script.sh &` on 2 Servers, do not execute on Server 3 - Execute step 1-3 and see how the files diverge - Kill the script on server 1 - Check now on server 1, the data was updated with latest version, but not on server 2 - Kill on server 2 and verify the data was updated after the script was not executing anymore",source-file | source-file | source-file,"[Mount] File changes are not propagated to other mounts if they are executing the file **Describe the bug** I had this bug for a while, but only now I was able to isolate and replicate it Consider 3 servers, each one has access to an executable file **script.sh** on SeaweedFS. The script is a long running process. Server 1 and Server 2 are running the script.sh Server 3 is not running the script.sh I want to update script.sh, and for testing I update a comment with a timestamp at the top of file. Step 1) I update the script from Server 3. Reading the same script from Server 1 or Server 2 show still the old version. - Server 1: `# 2024-06-05 02:07:25` - Server 2: `# 2024-06-05 02:07:25` - Server 3: `# 2024-06-05 02:18:05` Step 2) I update the script from Server 1. Server 3 sees the update, Server 2 is using the old version - Server 1: `# 2024-06-05 02:19:58` - Server 2: `# 2024-06-05 02:07:25` - Server 3: `# 2024-06-05 02:19:58` Similar effect is if I update from Server 2, then Server 2 and Server 3 match, but server 1 has the old version Step 3) I update again from Server 3. Now all 3 servers have 3 different versions of the same file - Server 1: `# 2024-06-05 02:19:58` - Server 2: `# 2024-06-05 02:07:25` - Server 3: `# 2024-06-05 02:25:23` However, only the last one updated is the real script.sh. I verified with weed sheel `fs.meta.cat script.sh` and `fs.cat script.sh`, connecting from both Server 1 and Server 2, that at every change, the fileId, timestamps etc are updated, and the data is the latest. Thus filer has the latest version always no matter which server updates the file. When a vacuum happens, the mounts with the older versions lose access to the file because they try to get a chunk that does not exists:  Jun 05 01:09:17.836133 reader_at.go:159 fetching chunk &{FileId:4,18f373f609487000a5da75fb OffsetInChunk:0 ViewSize:18130 ViewOffset:0 ChunkSize:18130 CipherKey:[] IsGzipped:true ModifiedTsNs:1717489687525686323}: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:17.836236 filehandle_read.go:65 file handle read /script.sh: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:17.836268 weedfs_file_read.go:51 file handle read /script.sh 0: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:17.837876 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:17.837919 http_util.go:488 retry reading in 1s Jun 05 01:09:18.840220 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:18.840263 http_util.go:488 retry reading in 1.5s Jun 05 01:09:20.341886 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:20.341911 http_util.go:488 retry reading in 2.25s Jun 05 01:09:22.594019 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:22.594053 http_util.go:488 retry reading in 3.375s Jun 05 01:09:25.971267 http_util.go:482 read http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb failed, err: http://vpn.data01.nash01.usa.katapy.io:8080/4,18f373f609487000a5da75fb?readDeleted=true: 404 Not Found Jun 05 01:09:25.971304 http_util.go:488 retry reading in 5.0625s  The file is not available to the mounts on Server 1 and Server 2 until the mount is restarted. When the mount is restarted, the latest version becomes visibile, but once the script is executed, the file is not updated again if steps 1-3 are repeated. In my example I was using a bash script, but the same is true if a binary file is on SeaweedFS, being executed and then replaced with an updated version. When a file that is not being executed, like test.txt is updated in any server, the others see the latest version. I usually test that the mount sync works by executing a command like `date >> /mnt/seaweedfs/test.txt` on one server, and `less /mnt/seaweedfs/test.txt` on the others always shows the latest version. Also if I have a script which is not directly executed, like by using `python /mnt/seaweedfs/script.py` the updates to `/mnt/seaweedfs/script.py` are propagated correctly **Summary** Long story short, updates to scripts that are in a weed mount are not applied to other mounts if the file in these mounts is currently being **executed**. If the mount is not executing the file, it has always access to the latest version of the file **System Setup** - Command: /opt/weed/bin/weed-large-disk -v 0 mount -filer=vpn.katapy.io:8888,lh1.vpn.katapy.io:8888,lh2.vpn.katapy.io:8888,lh3.vpn.katapy.io:8888 -dir=/mnt/seaweedfs/cloud -cacheDir=/mnt/seaweedfs/.docker/cloud_edge -cacheCapacityMB=134995 -chunkSizeLimitMB=250 -concurrentWriters=128 -volumeServerAccess=publicUrl -dirAutoCreate=true - OS version: Ubuntu 22 LTS, kernel 5.15.0-76-generic x86_64 - output of `weed version`: version 8000GB 3.65 - if using filer, show the content of `filer.toml`:  [filer.options] recursive_delete = true [leveldb2] enabled = true dir = ""./filerldb2"" # directory to store level db files  **Expected behavior** The file should always be the latest version, even if it is executed. Linux for example supports modify/replate/delete executable files that are running, without impacting the running processes, because the version they are using is in memory. **Additional context** Minimal script.sh to reproduce the bug:  #!/usr/bin/env bash # -*- coding: utf-8 -*- # 2024-06-05 03:08:45 while(true); do sleep 10 done  - Create the script on a seaweedfs mount shared between 3 servers - Execute with `./script.sh &` on 2 Servers, do not execute on Server 3 - Execute step 1-3 and see how the files diverge - Kill the script on server 1 - Check now on server 1, the data was updated with latest version, but not on server 2 - Kill on server 2 and verify the data was updated after the script was not executing anymore source-file source-file source-file",no-bug,0.9
328,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/328,fatal error: concurrent map read and map write,"## Version - SeaweedFS: version 0.71 beta linux amd64 - Go: go version go1.6.1 linux/amd64 ## Problem I encounter this error in one **volume server** when I **read & write to same collection** heavily. > fatal error: concurrent map read and map write > > goroutine 2258 [running]: > runtime.throw(0xe4f180, 0x21) > /usr/local/go/src/runtime/panic.go:530 +0x90 fp=0xc82601d280 sp=0xc82601d268 > runtime.mapaccess2_fast64(0xaecc60, 0xc823a5ccf0, 0x1fd21d2, 0x453096, 0xc82001c00c) > /usr/local/go/src/runtime/hashmap_fast.go:157 +0x5a fp=0xc82601d2a0 sp=0xc82601d280 > github.com/chrislusf/seaweedfs/go/storage.(_CompactSection).Get(0xc8248370c0, 0x1fd21d2, 0x0, 0x0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/compact_map.go:82 +0x59 fp=0xc82601d2d8 sp=0xc82601d2a0 > github.com/chrislusf/seaweedfs/go/storage.(_CompactMap).Get(0xc825f44180, 0x1fd21d2, 0xf0d9c1, 0xc800000002) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/compact_map.go:150 +0x91 fp=0xc82601d318 sp=0xc82601d2d8 > github.com/chrislusf/seaweedfs/go/storage.(_NeedleMap).Get(0xc825f44180, 0x1fd21d2, 0x2, 0x42ee47) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/needle_map_memory.go:92 +0x32 fp=0xc82601d340 sp=0xc82601d318 > github.com/chrislusf/seaweedfs/go/storage.(_Volume).readNeedle(0xc823984980, 0xc829756dc0, 0xc823984980, 0x0, 0x0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/volume.go:286 +0x76 fp=0xc82601d408 sp=0xc82601d340 > github.com/chrislusf/seaweedfs/go/storage.(_Store).ReadVolumeNeedle(0xc8201fe080, 0xc8000000f4, 0xc829756dc0, 0x4, 0x0, 0x0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/store.go:329 +0x67 fp=0xc82601d488 sp=0xc82601d408 > github.com/chrislusf/seaweedfs/go/weed/weed_server.(_VolumeServer).GetOrHeadHandler(0xc8202000e0, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/weed/weed_server/volume_server_handlers_read.go:67 +0x174d fp=0xc82601da88 sp=0xc82601d488 > github.com/chrislusf/seaweedfs/go/weed/weed_server.(_VolumeServer).privateStoreHandler(0xc8202000e0, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/weed/weed_server/volume_server_handlers.go:28 +0xf6 fp=0xc82601dad0 sp=0xc82601da88 > github.com/chrislusf/seaweedfs/go/weed/weed_server.(_VolumeServer).(github.com/chrislusf/seaweedfs/go/weed/weed_server.privateStoreHandler)-fm(0x7fa61fc93478, 0xc824604dd0, 0xc82b > eac1c0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/weed/weed_server/volume_server.go:64 +0x3e fp=0xc82601daf8 sp=0xc82601dad0 > net/http.HandlerFunc.ServeHTTP(0xc82053e170, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /usr/local/go/src/net/http/server.go:1618 +0x3a fp=0xc82601db18 sp=0xc82601daf8 > net/http.(_ServeMux).ServeHTTP(0xc8201d4750, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /usr/local/go/src/net/http/server.go:1910 +0x17d fp=0xc82601db70 sp=0xc82601db18 > net/http.serverHandler.ServeHTTP(0xc8201fe400, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /usr/local/go/src/net/http/server.go:2081 +0x19e fp=0xc82601dbd0 sp=0xc82601db70 > net/http.(_conn).serve(0xc827695b00) > /usr/local/go/src/net/http/server.go:1472 +0xf2e fp=0xc82601df98 sp=0xc82601dbd0 > runtime.goexit() > /usr/local/go/src/runtime/asm_amd64.s:1998 +0x1 fp=0xc82601dfa0 sp=0xc82601df98 > created by net/http.(*Server).Serve > /usr/local/go/src/net/http/server.go:2137 +0x44e",other-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file,"fatal error: concurrent map read and map write ## Version - SeaweedFS: version 0.71 beta linux amd64 - Go: go version go1.6.1 linux/amd64 ## Problem I encounter this error in one **volume server** when I **read & write to same collection** heavily. > fatal error: concurrent map read and map write > > goroutine 2258 [running]: > runtime.throw(0xe4f180, 0x21) > /usr/local/go/src/runtime/panic.go:530 +0x90 fp=0xc82601d280 sp=0xc82601d268 > runtime.mapaccess2_fast64(0xaecc60, 0xc823a5ccf0, 0x1fd21d2, 0x453096, 0xc82001c00c) > /usr/local/go/src/runtime/hashmap_fast.go:157 +0x5a fp=0xc82601d2a0 sp=0xc82601d280 > github.com/chrislusf/seaweedfs/go/storage.(_CompactSection).Get(0xc8248370c0, 0x1fd21d2, 0x0, 0x0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/compact_map.go:82 +0x59 fp=0xc82601d2d8 sp=0xc82601d2a0 > github.com/chrislusf/seaweedfs/go/storage.(_CompactMap).Get(0xc825f44180, 0x1fd21d2, 0xf0d9c1, 0xc800000002) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/compact_map.go:150 +0x91 fp=0xc82601d318 sp=0xc82601d2d8 > github.com/chrislusf/seaweedfs/go/storage.(_NeedleMap).Get(0xc825f44180, 0x1fd21d2, 0x2, 0x42ee47) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/needle_map_memory.go:92 +0x32 fp=0xc82601d340 sp=0xc82601d318 > github.com/chrislusf/seaweedfs/go/storage.(_Volume).readNeedle(0xc823984980, 0xc829756dc0, 0xc823984980, 0x0, 0x0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/volume.go:286 +0x76 fp=0xc82601d408 sp=0xc82601d340 > github.com/chrislusf/seaweedfs/go/storage.(_Store).ReadVolumeNeedle(0xc8201fe080, 0xc8000000f4, 0xc829756dc0, 0x4, 0x0, 0x0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/storage/store.go:329 +0x67 fp=0xc82601d488 sp=0xc82601d408 > github.com/chrislusf/seaweedfs/go/weed/weed_server.(_VolumeServer).GetOrHeadHandler(0xc8202000e0, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/weed/weed_server/volume_server_handlers_read.go:67 +0x174d fp=0xc82601da88 sp=0xc82601d488 > github.com/chrislusf/seaweedfs/go/weed/weed_server.(_VolumeServer).privateStoreHandler(0xc8202000e0, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/weed/weed_server/volume_server_handlers.go:28 +0xf6 fp=0xc82601dad0 sp=0xc82601da88 > github.com/chrislusf/seaweedfs/go/weed/weed_server.(_VolumeServer).(github.com/chrislusf/seaweedfs/go/weed/weed_server.privateStoreHandler)-fm(0x7fa61fc93478, 0xc824604dd0, 0xc82b > eac1c0) > /home/xxr/golang/src/github.com/chrislusf/seaweedfs/go/weed/weed_server/volume_server.go:64 +0x3e fp=0xc82601daf8 sp=0xc82601dad0 > net/http.HandlerFunc.ServeHTTP(0xc82053e170, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /usr/local/go/src/net/http/server.go:1618 +0x3a fp=0xc82601db18 sp=0xc82601daf8 > net/http.(_ServeMux).ServeHTTP(0xc8201d4750, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /usr/local/go/src/net/http/server.go:1910 +0x17d fp=0xc82601db70 sp=0xc82601db18 > net/http.serverHandler.ServeHTTP(0xc8201fe400, 0x7fa61fc93478, 0xc824604dd0, 0xc82beac1c0) > /usr/local/go/src/net/http/server.go:2081 +0x19e fp=0xc82601dbd0 sp=0xc82601db70 > net/http.(_conn).serve(0xc827695b00) > /usr/local/go/src/net/http/server.go:1472 +0xf2e fp=0xc82601df98 sp=0xc82601dbd0 > runtime.goexit() > /usr/local/go/src/runtime/asm_amd64.s:1998 +0x1 fp=0xc82601dfa0 sp=0xc82601df98 > created by net/http.(*Server).Serve > /usr/local/go/src/net/http/server.go:2137 +0x44e other-file other-file source-file other-file source-file source-file source-file source-file other-file source-file source-file",no-bug,0.9
1541,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1541,2.05: spurious read errors on FUSE mount,"One master, two volume servers, two filers with `-peers`, `-defaultReplicaPlacement=001` and `-encryptVolumeData`. Reading files from FUSE mount randomly fails, sometimes after 4 GiB read, sometimes after 6 or 7 GiB. One in 24003500 files fails to read with `Read failed: Input/output error`. Mount prints ` filehandle.go:81] file handle read {FILENAME} 0: EOF`. Repeating recursive read of all files fails in about a minute on a random file. Reproducible 100%. No other errors logged by any other components.",source-file,"2.05: spurious read errors on FUSE mount One master, two volume servers, two filers with `-peers`, `-defaultReplicaPlacement=001` and `-encryptVolumeData`. Reading files from FUSE mount randomly fails, sometimes after 4 GiB read, sometimes after 6 or 7 GiB. One in 24003500 files fails to read with `Read failed: Input/output error`. Mount prints ` filehandle.go:81] file handle read {FILENAME} 0: EOF`. Repeating recursive read of all files fails in about a minute on a random file. Reproducible 100%. No other errors logged by any other components. source-file",no-bug,0.95
1233,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1233,Volume file becomes readonly and failing to write occur after master leader completes committing vacuum.,"**Describe the bug** -volumeSizeLimitMB=50000, it was changed from 30000 to this value three months ago. Before vacuuming, the volume file datasize is about 36G and the volume file has about 2G trash, and file write is normal. After master complete committing vacuum: 1. Why does volume file become readonly 2. Why does filer still write file to the readonly volume This occur in both `linux_amd64_large_disk-v1.61` and `linux_amd64_large_disk-v1.63`. For the running cluster, I try to restart master leader node, then vacuuming is stopped, and filer does not write file to the readonly volume, but the volume file still keep readonly. In another cluster running the same version, -volumeSizeLimitMB=1000, the volume file datasize is almost 1000M and the volume file has 300M trash. The read and write rate are low in this cluster. After vacuum, everything is ok. **System Setup** `nohup ./weed master -metrics.address=metricsIp:9091 -volumeSizeLimitMB=50000 -mdir=./masterData -ip=masterIp1 -port=8180 -peers=masterIp1:8180,masterIp2:8180,masterIp3:8180 -defaultReplication=002 -cpuprofile=./logs/master-cpuprofile.log -memprofile=./logs/master-memprofile.log >> ./logs/master.log &` `nohup ./weed volume -dir=./volumeData -ip=ip1 -port=8180 -max=18 -mserver=masterIp1:8180,masterIp2:8180,masterIp3:8180 -dataCenter=dataCenter1 -rack=dataCenter1-rack1 -cpuprofile=./logs/volume-cpuprofile.log -memprofile=./logs/volume-memprofile.log >> ./logs/volume.log &` `nohup ./weed -v=4 filer -collection=filer -ip=filerIp -port=8180 -master=masterIp1:8180,masterIp2:8180,masterIp3:8180 -dataCenter=dataCenter1 -defaultReplicaPlacement=002 -maxMB=32 >> ./logs/filer.log &` 3 master, 4 volume, 2 filer. One machine runs one node. **Logs about vacuum** - Master leader log: I0316 23:13:54 30854 volume_layout.go:229] Volume 13 becomes unwritable I0316 23:13:54 30854 topology_vacuum.go:66] 2 Start vacuuming 13 on ip2:8180 I0316 23:13:54 30854 topology_vacuum.go:66] 0 Start vacuuming 13 on ip3:8180 I0316 23:13:54 30854 topology_vacuum.go:66] 1 Start vacuuming 13 on ip1:8180 I0316 23:16:36 30854 topology_vacuum.go:78] Complete vacuuming 13 on ip1:8180 I0316 23:17:23 30854 topology_vacuum.go:78] Complete vacuuming 13 on ip3:8180 I0316 23:18:04 30854 topology_vacuum.go:78] Complete vacuuming 13 on ip2:8180 I0316 23:18:04 30854 topology_vacuum.go:97] Start Committing vacuum 13 on ip3:8180 I0316 23:18:18 30854 topology_vacuum.go:108] Complete Committing vacuum 13 on ip3:8180 I0316 23:18:18 30854 topology_vacuum.go:97] Start Committing vacuum 13 on ip1:8180 I0316 23:18:33 30854 topology_vacuum.go:108] Complete Committing vacuum 13 on ip1:8180 I0316 23:18:33 30854 topology_vacuum.go:97] Start Committing vacuum 13 on ip2:8180 I0316 23:18:55 30854 topology_vacuum.go:108] Complete Committing vacuum 13 on ip2:8180 I0316 23:18:55 30854 volume_layout.go:241] Volume 13 becomes writable - ip1 volume log I0316 23:18:18 14822 volume_vacuum.go:83] Committing volume 13 vacuuming I0316 23:18:25 14822 volume_loading.go:94] volumeDataIntegrityChecking failed verifyNeedleIntegrity /opt/app/seaweedfs/volumeData/filer_13.idx failed: EOF I0316 23:18:25 14822 needle_map_sorted_file.go:24] Start to Generate /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx I0316 23:18:31 14822 needle_map_sorted_file.go:26] Finished Generating /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx - ip2 volume log I0316 23:18:33 13143 volume_vacuum.go:83] Committing volume 13 vacuuming I0316 23:18:47 13143 volume_loading.go:94] volumeDataIntegrityChecking failed verifyNeedleIntegrity /opt/app/seaweedfs/volumeData/filer_13.idx failed: EOF I0316 23:18:47 13143 needle_map_sorted_file.go:24] Start to Generate /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx I0316 23:18:53 13143 needle_map_sorted_file.go:26] Finished Generating /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx - ip3 volume log I0316 23:18:04 36486 volume_vacuum.go:83] Committing volume 13 vacuuming I0316 23:18:11 36486 volume_loading.go:94] volumeDataIntegrityChecking failed verifyNeedleIntegrity /opt/app/seaweedfs/volumeData/filer_13.idx failed: EOF I0316 23:18:11 36486 needle_map_sorted_file.go:24] Start to Generate /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx I0316 23:18:17 36486 needle_map_sorted_file.go:26] Finished Generating /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx **Logs about falling to write** - ip2 volume log I0316 23:19:31 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:19:39 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:19:39 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:19:57 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:20:00 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:20:17 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:21:29 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:21:29 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:21:40 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only - filer log I0316 23:19:31 23042 filer_server_handlers_write_autochunk.go:39] AutoChunking level set to 32 (MB) I0316 23:19:31 23042 filer_server_handlers_write_autochunk.go:47] Content-Length of 95948 is less than the chunk size of 33554432 so autoChunking will be skipped. I0316 23:19:31 23042 filer_server_handlers_write.go:122] write /a/b/32.jpg to http://ip2:8180/13,011ca1fac012f5a4 I0316 23:19:31 23042 filer_server_handlers_write.go:260] post result {""name"":""32.jpg"",""size"":95723,""error"":""failed to write to local disk: volume 13 is read only"",""eTag"":""a313d1ac""} I0316 23:19:31 23042 filer_server_handlers_write.go:270] failing to post to volume server /a/b/32.jpg failed to write to local disk: volume 13 is read only",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Volume file becomes readonly and failing to write occur after master leader completes committing vacuum. **Describe the bug** -volumeSizeLimitMB=50000, it was changed from 30000 to this value three months ago. Before vacuuming, the volume file datasize is about 36G and the volume file has about 2G trash, and file write is normal. After master complete committing vacuum: 1. Why does volume file become readonly 2. Why does filer still write file to the readonly volume This occur in both `linux_amd64_large_disk-v1.61` and `linux_amd64_large_disk-v1.63`. For the running cluster, I try to restart master leader node, then vacuuming is stopped, and filer does not write file to the readonly volume, but the volume file still keep readonly. In another cluster running the same version, -volumeSizeLimitMB=1000, the volume file datasize is almost 1000M and the volume file has 300M trash. The read and write rate are low in this cluster. After vacuum, everything is ok. **System Setup** `nohup ./weed master -metrics.address=metricsIp:9091 -volumeSizeLimitMB=50000 -mdir=./masterData -ip=masterIp1 -port=8180 -peers=masterIp1:8180,masterIp2:8180,masterIp3:8180 -defaultReplication=002 -cpuprofile=./logs/master-cpuprofile.log -memprofile=./logs/master-memprofile.log >> ./logs/master.log &` `nohup ./weed volume -dir=./volumeData -ip=ip1 -port=8180 -max=18 -mserver=masterIp1:8180,masterIp2:8180,masterIp3:8180 -dataCenter=dataCenter1 -rack=dataCenter1-rack1 -cpuprofile=./logs/volume-cpuprofile.log -memprofile=./logs/volume-memprofile.log >> ./logs/volume.log &` `nohup ./weed -v=4 filer -collection=filer -ip=filerIp -port=8180 -master=masterIp1:8180,masterIp2:8180,masterIp3:8180 -dataCenter=dataCenter1 -defaultReplicaPlacement=002 -maxMB=32 >> ./logs/filer.log &` 3 master, 4 volume, 2 filer. One machine runs one node. **Logs about vacuum** - Master leader log: I0316 23:13:54 30854 volume_layout.go:229] Volume 13 becomes unwritable I0316 23:13:54 30854 topology_vacuum.go:66] 2 Start vacuuming 13 on ip2:8180 I0316 23:13:54 30854 topology_vacuum.go:66] 0 Start vacuuming 13 on ip3:8180 I0316 23:13:54 30854 topology_vacuum.go:66] 1 Start vacuuming 13 on ip1:8180 I0316 23:16:36 30854 topology_vacuum.go:78] Complete vacuuming 13 on ip1:8180 I0316 23:17:23 30854 topology_vacuum.go:78] Complete vacuuming 13 on ip3:8180 I0316 23:18:04 30854 topology_vacuum.go:78] Complete vacuuming 13 on ip2:8180 I0316 23:18:04 30854 topology_vacuum.go:97] Start Committing vacuum 13 on ip3:8180 I0316 23:18:18 30854 topology_vacuum.go:108] Complete Committing vacuum 13 on ip3:8180 I0316 23:18:18 30854 topology_vacuum.go:97] Start Committing vacuum 13 on ip1:8180 I0316 23:18:33 30854 topology_vacuum.go:108] Complete Committing vacuum 13 on ip1:8180 I0316 23:18:33 30854 topology_vacuum.go:97] Start Committing vacuum 13 on ip2:8180 I0316 23:18:55 30854 topology_vacuum.go:108] Complete Committing vacuum 13 on ip2:8180 I0316 23:18:55 30854 volume_layout.go:241] Volume 13 becomes writable - ip1 volume log I0316 23:18:18 14822 volume_vacuum.go:83] Committing volume 13 vacuuming I0316 23:18:25 14822 volume_loading.go:94] volumeDataIntegrityChecking failed verifyNeedleIntegrity /opt/app/seaweedfs/volumeData/filer_13.idx failed: EOF I0316 23:18:25 14822 needle_map_sorted_file.go:24] Start to Generate /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx I0316 23:18:31 14822 needle_map_sorted_file.go:26] Finished Generating /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx - ip2 volume log I0316 23:18:33 13143 volume_vacuum.go:83] Committing volume 13 vacuuming I0316 23:18:47 13143 volume_loading.go:94] volumeDataIntegrityChecking failed verifyNeedleIntegrity /opt/app/seaweedfs/volumeData/filer_13.idx failed: EOF I0316 23:18:47 13143 needle_map_sorted_file.go:24] Start to Generate /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx I0316 23:18:53 13143 needle_map_sorted_file.go:26] Finished Generating /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx - ip3 volume log I0316 23:18:04 36486 volume_vacuum.go:83] Committing volume 13 vacuuming I0316 23:18:11 36486 volume_loading.go:94] volumeDataIntegrityChecking failed verifyNeedleIntegrity /opt/app/seaweedfs/volumeData/filer_13.idx failed: EOF I0316 23:18:11 36486 needle_map_sorted_file.go:24] Start to Generate /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx I0316 23:18:17 36486 needle_map_sorted_file.go:26] Finished Generating /opt/app/seaweedfs/volumeData/filer_13.sdx from /opt/app/seaweedfs/volumeData/filer_13.idx **Logs about falling to write** - ip2 volume log I0316 23:19:31 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:19:39 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:19:39 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:19:57 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:20:00 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:20:17 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:21:29 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:21:29 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only I0316 23:21:40 13143 store_replicate.go:39] failed to write to local disk: volume 13 is read only - filer log I0316 23:19:31 23042 filer_server_handlers_write_autochunk.go:39] AutoChunking level set to 32 (MB) I0316 23:19:31 23042 filer_server_handlers_write_autochunk.go:47] Content-Length of 95948 is less than the chunk size of 33554432 so autoChunking will be skipped. I0316 23:19:31 23042 filer_server_handlers_write.go:122] write /a/b/32.jpg to http://ip2:8180/13,011ca1fac012f5a4 I0316 23:19:31 23042 filer_server_handlers_write.go:260] post result {""name"":""32.jpg"",""size"":95723,""error"":""failed to write to local disk: volume 13 is read only"",""eTag"":""a313d1ac""} I0316 23:19:31 23042 filer_server_handlers_write.go:270] failing to post to volume server /a/b/32.jpg failed to write to local disk: volume 13 is read only other-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
5615,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5615,"Major issues with EC - ""too few shards given"" during nearly every reconstruction","**Describe the bug** Despite having enough shards to reconstruct my volumes, I fail to reconstruct volumes during ec.rebuild. Example 1:  > ec.rebuild -force rebuildEcVolumes collections 2 rebuildEcVolumes collection rebuildEcVolumes rebuildOneEcVolume 1572 missing shard 1572.0 vaxis.storage.riff.cc:8080 copied 1572.1 from atris.storage.riff.cc:8080 use existing shard 1572.2 vaxis.storage.riff.cc:8080 copied 1572.3 from sizer.storage.riff.cc:8080 missing shard 1572.4 missing shard 1572.5 vaxis.storage.riff.cc:8080 copied 1572.6 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.7 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.8 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.9 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.10 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.11 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.12 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.13 from ambellina.storage.riff.cc:8080 delete 1572.[1 3 6 7 8 9 10 11 12 13] from vaxis.storage.riff.cc:8080 error: rpc error: code = Unknown desc = RebuildEcFiles /mnt/brick.tgc-jbod.9/seaweedfs/1572: rebuildEcFiles: reconstruct: too few shards given  **too few shards given** despite 3 shards being missing which shouldn't be enough to ruin that volume A much worse example:  > ec.rebuild -force rebuildEcVolumes collections 2 rebuildEcVolumes collection rebuildEcVolumes rebuildOneEcVolume 113 missing shard 113.0 vaxis.storage.riff.cc:8080 copied 113.1 from atris.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.2 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.3 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.4 from ambellina.storage.riff.cc:8080 use existing shard 113.5 vaxis.storage.riff.cc:8080 copied 113.6 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.7 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.8 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.9 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.10 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.11 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.12 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.13 from al.storage.riff.cc:8080 delete 113.[1 2 3 4 6 7 8 9 10 11 12 13] from vaxis.storage.riff.cc:8080 error: rpc error: code = Unknown desc = RebuildEcFiles /mnt/brick.tgc-jbod.6/seaweedfs/113: rebuildEcFiles: reconstruct: too few shards given  In this example, we fail to reconstruct our volume even though only 1 shard is missing. In a 10+4 erasure code such as this , we should be able to lose a minimum of 4 shards at a time and not fail reconstruction. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". Starting via systemd. Standard command lines as used in the docs. - OS version Debian 12 - output of `weed version` `version 8000GB 3.67 d3032d1e805ab363242c833d9a61db59b3941f21 linux amd64` - if using filer, show the content of `filer.toml`  root@seaweedfs-filer01:~# cat /etc/seaweedfs/filer.toml # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml  # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false #max_file_name_length = 255  # The following are filer store options  [postgres] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT, # name VARCHAR(65535), # directory VARCHAR(65535), # meta bytea, # PRIMARY KEY (dirhash, name) # ); enabled = true hostname = ""redacted.riff.cc"" port = 5433 username = ""seaweedfs"" password = ""redacted"" database = ""seaweedfs"" # create or use an existing database schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0 # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true #upsertQuery = UPSERT INTO ""%[1]s"" (dirhash,name,directory,meta) VALUES($1,$2,$3,$4) upsertQuery =  INSERT INTO ""%[1]s"" (dirhash, name, directory, meta) VALUES ($1, $2, $3, $4) ON CONFLICT (dirhash, name) DO UPDATE SET directory = EXCLUDED.directory, meta = EXCLUDED.meta;  # Add an index: # yugabyte=# \c seaweedfs # You are now connected to database ""seaweedfs"" as user ""yugabyte"". # seaweedfs=# ALTER TABLE filemeta ADD CONSTRAINT unique_dirhash UNIQUE (dirhash);  **Expected behavior** EC should cleanly reconstruct. **Additional context** This is a major issue for us and until fixed we may have to stop using EC entirely out of safety concerns",source-file | source-file | source-file,"Major issues with EC - ""too few shards given"" during nearly every reconstruction **Describe the bug** Despite having enough shards to reconstruct my volumes, I fail to reconstruct volumes during ec.rebuild. Example 1:  > ec.rebuild -force rebuildEcVolumes collections 2 rebuildEcVolumes collection rebuildEcVolumes rebuildOneEcVolume 1572 missing shard 1572.0 vaxis.storage.riff.cc:8080 copied 1572.1 from atris.storage.riff.cc:8080 use existing shard 1572.2 vaxis.storage.riff.cc:8080 copied 1572.3 from sizer.storage.riff.cc:8080 missing shard 1572.4 missing shard 1572.5 vaxis.storage.riff.cc:8080 copied 1572.6 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.7 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.8 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.9 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.10 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.11 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.12 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 1572.13 from ambellina.storage.riff.cc:8080 delete 1572.[1 3 6 7 8 9 10 11 12 13] from vaxis.storage.riff.cc:8080 error: rpc error: code = Unknown desc = RebuildEcFiles /mnt/brick.tgc-jbod.9/seaweedfs/1572: rebuildEcFiles: reconstruct: too few shards given  **too few shards given** despite 3 shards being missing which shouldn't be enough to ruin that volume A much worse example:  > ec.rebuild -force rebuildEcVolumes collections 2 rebuildEcVolumes collection rebuildEcVolumes rebuildOneEcVolume 113 missing shard 113.0 vaxis.storage.riff.cc:8080 copied 113.1 from atris.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.2 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.3 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.4 from ambellina.storage.riff.cc:8080 use existing shard 113.5 vaxis.storage.riff.cc:8080 copied 113.6 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.7 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.8 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.9 from al.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.10 from sizer.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.11 from monstar.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.12 from ambellina.storage.riff.cc:8080 vaxis.storage.riff.cc:8080 copied 113.13 from al.storage.riff.cc:8080 delete 113.[1 2 3 4 6 7 8 9 10 11 12 13] from vaxis.storage.riff.cc:8080 error: rpc error: code = Unknown desc = RebuildEcFiles /mnt/brick.tgc-jbod.6/seaweedfs/113: rebuildEcFiles: reconstruct: too few shards given  In this example, we fail to reconstruct our volume even though only 1 shard is missing. In a 10+4 erasure code such as this , we should be able to lose a minimum of 4 shards at a time and not fail reconstruction. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". Starting via systemd. Standard command lines as used in the docs. - OS version Debian 12 - output of `weed version` `version 8000GB 3.67 d3032d1e805ab363242c833d9a61db59b3941f21 linux amd64` - if using filer, show the content of `filer.toml`  root@seaweedfs-filer01:~# cat /etc/seaweedfs/filer.toml # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml  # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false #max_file_name_length = 255  # The following are filer store options  [postgres] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT, # name VARCHAR(65535), # directory VARCHAR(65535), # meta bytea, # PRIMARY KEY (dirhash, name) # ); enabled = true hostname = ""redacted.riff.cc"" port = 5433 username = ""seaweedfs"" password = ""redacted"" database = ""seaweedfs"" # create or use an existing database schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0 # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true #upsertQuery = UPSERT INTO ""%[1]s"" (dirhash,name,directory,meta) VALUES($1,$2,$3,$4) upsertQuery =  INSERT INTO ""%[1]s"" (dirhash, name, directory, meta) VALUES ($1, $2, $3, $4) ON CONFLICT (dirhash, name) DO UPDATE SET directory = EXCLUDED.directory, meta = EXCLUDED.meta;  # Add an index: # yugabyte=# \c seaweedfs # You are now connected to database ""seaweedfs"" as user ""yugabyte"". # seaweedfs=# ALTER TABLE filemeta ADD CONSTRAINT unique_dirhash UNIQUE (dirhash);  **Expected behavior** EC should cleanly reconstruct. **Additional context** This is a major issue for us and until fixed we may have to stop using EC entirely out of safety concerns source-file source-file source-file",no-bug,0.9
3590,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3590,[master] DATA RACE on reaches full capacity,"https://github.com/seaweedfs/seaweedfs/issues/3507  | Sep 3, 2022 @ 14:50:12.709 | I0903 09:50:12.708915 volume_layout.go:447 Volume 1837 reaches full capacity. | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/command.startMaster() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/topology_event_handling.go:35 +0x28e | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/server.NewMasterServer() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | WARNING: DATA RACE | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x187 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 |  | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | Goroutine 3737364 (running) created at: | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).serveStreams() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | main.main() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).handleRawConn.func1() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/master.go:146 +0x44c | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | sync/atomic.AddInt64() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).handleStream() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_server.go:151 +0x1b24 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | sync/atomic.AddInt64() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | Goroutine 50 (running) created at: | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/topology_event_handling.go:68 +0x394 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | Previous read at 0x00c000afe830 by goroutine 3737364: | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /usr/local/go/src/runtime/race_amd64.s:289 +0xb | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/command.runMaster() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:144 +0x1f6 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*Topology).StartRefreshWritableVolumes() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).serveStreams.func1() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | - | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | <autogenerated>:1 +0x1b | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | - | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x118 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).serveStreams.func1.2() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*Topology).SetVolumeCapacityFull() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).processStreamingRPC() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | - | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | Write at 0x00c000afe830 by goroutine 50: | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 |  | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/topology_event_handling.go:39 +0x224 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*Topology).StartRefreshWritableVolumes.func3() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:136 +0x92b | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/master.go:122 +0x4af | fast-master-2 | Sep 3, 2022 @ 14:50:20.465 | I0903 09:50:20.465211 volume_layout.go:447 Volume 1804 reaches full capacity. | fast-master-2 ",source-file | source-file,"[master] DATA RACE on reaches full capacity https://github.com/seaweedfs/seaweedfs/issues/3507  | Sep 3, 2022 @ 14:50:12.709 | I0903 09:50:12.708915 volume_layout.go:447 Volume 1837 reaches full capacity. | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/command.startMaster() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/topology_event_handling.go:35 +0x28e | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/server.NewMasterServer() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | WARNING: DATA RACE | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x187 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 |  | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | Goroutine 3737364 (running) created at: | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).serveStreams() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | main.main() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).handleRawConn.func1() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/master.go:146 +0x44c | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | sync/atomic.AddInt64() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).handleStream() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_server.go:151 +0x1b24 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | sync/atomic.AddInt64() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | Goroutine 50 (running) created at: | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/topology_event_handling.go:68 +0x394 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | Previous read at 0x00c000afe830 by goroutine 3737364: | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /usr/local/go/src/runtime/race_amd64.s:289 +0xb | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/command.runMaster() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:144 +0x1f6 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*Topology).StartRefreshWritableVolumes() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).serveStreams.func1() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | - | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | <autogenerated>:1 +0x1b | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | - | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x118 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).serveStreams.func1.2() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*Topology).SetVolumeCapacityFull() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc.(*Server).processStreamingRPC() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | - | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | Write at 0x00c000afe830 by goroutine 50: | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 |  | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/topology_event_handling.go:39 +0x224 | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | github.com/seaweedfs/seaweedfs/weed/topology.(*Topology).StartRefreshWritableVolumes.func3() | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:136 +0x92b | fast-master-2 | Sep 3, 2022 @ 14:50:12.712 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/master.go:122 +0x4af | fast-master-2 | Sep 3, 2022 @ 14:50:20.465 | I0903 09:50:20.465211 volume_layout.go:447 Volume 1804 reaches full capacity. | fast-master-2  source-file source-file",no-bug,0.95
6136,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6136,Example nginx configuration does not work after upgrading to 3.75,"Using example configuration https://github.com/seaweedfs/seaweedfs/wiki/S3-Nginx-Proxy With version 3.73 it works fine Once upgrading to 3.75 (or 3.76 or 3.77) we get the following error:  $ rclone lsd dropbox: <3>ERROR : : error listing: SignatureDoesNotMatch: The request signature we calculated does not match the signature you provided. Check your key and signing method. status code: 403, request id: 1729085633541862383, host id: Failed to lsd with 2 errors: last error was: SignatureDoesNotMatch: The request signature we calculated does not match the signature you provided. Check your key and signing method. status code: 403, request id: 1729085633541862383, host id:  rclone config:  [dropbox] type = s3 provider = SeaweedFS env_auth = false access_key_id = xxxx secret_access_key = xxx endpoint = https://dropbox.my.domain acl = private  nginx config:  server { listen 443 ssl; listen [::]:443 ssl; http2 on; # Assumes that your subdomain is s3 # The regex will support path style as well as virtual-hosted style bucket URLs # path style: http://s3.yourdomain.com/mybucket # virtual-hosted style: http://mybucket.s3.yourdomain.com server_name ~^(?:(?<bucket>[^.]+)\.)dropbox\.my\.domain; ssl_protocols TLSv1.2 TLSv1.3; ssl_certificate /etc/ssl/private/xxxxxxxxxxxxx ssl_certificate_key /etc/ssl/private/xxxxxxxxxxx ignore_invalid_headers off; client_max_body_size 0; proxy_buffering off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_connect_timeout 300; proxy_http_version 1.1; proxy_set_header Connection """"; chunked_transfer_encoding off; # If bucket subdomain is not empty, # rewrite request to backend. if ($bucket != """") { rewrite (.*) /$bucket$1 last; } location / { proxy_pass http://localhost:8333/; } } ",source-file,"Example nginx configuration does not work after upgrading to 3.75 Using example configuration https://github.com/seaweedfs/seaweedfs/wiki/S3-Nginx-Proxy With version 3.73 it works fine Once upgrading to 3.75 (or 3.76 or 3.77) we get the following error:  $ rclone lsd dropbox: <3>ERROR : : error listing: SignatureDoesNotMatch: The request signature we calculated does not match the signature you provided. Check your key and signing method. status code: 403, request id: 1729085633541862383, host id: Failed to lsd with 2 errors: last error was: SignatureDoesNotMatch: The request signature we calculated does not match the signature you provided. Check your key and signing method. status code: 403, request id: 1729085633541862383, host id:  rclone config:  [dropbox] type = s3 provider = SeaweedFS env_auth = false access_key_id = xxxx secret_access_key = xxx endpoint = https://dropbox.my.domain acl = private  nginx config:  server { listen 443 ssl; listen [::]:443 ssl; http2 on; # Assumes that your subdomain is s3 # The regex will support path style as well as virtual-hosted style bucket URLs # path style: http://s3.yourdomain.com/mybucket # virtual-hosted style: http://mybucket.s3.yourdomain.com server_name ~^(?:(?<bucket>[^.]+)\.)dropbox\.my\.domain; ssl_protocols TLSv1.2 TLSv1.3; ssl_certificate /etc/ssl/private/xxxxxxxxxxxxx ssl_certificate_key /etc/ssl/private/xxxxxxxxxxx ignore_invalid_headers off; client_max_body_size 0; proxy_buffering off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_connect_timeout 300; proxy_http_version 1.1; proxy_set_header Connection """"; chunked_transfer_encoding off; # If bucket subdomain is not empty, # rewrite request to backend. if ($bucket != """") { rewrite (.*) /$bucket$1 last; } location / { proxy_pass http://localhost:8333/; } }  source-file",no-bug,0.9
3919,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3919,[volume.check.disk] loop missed entries,"It seems that files are being actively written to this volume version: 3.32 log:  load collection logs volume 2547 index size 5463216 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465216 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230539 entries, fast-volume-10.dc2:8080 missed 3 entries read 2547,61663132613838 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132616165 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132616232 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230536 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463392 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465312 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230545 entries, fast-volume-10.dc2:8080 missed 1 entries read 2547,61663132623639 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230544 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463520 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465424 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230552 entries, fast-volume-10.dc2:8080 missed 1 entries read 2547,61663132633631 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230551 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463600 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465504 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230557 entries, fast-volume-10.dc2:8080 missed 2 entries read 2547,61663132643262 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132643364 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230555 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463744 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465648 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230566 entries, fast-volume-10.dc2:8080 missed 4 entries read 2547,61663132653263 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132653266 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132653365 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132653534 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230562 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463920 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465824 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230577 entries, fast-volume-10.dc2:8080 missed 8 entries read 2547,61663132663234 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663238 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663262 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663265 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663330 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663464 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663562 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663566 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230569 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5464304 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466000 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230588 entries, fast-volume-10.dc2:8080 missed 3 entries read 2547,61663133303361 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133303463 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133303664 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230585 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5464496 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466160 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230598 entries, fast-volume-10.dc2:8080 missed 4 entries read 2547,61663133313064 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133313131 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133313261 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133313263 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230594 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5464704 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466304 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230607 entries, fast-volume-10.dc2:8080 missed 4 entries read 2547,61663133316561 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133316666 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133323162 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133323266 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230603 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5464928 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466432 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230615 entries, fast-volume-10.dc2:8080 missed 2 entries read 2547,61663133326635 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133333161 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230613 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5465024 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466480 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230618 entries, fast-volume-10.dc2:8080 missed 1 entries read 2547,61663133333762 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230617 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5465152 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466592 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230625 entries, fast-volume-10.dc2:8080 missed 1 entries read 2547,61663133343263 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230624 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5465296 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466704 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230632 entries, fast-volume-10.dc2:8080 missed 0 entries volume 2547 fast-volume-10.dc2:8080 has 230632 entries, fast-volume-12.dc1:8080 missed 0 entries ",source-file | source-file | source-file | source-file | source-file | source-file,"[volume.check.disk] loop missed entries It seems that files are being actively written to this volume version: 3.32 log:  load collection logs volume 2547 index size 5463216 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465216 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230539 entries, fast-volume-10.dc2:8080 missed 3 entries read 2547,61663132613838 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132616165 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132616232 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230536 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463392 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465312 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230545 entries, fast-volume-10.dc2:8080 missed 1 entries read 2547,61663132623639 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230544 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463520 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465424 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230552 entries, fast-volume-10.dc2:8080 missed 1 entries read 2547,61663132633631 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230551 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463600 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465504 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230557 entries, fast-volume-10.dc2:8080 missed 2 entries read 2547,61663132643262 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132643364 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230555 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463744 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465648 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230566 entries, fast-volume-10.dc2:8080 missed 4 entries read 2547,61663132653263 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132653266 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132653365 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132653534 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230562 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5463920 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5465824 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230577 entries, fast-volume-10.dc2:8080 missed 8 entries read 2547,61663132663234 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663238 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663262 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663265 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663330 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663464 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663562 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663132663566 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230569 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5464304 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466000 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230588 entries, fast-volume-10.dc2:8080 missed 3 entries read 2547,61663133303361 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133303463 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133303664 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230585 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5464496 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466160 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230598 entries, fast-volume-10.dc2:8080 missed 4 entries read 2547,61663133313064 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133313131 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133313261 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133313263 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230594 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5464704 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466304 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230607 entries, fast-volume-10.dc2:8080 missed 4 entries read 2547,61663133316561 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133316666 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133323162 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133323266 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230603 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5464928 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466432 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230615 entries, fast-volume-10.dc2:8080 missed 2 entries read 2547,61663133326635 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 read 2547,61663133333161 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230613 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5465024 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466480 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230618 entries, fast-volume-10.dc2:8080 missed 1 entries read 2547,61663133333762 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230617 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5465152 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466592 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230625 entries, fast-volume-10.dc2:8080 missed 1 entries read 2547,61663133343263 fast-volume-12.dc1:8080 => fast-volume-10.dc2:8080 volume 2547 fast-volume-10.dc2:8080 has 230624 entries, fast-volume-12.dc1:8080 missed 0 entries load collection logs volume 2547 index size 5465296 from fast-volume-10.dc2:8080  load collection logs volume 2547 index size 5466704 from fast-volume-12.dc1:8080  volume 2547 fast-volume-12.dc1:8080 has 230632 entries, fast-volume-10.dc2:8080 missed 0 entries volume 2547 fast-volume-10.dc2:8080 has 230632 entries, fast-volume-12.dc1:8080 missed 0 entries  source-file source-file source-file source-file source-file source-file",no-bug,0.9
5906,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5906,volume.vacuum needs warning if replication isn't met,"**Describe the bug** If you run volume.vacuum, it doesn't do anything to volumes that aren't replicated to the spec (currently only 2 copies when you have 002 set). It just skips them silently **System Setup** - version 30GB 3.67 N/A linux amd64 **Expected behavior** I still think it shouldn't do anything other then let the user know that it would have done those volumes if they were replicated properly # Additional context OK, Story time I recently started using seaweedfs and migrated from a large 10 drive BTRFS raid1c3 array (3x 14TB and 7x 6TB) that was fairly full, I have about 19TB of data to migrate. BTRFS has the function to remove drives and move their data to other drives. So I started with a couple 6TB that weren't in the array and started removing a couple others while I started coping data to seaweedfs with replication 001. Was still using all the seaweedfs parts manually with tmux windows (I had 17 windows open at one point) , and I had problems with remembering the -encryption flag half way through the migration. Ok, I thought maybe I should actually use the collections feature instead just a huge big vault. so I will just migrate it again later, lets just get it off of the BTRFS array asap. After the migration completed, I used all the 6TB drives I have for this array, for a total of 14 drives, and saved the 14TB drives for a 2nd server in the future. I then change the default and all the volumes from 001 to 002 via master startup config and volume.configure.replication command. I then started to copy the 15TB of media I have into a new seaweedfs mount specifying -collection ""Media"" with replication 002. I realized I wasn't gonna have enough storage for all of it with the old 2 copies and 3 copies for the new, so I started moving media collection to ensure encoding as I was coping it. Starting to run really tight on storage (in fact, ensure encoding failed because one drive had only 5gb available), and I was finished with a large ~8.5TiB folder of the media so I deleted it on the """" collection and I could not figure out how to crop the drives down, I must have had over 150 volumes with 99% deleted files. I spent several days searching around and found that you need to run volume.vacuum, but I couldn't get any output and it ran almost instantly, I could not for the life of me figure out what was wrong. Turns out volume.vacuum only started to work when I did ~0.01 or less because it was doing volumes from the media collection that were caught up on replication and had a couple deleted files from when I was migrating media and had to stop midway, this was the first time I saw volume.vacuum actually work, so now that I know it wasn't some weird edge case that with vacuum.enable/disable breaking a scanning service or something. (keep in mind this was my first time playing with seaweedfs) I was like it worked with -collection ""Media"", maybe it doesn't work with -collection """" or something, then I remember I haven't run volume.fix.replication yet because I planned to migrate all the data off into different pools. so I changed replication for collection  back to 001 and did a vacuum for .99 and got like 6+tb freed in about 2 minutes, did it again for .9 and 10 minutes another tb or so was freed",source-file,"volume.vacuum needs warning if replication isn't met **Describe the bug** If you run volume.vacuum, it doesn't do anything to volumes that aren't replicated to the spec (currently only 2 copies when you have 002 set). It just skips them silently **System Setup** - version 30GB 3.67 N/A linux amd64 **Expected behavior** I still think it shouldn't do anything other then let the user know that it would have done those volumes if they were replicated properly # Additional context OK, Story time I recently started using seaweedfs and migrated from a large 10 drive BTRFS raid1c3 array (3x 14TB and 7x 6TB) that was fairly full, I have about 19TB of data to migrate. BTRFS has the function to remove drives and move their data to other drives. So I started with a couple 6TB that weren't in the array and started removing a couple others while I started coping data to seaweedfs with replication 001. Was still using all the seaweedfs parts manually with tmux windows (I had 17 windows open at one point) , and I had problems with remembering the -encryption flag half way through the migration. Ok, I thought maybe I should actually use the collections feature instead just a huge big vault. so I will just migrate it again later, lets just get it off of the BTRFS array asap. After the migration completed, I used all the 6TB drives I have for this array, for a total of 14 drives, and saved the 14TB drives for a 2nd server in the future. I then change the default and all the volumes from 001 to 002 via master startup config and volume.configure.replication command. I then started to copy the 15TB of media I have into a new seaweedfs mount specifying -collection ""Media"" with replication 002. I realized I wasn't gonna have enough storage for all of it with the old 2 copies and 3 copies for the new, so I started moving media collection to ensure encoding as I was coping it. Starting to run really tight on storage (in fact, ensure encoding failed because one drive had only 5gb available), and I was finished with a large ~8.5TiB folder of the media so I deleted it on the """" collection and I could not figure out how to crop the drives down, I must have had over 150 volumes with 99% deleted files. I spent several days searching around and found that you need to run volume.vacuum, but I couldn't get any output and it ran almost instantly, I could not for the life of me figure out what was wrong. Turns out volume.vacuum only started to work when I did ~0.01 or less because it was doing volumes from the media collection that were caught up on replication and had a couple deleted files from when I was migrating media and had to stop midway, this was the first time I saw volume.vacuum actually work, so now that I know it wasn't some weird edge case that with vacuum.enable/disable breaking a scanning service or something. (keep in mind this was my first time playing with seaweedfs) I was like it worked with -collection ""Media"", maybe it doesn't work with -collection """" or something, then I remember I haven't run volume.fix.replication yet because I planned to migrate all the data off into different pools. so I changed replication for collection  back to 001 and did a vacuum for .99 and got like 6+tb freed in about 2 minutes, did it again for .9 and 10 minutes another tb or so was freed source-file",no-bug,0.8
1990,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1990,[shell] volumeServer.evacuate uniform movement,Now all volumes have gone to the one volume server `slow-volume-7.dc1:8080`  > volumeServer.evacuate -node slow-volume-4.dc1:8080 moving volume logs-p_409 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_425 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_427 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_383 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume 220 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_407 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_359 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-e_196 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-t_210 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-s_205 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume d_236 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_391 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume d_234 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 ,source-file,[shell] volumeServer.evacuate uniform movement Now all volumes have gone to the one volume server `slow-volume-7.dc1:8080`  > volumeServer.evacuate -node slow-volume-4.dc1:8080 moving volume logs-p_409 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_425 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_427 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_383 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume 220 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_407 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_359 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-e_196 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-t_210 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-s_205 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume d_236 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume logs-p_391 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080 moving volume d_234 slow-volume-4.dc1:8080 => slow-volume-7.dc1:8080  source-file,no-bug,0.9
5676,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5676,"Sqlite filer store is missing from Docker ""_full"" images","**Describe the bug** The sqlite filer store is missing from the full docker image. Attempting to start the filer with an enabled sqlite section in filer.toml produces an error, and the store is not listed when running `filer -help`. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"": `docker run chrislusf/seaweedfs:3.68_full filer -help` - output of `weed version`: `version 30GB 3.68 a9cd9b054 linux amd64` (via `docker run chrislusf/seaweedfs:3.68_full version`) **Expected behavior** The standalone binary has the expected behavior:  $ ./weed version version 30GB 3.68 a9cd9b0542ef9e2c795baf063d3f7db395ff209b linux amd64 $ ./weed filer -help [] Supported Filer Stores: arangodb cassandra elastic7 etcd hbase leveldb leveldb2 leveldb3 mongodb mysql mysql2 postgres postgres2 redis redis2 redis2_sentinel redis3 redis3_sentinel redis_cluster redis_cluster2 redis_cluster3 sqlite # present tikv ydb  All the other file listed file stores are present in the output from the docker image, except `sqlite`. **Additional context** 1. Commit bf0899cbf4ccb42e02f5984802d41c5e9b5e90bf added sqlite to `binaries_release4.yml`, but `container_release4.yml` wasn't updated at the same time. I don't know if this was intentional or an oversight. 2. This is not a request to add `sqlite` to the standard image. I don't think it would increase the size much, but it clearly hasn't been used before now so I don't think it's necessary. 3. It would be nice if `filer scaffold` didn't output unsupported sections, but that's a separate feature. 4. It would be nice to have a `latest_full` docker tag.",config-file | config-file,"Sqlite filer store is missing from Docker ""_full"" images **Describe the bug** The sqlite filer store is missing from the full docker image. Attempting to start the filer with an enabled sqlite section in filer.toml produces an error, and the store is not listed when running `filer -help`. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"": `docker run chrislusf/seaweedfs:3.68_full filer -help` - output of `weed version`: `version 30GB 3.68 a9cd9b054 linux amd64` (via `docker run chrislusf/seaweedfs:3.68_full version`) **Expected behavior** The standalone binary has the expected behavior:  $ ./weed version version 30GB 3.68 a9cd9b0542ef9e2c795baf063d3f7db395ff209b linux amd64 $ ./weed filer -help [] Supported Filer Stores: arangodb cassandra elastic7 etcd hbase leveldb leveldb2 leveldb3 mongodb mysql mysql2 postgres postgres2 redis redis2 redis2_sentinel redis3 redis3_sentinel redis_cluster redis_cluster2 redis_cluster3 sqlite # present tikv ydb  All the other file listed file stores are present in the output from the docker image, except `sqlite`. **Additional context** 1. Commit bf0899cbf4ccb42e02f5984802d41c5e9b5e90bf added sqlite to `binaries_release4.yml`, but `container_release4.yml` wasn't updated at the same time. I don't know if this was intentional or an oversight. 2. This is not a request to add `sqlite` to the standard image. I don't think it would increase the size much, but it clearly hasn't been used before now so I don't think it's necessary. 3. It would be nice if `filer scaffold` didn't output unsupported sections, but that's a separate feature. 4. It would be nice to have a `latest_full` docker tag. config-file config-file",no-bug,0.9
1682,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1682,panic when loading volumes concurrently,"**Describe the bug** Loading same volume more than once leads to SIGSEGV **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version - output of `weed version` - if using filer, show the content of `filer.toml` 1. start server: `./weed server` 2. upload some random files 3. restart with ""-volume.index leveldb"" `./weed server -volume.index leveldb` 4. crash log > I1216 18:24:45 91019 master_grpc_server.go:250] + client master@10.170.160.252:56816 I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/2.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/4.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/3.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/2.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/3.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/1.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/1.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/4.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/5.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/5.ldb I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/4.ldb error: resource temporarily unavailable I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/2.ldb error: resource temporarily unavailable I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/3.ldb error: resource temporarily unavailable I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/1.ldb error: resource temporarily unavailable I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/5.ldb error: resource temporarily unavailable panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x188 pc=0x49e80be] **Expected behavior** not crash",source-file,"panic when loading volumes concurrently **Describe the bug** Loading same volume more than once leads to SIGSEGV **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version - output of `weed version` - if using filer, show the content of `filer.toml` 1. start server: `./weed server` 2. upload some random files 3. restart with ""-volume.index leveldb"" `./weed server -volume.index leveldb` 4. crash log > I1216 18:24:45 91019 master_grpc_server.go:250] + client master@10.170.160.252:56816 I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/2.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/4.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/3.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/2.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/3.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/1.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/1.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/4.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/5.ldb I1216 18:24:45 91019 volume_loading.go:128] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/5.ldb I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/4.ldb error: resource temporarily unavailable I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/2.ldb error: resource temporarily unavailable I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/3.ldb error: resource temporarily unavailable I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/1.ldb error: resource temporarily unavailable I1216 18:24:45 91019 volume_loading.go:135] loading leveldb /var/folders/1x/lbz9zhkd1_n0vd2zlmsl_0n40000gn/T/5.ldb error: resource temporarily unavailable panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x188 pc=0x49e80be] **Expected behavior** not crash source-file",no-bug,0.9
2257,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2257,Filer locationPrefix configure does not exec replication,"**Describe the bug** When apply fs.configure on locationPrefix, replication rule does not exec - WEED places volumes in the same datacenter, regardless of the replication rule At the same time, TTL and volumeGrowthCount work correctly  > fs.configure { ""locations"": [ { ""locationPrefix"": ""/buckets/test"", ""replication"": ""100"", ""ttl"": ""600"", ""volumeGrowthCount"": 2 } ] }  syslog:  seaweedfs-master[26839]: volume_layout.go:362] Volume 109 becomes writable seaweedfs-master[26839]: volume_growth.go:235] Created Volume 109 on topo:dc2:0:<ip node1>:8080 seaweedfs-master[26839]: volume_layout.go:362] Volume 110 becomes writable seaweedfs-master[26839]: volume_growth.go:235] Created Volume 110 on topo:dc2:0:<ip node1>:8080 volume.list: DataCenter dc2 hdd(volume:6/1771 active:6 free:1765 remote:0) Rack 0 hdd(volume:6/1771 active:6 free:1765 remote:0) volume id:109 size:22777781424 collection:""test"" file_count:6022 delete_count:6 deleted_byte_count:950374 version:3 ttl:1281 modified_at_second:1628858635 volume id:110 size:22676154832 collection:""test"" file_count:5959 delete_count:3 deleted_byte_count:12142 version:3 ttl:1281 modified_at_second:1628858635  **System Setup** node1  /usr/local/bin/weed master /usr/local/bin/weed volume -dir=/var/spool/weed/vol -max=0 -mserver=stor:9333 -port=8080 -dataCenter dc2 -rack 0 /usr/local/bin/weed filer /usr/local/bin/weed s3 -config=/etc/seaweedfs/config.json  node2:  /usr/local/bin/weed volume -dir=/var/spool/weed/vol -max=0 -mserver=stor:9333 -port=8080 -dataCenter dc1 -rack 0  (`stor` ip present in /etc/hosts file)  # weed version version 30GB 2.61 3afbf040 linux amd64 Debian GNU/Linux 10 (buster) #/etc/seaweedfs/filer.toml [filer.options] recursive_delete = true [postgres2] enabled = true createTable =  CREATE TABLE IF NOT EXISTS ""%s"" ( dirhash BIGINT, name VARCHAR(65535), directory VARCHAR(65535), meta bytea, PRIMARY KEY (dirhash, name) );  hostname = ""stor"" port = 5432 username = ""filer"" password = ""seaweed"" database = ""weed"" schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0 # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO ""%[1]s"" (dirhash,name,directory,meta) VALUES($1,$2,$3,$4) ON CONFLICT (dirhash,name) DO UPDATE SET meta = EXCLUDED.meta WHERE ""%[1]s"".meta != EXCLUDED.meta  **Expected behavior** Weed places one volume in datacenter dc1 with one replica in dc2 **Additional context** weed check volumeGrowthCount needed:  > fs.configure -locationPrefix=/buckets/test -replication=111 -volumeGrowthCount=2 -apply -ttl 5 error: volumeGrowthCount 2 should be devided by replication copy count 4  when set volumeGrowthCount=4, Weed places 4 volume, without replica(with any replication value - 111/100/110)",source-file | source-file | source-file,"Filer locationPrefix configure does not exec replication **Describe the bug** When apply fs.configure on locationPrefix, replication rule does not exec - WEED places volumes in the same datacenter, regardless of the replication rule At the same time, TTL and volumeGrowthCount work correctly  > fs.configure { ""locations"": [ { ""locationPrefix"": ""/buckets/test"", ""replication"": ""100"", ""ttl"": ""600"", ""volumeGrowthCount"": 2 } ] }  syslog:  seaweedfs-master[26839]: volume_layout.go:362] Volume 109 becomes writable seaweedfs-master[26839]: volume_growth.go:235] Created Volume 109 on topo:dc2:0:<ip node1>:8080 seaweedfs-master[26839]: volume_layout.go:362] Volume 110 becomes writable seaweedfs-master[26839]: volume_growth.go:235] Created Volume 110 on topo:dc2:0:<ip node1>:8080 volume.list: DataCenter dc2 hdd(volume:6/1771 active:6 free:1765 remote:0) Rack 0 hdd(volume:6/1771 active:6 free:1765 remote:0) volume id:109 size:22777781424 collection:""test"" file_count:6022 delete_count:6 deleted_byte_count:950374 version:3 ttl:1281 modified_at_second:1628858635 volume id:110 size:22676154832 collection:""test"" file_count:5959 delete_count:3 deleted_byte_count:12142 version:3 ttl:1281 modified_at_second:1628858635  **System Setup** node1  /usr/local/bin/weed master /usr/local/bin/weed volume -dir=/var/spool/weed/vol -max=0 -mserver=stor:9333 -port=8080 -dataCenter dc2 -rack 0 /usr/local/bin/weed filer /usr/local/bin/weed s3 -config=/etc/seaweedfs/config.json  node2:  /usr/local/bin/weed volume -dir=/var/spool/weed/vol -max=0 -mserver=stor:9333 -port=8080 -dataCenter dc1 -rack 0  (`stor` ip present in /etc/hosts file)  # weed version version 30GB 2.61 3afbf040 linux amd64 Debian GNU/Linux 10 (buster) #/etc/seaweedfs/filer.toml [filer.options] recursive_delete = true [postgres2] enabled = true createTable =  CREATE TABLE IF NOT EXISTS ""%s"" ( dirhash BIGINT, name VARCHAR(65535), directory VARCHAR(65535), meta bytea, PRIMARY KEY (dirhash, name) );  hostname = ""stor"" port = 5432 username = ""filer"" password = ""seaweed"" database = ""weed"" schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0 # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO ""%[1]s"" (dirhash,name,directory,meta) VALUES($1,$2,$3,$4) ON CONFLICT (dirhash,name) DO UPDATE SET meta = EXCLUDED.meta WHERE ""%[1]s"".meta != EXCLUDED.meta  **Expected behavior** Weed places one volume in datacenter dc1 with one replica in dc2 **Additional context** weed check volumeGrowthCount needed:  > fs.configure -locationPrefix=/buckets/test -replication=111 -volumeGrowthCount=2 -apply -ttl 5 error: volumeGrowthCount 2 should be devided by replication copy count 4  when set volumeGrowthCount=4, Weed places 4 volume, without replica(with any replication value - 111/100/110) source-file source-file source-file",no-bug,0.8
4577,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4577,Auth Value of gRPC Response of LookupVolume is empty instead of containing a JWT,"**Describe the bug** When calling the Method ""LookupVolume"" with a FileId via gRPC on the Master Server the Auth-Value of the response is empty even though i added a security.toml with jwt keys to my servers.  var channel = GrpcChannel.ForAddress(""<ip address>""); var client = new Seaweed.SeaweedClient(channel); LookupVolumeRequest request = new LookupVolumeRequest(); request.VolumeOrFileIds.Add(""1,290c3fc91f20""); var res = client.LookupVolume(request); Console.WriteLine(""Auth: '"" + res.VolumeIdLocations[0].Auth + ""'"");  The Console Part outputs nothing and res.Auth == """" is True. **System Setup** Seaweed running via docker with this compose file:  version: '3.9' services: masterjwt: image: chrislusf/seaweedfs # use a remote image ports: - 9333:9333 - 19333:19333 - 9324:9324 container_name: seaweedfs-master-jwt command: ""master -ip=172.28.0.102 -ip.bind=0.0.0.0 -metricsPort=9324"" volume1jwt: image: chrislusf/seaweedfs # use a remote image ports: - 8080:8080 - 18080:18080 - 9325:9325 container_name: seaweedfs-volume-1-jwt command: 'volume -mserver=""masterjwt:9333"" -ip.bind=0.0.0.0 -port=8080 -metricsPort=9325 -publicUrl=<ip>' depends_on: - masterjwt  - output of `weed version`: version 30GB 3.51 4310e1fac linux amd64 - i added following security.toml file to volume and master server:  [jwt.signing] key = ""<my key>"" expires_after_seconds = 120 # seconds [access] ui = true [jwt.signing.read] key = ""<m< key>"" expires_after_seconds = 120 # seconds  **Expected behavior** I excpect the Response to include a JWT in the Auth value to read or update the given file. It works fine via http like this: `curl -i ""<ip master>:9333/dir/lookup?fileId=1,290c3fc91f20&read=yes""`",source-file | source-file,"Auth Value of gRPC Response of LookupVolume is empty instead of containing a JWT **Describe the bug** When calling the Method ""LookupVolume"" with a FileId via gRPC on the Master Server the Auth-Value of the response is empty even though i added a security.toml with jwt keys to my servers.  var channel = GrpcChannel.ForAddress(""<ip address>""); var client = new Seaweed.SeaweedClient(channel); LookupVolumeRequest request = new LookupVolumeRequest(); request.VolumeOrFileIds.Add(""1,290c3fc91f20""); var res = client.LookupVolume(request); Console.WriteLine(""Auth: '"" + res.VolumeIdLocations[0].Auth + ""'"");  The Console Part outputs nothing and res.Auth == """" is True. **System Setup** Seaweed running via docker with this compose file:  version: '3.9' services: masterjwt: image: chrislusf/seaweedfs # use a remote image ports: - 9333:9333 - 19333:19333 - 9324:9324 container_name: seaweedfs-master-jwt command: ""master -ip=172.28.0.102 -ip.bind=0.0.0.0 -metricsPort=9324"" volume1jwt: image: chrislusf/seaweedfs # use a remote image ports: - 8080:8080 - 18080:18080 - 9325:9325 container_name: seaweedfs-volume-1-jwt command: 'volume -mserver=""masterjwt:9333"" -ip.bind=0.0.0.0 -port=8080 -metricsPort=9325 -publicUrl=<ip>' depends_on: - masterjwt  - output of `weed version`: version 30GB 3.51 4310e1fac linux amd64 - i added following security.toml file to volume and master server:  [jwt.signing] key = ""<my key>"" expires_after_seconds = 120 # seconds [access] ui = true [jwt.signing.read] key = ""<m< key>"" expires_after_seconds = 120 # seconds  **Expected behavior** I excpect the Response to include a JWT in the Auth value to read or update the given file. It works fine via http like this: `curl -i ""<ip master>:9333/dir/lookup?fileId=1,290c3fc91f20&read=yes""` source-file source-file",no-bug,0.8
2952,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2952,weed fuse mount hangs.,"**Describe the bug** Fuse mount/filer hangs after high load from a restic restore.  [root@mouse-r13 ~]# sh -x /home/tdavis/home-backup.sh + RESTIC_PASSWORD=badbadbadjuju + export RESTIC_PASSWORD + RESTIC_REPOSITORY=s3:http://mouse-r11:8333/homes + export RESTIC_REPOSITORY + restic backup /home repository 7192c674 opened successfully, password is correct using parent snapshot 2e42bd8f Files: 231 new, 29 changed, 1201279 unmodified Dirs: 22 new, 43 changed, 203382 unmodified Added to the repo: 130.694 MiB processed 1201539 files, 233.310 GiB in 54:39 snapshot 02dacef4 saved [root@mouse-r13 ~]#  this is the snapshot to restore from. 1.2 million files, 233 GB..  mkdir /weed/ weed mount -dir /weed -filer mouse-r11:8889  this runs for a while, creates all the directories.. starts to restore, then hangs.  mkdir home cd home restic restore latest --target .  The repo is the s3 based repo from above backup. **System Setup** 3ea, AMD 8/32 CPU, 64Gb of ram, 10GB/bonded interfaces, NVME/m2 2TB storage. The S3 storage is 5 nodes, 2x1G ethernet, fanless Zotac ci329's, 8gb ram, 4 core intel celeron @ 1.10Ghz, 8TB SSD Micron 5100 Pro SATA (it's for disaster recovery) A restic restore from those 5 nodes to the local nvme drive is capable of doing 1.5Gb/sec easily - see:  [root@mouse-r13 restore]# time restic restore latest --target . repository 7192c674 opened successfully, password is correct restoring <Snapshot 02dacef4 of [/home] at 2022-04-21 12:07:27.565531555 -0700 PDT by root@mouse-r13> to . real 17m17.017s user 32m43.975s sys 9m46.551s [root@mouse-r13 restore]#  The same restore to the seaweedfs fuse mount hangs after several minutes. If I do a systemctl restart seaweedfs-filer/kill -9 the filer, it restarts, the restore restarts, and then hangs again..  [root@mouse-r11 system]# weed version version 30GB 2.99 8e98d7326b8cbd715033ec5a0e602732a4034850 linux amd64 [root@mouse-r11 system]#   [root@mouse-r11 system]# uname -a Linux mouse-r11 5.16.11-200.fc35.x86_64 #1 SMP PREEMPT Wed Feb 23 17:08:49 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux [root@mouse-r11 system]#  OS is Fedora 35 Server, selinux disabled. systemd service files: [seaweedfs-volume.service.txt](https://github.com/chrislusf/seaweedfs/files/8535084/seaweedfs-volume.service.txt) [seaweedfs-s3.service.txt](https://github.com/chrislusf/seaweedfs/files/8535085/seaweedfs-s3.service.txt) [seaweedfs-master.service.txt](https://github.com/chrislusf/seaweedfs/files/8535087/seaweedfs-master.service.txt) [seaweedfs-filer.service.txt](https://github.com/chrislusf/seaweedfs/files/8535088/seaweedfs-filer.service.txt) - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version - output of `weed version` - if using filer, show the content of `filer.toml` filer.toml is empty.  [root@mouse-r11 system]# weed shell master: localhost:9333 filers: [mouse-r11:8889] > fs.configure { ""locations"": [ { ""locationPrefix"": ""/backup/"", ""replication"": ""001"", ""diskType"": ""ssd"" }, { ""locationPrefix"": ""/buckets/"", ""replication"": ""001"", ""diskType"": ""ssd"" }, { ""locationPrefix"": ""/home/"", ""replication"": ""001"", ""diskType"": ""nvme"" } ] } >  **Expected behavior** not hangs, restore finishes. **Additional context** weed mount reports this when I crash and restart the filer:  2022/04/20 23:47:05 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:06 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:07 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:08 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:09 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:12 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:12 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:12 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:12 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:15 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:15 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:20 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT E0421 08:53:54 70094 weedfs_file_sync.go:168] fh flush create /home/home/boverhof/collectors/modbus/pollmb/logs/b59-ups1.log: CreateEntry: rpc error: code = Unavailable desc = error reading from server: EOF I0421 08:53:54 70094 wfs_filer_client.go:29] WithFilerClient 0 mouse-r11:18889: fh flush create /home/home/boverhof/collectors/modbus/pollmb/logs/b59-ups1.log: CreateEntry: rpc error: code = Unavailable desc = error reading from server: EOF E0421 08:53:54 70094 weedfs_file_sync.go:182] /home/home/boverhof/collectors/modbus/pollmb/logs/b59-ups1.log fh 0 flush: fh flush create /home/home/boverhof/collectors/modbus/pollmb/logs/b59-ups1.log: CreateEntry: rpc error: code = Unavailable desc = error reading from server: EOF I0421 08:53:54 70094 wfs_filer_client.go:29] WithFilerClient 0 mouse-r11:18889: rpc error: code = Unavailable desc = error reading from server: EOF E0421 08:53:54 70094 meta_cache_subscribe.go:63] follow metadata updates: subscribing filer meta change: rpc error: code = Unavailable desc = error reading from server: EOF I0421 08:53:54 70094 weedfs_write.go:36] assign volume failure count:1 path:""/home/home/tdavis/go/pkg/dep/sources/httpsgo.googlesource.com-crypto/.git/hooks/prepare-commit-msg.sample"": rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:54 70094 retry.go:25] retry assignVolume: err: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:55 70094 weedfs_write.go:36] assign volume failure count:1 path:""/home/home/tdavis/go/pkg/dep/sources/httpsgo.googlesource.com-crypto/.git/hooks/prepare-commit-msg.sample"": rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:55 70094 retry.go:25] retry assignVolume: err: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:57 70094 weedfs_write.go:36] assign volume failure count:1 path:""/home/home/tdavis/go/pkg/dep/sources/httpsgo.googlesource.com-crypto/.git/hooks/prepare-commit-msg.sample"": rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:57 70094 retry.go:25] retry assignVolume: err: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:59 70094 weedfs_write.go:36] assign volume failure count:1 path:""/home/home/tdavis/go/pkg/dep/sources/httpsgo.googlesource.com-crypto/.git/hooks/prepare-commit-msg.sample"": rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:59 70094 retry.go:25] retry assignVolume: err: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:54:02 70094 retry.go:19] retry assignVolume successfully 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT ",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"weed fuse mount hangs. **Describe the bug** Fuse mount/filer hangs after high load from a restic restore.  [root@mouse-r13 ~]# sh -x /home/tdavis/home-backup.sh + RESTIC_PASSWORD=badbadbadjuju + export RESTIC_PASSWORD + RESTIC_REPOSITORY=s3:http://mouse-r11:8333/homes + export RESTIC_REPOSITORY + restic backup /home repository 7192c674 opened successfully, password is correct using parent snapshot 2e42bd8f Files: 231 new, 29 changed, 1201279 unmodified Dirs: 22 new, 43 changed, 203382 unmodified Added to the repo: 130.694 MiB processed 1201539 files, 233.310 GiB in 54:39 snapshot 02dacef4 saved [root@mouse-r13 ~]#  this is the snapshot to restore from. 1.2 million files, 233 GB..  mkdir /weed/ weed mount -dir /weed -filer mouse-r11:8889  this runs for a while, creates all the directories.. starts to restore, then hangs.  mkdir home cd home restic restore latest --target .  The repo is the s3 based repo from above backup. **System Setup** 3ea, AMD 8/32 CPU, 64Gb of ram, 10GB/bonded interfaces, NVME/m2 2TB storage. The S3 storage is 5 nodes, 2x1G ethernet, fanless Zotac ci329's, 8gb ram, 4 core intel celeron @ 1.10Ghz, 8TB SSD Micron 5100 Pro SATA (it's for disaster recovery) A restic restore from those 5 nodes to the local nvme drive is capable of doing 1.5Gb/sec easily - see:  [root@mouse-r13 restore]# time restic restore latest --target . repository 7192c674 opened successfully, password is correct restoring <Snapshot 02dacef4 of [/home] at 2022-04-21 12:07:27.565531555 -0700 PDT by root@mouse-r13> to . real 17m17.017s user 32m43.975s sys 9m46.551s [root@mouse-r13 restore]#  The same restore to the seaweedfs fuse mount hangs after several minutes. If I do a systemctl restart seaweedfs-filer/kill -9 the filer, it restarts, the restore restarts, and then hangs again..  [root@mouse-r11 system]# weed version version 30GB 2.99 8e98d7326b8cbd715033ec5a0e602732a4034850 linux amd64 [root@mouse-r11 system]#   [root@mouse-r11 system]# uname -a Linux mouse-r11 5.16.11-200.fc35.x86_64 #1 SMP PREEMPT Wed Feb 23 17:08:49 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux [root@mouse-r11 system]#  OS is Fedora 35 Server, selinux disabled. systemd service files: [seaweedfs-volume.service.txt](https://github.com/chrislusf/seaweedfs/files/8535084/seaweedfs-volume.service.txt) [seaweedfs-s3.service.txt](https://github.com/chrislusf/seaweedfs/files/8535085/seaweedfs-s3.service.txt) [seaweedfs-master.service.txt](https://github.com/chrislusf/seaweedfs/files/8535087/seaweedfs-master.service.txt) [seaweedfs-filer.service.txt](https://github.com/chrislusf/seaweedfs/files/8535088/seaweedfs-filer.service.txt) - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version - output of `weed version` - if using filer, show the content of `filer.toml` filer.toml is empty.  [root@mouse-r11 system]# weed shell master: localhost:9333 filers: [mouse-r11:8889] > fs.configure { ""locations"": [ { ""locationPrefix"": ""/backup/"", ""replication"": ""001"", ""diskType"": ""ssd"" }, { ""locationPrefix"": ""/buckets/"", ""replication"": ""001"", ""diskType"": ""ssd"" }, { ""locationPrefix"": ""/home/"", ""replication"": ""001"", ""diskType"": ""nvme"" } ] } >  **Expected behavior** not hangs, restore finishes. **Additional context** weed mount reports this when I crash and restart the filer:  2022/04/20 23:47:05 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:06 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:07 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:08 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:09 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:12 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:12 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:12 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:12 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:15 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:15 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/20 23:47:20 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT E0421 08:53:54 70094 weedfs_file_sync.go:168] fh flush create /home/home/boverhof/collectors/modbus/pollmb/logs/b59-ups1.log: CreateEntry: rpc error: code = Unavailable desc = error reading from server: EOF I0421 08:53:54 70094 wfs_filer_client.go:29] WithFilerClient 0 mouse-r11:18889: fh flush create /home/home/boverhof/collectors/modbus/pollmb/logs/b59-ups1.log: CreateEntry: rpc error: code = Unavailable desc = error reading from server: EOF E0421 08:53:54 70094 weedfs_file_sync.go:182] /home/home/boverhof/collectors/modbus/pollmb/logs/b59-ups1.log fh 0 flush: fh flush create /home/home/boverhof/collectors/modbus/pollmb/logs/b59-ups1.log: CreateEntry: rpc error: code = Unavailable desc = error reading from server: EOF I0421 08:53:54 70094 wfs_filer_client.go:29] WithFilerClient 0 mouse-r11:18889: rpc error: code = Unavailable desc = error reading from server: EOF E0421 08:53:54 70094 meta_cache_subscribe.go:63] follow metadata updates: subscribing filer meta change: rpc error: code = Unavailable desc = error reading from server: EOF I0421 08:53:54 70094 weedfs_write.go:36] assign volume failure count:1 path:""/home/home/tdavis/go/pkg/dep/sources/httpsgo.googlesource.com-crypto/.git/hooks/prepare-commit-msg.sample"": rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:54 70094 retry.go:25] retry assignVolume: err: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:55 70094 weedfs_write.go:36] assign volume failure count:1 path:""/home/home/tdavis/go/pkg/dep/sources/httpsgo.googlesource.com-crypto/.git/hooks/prepare-commit-msg.sample"": rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:55 70094 retry.go:25] retry assignVolume: err: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:57 70094 weedfs_write.go:36] assign volume failure count:1 path:""/home/home/tdavis/go/pkg/dep/sources/httpsgo.googlesource.com-crypto/.git/hooks/prepare-commit-msg.sample"": rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:57 70094 retry.go:25] retry assignVolume: err: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:59 70094 weedfs_write.go:36] assign volume failure count:1 path:""/home/home/tdavis/go/pkg/dep/sources/httpsgo.googlesource.com-crypto/.git/hooks/prepare-commit-msg.sample"": rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:53:59 70094 retry.go:25] retry assignVolume: err: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.84.2:18889: connect: connection refused"" I0421 08:54:02 70094 retry.go:19] retry assignVolume successfully 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT 2022/04/21 08:54:03 writer: Write/Writev failed, err: 2=no such file or directory. opcode: INTERRUPT  source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
81,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/81,"weed listen ip on 0.0.0.0 ,regardless of -ip= setting",this is a bug ? find in 0.67-0.68 version [root@backgroup ~]# ps aux | grep weed root 15526 0.0 0.0 103252 840 pts/0 R+ 17:23 0:00 grep weed weedfs 32554 0.0 0.0 777940 24076 ? Sl 2014 21:58 /usr/local/weed/weed master -mdir=/opt/weedfs -ip=10.168.241.178 [root@backgroup ~]# netstat -tnlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:6379 0.0.0.0:\* LISTEN 11159/redis-server tcp 0 0 0.0.0.0:11211 0.0.0.0:\* LISTEN 4755/memcached tcp 0 0 0.0.0.0:4369 0.0.0.0:\* LISTEN 4621/epmd tcp 0 0 0.0.0.0:9333 0.0.0.0:\* LISTEN 32554/weed,config-file | config-file | config-file | config-file | test-file | config-file | config-file | config-file | config-file | other-file | documentation-file | container-file | container-file | container-file | container-file | other-file | other-file | other-file | documentation-file | documentation-file | documentation-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | source-file | source-file | source-file | source-file | source-file | other-file | documentation-file | test-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"weed listen ip on 0.0.0.0 ,regardless of -ip= setting this is a bug ? find in 0.67-0.68 version [root@backgroup ~]# ps aux | grep weed root 15526 0.0 0.0 103252 840 pts/0 R+ 17:23 0:00 grep weed weedfs 32554 0.0 0.0 777940 24076 ? Sl 2014 21:58 /usr/local/weed/weed master -mdir=/opt/weedfs -ip=10.168.241.178 [root@backgroup ~]# netstat -tnlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:6379 0.0.0.0:\* LISTEN 11159/redis-server tcp 0 0 0.0.0.0:11211 0.0.0.0:\* LISTEN 4755/memcached tcp 0 0 0.0.0.0:4369 0.0.0.0:\* LISTEN 4621/epmd tcp 0 0 0.0.0.0:9333 0.0.0.0:\* LISTEN 32554/weed config-file config-file config-file config-file test-file config-file config-file config-file config-file other-file documentation-file container-file container-file container-file container-file other-file other-file other-file documentation-file documentation-file documentation-file other-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file source-file source-file source-file source-file source-file other-file documentation-file test-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file other-file other-file source-file source-file source-file source-file source-file other-file source-file other-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
2583,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2583,[s3] Bug with backward compatibility of accesses 2.85,"version  2.85   Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 auth_credentials.go:219] v4 auth type -- | -- | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 error_handler.go:85] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 auth_credentials.go:248] user name: cdn actions: [Admin:cdn-*], action: Write | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 error_handler.go:85] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> | Jan 12, 2022 @ 15:05:13.935 | <Error><Code>AccessDenied</Code><Message>Access Denied.</Message><Resource>/d28547ea7e450b9d42b86d2dd1dd89b02598dce2.original</Resource><RequestId>1641981913107869339</RequestId><Key>d28547ea7e450b9d42b86d2dd1dd89b02598dce2.original</Key><BucketName>cdn</BucketName></Error> ",source-file | test-file,"[s3] Bug with backward compatibility of accesses 2.85 version  2.85   Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 auth_credentials.go:219] v4 auth type -- | -- | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 error_handler.go:85] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 auth_credentials.go:248] user name: cdn actions: [Admin:cdn-*], action: Write | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 error_handler.go:85] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> | Jan 12, 2022 @ 15:05:13.935 | <Error><Code>AccessDenied</Code><Message>Access Denied.</Message><Resource>/d28547ea7e450b9d42b86d2dd1dd89b02598dce2.original</Resource><RequestId>1641981913107869339</RequestId><Key>d28547ea7e450b9d42b86d2dd1dd89b02598dce2.original</Key><BucketName>cdn</BucketName></Error>  source-file test-file",bug,0.85
5066,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5066,Failed to commit new volume file while performing garbage collection on Windows,"**Describe the bug** When the system runs for a while, the volume becomes unavailable, and when recreated, it shows that the. bat file is being occupied by other processes. Causing historical files to be unreadable and writable, and being able to recover after restarting. Tested other versions on Windows that also have the same issue, such as 3.51 and 3.59. **System Setup** Windows 11 version 30GB 3.58 windows amd64 Start with weed -logdir=D:\ims-data\seaweedfs\logs server -s3 -ip=0.0.0.0 -dir=D:\ims-data\seaweedfs\datanode -s3.port=8333 -s3.config=C:\ims-depends\seaweedfs\script\s3_auth_config.json -filer.port=8888 -master.port=9333 -master.volumeSizeLimitMB=30000 -volume.max=1400 -volume.port=9011 Upload a file and delete Trigger the vacuum **Expected behavior** Vacuum completes with no errors. **Screenshots** **Additional context** I1130 14:43:18.806449 volume_layout.go:383 Volume 4 becomes unwritable I1130 14:43:18.806449 topology_vacuum.go:74 0 Start vacuuming 4 on 0.0.0.0:9011 I1130 14:43:18.822075 topology_vacuum.go:93 0 vacuum 4 on 0.0.0.0:9011 processed 292051360 bytes, loadAvg 0.00% I1130 14:43:18.868939 needle_map_memory.go:111 loading idx from offset 0 for file: D:\ims-data\seaweedfs\datanode/test-bucket_4.cpx I1130 14:43:18.931785 topology_vacuum.go:102 Complete vacuuming 4 on 0.0.0.0:9011 I1130 14:43:18.931785 topology_vacuum.go:128 Start Committing vacuum 4 on 0.0.0.0:9011 I1130 14:43:18.931785 volume_vacuum.go:106 Committing volume 4 vacuuming E1130 14:43:18.947110 volume_grpc_vacuum.go:89 failed commit volume 4: remove D:\ims-data\seaweedfs\datanode/test-bucket_4.dat: The process cannot access the file because it is being used by another process. E1130 14:43:18.947110 topology_vacuum.go:144 Error when committing vacuum 4 on 0.0.0.0:9011: rpc error: code = Unknown desc = remove D:\ims-data\seaweedfs\datanode/test-bucket_4.dat: The process cannot access the file because it is being used by another process.",source-file,"Failed to commit new volume file while performing garbage collection on Windows **Describe the bug** When the system runs for a while, the volume becomes unavailable, and when recreated, it shows that the. bat file is being occupied by other processes. Causing historical files to be unreadable and writable, and being able to recover after restarting. Tested other versions on Windows that also have the same issue, such as 3.51 and 3.59. **System Setup** Windows 11 version 30GB 3.58 windows amd64 Start with weed -logdir=D:\ims-data\seaweedfs\logs server -s3 -ip=0.0.0.0 -dir=D:\ims-data\seaweedfs\datanode -s3.port=8333 -s3.config=C:\ims-depends\seaweedfs\script\s3_auth_config.json -filer.port=8888 -master.port=9333 -master.volumeSizeLimitMB=30000 -volume.max=1400 -volume.port=9011 Upload a file and delete Trigger the vacuum **Expected behavior** Vacuum completes with no errors. **Screenshots** **Additional context** I1130 14:43:18.806449 volume_layout.go:383 Volume 4 becomes unwritable I1130 14:43:18.806449 topology_vacuum.go:74 0 Start vacuuming 4 on 0.0.0.0:9011 I1130 14:43:18.822075 topology_vacuum.go:93 0 vacuum 4 on 0.0.0.0:9011 processed 292051360 bytes, loadAvg 0.00% I1130 14:43:18.868939 needle_map_memory.go:111 loading idx from offset 0 for file: D:\ims-data\seaweedfs\datanode/test-bucket_4.cpx I1130 14:43:18.931785 topology_vacuum.go:102 Complete vacuuming 4 on 0.0.0.0:9011 I1130 14:43:18.931785 topology_vacuum.go:128 Start Committing vacuum 4 on 0.0.0.0:9011 I1130 14:43:18.931785 volume_vacuum.go:106 Committing volume 4 vacuuming E1130 14:43:18.947110 volume_grpc_vacuum.go:89 failed commit volume 4: remove D:\ims-data\seaweedfs\datanode/test-bucket_4.dat: The process cannot access the file because it is being used by another process. E1130 14:43:18.947110 topology_vacuum.go:144 Error when committing vacuum 4 on 0.0.0.0:9011: rpc error: code = Unknown desc = remove D:\ims-data\seaweedfs\datanode/test-bucket_4.dat: The process cannot access the file because it is being used by another process. source-file",no-bug,0.9
2389,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2389,"[s3test] PutObjectTagging, GetObjectTagging and DeleteObjectTagging","Nexus Blob Storage requires PutObjectTagging, GetObjectTagging and DeleteObjectTagging https://help.sonatype.com/repomanager3/repository-management/storage-guide/configuring-blob-stores#ConfiguringBlobStores-AWSSimpleStorageService(S3)  s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_put_obj_with_tags s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11449, in test_put_obj_with_tags s3tests_1 | eq(response_tagset, tagset) s3tests_1 | AssertionError: [{'Key': 'foo', 'Value': 'bar'}] != [{'Key': 'bar', 'Value': ''}, {'Key': 'foo', 'Value': 'bar'}] s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % ([{'Key': 'foo', 'Value': 'bar'}], [{'Key': 'bar', 'Value': ''}, {'Key': 'foo', 'Value': 'bar'}]))   s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_put_delete_tags s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11323, in test_put_delete_tags s3tests_1 | eq(response['ResponseMetadata']['HTTPStatusCode'], 200) s3tests_1 | AssertionError: 204 != 200 s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % (204, 200))   s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_get_obj_tagging s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11140, in test_get_obj_tagging s3tests_1 | eq(response['ResponseMetadata']['HTTPStatusCode'], 200) s3tests_1 | AssertionError: 204 != 200 s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % (204, 200))   E1020 11:37:12 1 s3api_object_tagging_handlers.go:59] PutObjectTaggingHandler Unmarshal /package-cache-nexus-proxy-cache/nexus/cache/content/vol-31/chap-12/aecabacb-1999-47b8-80f7-1dad5b639ed0.bytes?tagging: expected element <Tagging> in name space http://s3.amazonaws.com/doc/2006-03-01/ but have no name space",source-file | source-file | source-file | source-file,"[s3test] PutObjectTagging, GetObjectTagging and DeleteObjectTagging Nexus Blob Storage requires PutObjectTagging, GetObjectTagging and DeleteObjectTagging https://help.sonatype.com/repomanager3/repository-management/storage-guide/configuring-blob-stores#ConfiguringBlobStores-AWSSimpleStorageService(S3)  s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_put_obj_with_tags s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11449, in test_put_obj_with_tags s3tests_1 | eq(response_tagset, tagset) s3tests_1 | AssertionError: [{'Key': 'foo', 'Value': 'bar'}] != [{'Key': 'bar', 'Value': ''}, {'Key': 'foo', 'Value': 'bar'}] s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % ([{'Key': 'foo', 'Value': 'bar'}], [{'Key': 'bar', 'Value': ''}, {'Key': 'foo', 'Value': 'bar'}]))   s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_put_delete_tags s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11323, in test_put_delete_tags s3tests_1 | eq(response['ResponseMetadata']['HTTPStatusCode'], 200) s3tests_1 | AssertionError: 204 != 200 s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % (204, 200))   s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_get_obj_tagging s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11140, in test_get_obj_tagging s3tests_1 | eq(response['ResponseMetadata']['HTTPStatusCode'], 200) s3tests_1 | AssertionError: 204 != 200 s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % (204, 200))   E1020 11:37:12 1 s3api_object_tagging_handlers.go:59] PutObjectTaggingHandler Unmarshal /package-cache-nexus-proxy-cache/nexus/cache/content/vol-31/chap-12/aecabacb-1999-47b8-80f7-1dad5b639ed0.bytes?tagging: expected element <Tagging> in name space http://s3.amazonaws.com/doc/2006-03-01/ but have no name space source-file source-file source-file source-file",bug,0.95
6733,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6733,S3 Feature: please add s3.ip.bind command line parameter,"In our application, it is necessary to set the s3 bind ip to a value different from the ip specified by the parameter ""ip.bind (localhost)"". Starting weed.exe multiple times would be impractical in our case. To address this, we propose adding a command line parameter ""s3.ip.bind"", similar to the existing ""s3.port"".",source-file | source-file | source-file | source-file | source-file | source-file,"S3 Feature: please add s3.ip.bind command line parameter In our application, it is necessary to set the s3 bind ip to a value different from the ip specified by the parameter ""ip.bind (localhost)"". Starting weed.exe multiple times would be impractical in our case. To address this, we propose adding a command line parameter ""s3.ip.bind"", similar to the existing ""s3.port"". source-file source-file source-file source-file source-file source-file",no-bug,0.9
6163,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6163,Erasure coding that fails due to tight disk space does not clean itself up and leaves the disk full.,"**Describe the bug** I have a few volume servers that look like they tried to erasure code full volumes, but ran out of disk space. The volume directory now has the 244GB .dat file along with .ec files 00 through 09 which are each 24GB. None of the other volume servers has an ec file for this volume and the volume shows in the web console as being a regular volume still. Is it safe to just delete those files to free up space? I ran volume.move on one of them and the dat file moved, but the ec## files are still there. **System Setup** `weed volume -ip=weedve4 -ip.bind=0.0.0.0 -mserver=weedmb:9333 -port=9334 -metricsPort=9331 -disk hdd -dir=/mnt/weed -dir.idx=/root/weedvol -max 14` - OS version `Linux 6.8.12-2-pve #1 SMP PREEMPT_DYNAMIC PMX 6.8.12-2 (2024-09-05T10:03Z) x86_64 Linux` - output of `weed version` `version 8000GB 3.77 b28b1a34025a2f2ed80883e245250d00783bfea7 linux amd64` **Expected behavior** The erasure coding should not start if there is not enough space. I was bulk loading data while this happened, but with pre-allocation it should have had enough space and it should not have allocated a new volume while the volume was being encoded. If it fails it should clean up the shards if it doesn't get to at least 10 and it should send shards to the other volume servers if it does. The volume is only used for seaweed storage so there are no other processes using space on the volumes. I am using a standard maintenance .toml on the master:  lock ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force ec.balance -force volume.deleteEmpty -quietFor=24h -force volume.balance -force volume.fix.replication s3.clean.uploads -timeAgo=24h unlock  Here is the directory of one of the volume servers. The problems here are volids 107, 117, 52, 53, 82 and 93:  total 5T drwxrwxrwx 1 nobody nobody 2.7K Oct 23 05:47 . drwxr-xr-x 3 root root 4.0K Sep 25 18:58 .. -rw-r--r-- 1 root root 24.4G Sep 26 04:08 1.ec08 -rw-r--r-- 1 root root 24.4G Sep 26 04:17 1.ec12 -rw-r--r-- 1 root root 157 Sep 26 04:17 1.vif -rw-r--r-- 1 root root 24.4G Oct 8 06:02 10.ec06 -rw-r--r-- 1 root root 24.4G Oct 8 06:08 10.ec07 -rw-r--r-- 1 root root 157 Oct 8 06:08 10.vif -rw-r--r-- 1 root root 244.2G Oct 14 01:31 107.dat -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec00 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec01 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec02 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec03 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec04 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec05 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec06 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec07 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec08 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec09 -rw-r--r-- 1 root root 139 Oct 12 17:32 107.vif -rw-r--r-- 1 root root 24.4G Oct 8 15:27 11.ec06 -rw-r--r-- 1 root root 24.4G Oct 8 15:34 11.ec07 -rw-r--r-- 1 root root 157 Oct 8 15:34 11.vif -rw-r--r-- 1 root root 244.2G Oct 15 02:26 117.dat -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec00 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec01 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec02 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec03 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec04 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec05 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec06 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec07 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec08 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec09 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec10 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec11 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec12 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec13 -rw-r--r-- 1 root root 139 Oct 14 03:15 117.vif -rw-r--r-- 1 root root 24.4G Sep 26 06:40 12.ec06 -rw-r--r-- 1 root root 24.4G Sep 26 06:53 12.ec10 -rw-r--r-- 1 root root 157 Sep 26 06:53 12.vif -rw-r--r-- 1 root root 24.4G Sep 29 13:17 13.ec06 -rw-r--r-- 1 root root 24.4G Sep 29 13:39 13.ec11 -rw-r--r-- 1 root root 157 Sep 29 13:39 13.vif -rw-r--r-- 1 root root 244.2G Oct 21 13:07 133.dat -rw-r--r-- 1 root root 139 Oct 15 09:08 133.vif -rw-r--r-- 1 root root 24.4G Sep 27 05:14 14.ec08 -rw-r--r-- 1 root root 24.4G Sep 27 05:33 14.ec12 -rw-r--r-- 1 root root 157 Sep 27 05:33 14.vif -rw-r--r-- 1 root root 24.4G Sep 26 18:53 15.ec08 -rw-r--r-- 1 root root 24.4G Sep 26 19:02 15.ec12 -rw-r--r-- 1 root root 157 Sep 26 19:02 15.vif -rw-r--r-- 1 root root 24.4G Sep 26 10:42 16.ec06 -rw-r--r-- 1 root root 24.4G Sep 26 10:58 16.ec10 -rw-r--r-- 1 root root 157 Sep 26 10:58 16.vif -rw-r--r-- 1 root root 24.4G Sep 29 08:58 17.ec04 -rw-r--r-- 1 root root 24.4G Sep 29 09:26 17.ec09 -rw-r--r-- 1 root root 157 Sep 29 09:26 17.vif -rw-r--r-- 1 root root 24.4G Sep 29 18:33 18.ec04 -rw-r--r-- 1 root root 24.4G Sep 29 18:56 18.ec09 -rw-r--r-- 1 root root 157 Sep 29 18:56 18.vif -rw-r--r-- 1 root root 24.4G Sep 29 01:32 19.ec05 -rw-r--r-- 1 root root 24.4G Sep 29 01:49 19.ec10 -rw-r--r-- 1 root root 157 Sep 29 01:49 19.vif -rw-r--r-- 1 root root 24.4G Oct 2 04:23 20.ec04 -rw-r--r-- 1 root root 24.4G Oct 2 04:28 20.ec05 -rw-r--r-- 1 root root 157 Oct 2 04:28 20.vif -rw-r--r-- 1 root root 24.4G Oct 8 10:08 21.ec06 -rw-r--r-- 1 root root 24.4G Oct 8 10:14 21.ec07 -rw-r--r-- 1 root root 157 Oct 8 10:14 21.vif -rw-r--r-- 1 root root 23.3G Oct 4 08:05 22.ec06 -rw-r--r-- 1 root root 23.3G Oct 4 08:12 22.ec07 -rw-r--r-- 1 root root 145 Oct 4 08:12 22.vif -rw-r--r-- 1 root root 24.4G Sep 30 18:55 23.ec06 -rw-r--r-- 1 root root 24.4G Sep 30 19:06 23.ec11 -rw-r--r-- 1 root root 157 Sep 30 19:06 23.vif -rw-r--r-- 1 root root 24.4G Oct 11 11:18 24.ec06 -rw-r--r-- 1 root root 24.4G Oct 11 11:24 24.ec07 -rw-r--r-- 1 root root 157 Oct 11 11:24 24.vif -rw-r--r-- 1 root root 24.4G Sep 30 07:55 26.ec04 -rw-r--r-- 1 root root 24.4G Sep 30 08:14 26.ec09 -rw-r--r-- 1 root root 157 Sep 30 08:15 26.vif -rw-r--r-- 1 root root 24.4G Oct 3 00:20 27.ec09 -rw-r--r-- 1 root root 24.4G Oct 3 13:41 27.ec11 -rw-r--r-- 1 root root 157 Oct 3 13:41 27.vif -rw-r--r-- 1 root root 244.2G Sep 29 12:02 28.dat -rw-r--r-- 1 root root 24.4G Oct 10 02:50 28.ec11 -rw-r--r-- 1 root root 24.4G Oct 10 02:50 28.ec12 -rw-r--r-- 1 root root 150 Oct 10 02:50 28.vif -rw-r--r-- 1 root root 24.4G Sep 30 03:26 29.ec06 -rw-r--r-- 1 root root 24.4G Sep 30 03:26 29.ec11 -rw-r--r-- 1 root root 146 Oct 4 00:07 29.vif -rw-r--r-- 1 root root 24.4G Oct 8 07:40 31.ec04 -rw-r--r-- 1 root root 24.4G Oct 8 07:45 31.ec05 -rw-r--r-- 1 root root 157 Oct 8 07:45 31.vif -rw-r--r-- 1 root root 24.4G Oct 14 21:52 32.ec05 -rw-r--r-- 1 root root 24.4G Oct 14 21:58 32.ec06 -rw-r--r-- 1 root root 150 Oct 14 21:58 32.vif -rw-r--r-- 1 root root 24.4G Oct 5 07:40 35.ec06 -rw-r--r-- 1 root root 24.4G Oct 5 08:28 35.ec13 -rw-r--r-- 1 root root 157 Oct 5 08:28 35.vif -rw-r--r-- 1 root root 24.4G Oct 4 22:20 36.ec06 -rw-r--r-- 1 root root 24.4G Oct 4 23:07 36.ec13 -rw-r--r-- 1 root root 157 Oct 4 23:07 36.vif -rw-r--r-- 1 root root 24.3G Oct 10 12:48 37.ec05 -rw-r--r-- 1 root root 24.4G Oct 11 05:24 37.ec07 -rw-r--r-- 1 root root 150 Oct 11 05:24 37.vif -rw-r--r-- 1 root root 24.4G Oct 14 23:36 38.ec06 -rw-r--r-- 1 root root 24.4G Oct 14 23:42 38.ec07 -rw-r--r-- 1 root root 150 Oct 14 23:42 38.vif -rw-r--r-- 1 root root 24.4G Oct 9 15:51 40.ec01 -rw-r--r-- 1 root root 24.4G Oct 9 16:41 40.ec08 -rw-r--r-- 1 root root 150 Oct 9 16:41 40.vif -rw-r--r-- 1 root root 24.4G Oct 17 02:19 42.ec08 -rw-r--r-- 1 root root 20.9G Oct 17 02:25 42.ec09 -rw-r--r-- 1 root root 150 Oct 17 02:19 42.vif -rw-r--r-- 1 root root 24.4G Oct 14 17:22 43.ec06 -rw-r--r-- 1 root root 24.4G Oct 14 17:29 43.ec07 -rw-r--r-- 1 root root 150 Oct 14 17:29 43.vif -rw-r--r-- 1 root root 1.2G Oct 7 03:34 45.ec04 -rw-r--r-- 1 root root 24.4G Oct 8 02:45 45.ec07 -rw-r--r-- 1 root root 150 Oct 8 02:45 45.vif -rw-r--r-- 1 root root 244.2G Oct 8 03:36 49.dat -rw-r--r-- 1 root root 24.4G Oct 12 23:09 49.ec12 -rw-r--r-- 1 root root 24.4G Oct 12 23:09 49.ec13 -rw-r--r-- 1 root root 150 Oct 12 23:09 49.vif -rw-r--r-- 1 root root 24.4G Oct 8 11:52 5.ec04 -rw-r--r-- 1 root root 24.4G Oct 8 11:58 5.ec06 -rw-r--r-- 1 root root 157 Oct 8 11:58 5.vif -rw-r--r-- 1 root root 244.2G Oct 15 16:33 52.dat -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec00 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec01 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec02 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec03 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec04 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec05 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec06 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec07 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec08 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec09 -rw-r--r-- 1 root root 146 Oct 5 19:21 52.vif -rw-r--r-- 1 root root 244.2G Oct 8 10:59 53.dat -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec00 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec01 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec02 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec03 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec04 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec05 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec06 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec07 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec08 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec09 -rw-r--r-- 1 root root 146 Oct 5 19:21 53.vif -rw-r--r-- 1 root root 24.4G Oct 12 18:57 56.ec03 -rw-r--r-- 1 root root 24.4G Oct 12 19:21 56.ec09 -rw-r--r-- 1 root root 150 Oct 12 19:21 56.vif -rw-r--r-- 1 root root 23.8G Oct 14 22:35 58.ec05 -rw-r--r-- 1 root root 23.8G Oct 14 22:42 58.ec06 -rw-r--r-- 1 root root 150 Oct 14 22:42 58.vif -rw-r--r-- 1 root root 0 Sep 26 01:42 6.dat -rw-r--r-- 1 root root 24.4G Sep 26 00:30 6.ec11 -rw-r--r-- 1 root root 24.4G Sep 27 01:13 6.ec12 -rw-r--r-- 1 root root 157 Sep 27 01:13 6.vif -rw-r--r-- 1 root root 24.4G Oct 15 18:48 67.ec07 -rw-r--r-- 1 root root 24.4G Oct 15 18:56 67.ec08 -rw-r--r-- 1 root root 150 Oct 15 18:56 67.vif -rw-r--r-- 1 root root 24.4G Oct 16 22:59 68.ec08 -rw-r--r-- 1 root root 24.4G Oct 16 23:06 68.ec09 -rw-r--r-- 1 root root 150 Oct 16 23:06 68.vif -rw-r--r-- 1 root root 24.4G Sep 26 15:49 7.ec07 -rw-r--r-- 1 root root 24.4G Sep 26 16:06 7.ec11 -rw-r--r-- 1 root root 157 Sep 26 16:06 7.vif -rw-r--r-- 1 root root 24.4G Oct 14 08:00 70.ec06 -rw-r--r-- 1 root root 24.4G Oct 14 08:10 70.ec12 -rw-r--r-- 1 root root 150 Oct 14 08:10 70.vif -rw-r--r-- 1 root root 24.4G Oct 1 00:44 8.ec08 -rw-r--r-- 1 root root 24.4G Oct 1 01:00 8.ec13 -rw-r--r-- 1 root root 157 Oct 1 01:00 8.vif -rw-r--r-- 1 root root 244.2G Oct 11 13:17 82.dat -rw-r--r-- 1 root root 24.4G Oct 11 22:15 82.ec10 -rw-r--r-- 1 root root 24.4G Oct 11 22:15 82.ec11 -rw-r--r-- 1 root root 24.4G Oct 11 22:15 82.ec12 -rw-r--r-- 1 root root 24.4G Oct 11 22:15 82.ec13 -rw-r--r-- 1 root root 150 Oct 11 22:15 82.vif -rw-r--r-- 1 root root 6.7G Oct 10 06:10 87.dat -rw-r--r-- 1 root root 139 Oct 10 05:51 87.vif -rw-r--r-- 1 root root 24.4G Sep 30 00:17 9.ec04 -rw-r--r-- 1 root root 24.4G Sep 30 00:38 9.ec09 -rw-r--r-- 1 root root 157 Sep 30 13:13 9.vif -rw-r--r-- 1 root root 244.2G Oct 11 15:30 93.dat -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec00 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec01 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec02 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec03 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec04 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec05 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec06 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec07 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec08 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec09 -rw-r--r-- 1 root root 139 Oct 10 07:24 93.vif -rw-r--r-- 1 root root 36 Sep 25 19:03 vol_dir.uuid ",source-file | source-file,"Erasure coding that fails due to tight disk space does not clean itself up and leaves the disk full. **Describe the bug** I have a few volume servers that look like they tried to erasure code full volumes, but ran out of disk space. The volume directory now has the 244GB .dat file along with .ec files 00 through 09 which are each 24GB. None of the other volume servers has an ec file for this volume and the volume shows in the web console as being a regular volume still. Is it safe to just delete those files to free up space? I ran volume.move on one of them and the dat file moved, but the ec## files are still there. **System Setup** `weed volume -ip=weedve4 -ip.bind=0.0.0.0 -mserver=weedmb:9333 -port=9334 -metricsPort=9331 -disk hdd -dir=/mnt/weed -dir.idx=/root/weedvol -max 14` - OS version `Linux 6.8.12-2-pve #1 SMP PREEMPT_DYNAMIC PMX 6.8.12-2 (2024-09-05T10:03Z) x86_64 Linux` - output of `weed version` `version 8000GB 3.77 b28b1a34025a2f2ed80883e245250d00783bfea7 linux amd64` **Expected behavior** The erasure coding should not start if there is not enough space. I was bulk loading data while this happened, but with pre-allocation it should have had enough space and it should not have allocated a new volume while the volume was being encoded. If it fails it should clean up the shards if it doesn't get to at least 10 and it should send shards to the other volume servers if it does. The volume is only used for seaweed storage so there are no other processes using space on the volumes. I am using a standard maintenance .toml on the master:  lock ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force ec.balance -force volume.deleteEmpty -quietFor=24h -force volume.balance -force volume.fix.replication s3.clean.uploads -timeAgo=24h unlock  Here is the directory of one of the volume servers. The problems here are volids 107, 117, 52, 53, 82 and 93:  total 5T drwxrwxrwx 1 nobody nobody 2.7K Oct 23 05:47 . drwxr-xr-x 3 root root 4.0K Sep 25 18:58 .. -rw-r--r-- 1 root root 24.4G Sep 26 04:08 1.ec08 -rw-r--r-- 1 root root 24.4G Sep 26 04:17 1.ec12 -rw-r--r-- 1 root root 157 Sep 26 04:17 1.vif -rw-r--r-- 1 root root 24.4G Oct 8 06:02 10.ec06 -rw-r--r-- 1 root root 24.4G Oct 8 06:08 10.ec07 -rw-r--r-- 1 root root 157 Oct 8 06:08 10.vif -rw-r--r-- 1 root root 244.2G Oct 14 01:31 107.dat -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec00 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec01 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec02 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec03 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec04 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec05 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec06 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec07 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec08 -rw-r--r-- 1 root root 780.8M Oct 16 19:49 107.ec09 -rw-r--r-- 1 root root 139 Oct 12 17:32 107.vif -rw-r--r-- 1 root root 24.4G Oct 8 15:27 11.ec06 -rw-r--r-- 1 root root 24.4G Oct 8 15:34 11.ec07 -rw-r--r-- 1 root root 157 Oct 8 15:34 11.vif -rw-r--r-- 1 root root 244.2G Oct 15 02:26 117.dat -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec00 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec01 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec02 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec03 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec04 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec05 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec06 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec07 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec08 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec09 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec10 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec11 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec12 -rw-r--r-- 1 root root 5.0G Oct 24 16:19 117.ec13 -rw-r--r-- 1 root root 139 Oct 14 03:15 117.vif -rw-r--r-- 1 root root 24.4G Sep 26 06:40 12.ec06 -rw-r--r-- 1 root root 24.4G Sep 26 06:53 12.ec10 -rw-r--r-- 1 root root 157 Sep 26 06:53 12.vif -rw-r--r-- 1 root root 24.4G Sep 29 13:17 13.ec06 -rw-r--r-- 1 root root 24.4G Sep 29 13:39 13.ec11 -rw-r--r-- 1 root root 157 Sep 29 13:39 13.vif -rw-r--r-- 1 root root 244.2G Oct 21 13:07 133.dat -rw-r--r-- 1 root root 139 Oct 15 09:08 133.vif -rw-r--r-- 1 root root 24.4G Sep 27 05:14 14.ec08 -rw-r--r-- 1 root root 24.4G Sep 27 05:33 14.ec12 -rw-r--r-- 1 root root 157 Sep 27 05:33 14.vif -rw-r--r-- 1 root root 24.4G Sep 26 18:53 15.ec08 -rw-r--r-- 1 root root 24.4G Sep 26 19:02 15.ec12 -rw-r--r-- 1 root root 157 Sep 26 19:02 15.vif -rw-r--r-- 1 root root 24.4G Sep 26 10:42 16.ec06 -rw-r--r-- 1 root root 24.4G Sep 26 10:58 16.ec10 -rw-r--r-- 1 root root 157 Sep 26 10:58 16.vif -rw-r--r-- 1 root root 24.4G Sep 29 08:58 17.ec04 -rw-r--r-- 1 root root 24.4G Sep 29 09:26 17.ec09 -rw-r--r-- 1 root root 157 Sep 29 09:26 17.vif -rw-r--r-- 1 root root 24.4G Sep 29 18:33 18.ec04 -rw-r--r-- 1 root root 24.4G Sep 29 18:56 18.ec09 -rw-r--r-- 1 root root 157 Sep 29 18:56 18.vif -rw-r--r-- 1 root root 24.4G Sep 29 01:32 19.ec05 -rw-r--r-- 1 root root 24.4G Sep 29 01:49 19.ec10 -rw-r--r-- 1 root root 157 Sep 29 01:49 19.vif -rw-r--r-- 1 root root 24.4G Oct 2 04:23 20.ec04 -rw-r--r-- 1 root root 24.4G Oct 2 04:28 20.ec05 -rw-r--r-- 1 root root 157 Oct 2 04:28 20.vif -rw-r--r-- 1 root root 24.4G Oct 8 10:08 21.ec06 -rw-r--r-- 1 root root 24.4G Oct 8 10:14 21.ec07 -rw-r--r-- 1 root root 157 Oct 8 10:14 21.vif -rw-r--r-- 1 root root 23.3G Oct 4 08:05 22.ec06 -rw-r--r-- 1 root root 23.3G Oct 4 08:12 22.ec07 -rw-r--r-- 1 root root 145 Oct 4 08:12 22.vif -rw-r--r-- 1 root root 24.4G Sep 30 18:55 23.ec06 -rw-r--r-- 1 root root 24.4G Sep 30 19:06 23.ec11 -rw-r--r-- 1 root root 157 Sep 30 19:06 23.vif -rw-r--r-- 1 root root 24.4G Oct 11 11:18 24.ec06 -rw-r--r-- 1 root root 24.4G Oct 11 11:24 24.ec07 -rw-r--r-- 1 root root 157 Oct 11 11:24 24.vif -rw-r--r-- 1 root root 24.4G Sep 30 07:55 26.ec04 -rw-r--r-- 1 root root 24.4G Sep 30 08:14 26.ec09 -rw-r--r-- 1 root root 157 Sep 30 08:15 26.vif -rw-r--r-- 1 root root 24.4G Oct 3 00:20 27.ec09 -rw-r--r-- 1 root root 24.4G Oct 3 13:41 27.ec11 -rw-r--r-- 1 root root 157 Oct 3 13:41 27.vif -rw-r--r-- 1 root root 244.2G Sep 29 12:02 28.dat -rw-r--r-- 1 root root 24.4G Oct 10 02:50 28.ec11 -rw-r--r-- 1 root root 24.4G Oct 10 02:50 28.ec12 -rw-r--r-- 1 root root 150 Oct 10 02:50 28.vif -rw-r--r-- 1 root root 24.4G Sep 30 03:26 29.ec06 -rw-r--r-- 1 root root 24.4G Sep 30 03:26 29.ec11 -rw-r--r-- 1 root root 146 Oct 4 00:07 29.vif -rw-r--r-- 1 root root 24.4G Oct 8 07:40 31.ec04 -rw-r--r-- 1 root root 24.4G Oct 8 07:45 31.ec05 -rw-r--r-- 1 root root 157 Oct 8 07:45 31.vif -rw-r--r-- 1 root root 24.4G Oct 14 21:52 32.ec05 -rw-r--r-- 1 root root 24.4G Oct 14 21:58 32.ec06 -rw-r--r-- 1 root root 150 Oct 14 21:58 32.vif -rw-r--r-- 1 root root 24.4G Oct 5 07:40 35.ec06 -rw-r--r-- 1 root root 24.4G Oct 5 08:28 35.ec13 -rw-r--r-- 1 root root 157 Oct 5 08:28 35.vif -rw-r--r-- 1 root root 24.4G Oct 4 22:20 36.ec06 -rw-r--r-- 1 root root 24.4G Oct 4 23:07 36.ec13 -rw-r--r-- 1 root root 157 Oct 4 23:07 36.vif -rw-r--r-- 1 root root 24.3G Oct 10 12:48 37.ec05 -rw-r--r-- 1 root root 24.4G Oct 11 05:24 37.ec07 -rw-r--r-- 1 root root 150 Oct 11 05:24 37.vif -rw-r--r-- 1 root root 24.4G Oct 14 23:36 38.ec06 -rw-r--r-- 1 root root 24.4G Oct 14 23:42 38.ec07 -rw-r--r-- 1 root root 150 Oct 14 23:42 38.vif -rw-r--r-- 1 root root 24.4G Oct 9 15:51 40.ec01 -rw-r--r-- 1 root root 24.4G Oct 9 16:41 40.ec08 -rw-r--r-- 1 root root 150 Oct 9 16:41 40.vif -rw-r--r-- 1 root root 24.4G Oct 17 02:19 42.ec08 -rw-r--r-- 1 root root 20.9G Oct 17 02:25 42.ec09 -rw-r--r-- 1 root root 150 Oct 17 02:19 42.vif -rw-r--r-- 1 root root 24.4G Oct 14 17:22 43.ec06 -rw-r--r-- 1 root root 24.4G Oct 14 17:29 43.ec07 -rw-r--r-- 1 root root 150 Oct 14 17:29 43.vif -rw-r--r-- 1 root root 1.2G Oct 7 03:34 45.ec04 -rw-r--r-- 1 root root 24.4G Oct 8 02:45 45.ec07 -rw-r--r-- 1 root root 150 Oct 8 02:45 45.vif -rw-r--r-- 1 root root 244.2G Oct 8 03:36 49.dat -rw-r--r-- 1 root root 24.4G Oct 12 23:09 49.ec12 -rw-r--r-- 1 root root 24.4G Oct 12 23:09 49.ec13 -rw-r--r-- 1 root root 150 Oct 12 23:09 49.vif -rw-r--r-- 1 root root 24.4G Oct 8 11:52 5.ec04 -rw-r--r-- 1 root root 24.4G Oct 8 11:58 5.ec06 -rw-r--r-- 1 root root 157 Oct 8 11:58 5.vif -rw-r--r-- 1 root root 244.2G Oct 15 16:33 52.dat -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec00 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec01 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec02 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec03 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec04 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec05 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec06 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec07 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec08 -rw-r--r-- 1 root root 5.7G Oct 23 05:45 52.ec09 -rw-r--r-- 1 root root 146 Oct 5 19:21 52.vif -rw-r--r-- 1 root root 244.2G Oct 8 10:59 53.dat -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec00 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec01 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec02 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec03 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec04 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec05 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec06 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec07 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec08 -rw-r--r-- 1 root root 21.6G Oct 15 13:07 53.ec09 -rw-r--r-- 1 root root 146 Oct 5 19:21 53.vif -rw-r--r-- 1 root root 24.4G Oct 12 18:57 56.ec03 -rw-r--r-- 1 root root 24.4G Oct 12 19:21 56.ec09 -rw-r--r-- 1 root root 150 Oct 12 19:21 56.vif -rw-r--r-- 1 root root 23.8G Oct 14 22:35 58.ec05 -rw-r--r-- 1 root root 23.8G Oct 14 22:42 58.ec06 -rw-r--r-- 1 root root 150 Oct 14 22:42 58.vif -rw-r--r-- 1 root root 0 Sep 26 01:42 6.dat -rw-r--r-- 1 root root 24.4G Sep 26 00:30 6.ec11 -rw-r--r-- 1 root root 24.4G Sep 27 01:13 6.ec12 -rw-r--r-- 1 root root 157 Sep 27 01:13 6.vif -rw-r--r-- 1 root root 24.4G Oct 15 18:48 67.ec07 -rw-r--r-- 1 root root 24.4G Oct 15 18:56 67.ec08 -rw-r--r-- 1 root root 150 Oct 15 18:56 67.vif -rw-r--r-- 1 root root 24.4G Oct 16 22:59 68.ec08 -rw-r--r-- 1 root root 24.4G Oct 16 23:06 68.ec09 -rw-r--r-- 1 root root 150 Oct 16 23:06 68.vif -rw-r--r-- 1 root root 24.4G Sep 26 15:49 7.ec07 -rw-r--r-- 1 root root 24.4G Sep 26 16:06 7.ec11 -rw-r--r-- 1 root root 157 Sep 26 16:06 7.vif -rw-r--r-- 1 root root 24.4G Oct 14 08:00 70.ec06 -rw-r--r-- 1 root root 24.4G Oct 14 08:10 70.ec12 -rw-r--r-- 1 root root 150 Oct 14 08:10 70.vif -rw-r--r-- 1 root root 24.4G Oct 1 00:44 8.ec08 -rw-r--r-- 1 root root 24.4G Oct 1 01:00 8.ec13 -rw-r--r-- 1 root root 157 Oct 1 01:00 8.vif -rw-r--r-- 1 root root 244.2G Oct 11 13:17 82.dat -rw-r--r-- 1 root root 24.4G Oct 11 22:15 82.ec10 -rw-r--r-- 1 root root 24.4G Oct 11 22:15 82.ec11 -rw-r--r-- 1 root root 24.4G Oct 11 22:15 82.ec12 -rw-r--r-- 1 root root 24.4G Oct 11 22:15 82.ec13 -rw-r--r-- 1 root root 150 Oct 11 22:15 82.vif -rw-r--r-- 1 root root 6.7G Oct 10 06:10 87.dat -rw-r--r-- 1 root root 139 Oct 10 05:51 87.vif -rw-r--r-- 1 root root 24.4G Sep 30 00:17 9.ec04 -rw-r--r-- 1 root root 24.4G Sep 30 00:38 9.ec09 -rw-r--r-- 1 root root 157 Sep 30 13:13 9.vif -rw-r--r-- 1 root root 244.2G Oct 11 15:30 93.dat -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec00 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec01 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec02 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec03 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec04 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec05 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec06 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec07 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec08 -rw-r--r-- 1 root root 2.0G Oct 21 05:06 93.ec09 -rw-r--r-- 1 root root 139 Oct 10 07:24 93.vif -rw-r--r-- 1 root root 36 Sep 25 19:03 vol_dir.uuid  source-file source-file",no-bug,0.9
34,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/34,Backups / Migrations,"Hi, I'd like to migrate data from a running weed-fs to another one (from a staging server to a production one for instance), or even just make a backup of the files (that I could re-import if needed, not just a big dump) is there some export/import/migration possibility in place ? Thanks!",config-file | documentation-file | other-file | other-file | documentation-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Backups / Migrations Hi, I'd like to migrate data from a running weed-fs to another one (from a staging server to a production one for instance), or even just make a backup of the files (that I could re-import if needed, not just a big dump) is there some export/import/migration possibility in place ? Thanks! config-file documentation-file other-file other-file documentation-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2345,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2345,seaweedfs crashed,"version:**2.65 linux amd64** Command: **nohup weed server -ip=90.90.90.12 -dir=/mnt/vol/object_444/data_1 -s3 -s3.port=29000 -s3.allowEmptyFolder -volume.port=27000 -filer.port=28000 -volume.max=4294967295 &** I use cosbench to test performance of weed. When running the test , I quickly encountered two serious problems **1 weed crashed**  I0928 22:04:43 61566 volume_loading.go:133] loading index /mnt/vol/object_444/data_1/abc203726_55138.idx to memory I0928 22:04:43 61566 store.go:135] add volume 55138 I0928 22:04:44 61566 topology.go:208] removing volume info: Id:55135, Size:0, ReplicaPlacement:000, Collection:abc203726, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false I0928 22:04:44 61566 volume_layout.go:349] Volume 55135 becomes unwritable I0928 22:04:44 61566 topology.go:208] removing volume info: Id:55137, Size:0, ReplicaPlacement:000, Collection:abc203726, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false I0928 22:04:44 61566 volume_layout.go:349] Volume 55137 becomes unwritable I0928 22:04:44 61566 topology.go:208] removing volume info: Id:55136, Size:0, ReplicaPlacement:000, Collection:abc203726, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false I0928 22:04:44 61566 volume_layout.go:349] Volume 55136 becomes unwritable I0928 22:04:44 61566 master_grpc_server.go:113] master see deleted volume 55135 from 90.90.90.12:27000 I0928 22:04:44 61566 master_grpc_server.go:113] master see deleted volume 55137 from 90.90.90.12:27000 I0928 22:04:44 61566 master_grpc_server.go:113] master see deleted volume 55136 from 90.90.90.12:27000 I0928 22:04:44 61566 master_grpc_server.go:154] master send to filer@90.90.90.12:28000: url:""90.90.90.12:27000"" public_url:""90.90.90.12:27000"" deleted_vids:55135 deleted_vids:55137 deleted_vids:55136 data_center:""DefaultDataCenter"" panic: runtime error: index out of range [0] with length 0 goroutine 8037320 [running]: github.com/chrislusf/seaweedfs/weed/topology.(*VolumeLocationList).Head(0xd53fc12f48) /root/original_weed/seaweedfs/weed/topology/volume_location_list.go:31 +0x4a github.com/chrislusf/seaweedfs/weed/topology.(*Topology).PickForWrite(0xc0003c81e0, 0x1, 0xd54ff8fe30) /root/original_weed/seaweedfs/weed/topology/topology.go:148 +0x774 github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).Assign(0xc000ed6f00, {0x31bea78, 0xd5529cd950}, 0xd5529de6e0) /root/original_weed/seaweedfs/weed/server/master_grpc_server_volume.go:150 +0x7d2 github.com/chrislusf/seaweedfs/weed/pb/master_pb._Seaweed_Assign_Handler({0x2e726a0, 0xc000ed6f00}, {0x31bea78, 0xd5529cd950}, 0xd5529a5e60, 0x0) /root/original_weed/seaweedfs/weed/pb/master_pb/master.pb.go:4460 +0x385 google.golang.org/grpc.(*Server).processUnaryRPC(0xc00068ad00, {0x31e7e90, 0xc000282480}, 0xd5529bf100, 0xc001069b00, 0x431edd8, 0x0) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:1082 +0x14c9 google.golang.org/grpc.(*Server).handleStream(0xc00068ad00, {0x31e7e90, 0xc000282480}, 0xd5529bf100, 0x0) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:1405 +0x852 google.golang.org/grpc.(*Server).serveStreams.func1.1() /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:746 +0x11d created by google.golang.org/grpc.(*Server).serveStreams.func1 /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:744 +0x125 I0928 22:04:47 02813 master.go:165] current: 90.90.90.12:9333 peers: I0928 22:04:47 02813 file_util.go:23] Folder /mnt/vol/object_444/data_1 Permission: -rwxr-xr-x I0928 22:04:47 02813 file_util.go:23] Folder /mnt/vol/object_444/data_1 Permission: -rwxr-xr-x I0928 22:04:47 02813 master.go:165] current: 90.90.90.12:9333 peers:90.90.90.12:9333 I0928 22:04:47 02813 master_server.go:116] Volume Size Limit is 30000 MB I0928 22:04:47 02813 master_server.go:210] adminScripts: I0928 22:04:47 02813 master.go:120] Start Seaweed Master 30GB 2.65 at :9333 F0928 22:04:47 02813 master.go:123] Master startup error: listen tcp :9333: bind: address already in use goroutine 44 [running]:  **2) weed show no free volume left ,but --volume.max was set to 4294967295 . After restarting weed, the error disapperd, but a few minutes later ,it shows again. I used weed shell to list volumes, and found that the number of volume was increasing** Here is th weed log. [weed.log](https://github.com/chrislusf/seaweedfs/files/7244879/weed.log)",source-file,"seaweedfs crashed version:**2.65 linux amd64** Command: **nohup weed server -ip=90.90.90.12 -dir=/mnt/vol/object_444/data_1 -s3 -s3.port=29000 -s3.allowEmptyFolder -volume.port=27000 -filer.port=28000 -volume.max=4294967295 &** I use cosbench to test performance of weed. When running the test , I quickly encountered two serious problems **1 weed crashed**  I0928 22:04:43 61566 volume_loading.go:133] loading index /mnt/vol/object_444/data_1/abc203726_55138.idx to memory I0928 22:04:43 61566 store.go:135] add volume 55138 I0928 22:04:44 61566 topology.go:208] removing volume info: Id:55135, Size:0, ReplicaPlacement:000, Collection:abc203726, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false I0928 22:04:44 61566 volume_layout.go:349] Volume 55135 becomes unwritable I0928 22:04:44 61566 topology.go:208] removing volume info: Id:55137, Size:0, ReplicaPlacement:000, Collection:abc203726, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false I0928 22:04:44 61566 volume_layout.go:349] Volume 55137 becomes unwritable I0928 22:04:44 61566 topology.go:208] removing volume info: Id:55136, Size:0, ReplicaPlacement:000, Collection:abc203726, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false I0928 22:04:44 61566 volume_layout.go:349] Volume 55136 becomes unwritable I0928 22:04:44 61566 master_grpc_server.go:113] master see deleted volume 55135 from 90.90.90.12:27000 I0928 22:04:44 61566 master_grpc_server.go:113] master see deleted volume 55137 from 90.90.90.12:27000 I0928 22:04:44 61566 master_grpc_server.go:113] master see deleted volume 55136 from 90.90.90.12:27000 I0928 22:04:44 61566 master_grpc_server.go:154] master send to filer@90.90.90.12:28000: url:""90.90.90.12:27000"" public_url:""90.90.90.12:27000"" deleted_vids:55135 deleted_vids:55137 deleted_vids:55136 data_center:""DefaultDataCenter"" panic: runtime error: index out of range [0] with length 0 goroutine 8037320 [running]: github.com/chrislusf/seaweedfs/weed/topology.(*VolumeLocationList).Head(0xd53fc12f48) /root/original_weed/seaweedfs/weed/topology/volume_location_list.go:31 +0x4a github.com/chrislusf/seaweedfs/weed/topology.(*Topology).PickForWrite(0xc0003c81e0, 0x1, 0xd54ff8fe30) /root/original_weed/seaweedfs/weed/topology/topology.go:148 +0x774 github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).Assign(0xc000ed6f00, {0x31bea78, 0xd5529cd950}, 0xd5529de6e0) /root/original_weed/seaweedfs/weed/server/master_grpc_server_volume.go:150 +0x7d2 github.com/chrislusf/seaweedfs/weed/pb/master_pb._Seaweed_Assign_Handler({0x2e726a0, 0xc000ed6f00}, {0x31bea78, 0xd5529cd950}, 0xd5529a5e60, 0x0) /root/original_weed/seaweedfs/weed/pb/master_pb/master.pb.go:4460 +0x385 google.golang.org/grpc.(*Server).processUnaryRPC(0xc00068ad00, {0x31e7e90, 0xc000282480}, 0xd5529bf100, 0xc001069b00, 0x431edd8, 0x0) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:1082 +0x14c9 google.golang.org/grpc.(*Server).handleStream(0xc00068ad00, {0x31e7e90, 0xc000282480}, 0xd5529bf100, 0x0) /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:1405 +0x852 google.golang.org/grpc.(*Server).serveStreams.func1.1() /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:746 +0x11d created by google.golang.org/grpc.(*Server).serveStreams.func1 /root/go/pkg/mod/google.golang.org/grpc@v1.29.1/server.go:744 +0x125 I0928 22:04:47 02813 master.go:165] current: 90.90.90.12:9333 peers: I0928 22:04:47 02813 file_util.go:23] Folder /mnt/vol/object_444/data_1 Permission: -rwxr-xr-x I0928 22:04:47 02813 file_util.go:23] Folder /mnt/vol/object_444/data_1 Permission: -rwxr-xr-x I0928 22:04:47 02813 master.go:165] current: 90.90.90.12:9333 peers:90.90.90.12:9333 I0928 22:04:47 02813 master_server.go:116] Volume Size Limit is 30000 MB I0928 22:04:47 02813 master_server.go:210] adminScripts: I0928 22:04:47 02813 master.go:120] Start Seaweed Master 30GB 2.65 at :9333 F0928 22:04:47 02813 master.go:123] Master startup error: listen tcp :9333: bind: address already in use goroutine 44 [running]:  **2) weed show no free volume left ,but --volume.max was set to 4294967295 . After restarting weed, the error disapperd, but a few minutes later ,it shows again. I used weed shell to list volumes, and found that the number of volume was increasing** Here is th weed log. [weed.log](https://github.com/chrislusf/seaweedfs/files/7244879/weed.log) source-file",no-bug,0.9
960,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/960,how to start filer,"I use this command to start filer: docker run -d -p 8888:8888 --name fs-filer --restart=always -v /data/weedfs/filer:/data -e WEED_IP=$smartIp --add-host=mysql:$smartIp registry.cn-hangzhou.aliyuncs.com/joywise-iedu/seaweedfs:1.33 filer -master=""$smartIp:9333"" -port=8888 Cause an error: I0515 06:09:16 1 filer_server.go:103] Reading : Config File ""security"" Not Found in ""[/ /root/.seaweedfs /etc/seaweedfs]"" I0515 06:09:16 1 filer_server.go:103] Reading /etc/seaweedfs/filer.toml: While parsing config: (14, 11): keys cannot contain new lines I0515 06:09:16 1 filer_server.go:103] Reading : Config File ""notification"" Not Found in ""[/ /root/.seaweedfs /etc/seaweedfs]"" I0515 06:09:16 1 leveldb_store.go:37] filer store dir: ./filerdb I0515 06:09:16 1 file_util.go:19] Folder ./filerdb Permission: -rwxr-xr-x I0515 06:09:16 1 configuration.go:26] Configure filer for leveldb I0515 06:09:16 1 filer.go:131] Start Seaweed Filer 30GB 1.33 at 10.10.23.22:8888 F0515 06:09:16 1 filer.go:137] Filer listener error: listen tcp 10.10.23.22:8888: bind: cannot assign requested address goroutine 1 [running]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0xc0005a2a00, 0xc0004180e0, 0x7c, 0xd3) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:767 +0xb1 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x262fac0, 0xc000000003, 0xc0001bd960, 0x25ab9c1, 0x8, 0x89, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:718 +0x2d9 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x262fac0, 0x3, 0x16b6085, 0x18, 0xc000465de8, 0x1, 0x1) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:656 +0x14e github.com/chrislusf/seaweedfs/weed/glog.Fatalf() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:1149 github.com/chrislusf/seaweedfs/weed/command.(*FilerOptions).startFiler(0x262f700) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:137 +0x50c github.com/chrislusf/seaweedfs/weed/command.runFiler(0x261bd60, 0xc00003a230, 0x0, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:82 +0x4b main.main() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/weed.go:67 +0x2fe",config-file,"how to start filer I use this command to start filer: docker run -d -p 8888:8888 --name fs-filer --restart=always -v /data/weedfs/filer:/data -e WEED_IP=$smartIp --add-host=mysql:$smartIp registry.cn-hangzhou.aliyuncs.com/joywise-iedu/seaweedfs:1.33 filer -master=""$smartIp:9333"" -port=8888 Cause an error: I0515 06:09:16 1 filer_server.go:103] Reading : Config File ""security"" Not Found in ""[/ /root/.seaweedfs /etc/seaweedfs]"" I0515 06:09:16 1 filer_server.go:103] Reading /etc/seaweedfs/filer.toml: While parsing config: (14, 11): keys cannot contain new lines I0515 06:09:16 1 filer_server.go:103] Reading : Config File ""notification"" Not Found in ""[/ /root/.seaweedfs /etc/seaweedfs]"" I0515 06:09:16 1 leveldb_store.go:37] filer store dir: ./filerdb I0515 06:09:16 1 file_util.go:19] Folder ./filerdb Permission: -rwxr-xr-x I0515 06:09:16 1 configuration.go:26] Configure filer for leveldb I0515 06:09:16 1 filer.go:131] Start Seaweed Filer 30GB 1.33 at 10.10.23.22:8888 F0515 06:09:16 1 filer.go:137] Filer listener error: listen tcp 10.10.23.22:8888: bind: cannot assign requested address goroutine 1 [running]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0xc0005a2a00, 0xc0004180e0, 0x7c, 0xd3) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:767 +0xb1 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x262fac0, 0xc000000003, 0xc0001bd960, 0x25ab9c1, 0x8, 0x89, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:718 +0x2d9 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x262fac0, 0x3, 0x16b6085, 0x18, 0xc000465de8, 0x1, 0x1) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:656 +0x14e github.com/chrislusf/seaweedfs/weed/glog.Fatalf() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:1149 github.com/chrislusf/seaweedfs/weed/command.(*FilerOptions).startFiler(0x262f700) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:137 +0x50c github.com/chrislusf/seaweedfs/weed/command.runFiler(0x261bd60, 0xc00003a230, 0x0, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:82 +0x4b main.main() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/weed.go:67 +0x2fe config-file",no-bug,0.9
3578,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3578,[filer] Data chunk that could not be uploaded to replicas volume is also deleted.,"**Describe the bug** When uploading chunks to the volume server, an error occurs in replication, the chunk is not removed from the volume locally https://github.com/seaweedfs/seaweedfs/pull/2740/files **System Setup**  3.24  **Expected behavior** Data chunk that could not be uploaded to the volume is also deleted.",source-file | source-file | source-file | source-file,"[filer] Data chunk that could not be uploaded to replicas volume is also deleted. **Describe the bug** When uploading chunks to the volume server, an error occurs in replication, the chunk is not removed from the volume locally https://github.com/seaweedfs/seaweedfs/pull/2740/files **System Setup**  3.24  **Expected behavior** Data chunk that could not be uploaded to the volume is also deleted. source-file source-file source-file source-file",no-bug,0.8
3075,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3075,Records after ttl continue to be stored in the filer database,"Filer database: MySql fs.configure { ""locations"": [ { ""locationPrefix"": ""/buckets/s3-test_ttl_10m"", ""ttl"": ""10m"" } ] }  - Added file s3-test_ttl_10m/12345 via s3 - Volume deleted itself after 10+ minutes - Now when I try to get the file I get a 50x error and error in the filler logs:  failed to stream content /buckets/s3-test_ttl_10m/12345: volume 17 not found And the filer's database continues to store information about this file. So, is this functionality not working? Because the database will forever accumulate garbage",source-file | source-file | source-file | source-file | source-file | source-file,"Records after ttl continue to be stored in the filer database Filer database: MySql fs.configure { ""locations"": [ { ""locationPrefix"": ""/buckets/s3-test_ttl_10m"", ""ttl"": ""10m"" } ] }  - Added file s3-test_ttl_10m/12345 via s3 - Volume deleted itself after 10+ minutes - Now when I try to get the file I get a 50x error and error in the filler logs:  failed to stream content /buckets/s3-test_ttl_10m/12345: volume 17 not found And the filer's database continues to store information about this file. So, is this functionality not working? Because the database will forever accumulate garbage source-file source-file source-file source-file source-file source-file",no-bug,0.8
4195,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4195,Unable to balance volumes with s3 tiering in place,"**Describe the bug** Unable to fully balance my nodes:  error: copy volume 1122 from <Node A>:8080 to <Node B>:8080: rpc error: code = Unknown desc = failed to copy /mnt/Disk-4/360_1122.dat file: receiving /mnt/Disk-4/360_1122.dat: rpc error: code = Unknown desc = open /mnt/Disk-5/360_1122.dat: no such file or directory  this halts the balance process so i can't really balance at all Not always the same volume erroring, but is always one in my s3 tier **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". * master: `/usr/bin/weed master -ip=<ip> -peers=<master ips> -defaultReplication=100 -mdir=/var/lib/weed` * volulme: `weed volume -dataCenter=DFW -rack=DFWCLOUD -mserver=<master ips> -dir=<dirlist> -port=8080 -max=0` - OS version CentOS 7 - output of `weed version` `version 30GB 3.41 4d71af87f39324b0ff3136947f8e3c58868c3241 linux amd64` **Expected behavior** S3 volume info to seamlessly shuffle, or not balance at all. Not sure which really. **Other info** Affected volume info :  > volume.list -volumeId=1122 DataNode <Node A>:8080 hdd(volume:480/480 active:453 free:0 remote:18) Disk hdd(volume:480/480 active:453 free:0 remote:18) volume id:1122 size:7336 collection:""360"" file_count:1 read_only:true replica_placement:100 version:3 modified_at_second:1675099646 remote_storage_name:""s3.decom"" remote_storage_key:""7e22146b-5e9c-4045-9528-5fd579ea61bd"" DataNode <Node C>:8080 hdd(volume:79/165 active:79 free:86 remote:0) Disk hdd(volume:79/165 active:79 free:86 remote:0) volume id:1122 size:7336 collection:""360"" file_count:1 replica_placement:100 version:3 modified_at_second:1666739548 ",source-file | source-file,"Unable to balance volumes with s3 tiering in place **Describe the bug** Unable to fully balance my nodes:  error: copy volume 1122 from <Node A>:8080 to <Node B>:8080: rpc error: code = Unknown desc = failed to copy /mnt/Disk-4/360_1122.dat file: receiving /mnt/Disk-4/360_1122.dat: rpc error: code = Unknown desc = open /mnt/Disk-5/360_1122.dat: no such file or directory  this halts the balance process so i can't really balance at all Not always the same volume erroring, but is always one in my s3 tier **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". * master: `/usr/bin/weed master -ip=<ip> -peers=<master ips> -defaultReplication=100 -mdir=/var/lib/weed` * volulme: `weed volume -dataCenter=DFW -rack=DFWCLOUD -mserver=<master ips> -dir=<dirlist> -port=8080 -max=0` - OS version CentOS 7 - output of `weed version` `version 30GB 3.41 4d71af87f39324b0ff3136947f8e3c58868c3241 linux amd64` **Expected behavior** S3 volume info to seamlessly shuffle, or not balance at all. Not sure which really. **Other info** Affected volume info :  > volume.list -volumeId=1122 DataNode <Node A>:8080 hdd(volume:480/480 active:453 free:0 remote:18) Disk hdd(volume:480/480 active:453 free:0 remote:18) volume id:1122 size:7336 collection:""360"" file_count:1 read_only:true replica_placement:100 version:3 modified_at_second:1675099646 remote_storage_name:""s3.decom"" remote_storage_key:""7e22146b-5e9c-4045-9528-5fd579ea61bd"" DataNode <Node C>:8080 hdd(volume:79/165 active:79 free:86 remote:0) Disk hdd(volume:79/165 active:79 free:86 remote:0) volume id:1122 size:7336 collection:""360"" file_count:1 replica_placement:100 version:3 modified_at_second:1666739548  source-file source-file",no-bug,0.9
4967,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4967,webdav bug creates directories in wrong folder,"**Describe the bug** When using `weed webdav -filer.path` for a non `/` path, folders get created on the `/` of the filer instance the `weed webdav` is connected to **System Setup** weed 3.58 on seaweedfs docker container, arguments used for webdav:  -logtostderr webdav -collection=arman -replication=010 -port=${NOMAD_PORT_webdav} -filer=seaweedfs-filer-http.nomad:8888.18888 -filer.path=/buckets/arman -cacheDir=/alloc/data/ -cacheCapacityMB=1024  on seaweedfs docker container, arguments used for filer:  -logtostderr filer -ip=${NOMAD_IP_http} -ip.bind=0.0.0.0 -master=seaweedfs-master-http.nomad:${var.master_port_http}.${var.master_port_grpc} -port=${NOMAD_PORT_http} -port.grpc=${NOMAD_PORT_grpc} -metricsPort=${NOMAD_PORT_metrics} -webdav -webdav.collection= -webdav.replication=020 -webdav.port=${NOMAD_PORT_webdav}  (so as you can see I am running a normal webdav instance with filer, and I am trying to set up a new one on a different container that points to a different path) **Expected behavior** When creating a folder in `weed webdav -filer.path=/buckets/arman` directory gets created under `/buckets/arman` in filer (for the example above). **Actual Behaviour** It gets created under the top-level `/` instead",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"webdav bug creates directories in wrong folder **Describe the bug** When using `weed webdav -filer.path` for a non `/` path, folders get created on the `/` of the filer instance the `weed webdav` is connected to **System Setup** weed 3.58 on seaweedfs docker container, arguments used for webdav:  -logtostderr webdav -collection=arman -replication=010 -port=${NOMAD_PORT_webdav} -filer=seaweedfs-filer-http.nomad:8888.18888 -filer.path=/buckets/arman -cacheDir=/alloc/data/ -cacheCapacityMB=1024  on seaweedfs docker container, arguments used for filer:  -logtostderr filer -ip=${NOMAD_IP_http} -ip.bind=0.0.0.0 -master=seaweedfs-master-http.nomad:${var.master_port_http}.${var.master_port_grpc} -port=${NOMAD_PORT_http} -port.grpc=${NOMAD_PORT_grpc} -metricsPort=${NOMAD_PORT_metrics} -webdav -webdav.collection= -webdav.replication=020 -webdav.port=${NOMAD_PORT_webdav}  (so as you can see I am running a normal webdav instance with filer, and I am trying to set up a new one on a different container that points to a different path) **Expected behavior** When creating a folder in `weed webdav -filer.path=/buckets/arman` directory gets created under `/buckets/arman` in filer (for the example above). **Actual Behaviour** It gets created under the top-level `/` instead source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.9
6746,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6746,S3 Feature: please add s3.idleTimeout command line parameter,"Some clients connect to our S3 server with periodic checks (list bucket requests) every 10 seconds. If the S3 server also uses an idle timeout of 10 seconds (as it is currently hardcoded), unwanted connection losses or unnecessary reconnections occur. Therefore, we would like to make the S3 server's idle timeout configurable (similar to the volume timeout) by adding a new parameter: s3.idleTimeout.",source-file | source-file | source-file,"S3 Feature: please add s3.idleTimeout command line parameter Some clients connect to our S3 server with periodic checks (list bucket requests) every 10 seconds. If the S3 server also uses an idle timeout of 10 seconds (as it is currently hardcoded), unwanted connection losses or unnecessary reconnections occur. Therefore, we would like to make the S3 server's idle timeout configurable (similar to the volume timeout) by adding a new parameter: s3.idleTimeout. source-file source-file source-file",no-bug,0.9
4467,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4467,Master assigns write requests to unavailable volumes,"**Describe the bug** We performed reliability test for SeaweedFS in such a manner: - We wrote files through Filer in a loop - Sometimes we restarted one of Volume Servers (by random) to check how it will work, how many time will take recovery process depending on data size stored in SeaweedFS, how write process will work during partial outage (outage one of Volume Servers), etc. And during this simple test sometimes we observed such a problem: Filer reports that it cannot save the file with one of the following errors:  {""error"":""unmarshalled error http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612: failed to write to replicas for volume 16498: [seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444]: upload 489.part 4194304 bytes to http://seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612?ts=1683812487\u0026ttl=\u0026type=replicate: Post \""http://seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612?ts=1683812487\u0026ttl=\u0026type=replicate\"": dial tcp 10.183.0.39:8444: connect: connection refused""}  or  {""error"":""upload 486.part 4194304 bytes to http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/5122,1740bcaa7be3be: Post \""http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/5122,1740bcaa7be3be\"": dial tcp 10.161.3.122:8444: connect: connection refused""}  So, on a first sight it looks quite obvious, we shutdown one of Volume Servers, and Filer cannot write to it (we see `connection refused`). The question is: **_why_** Master assigns volumes for write, if they should be unwritable? Deeper investigation into the issue showed that it could be some issue of synchronization between threads on Master's side. This is a piece of SeaweedFS Volume Server log which was shutdown:  I0511 13:40:18.303550 signal_handling.go:48 exec interrupt hook func name:github.com/seaweedfs/seaweedfs/weed/command.VolumeServerOptions.startVolumeServer.func1 I0511 13:40:18.303585 volume_server.go:139 Stopping volume server volume server has been killed I0511 13:40:18.303671 volume_grpc_client_to_master.go:258 volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 stops and deletes all volumes I0511 13:40:19.587873 volume.go:280 stop send heartbeat and wait 10 seconds until shutdown  I0511 13:40:19.587922 store.go:166 In dir /data0 adds volume:16498 collection:test replicaPlacement:001 ttl: I0511 13:40:19.587969 volume_info.go:20 maybeLoadVolumeInfo checks /data0/test_16498.vif I0511 13:40:19.588117 volume_loading.go:121 open to write file /data0/test_16498.idx I0511 13:40:19.588154 volume_loading.go:142 loading memory index /data0/test_16498.idx to memory I0511 13:40:19.588208 needle_map_memory.go:54 max file key: 0 for file: /data0/test_16498.idx I0511 13:40:19.588721 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.588734 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.588750 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.606846 common.go:106 error writing JSON status /status 200: write tcp 10.183.0.38:8444->10.183.0.1:46920: write: connection reset by peer I0511 13:40:19.606865 common.go:107 JSON content: map[DiskStatuses:[dir:""/data0"" all:98953909501952 used:9914417262592 free:89039492239360 percent_free:89.980774 percent_used:10.019227] <omitted> I0511 13:40:19.731598 disk_location.go:440 dir /data0 disk free 89.98% >= required 1.00% I0511 13:40:19.916394 store.go:170 add volume 16498 I0511 13:40:19.916412 volume_grpc_admin.go:60 assign volume volume_id:16498 collection:""test"" replication:""001"" I0511 13:40:20.074794 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.074812 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.074826 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798244 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798261 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798275 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:29.588357 volume.go:304 graceful stop cluster http server  I0511 13:40:29.588947 volume.go:309 graceful stop gRPC  I0511 13:40:29.589452 volume_server.go:149 Shutting down volume server I0511 13:40:29.695784 volume_server.go:151 Shut down successfully!  Point to take a look is assignment of new volume (id=16498) on this Volume Server after its termination. And piece of log from Master:  I0511 13:40:18.304201 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 public_url:""seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444"" has_no_volumes:true I0511 13:40:18.446855 cluster_commands.go:32 max volume id 16497 ==> 16498 I0511 13:40:18.464245 volume_growth.go:244 Created Volume 16498 on topo:DefaultDataCenter:DefaultRack:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.464308 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 new_volumes:{id:16498 collection:""test"" replica_placement:1 version:3} I0511 13:40:18.464338 volume_layout.go:223 volume 16498 does not have enough copies I0511 13:40:18.464344 volume_layout.go:228 volume 16498 remove from writable I0511 13:40:18.464453 masterclient.go:277 .master: seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:18.464460 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter:DefaultDataCenter GrpcPort:0} W0511 13:40:18.469625 master_grpc_server.go:100 SendHeartbeat.Recv server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 : rpc error: code = Canceled desc = context canceled I0511 13:40:18.469648 node.go:237 topo:DefaultDataCenter:DefaultRack removes seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.469655 master_grpc_server.go:87 unregister disconnected volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.469659 master_grpc_server.go:58 remove volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444, online volume server: map[seaweedfs-test-volume-0.seaweedfs-test-volume-peer.seaweedfs-test:8444:[b81f6a9c-e4c1-4702-88d5-51974f4ca3d6] seaweedfs-test-volume-1.seaweedfs-test-volume-peer.seaweedfs-test:8444:[58a7e74e-84e2-48df-b52b-dc9555afb548] seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444:[ff43c257-c736-4b6b-a930-db16c409c12b]] I0511 13:40:18.527309 masterclient.go:292 updateVidMap(DefaultDataCenter) .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 volume add: 0, del: 8263, add ec: 0 del ec: 0 I0511 13:40:19.771416 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 public_url:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444"" max_file_key:5192448 volumes:{id:10324 size:1128282400 <omitted> I0511 13:40:19.916729 volume_growth.go:244 Created Volume 16498 on seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.916752 volume_layout.go:223 volume 16498 does not have enough copies I0511 13:40:19.916756 volume_layout.go:228 volume 16498 remove from writable I0511 13:40:19.916761 volume_growth.go:257 Registered Volume 16498 on topo:DefaultDataCenter:DefaultRack:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.916771 volume_layout.go:393 Volume 16498 becomes writable I0511 13:40:19.916776 volume_growth.go:257 Registered Volume 16498 on seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.919012 cluster_commands.go:32 max volume id 16498 ==> 16499 I0511 13:40:19.957609 masterclient.go:277 .master: seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:19.957611 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter:DefaultDataCenter GrpcPort:0} I0511 13:40:19.957620 masterclient.go:277 .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:19.957622 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter: GrpcPort:0} I0511 13:40:19.957626 masterclient.go:292 updateVidMap() .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 volume add: 1, del: 0, add ec: 0 del ec: 0  There also were a lot of messages like these:  I0511 13:40:18.329755 topology.go:252 removing volume info: Id:2458, Size:1329612128, ReplicaPlacement:001, Collection:test, Version:3, FileCount:317, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.431844 master_grpc_server.go:203 master see deleted volume 2458 from seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444  But there is no such message for Volume 16498, so it is writeable from Master's perspective (but in fact it doesn't), and Filer gets assignments for write requests on this volume. **System Setup** We have SeaweedFS running on Kubernetes via SeaweedFS Operator. There are 3 Masters, 4 Volume Servers, 4 Filers (with Scylla as its backend) - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"": - Master:  weed -v 4 -logtostderr=true master -volumeSizeLimitMB=1024 -defaultReplication=001 -ip=$(POD_NAME).seaweedfs-test-master-peer.seaweedfs-test -peers=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -metricsPort=9999  - Volume Server:  weed -v 4 -logtostderr=true volume -port=8444 -max=0 -ip=$(POD_NAME).seaweedfs-test-volume-peer.seaweedfs-test -metricsPort=9999 -mserver=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -dir=/data0  - Filer:  weed -v 4 -logtostderr=true filer -port=8888 -ip=$(POD_NAME).seaweedfs-test-filer-peer.seaweedfs-test -master=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -metricsPort=9999 -s3  - OS version: Fedora CoreOS 33.20210426.3.0 - output of `weed version`: `version 8000GB 3.43 673214574 linux amd64` - if using filer, show the content of `filer.toml`:  [leveldb2] enabled = false [etcd] enabled = false servers = ""seaweed-etcd.seaweedfs-test:2379"" timeout = ""3s"" [cassandra] enabled = true keyspace=""seaweedfs"" hosts=[ ""seaweed-scylla-client.seaweedfs-test:9042"", ] superLargeDirectories = [ ]  **Expected behavior** We expect unwritable (de facto) volumes will not be assigned for write requests.",source-file | source-file | source-file,"Master assigns write requests to unavailable volumes **Describe the bug** We performed reliability test for SeaweedFS in such a manner: - We wrote files through Filer in a loop - Sometimes we restarted one of Volume Servers (by random) to check how it will work, how many time will take recovery process depending on data size stored in SeaweedFS, how write process will work during partial outage (outage one of Volume Servers), etc. And during this simple test sometimes we observed such a problem: Filer reports that it cannot save the file with one of the following errors:  {""error"":""unmarshalled error http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612: failed to write to replicas for volume 16498: [seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444]: upload 489.part 4194304 bytes to http://seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612?ts=1683812487\u0026ttl=\u0026type=replicate: Post \""http://seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612?ts=1683812487\u0026ttl=\u0026type=replicate\"": dial tcp 10.183.0.39:8444: connect: connection refused""}  or  {""error"":""upload 486.part 4194304 bytes to http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/5122,1740bcaa7be3be: Post \""http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/5122,1740bcaa7be3be\"": dial tcp 10.161.3.122:8444: connect: connection refused""}  So, on a first sight it looks quite obvious, we shutdown one of Volume Servers, and Filer cannot write to it (we see `connection refused`). The question is: **_why_** Master assigns volumes for write, if they should be unwritable? Deeper investigation into the issue showed that it could be some issue of synchronization between threads on Master's side. This is a piece of SeaweedFS Volume Server log which was shutdown:  I0511 13:40:18.303550 signal_handling.go:48 exec interrupt hook func name:github.com/seaweedfs/seaweedfs/weed/command.VolumeServerOptions.startVolumeServer.func1 I0511 13:40:18.303585 volume_server.go:139 Stopping volume server volume server has been killed I0511 13:40:18.303671 volume_grpc_client_to_master.go:258 volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 stops and deletes all volumes I0511 13:40:19.587873 volume.go:280 stop send heartbeat and wait 10 seconds until shutdown  I0511 13:40:19.587922 store.go:166 In dir /data0 adds volume:16498 collection:test replicaPlacement:001 ttl: I0511 13:40:19.587969 volume_info.go:20 maybeLoadVolumeInfo checks /data0/test_16498.vif I0511 13:40:19.588117 volume_loading.go:121 open to write file /data0/test_16498.idx I0511 13:40:19.588154 volume_loading.go:142 loading memory index /data0/test_16498.idx to memory I0511 13:40:19.588208 needle_map_memory.go:54 max file key: 0 for file: /data0/test_16498.idx I0511 13:40:19.588721 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.588734 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.588750 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.606846 common.go:106 error writing JSON status /status 200: write tcp 10.183.0.38:8444->10.183.0.1:46920: write: connection reset by peer I0511 13:40:19.606865 common.go:107 JSON content: map[DiskStatuses:[dir:""/data0"" all:98953909501952 used:9914417262592 free:89039492239360 percent_free:89.980774 percent_used:10.019227] <omitted> I0511 13:40:19.731598 disk_location.go:440 dir /data0 disk free 89.98% >= required 1.00% I0511 13:40:19.916394 store.go:170 add volume 16498 I0511 13:40:19.916412 volume_grpc_admin.go:60 assign volume volume_id:16498 collection:""test"" replication:""001"" I0511 13:40:20.074794 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.074812 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.074826 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798244 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798261 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798275 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:29.588357 volume.go:304 graceful stop cluster http server  I0511 13:40:29.588947 volume.go:309 graceful stop gRPC  I0511 13:40:29.589452 volume_server.go:149 Shutting down volume server I0511 13:40:29.695784 volume_server.go:151 Shut down successfully!  Point to take a look is assignment of new volume (id=16498) on this Volume Server after its termination. And piece of log from Master:  I0511 13:40:18.304201 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 public_url:""seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444"" has_no_volumes:true I0511 13:40:18.446855 cluster_commands.go:32 max volume id 16497 ==> 16498 I0511 13:40:18.464245 volume_growth.go:244 Created Volume 16498 on topo:DefaultDataCenter:DefaultRack:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.464308 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 new_volumes:{id:16498 collection:""test"" replica_placement:1 version:3} I0511 13:40:18.464338 volume_layout.go:223 volume 16498 does not have enough copies I0511 13:40:18.464344 volume_layout.go:228 volume 16498 remove from writable I0511 13:40:18.464453 masterclient.go:277 .master: seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:18.464460 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter:DefaultDataCenter GrpcPort:0} W0511 13:40:18.469625 master_grpc_server.go:100 SendHeartbeat.Recv server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 : rpc error: code = Canceled desc = context canceled I0511 13:40:18.469648 node.go:237 topo:DefaultDataCenter:DefaultRack removes seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.469655 master_grpc_server.go:87 unregister disconnected volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.469659 master_grpc_server.go:58 remove volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444, online volume server: map[seaweedfs-test-volume-0.seaweedfs-test-volume-peer.seaweedfs-test:8444:[b81f6a9c-e4c1-4702-88d5-51974f4ca3d6] seaweedfs-test-volume-1.seaweedfs-test-volume-peer.seaweedfs-test:8444:[58a7e74e-84e2-48df-b52b-dc9555afb548] seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444:[ff43c257-c736-4b6b-a930-db16c409c12b]] I0511 13:40:18.527309 masterclient.go:292 updateVidMap(DefaultDataCenter) .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 volume add: 0, del: 8263, add ec: 0 del ec: 0 I0511 13:40:19.771416 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 public_url:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444"" max_file_key:5192448 volumes:{id:10324 size:1128282400 <omitted> I0511 13:40:19.916729 volume_growth.go:244 Created Volume 16498 on seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.916752 volume_layout.go:223 volume 16498 does not have enough copies I0511 13:40:19.916756 volume_layout.go:228 volume 16498 remove from writable I0511 13:40:19.916761 volume_growth.go:257 Registered Volume 16498 on topo:DefaultDataCenter:DefaultRack:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.916771 volume_layout.go:393 Volume 16498 becomes writable I0511 13:40:19.916776 volume_growth.go:257 Registered Volume 16498 on seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.919012 cluster_commands.go:32 max volume id 16498 ==> 16499 I0511 13:40:19.957609 masterclient.go:277 .master: seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:19.957611 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter:DefaultDataCenter GrpcPort:0} I0511 13:40:19.957620 masterclient.go:277 .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:19.957622 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter: GrpcPort:0} I0511 13:40:19.957626 masterclient.go:292 updateVidMap() .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 volume add: 1, del: 0, add ec: 0 del ec: 0  There also were a lot of messages like these:  I0511 13:40:18.329755 topology.go:252 removing volume info: Id:2458, Size:1329612128, ReplicaPlacement:001, Collection:test, Version:3, FileCount:317, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.431844 master_grpc_server.go:203 master see deleted volume 2458 from seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444  But there is no such message for Volume 16498, so it is writeable from Master's perspective (but in fact it doesn't), and Filer gets assignments for write requests on this volume. **System Setup** We have SeaweedFS running on Kubernetes via SeaweedFS Operator. There are 3 Masters, 4 Volume Servers, 4 Filers (with Scylla as its backend) - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"": - Master:  weed -v 4 -logtostderr=true master -volumeSizeLimitMB=1024 -defaultReplication=001 -ip=$(POD_NAME).seaweedfs-test-master-peer.seaweedfs-test -peers=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -metricsPort=9999  - Volume Server:  weed -v 4 -logtostderr=true volume -port=8444 -max=0 -ip=$(POD_NAME).seaweedfs-test-volume-peer.seaweedfs-test -metricsPort=9999 -mserver=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -dir=/data0  - Filer:  weed -v 4 -logtostderr=true filer -port=8888 -ip=$(POD_NAME).seaweedfs-test-filer-peer.seaweedfs-test -master=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -metricsPort=9999 -s3  - OS version: Fedora CoreOS 33.20210426.3.0 - output of `weed version`: `version 8000GB 3.43 673214574 linux amd64` - if using filer, show the content of `filer.toml`:  [leveldb2] enabled = false [etcd] enabled = false servers = ""seaweed-etcd.seaweedfs-test:2379"" timeout = ""3s"" [cassandra] enabled = true keyspace=""seaweedfs"" hosts=[ ""seaweed-scylla-client.seaweedfs-test:9042"", ] superLargeDirectories = [ ]  **Expected behavior** We expect unwritable (de facto) volumes will not be assigned for write requests. source-file source-file source-file",bug,0.95
3178,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3178,"[filechunk_manifest.go:190] read http://xxxx failed, err: unexpected EOF","**Describe the bug** Bulk read chunk error  [filechunk_manifest.go:190] read http://fast-volume-3:8080/957,2a7a3800944f67d09f322d81 failed, err: unexpected EOF  volume server 3.09  2022/06/14 11:35:27 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:329)  **System Setup**  3.10 ",source-file,"[filechunk_manifest.go:190] read http://xxxx failed, err: unexpected EOF **Describe the bug** Bulk read chunk error  [filechunk_manifest.go:190] read http://fast-volume-3:8080/957,2a7a3800944f67d09f322d81 failed, err: unexpected EOF  volume server 3.09  2022/06/14 11:35:27 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:329)  **System Setup**  3.10  source-file",no-bug,0.8
72,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/72,what about this logo?,![image](http://img.ui.cn/data/file/2/9/7/180792.png) My girlfriend made it. Maybe it can be used as this project's logo if you like it?,source-file | source-file | source-file,what about this logo? ![image](http://img.ui.cn/data/file/2/9/7/180792.png) My girlfriend made it. Maybe it can be used as this project's logo if you like it? source-file source-file source-file,no-bug,0.95
1722,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1722,s3 gateway ListObjects does not support arbitrary prefix,"**Describe the bug** The S3 gateway of seaweedfs does not support listing objects with arbitrary prefix. **System Setup** - filer leveldb2 backend, seaweedfs master **Expected behavior** Calling `GET` on `http://seaweedfs_s3_gw/bucket/?prefix=arbitrary_prefix` should always return files whose path starts with `arbitrary_prefix`, no matter whether `arbitrary_prefix` is an actual directory or not. **Actual behavior** Calling `GET` on `http://seaweedfs_s3_gw/bucket/?prefix=arbitrary_prefix` returns every single object in the bucket regardless of their prefix if `arbitrary_prefix` is not a folder inside `bucket`. **Additional context** After a bit of digging around myself, it seems that this issue is actually two issues (both of which are about : 1. The `namePattern` parameter passed to `ListDirectoryEntries` in `weed/filer/filer_search.go` should contain a wildcard character `*` at the end of the prefix (i.e. `prefix*`, not `prefix`); this is what caused the list request to return every single file 2. ~~(After making the change above) the `ListDirectoryPrefixedEntries` (at least in the leveldb2 backend) does not seem to work properly (I cannot figure out why yet because I don't really understand the filer store design). In my case, it simply does not return any entry if the prefix should match more than one files. I think it is related to the latest commit that implements hash-prefix-based searching in leveldb / leveldb2.~~ I think https://github.com/chrislusf/seaweedfs/blob/master/weed/filer/leveldb2/leveldb2_store.go#L188 needs to be `continue` instead of `break` Some programs expect ListObjects to be able to list files with arbitrary prefix (such as `s3ql`) and will error if this does not work. Most other S3 implementations, including the official S3 service, support this correctly.",source-file | source-file | source-file,"s3 gateway ListObjects does not support arbitrary prefix **Describe the bug** The S3 gateway of seaweedfs does not support listing objects with arbitrary prefix. **System Setup** - filer leveldb2 backend, seaweedfs master **Expected behavior** Calling `GET` on `http://seaweedfs_s3_gw/bucket/?prefix=arbitrary_prefix` should always return files whose path starts with `arbitrary_prefix`, no matter whether `arbitrary_prefix` is an actual directory or not. **Actual behavior** Calling `GET` on `http://seaweedfs_s3_gw/bucket/?prefix=arbitrary_prefix` returns every single object in the bucket regardless of their prefix if `arbitrary_prefix` is not a folder inside `bucket`. **Additional context** After a bit of digging around myself, it seems that this issue is actually two issues (both of which are about : 1. The `namePattern` parameter passed to `ListDirectoryEntries` in `weed/filer/filer_search.go` should contain a wildcard character `*` at the end of the prefix (i.e. `prefix*`, not `prefix`); this is what caused the list request to return every single file 2. ~~(After making the change above) the `ListDirectoryPrefixedEntries` (at least in the leveldb2 backend) does not seem to work properly (I cannot figure out why yet because I don't really understand the filer store design). In my case, it simply does not return any entry if the prefix should match more than one files. I think it is related to the latest commit that implements hash-prefix-based searching in leveldb / leveldb2.~~ I think https://github.com/chrislusf/seaweedfs/blob/master/weed/filer/leveldb2/leveldb2_store.go#L188 needs to be `continue` instead of `break` Some programs expect ListObjects to be able to list files with arbitrary prefix (such as `s3ql`) and will error if this does not work. Most other S3 implementations, including the official S3 service, support this correctly. source-file source-file source-file",bug,0.95
3595,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3595,[filer] data race on GoCDKPubSub.topic,"https://github.com/seaweedfs/seaweedfs/issues/3507  ""Sep 4, 2022 @ 05:00:43.544"","" /go/pkg/mod/gocloud.dev@v0.26.0/pubsub/pubsub.go:237 +0x74"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:114 +0x352"" ""Sep 4, 2022 @ 05:00:43.544"",""Previous write at 0x00c001b4c0d8 by goroutine 4234712:"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:248 +0x15a4"" ""Sep 4, 2022 @ 05:00:43.544"",""Goroutine 6329068 (running) created at:"" ""Sep 4, 2022 @ 05:00:43.544"",""-"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub/gocdk_pub_sub.go:72 +0x472"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/pkg/mod/gocloud.dev/pubsub/rabbitpubsub@v0.26.0/rabbit.go:162 +0x41c"" ""Sep 4, 2022 @ 05:00:43.544"",""Goroutine 4234712 (finished) created at:"" ""Sep 4, 2022 @ 05:00:43.544"","""" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:203 +0x716"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub/gocdk_pub_sub.go:99 +0x1a4"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).saveMetaData()"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:308 +0x1b1"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).CreateEntry()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:2109 +0x4d"" ""Sep 4, 2022 @ 05:00:43.544"",""Read at 0x00c001b4c0d8 by goroutine 6329068:"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler()"" ""Sep 4, 2022 @ 05:00:43.544"","" <autogenerated>:1 +0x57"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:3102 +0x58"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer_notify.go:59 +0x5c1"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a"" ""Sep 4, 2022 @ 05:00:43.544"","""" ""Sep 4, 2022 @ 05:00:43.544"","" gocloud.dev/pubsub.newTopic()"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub/gocdk_pub_sub.go:71 +0x27e"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub/gocdk_pub_sub.go:63 +0x15e"" ""Sep 4, 2022 @ 05:00:43.544"",""WARNING: DATA RACE"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm()"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.(*Server).Serve.func3()"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.(*conn).serve()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub.(*GoCDKPubSub).doReconnect.func1()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:3102 +0x837"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub.(*GoCDKPubSub).doReconnect()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).NotifyUpdateEvent()"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.serverHandler.ServeHTTP()"" ""Sep 4, 2022 @ 05:00:43.544"","" gocloud.dev/pubsub/rabbitpubsub.OpenTopic()"" ""Sep 4, 2022 @ 05:00:43.544"","" gocloud.dev/pubsub.(*Topic).Send()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk()"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.HandlerFunc.ServeHTTP()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:2947 +0x641"" ""Sep 4, 2022 @ 05:00:43.544"",""-"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.(*Server).Serve()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub.(*GoCDKPubSub).SendMessage()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk()"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.(*ServeMux).ServeHTTP()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:1991 +0xbe4"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler.func3()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:2487 +0xc5"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/pkg/mod/gocloud.dev@v0.26.0/pubsub/pubsub.go:343 +0x1d8"" ""Sep 4, 2022 @ 05:00:43.544"",""-"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub.(*GoCDKPubSub).doReconnect.func1()"" ",source-file,"[filer] data race on GoCDKPubSub.topic https://github.com/seaweedfs/seaweedfs/issues/3507  ""Sep 4, 2022 @ 05:00:43.544"","" /go/pkg/mod/gocloud.dev@v0.26.0/pubsub/pubsub.go:237 +0x74"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:114 +0x352"" ""Sep 4, 2022 @ 05:00:43.544"",""Previous write at 0x00c001b4c0d8 by goroutine 4234712:"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:248 +0x15a4"" ""Sep 4, 2022 @ 05:00:43.544"",""Goroutine 6329068 (running) created at:"" ""Sep 4, 2022 @ 05:00:43.544"",""-"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub/gocdk_pub_sub.go:72 +0x472"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/pkg/mod/gocloud.dev/pubsub/rabbitpubsub@v0.26.0/rabbit.go:162 +0x41c"" ""Sep 4, 2022 @ 05:00:43.544"",""Goroutine 4234712 (finished) created at:"" ""Sep 4, 2022 @ 05:00:43.544"","""" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:203 +0x716"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub/gocdk_pub_sub.go:99 +0x1a4"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).saveMetaData()"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:308 +0x1b1"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).CreateEntry()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:2109 +0x4d"" ""Sep 4, 2022 @ 05:00:43.544"",""Read at 0x00c001b4c0d8 by goroutine 6329068:"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler()"" ""Sep 4, 2022 @ 05:00:43.544"","" <autogenerated>:1 +0x57"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:3102 +0x58"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer_notify.go:59 +0x5c1"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a"" ""Sep 4, 2022 @ 05:00:43.544"","""" ""Sep 4, 2022 @ 05:00:43.544"","" gocloud.dev/pubsub.newTopic()"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub/gocdk_pub_sub.go:71 +0x27e"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub/gocdk_pub_sub.go:63 +0x15e"" ""Sep 4, 2022 @ 05:00:43.544"",""WARNING: DATA RACE"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm()"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.(*Server).Serve.func3()"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.(*conn).serve()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub.(*GoCDKPubSub).doReconnect.func1()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:3102 +0x837"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub.(*GoCDKPubSub).doReconnect()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).NotifyUpdateEvent()"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.serverHandler.ServeHTTP()"" ""Sep 4, 2022 @ 05:00:43.544"","" gocloud.dev/pubsub/rabbitpubsub.OpenTopic()"" ""Sep 4, 2022 @ 05:00:43.544"","" gocloud.dev/pubsub.(*Topic).Send()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk()"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.HandlerFunc.ServeHTTP()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:2947 +0x641"" ""Sep 4, 2022 @ 05:00:43.544"",""-"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.(*Server).Serve()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub.(*GoCDKPubSub).SendMessage()"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk()"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168"" ""Sep 4, 2022 @ 05:00:43.544"","" net/http.(*ServeMux).ServeHTTP()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:1991 +0xbe4"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler.func3()"" ""Sep 4, 2022 @ 05:00:43.544"","" /usr/local/go/src/net/http/server.go:2487 +0xc5"" ""Sep 4, 2022 @ 05:00:43.544"","" /go/pkg/mod/gocloud.dev@v0.26.0/pubsub/pubsub.go:343 +0x1d8"" ""Sep 4, 2022 @ 05:00:43.544"",""-"" ""Sep 4, 2022 @ 05:00:43.544"","" github.com/seaweedfs/seaweedfs/weed/notification/gocdk_pub_sub.(*GoCDKPubSub).doReconnect.func1()""  source-file",no-bug,0.9
1160,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1160,Deleting a non-existing file returns a 500 internal server error,"I'm testing a seaweedfs setup with a cassandra filer. When I try to delete a non-existing resource, the filer API returns a 500 error code. I would expect a 404.",source-file,"Deleting a non-existing file returns a 500 internal server error I'm testing a seaweedfs setup with a cassandra filer. When I try to delete a non-existing resource, the filer API returns a 500 error code. I would expect a 404. source-file",bug,0.95
1645,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1645,Very slow read speeds when running impala queries against seaweedfs,"**Describe the bug** Very slow read speeds when running a query against seaweed files via impala **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  weed -logdir /var/log/seaweedfs/filer filer -ip 127.0.0.1 -port 8888 -master 10.0.0.1:9333 -collection COL1 -maxMB 128 -defaultReplicaPlacement 001 weed -logdir /var/log/seaweedfs/master master -defaultReplication 001 -ip 10.0.0.1 -port 9333 -peers 10.0.0.1:9333 -mdir /var/lib/seaweedfs/master -volumeSizeLimitMB 64000 -volumePreallocate weed -logdir /var/log/seaweedfs/volume volume -max=2 -dataCenter DC1 -rack rack1 -dir=/data/d2/seaweedfs -mserver 10.0.0.1:9333 -port 5200  - OS version `Ubuntu 16.04.6 LTS` - output of `weed version` `version 8000GB 2.13 0e99531 linux amd64` - seaweed hadoop client `seaweedfs-hadoop2-client-1.5.6.jar` - seaweed hadoop client properties  <property> <name>fs.seaweedfs.impl</name> <value>seaweed.hdfs.SeaweedFileSystem</value> </property> <property> <name>fs.AbstractFileSystem.seaweedfs.impl</name> <value>seaweed.hdfs.SeaweedAbstractFileSystem</value> </property> <property> <name>fs.seaweed.buffer.size</name> <value>134217728</value> </property>  - if using filer, show the content of `filer.toml`  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml  # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false # directories under this folder will be automatically creating a separate bucket buckets_folder = ""/buckets"" buckets_fsync = [ # a list of buckets with all write requests fsync=true ""important_bucket"", ""should_always_fsync"", ]  # The following are filer store options  [redis2] enabled = true address = ""10.0.0.1:6390"" password = ""SOMEPASSWORD"" database = 0  **Additional context** When running a query via impala, the query evetually completes but takes an extremely long time compared to a query ran against data that exists on hdfs. Im seeing the following error on the impala daemons: `readDirect: FSDataInputStream#read error: UnsupportedOperationException: Byte-buffer read unsupported by input streamjava.lang.UnsupportedOperationException: Byte-buffer read unsupported by input stream` This error scrolls over and over until the query completes. Im able to cat out files, read and write files fine via hdfs but when queries are ran against the data it takes an extremely long time to complete.",config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Very slow read speeds when running impala queries against seaweedfs **Describe the bug** Very slow read speeds when running a query against seaweed files via impala **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  weed -logdir /var/log/seaweedfs/filer filer -ip 127.0.0.1 -port 8888 -master 10.0.0.1:9333 -collection COL1 -maxMB 128 -defaultReplicaPlacement 001 weed -logdir /var/log/seaweedfs/master master -defaultReplication 001 -ip 10.0.0.1 -port 9333 -peers 10.0.0.1:9333 -mdir /var/lib/seaweedfs/master -volumeSizeLimitMB 64000 -volumePreallocate weed -logdir /var/log/seaweedfs/volume volume -max=2 -dataCenter DC1 -rack rack1 -dir=/data/d2/seaweedfs -mserver 10.0.0.1:9333 -port 5200  - OS version `Ubuntu 16.04.6 LTS` - output of `weed version` `version 8000GB 2.13 0e99531 linux amd64` - seaweed hadoop client `seaweedfs-hadoop2-client-1.5.6.jar` - seaweed hadoop client properties  <property> <name>fs.seaweedfs.impl</name> <value>seaweed.hdfs.SeaweedFileSystem</value> </property> <property> <name>fs.AbstractFileSystem.seaweedfs.impl</name> <value>seaweed.hdfs.SeaweedAbstractFileSystem</value> </property> <property> <name>fs.seaweed.buffer.size</name> <value>134217728</value> </property>  - if using filer, show the content of `filer.toml`  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml  # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false # directories under this folder will be automatically creating a separate bucket buckets_folder = ""/buckets"" buckets_fsync = [ # a list of buckets with all write requests fsync=true ""important_bucket"", ""should_always_fsync"", ]  # The following are filer store options  [redis2] enabled = true address = ""10.0.0.1:6390"" password = ""SOMEPASSWORD"" database = 0  **Additional context** When running a query via impala, the query evetually completes but takes an extremely long time compared to a query ran against data that exists on hdfs. Im seeing the following error on the impala daemons: `readDirect: FSDataInputStream#read error: UnsupportedOperationException: Byte-buffer read unsupported by input streamjava.lang.UnsupportedOperationException: Byte-buffer read unsupported by input stream` This error scrolls over and over until the query completes. Im able to cat out files, read and write files fine via hdfs but when queries are ran against the data it takes an extremely long time to complete. config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
59,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/59,Reading Multi part error,"Getting tons of these errors, unable to upload. Any ideas? Restarted the volume and things are working now. `I0115 15:02:57 00001 needle.go:65] Reading Multi part [ERROR] EOF` (Edit: restarting didn't fix things)",source-file,"Reading Multi part error Getting tons of these errors, unable to upload. Any ideas? Restarted the volume and things are working now. `I0115 15:02:57 00001 needle.go:65] Reading Multi part [ERROR] EOF` (Edit: restarting didn't fix things) source-file",no-bug,0.7
3384,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3384,Support Locking via FUSE Mount,"**Describe the bug** When running the `linuxserver/plex:latest` [Docker image](https://hub.docker.com/r/linuxserver/plex) with its `/config` folder mapped to a collection mounted via FUSE (weed mount), the Plex internal SQLite3 DB gets corrupted constantly **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version Ubuntu 22.04 arm64 - output of `weed version` version 30GB 3.18 475185fb linux arm64 - if using filer, show the content of `filer.toml`  [leveldb3] enabled = true dir = ""/filer""  **Expected behavior** This used to work well in the past but now it renders Plex unusable right after it starts. According to the Plex Docker documentation `Note: the underlying filesystem needs to support file locking. This is known to not be default enabled on remote filesystems like NFS, SMB, and many many others. The 9PFS filesystem used by FreeNAS Corral is known to work but the vast majority will result in database corruption. Use a network share at your own risk.` Expected behaviour is that Plex can use a seaweedfs fuse mount to store its `/config` folder where it stores all its configs and internal SQLite3 DB. **Additional context** I have a full cluster running on top of Nomad using the `seaweedfs-csi-driver` and all applications are working just fine, except for Plex. A way to reproduce this is just by mounting a seaweedfs collection via `weed mount` and when running the docker container passing the `-v /local/path/of/the/mounted/volume:/config`. Plex will output DB crashes on its stderr logging output right after trying to startup.",source-file,"Support Locking via FUSE Mount **Describe the bug** When running the `linuxserver/plex:latest` [Docker image](https://hub.docker.com/r/linuxserver/plex) with its `/config` folder mapped to a collection mounted via FUSE (weed mount), the Plex internal SQLite3 DB gets corrupted constantly **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version Ubuntu 22.04 arm64 - output of `weed version` version 30GB 3.18 475185fb linux arm64 - if using filer, show the content of `filer.toml`  [leveldb3] enabled = true dir = ""/filer""  **Expected behavior** This used to work well in the past but now it renders Plex unusable right after it starts. According to the Plex Docker documentation `Note: the underlying filesystem needs to support file locking. This is known to not be default enabled on remote filesystems like NFS, SMB, and many many others. The 9PFS filesystem used by FreeNAS Corral is known to work but the vast majority will result in database corruption. Use a network share at your own risk.` Expected behaviour is that Plex can use a seaweedfs fuse mount to store its `/config` folder where it stores all its configs and internal SQLite3 DB. **Additional context** I have a full cluster running on top of Nomad using the `seaweedfs-csi-driver` and all applications are working just fine, except for Plex. A way to reproduce this is just by mounting a seaweedfs collection via `weed mount` and when running the docker container passing the `-v /local/path/of/the/mounted/volume:/config`. Plex will output DB crashes on its stderr logging output right after trying to startup. source-file",no-bug,0.9
5231,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5231,failed to specify '-dataCenter' when upload files,"Environments: - system: Ubuntu 22.04 amd64 - weed: version 30GB 3.61 linux amd64 I did `weed upload -master localhost:9333 -dataCenter dc index.py`, then I got  assign failure 1: Example: weed upload -master=localhost:9333 file1 [file2 file3] weed upload -master=localhost:9333 -dir=one_directory -include=*.pdf Default Usage: -collection string optional collection name -dataCenter string optional data center name -debug verbose debug information (omission)  But if I don't specify the dataCenter,  $ weed upload -master localhost:9333 index.py [{""fileName"":""index.py"",""url"":""myserverip:8080/8,0efe8ccccf"",""fid"":""8,0efe8ccccf"",""size"":3474}]  It worked correctly. I tried to replace the space to equal (-dataCenter=dc) but nothing different. Is this a bug?",source-file | source-file,"failed to specify '-dataCenter' when upload files Environments: - system: Ubuntu 22.04 amd64 - weed: version 30GB 3.61 linux amd64 I did `weed upload -master localhost:9333 -dataCenter dc index.py`, then I got  assign failure 1: Example: weed upload -master=localhost:9333 file1 [file2 file3] weed upload -master=localhost:9333 -dir=one_directory -include=*.pdf Default Usage: -collection string optional collection name -dataCenter string optional data center name -debug verbose debug information (omission)  But if I don't specify the dataCenter,  $ weed upload -master localhost:9333 index.py [{""fileName"":""index.py"",""url"":""myserverip:8080/8,0efe8ccccf"",""fid"":""8,0efe8ccccf"",""size"":3474}]  It worked correctly. I tried to replace the space to equal (-dataCenter=dc) but nothing different. Is this a bug? source-file source-file",no-bug,0.9
473,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/473,Master process crashed after 10 months smooth running,"@chrislusf Could you help me to find out the problem? ENV: production version: 0.71.beta source tree: https://github.com/chrislusf/seaweedfs/tree/d0dbf6d2eafc0a8758427870a8536f2fe1b82cc6 start args:  nohup ./weed master -ip=""0.0.0.0"" -defaultReplication=""000"" -mdir=""./meta"" & nohup ./weed volume -max=9999 -mserver=""localhost:9333"" -dir=""./data/v1"" -port=5083 -ip=""x.x.x.x"" -dataCenter=""dc1"" -rack=""rack1"" &  **the weed server serv 1TB small files, and the master process crashed suddenly, but the volume works well.** crash logs:  I0322 17:36:49 18067 volume_layout.go:193] Volume 129 has 0 replica, less than required 1 I0322 17:36:49 18067 volume_layout.go:169] Volume 129 becomes unwritable panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0xa8 pc=0x8388fe] goroutine 12 [running]: panic(0xc7bb40, 0xc8200100f0) /opt/dev/go/src/runtime/panic.go:481 +0x3e6 github.com/chrislusf/seaweedfs/weed/topology.(*Topology).UnRegisterDataNode(0xc8201a02a0, 0xc8203b23c0) /opt/dev/gowork/src/github.com/chrislusf/seaweedfs/weed/topology/topology_event_handling.go:65 +0x4ae github.com/chrislusf/seaweedfs/weed/topology.(*Topology).StartRefreshWritableVolumes.func3(0xc8201a02a0) /opt/dev/gowork/src/github.com/chrislusf/seaweedfs/weed/topology/topology_event_handling.go:38 +0x3ac created by github.com/chrislusf/seaweedfs/weed/topology.(*Topology).StartRefreshWritableVolumes /opt/dev/gowork/src/github.com/chrislusf/seaweedfs/weed/topology/topology_event_handling.go:42 +0x91  related codes:  func (t *Topology) UnRegisterDataNode(dn *DataNode) { for _, v := range dn.GetVolumes() { glog.V(0).Infoln(""Removing Volume"", v.Id, ""from the dead volume server"", dn) vl := t.GetVolumeLayout(v.Collection, v.ReplicaPlacement, v.Ttl) vl.SetVolumeUnavailable(dn, v.Id) } dn.UpAdjustVolumeCountDelta(-dn.GetVolumeCount()) dn.UpAdjustActiveVolumeCountDelta(-dn.GetActiveVolumeCount()) dn.UpAdjustMaxVolumeCountDelta(-dn.GetMaxVolumeCount()) dn.Parent().UnlinkChildNode(dn.Id()) }  **It seems that the dn.Parent() is nil, and cased by my disk issue? or any reasons ?**",source-file,"Master process crashed after 10 months smooth running @chrislusf Could you help me to find out the problem? ENV: production version: 0.71.beta source tree: https://github.com/chrislusf/seaweedfs/tree/d0dbf6d2eafc0a8758427870a8536f2fe1b82cc6 start args:  nohup ./weed master -ip=""0.0.0.0"" -defaultReplication=""000"" -mdir=""./meta"" & nohup ./weed volume -max=9999 -mserver=""localhost:9333"" -dir=""./data/v1"" -port=5083 -ip=""x.x.x.x"" -dataCenter=""dc1"" -rack=""rack1"" &  **the weed server serv 1TB small files, and the master process crashed suddenly, but the volume works well.** crash logs:  I0322 17:36:49 18067 volume_layout.go:193] Volume 129 has 0 replica, less than required 1 I0322 17:36:49 18067 volume_layout.go:169] Volume 129 becomes unwritable panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0xa8 pc=0x8388fe] goroutine 12 [running]: panic(0xc7bb40, 0xc8200100f0) /opt/dev/go/src/runtime/panic.go:481 +0x3e6 github.com/chrislusf/seaweedfs/weed/topology.(*Topology).UnRegisterDataNode(0xc8201a02a0, 0xc8203b23c0) /opt/dev/gowork/src/github.com/chrislusf/seaweedfs/weed/topology/topology_event_handling.go:65 +0x4ae github.com/chrislusf/seaweedfs/weed/topology.(*Topology).StartRefreshWritableVolumes.func3(0xc8201a02a0) /opt/dev/gowork/src/github.com/chrislusf/seaweedfs/weed/topology/topology_event_handling.go:38 +0x3ac created by github.com/chrislusf/seaweedfs/weed/topology.(*Topology).StartRefreshWritableVolumes /opt/dev/gowork/src/github.com/chrislusf/seaweedfs/weed/topology/topology_event_handling.go:42 +0x91  related codes:  func (t *Topology) UnRegisterDataNode(dn *DataNode) { for _, v := range dn.GetVolumes() { glog.V(0).Infoln(""Removing Volume"", v.Id, ""from the dead volume server"", dn) vl := t.GetVolumeLayout(v.Collection, v.ReplicaPlacement, v.Ttl) vl.SetVolumeUnavailable(dn, v.Id) } dn.UpAdjustVolumeCountDelta(-dn.GetVolumeCount()) dn.UpAdjustActiveVolumeCountDelta(-dn.GetActiveVolumeCount()) dn.UpAdjustMaxVolumeCountDelta(-dn.GetMaxVolumeCount()) dn.Parent().UnlinkChildNode(dn.Id()) }  **It seems that the dn.Parent() is nil, and cased by my disk issue? or any reasons ?** source-file",no-bug,0.9
2492,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2492,"When i ""mkdir /dfs/buckets/newbucket"", remote s3 will create many ""newbucket-xxxx"" buckets.","## System setup Same as: #2465 ## Info: /fastdfs : Mount of ""Local Weed"" /dfs: Mount of ""Remote Weed"" ## Describe the bug When: > mkdir /fastdfs/buckets/newbucket/ (**On Local Server**) I got : > ll /dfs/buckets/ (**On Remote Server**) shell drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-1317 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-1521 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-2486 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-2595 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-2863 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-3108 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-3293 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-4312 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-4410 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-5927 drwxrwxrwx 1 root root 0 Dec 5 23:40 'newbucket- 633' drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-8048 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-8791 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-9973  ## Expected behavior When: > mkdir /fastdfs/buckets/newbucket/ (**On Local Server**) I want : > ll /dfs/buckets/ (**On Remote Server**) shell drwxr-xr-x 1 root root 0 Dec 5 23:40 newbucket   Some logs  I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-2595 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-3108 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-1317 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-4410 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-2863 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-9973 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket- 633 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-1521 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-3293 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-2486 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-8048 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-8791 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-5927 ",source-file,"When i ""mkdir /dfs/buckets/newbucket"", remote s3 will create many ""newbucket-xxxx"" buckets. ## System setup Same as: #2465 ## Info: /fastdfs : Mount of ""Local Weed"" /dfs: Mount of ""Remote Weed"" ## Describe the bug When: > mkdir /fastdfs/buckets/newbucket/ (**On Local Server**) I got : > ll /dfs/buckets/ (**On Remote Server**) shell drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-1317 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-1521 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-2486 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-2595 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-2863 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-3108 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-3293 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-4312 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-4410 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-5927 drwxrwxrwx 1 root root 0 Dec 5 23:40 'newbucket- 633' drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-8048 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-8791 drwxrwxrwx 1 root root 0 Dec 5 23:40 newbucket-9973  ## Expected behavior When: > mkdir /fastdfs/buckets/newbucket/ (**On Local Server**) I want : > ll /dfs/buckets/ (**On Remote Server**) shell drwxr-xr-x 1 root root 0 Dec 5 23:40 newbucket   Some logs  I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-2595 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-3108 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-1317 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-4410 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-2863 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-9973 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket- 633 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-1521 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-3293 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-2486 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-8048 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-8791 I1205 23:40:10 15824 filer_remote_gateway_buckets.go:97] create bucket newbucket-5927  source-file",no-bug,0.9
1980,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1980,Filer: Too many open files after update to 2.38,"**Describe the bug** After upgrading from 2.35 to 2.38 we experience full service degradation after several hours of work. I see lots of ESTABLISHED connections to filer and ""too many open files"" errors in filer's log.  tcp6 64937 0 192.168.65.42:8888 192.168.65.42:44366 ESTABLISHED 9150/weed tcp6 45708 0 192.168.65.42:8888 192.168.65.42:41398 ESTABLISHED 9150/weed tcp6 95248 0 192.168.65.42:8888 192.168.65.42:38762 ESTABLISHED 9150/weed tcp6 50516 0 192.168.65.42:8888 192.168.65.42:36320 ESTABLISHED 9150/weed tcp6 9399 0 192.168.65.42:8888 192.168.65.42:56408 ESTABLISHED 9150/weed tcp6 63103 0 192.168.65.42:8888 192.168.65.42:38124 ESTABLISHED 9150/weed tcp6 1927 0 192.168.65.42:8888 192.168.65.42:37842 ESTABLISHED 9150/weed tcp6 6561 0 192.168.65.42:8888 192.168.65.42:41580 ESTABLISHED 9150/weed tcp6 10021 0 192.168.65.42:8888 192.168.65.42:43408 ESTABLISHED 9150/weed tcp6 22988 0 192.168.65.42:8888 192.168.65.42:58074 ESTABLISHED 9150/weed tcp6 13524 0 192.168.65.42:8888 192.168.65.42:54530 ESTABLISHED 9150/weed tcp6 50901 0 192.168.65.42:8888 192.168.65.42:47330 ESTABLISHED 9150/weed tcp6 60016 0 192.168.65.42:8888 192.168.65.42:49604 ESTABLISHED 9150/weed tcp6 53926 0 192.168.65.42:8888 192.168.65.42:44792 ESTABLISHED 9150/weed tcp6 50842 0 192.168.65.42:8888 192.168.65.42:34476 ESTABLISHED 9150/weed tcp6 32611 0 192.168.65.42:8888 192.168.65.42:39410 ESTABLISHED 9150/weed  LimitNOFILE is set to 65535. I'm seeing literally thousands of open and non-closing sockets. I'm using filer as s3 gateway. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"":  weed filer -s3 -master=192.168.65.42:9333 -defaultReplicaPlacement=000 -s3.config=/etc/seaweedfs/config.json -s3.allowEmptyFolder -s3.port=9000  - OS version: Debian 10.9 - output of `weed version`: version 30GB 2.38 2327c07 linux amd64 - if using filer, show the content of `filer.toml`:  [leveldb3] # similar to leveldb2. # each bucket has its own meta store. enabled = true dir = ""/var/lib/weed/filer"" # directory to store level db files ",source-file,"Filer: Too many open files after update to 2.38 **Describe the bug** After upgrading from 2.35 to 2.38 we experience full service degradation after several hours of work. I see lots of ESTABLISHED connections to filer and ""too many open files"" errors in filer's log.  tcp6 64937 0 192.168.65.42:8888 192.168.65.42:44366 ESTABLISHED 9150/weed tcp6 45708 0 192.168.65.42:8888 192.168.65.42:41398 ESTABLISHED 9150/weed tcp6 95248 0 192.168.65.42:8888 192.168.65.42:38762 ESTABLISHED 9150/weed tcp6 50516 0 192.168.65.42:8888 192.168.65.42:36320 ESTABLISHED 9150/weed tcp6 9399 0 192.168.65.42:8888 192.168.65.42:56408 ESTABLISHED 9150/weed tcp6 63103 0 192.168.65.42:8888 192.168.65.42:38124 ESTABLISHED 9150/weed tcp6 1927 0 192.168.65.42:8888 192.168.65.42:37842 ESTABLISHED 9150/weed tcp6 6561 0 192.168.65.42:8888 192.168.65.42:41580 ESTABLISHED 9150/weed tcp6 10021 0 192.168.65.42:8888 192.168.65.42:43408 ESTABLISHED 9150/weed tcp6 22988 0 192.168.65.42:8888 192.168.65.42:58074 ESTABLISHED 9150/weed tcp6 13524 0 192.168.65.42:8888 192.168.65.42:54530 ESTABLISHED 9150/weed tcp6 50901 0 192.168.65.42:8888 192.168.65.42:47330 ESTABLISHED 9150/weed tcp6 60016 0 192.168.65.42:8888 192.168.65.42:49604 ESTABLISHED 9150/weed tcp6 53926 0 192.168.65.42:8888 192.168.65.42:44792 ESTABLISHED 9150/weed tcp6 50842 0 192.168.65.42:8888 192.168.65.42:34476 ESTABLISHED 9150/weed tcp6 32611 0 192.168.65.42:8888 192.168.65.42:39410 ESTABLISHED 9150/weed  LimitNOFILE is set to 65535. I'm seeing literally thousands of open and non-closing sockets. I'm using filer as s3 gateway. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"":  weed filer -s3 -master=192.168.65.42:9333 -defaultReplicaPlacement=000 -s3.config=/etc/seaweedfs/config.json -s3.allowEmptyFolder -s3.port=9000  - OS version: Debian 10.9 - output of `weed version`: version 30GB 2.38 2327c07 linux amd64 - if using filer, show the content of `filer.toml`:  [leveldb3] # similar to leveldb2. # each bucket has its own meta store. enabled = true dir = ""/var/lib/weed/filer"" # directory to store level db files  source-file",no-bug,0.95
3214,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3214,"[NewHashicorpRaftServer] boltdb.NewBoltStore(""/data/m9333/logs.dat""): open /data/m9333/logs.dat: no such file or directory","**Describe the bug** master CrashLoopBackOff  F0621 08:29:10 1 master.go:172] NewHashicorpRaftServer: boltdb.NewBoltStore(""/data/m9333/logs.dat""): open /data/m9333/logs.dat: no such file or directory  **System Setup** 3.12  + exec /usr/bin/weed '-logtostderr=true' '-v=4' master -mdir /data -port 9333 '-defaultReplication=100' '-metricsPort=9090' '-volumeSizeLimitMB=1000' '-resumeState=false' -raftHashicorp '-ip.bind=0.0.0.0' ",source-file | source-file,"[NewHashicorpRaftServer] boltdb.NewBoltStore(""/data/m9333/logs.dat""): open /data/m9333/logs.dat: no such file or directory **Describe the bug** master CrashLoopBackOff  F0621 08:29:10 1 master.go:172] NewHashicorpRaftServer: boltdb.NewBoltStore(""/data/m9333/logs.dat""): open /data/m9333/logs.dat: no such file or directory  **System Setup** 3.12  + exec /usr/bin/weed '-logtostderr=true' '-v=4' master -mdir /data -port 9333 '-defaultReplication=100' '-metricsPort=9090' '-volumeSizeLimitMB=1000' '-resumeState=false' -raftHashicorp '-ip.bind=0.0.0.0'  source-file source-file",no-bug,0.9
2038,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2038,Weed mount not showing changes happening on another node,"**Describe the bug** I am trying to use seaweedfs as a distributed filesystem. Essentially the seaweedfs mounted folder should more or less be the same on all hosts. Change a file on one server, the changes should be visible on the other server in a a few seconds. In my testing setup it seems like file creation and deletion sync properly but changes to a file don't. The master server sees changes but the other mounts don't see the changes. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". Create the master, filer, and volume server as specified in wiki: https://github.com/chrislusf/seaweedfs/wiki/Directories-and-Files  weed server -filer=true  Create a mount in server1:  mkdir -p /mnt/seaweed weed mount -filer=localhost:8888 -dir=/mnt/seaweed/ -filer.path=/  Create a mount in server2:  mkdir -p /mnt/seaweed weed mount -filer=server1ip:8888 -dir=/mnt/seaweed/ -filer.path=/  Create a file on server1:  echo ""testing"" > /mnt/seaweed/testing.txt  Edit file on server2:  nano /mnt/seaweed/testing.txt insert changes  See differences in files on both servers: server2:  # cat testing.txt testing testing2  server1:  # cat testing.txt testing  But if I dig around in the actual master server the changes do appear to be there.  curl http://server1:8080/5,3f6f9515ff testing testing2  - OS version  lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 18.04.3 LTS Release: 18.04 Codename: bionic  - output of `weed version`  root@server1:~# weed version version 30GB 2.42 84312e6 linux amd64  - if using filer, show the content of `filer.toml`  [leveldb2] # local on disk, mostly for simple single-machine setup, fairly scalable # faster than previous leveldb, recommended. enabled = true dir = ""./filerldb2"" # directory to store level db files  **Expected behavior** The files should be synced eventually. Even if I wait a few minutes, the files never seem to sync up. The only thing that syncs them is unmount and then remounting. Or deleting and creating a new file. It seems like seaweedfs should support this, but let me know if I misunderstood something.",source-file | source-file | source-file | source-file,"Weed mount not showing changes happening on another node **Describe the bug** I am trying to use seaweedfs as a distributed filesystem. Essentially the seaweedfs mounted folder should more or less be the same on all hosts. Change a file on one server, the changes should be visible on the other server in a a few seconds. In my testing setup it seems like file creation and deletion sync properly but changes to a file don't. The master server sees changes but the other mounts don't see the changes. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". Create the master, filer, and volume server as specified in wiki: https://github.com/chrislusf/seaweedfs/wiki/Directories-and-Files  weed server -filer=true  Create a mount in server1:  mkdir -p /mnt/seaweed weed mount -filer=localhost:8888 -dir=/mnt/seaweed/ -filer.path=/  Create a mount in server2:  mkdir -p /mnt/seaweed weed mount -filer=server1ip:8888 -dir=/mnt/seaweed/ -filer.path=/  Create a file on server1:  echo ""testing"" > /mnt/seaweed/testing.txt  Edit file on server2:  nano /mnt/seaweed/testing.txt insert changes  See differences in files on both servers: server2:  # cat testing.txt testing testing2  server1:  # cat testing.txt testing  But if I dig around in the actual master server the changes do appear to be there.  curl http://server1:8080/5,3f6f9515ff testing testing2  - OS version  lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 18.04.3 LTS Release: 18.04 Codename: bionic  - output of `weed version`  root@server1:~# weed version version 30GB 2.42 84312e6 linux amd64  - if using filer, show the content of `filer.toml`  [leveldb2] # local on disk, mostly for simple single-machine setup, fairly scalable # faster than previous leveldb, recommended. enabled = true dir = ""./filerldb2"" # directory to store level db files  **Expected behavior** The files should be synced eventually. Even if I wait a few minutes, the files never seem to sync up. The only thing that syncs them is unmount and then remounting. Or deleting and creating a new file. It seems like seaweedfs should support this, but let me know if I misunderstood something. source-file source-file source-file source-file",no-bug,0.9
2417,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2417,S3 using IAM action Write does not work properly,"**Describe the bug** I have followed the documentation to enable S3 IAM identities but it seems that the Write action for an identity does not allow to actually create files using S3. **System Setup** - Running seaweedfs from Docker, config below  docker_container: name: seaweedfs image: chrislusf/seaweedfs state: started restart_policy: unless-stopped pull: true user: nobody:20000 command: server -dir=""/data"" -volume.max=0 -master.volumePreallocate=false -master.volumeSizeLimitMB=1024 -s3 -s3.config=/etc/seaweedfs-s3-config.json comparisons: image: strict ports: - ""127.0.0.1:28080:8080"" - ""127.0.0.1:18080:18080"" - ""127.0.0.1:8333:8333"" volumes: - ""/etc/seaweedfs-s3-config.json:/etc/seaweedfs-s3-config.json:ro"" - ""/var/lib/seaweedfs-data:/data""  - `version 30GB 2.76 1b90d607 linux amd64` - Using `rclone` for file operations **Expected behavior** I would expect that the `Write` permission allow to create a file in a bucket, otherwise I have to grant `Admin` which is not very granular. **IAM config**:  { ""identities"": [ { ""name"": ""admin"", ""credentials"": [ { ""accessKey"": ""admin_access"", ""secretKey"": ""admin_secret"" } ], ""actions"": [ ""Admin"", ""Read"", ""List"", ""Tagging"", ""Write"" ] }, { ""name"": ""rclone"", ""credentials"": [ { ""accessKey"": ""rclone_access"", ""secretKey"": ""rclone_secret"" } ], ""actions"": [ ""Read"", ""Write"", ""List"" ] } ] }  **rclone config**:  [weed] type = s3 provider = Other access_key_id = rclone_access secret_access_key = rclone_secret endpoint = http://127.0.0.1:8333 acl = private [weedAdmin] type = s3 provider = Other access_key_id = admin_access secret_access_key = admin_secret endpoint = http://127.0.0.1:8333 acl = private  **Using rclone with low-priv user**:  #Bucket listing works # rclone lsd weed: -1 2021-11-02 15:11:23 -1 photos_staging_dir #File listing works # rclone ls weed:photos_staging_dir #Creating a file fails # rclone touch weed:photos_staging_dir/fstab 2021/11/02 16:06:26 ERROR : Attempt 1/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186380983481, host id: 2021/11/02 16:06:26 ERROR : Attempt 2/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186384910685, host id: 2021/11/02 16:06:26 ERROR : Attempt 3/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186388820806, host id: 2021/11/02 16:06:26 Failed to touch: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186388820806, host id:  Creating empty file with admin identity:  rclone touch weedAdmin:photos_staging_dir/fstab  Created file can now be written/deleted by low-priv identity:  # rclone copy /etc/fstab weed:photos_staging_dir/ # rclone ls weed:photos_staging_dir/ 881 fstab #rclone delete weed:photos_staging_dir/fstab ",source-file,"S3 using IAM action Write does not work properly **Describe the bug** I have followed the documentation to enable S3 IAM identities but it seems that the Write action for an identity does not allow to actually create files using S3. **System Setup** - Running seaweedfs from Docker, config below  docker_container: name: seaweedfs image: chrislusf/seaweedfs state: started restart_policy: unless-stopped pull: true user: nobody:20000 command: server -dir=""/data"" -volume.max=0 -master.volumePreallocate=false -master.volumeSizeLimitMB=1024 -s3 -s3.config=/etc/seaweedfs-s3-config.json comparisons: image: strict ports: - ""127.0.0.1:28080:8080"" - ""127.0.0.1:18080:18080"" - ""127.0.0.1:8333:8333"" volumes: - ""/etc/seaweedfs-s3-config.json:/etc/seaweedfs-s3-config.json:ro"" - ""/var/lib/seaweedfs-data:/data""  - `version 30GB 2.76 1b90d607 linux amd64` - Using `rclone` for file operations **Expected behavior** I would expect that the `Write` permission allow to create a file in a bucket, otherwise I have to grant `Admin` which is not very granular. **IAM config**:  { ""identities"": [ { ""name"": ""admin"", ""credentials"": [ { ""accessKey"": ""admin_access"", ""secretKey"": ""admin_secret"" } ], ""actions"": [ ""Admin"", ""Read"", ""List"", ""Tagging"", ""Write"" ] }, { ""name"": ""rclone"", ""credentials"": [ { ""accessKey"": ""rclone_access"", ""secretKey"": ""rclone_secret"" } ], ""actions"": [ ""Read"", ""Write"", ""List"" ] } ] }  **rclone config**:  [weed] type = s3 provider = Other access_key_id = rclone_access secret_access_key = rclone_secret endpoint = http://127.0.0.1:8333 acl = private [weedAdmin] type = s3 provider = Other access_key_id = admin_access secret_access_key = admin_secret endpoint = http://127.0.0.1:8333 acl = private  **Using rclone with low-priv user**:  #Bucket listing works # rclone lsd weed: -1 2021-11-02 15:11:23 -1 photos_staging_dir #File listing works # rclone ls weed:photos_staging_dir #Creating a file fails # rclone touch weed:photos_staging_dir/fstab 2021/11/02 16:06:26 ERROR : Attempt 1/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186380983481, host id: 2021/11/02 16:06:26 ERROR : Attempt 2/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186384910685, host id: 2021/11/02 16:06:26 ERROR : Attempt 3/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186388820806, host id: 2021/11/02 16:06:26 Failed to touch: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186388820806, host id:  Creating empty file with admin identity:  rclone touch weedAdmin:photos_staging_dir/fstab  Created file can now be written/deleted by low-priv identity:  # rclone copy /etc/fstab weed:photos_staging_dir/ # rclone ls weed:photos_staging_dir/ 881 fstab #rclone delete weed:photos_staging_dir/fstab  source-file",bug,0.9
29,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/29,Add a tool to change a volume's replication setting.,Hello. We are going to try weed-fs in our pretty big project to store 3m+ images. There are few questions about replication which are not clear from docs: 1. Weed replicates volumes. Is it correct? 2. Is it possible to change replication type for volume `x`? Suppose we added one more server 3. Is it possible to control volume location? We've got 3 servers and `001` replication type. Volume `1` is located on server `A` and `B`. How can I move it from `B` to `C`?,config-file | other-file | config-file | config-file | config-file | source-file | source-file | config-file | config-file | source-file | source-file,Add a tool to change a volume's replication setting. Hello. We are going to try weed-fs in our pretty big project to store 3m+ images. There are few questions about replication which are not clear from docs: 1. Weed replicates volumes. Is it correct? 2. Is it possible to change replication type for volume `x`? Suppose we added one more server 3. Is it possible to control volume location? We've got 3 servers and `001` replication type. Volume `1` is located on server `A` and `B`. How can I move it from `B` to `C`? config-file other-file config-file config-file config-file source-file source-file config-file config-file source-file source-file,no-bug,0.9
1534,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1534,2.04: volumeServer.evacuate moves one volume only,"`volumeServer.evacuate` fails to move all volumes but succeeds in moving one volume at a time. I've started a new volume server and I'm trying to move data from another volume server (which I want to decommission):  > volumeServer.evacuate -node 192.168.0.250:9334 -force moving volume 2 192.168.0.250:9334 => 192.168.0.204:8080 2020-10-14 00:24:04.230186 I | copying volume 2 from 192.168.0.250:9334 to 192.168.0.204:8080 2020-10-14 00:24:07.278448 I | tailing volume 2 from 192.168.0.250:9334 to 192.168.0.204:8080 2020-10-14 00:24:19.473121 I | deleting volume 2 from 192.168.0.250:9334 2020-10-14 00:24:19.682220 I | moved volume 2 from 192.168.0.250:9334 to 192.168.0.204:8080 error: failed to move volume 19 from 192.168.0.250:9334 > volumeServer.evacuate -node 192.168.0.250:9334 -force moving volume 4 192.168.0.250:9334 => 192.168.0.204:8080 2020-10-14 00:24:30.661134 I | copying volume 4 from 192.168.0.250:9334 to 192.168.0.204:8080 2020-10-14 00:24:32.954465 I | tailing volume 4 from 192.168.0.250:9334 to 192.168.0.204:8080 2020-10-14 00:24:45.109108 I | deleting volume 4 from 192.168.0.250:9334 2020-10-14 00:24:45.272594 I | moved volume 4 from 192.168.0.250:9334 to 192.168.0.204:8080 error: failed to move volume 3 from 192.168.0.250:9334  Re-trying the command `volumeServer.evacuate -node 192.168.0.250:9334 -force` always stops after processing one volume which it manages to evacuate successfully. With one volume processed per command invocation, running `volumeServer.evacuate` enough times eventually managed to move/delete all the volumes from server 192.168.0.250.",source-file | test-file | test-file,"2.04: volumeServer.evacuate moves one volume only `volumeServer.evacuate` fails to move all volumes but succeeds in moving one volume at a time. I've started a new volume server and I'm trying to move data from another volume server (which I want to decommission):  > volumeServer.evacuate -node 192.168.0.250:9334 -force moving volume 2 192.168.0.250:9334 => 192.168.0.204:8080 2020-10-14 00:24:04.230186 I | copying volume 2 from 192.168.0.250:9334 to 192.168.0.204:8080 2020-10-14 00:24:07.278448 I | tailing volume 2 from 192.168.0.250:9334 to 192.168.0.204:8080 2020-10-14 00:24:19.473121 I | deleting volume 2 from 192.168.0.250:9334 2020-10-14 00:24:19.682220 I | moved volume 2 from 192.168.0.250:9334 to 192.168.0.204:8080 error: failed to move volume 19 from 192.168.0.250:9334 > volumeServer.evacuate -node 192.168.0.250:9334 -force moving volume 4 192.168.0.250:9334 => 192.168.0.204:8080 2020-10-14 00:24:30.661134 I | copying volume 4 from 192.168.0.250:9334 to 192.168.0.204:8080 2020-10-14 00:24:32.954465 I | tailing volume 4 from 192.168.0.250:9334 to 192.168.0.204:8080 2020-10-14 00:24:45.109108 I | deleting volume 4 from 192.168.0.250:9334 2020-10-14 00:24:45.272594 I | moved volume 4 from 192.168.0.250:9334 to 192.168.0.204:8080 error: failed to move volume 3 from 192.168.0.250:9334  Re-trying the command `volumeServer.evacuate -node 192.168.0.250:9334 -force` always stops after processing one volume which it manages to evacuate successfully. With one volume processed per command invocation, running `volumeServer.evacuate` enough times eventually managed to move/delete all the volumes from server 192.168.0.250. source-file test-file test-file",no-bug,0.9
93,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/93,"Lots of ""volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01"" errors in our production server log files","Here is the  Deploy structure  10.252.130.159:9333(master) 10.252.130.159:5088(haproxy) / \ 10.252.133.22:5083 (volume1) 10.252.135.207:5084(volume2) Replication Stratage: 001  So, it always gets the content via haproxy from the volume server. But after running few days, we get a 404 error sometimes from the 10.252.130.159:5088 for a special fid such as :5,1001e1b02c1b01. And we did a check and found that one of volume server(different fid on the random different server) always output the following logs:  I0303 15:44:23 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:45:14 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:52:52 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:52:52 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:05 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:06 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:07 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:07 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:18 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01  It means that the file for [fid:5,1001e1b02c1b01] has be damaged? And how to fix this? How could be happened? any suggestions?",source-file | documentation-file | source-file,"Lots of ""volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01"" errors in our production server log files Here is the  Deploy structure  10.252.130.159:9333(master) 10.252.130.159:5088(haproxy) / \ 10.252.133.22:5083 (volume1) 10.252.135.207:5084(volume2) Replication Stratage: 001  So, it always gets the content via haproxy from the volume server. But after running few days, we get a 404 error sometimes from the 10.252.130.159:5088 for a special fid such as :5,1001e1b02c1b01. And we did a check and found that one of volume server(different fid on the random different server) always output the following logs:  I0303 15:44:23 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:45:14 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:52:52 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:52:52 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:05 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:06 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:07 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:07 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:18 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01  It means that the file for [fid:5,1001e1b02c1b01] has be damaged? And how to fix this? How could be happened? any suggestions? source-file documentation-file source-file",bug,0.85
341,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/341,config file,"Whether we can write mdir,ip,peers in the config file when starting a master? If it is allowed, can you provide a template?",other-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file,"config file Whether we can write mdir,ip,peers in the config file when starting a master? If it is allowed, can you provide a template? other-file other-file source-file other-file source-file source-file source-file source-file other-file source-file source-file",no-bug,0.9
2648,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2648,[store] failed to write to local disk: invalid argument,"**Describe the bug** logs  upload_content.go:109] uploading to http://fast-volume-6.s3-fast-volume.service.dcdp.consul:8080/825,01366342ecebf5fc: unmarshalled error http://fast-volume-6.s3-fast-volume.service.dcdp.consul:8080/825,01366342ecebf5fc: failed to write to local disk: invalid argument | fast-api-658d59f67b-vd9ct store_replicate.go:48] failed to write to local disk: invalid argument | fast-volume-6 common.go:69] response method:POST URL:/825,01366342ecebf5fc with httpStatus:500 and JSON:{""name"":""0006.part"",""size"":5242880,""error"":""failed to write to local disk: invalid argument"",""eTag"":""971972b3""} | fast-volume-6  **System Setup**  2.88 ",source-file,"[store] failed to write to local disk: invalid argument **Describe the bug** logs  upload_content.go:109] uploading to http://fast-volume-6.s3-fast-volume.service.dcdp.consul:8080/825,01366342ecebf5fc: unmarshalled error http://fast-volume-6.s3-fast-volume.service.dcdp.consul:8080/825,01366342ecebf5fc: failed to write to local disk: invalid argument | fast-api-658d59f67b-vd9ct store_replicate.go:48] failed to write to local disk: invalid argument | fast-volume-6 common.go:69] response method:POST URL:/825,01366342ecebf5fc with httpStatus:500 and JSON:{""name"":""0006.part"",""size"":5242880,""error"":""failed to write to local disk: invalid argument"",""eTag"":""971972b3""} | fast-volume-6  **System Setup**  2.88  source-file",bug,0.9
2055,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2055,Mount point crashed,"Had a mount point crash:  May 07 03:00:00 weatherwax weed[3259922]: E0507 03:00:00 59922 reader_at.go:146] fetching chunk &{FileId:105,0160610d87233a6d Offset:0 Size:574 LogicOffset:20480 ChunkSize:574 CipherKey:[] IsGzipped:true}: http://138.38.108.115:9380/105,0160610d87233a6d> May 07 03:00:00 weatherwax weed[3259922]: E0507 03:00:00 59922 filehandle.go:148] file handle read /homes/ar2056/.bash_history: http://138.38.108.115:9380/105,0160610d87233a6d?readDeleted=true: 404 Not Found May 07 03:00:00 weatherwax weed[3259922]: W0507 03:00:00 59922 filehandle.go:88] file handle read /homes/ar2056/.bash_history 20480: http://138.38.108.115:9380/105,0160610d87233a6d?readDeleted=true: 404 Not Found May 07 03:00:00 weatherwax weed[3259922]: E0507 03:00:00 59922 reader_at.go:146] fetching chunk &{FileId:105,0160610d87233a6d Offset:0 Size:574 LogicOffset:20480 ChunkSize:574 CipherKey:[] IsGzipped:true}: http://138.38.108.125:9380/105,0160610d87233a6d> May 07 03:00:00 weatherwax weed[3259922]: E0507 03:00:00 59922 filehandle.go:148] file handle read /homes/ar2056/.bash_history: http://138.38.108.125:9380/105,0160610d87233a6d?readDeleted=true: 404 Not Found May 07 03:00:00 weatherwax weed[3259922]: W0507 03:00:00 59922 filehandle.go:88] file handle read /homes/ar2056/.bash_history 0: http://138.38.108.125:9380/105,0160610d87233a6d?readDeleted=true: 404 Not Found May 07 07:43:26 weatherwax weed[3259922]: panic: runtime error: invalid memory address or nil pointer dereference May 07 07:43:26 weatherwax weed[3259922]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1bb85ad] May 07 07:43:26 weatherwax weed[3259922]: goroutine 229 [running]: May 07 07:43:26 weatherwax weed[3259922]: github.com/seaweedfs/fuse/fs.(*Server).InvalidateEntry(0xc0002ba8c0, 0x2613d40, 0xc002859690, 0xc00114c3b5, 0x9, 0x0, 0x0) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/pkg/mod/github.com/seaweedfs/fuse@v1.1.4/fs/serve.go:1851 +0xcd May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys.NewSeaweedFileSystem.func2(0xc00114c3a0, 0x1e) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs.go:117 +0x185 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys/meta_cache.NewMetaCache.func1(0xc00114c3a0, 0x1e) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/meta_cache/meta_cache.go:33 +0x39 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys/meta_cache.SubscribeMetaEvents.func1(0xc008d90230, 0xc008d90230, 0x0) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/meta_cache/meta_cache_subscribe.go:45 +0x40c May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys/meta_cache.SubscribeMetaEvents.func2(0x266bc68, 0xc000876580, 0x0, 0x0) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/meta_cache/meta_cache_subscribe.go:75 +0x2c4 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys.(*WFS).WithFilerClient.func1.1(0xc000b0e000, 0x14, 0xc0016d5e00) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs_filer_client.go:18 +0x76 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/pb.WithCachedGrpcClient(0xc0016d5e10, 0xc0005a7d70, 0x14, 0xc0016d5e00, 0x1, 0x1, 0x22df9b0, 0xc0014f0320) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/pb/grpc_client_server.go:108 +0x15f May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys.(*WFS).WithFilerClient.func1(0x861c4680, 0x0) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs_filer_client.go:16 +0x9b May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/util.Retry(0xc00032a200, 0x1f, 0xc0016d5f08, 0xc0005a7d70, 0x14) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/util/retry.go:16 +0x91 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys.(*WFS).WithFilerClient(0xc0009bcd00, 0xc0015c0030, 0x2267635, 0x21) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs_filer_client.go:15 +0xab May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys/meta_cache.SubscribeMetaEvents(0xc000337100, 0xf751e10e, 0x262aa10, 0xc0009bcd00, 0x2225dce, 0x1, 0x167b107fcbd55bc9, 0xc000154740, 0x32) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/meta_cache/meta_cache_subscribe.go:53 +0x11e May 07 07:43:26 weatherwax weed[3259922]: created by github.com/chrislusf/seaweedfs/weed/filesys.NewSeaweedFileSystem May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs.go:122 +0x473 May 07 07:43:26 weatherwax systemd[1]: seaweed-mount.service: Main process exited, code=exited, status=2/INVALIDARGUMENT May 07 07:43:26 weatherwax systemd[1]: seaweed-mount.service: Failed with result 'exit-code'.  Don't think they are helpful, as they look like the messages you would expect after a crash, but here is the filer on that node and master at the same time. Nothing in the volumes: Filer:  May 07 07:43:23 weatherwax weed[3259835]: I0507 07:43:23 59835 meta_aggregator.go:151] subscribing remote 138.38.108.119:8888 meta change: rpc error: code = Unavailable desc = transport is closing May 07 07:43:26 weatherwax weed[3259835]: I0507 07:43:26 59835 filer_grpc_server_sub_meta.go:187] => client mount@138.38.108.125:39534: rpc error: code = Unavailable desc = transport is closing May 07 07:43:26 weatherwax weed[3259835]: E0507 07:43:26 59835 filer_grpc_server_sub_meta.go:56] processed to 2021-05-07 07:43:26.181162812 +0000 UTC: rpc error: code = Unavailable desc = transport is closing May 07 07:43:29 weatherwax weed[3259835]: I0507 07:43:29 59835 filer_grpc_server_sub_meta.go:201] - listener mount@138.38.108.125:39534  Master:  May 07 07:43:50 weatherwax weed[3259663]: I0507 07:43:50 59663 master_grpc_server.go:265] - client master@138.38.108.125:52366 May 07 07:43:50 weatherwax weed[3259663]: I0507 07:43:50 59663 masterclient.go:120] master masterClient failed to receive from 138.38.108.125:9333: rpc error: code = Unavailable desc = transport is closing May 07 07:43:50 weatherwax weed[3259663]: I0507 07:43:50 59663 master_grpc_server.go:249] + client master@138.38.108.125:49216  Afraid I have no idea what was occuring on the computer during the crash, but it seems doubtful that any students were up and using the server at that time;-) Plenty of processes running that could be doing anything however. Seaweed 2.43, fully distributed and secure setup over 7 nodes - happy to provide setup details if useful!",other-file | other-file,"Mount point crashed Had a mount point crash:  May 07 03:00:00 weatherwax weed[3259922]: E0507 03:00:00 59922 reader_at.go:146] fetching chunk &{FileId:105,0160610d87233a6d Offset:0 Size:574 LogicOffset:20480 ChunkSize:574 CipherKey:[] IsGzipped:true}: http://138.38.108.115:9380/105,0160610d87233a6d> May 07 03:00:00 weatherwax weed[3259922]: E0507 03:00:00 59922 filehandle.go:148] file handle read /homes/ar2056/.bash_history: http://138.38.108.115:9380/105,0160610d87233a6d?readDeleted=true: 404 Not Found May 07 03:00:00 weatherwax weed[3259922]: W0507 03:00:00 59922 filehandle.go:88] file handle read /homes/ar2056/.bash_history 20480: http://138.38.108.115:9380/105,0160610d87233a6d?readDeleted=true: 404 Not Found May 07 03:00:00 weatherwax weed[3259922]: E0507 03:00:00 59922 reader_at.go:146] fetching chunk &{FileId:105,0160610d87233a6d Offset:0 Size:574 LogicOffset:20480 ChunkSize:574 CipherKey:[] IsGzipped:true}: http://138.38.108.125:9380/105,0160610d87233a6d> May 07 03:00:00 weatherwax weed[3259922]: E0507 03:00:00 59922 filehandle.go:148] file handle read /homes/ar2056/.bash_history: http://138.38.108.125:9380/105,0160610d87233a6d?readDeleted=true: 404 Not Found May 07 03:00:00 weatherwax weed[3259922]: W0507 03:00:00 59922 filehandle.go:88] file handle read /homes/ar2056/.bash_history 0: http://138.38.108.125:9380/105,0160610d87233a6d?readDeleted=true: 404 Not Found May 07 07:43:26 weatherwax weed[3259922]: panic: runtime error: invalid memory address or nil pointer dereference May 07 07:43:26 weatherwax weed[3259922]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1bb85ad] May 07 07:43:26 weatherwax weed[3259922]: goroutine 229 [running]: May 07 07:43:26 weatherwax weed[3259922]: github.com/seaweedfs/fuse/fs.(*Server).InvalidateEntry(0xc0002ba8c0, 0x2613d40, 0xc002859690, 0xc00114c3b5, 0x9, 0x0, 0x0) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/pkg/mod/github.com/seaweedfs/fuse@v1.1.4/fs/serve.go:1851 +0xcd May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys.NewSeaweedFileSystem.func2(0xc00114c3a0, 0x1e) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs.go:117 +0x185 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys/meta_cache.NewMetaCache.func1(0xc00114c3a0, 0x1e) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/meta_cache/meta_cache.go:33 +0x39 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys/meta_cache.SubscribeMetaEvents.func1(0xc008d90230, 0xc008d90230, 0x0) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/meta_cache/meta_cache_subscribe.go:45 +0x40c May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys/meta_cache.SubscribeMetaEvents.func2(0x266bc68, 0xc000876580, 0x0, 0x0) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/meta_cache/meta_cache_subscribe.go:75 +0x2c4 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys.(*WFS).WithFilerClient.func1.1(0xc000b0e000, 0x14, 0xc0016d5e00) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs_filer_client.go:18 +0x76 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/pb.WithCachedGrpcClient(0xc0016d5e10, 0xc0005a7d70, 0x14, 0xc0016d5e00, 0x1, 0x1, 0x22df9b0, 0xc0014f0320) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/pb/grpc_client_server.go:108 +0x15f May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys.(*WFS).WithFilerClient.func1(0x861c4680, 0x0) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs_filer_client.go:16 +0x9b May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/util.Retry(0xc00032a200, 0x1f, 0xc0016d5f08, 0xc0005a7d70, 0x14) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/util/retry.go:16 +0x91 May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys.(*WFS).WithFilerClient(0xc0009bcd00, 0xc0015c0030, 0x2267635, 0x21) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs_filer_client.go:15 +0xab May 07 07:43:26 weatherwax weed[3259922]: github.com/chrislusf/seaweedfs/weed/filesys/meta_cache.SubscribeMetaEvents(0xc000337100, 0xf751e10e, 0x262aa10, 0xc0009bcd00, 0x2225dce, 0x1, 0x167b107fcbd55bc9, 0xc000154740, 0x32) May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/meta_cache/meta_cache_subscribe.go:53 +0x11e May 07 07:43:26 weatherwax weed[3259922]: created by github.com/chrislusf/seaweedfs/weed/filesys.NewSeaweedFileSystem May 07 07:43:26 weatherwax weed[3259922]: /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filesys/wfs.go:122 +0x473 May 07 07:43:26 weatherwax systemd[1]: seaweed-mount.service: Main process exited, code=exited, status=2/INVALIDARGUMENT May 07 07:43:26 weatherwax systemd[1]: seaweed-mount.service: Failed with result 'exit-code'.  Don't think they are helpful, as they look like the messages you would expect after a crash, but here is the filer on that node and master at the same time. Nothing in the volumes: Filer:  May 07 07:43:23 weatherwax weed[3259835]: I0507 07:43:23 59835 meta_aggregator.go:151] subscribing remote 138.38.108.119:8888 meta change: rpc error: code = Unavailable desc = transport is closing May 07 07:43:26 weatherwax weed[3259835]: I0507 07:43:26 59835 filer_grpc_server_sub_meta.go:187] => client mount@138.38.108.125:39534: rpc error: code = Unavailable desc = transport is closing May 07 07:43:26 weatherwax weed[3259835]: E0507 07:43:26 59835 filer_grpc_server_sub_meta.go:56] processed to 2021-05-07 07:43:26.181162812 +0000 UTC: rpc error: code = Unavailable desc = transport is closing May 07 07:43:29 weatherwax weed[3259835]: I0507 07:43:29 59835 filer_grpc_server_sub_meta.go:201] - listener mount@138.38.108.125:39534  Master:  May 07 07:43:50 weatherwax weed[3259663]: I0507 07:43:50 59663 master_grpc_server.go:265] - client master@138.38.108.125:52366 May 07 07:43:50 weatherwax weed[3259663]: I0507 07:43:50 59663 masterclient.go:120] master masterClient failed to receive from 138.38.108.125:9333: rpc error: code = Unavailable desc = transport is closing May 07 07:43:50 weatherwax weed[3259663]: I0507 07:43:50 59663 master_grpc_server.go:249] + client master@138.38.108.125:49216  Afraid I have no idea what was occuring on the computer during the crash, but it seems doubtful that any students were up and using the server at that time;-) Plenty of processes running that could be doing anything however. Seaweed 2.43, fully distributed and secure setup over 7 nodes - happy to provide setup details if useful! other-file other-file",no-bug,0.9
1271,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1271,adding header 'Access-Control-Allow-Origin',"Could you please include the feature adding individual headers like 'Access-Control-Allow-Origin' for responses? Otherwise, like many users (sea Google search) we have to use nginx or apache in front of seaweedfs. That slows the great speed of seaweedfs down and eats unnecessary resources . In the meantime, where do we find this ""response part"" in the source code, so we would manually add this part and rebuild everything? Thanks",source-file,"adding header 'Access-Control-Allow-Origin' Could you please include the feature adding individual headers like 'Access-Control-Allow-Origin' for responses? Otherwise, like many users (sea Google search) we have to use nginx or apache in front of seaweedfs. That slows the great speed of seaweedfs down and eats unnecessary resources . In the meantime, where do we find this ""response part"" in the source code, so we would manually add this part and rebuild everything? Thanks source-file",no-bug,0.9
5215,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5215,[volume] error reading newly written files after vacuum and data loss (Critical),"**Describe the bug** error reading newly written files after vacuum:  Jan 17, 2024 @ 17:36:38.738 I0117 12:36:09.943514 needle_map_memory.go:111 loading idx from offset 0 for file: /data/bucket_306.cpx Jan 17, 2024 @ 17:36:38.738 I0117 12:36:23.346201 volume_loading.go:139 updating memory compact index /data/bucket_306.idx Jan 17, 2024 @ 17:36:38.738 W0117 12:36:23.066922 volume_checking.go:121 Truncate /data/bucket_306.dat from 38649746072 bytes to 34362613416 bytes! Jan 17, 2024 @ 17:36:43.709 W0117 12:36:23.066922 volume_checking.go:121 Truncate /data/bucket_306.dat from 38649746072 bytes to 34362613416 bytes! Jan 17, 2024 @ 19:35:10.120 E0117 14:35:03.562706 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:07.184218 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 472 offset 36492488624 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:05.063442 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:06.182941 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 472 offset 36492488624 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:02.562017 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495144: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:06.182941 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 472 offset 36492488624 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:07.314882 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:07.184218 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 472 offset 36492488624 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:02.562017 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495144: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:03.562706 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:05.063442 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF  see_dat:  I0118 17:19:01.605226 volume_loading.go:91 readSuperBlock volume 306 version 3 I0118 17:19:01.605599 see_dat.go:36 306,3be065a31ce6043 offset 8 size 218039(212.93 KiB) cookie 31ce6043 appendedAt 2023-12-27 03:21:39.531516313 +0000 UTC name a5361c29c3d12558bf147154a0eeb637 I0118 17:19:01.605694 see_dat.go:36 306,3be0664820cc0f4 offset 218080 size 110095(107.51 KiB) cookie 820cc0f4 appendedAt 2023-12-27 03:21:39.764625178 +0000 UTC name 4893287b8807871151ea786088c16ba0 I0118 17:19:01.605703 see_dat.go:36 306,3be07f1bb8175cf offset 328208 size 253(253 B) cookie bb8175cf appendedAt 2023-12-27 03:25:13.798546319 +0000 UTC name 7b065779f740338386666811c989ae4d902c25aa20a00fd0b4e8b228e6485bbb I0118 17:19:01.605708 see_dat.go:36 306,3be0808b18ddff9 offset 328496 size 254(254 B) cookie b18ddff9 appendedAt 2023-12-27 03:25:13.822058588 +0000 UTC name f61f70cc01380eb3027d2975014f8e6bfd7908852db9ed76f77038a4b34a547d I0118 17:19:01.605894 see_dat.go:36 306,3be0957d6e0bbb3 offset 328784 size 251031(245.15 KiB) cookie d6e0bbb3 appendedAt 2023-12-27 03:26:32.22218443 +0000 UTC name efd741888c821015350dfe2785ccbf5f    I0118 17:19:51.584695 see_dat.go:36 306,423263c31ad67f7 offset 34077050288 size 389241(380.12 KiB) cookie 31ad67f7 appendedAt 2024-01-16 02:20:42.286250838 +0000 UTC name d2e970d816b80be6b3b61abc6e4564c9 I0118 17:19:51.584785 see_dat.go:36 306,42327970e1e3d89 offset 34077439560 size 286349(279.64 KiB) cookie 0e1e3d89 appendedAt 2024-01-16 02:23:14.442319209 +0000 UTC name 7eeeda111e6022010c28ac49b6e6d3b5 I0118 17:19:51.584860 see_dat.go:36 306,42329de681c74af offset 34077725944 size 256625(250.61 KiB) cookie 681c74af appendedAt 2024-01-16 02:29:00.061529669 +0000 UTC name 20c257e0e18a70967ac03801bcfa6075 I0118 17:19:51.584956 see_dat.go:36 306,42329e136fad834 offset 34077982600 size 345261(337.17 KiB) cookie 36fad834 appendedAt 2024-01-16 02:29:00.598741247 +0000 UTC name c6be0777abd05f1c0fbfd1396a779f0a I0118 17:19:51.588317 see_dat.go:36 306,4232a02cfa067d6 offset 34078327896 size 461841(451.02 KiB) cookie cfa067d6 appendedAt 2024-01-16 02:29:23.338838951 +0000 UTC name d47917d3a6276b48fd38613380073a40 I0118 17:19:51.591132 see_dat.go:36 306,4232b47e9cf68be offset 34078789768 size 2192349(2.09 MiB) cookie e9cf68be appendedAt 2024-01-16 02:31:22.359343585 +0000 UTC name d97c1fbe57c9dc239359bb68a8225b35 I0118 17:19:51.591298 see_dat.go:36 306,4232b7afbd1ec71 offset 34080982152 size 492125(480.59 KiB) cookie fbd1ec71 appendedAt 2024-01-16 02:32:02.543454623 +0000 UTC name 669426d66303f2e080fd5f6d36731f4e I0118 17:19:51.591497 see_dat.go:36 306,4232e0fe9713c90 offset 34081474312 size 698314(681.95 KiB) cookie e9713c90 appendedAt 2024-01-16 02:37:32.579458075 +0000 UTC name 910af7dd4f47507862ac70d6ca90368e I0118 17:19:51.591570 see_dat.go:36 306,42331dec4f98764 offset 34082172656 size 239968(234.34 KiB) cookie c4f98764 appendedAt 2024-01-16 02:43:36.040863561 +0000 UTC name 84ac94ff17ffc829036e2da75f908894 I0118 17:19:51.594942 see_dat.go:36 306,42332a43d012ab1 offset 34082412656 size 345832(337.73 KiB) cookie 3d012ab1 appendedAt 2024-01-16 02:45:23.574424616 +0000 UTC name 06a46b042d543245677182316a0b3673 I0118 17:19:51.595044 see_dat.go:36 306,4233393a7ab8bb7 offset 34082758520 size 274304(267.88 KiB) cookie a7ab8bb7 appendedAt 2024-01-16 02:48:01.008616274 +0000 UTC name fbd6b45d7249aac0f838610ebdaf75d4 I0118 17:19:51.598048 see_dat.go:36 306,42333ed43de8834 offset 34083032856 size 3238884(3.09 MiB) cookie 43de8834 appendedAt 2024-01-16 02:48:08.078079171 +0000 UTC name 494f5451c895d45b55563fb94b69fe3d I0118 17:19:51.602139 see_dat.go:36 306,4233b443bb21870 offset 34086271776 size 2250399(2.15 MiB) cookie 3bb21870 appendedAt 2024-01-16 03:02:17.884903798 +0000 UTC name 6fb3625d7edece05f4c73f273302e2a1 I0118 17:19:51.602199 see_dat.go:36 306,4233bd9bf06484e offset 34088522208 size 39143(38.23 KiB) cookie bf06484e appendedAt 2024-01-16 03:03:17.420516551 +0000 UTC name 1a25ac95357ff4b85813221d69bf6148 I0118 17:19:51.602240 see_dat.go:36 306,4233d0939a889fc offset 34088561384 size 130893(127.83 KiB) cookie 39a889fc appendedAt 2024-01-16 03:04:23.765892237 +0000 UTC name 21bf67f5671d08dc6c159521dc4c5aa4 I0118 17:19:51.716505 see_dat.go:36 306,4233d6e631a8505 offset 34088692312 size 67275322(64.16 MiB) cookie 631a8505 appendedAt 2024-01-16 03:05:25.717942952 +0000 UTC name 867ac9ff99498f57daacf4700fb11236b532d69d50090063dd0 8809662f90197 I0118 17:19:51.833313 see_dat.go:36 306,4233d7db25cebf7 offset 34155967664 size 67620533(64.49 MiB) cookie b25cebf7 appendedAt 2024-01-16 03:05:27.848121402 +0000 UTC name fda1281b282d90e79371e81b1add23dea1d7433864f6a0236cb 9a62889f4b839 I0118 17:19:51.833421 see_dat.go:36 306,4233d813cdd3be1 offset 34223588232 size 232732(227.28 KiB) cookie 3cdd3be1 appendedAt 2024-01-16 03:05:28.49008878 +0000 UTC name a57041428492630f805b6c5df50b1ef9 I0118 17:19:51.947632 see_dat.go:36 306,4233da2b99907c5 offset 34223821000 size 68226599(65.07 MiB) cookie b99907c5 appendedAt 2024-01-16 03:05:41.411330528 +0000 UTC name 0216e4a416f2c135cafc2fcf3967cf93f9855df08591a81dc55 d99cc765b91ef I0118 17:19:52.068052 see_dat.go:36 306,4233e1651ee5124 offset 34292047632 size 70565753(67.30 MiB) cookie 51ee5124 appendedAt 2024-01-16 03:06:06.302138326 +0000 UTC name 2ee2ce4b73522ef28ec2ed4599338a85fa142fc7b6019d90835 d7bee2ec866a5 I0118 17:19:52.068370 see_dat.go:36 306,42de1dc2d23c7ac offset 34362613416 size 434780(424.59 KiB) cookie 2d23c7ac appendedAt 2024-01-17 12:37:18.747566921 +0000 UTC name 2a6306dc58904c51d15667e789c40d5f I0118 17:19:52.068518 see_dat.go:36 306,42de1f613571038 offset 34363048232 size 218979(213.85 KiB) cookie 13571038 appendedAt 2024-01-17 12:37:20.540658568 +0000 UTC name 11176434e8eedf3a6d9d28d2b0f51195 I0118 17:19:52.068528 see_dat.go:36 306,42de470b7c2e2a1 offset 34363267240 size 251(251 B) cookie b7c2e2a1 appendedAt 2024-01-17 12:37:39.390146706 +0000 UTC name 0c92dfafd10a0589b9dfac17845c3a438dda40bc1d92f8886bef31d0a5e4 d529 I0118 17:19:52.068534 see_dat.go:36 306,42de47000000000 offset 34363267520 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:37:40.050513736 +0000 UTC name I0118 17:19:52.068540 see_dat.go:36 306,42de4fd90f50a74 offset 34363267552 size 254(254 B) cookie 90f50a74 appendedAt 2024-01-17 12:37:50.956080809 +0000 UTC name ea34980c7ebefe5c0dec49223cf528e6cfa5ea7ec161c98df3a8c1fefda1 4be5 I0118 17:19:52.068545 see_dat.go:36 306,42de4fd00000000 offset 34363267840 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:37:51.191687807 +0000 UTC name I0118 17:19:52.068551 see_dat.go:36 306,42deaf0bfdbf5c4 offset 34363267872 size 252(252 B) cookie bfdbf5c4 appendedAt 2024-01-17 12:39:25.833348754 +0000 UTC name cbcbe63e7180d0eabbd32b2be0633580c07672fb8ef79b43c8fd413f836c 4b93 I0118 17:19:52.068556 see_dat.go:36 306,42deaf000000000 offset 34363268160 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:39:26.049790231 +0000 UTC name I0118 17:19:52.068561 see_dat.go:36 306,42deb95c53273e6 offset 34363268192 size 252(252 B) cookie c53273e6 appendedAt 2024-01-17 12:39:42.531562106 +0000 UTC name 547e3bbea07e1fefcd86a9cadc9bd24da1f27a4a6e74307d906ba0a1d833 ed2d I0118 17:19:52.068567 see_dat.go:36 306,42deb9500000000 offset 34363268480 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:39:43.116128478 +0000 UTC name I0118 17:19:52.068808 see_dat.go:36 306,42ded9d5d7aae3e offset 34363268512 size 381508(372.57 KiB) cookie 5d7aae3e appendedAt 2024-01-17 12:40:01.414961987 +0000 UTC name 382a98788822934414f53684bac5a812 I0118 17:19:52.070763 see_dat.go:36 306,42dedb5cae2e24f offset 34363650056 size 2804355(2.67 MiB) cookie cae2e24f appendedAt 2024-01-17 12:40:03.189488243 +0000 UTC name 14c4a0bc6cdb0012a14fb0506185ab04 I0118 17:19:52.070786 see_dat.go:36 306,42dedb500000000 offset 34366454440 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:40:05.407735232 +0000 UTC name I0118 17:19:52.074318 see_dat.go:36 306,42df0264d13ae03 offset 34366454472 size 2481497(2.37 MiB) cookie 4d13ae03 appendedAt 2024-01-17 12:41:28.060904874 +0000 UTC name 2d032ef7043c1c4144da7cbd725c0c3b I0118 17:19:52.074349 see_dat.go:36 306,42df02600000000 offset 34368936000 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:41:29.544656561 +0000 UTC name I0118 17:19:52.074357 see_dat.go:36 306,42df0eb621915b4 offset 34368936032 size 252(252 B) cookie 621915b4 appendedAt 2024-01-17 12:41:49.582088965 +0000 UTC name 8bf5b1562004570ed7f760fe8baec743a88dd1b34c83663f69727a744d80 4193    I0118 17:19:55.251030 see_dat.go:36 306,43997a700000000 offset 36399211784 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:50:49.23505557 +0000 UTC name I0118 17:19:55.251170 see_dat.go:36 306,43997d12d642169 offset 36399211816 size 203965(199.18 KiB) cookie 2d642169 appendedAt 2024-01-18 14:50:49.681077901 +0000 UTC name e58f69125538e2009760ac37a3594f46 I0118 17:19:55.251177 see_dat.go:36 306,43997d100000000 offset 36399415816 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:50:50.173978636 +0000 UTC name I0118 17:19:55.251375 see_dat.go:36 306,43999669edbc06f offset 36399415848 size 315035(307.65 KiB) cookie 9edbc06f appendedAt 2024-01-18 14:52:01.686168611 +0000 UTC name 8bb382c777837219039457e9547e3497 I0118 17:19:55.251390 see_dat.go:36 306,43999f52df61bd6 offset 36399730912 size 20919(20.43 KiB) cookie 2df61bd6 appendedAt 2024-01-18 14:52:32.101891445 +0000 UTC name 82c7b1e1b772251d63b8232ad01c510a I0118 17:19:55.251396 see_dat.go:36 306,43999f500000000 offset 36399751864 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:52:33.29600673 +0000 UTC name I0118 17:19:55.251504 see_dat.go:36 306,4399bc0fa7db986 offset 36399751896 size 167961(164.02 KiB) cookie fa7db986 appendedAt 2024-01-18 14:53:25.570011368 +0000 UTC name 529a450cab92fcd9b219b51fc066c0ad I0118 17:19:55.251512 see_dat.go:36 306,4399bd06bb7ff0e offset 36399919888 size 251(251 B) cookie 6bb7ff0e appendedAt 2024-01-18 14:53:28.962604899 +0000 UTC name 325af1c78e57c6524ee2d8c4c42970ef7ad1706fdd3ff69a60002179fb0365b9 I0118 17:19:55.251517 see_dat.go:36 306,4399bd000000000 offset 36399920168 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:53:29.615904279 +0000 UTC name I0118 17:19:55.252385 see_dat.go:36 306,4399bfac6ba2f65 offset 36399920200 size 705624(689.09 KiB) cookie c6ba2f65 appendedAt 2024-01-18 14:53:44.833676382 +0000 UTC name 8f7c9cbcc224a08e570b99f303457f2e I0118 17:19:55.252715 see_dat.go:36 306,4399c16d2e063b4 offset 36400625856 size 519835(507.65 KiB) cookie d2e063b4 appendedAt 2024-01-18 14:54:00.491714658 +0000 UTC name 54b6534f0c7e8ad282bc0c89106ce31f I0118 17:19:55.252724 see_dat.go:36 306,4399c1600000000 offset 36401145720 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:54:02.264603775 +0000 UTC name I0118 17:19:55.252732 see_dat.go:36 306,4399c26600a7ae5 offset 36401145752 size 252(252 B) cookie 600a7ae5 appendedAt 2024-01-18 14:54:05.3725053 +0000 UTC name 602ed288f155efb3f13db4d3714a6947dd5ec03665ffb14b8fb897ed6d70c57c I0118 17:19:55.252738 see_dat.go:36 306,4399c2600000000 offset 36401146040 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:54:05.586600235 +0000 UTC name I0118 17:19:55.252743 see_dat.go:36 306,4399e8db1cc520c offset 36401146072 size 252(252 B) cookie b1cc520c appendedAt 2024-01-18 14:54:50.818452669 +0000 UTC name a545ec2b712248b713dd0809b0f0f3c6a0a9ab06d70ec63fe92c040306ddf298 I0118 17:19:55.252748 see_dat.go:36 306,4399e8d00000000 offset 36401146360 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:54:51.548502345 +0000 UTC name I0118 17:19:55.252754 see_dat.go:36 306,43995f000000000 offset 36401146392 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:55:01.108295529 +0000 UTC name I0118 17:19:55.253196 see_dat.go:36 306,4399f87a11a3e9e offset 36401146424 size 724590(707.61 KiB) cookie a11a3e9e appendedAt 2024-01-18 14:55:05.17607127 +0000 UTC name 4a3d808ee6f64151b36abe02c8a0919b I0118 17:19:55.253206 see_dat.go:36 306,439a04cda07a19d offset 36401871048 size 252(252 B) cookie da07a19d appendedAt 2024-01-18 14:55:37.454432036 +0000 UTC name 003c2de07140beb740ab651098e4e1e262be50a94b35343817ecb1e08b0e459d I0118 17:19:55.253211 see_dat.go:36 306,439a04c00000000 offset 36401871336 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:55:38.121968313 +0000 UTC name I0118 17:19:55.253290 see_dat.go:36 306,439a2a7836ec5ab offset 36401871368 size 123465(120.57 KiB) cookie 836ec5ab appendedAt 2024-01-18 14:56:25.761167843 +0000 UTC name 7307fed6f96351ce491103a221057379  see_idx:  key:3be065a offset:1 size:218039(212.93 KiB) key:3be0664 offset:27260 size:110095(107.51 KiB) key:3be07f1 offset:41026 size:253(253 B) key:3be0808 offset:41062 size:254(254 B) key:3be0957 offset:41098 size:251031(245.15 KiB) key:3be098f offset:72481 size:346730(338.60 KiB) key:3be09c0 offset:115826 size:225906(220.61 KiB) key:3be09e0 offset:144068 size:2859942(2.73 MiB) key:4233e58 offset:4295326677 size:67674641(64.54 MiB) key:3be09e5 offset:501565 size:1086836(1.04 MiB) key:3be09f2 offset:637424 size:486862(475.45 KiB) key:3be0a36 offset:698286 size:1790019(1.71 MiB) key:3be0a76 offset:922042 size:340148(332.18 KiB) key:3be0ab0 offset:964565 size:310668(303.39 KiB) key:3be0b88 offset:1003403 size:445387(434.95 KiB) key:3be0dbb offset:1059080 size:114077(111.40 KiB) key:3be0e01 offset:1073344 size:47581(46.47 KiB) key:3be0eb6 offset:1079296 size:690062(673.89 KiB)    key:43433d6 offset:4472615086 size:-1(16.00 EiB) key:4343402 offset:4472615090 size:274801(268.36 KiB) key:4343404 offset:4472649444 size:336767(328.87 KiB) key:4343402 offset:4472691544 size:-1(16.00 EiB) key:434340a offset:4472691548 size:253(253 B) key:434340a offset:4472691584 size:-1(16.00 EiB) key:4343410 offset:4472691588 size:251(251 B) key:4343410 offset:4472691623 size:-1(16.00 EiB) key:43435bc offset:4472691627 size:245(245 B) key:43435bc offset:4472691662 size:-1(16.00 EiB) key:4343799 offset:4472691666 size:244(244 B) key:4343799 offset:4472691701 size:-1(16.00 EiB) key:4343887 offset:4472691705 size:251(251 B) key:4343887 offset:4472691740 size:-1(16.00 EiB) key:43438a3 offset:4472691744 size:252(252 B) key:43438a3 offset:4472691780 size:-1(16.00 EiB) key:43438a9 offset:4472691784 size:4123346(3.93 MiB) key:4343a67 offset:4474721613 size:114485(111.80 KiB) key:434726d offset:4482289300 size:252(252 B) key:434726d offset:4482289336 size:-1(16.00 EiB) key:4364eda offset:4504522240 size:379472(370.58 KiB) key:4364f78 offset:4504569678 size:379472(370.58 KiB) key:436527a offset:4504720805 size:-1(16.00 EiB) key:4365286 offset:4504720809 size:85472(83.47 KiB) key:4369191 offset:4508617246 size:472906(461.82 KiB) key:43691a1 offset:4508676363 size:472906(461.82 KiB) key:4376320 offset:4518510784 size:85472(83.47 KiB) key:437631a offset:4518521472 size:-1(16.00 EiB) key:437b166 offset:4520992472 size:251(251 B) key:437b21c offset:4521004631 size:347246(339.11 KiB) key:438983c offset:4533947215 size:-1(16.00 EiB) key:438983a offset:4533947219 size:-1(16.00 EiB) key:4389a41 offset:4533947223 size:252(252 B) key:4389a4b offset:4533947259 size:543810(531.06 KiB) key:438f434 offset:4538439670 size:483424(472.09 KiB) key:4395f7d offset:4546322526 size:257472(251.44 KiB) key:4395fb0 offset:4546394868 size:257472(251.44 KiB) key:4397c55 offset:4547223657 size:-1(16.00 EiB) key:4397c79 offset:4547223661 size:251(251 B) key:4397c79 offset:4547223696 size:-1(16.00 EiB) key:4397e4d offset:4547223700 size:2321015(2.21 MiB)  **System Setup**  updated from 3.59 to 3.62 ",source-file | source-file,"[volume] error reading newly written files after vacuum and data loss (Critical) **Describe the bug** error reading newly written files after vacuum:  Jan 17, 2024 @ 17:36:38.738 I0117 12:36:09.943514 needle_map_memory.go:111 loading idx from offset 0 for file: /data/bucket_306.cpx Jan 17, 2024 @ 17:36:38.738 I0117 12:36:23.346201 volume_loading.go:139 updating memory compact index /data/bucket_306.idx Jan 17, 2024 @ 17:36:38.738 W0117 12:36:23.066922 volume_checking.go:121 Truncate /data/bucket_306.dat from 38649746072 bytes to 34362613416 bytes! Jan 17, 2024 @ 17:36:43.709 W0117 12:36:23.066922 volume_checking.go:121 Truncate /data/bucket_306.dat from 38649746072 bytes to 34362613416 bytes! Jan 17, 2024 @ 19:35:10.120 E0117 14:35:03.562706 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:07.184218 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 472 offset 36492488624 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:05.063442 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:06.182941 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 472 offset 36492488624 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:02.562017 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495144: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:06.182941 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 472 offset 36492488624 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:07.314882 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:07.184218 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 472 offset 36492488624 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:02.562017 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495144: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:03.562706 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF Jan 17, 2024 @ 19:35:10.120 E0117 14:35:05.063442 needle_read.go:45 /data/bucket_306.dat read 0 dataSize 11776 offset 34843571792 fileSize 34562495176: EOF  see_dat:  I0118 17:19:01.605226 volume_loading.go:91 readSuperBlock volume 306 version 3 I0118 17:19:01.605599 see_dat.go:36 306,3be065a31ce6043 offset 8 size 218039(212.93 KiB) cookie 31ce6043 appendedAt 2023-12-27 03:21:39.531516313 +0000 UTC name a5361c29c3d12558bf147154a0eeb637 I0118 17:19:01.605694 see_dat.go:36 306,3be0664820cc0f4 offset 218080 size 110095(107.51 KiB) cookie 820cc0f4 appendedAt 2023-12-27 03:21:39.764625178 +0000 UTC name 4893287b8807871151ea786088c16ba0 I0118 17:19:01.605703 see_dat.go:36 306,3be07f1bb8175cf offset 328208 size 253(253 B) cookie bb8175cf appendedAt 2023-12-27 03:25:13.798546319 +0000 UTC name 7b065779f740338386666811c989ae4d902c25aa20a00fd0b4e8b228e6485bbb I0118 17:19:01.605708 see_dat.go:36 306,3be0808b18ddff9 offset 328496 size 254(254 B) cookie b18ddff9 appendedAt 2023-12-27 03:25:13.822058588 +0000 UTC name f61f70cc01380eb3027d2975014f8e6bfd7908852db9ed76f77038a4b34a547d I0118 17:19:01.605894 see_dat.go:36 306,3be0957d6e0bbb3 offset 328784 size 251031(245.15 KiB) cookie d6e0bbb3 appendedAt 2023-12-27 03:26:32.22218443 +0000 UTC name efd741888c821015350dfe2785ccbf5f    I0118 17:19:51.584695 see_dat.go:36 306,423263c31ad67f7 offset 34077050288 size 389241(380.12 KiB) cookie 31ad67f7 appendedAt 2024-01-16 02:20:42.286250838 +0000 UTC name d2e970d816b80be6b3b61abc6e4564c9 I0118 17:19:51.584785 see_dat.go:36 306,42327970e1e3d89 offset 34077439560 size 286349(279.64 KiB) cookie 0e1e3d89 appendedAt 2024-01-16 02:23:14.442319209 +0000 UTC name 7eeeda111e6022010c28ac49b6e6d3b5 I0118 17:19:51.584860 see_dat.go:36 306,42329de681c74af offset 34077725944 size 256625(250.61 KiB) cookie 681c74af appendedAt 2024-01-16 02:29:00.061529669 +0000 UTC name 20c257e0e18a70967ac03801bcfa6075 I0118 17:19:51.584956 see_dat.go:36 306,42329e136fad834 offset 34077982600 size 345261(337.17 KiB) cookie 36fad834 appendedAt 2024-01-16 02:29:00.598741247 +0000 UTC name c6be0777abd05f1c0fbfd1396a779f0a I0118 17:19:51.588317 see_dat.go:36 306,4232a02cfa067d6 offset 34078327896 size 461841(451.02 KiB) cookie cfa067d6 appendedAt 2024-01-16 02:29:23.338838951 +0000 UTC name d47917d3a6276b48fd38613380073a40 I0118 17:19:51.591132 see_dat.go:36 306,4232b47e9cf68be offset 34078789768 size 2192349(2.09 MiB) cookie e9cf68be appendedAt 2024-01-16 02:31:22.359343585 +0000 UTC name d97c1fbe57c9dc239359bb68a8225b35 I0118 17:19:51.591298 see_dat.go:36 306,4232b7afbd1ec71 offset 34080982152 size 492125(480.59 KiB) cookie fbd1ec71 appendedAt 2024-01-16 02:32:02.543454623 +0000 UTC name 669426d66303f2e080fd5f6d36731f4e I0118 17:19:51.591497 see_dat.go:36 306,4232e0fe9713c90 offset 34081474312 size 698314(681.95 KiB) cookie e9713c90 appendedAt 2024-01-16 02:37:32.579458075 +0000 UTC name 910af7dd4f47507862ac70d6ca90368e I0118 17:19:51.591570 see_dat.go:36 306,42331dec4f98764 offset 34082172656 size 239968(234.34 KiB) cookie c4f98764 appendedAt 2024-01-16 02:43:36.040863561 +0000 UTC name 84ac94ff17ffc829036e2da75f908894 I0118 17:19:51.594942 see_dat.go:36 306,42332a43d012ab1 offset 34082412656 size 345832(337.73 KiB) cookie 3d012ab1 appendedAt 2024-01-16 02:45:23.574424616 +0000 UTC name 06a46b042d543245677182316a0b3673 I0118 17:19:51.595044 see_dat.go:36 306,4233393a7ab8bb7 offset 34082758520 size 274304(267.88 KiB) cookie a7ab8bb7 appendedAt 2024-01-16 02:48:01.008616274 +0000 UTC name fbd6b45d7249aac0f838610ebdaf75d4 I0118 17:19:51.598048 see_dat.go:36 306,42333ed43de8834 offset 34083032856 size 3238884(3.09 MiB) cookie 43de8834 appendedAt 2024-01-16 02:48:08.078079171 +0000 UTC name 494f5451c895d45b55563fb94b69fe3d I0118 17:19:51.602139 see_dat.go:36 306,4233b443bb21870 offset 34086271776 size 2250399(2.15 MiB) cookie 3bb21870 appendedAt 2024-01-16 03:02:17.884903798 +0000 UTC name 6fb3625d7edece05f4c73f273302e2a1 I0118 17:19:51.602199 see_dat.go:36 306,4233bd9bf06484e offset 34088522208 size 39143(38.23 KiB) cookie bf06484e appendedAt 2024-01-16 03:03:17.420516551 +0000 UTC name 1a25ac95357ff4b85813221d69bf6148 I0118 17:19:51.602240 see_dat.go:36 306,4233d0939a889fc offset 34088561384 size 130893(127.83 KiB) cookie 39a889fc appendedAt 2024-01-16 03:04:23.765892237 +0000 UTC name 21bf67f5671d08dc6c159521dc4c5aa4 I0118 17:19:51.716505 see_dat.go:36 306,4233d6e631a8505 offset 34088692312 size 67275322(64.16 MiB) cookie 631a8505 appendedAt 2024-01-16 03:05:25.717942952 +0000 UTC name 867ac9ff99498f57daacf4700fb11236b532d69d50090063dd0 8809662f90197 I0118 17:19:51.833313 see_dat.go:36 306,4233d7db25cebf7 offset 34155967664 size 67620533(64.49 MiB) cookie b25cebf7 appendedAt 2024-01-16 03:05:27.848121402 +0000 UTC name fda1281b282d90e79371e81b1add23dea1d7433864f6a0236cb 9a62889f4b839 I0118 17:19:51.833421 see_dat.go:36 306,4233d813cdd3be1 offset 34223588232 size 232732(227.28 KiB) cookie 3cdd3be1 appendedAt 2024-01-16 03:05:28.49008878 +0000 UTC name a57041428492630f805b6c5df50b1ef9 I0118 17:19:51.947632 see_dat.go:36 306,4233da2b99907c5 offset 34223821000 size 68226599(65.07 MiB) cookie b99907c5 appendedAt 2024-01-16 03:05:41.411330528 +0000 UTC name 0216e4a416f2c135cafc2fcf3967cf93f9855df08591a81dc55 d99cc765b91ef I0118 17:19:52.068052 see_dat.go:36 306,4233e1651ee5124 offset 34292047632 size 70565753(67.30 MiB) cookie 51ee5124 appendedAt 2024-01-16 03:06:06.302138326 +0000 UTC name 2ee2ce4b73522ef28ec2ed4599338a85fa142fc7b6019d90835 d7bee2ec866a5 I0118 17:19:52.068370 see_dat.go:36 306,42de1dc2d23c7ac offset 34362613416 size 434780(424.59 KiB) cookie 2d23c7ac appendedAt 2024-01-17 12:37:18.747566921 +0000 UTC name 2a6306dc58904c51d15667e789c40d5f I0118 17:19:52.068518 see_dat.go:36 306,42de1f613571038 offset 34363048232 size 218979(213.85 KiB) cookie 13571038 appendedAt 2024-01-17 12:37:20.540658568 +0000 UTC name 11176434e8eedf3a6d9d28d2b0f51195 I0118 17:19:52.068528 see_dat.go:36 306,42de470b7c2e2a1 offset 34363267240 size 251(251 B) cookie b7c2e2a1 appendedAt 2024-01-17 12:37:39.390146706 +0000 UTC name 0c92dfafd10a0589b9dfac17845c3a438dda40bc1d92f8886bef31d0a5e4 d529 I0118 17:19:52.068534 see_dat.go:36 306,42de47000000000 offset 34363267520 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:37:40.050513736 +0000 UTC name I0118 17:19:52.068540 see_dat.go:36 306,42de4fd90f50a74 offset 34363267552 size 254(254 B) cookie 90f50a74 appendedAt 2024-01-17 12:37:50.956080809 +0000 UTC name ea34980c7ebefe5c0dec49223cf528e6cfa5ea7ec161c98df3a8c1fefda1 4be5 I0118 17:19:52.068545 see_dat.go:36 306,42de4fd00000000 offset 34363267840 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:37:51.191687807 +0000 UTC name I0118 17:19:52.068551 see_dat.go:36 306,42deaf0bfdbf5c4 offset 34363267872 size 252(252 B) cookie bfdbf5c4 appendedAt 2024-01-17 12:39:25.833348754 +0000 UTC name cbcbe63e7180d0eabbd32b2be0633580c07672fb8ef79b43c8fd413f836c 4b93 I0118 17:19:52.068556 see_dat.go:36 306,42deaf000000000 offset 34363268160 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:39:26.049790231 +0000 UTC name I0118 17:19:52.068561 see_dat.go:36 306,42deb95c53273e6 offset 34363268192 size 252(252 B) cookie c53273e6 appendedAt 2024-01-17 12:39:42.531562106 +0000 UTC name 547e3bbea07e1fefcd86a9cadc9bd24da1f27a4a6e74307d906ba0a1d833 ed2d I0118 17:19:52.068567 see_dat.go:36 306,42deb9500000000 offset 34363268480 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:39:43.116128478 +0000 UTC name I0118 17:19:52.068808 see_dat.go:36 306,42ded9d5d7aae3e offset 34363268512 size 381508(372.57 KiB) cookie 5d7aae3e appendedAt 2024-01-17 12:40:01.414961987 +0000 UTC name 382a98788822934414f53684bac5a812 I0118 17:19:52.070763 see_dat.go:36 306,42dedb5cae2e24f offset 34363650056 size 2804355(2.67 MiB) cookie cae2e24f appendedAt 2024-01-17 12:40:03.189488243 +0000 UTC name 14c4a0bc6cdb0012a14fb0506185ab04 I0118 17:19:52.070786 see_dat.go:36 306,42dedb500000000 offset 34366454440 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:40:05.407735232 +0000 UTC name I0118 17:19:52.074318 see_dat.go:36 306,42df0264d13ae03 offset 34366454472 size 2481497(2.37 MiB) cookie 4d13ae03 appendedAt 2024-01-17 12:41:28.060904874 +0000 UTC name 2d032ef7043c1c4144da7cbd725c0c3b I0118 17:19:52.074349 see_dat.go:36 306,42df02600000000 offset 34368936000 size 0(0 B) cookie 00000000 appendedAt 2024-01-17 12:41:29.544656561 +0000 UTC name I0118 17:19:52.074357 see_dat.go:36 306,42df0eb621915b4 offset 34368936032 size 252(252 B) cookie 621915b4 appendedAt 2024-01-17 12:41:49.582088965 +0000 UTC name 8bf5b1562004570ed7f760fe8baec743a88dd1b34c83663f69727a744d80 4193    I0118 17:19:55.251030 see_dat.go:36 306,43997a700000000 offset 36399211784 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:50:49.23505557 +0000 UTC name I0118 17:19:55.251170 see_dat.go:36 306,43997d12d642169 offset 36399211816 size 203965(199.18 KiB) cookie 2d642169 appendedAt 2024-01-18 14:50:49.681077901 +0000 UTC name e58f69125538e2009760ac37a3594f46 I0118 17:19:55.251177 see_dat.go:36 306,43997d100000000 offset 36399415816 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:50:50.173978636 +0000 UTC name I0118 17:19:55.251375 see_dat.go:36 306,43999669edbc06f offset 36399415848 size 315035(307.65 KiB) cookie 9edbc06f appendedAt 2024-01-18 14:52:01.686168611 +0000 UTC name 8bb382c777837219039457e9547e3497 I0118 17:19:55.251390 see_dat.go:36 306,43999f52df61bd6 offset 36399730912 size 20919(20.43 KiB) cookie 2df61bd6 appendedAt 2024-01-18 14:52:32.101891445 +0000 UTC name 82c7b1e1b772251d63b8232ad01c510a I0118 17:19:55.251396 see_dat.go:36 306,43999f500000000 offset 36399751864 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:52:33.29600673 +0000 UTC name I0118 17:19:55.251504 see_dat.go:36 306,4399bc0fa7db986 offset 36399751896 size 167961(164.02 KiB) cookie fa7db986 appendedAt 2024-01-18 14:53:25.570011368 +0000 UTC name 529a450cab92fcd9b219b51fc066c0ad I0118 17:19:55.251512 see_dat.go:36 306,4399bd06bb7ff0e offset 36399919888 size 251(251 B) cookie 6bb7ff0e appendedAt 2024-01-18 14:53:28.962604899 +0000 UTC name 325af1c78e57c6524ee2d8c4c42970ef7ad1706fdd3ff69a60002179fb0365b9 I0118 17:19:55.251517 see_dat.go:36 306,4399bd000000000 offset 36399920168 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:53:29.615904279 +0000 UTC name I0118 17:19:55.252385 see_dat.go:36 306,4399bfac6ba2f65 offset 36399920200 size 705624(689.09 KiB) cookie c6ba2f65 appendedAt 2024-01-18 14:53:44.833676382 +0000 UTC name 8f7c9cbcc224a08e570b99f303457f2e I0118 17:19:55.252715 see_dat.go:36 306,4399c16d2e063b4 offset 36400625856 size 519835(507.65 KiB) cookie d2e063b4 appendedAt 2024-01-18 14:54:00.491714658 +0000 UTC name 54b6534f0c7e8ad282bc0c89106ce31f I0118 17:19:55.252724 see_dat.go:36 306,4399c1600000000 offset 36401145720 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:54:02.264603775 +0000 UTC name I0118 17:19:55.252732 see_dat.go:36 306,4399c26600a7ae5 offset 36401145752 size 252(252 B) cookie 600a7ae5 appendedAt 2024-01-18 14:54:05.3725053 +0000 UTC name 602ed288f155efb3f13db4d3714a6947dd5ec03665ffb14b8fb897ed6d70c57c I0118 17:19:55.252738 see_dat.go:36 306,4399c2600000000 offset 36401146040 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:54:05.586600235 +0000 UTC name I0118 17:19:55.252743 see_dat.go:36 306,4399e8db1cc520c offset 36401146072 size 252(252 B) cookie b1cc520c appendedAt 2024-01-18 14:54:50.818452669 +0000 UTC name a545ec2b712248b713dd0809b0f0f3c6a0a9ab06d70ec63fe92c040306ddf298 I0118 17:19:55.252748 see_dat.go:36 306,4399e8d00000000 offset 36401146360 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:54:51.548502345 +0000 UTC name I0118 17:19:55.252754 see_dat.go:36 306,43995f000000000 offset 36401146392 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:55:01.108295529 +0000 UTC name I0118 17:19:55.253196 see_dat.go:36 306,4399f87a11a3e9e offset 36401146424 size 724590(707.61 KiB) cookie a11a3e9e appendedAt 2024-01-18 14:55:05.17607127 +0000 UTC name 4a3d808ee6f64151b36abe02c8a0919b I0118 17:19:55.253206 see_dat.go:36 306,439a04cda07a19d offset 36401871048 size 252(252 B) cookie da07a19d appendedAt 2024-01-18 14:55:37.454432036 +0000 UTC name 003c2de07140beb740ab651098e4e1e262be50a94b35343817ecb1e08b0e459d I0118 17:19:55.253211 see_dat.go:36 306,439a04c00000000 offset 36401871336 size 0(0 B) cookie 00000000 appendedAt 2024-01-18 14:55:38.121968313 +0000 UTC name I0118 17:19:55.253290 see_dat.go:36 306,439a2a7836ec5ab offset 36401871368 size 123465(120.57 KiB) cookie 836ec5ab appendedAt 2024-01-18 14:56:25.761167843 +0000 UTC name 7307fed6f96351ce491103a221057379  see_idx:  key:3be065a offset:1 size:218039(212.93 KiB) key:3be0664 offset:27260 size:110095(107.51 KiB) key:3be07f1 offset:41026 size:253(253 B) key:3be0808 offset:41062 size:254(254 B) key:3be0957 offset:41098 size:251031(245.15 KiB) key:3be098f offset:72481 size:346730(338.60 KiB) key:3be09c0 offset:115826 size:225906(220.61 KiB) key:3be09e0 offset:144068 size:2859942(2.73 MiB) key:4233e58 offset:4295326677 size:67674641(64.54 MiB) key:3be09e5 offset:501565 size:1086836(1.04 MiB) key:3be09f2 offset:637424 size:486862(475.45 KiB) key:3be0a36 offset:698286 size:1790019(1.71 MiB) key:3be0a76 offset:922042 size:340148(332.18 KiB) key:3be0ab0 offset:964565 size:310668(303.39 KiB) key:3be0b88 offset:1003403 size:445387(434.95 KiB) key:3be0dbb offset:1059080 size:114077(111.40 KiB) key:3be0e01 offset:1073344 size:47581(46.47 KiB) key:3be0eb6 offset:1079296 size:690062(673.89 KiB)    key:43433d6 offset:4472615086 size:-1(16.00 EiB) key:4343402 offset:4472615090 size:274801(268.36 KiB) key:4343404 offset:4472649444 size:336767(328.87 KiB) key:4343402 offset:4472691544 size:-1(16.00 EiB) key:434340a offset:4472691548 size:253(253 B) key:434340a offset:4472691584 size:-1(16.00 EiB) key:4343410 offset:4472691588 size:251(251 B) key:4343410 offset:4472691623 size:-1(16.00 EiB) key:43435bc offset:4472691627 size:245(245 B) key:43435bc offset:4472691662 size:-1(16.00 EiB) key:4343799 offset:4472691666 size:244(244 B) key:4343799 offset:4472691701 size:-1(16.00 EiB) key:4343887 offset:4472691705 size:251(251 B) key:4343887 offset:4472691740 size:-1(16.00 EiB) key:43438a3 offset:4472691744 size:252(252 B) key:43438a3 offset:4472691780 size:-1(16.00 EiB) key:43438a9 offset:4472691784 size:4123346(3.93 MiB) key:4343a67 offset:4474721613 size:114485(111.80 KiB) key:434726d offset:4482289300 size:252(252 B) key:434726d offset:4482289336 size:-1(16.00 EiB) key:4364eda offset:4504522240 size:379472(370.58 KiB) key:4364f78 offset:4504569678 size:379472(370.58 KiB) key:436527a offset:4504720805 size:-1(16.00 EiB) key:4365286 offset:4504720809 size:85472(83.47 KiB) key:4369191 offset:4508617246 size:472906(461.82 KiB) key:43691a1 offset:4508676363 size:472906(461.82 KiB) key:4376320 offset:4518510784 size:85472(83.47 KiB) key:437631a offset:4518521472 size:-1(16.00 EiB) key:437b166 offset:4520992472 size:251(251 B) key:437b21c offset:4521004631 size:347246(339.11 KiB) key:438983c offset:4533947215 size:-1(16.00 EiB) key:438983a offset:4533947219 size:-1(16.00 EiB) key:4389a41 offset:4533947223 size:252(252 B) key:4389a4b offset:4533947259 size:543810(531.06 KiB) key:438f434 offset:4538439670 size:483424(472.09 KiB) key:4395f7d offset:4546322526 size:257472(251.44 KiB) key:4395fb0 offset:4546394868 size:257472(251.44 KiB) key:4397c55 offset:4547223657 size:-1(16.00 EiB) key:4397c79 offset:4547223661 size:251(251 B) key:4397c79 offset:4547223696 size:-1(16.00 EiB) key:4397e4d offset:4547223700 size:2321015(2.21 MiB)  **System Setup**  updated from 3.59 to 3.62  source-file source-file",no-bug,0.95
3479,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3479,sometimes weed mount crashed while copying files,"**Describe the bug** Seaweedfs server cluster work well all the time, and I used weed mount to mount filer to local directory, but sometimes weed mount crash while copying files continuously. **System Setup** - OS version Ubuntu 20.04.3 LTS - output of `weed version` version 8000GB 3.22 fa4d0093e17f710c3da00545022646cb96a6fd98 linux amd64 **Additional context** - my weed mount docker-compose.yml: ![image](https://user-images.githubusercontent.com/35862733/185836721-1d1dbb60-b898-4556-8248-e2c5d555fb9d.png) - weed mount logs:  seaweedfs-fuse-3.22 | I0822 11:17:06.204712 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 263: 2304,014813df79413fb4 [300,301) seaweedfs-fuse-3.22 | I0822 11:17:06.204722 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 264: 2361,014813e1f0b51c6f [301,302) seaweedfs-fuse-3.22 | I0822 11:17:06.204734 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 265: 2334,014813e668bccfa7 [304,305) seaweedfs-fuse-3.22 | I0822 11:17:06.204748 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 266: 2288,014813e734d407c3 [302,304) seaweedfs-fuse-3.22 | I0822 11:17:06.204759 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 267: 2297,014813ea88319f00 [305,306) seaweedfs-fuse-3.22 | I0822 11:17:06.204769 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 268: 2332,014813eb6a2a19b4 [306,307) seaweedfs-fuse-3.22 | I0822 11:17:06.204782 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 269: 2315,014813ed0aae3825 [307,308) seaweedfs-fuse-3.22 | I0822 11:17:06.204792 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 270: 2319,014813f1bc271cb1 [308,309) seaweedfs-fuse-3.22 | I0822 11:17:06.204802 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 271: 2316,014813f2b76da602 [310,311) seaweedfs-fuse-3.22 | I0822 11:17:06.204813 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 272: 2313,014813f30df0d8af [309,310) seaweedfs-fuse-3.22 | panic: runtime error: invalid memory address or nil pointer dereference seaweedfs-fuse-3.22 | [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1cd0b8a] seaweedfs-fuse-3.22 | seaweedfs-fuse-3.22 | goroutine 218 [running]: seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount/page_writer.(*SwapFileChunk).ReadDataAt(0xc0006a1220, {0xc001b82000, 0x1000, 0x1000}, 0x0) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/page_writer/page_chunk_swapfile.go:101 +0x8a seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount/page_writer.(*UploadPipeline).MaybeReadDataAt(0xc00073a100, {0xc001b82000, 0x1000, 0x1000}, 0x0) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/page_writer/upload_pipeline.go:106 +0x175 seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount.(*ChunkedDirtyPages).ReadDirtyDataAt(0x1000?, {0xc001b82000?, 0x235cb9b?, 0x1b?}, 0xc00186bd28?) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/dirty_pages_chunked.go:65 +0x28 seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount.(*PageWriter).ReadDirtyDataAt(0xc00cfed1d0, {0xc001b82000, 0x1000, 0x1000}, 0x0) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/page_writer.go:60 +0x202 seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount.(*FileHandle).readFromDirtyPages() seaweedfs-fuse-3.22 | /github/workspace/weed/mount/filehandle_read.go:20 seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).Read(0x47958e?, 0xc000320480?, 0xc000320618, {0xc001b82000, 0x1000, 0x1000}) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/weedfs_file_read.go:46 +0x1b0 seaweedfs-fuse-3.22 | github.com/hanwen/go-fuse/v2/fuse.doRead(0xc0002491e0, 0xc000320480) seaweedfs-fuse-3.22 | /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/opcode.go:374 +0x83 seaweedfs-fuse-3.22 | github.com/hanwen/go-fuse/v2/fuse.(*Server).handleRequest(0xc0002491e0, 0xc000320480) seaweedfs-fuse-3.22 | /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:514 +0x1f3 seaweedfs-fuse-3.22 | github.com/hanwen/go-fuse/v2/fuse.(*Server).loop(0xc0002491e0, 0x0?) seaweedfs-fuse-3.22 | /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:487 +0x108 seaweedfs-fuse-3.22 | created by github.com/hanwen/go-fuse/v2/fuse.(*Server).readRequest seaweedfs-fuse-3.22 | /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:354 +0x53e seaweedfs-fuse-3.22 exited with code 2 ",source-file | source-file,"sometimes weed mount crashed while copying files **Describe the bug** Seaweedfs server cluster work well all the time, and I used weed mount to mount filer to local directory, but sometimes weed mount crash while copying files continuously. **System Setup** - OS version Ubuntu 20.04.3 LTS - output of `weed version` version 8000GB 3.22 fa4d0093e17f710c3da00545022646cb96a6fd98 linux amd64 **Additional context** - my weed mount docker-compose.yml: ![image](https://user-images.githubusercontent.com/35862733/185836721-1d1dbb60-b898-4556-8248-e2c5d555fb9d.png) - weed mount logs:  seaweedfs-fuse-3.22 | I0822 11:17:06.204712 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 263: 2304,014813df79413fb4 [300,301) seaweedfs-fuse-3.22 | I0822 11:17:06.204722 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 264: 2361,014813e1f0b51c6f [301,302) seaweedfs-fuse-3.22 | I0822 11:17:06.204734 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 265: 2334,014813e668bccfa7 [304,305) seaweedfs-fuse-3.22 | I0822 11:17:06.204748 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 266: 2288,014813e734d407c3 [302,304) seaweedfs-fuse-3.22 | I0822 11:17:06.204759 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 267: 2297,014813ea88319f00 [305,306) seaweedfs-fuse-3.22 | I0822 11:17:06.204769 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 268: 2332,014813eb6a2a19b4 [306,307) seaweedfs-fuse-3.22 | I0822 11:17:06.204782 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 269: 2315,014813ed0aae3825 [307,308) seaweedfs-fuse-3.22 | I0822 11:17:06.204792 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 270: 2319,014813f1bc271cb1 [308,309) seaweedfs-fuse-3.22 | I0822 11:17:06.204802 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 271: 2316,014813f2b76da602 [310,311) seaweedfs-fuse-3.22 | I0822 11:17:06.204813 weedfs_file_sync.go:153 /data/sectionUploadVerify/983fe2e7c3d845369db6432c52b77e98/4d7ff4d592b48ca87ec79726f2be24a7/4d7ff4d592b48ca87ec79726f2be24a7.conf chunks 272: 2313,014813f30df0d8af [309,310) seaweedfs-fuse-3.22 | panic: runtime error: invalid memory address or nil pointer dereference seaweedfs-fuse-3.22 | [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x1cd0b8a] seaweedfs-fuse-3.22 | seaweedfs-fuse-3.22 | goroutine 218 [running]: seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount/page_writer.(*SwapFileChunk).ReadDataAt(0xc0006a1220, {0xc001b82000, 0x1000, 0x1000}, 0x0) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/page_writer/page_chunk_swapfile.go:101 +0x8a seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount/page_writer.(*UploadPipeline).MaybeReadDataAt(0xc00073a100, {0xc001b82000, 0x1000, 0x1000}, 0x0) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/page_writer/upload_pipeline.go:106 +0x175 seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount.(*ChunkedDirtyPages).ReadDirtyDataAt(0x1000?, {0xc001b82000?, 0x235cb9b?, 0x1b?}, 0xc00186bd28?) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/dirty_pages_chunked.go:65 +0x28 seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount.(*PageWriter).ReadDirtyDataAt(0xc00cfed1d0, {0xc001b82000, 0x1000, 0x1000}, 0x0) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/page_writer.go:60 +0x202 seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount.(*FileHandle).readFromDirtyPages() seaweedfs-fuse-3.22 | /github/workspace/weed/mount/filehandle_read.go:20 seaweedfs-fuse-3.22 | github.com/seaweedfs/seaweedfs/weed/mount.(*WFS).Read(0x47958e?, 0xc000320480?, 0xc000320618, {0xc001b82000, 0x1000, 0x1000}) seaweedfs-fuse-3.22 | /github/workspace/weed/mount/weedfs_file_read.go:46 +0x1b0 seaweedfs-fuse-3.22 | github.com/hanwen/go-fuse/v2/fuse.doRead(0xc0002491e0, 0xc000320480) seaweedfs-fuse-3.22 | /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/opcode.go:374 +0x83 seaweedfs-fuse-3.22 | github.com/hanwen/go-fuse/v2/fuse.(*Server).handleRequest(0xc0002491e0, 0xc000320480) seaweedfs-fuse-3.22 | /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:514 +0x1f3 seaweedfs-fuse-3.22 | github.com/hanwen/go-fuse/v2/fuse.(*Server).loop(0xc0002491e0, 0x0?) seaweedfs-fuse-3.22 | /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:487 +0x108 seaweedfs-fuse-3.22 | created by github.com/hanwen/go-fuse/v2/fuse.(*Server).readRequest seaweedfs-fuse-3.22 | /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:354 +0x53e seaweedfs-fuse-3.22 exited with code 2  source-file source-file",no-bug,0.9
978,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/978,weed mount,linux3.10.0-327.el7.x86_64CentOS Linux release 7.2.1511seaweedfs1.35; fusefuse-2.9.2-11.el7.x86_64 1. mastervolumefiler 2. filer 3. weed mountmount2chmodPermission deniedmount,source-file | source-file | source-file | source-file | source-file | source-file,weed mount linux3.10.0-327.el7.x86_64CentOS Linux release 7.2.1511seaweedfs1.35; fusefuse-2.9.2-11.el7.x86_64 1. mastervolumefiler 2. filer 3. weed mountmount2chmodPermission deniedmount source-file source-file source-file source-file source-file source-file,no-bug,0.9
5864,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5864,"[webdav] When the webdav service stops, a 404 is returned for an existing file","**Describe the bug** When the webdav service stops, a 404 is returned for an existing file **System Setup** `3.71` **Expected behavior** Returning always 200 or return nothing **Additional context**  1. make server with -webdav option 2. while true; do curl -sI ""http://127.0.0.1:7333/buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd"" | grep HTTP; done 3. Crtl+C stop server 4. Got HTTP/1.1 200 OK HTTP/1.1 404 Not Found  logs:  I0806 14:38:20.436016 filer_grpc_server.go:31 LookupDirectoryEntry /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd: get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed, I0806 14:38:20.436090 filer_pb_helper.go:139 read /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd: rpc error: code = Unknown desc = get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed I0806 14:38:20.436096 filer_client.go:42 read /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd <nil>: LookupEntry1: rpc error: code = Unknown desc = get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed ",source-file,"[webdav] When the webdav service stops, a 404 is returned for an existing file **Describe the bug** When the webdav service stops, a 404 is returned for an existing file **System Setup** `3.71` **Expected behavior** Returning always 200 or return nothing **Additional context**  1. make server with -webdav option 2. while true; do curl -sI ""http://127.0.0.1:7333/buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd"" | grep HTTP; done 3. Crtl+C stop server 4. Got HTTP/1.1 200 OK HTTP/1.1 404 Not Found  logs:  I0806 14:38:20.436016 filer_grpc_server.go:31 LookupDirectoryEntry /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd: get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed, I0806 14:38:20.436090 filer_pb_helper.go:139 read /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd: rpc error: code = Unknown desc = get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed I0806 14:38:20.436096 filer_client.go:42 read /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd <nil>: LookupEntry1: rpc error: code = Unknown desc = get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed  source-file",bug,0.9
1552,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1552,[Feature Request] Enhance volume.fsck to allow for finding lost files,"As part of my testing of Disaster Recovery and redundancy, I've managed to end up with a handful of lost files.  > volume.fsck volume:7 entries:1787 orphan:2 0.11% 120B volume:6 entries:1839 orphan:1 0.05% 60B volume:3 entries:1769 orphan:2 0.11% 120B volume:1 entries:65 orphan:7 10.77% 334153B volume:4 entries:1771 orphan:1 0.06% 60B volume:2 entries:1786 orphan:4 0.22% 240B volume:5 entries:1843 orphan:2 0.11% 120B Total entries:56849 orphan:19 0.03% 334873B  There doesn't appear to be any way to get a list of those orphan files from the volume. I am thinking that this would be useful if someone created a new filer, saved a file to a volume, and then deleted the filer, losing the metadata. The admin could then consolidate all the IDs from the known filer(s) and then figure out which ones are REALLY orphan to assist in data recovery.",source-file,"[Feature Request] Enhance volume.fsck to allow for finding lost files As part of my testing of Disaster Recovery and redundancy, I've managed to end up with a handful of lost files.  > volume.fsck volume:7 entries:1787 orphan:2 0.11% 120B volume:6 entries:1839 orphan:1 0.05% 60B volume:3 entries:1769 orphan:2 0.11% 120B volume:1 entries:65 orphan:7 10.77% 334153B volume:4 entries:1771 orphan:1 0.06% 60B volume:2 entries:1786 orphan:4 0.22% 240B volume:5 entries:1843 orphan:2 0.11% 120B Total entries:56849 orphan:19 0.03% 334873B  There doesn't appear to be any way to get a list of those orphan files from the volume. I am thinking that this would be useful if someone created a new filer, saved a file to a volume, and then deleted the filer, losing the metadata. The admin could then consolidate all the IDs from the known filer(s) and then figure out which ones are REALLY orphan to assist in data recovery. source-file",no-bug,0.95
717,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/717,Invalid memory address or nil pointer dereference,"Hi, When starting SeaweedFS using pre-built binary (**v0.94 linux_386**) on _Ubuntu Xenial_, it ends with an `invalid memory address or nil pointer dereference` error. **Describe the bug**  $ weed server -dir=/data I0829 12:37:52 9413 file_util.go:20] Folder /data Permission: -rwxr-xr-x I0829 12:37:52 9413 file_util.go:20] Folder /data Permission: -rwxr-xr-x I0829 12:37:52 9413 master_server.go:68] Volume Size Limit is 30000 MB I0829 12:37:52 9413 server.go:186] Start Seaweed Master 0.94 at localhost:9333 I0829 12:37:52 9413 raft_server.go:47] Starting RaftServer with localhost:9333 I0829 12:37:52 9413 raft_server.go:51] Peers Change: [] => [] I0829 12:37:54 9413 raft_server.go:75] Initializing new cluster I0829 12:37:54 9413 raft_server.go:83] raft: Has been stopped panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0xc0f163] goroutine 25 [running]: github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).SetRaftServer(0xc0001dab40, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/master_server.go:95 +0x43 github.com/chrislusf/seaweedfs/weed/command.runServer.func2.1(0xc000192af0, 0xc000263dc0, 0xc0001dab40, 0xc000192b00) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/server.go:197 +0x10c created by github.com/chrislusf/seaweedfs/weed/command.runServer.func2 /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/server.go:192 +0x407  **System Setup** `$ weed server -dir=/data` **Expected behavior** Expecting `seaweed` to start properly **Additional context**  OS: Ubuntu 16.04.4 LTS Kernel: 4.4.0-1049-aws Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 2 On-line CPU(s) list: 0,1 Thread(s) per core: 1 Core(s) per socket: 2 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 63 Model name: Intel(R) Xeon(R) CPU E5-2676 v3 @ 2.40GHz Stepping: 2 CPU MHz: 2400.038 BogoMIPS: 4800.07 Hypervisor vendor: Xen Virtualization type: full L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 30720K NUMA node0 CPU(s): 0,1 ",source-file,"Invalid memory address or nil pointer dereference Hi, When starting SeaweedFS using pre-built binary (**v0.94 linux_386**) on _Ubuntu Xenial_, it ends with an `invalid memory address or nil pointer dereference` error. **Describe the bug**  $ weed server -dir=/data I0829 12:37:52 9413 file_util.go:20] Folder /data Permission: -rwxr-xr-x I0829 12:37:52 9413 file_util.go:20] Folder /data Permission: -rwxr-xr-x I0829 12:37:52 9413 master_server.go:68] Volume Size Limit is 30000 MB I0829 12:37:52 9413 server.go:186] Start Seaweed Master 0.94 at localhost:9333 I0829 12:37:52 9413 raft_server.go:47] Starting RaftServer with localhost:9333 I0829 12:37:52 9413 raft_server.go:51] Peers Change: [] => [] I0829 12:37:54 9413 raft_server.go:75] Initializing new cluster I0829 12:37:54 9413 raft_server.go:83] raft: Has been stopped panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0xc0f163] goroutine 25 [running]: github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).SetRaftServer(0xc0001dab40, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/master_server.go:95 +0x43 github.com/chrislusf/seaweedfs/weed/command.runServer.func2.1(0xc000192af0, 0xc000263dc0, 0xc0001dab40, 0xc000192b00) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/server.go:197 +0x10c created by github.com/chrislusf/seaweedfs/weed/command.runServer.func2 /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/server.go:192 +0x407  **System Setup** `$ weed server -dir=/data` **Expected behavior** Expecting `seaweed` to start properly **Additional context**  OS: Ubuntu 16.04.4 LTS Kernel: 4.4.0-1049-aws Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 2 On-line CPU(s) list: 0,1 Thread(s) per core: 1 Core(s) per socket: 2 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 63 Model name: Intel(R) Xeon(R) CPU E5-2676 v3 @ 2.40GHz Stepping: 2 CPU MHz: 2400.038 BogoMIPS: 4800.07 Hypervisor vendor: Xen Virtualization type: full L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 30720K NUMA node0 CPU(s): 0,1  source-file",no-bug,0.9
1453,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1453,Can we seaweed be deployed more simple,"Hi, in productive,weed need another etcd-cluster to generate sequence number which based on raft, and weed master is also implemented with raft, can weed generate numbers only using master.",source-file,"Can we seaweed be deployed more simple Hi, in productive,weed need another etcd-cluster to generate sequence number which based on raft, and weed master is also implemented with raft, can weed generate numbers only using master. source-file",no-bug,0.9
5195,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5195,[filer_sync] DATA RACE AddSyncJob,"**Describe the bug** steps:  make 2mount CGO_ENABLED=1 go build -race ./weed -v=4 filer.sync -a=127.0.0.1:8888 -b=127.0.0.1:7888 -a.debug -b.debug docker exec -it seaweedfs-mount1-1 sh -c ""for i in $(seq 1 100); do echo ""test$i"" > /mnt/test_$i & done""  trace:  WARNING: DATA RACE Write at 0x00c00013e660 by goroutine 119: github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.genProcessFunction.func4() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:446 +0x718 github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:270 +0x198 github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).AddSyncJob.func1.1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:45 +0x50 github.com/seaweedfs/seaweedfs/weed/util.Retry() /Users/whitefox/GolandProjects/seaweedfs/weed/util/retry.go:16 +0xa0 github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).AddSyncJob.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:44 +0x6c Previous read at 0x00c00013e660 by goroutine 71: github.com/seaweedfs/seaweedfs/weed/pb/filer_pb.IsUpdate() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb/filer_pb_helper.go:161 +0x490 github.com/seaweedfs/seaweedfs/weed/command.extractPathsFromMetadata() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:139 +0x57c github.com/seaweedfs/seaweedfs/weed/command.shouldWaitFor() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:86 +0x4c github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).conflictsWith() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:75 +0x1f4 github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).AddSyncJob() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:38 +0x11c github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.func2() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:281 +0x34 github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.AddOffsetFunc.func5() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:112 +0x5c github.com/seaweedfs/seaweedfs/weed/pb.FollowMetadata.makeSubscribeMetadataFunc.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:86 +0x4f0 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:262 +0x94 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:155 +0x2a0 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:260 +0x9c github.com/seaweedfs/seaweedfs/weed/pb.WithFilerClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:254 +0x8c github.com/seaweedfs/seaweedfs/weed/pb.FollowMetadata() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:41 +0x3c github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:306 +0xa0c github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:154 +0x5e8 Goroutine 119 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).AddSyncJob() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:42 +0x314 github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.func2() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:281 +0x34 github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.AddOffsetFunc.func5() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:112 +0x5c github.com/seaweedfs/seaweedfs/weed/pb.FollowMetadata.makeSubscribeMetadataFunc.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:86 +0x4f0 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:262 +0x94 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:155 +0x2a0 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:260 +0x9c github.com/seaweedfs/seaweedfs/weed/pb.WithFilerClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:254 +0x8c github.com/seaweedfs/seaweedfs/weed/pb.FollowMetadata() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:41 +0x3c github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:306 +0xa0c github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:154 +0x5e8 Goroutine 71 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:144 +0x54c main.main() /Users/whitefox/GolandProjects/seaweedfs/weed/weed.go:80 +0x73c   **System Setup**  master branch ",config-file | source-file | source-file | source-file | source-file | config-file | source-file | source-file | source-file | source-file,"[filer_sync] DATA RACE AddSyncJob **Describe the bug** steps:  make 2mount CGO_ENABLED=1 go build -race ./weed -v=4 filer.sync -a=127.0.0.1:8888 -b=127.0.0.1:7888 -a.debug -b.debug docker exec -it seaweedfs-mount1-1 sh -c ""for i in $(seq 1 100); do echo ""test$i"" > /mnt/test_$i & done""  trace:  WARNING: DATA RACE Write at 0x00c00013e660 by goroutine 119: github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.genProcessFunction.func4() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:446 +0x718 github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:270 +0x198 github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).AddSyncJob.func1.1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:45 +0x50 github.com/seaweedfs/seaweedfs/weed/util.Retry() /Users/whitefox/GolandProjects/seaweedfs/weed/util/retry.go:16 +0xa0 github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).AddSyncJob.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:44 +0x6c Previous read at 0x00c00013e660 by goroutine 71: github.com/seaweedfs/seaweedfs/weed/pb/filer_pb.IsUpdate() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb/filer_pb_helper.go:161 +0x490 github.com/seaweedfs/seaweedfs/weed/command.extractPathsFromMetadata() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:139 +0x57c github.com/seaweedfs/seaweedfs/weed/command.shouldWaitFor() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:86 +0x4c github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).conflictsWith() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:75 +0x1f4 github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).AddSyncJob() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:38 +0x11c github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.func2() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:281 +0x34 github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.AddOffsetFunc.func5() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:112 +0x5c github.com/seaweedfs/seaweedfs/weed/pb.FollowMetadata.makeSubscribeMetadataFunc.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:86 +0x4f0 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:262 +0x94 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:155 +0x2a0 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:260 +0x9c github.com/seaweedfs/seaweedfs/weed/pb.WithFilerClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:254 +0x8c github.com/seaweedfs/seaweedfs/weed/pb.FollowMetadata() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:41 +0x3c github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:306 +0xa0c github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:154 +0x5e8 Goroutine 119 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.(*MetadataProcessor).AddSyncJob() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync_jobs.go:42 +0x314 github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.func2() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:281 +0x34 github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges.AddOffsetFunc.func5() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:112 +0x5c github.com/seaweedfs/seaweedfs/weed/pb.FollowMetadata.makeSubscribeMetadataFunc.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:86 +0x4f0 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:262 +0x94 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:155 +0x2a0 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:260 +0x9c github.com/seaweedfs/seaweedfs/weed/pb.WithFilerClient() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/grpc_client_server.go:254 +0x8c github.com/seaweedfs/seaweedfs/weed/pb.FollowMetadata() /Users/whitefox/GolandProjects/seaweedfs/weed/pb/filer_pb_tail.go:41 +0x3c github.com/seaweedfs/seaweedfs/weed/command.doSubscribeFilerMetaChanges() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:306 +0xa0c github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:154 +0x5e8 Goroutine 71 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:144 +0x54c main.main() /Users/whitefox/GolandProjects/seaweedfs/weed/weed.go:80 +0x73c   **System Setup**  master branch  config-file source-file source-file source-file source-file config-file source-file source-file source-file source-file",no-bug,0.9
2016,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2016,[filer.copy] filer.copy can not copy empty folders,"**Describe the bug** filer.copy does not copy empty folder **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # setup master weed master -port=9333 -mdir=/tmp/master0 -ip=localhost # setup volume weed volume -port=8080 -dir=/tmp/volume0 -ip=localhost -mserver=localhost:9333 # setup filer weed filer -port=8888 -ip=localhost -master=localhost:9333 #weed mount weed mount -filer=localhost:8888 -cacheCapacityMB=0 -cacheDir=/tmp/cache001 -dir=/root/swfs/mnt #write some files and folders, and ls root@dev-4:~# mkdir -p /root/swfs/mnt/pfolder root@dev-4:~# mkdir -p /root/swfs/mnt/pfolder/subfolder1 root@dev-4:~# mkdir -p /root/swfs/mnt/pfolder/subfolder2 root@dev-4:~# touch /root/swfs/mnt/pfolder/file root@dev-4:~# touch /root/swfs/mnt/pfolder/subfolder2/file2 root@dev-4:~# ls /root/swfs/mnt/pfolder file subfolder1 subfolder2 # use filer.copy copy folder `pfolder` weed filer.copy /root/swfs/mnt/pfolder/* http://localhost:8888/newfolder/ # ls copied folder root@dev-4:~/swfs/mnt# ls /root/swfs/mnt/newfolder file subfolder2  empty folder `subfolder1` is missing - OS version version 30GB 2.28 37f104f linux amd64 - if using filer, show the content of `filer.toml` default **Expected behavior** `filer.copy` can copy empty folders",source-file,"[filer.copy] filer.copy can not copy empty folders **Describe the bug** filer.copy does not copy empty folder **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # setup master weed master -port=9333 -mdir=/tmp/master0 -ip=localhost # setup volume weed volume -port=8080 -dir=/tmp/volume0 -ip=localhost -mserver=localhost:9333 # setup filer weed filer -port=8888 -ip=localhost -master=localhost:9333 #weed mount weed mount -filer=localhost:8888 -cacheCapacityMB=0 -cacheDir=/tmp/cache001 -dir=/root/swfs/mnt #write some files and folders, and ls root@dev-4:~# mkdir -p /root/swfs/mnt/pfolder root@dev-4:~# mkdir -p /root/swfs/mnt/pfolder/subfolder1 root@dev-4:~# mkdir -p /root/swfs/mnt/pfolder/subfolder2 root@dev-4:~# touch /root/swfs/mnt/pfolder/file root@dev-4:~# touch /root/swfs/mnt/pfolder/subfolder2/file2 root@dev-4:~# ls /root/swfs/mnt/pfolder file subfolder1 subfolder2 # use filer.copy copy folder `pfolder` weed filer.copy /root/swfs/mnt/pfolder/* http://localhost:8888/newfolder/ # ls copied folder root@dev-4:~/swfs/mnt# ls /root/swfs/mnt/newfolder file subfolder2  empty folder `subfolder1` is missing - OS version version 30GB 2.28 37f104f linux amd64 - if using filer, show the content of `filer.toml` default **Expected behavior** `filer.copy` can copy empty folders source-file",no-bug,0.9
5001,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5001,NoSuchMethodError in java client icebreg,"When I first created a iceberg table with hadoop catalog and wrote data normally, but threw this exception during my second append data to this table ,I am using Java8 <dependency> <groupId>com.github.chrislusf</groupId> <artifactId>seaweedfs-hadoop3-client</artifactId> <version>3.13</version> </dependency> <dependency> <groupId>org.apache.parquet</groupId> <artifactId>parquet-column</artifactId> <version>1.13.1</version> </dependency> <dependency> <groupId>com.google.guava</groupId> <artifactId>guava</artifactId> <version>11.0.2</version> </dependency> <dependency> <groupId>org.apache.hadoop</groupId> <artifactId>hadoop-common</artifactId> <version>3.3.3</version> </dependency> Exception in thread ""main"" java.lang.NoSuchMethodError: java.nio.ByteBuffer.position(I)Ljava/nio/ByteBuffer; at seaweedfs.client.SeaweedRead.read(SeaweedRead.java:89) at seaweedfs.client.SeaweedInputStream.read(SeaweedInputStream.java:126) at seaweedfs.client.SeaweedInputStream.read(SeaweedInputStream.java:106) at seaweed.hdfs.SeaweedHadoopInputStream.read(SeaweedHadoopInputStream.java:37) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) at java.io.BufferedInputStream.read(BufferedInputStream.java:345) at java.io.DataInputStream.read(DataInputStream.java:149) at org.apache.iceberg.hadoop.HadoopStreams$HadoopSeekableInputStream.read(HadoopStreams.java:123) at org.apache.iceberg.avro.AvroIO$AvroInputStreamAdapter.read(AvroIO.java:117) at org.apache.avro.file.DataFileReader.openReader(DataFileReader.java:65) at org.apache.iceberg.avro.AvroIterable.newFileReader(AvroIterable.java:100) at org.apache.iceberg.avro.AvroIterable.iterator(AvroIterable.java:76) at org.apache.iceberg.avro.AvroIterable.iterator(AvroIterable.java:36) at org.apache.iceberg.relocated.com.google.common.collect.Iterables.addAll(Iterables.java:337) at org.apache.iceberg.relocated.com.google.common.collect.Lists.newLinkedList(Lists.java:241) at org.apache.iceberg.ManifestLists.read(ManifestLists.java:45) at org.apache.iceberg.BaseSnapshot.cacheManifests(BaseSnapshot.java:148) at org.apache.iceberg.BaseSnapshot.dataManifests(BaseSnapshot.java:174) at org.apache.iceberg.MergingSnapshotProducer.apply(MergingSnapshotProducer.java:848) at org.apache.iceberg.SnapshotProducer.apply(SnapshotProducer.java:217) at org.apache.iceberg.SnapshotProducer.lambda$commit$2(SnapshotProducer.java:366) at org.apache.iceberg.SnapshotProducer$$Lambda$77/7649301.run(Unknown Source) at org.apache.iceberg.util.Tasks$Builder.runTaskWithRetry(Tasks.java:413) at org.apache.iceberg.util.Tasks$Builder.runSingleThreaded(Tasks.java:219) at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:203) at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:196) at org.apache.iceberg.SnapshotProducer.commit(SnapshotProducer.java:364) at operator.TestRest.main(TestRest.java:123)",config-file | other-file | config-file | config-file | config-file | config-file | config-file | config-file | test-file | config-file | other-file | config-file | config-file | config-file | config-file | config-file | config-file | test-file | config-file | other-file | config-file | config-file | config-file | config-file | config-file | config-file | test-file,"NoSuchMethodError in java client icebreg When I first created a iceberg table with hadoop catalog and wrote data normally, but threw this exception during my second append data to this table ,I am using Java8 <dependency> <groupId>com.github.chrislusf</groupId> <artifactId>seaweedfs-hadoop3-client</artifactId> <version>3.13</version> </dependency> <dependency> <groupId>org.apache.parquet</groupId> <artifactId>parquet-column</artifactId> <version>1.13.1</version> </dependency> <dependency> <groupId>com.google.guava</groupId> <artifactId>guava</artifactId> <version>11.0.2</version> </dependency> <dependency> <groupId>org.apache.hadoop</groupId> <artifactId>hadoop-common</artifactId> <version>3.3.3</version> </dependency> Exception in thread ""main"" java.lang.NoSuchMethodError: java.nio.ByteBuffer.position(I)Ljava/nio/ByteBuffer; at seaweedfs.client.SeaweedRead.read(SeaweedRead.java:89) at seaweedfs.client.SeaweedInputStream.read(SeaweedInputStream.java:126) at seaweedfs.client.SeaweedInputStream.read(SeaweedInputStream.java:106) at seaweed.hdfs.SeaweedHadoopInputStream.read(SeaweedHadoopInputStream.java:37) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) at java.io.BufferedInputStream.read(BufferedInputStream.java:345) at java.io.DataInputStream.read(DataInputStream.java:149) at org.apache.iceberg.hadoop.HadoopStreams$HadoopSeekableInputStream.read(HadoopStreams.java:123) at org.apache.iceberg.avro.AvroIO$AvroInputStreamAdapter.read(AvroIO.java:117) at org.apache.avro.file.DataFileReader.openReader(DataFileReader.java:65) at org.apache.iceberg.avro.AvroIterable.newFileReader(AvroIterable.java:100) at org.apache.iceberg.avro.AvroIterable.iterator(AvroIterable.java:76) at org.apache.iceberg.avro.AvroIterable.iterator(AvroIterable.java:36) at org.apache.iceberg.relocated.com.google.common.collect.Iterables.addAll(Iterables.java:337) at org.apache.iceberg.relocated.com.google.common.collect.Lists.newLinkedList(Lists.java:241) at org.apache.iceberg.ManifestLists.read(ManifestLists.java:45) at org.apache.iceberg.BaseSnapshot.cacheManifests(BaseSnapshot.java:148) at org.apache.iceberg.BaseSnapshot.dataManifests(BaseSnapshot.java:174) at org.apache.iceberg.MergingSnapshotProducer.apply(MergingSnapshotProducer.java:848) at org.apache.iceberg.SnapshotProducer.apply(SnapshotProducer.java:217) at org.apache.iceberg.SnapshotProducer.lambda$commit$2(SnapshotProducer.java:366) at org.apache.iceberg.SnapshotProducer$$Lambda$77/7649301.run(Unknown Source) at org.apache.iceberg.util.Tasks$Builder.runTaskWithRetry(Tasks.java:413) at org.apache.iceberg.util.Tasks$Builder.runSingleThreaded(Tasks.java:219) at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:203) at org.apache.iceberg.util.Tasks$Builder.run(Tasks.java:196) at org.apache.iceberg.SnapshotProducer.commit(SnapshotProducer.java:364) at operator.TestRest.main(TestRest.java:123) config-file other-file config-file config-file config-file config-file config-file config-file test-file config-file other-file config-file config-file config-file config-file config-file config-file test-file config-file other-file config-file config-file config-file config-file config-file config-file test-file",no-bug,0.95
5276,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5276,The second of two consecutive chunks with the same modified_ts_ns would be determined as garbage chunk,"**Describe the bug** when using s3 multipart upload to upload large files, sometimes the uploaded file is not complete. the filer log shows that some chunks were deleted in s3 CompleteMultipartUpload process:  s3api_object_multipart_handlers.go:87 CompleteMultipartUploadHandler<?xml version=""1.0"" encoding=""UTF-8""?> <CompleteMultipartUploadResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Bucket>test</Bucket><ETag>""5fcca6e6a9d993c696e93a4ff590e876-25601""</ETag><Key>test_100G</Key><Location>http://10.2.8.15:8888/buckets/test/test_100G</Location></CompleteMultipartUploadResult>0 error_handler.go:96 status 200 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <CompleteMultipartUploadResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Bucket>test</Bucket><ETag>""5fcca6e6a9d993c696e93a4ff590e876-25601""</ETag><Key>test_100G</Key><Location>http://10.2.8.15:8888/buckets/test/test_100G</Location></CompleteMultipartUploadResult> filer_deletion.go:63 deleting fileIds [209,06fcc9d0c356d9 267,07111283476be2 120,0734dda3e94fcf 23,07380b4872bb69]  I printed deleted chunks' info:  209,06fcc9d0c356d9, offset: 31423725568, size:4194304, modified_ts_ns:1704948775800315374 267,07111283476be2, offset: 53183774720, size:4194304, modified_ts_ns:1704949043164890748 120,0734dda3e94fcf, offset: 91574239232, size:4194304, modified_ts_ns:1704949642723286286 23,07380b4872bb69, offset: 94984208384, size:4194304, modified_ts_ns:1704949720478107269  take chunk 209,06fcc9d0c356d9 as example, the chunk belongs to 1499.part, and 1499.part has totally 5 chunks:  filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 1 to 178,06fcc7ef2a9ee1 [0,4194304) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 2 to 12,06fcc81e2bf1ad [4194304,8388608) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 3 to 209,06fcc9d0c356d9 [8388608,12582912) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 4 to 133,06fcca90fe005d [12582912,16777216) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 5 to 226,06fccb9dfa4413 [16777216,20971520)  the uploaded file's metadata shows that chunk 12,06fcc81e2bf1ad has the same modified_ts_ns as chunk 209,06fcc9d0c356d9:  HTTP/1.1 200 OK Content-Type: application/json Server: SeaweedFS Filer 30GB 3.59 Date: Thu, 11 Jan 2024 06:07:51 GMT Transfer-Encoding: chunked { ""FullPath"": ""/buckets/test/test_100G"", ""Mtime"": ""2024-01-11T13:13:29+08:00"", ""Crtime"": ""2024-01-11T13:13:29+08:00"", ""Mode"": 504, ""Uid"": 0, ""Gid"": 0, ""Mime"": """", ""TtlSec"": 0, ""UserName"": """", ""GroupNames"": null, ""SymlinkTarget"": """", ""Md5"": null, ""FileSize"": 107374182432, ""Rdev"": 0, ""Inode"": 0, ""Extended"": null, ""chunks"": [  { ""file_id"": ""178,06fcc7ef2a9ee1"", ""offset"": 31415336960, ""size"": 4194304, ""modified_ts_ns"": 1704948775742876389, ""e_tag"": ""T1WHruL2rdcNzpBNzzYLow=="", ""fid"": { ""volume_id"": 178, ""file_key"": 457927, ""cookie"": 4012547809 } }, { ""file_id"": ""12,06fcc81e2bf1ad"", ""offset"": 31419531264, ""size"": 4194304, ""modified_ts_ns"": 1704948775800315374, ""e_tag"": ""Wi+o67I2ISAyEGL1vvGDGA=="", ""fid"": { ""volume_id"": 12, ""file_key"": 457928, ""cookie"": 506196397 } }, { ""file_id"": ""133,06fcca90fe005d"", ""offset"": 31427919872, ""size"": 4194304, ""modified_ts_ns"": 1704948775802870518, ""e_tag"": ""gxyHCpAf2vECDOmwgTBF3g=="", ""fid"": { ""volume_id"": 133, ""file_key"": 457930, ""cookie"": 2432565341 } }, { ""file_id"": ""226,06fccb9dfa4413"", ""offset"": 31432114176, ""size"": 4194304, ""modified_ts_ns"": 1704948775809675155, ""e_tag"": ""XHMn+bM40q0ysKIG5ajD3Q=="", ""fid"": { ""volume_id"": 226, ""file_key"": 457931, ""cookie"": 2650424339 } }  ], ""HardLinkId"": null, ""HardLinkCounter"": 0, ""Content"": null, ""Remote"": null, ""Quota"": 0 }  the other deleted chunks shows the same feature. then I added a test case in filechunks_test.go:  func TestCompactFileChunks3(t *testing.T) { chunks := []*filer_pb.FileChunk{ {Offset: 0, Size: 100, FileId: ""abc"", ModifiedTsNs: 50}, {Offset: 100, Size: 100, FileId: ""ghi"", ModifiedTsNs: 50}, {Offset: 200, Size: 100, FileId: ""jkl"", ModifiedTsNs: 100}, {Offset: 300, Size: 100, FileId: ""def"", ModifiedTsNs: 200}, } compacted, _ := CompactFileChunks(nil, chunks) if len(compacted) != 4 { t.Fatalf(""unexpected compacted: %d"", len(compacted)) } }  the test case did not pass **System Setup** seaweedfs version: 3.59",source-file | test-file,"The second of two consecutive chunks with the same modified_ts_ns would be determined as garbage chunk **Describe the bug** when using s3 multipart upload to upload large files, sometimes the uploaded file is not complete. the filer log shows that some chunks were deleted in s3 CompleteMultipartUpload process:  s3api_object_multipart_handlers.go:87 CompleteMultipartUploadHandler<?xml version=""1.0"" encoding=""UTF-8""?> <CompleteMultipartUploadResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Bucket>test</Bucket><ETag>""5fcca6e6a9d993c696e93a4ff590e876-25601""</ETag><Key>test_100G</Key><Location>http://10.2.8.15:8888/buckets/test/test_100G</Location></CompleteMultipartUploadResult>0 error_handler.go:96 status 200 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <CompleteMultipartUploadResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Bucket>test</Bucket><ETag>""5fcca6e6a9d993c696e93a4ff590e876-25601""</ETag><Key>test_100G</Key><Location>http://10.2.8.15:8888/buckets/test/test_100G</Location></CompleteMultipartUploadResult> filer_deletion.go:63 deleting fileIds [209,06fcc9d0c356d9 267,07111283476be2 120,0734dda3e94fcf 23,07380b4872bb69]  I printed deleted chunks' info:  209,06fcc9d0c356d9, offset: 31423725568, size:4194304, modified_ts_ns:1704948775800315374 267,07111283476be2, offset: 53183774720, size:4194304, modified_ts_ns:1704949043164890748 120,0734dda3e94fcf, offset: 91574239232, size:4194304, modified_ts_ns:1704949642723286286 23,07380b4872bb69, offset: 94984208384, size:4194304, modified_ts_ns:1704949720478107269  take chunk 209,06fcc9d0c356d9 as example, the chunk belongs to 1499.part, and 1499.part has totally 5 chunks:  filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 1 to 178,06fcc7ef2a9ee1 [0,4194304) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 2 to 12,06fcc81e2bf1ad [4194304,8388608) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 3 to 209,06fcc9d0c356d9 [8388608,12582912) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 4 to 133,06fcca90fe005d [12582912,16777216) filer_server_handlers_write_upload.go:117 uploaded 1499.part chunk 5 to 226,06fccb9dfa4413 [16777216,20971520)  the uploaded file's metadata shows that chunk 12,06fcc81e2bf1ad has the same modified_ts_ns as chunk 209,06fcc9d0c356d9:  HTTP/1.1 200 OK Content-Type: application/json Server: SeaweedFS Filer 30GB 3.59 Date: Thu, 11 Jan 2024 06:07:51 GMT Transfer-Encoding: chunked { ""FullPath"": ""/buckets/test/test_100G"", ""Mtime"": ""2024-01-11T13:13:29+08:00"", ""Crtime"": ""2024-01-11T13:13:29+08:00"", ""Mode"": 504, ""Uid"": 0, ""Gid"": 0, ""Mime"": """", ""TtlSec"": 0, ""UserName"": """", ""GroupNames"": null, ""SymlinkTarget"": """", ""Md5"": null, ""FileSize"": 107374182432, ""Rdev"": 0, ""Inode"": 0, ""Extended"": null, ""chunks"": [  { ""file_id"": ""178,06fcc7ef2a9ee1"", ""offset"": 31415336960, ""size"": 4194304, ""modified_ts_ns"": 1704948775742876389, ""e_tag"": ""T1WHruL2rdcNzpBNzzYLow=="", ""fid"": { ""volume_id"": 178, ""file_key"": 457927, ""cookie"": 4012547809 } }, { ""file_id"": ""12,06fcc81e2bf1ad"", ""offset"": 31419531264, ""size"": 4194304, ""modified_ts_ns"": 1704948775800315374, ""e_tag"": ""Wi+o67I2ISAyEGL1vvGDGA=="", ""fid"": { ""volume_id"": 12, ""file_key"": 457928, ""cookie"": 506196397 } }, { ""file_id"": ""133,06fcca90fe005d"", ""offset"": 31427919872, ""size"": 4194304, ""modified_ts_ns"": 1704948775802870518, ""e_tag"": ""gxyHCpAf2vECDOmwgTBF3g=="", ""fid"": { ""volume_id"": 133, ""file_key"": 457930, ""cookie"": 2432565341 } }, { ""file_id"": ""226,06fccb9dfa4413"", ""offset"": 31432114176, ""size"": 4194304, ""modified_ts_ns"": 1704948775809675155, ""e_tag"": ""XHMn+bM40q0ysKIG5ajD3Q=="", ""fid"": { ""volume_id"": 226, ""file_key"": 457931, ""cookie"": 2650424339 } }  ], ""HardLinkId"": null, ""HardLinkCounter"": 0, ""Content"": null, ""Remote"": null, ""Quota"": 0 }  the other deleted chunks shows the same feature. then I added a test case in filechunks_test.go:  func TestCompactFileChunks3(t *testing.T) { chunks := []*filer_pb.FileChunk{ {Offset: 0, Size: 100, FileId: ""abc"", ModifiedTsNs: 50}, {Offset: 100, Size: 100, FileId: ""ghi"", ModifiedTsNs: 50}, {Offset: 200, Size: 100, FileId: ""jkl"", ModifiedTsNs: 100}, {Offset: 300, Size: 100, FileId: ""def"", ModifiedTsNs: 200}, } compacted, _ := CompactFileChunks(nil, chunks) if len(compacted) != 4 { t.Fatalf(""unexpected compacted: %d"", len(compacted)) } }  the test case did not pass **System Setup** seaweedfs version: 3.59 source-file test-file",no-bug,0.9
5212,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5212,[filer] loop of connecting and disconnecting filers,**Describe the bug** Endless loop of connecting and disconnecting filers  I0117 15:25:20.181356 filer_grpc_server_sub_meta.go:117 + filer:192.168.1.17:8889@192.168.1.17:39492 local subscribe / from 2024-01-17 15:25:14.079534422 +0000 UTC clientId:-190561764 I0117 15:25:20.193843 filer_grpc_server_sub_meta.go:149 read in memory filer:192.168.1.17:8889@192.168.1.17:39492 local subscribe / from 2024-01-17 15:25:14.079534422 +0000 UTC I0117 15:25:20.181337 filer_grpc_server_sub_meta.go:296 + local listener filer:192.168.1.17:8889@192.168.1.17:39492 clientId -190561764 clientEpoch 190395 I0117 15:25:20.181364 filer_grpc_server_sub_meta.go:130 read on disk filer:192.168.1.17:8889@192.168.1.17:39492 local subscribe / from 2024-01-17 15:25:14.079534422 +0000 UTC I0117 15:25:21.924645 filer_grpc_server_sub_meta.go:112 disconnect filer:192.168.1.17:8889@192.168.1.17:39492 local subscriber / clientId:-190561764 I0117 15:25:21.924654 filer_grpc_server_sub_meta.go:312 - local listener filer:192.168.1.17:8889@192.168.1.17:39492 clientId -190561764 clientEpoch 190395  **System Setup**  3.62  **Expected behavior** Break loop,source-file,[filer] loop of connecting and disconnecting filers **Describe the bug** Endless loop of connecting and disconnecting filers  I0117 15:25:20.181356 filer_grpc_server_sub_meta.go:117 + filer:192.168.1.17:8889@192.168.1.17:39492 local subscribe / from 2024-01-17 15:25:14.079534422 +0000 UTC clientId:-190561764 I0117 15:25:20.193843 filer_grpc_server_sub_meta.go:149 read in memory filer:192.168.1.17:8889@192.168.1.17:39492 local subscribe / from 2024-01-17 15:25:14.079534422 +0000 UTC I0117 15:25:20.181337 filer_grpc_server_sub_meta.go:296 + local listener filer:192.168.1.17:8889@192.168.1.17:39492 clientId -190561764 clientEpoch 190395 I0117 15:25:20.181364 filer_grpc_server_sub_meta.go:130 read on disk filer:192.168.1.17:8889@192.168.1.17:39492 local subscribe / from 2024-01-17 15:25:14.079534422 +0000 UTC I0117 15:25:21.924645 filer_grpc_server_sub_meta.go:112 disconnect filer:192.168.1.17:8889@192.168.1.17:39492 local subscriber / clientId:-190561764 I0117 15:25:21.924654 filer_grpc_server_sub_meta.go:312 - local listener filer:192.168.1.17:8889@192.168.1.17:39492 clientId -190561764 clientEpoch 190395  **System Setup**  3.62  **Expected behavior** Break loop source-file,no-bug,0.9
3038,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3038,volume.tier.upload rpc error,"**Describe the bug** When I use the `volume.tier.upload` command, I get an error `rpc error: code = Unavailable desc = error reading from server: EOF` **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - After the configuration is complete, restart all weed related services. - The firewall of the volume server is fully open - OS version: Linux x64 ubuntu 20.04 - output of `weed version` : version 30GB 3.02 a4ca3ed1f0c2bcde1d36bb48f81dedc3e1924679 linux amd64 - filer.toml  [postgres2] enabled = true createTable =  CREATE TABLE IF NOT EXISTS ""%s"" ( dirhash BIGINT, name VARCHAR(65535), directory VARCHAR(65535), meta bytea, PRIMARY KEY (dirhash, name) );  hostname = ""192.168.50.123"" port = 5432 username = ""seaweedfs"" password = ""seaweedfs"" database = ""seaweedfs"" # create or use an existing database schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0 # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO ""%[1]s"" (dirhash,name,directory,meta) VALUES($1,$2,$3,$4) ON CONFLICT (dirhash,name) DO UPDATE SET meta = EXCLUDED.meta WHERE ""%[1]s"".meta != EXCLUDED.meta  - security.toml  [jwt.signing] key = ""seaweedfs"" expires_after_seconds = 30 [jwt.signing.read] key = """" expires_after_seconds = 30 [jwt.filer_signing] key = ""seaweedfs"" expires_after_seconds = 30 [jwt.filer_signing.read] key = ""seaweedfs"" expires_after_seconds = 30 [grpc] ca = ""/etc/seaweedfs/out/seaweedfs_CA.crt"" [grpc.volume] cert = ""/etc/seaweedfs/out/volume01.crt"" key = ""/etc/seaweedfs/out/volume01.key"" [grpc.master] cert = ""/etc/seaweedfs/out/master01.crt"" key = ""/etc/seaweedfs/out/master01.key"" [grpc.filer] cert = ""/etc/seaweedfs/out/filer01.crt"" key = ""/etc/seaweedfs/out/filer01.key"" [grpc.client] cert = ""/etc/seaweedfs/out/client01.crt"" key = ""/etc/seaweedfs/out/client01.key""  - master.toml *s3 is accessible*  [storage.backend] [storage.backend.s3.default] enabled = true aws_access_key_id = """" # if empty, loads from the shared credentials file (~/.aws/credentials). aws_secret_access_key = """" # if empty, loads from the shared credentials file (~/.aws/credentials). region = ""ap-beijing"" bucket = ""test"" # an existing bucket endpoint = ""xxx.xxx.com""  **Expected behavior** **Screenshots** **Additional context** *volumeId exists* *collection exists*  > lock > volume.tier.upload -dest=s3 -volumeId=22 -collection=ttt markVolumeReadonly 22 on 192.168.50.5:9005  error: copy dat file for volume 22 on 192.168.50.5:9005 to s3: rpc error: code = Unavailable desc = error reading from server: EOF ",source-file,"volume.tier.upload rpc error **Describe the bug** When I use the `volume.tier.upload` command, I get an error `rpc error: code = Unavailable desc = error reading from server: EOF` **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - After the configuration is complete, restart all weed related services. - The firewall of the volume server is fully open - OS version: Linux x64 ubuntu 20.04 - output of `weed version` : version 30GB 3.02 a4ca3ed1f0c2bcde1d36bb48f81dedc3e1924679 linux amd64 - filer.toml  [postgres2] enabled = true createTable =  CREATE TABLE IF NOT EXISTS ""%s"" ( dirhash BIGINT, name VARCHAR(65535), directory VARCHAR(65535), meta bytea, PRIMARY KEY (dirhash, name) );  hostname = ""192.168.50.123"" port = 5432 username = ""seaweedfs"" password = ""seaweedfs"" database = ""seaweedfs"" # create or use an existing database schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0 # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO ""%[1]s"" (dirhash,name,directory,meta) VALUES($1,$2,$3,$4) ON CONFLICT (dirhash,name) DO UPDATE SET meta = EXCLUDED.meta WHERE ""%[1]s"".meta != EXCLUDED.meta  - security.toml  [jwt.signing] key = ""seaweedfs"" expires_after_seconds = 30 [jwt.signing.read] key = """" expires_after_seconds = 30 [jwt.filer_signing] key = ""seaweedfs"" expires_after_seconds = 30 [jwt.filer_signing.read] key = ""seaweedfs"" expires_after_seconds = 30 [grpc] ca = ""/etc/seaweedfs/out/seaweedfs_CA.crt"" [grpc.volume] cert = ""/etc/seaweedfs/out/volume01.crt"" key = ""/etc/seaweedfs/out/volume01.key"" [grpc.master] cert = ""/etc/seaweedfs/out/master01.crt"" key = ""/etc/seaweedfs/out/master01.key"" [grpc.filer] cert = ""/etc/seaweedfs/out/filer01.crt"" key = ""/etc/seaweedfs/out/filer01.key"" [grpc.client] cert = ""/etc/seaweedfs/out/client01.crt"" key = ""/etc/seaweedfs/out/client01.key""  - master.toml *s3 is accessible*  [storage.backend] [storage.backend.s3.default] enabled = true aws_access_key_id = """" # if empty, loads from the shared credentials file (~/.aws/credentials). aws_secret_access_key = """" # if empty, loads from the shared credentials file (~/.aws/credentials). region = ""ap-beijing"" bucket = ""test"" # an existing bucket endpoint = ""xxx.xxx.com""  **Expected behavior** **Screenshots** **Additional context** *volumeId exists* *collection exists*  > lock > volume.tier.upload -dest=s3 -volumeId=22 -collection=ttt markVolumeReadonly 22 on 192.168.50.5:9005  error: copy dat file for volume 22 on 192.168.50.5:9005 to s3: rpc error: code = Unavailable desc = error reading from server: EOF  source-file",no-bug,0.8
2075,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2075,Corrupt upload using AWS Java SDK,"**Describe the bug** Client upload using AWS SDK 1.11.745 fails with data integrity error:  Unable to verify integrity of data upload. Client calculated content hash (contentMD5: DyYDJ6odjkGLkn0zZ7ojjA== in base 64) didn't match hash (etag: 3df389e4041f77e0a9557d486d6e9fcf in hex) calculated by Amazon S3. You may need to delete the data stored in Amazon S3. (metadata.contentMD5: null, md5DigestStream: com.amazonaws.services.s3.internal.MD5DigestCalculatingInputStream@341308f5, bucketName: foo, key: path/to/key.jar)  A partial file is uploaded. Upon download the file is obviously corrupt:  $ unzip -l file.jar Archive: file.jar error: End-of-centdir-64 signature not where expected (prepended bytes?) (attempting to process anyway) warning [file.jar]: 230757 extra bytes at beginning or within zipfile (attempting to process anyway) error [file.jar]: start of central directory not found; zipfile corrupt. (please check that you have transferred or created the zipfile in the appropriate BINARY mode and that you have compiled UnZip properly)  Example Java SDK usage:  if (!amazonS3Client.doesObjectExist(s3Bucket, keyName)) { try { Resource resource = new UrlResource(""path/to/resource""); ObjectMetadata metadata = new ObjectMetadata(); metadata.setContentLength(resource.contentLength()); metadata.setContentType(MediaType.APPLICATION_OCTET_STREAM_VALUE); PutObjectRequest request = new PutObjectRequest(s3Bucket, keyName, resource.getInputStream(), metadata); amazonS3Client.putObject(request);  **System Setup** - `weed master -volumeSizeLimitMB=1000` - `weed volume -dir=/data -mserver=seaweedfs-master:9333 -max=1000 -port=8080` - `weed filer -s3 -master=seaweedfs-master:9333 port=8888` - Docker container chrislusf/seaweedfs:2.48 - output of `weed version`  # weed version version 30GB 2.48 45a76222 linux amd64  - if using filer, show the content of `filer.toml` None - using defaults from docker image **Expected behavior** The full file should be uploaded. **Additional context** Uploads using the aws CLI command and the AWS golang API do not have the same issue.",source-file | source-file,"Corrupt upload using AWS Java SDK **Describe the bug** Client upload using AWS SDK 1.11.745 fails with data integrity error:  Unable to verify integrity of data upload. Client calculated content hash (contentMD5: DyYDJ6odjkGLkn0zZ7ojjA== in base 64) didn't match hash (etag: 3df389e4041f77e0a9557d486d6e9fcf in hex) calculated by Amazon S3. You may need to delete the data stored in Amazon S3. (metadata.contentMD5: null, md5DigestStream: com.amazonaws.services.s3.internal.MD5DigestCalculatingInputStream@341308f5, bucketName: foo, key: path/to/key.jar)  A partial file is uploaded. Upon download the file is obviously corrupt:  $ unzip -l file.jar Archive: file.jar error: End-of-centdir-64 signature not where expected (prepended bytes?) (attempting to process anyway) warning [file.jar]: 230757 extra bytes at beginning or within zipfile (attempting to process anyway) error [file.jar]: start of central directory not found; zipfile corrupt. (please check that you have transferred or created the zipfile in the appropriate BINARY mode and that you have compiled UnZip properly)  Example Java SDK usage:  if (!amazonS3Client.doesObjectExist(s3Bucket, keyName)) { try { Resource resource = new UrlResource(""path/to/resource""); ObjectMetadata metadata = new ObjectMetadata(); metadata.setContentLength(resource.contentLength()); metadata.setContentType(MediaType.APPLICATION_OCTET_STREAM_VALUE); PutObjectRequest request = new PutObjectRequest(s3Bucket, keyName, resource.getInputStream(), metadata); amazonS3Client.putObject(request);  **System Setup** - `weed master -volumeSizeLimitMB=1000` - `weed volume -dir=/data -mserver=seaweedfs-master:9333 -max=1000 -port=8080` - `weed filer -s3 -master=seaweedfs-master:9333 port=8888` - Docker container chrislusf/seaweedfs:2.48 - output of `weed version`  # weed version version 30GB 2.48 45a76222 linux amd64  - if using filer, show the content of `filer.toml` None - using defaults from docker image **Expected behavior** The full file should be uploaded. **Additional context** Uploads using the aws CLI command and the AWS golang API do not have the same issue. source-file source-file",no-bug,0.9
5527,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5527,The files on the mounted point are not deleted after the TTL expires,"**Describe the bug** Create a bucket named ""test2"" with a TTL (Time To Live) of 1 minute. Upload files into the bucket. After the TTL expires, verify that the files no longer exist inside the bucket. However, the files on the mounted point are still present. upload file curl -F file=@Readme.txt ""http://10.xxx.xx.x:9283/home/hdpu/lyh/mount_dir/test2/20240424/Readme1.txt"" curl -F file=@Readme.txt ""http://10.xxx.xx.x:9283/home/hdpu/lyh/mount_dir/test2/20240424/Readme2.txt"" curl -F file=@Readme.txt ""http://10.xxx.xx.x:9283/home/hdpu/lyh/mount_dir/test2/20240424/Readme3.txt"" **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". ./weed -logdir=/data/obs/hdd/log/master master -mdir=/data/obs/ssd/data/master -peers=10.xxx.xx.x:9666 -ip=10.xxx.xx.x -port=9666 -defaultReplication=000 -volumePreallocate -volumeSizeLimitMB=80 /weed -logdir=/data/obs/hdd/log/volume volume -index=leveldb -idleTimeout=30 -dir=/data/obs/ssd/data/volume,/data/obs/hdd/data/volume,/data/obs/warm/data/volume,/data/obs/cold/data/volume -disk=ssd,hdd,warm,cold -mserver=10.xxx.xx.x:9666 -dataCenter=dc -rack=rack1 -ip=10.xxx.xx.x -port=9189 -concurrentDownloadLimitMB=2048 -max=0 ./weed -logdir=/data/obs/hdd/log/filer filer -master=10.xxx.xx.x:9666 -ip=10.xxx.xx.x -port=9283 -defaultReplicaPlacement=000 -maxMB=4 -s3 -s3.allowEmptyFolder -encryptVolumeData -s3.port=9383 -iam -iam.port=9483 ./weed mount -cacheCapacityMB=0 -filer=10.xxx.xx.x:9283 -volumeServerAccess=filerProxy -dir=/home/hdpu/lyh/mount_dir/ -filer.path=/home/hdpu/lyh/mount_dir/ - OS version centos7 - output of `weed version` seaweedfs 3.15 - if using filer, show the content of `filer.toml` [cassandra] enabled = true keyspace = ""seaweedfs"" hosts = [ ""10.xxx.xx.x:9042"", ] username = """" password = """" This changes the data layout. Only add new directories. Removing/Updating will cause data loss. superLargeDirectories = [] Name of the datacenter local to this filer, used as host selection fallback. localDC = """" **Expected behavior** The files on the mounted point have been deleted. **Screenshots** If applicable, add screenshots to help explain your problem. ![image](https://github.com/seaweedfs/seaweedfs/assets/45417436/daf66b57-fbae-4cb2-aba0-5f046c86beb1) ![image](https://github.com/seaweedfs/seaweedfs/assets/45417436/d115c59c-c188-4a32-b831-1bf3071727fb) **Additional context** Add any other context about the problem here.",source-file,"The files on the mounted point are not deleted after the TTL expires **Describe the bug** Create a bucket named ""test2"" with a TTL (Time To Live) of 1 minute. Upload files into the bucket. After the TTL expires, verify that the files no longer exist inside the bucket. However, the files on the mounted point are still present. upload file curl -F file=@Readme.txt ""http://10.xxx.xx.x:9283/home/hdpu/lyh/mount_dir/test2/20240424/Readme1.txt"" curl -F file=@Readme.txt ""http://10.xxx.xx.x:9283/home/hdpu/lyh/mount_dir/test2/20240424/Readme2.txt"" curl -F file=@Readme.txt ""http://10.xxx.xx.x:9283/home/hdpu/lyh/mount_dir/test2/20240424/Readme3.txt"" **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". ./weed -logdir=/data/obs/hdd/log/master master -mdir=/data/obs/ssd/data/master -peers=10.xxx.xx.x:9666 -ip=10.xxx.xx.x -port=9666 -defaultReplication=000 -volumePreallocate -volumeSizeLimitMB=80 /weed -logdir=/data/obs/hdd/log/volume volume -index=leveldb -idleTimeout=30 -dir=/data/obs/ssd/data/volume,/data/obs/hdd/data/volume,/data/obs/warm/data/volume,/data/obs/cold/data/volume -disk=ssd,hdd,warm,cold -mserver=10.xxx.xx.x:9666 -dataCenter=dc -rack=rack1 -ip=10.xxx.xx.x -port=9189 -concurrentDownloadLimitMB=2048 -max=0 ./weed -logdir=/data/obs/hdd/log/filer filer -master=10.xxx.xx.x:9666 -ip=10.xxx.xx.x -port=9283 -defaultReplicaPlacement=000 -maxMB=4 -s3 -s3.allowEmptyFolder -encryptVolumeData -s3.port=9383 -iam -iam.port=9483 ./weed mount -cacheCapacityMB=0 -filer=10.xxx.xx.x:9283 -volumeServerAccess=filerProxy -dir=/home/hdpu/lyh/mount_dir/ -filer.path=/home/hdpu/lyh/mount_dir/ - OS version centos7 - output of `weed version` seaweedfs 3.15 - if using filer, show the content of `filer.toml` [cassandra] enabled = true keyspace = ""seaweedfs"" hosts = [ ""10.xxx.xx.x:9042"", ] username = """" password = """" This changes the data layout. Only add new directories. Removing/Updating will cause data loss. superLargeDirectories = [] Name of the datacenter local to this filer, used as host selection fallback. localDC = """" **Expected behavior** The files on the mounted point have been deleted. **Screenshots** If applicable, add screenshots to help explain your problem. ![image](https://github.com/seaweedfs/seaweedfs/assets/45417436/daf66b57-fbae-4cb2-aba0-5f046c86beb1) ![image](https://github.com/seaweedfs/seaweedfs/assets/45417436/d115c59c-c188-4a32-b831-1bf3071727fb) **Additional context** Add any other context about the problem here. source-file",no-bug,0.9
11,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/11,Enable RTD service in repo settings for docs auto-building,Settings -> Webhooks & Services -> Add service -> ReadTheDocs,documentation-file | other-file | other-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | config-file | config-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Enable RTD service in repo settings for docs auto-building Settings -> Webhooks & Services -> Add service -> ReadTheDocs documentation-file other-file other-file documentation-file documentation-file config-file other-file config-file source-file config-file config-file config-file config-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.9
1908,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1908,[filler autoChunk] Chunk size matches chunk size s3,https://github.com/chrislusf/seaweedfs/pull/1903,source-file,[filler autoChunk] Chunk size matches chunk size s3 https://github.com/chrislusf/seaweedfs/pull/1903 source-file,no-bug,0.3
3549,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3549,[filer] DATA RACE on uploadReaderToChunks,"https://github.com/seaweedfs/seaweedfs/issues/3507  s3_1 | I0830 06:23:24.797198 auth_credentials.go:225 v4 auth type s3_1 | I0830 06:23:24.798512 auth_credentials.go:254 user name: some_admin_user actions: [Admin Read List Tagging Write], action: Write s3_1 | I0830 06:23:24.799422 s3api_object_multipart_handlers.go:248 PutObjectPartHandler registry 8d57564b4de275ffb5f210d3e8143dbef8607349 0004 s3_1 | I0830 06:23:24.800860 filer_server_handlers_write_upload.go:67 received byte buffer 1 s3_1 | I0830 06:23:24.819558 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 3 to 3,01ba893a4fc9 [20971520,25165824) s3_1 | I0830 06:23:24.822147 filer_server_handlers_write_upload.go:67 received byte buffer 4 s3_1 | I0830 06:23:24.878356 filer_server_handlers_write_upload.go:60 waiting for byte buffer 4 s3_1 | I0830 06:23:25.164557 filer_server_handlers_write_upload.go:67 received byte buffer 2 s3_1 | I0830 06:23:25.570195 filer_server_handlers_write_upload.go:67 received byte buffer 3 s3_1 | I0830 06:23:26.185096 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 4 to 5,01b675b06671 [8388608,12582912) s3_1 | I0830 06:23:26.185448 filer_server_handlers_write_upload.go:67 received byte buffer 4 s3_1 | I0830 06:23:26.336514 filer_server_handlers_write_upload.go:60 waiting for byte buffer 4 s3_1 | I0830 06:23:26.439257 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 5 to 4,01b9e55cf059 [16777216,20971520) s3_1 | I0830 06:23:26.439486 filer_server_handlers_write_upload.go:67 received byte buffer 4 s3_1 |  s3_1 | WARNING: DATA RACE s3_1 | Read at 0x00c00013a120 by goroutine 735: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:108 +0x22e s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:117 +0x47 s3_1 | s3_1 | Previous write at 0x00c00013a120 by goroutine 455: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:80 +0x1324 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 735 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:99 +0xf7d s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 455 (running) created at: s3_1 | net/http.(*Server).Serve() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x837 s3_1 | github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:308 +0x1b1 s3_1 |  s3_1 | I0830 06:23:26.936048 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 6 to 5,01b8993d1b57 [12582912,16777216) s3_1 | I0830 06:23:27.339330 filer_server_handlers_write_upload.go:115 uploaded 0004.part chunk 1 to 7,01bf74910830 [8388608,11026957) s3_1 | I0830 06:23:29.096974 filer_server_handlers_write_upload.go:115 uploaded 0004.part chunk 2 to 6,01bd1224517f [0,4194304) s3_1 | I0830 06:23:29.101658 filer_server_handlers_write_upload.go:115 uploaded 0004.part chunk 3 to 7,01be0b9c5e5d [4194304,8388608) s3_1 | I0830 06:23:29.107207 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 7 to 2,01c092dabc91 [29360128,33554432) s3_1 | I0830 06:23:29.109798 filer_server_handlers_write_autochunk.go:192 saving /buckets/registry/.uploads/8d57564b4de275ffb5f210d3e8143dbef8607349/0004.part s3_1 | I0830 06:23:29.111580 filer.go:222 find uncached directory: /buckets/registry/.uploads/8d57564b4de275ffb5f210d3e8143dbef8607349 s3_1 | I0830 06:23:29.116899 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 8 to 4,01bcab96b00a [25165824,29360128) s3_1 | I0830 06:23:29.116795 filer.go:186 InsertEntry /buckets/registry/.uploads/8d57564b4de275ffb5f210d3e8143dbef8607349/0004.part: new entry: 0004.part s3_1 | I0830 06:23:29.123204 filer_server_handlers_write_autochunk.go:192 saving /buckets/registry/.uploads/5898b95e46514183a7a0f0bc6419ec8460ee54e5/0001.part s3_1 | I0830 06:23:29.124379 filer.go:196 UpdateEntry /buckets/registry/.uploads/5898b95e46514183a7a0f0bc6419ec8460ee54e5/0001.part: old entry: 0001.part s3_1 | I0830 06:23:29.127061 filer.go:207 CreateEntry /buckets/registry/.uploads/8d57564b4de275ffb5f210d3e8143dbef8607349/0004.part: created s3_1 | I0830 06:23:29.128978 filer.go:207 CreateEntry /buckets/registry/.uploads/5898b95e46514183a7a0f0bc6419ec8460ee54e5/0001.part: created s3_1 | I0830 06:23:29.129031 error_handler.go:85 status 200 : s3_1 | I0830 06:23:29.140007 error_handler.go:85 status 200 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> s3_1 | <CopyPartResult><LastModified>2022-08-30T06:23:29.1327331Z</LastModified><ETag>db384c993ba5c934e18377726f9d6c29</ETag></CopyPartResult> s3_1 | I0830 06:23:29.151712 auth_credentials.go:225 v4 auth type s3_1 | I0830 06:23:29.153330 auth_credentials.go:225 v4 auth type s3_1 | I0830 06:23:29.154036 auth_credentials.go:254 user name: some_admin_user actions: [Admin Read List Tagging Write], action: Write s3_1 | I0830 06:23:29.155906 auth_credentials.go:254 user name: some_admin_user actions: [Admin Read List Tagging Write], action: Write s3_1 | I0830 06:23:29.156030 s3api_object_handlers.go:49 PutObjectHandler registry /docker/registry/v2/repositories/minio/_uploads/1abe4c43-6164-4080-adac-ca0fcdb18c6e/hashstates/sha256/42484237 s3_1 | I0830 06:23:29.160032 fi ",source-file | source-file,"[filer] DATA RACE on uploadReaderToChunks https://github.com/seaweedfs/seaweedfs/issues/3507  s3_1 | I0830 06:23:24.797198 auth_credentials.go:225 v4 auth type s3_1 | I0830 06:23:24.798512 auth_credentials.go:254 user name: some_admin_user actions: [Admin Read List Tagging Write], action: Write s3_1 | I0830 06:23:24.799422 s3api_object_multipart_handlers.go:248 PutObjectPartHandler registry 8d57564b4de275ffb5f210d3e8143dbef8607349 0004 s3_1 | I0830 06:23:24.800860 filer_server_handlers_write_upload.go:67 received byte buffer 1 s3_1 | I0830 06:23:24.819558 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 3 to 3,01ba893a4fc9 [20971520,25165824) s3_1 | I0830 06:23:24.822147 filer_server_handlers_write_upload.go:67 received byte buffer 4 s3_1 | I0830 06:23:24.878356 filer_server_handlers_write_upload.go:60 waiting for byte buffer 4 s3_1 | I0830 06:23:25.164557 filer_server_handlers_write_upload.go:67 received byte buffer 2 s3_1 | I0830 06:23:25.570195 filer_server_handlers_write_upload.go:67 received byte buffer 3 s3_1 | I0830 06:23:26.185096 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 4 to 5,01b675b06671 [8388608,12582912) s3_1 | I0830 06:23:26.185448 filer_server_handlers_write_upload.go:67 received byte buffer 4 s3_1 | I0830 06:23:26.336514 filer_server_handlers_write_upload.go:60 waiting for byte buffer 4 s3_1 | I0830 06:23:26.439257 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 5 to 4,01b9e55cf059 [16777216,20971520) s3_1 | I0830 06:23:26.439486 filer_server_handlers_write_upload.go:67 received byte buffer 4 s3_1 |  s3_1 | WARNING: DATA RACE s3_1 | Read at 0x00c00013a120 by goroutine 735: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:108 +0x22e s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:117 +0x47 s3_1 | s3_1 | Previous write at 0x00c00013a120 by goroutine 455: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:80 +0x1324 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 735 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:99 +0xf7d s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 455 (running) created at: s3_1 | net/http.(*Server).Serve() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x837 s3_1 | github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:308 +0x1b1 s3_1 |  s3_1 | I0830 06:23:26.936048 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 6 to 5,01b8993d1b57 [12582912,16777216) s3_1 | I0830 06:23:27.339330 filer_server_handlers_write_upload.go:115 uploaded 0004.part chunk 1 to 7,01bf74910830 [8388608,11026957) s3_1 | I0830 06:23:29.096974 filer_server_handlers_write_upload.go:115 uploaded 0004.part chunk 2 to 6,01bd1224517f [0,4194304) s3_1 | I0830 06:23:29.101658 filer_server_handlers_write_upload.go:115 uploaded 0004.part chunk 3 to 7,01be0b9c5e5d [4194304,8388608) s3_1 | I0830 06:23:29.107207 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 7 to 2,01c092dabc91 [29360128,33554432) s3_1 | I0830 06:23:29.109798 filer_server_handlers_write_autochunk.go:192 saving /buckets/registry/.uploads/8d57564b4de275ffb5f210d3e8143dbef8607349/0004.part s3_1 | I0830 06:23:29.111580 filer.go:222 find uncached directory: /buckets/registry/.uploads/8d57564b4de275ffb5f210d3e8143dbef8607349 s3_1 | I0830 06:23:29.116899 filer_server_handlers_write_upload.go:115 uploaded 0001.part chunk 8 to 4,01bcab96b00a [25165824,29360128) s3_1 | I0830 06:23:29.116795 filer.go:186 InsertEntry /buckets/registry/.uploads/8d57564b4de275ffb5f210d3e8143dbef8607349/0004.part: new entry: 0004.part s3_1 | I0830 06:23:29.123204 filer_server_handlers_write_autochunk.go:192 saving /buckets/registry/.uploads/5898b95e46514183a7a0f0bc6419ec8460ee54e5/0001.part s3_1 | I0830 06:23:29.124379 filer.go:196 UpdateEntry /buckets/registry/.uploads/5898b95e46514183a7a0f0bc6419ec8460ee54e5/0001.part: old entry: 0001.part s3_1 | I0830 06:23:29.127061 filer.go:207 CreateEntry /buckets/registry/.uploads/8d57564b4de275ffb5f210d3e8143dbef8607349/0004.part: created s3_1 | I0830 06:23:29.128978 filer.go:207 CreateEntry /buckets/registry/.uploads/5898b95e46514183a7a0f0bc6419ec8460ee54e5/0001.part: created s3_1 | I0830 06:23:29.129031 error_handler.go:85 status 200 : s3_1 | I0830 06:23:29.140007 error_handler.go:85 status 200 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> s3_1 | <CopyPartResult><LastModified>2022-08-30T06:23:29.1327331Z</LastModified><ETag>db384c993ba5c934e18377726f9d6c29</ETag></CopyPartResult> s3_1 | I0830 06:23:29.151712 auth_credentials.go:225 v4 auth type s3_1 | I0830 06:23:29.153330 auth_credentials.go:225 v4 auth type s3_1 | I0830 06:23:29.154036 auth_credentials.go:254 user name: some_admin_user actions: [Admin Read List Tagging Write], action: Write s3_1 | I0830 06:23:29.155906 auth_credentials.go:254 user name: some_admin_user actions: [Admin Read List Tagging Write], action: Write s3_1 | I0830 06:23:29.156030 s3api_object_handlers.go:49 PutObjectHandler registry /docker/registry/v2/repositories/minio/_uploads/1abe4c43-6164-4080-adac-ca0fcdb18c6e/hashstates/sha256/42484237 s3_1 | I0830 06:23:29.160032 fi  source-file source-file",no-bug,0.9
1226,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1226,append,- append https://github.com/chrislusf/seaweedfs/blob/1.59/weed/replication/sink/s3sink/s3_sink.go#L119 https://github.com/chrislusf/seaweedfs/blob/1.59/weed/replication/sink/filersink/fetch_write.go#L31,source-file | source-file | source-file | source-file,append - append https://github.com/chrislusf/seaweedfs/blob/1.59/weed/replication/sink/s3sink/s3_sink.go#L119 https://github.com/chrislusf/seaweedfs/blob/1.59/weed/replication/sink/filersink/fetch_write.go#L31 source-file source-file source-file source-file,no-bug,0.7
1036,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1036,Update existing file fails - Even possible?,"**Describe the bug** I want to perform updates to existing files by uploading the data to the already existing fid. The first upload works, but then all following updates will fail with an HTTP error: **System Setup** Running version 1.4.2 on Linux64 ./weed master -mdir=""master01"" -defaultReplication=002 ./weed volume -port=8081 -mserver=""localhost:9333"" -dir=""volume01"" -max=100 ./weed volume -port=8082 -mserver=""localhost:9333"" -dir=""volume02"" -max=100 ./weed volume -port=8083 -mserver=""localhost:9333"" -dir=""volume03"" -max=100 **Expected behavior** I would expect that the file upload works like the first with this file. But maybe I'm wrong and the update of an existing file is not possible. An other way would be to assign a new file id for every update and to delete the old. **Sequence** _Client:_ curl -F file=myFile http://127.0.0.1:8083/3,02b3f5780c Response: `{""size"":8,""error"":""failed to write to replicas for volume 3: [127.0.0.1:8081]: unexpected end of JSON input\n[127.0.0.1:8082]: unexpected end of JSON input"",""eTag"":""0ca153a6""}` _Master:_ No related console output _volume01:_ `I0809 23:03:11 11674 common.go:73] error writing JSON {Name: Size:8 Error: ETag:0ca153a6} status 304: http: req` _volume02:_ `I0809 23:03:11 11704 common.go:73] error writing JSON {Name: Size:8 Error: ETag:0ca153a6} status 304: http: request method or response status code does not allow body` _volume03:_  I0809 23:03:11 11688 upload_content.go:136] failing to read upload response http://127.0.0.1:8081/3,02b3f5780c?ts=1565384591&ttl=&type=replicate I0809 23:03:11 11688 upload_content.go:136] failing to read upload response http://127.0.0.1:8082/3,02b3f5780c?ts=1565384591&ttl=&type=replicate  Thank you!",source-file,"Update existing file fails - Even possible? **Describe the bug** I want to perform updates to existing files by uploading the data to the already existing fid. The first upload works, but then all following updates will fail with an HTTP error: **System Setup** Running version 1.4.2 on Linux64 ./weed master -mdir=""master01"" -defaultReplication=002 ./weed volume -port=8081 -mserver=""localhost:9333"" -dir=""volume01"" -max=100 ./weed volume -port=8082 -mserver=""localhost:9333"" -dir=""volume02"" -max=100 ./weed volume -port=8083 -mserver=""localhost:9333"" -dir=""volume03"" -max=100 **Expected behavior** I would expect that the file upload works like the first with this file. But maybe I'm wrong and the update of an existing file is not possible. An other way would be to assign a new file id for every update and to delete the old. **Sequence** _Client:_ curl -F file=myFile http://127.0.0.1:8083/3,02b3f5780c Response: `{""size"":8,""error"":""failed to write to replicas for volume 3: [127.0.0.1:8081]: unexpected end of JSON input\n[127.0.0.1:8082]: unexpected end of JSON input"",""eTag"":""0ca153a6""}` _Master:_ No related console output _volume01:_ `I0809 23:03:11 11674 common.go:73] error writing JSON {Name: Size:8 Error: ETag:0ca153a6} status 304: http: req` _volume02:_ `I0809 23:03:11 11704 common.go:73] error writing JSON {Name: Size:8 Error: ETag:0ca153a6} status 304: http: request method or response status code does not allow body` _volume03:_  I0809 23:03:11 11688 upload_content.go:136] failing to read upload response http://127.0.0.1:8081/3,02b3f5780c?ts=1565384591&ttl=&type=replicate I0809 23:03:11 11688 upload_content.go:136] failing to read upload response http://127.0.0.1:8082/3,02b3f5780c?ts=1565384591&ttl=&type=replicate  Thank you! source-file",bug,0.95
635,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/635,Volume Marked as Unwritable,"Hi Chris, I have found a bug that can cause individual volumes to become unwritable over time -- requiring a restart of seaweedfs to get the volumes back in a writable state. We have seen this in production where you see errors like this in the log file: ""Failed to read file size /tmp/7.dat stat /tmp/7.dat: bad file descriptor"" ""failing to assign a file id /dir/assign: 404 Not Found"" I believe this is caused by a rare case when the os.Stat() method in linux returns an error code because it can't read the size of a file on disk -- perhaps it is in use or something like that. When this happens, the [Size()](https://github.com/chrislusf/seaweedfs/blob/master/weed/storage/volume.go#L58) method in volume.go returns a -1 instead of the actual file size. This -1 is passed along to the master server, and it compares the -1 against the maximum volume size and sees that -1 is greater than the max: In [CollectDeadNodeAndFullVolumes](https://github.com/chrislusf/seaweedfs/blob/master/weed/topology/node.go#L246), the Size property gets converted from -1 to a uint64 if uint64(v.Size) >= volumeSizeLimit  and so the -1 then becomes the max value of a uint64, and it is always greater than volumeSizeLimit. The master server then considers the volume to be too large and it stops allowing writes to it. My naive thought for fixing this would simply be to return a 0 instead of a -1 [here](https://github.com/chrislusf/seaweedfs/blob/master/weed/storage/volume.go#L64). That would solve the integer overflow issue. I just want to make sure that this sounds like an appropriate fix to you, and ask if you can think of any unwanted side effects that this might cause. Thanks! Mike",source-file | source-file | source-file,"Volume Marked as Unwritable Hi Chris, I have found a bug that can cause individual volumes to become unwritable over time -- requiring a restart of seaweedfs to get the volumes back in a writable state. We have seen this in production where you see errors like this in the log file: ""Failed to read file size /tmp/7.dat stat /tmp/7.dat: bad file descriptor"" ""failing to assign a file id /dir/assign: 404 Not Found"" I believe this is caused by a rare case when the os.Stat() method in linux returns an error code because it can't read the size of a file on disk -- perhaps it is in use or something like that. When this happens, the [Size()](https://github.com/chrislusf/seaweedfs/blob/master/weed/storage/volume.go#L58) method in volume.go returns a -1 instead of the actual file size. This -1 is passed along to the master server, and it compares the -1 against the maximum volume size and sees that -1 is greater than the max: In [CollectDeadNodeAndFullVolumes](https://github.com/chrislusf/seaweedfs/blob/master/weed/topology/node.go#L246), the Size property gets converted from -1 to a uint64 if uint64(v.Size) >= volumeSizeLimit  and so the -1 then becomes the max value of a uint64, and it is always greater than volumeSizeLimit. The master server then considers the volume to be too large and it stops allowing writes to it. My naive thought for fixing this would simply be to return a 0 instead of a -1 [here](https://github.com/chrislusf/seaweedfs/blob/master/weed/storage/volume.go#L64). That would solve the integer overflow issue. I just want to make sure that this sounds like an appropriate fix to you, and ask if you can think of any unwanted side effects that this might cause. Thanks! Mike source-file source-file source-file",no-bug,0.9
1015,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1015,delete or vacuum leads to data loss?,"**Describe the bug** i transfing image and lossy compression image to another filer one by one in the same volume I'm sure all image before transfer in the volume 2 are correct. volume 2 is old filer valume and no longer post image, last Inspectionvolume 2 is 29GB, free space less than 10 GB, after error log volume 2 is 8.9GB only seaweedfs in the server, I'm not sure which node occupies all the disks then released disk and causes errors. **System Setup** version 30GB 1.41 linux amd64 volume `volume -max=45 -index=leveldb -mserver=""master:9333"" -port=8080` old filer `filer -master=""master:9333"" -collection ""image""` new filer `filer -master=""master:9333"" -collection ""img""` **Screenshots**  I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 14:10:55 1 volume_server_handlers_read.go:92] read /2,01273e96d6df53 isNormalVolume true error: not found I0717 14:11:05 1 volume_server_handlers_read.go:92] read /2,0172465fa26580 isNormalVolume true error: not found I0717 14:11:10 1 volume_server_handlers_read.go:92] read /2,0179b6e78fbfcf isNormalVolume true error: not found I0717 14:11:16 1 volume_server_handlers_read.go:92] read /2,0131fa097437d1 isNormalVolume true error: not found I0717 14:12:08 1 volume_server_handlers_read.go:92] read /2,011c073186daa1 isNormalVolume true error: not found I0717 14:12:08 1 volume_server_handlers_read.go:92] read /2,019f705fb54a37 isNormalVolume true error: not found I0717 14:12:12 1 volume_server_handlers_read.go:92] read /2,01120f96fbabdb isNormalVolume true error: not found I0717 14:12:13 1 volume_server_handlers_read.go:92] read /2,013242ee91232e isNormalVolume true error: not found I0717 14:12:40 1 volume_server_handlers_read.go:92] read /2,f63dbc874d94 isNormalVolume true error: not found I0717 14:13:16 1 volume_server_handlers_read.go:92] read /2,013af69a752e8a isNormalVolume true error: not found I0717 14:13:30 1 volume_server_handlers_read.go:92] read /2,0113d387393be6 isNormalVolume true error: not found I0717 14:13:40 1 volume_server_handlers_read.go:92] read /2,014aabddb480fb isNormalVolume true error: not found I0717 14:14:50 1 volume_server_handlers_read.go:92] read /2,014bcc428ad833 isNormalVolume true error: not found I0717 14:15:05 1 volume_server_handlers_read.go:92] read /2,ed6990252da4 isNormalVolume true error: EOF I0717 14:15:12 1 volume_server_handlers_read.go:92] read /2,ec43b0ba540a isNormalVolume true error: EOF I0717 14:15:12 1 volume_server_handlers_read.go:92] read /2,013e9808e11abb isNormalVolume true error: not found I0717 14:15:13 1 volume_server_handlers_read.go:92] read /2,010f5fcc1055e8 isNormalVolume true error: not found ",source-file,"delete or vacuum leads to data loss? **Describe the bug** i transfing image and lossy compression image to another filer one by one in the same volume I'm sure all image before transfer in the volume 2 are correct. volume 2 is old filer valume and no longer post image, last Inspectionvolume 2 is 29GB, free space less than 10 GB, after error log volume 2 is 8.9GB only seaweedfs in the server, I'm not sure which node occupies all the disks then released disk and causes errors. **System Setup** version 30GB 1.41 linux amd64 volume `volume -max=45 -index=leveldb -mserver=""master:9333"" -port=8080` old filer `filer -master=""master:9333"" -collection ""image""` new filer `filer -master=""master:9333"" -collection ""img""` **Screenshots**  I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 12:14:46 1 volume_read_write.go:226] visit needle error: cannot append needle: write /data/image_2.cpd: no space left on device I0717 14:10:55 1 volume_server_handlers_read.go:92] read /2,01273e96d6df53 isNormalVolume true error: not found I0717 14:11:05 1 volume_server_handlers_read.go:92] read /2,0172465fa26580 isNormalVolume true error: not found I0717 14:11:10 1 volume_server_handlers_read.go:92] read /2,0179b6e78fbfcf isNormalVolume true error: not found I0717 14:11:16 1 volume_server_handlers_read.go:92] read /2,0131fa097437d1 isNormalVolume true error: not found I0717 14:12:08 1 volume_server_handlers_read.go:92] read /2,011c073186daa1 isNormalVolume true error: not found I0717 14:12:08 1 volume_server_handlers_read.go:92] read /2,019f705fb54a37 isNormalVolume true error: not found I0717 14:12:12 1 volume_server_handlers_read.go:92] read /2,01120f96fbabdb isNormalVolume true error: not found I0717 14:12:13 1 volume_server_handlers_read.go:92] read /2,013242ee91232e isNormalVolume true error: not found I0717 14:12:40 1 volume_server_handlers_read.go:92] read /2,f63dbc874d94 isNormalVolume true error: not found I0717 14:13:16 1 volume_server_handlers_read.go:92] read /2,013af69a752e8a isNormalVolume true error: not found I0717 14:13:30 1 volume_server_handlers_read.go:92] read /2,0113d387393be6 isNormalVolume true error: not found I0717 14:13:40 1 volume_server_handlers_read.go:92] read /2,014aabddb480fb isNormalVolume true error: not found I0717 14:14:50 1 volume_server_handlers_read.go:92] read /2,014bcc428ad833 isNormalVolume true error: not found I0717 14:15:05 1 volume_server_handlers_read.go:92] read /2,ed6990252da4 isNormalVolume true error: EOF I0717 14:15:12 1 volume_server_handlers_read.go:92] read /2,ec43b0ba540a isNormalVolume true error: EOF I0717 14:15:12 1 volume_server_handlers_read.go:92] read /2,013e9808e11abb isNormalVolume true error: not found I0717 14:15:13 1 volume_server_handlers_read.go:92] read /2,010f5fcc1055e8 isNormalVolume true error: not found  source-file",no-bug,0.9
4642,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4642,ec.encode original volume maybe delete fail,"**Describe the bug** ec.encode command maybe fail when execute delete original volume step command: shell weed shell -master=xxxx lock ec.encode -collection=xxxx -volumeId=xxxx unlock  log output: shell markVolumeReadonly 154 on 10.117.32.36:9334  markVolumeReadonly 154 on 10.117.32.34:9334  markVolumeReadonly 154 on 10.117.32.35:9334    delete volume 154 from 10.117.32.36:9334 delete volume 154 from 10.117.32.35:9334 delete volume 154 from 10.117.32.35:9334  > 10.117.32.35 delete execute repeated, 10.117.32.34 not delete **System Setup** any cluster with more than 2 replica, for example: -defaultReplication=020 **Screenshots** ![image](https://github.com/seaweedfs/seaweedfs/assets/44025291/281e95b6-0e68-4ccc-a576-7faf2c528c34) **Additional context** i think this caused by the shared memory of the locations slice.While iterating through the locations and deleting the original volume, the master client will also update the members in the locations. **reproduce**: add a sleep within the loop. file: weed/shell/command_ec_encode.go, line: 185 ![image](https://github.com/seaweedfs/seaweedfs/assets/44025291/f3a89a70-952c-476a-8533-318eb5b58377)",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"ec.encode original volume maybe delete fail **Describe the bug** ec.encode command maybe fail when execute delete original volume step command: shell weed shell -master=xxxx lock ec.encode -collection=xxxx -volumeId=xxxx unlock  log output: shell markVolumeReadonly 154 on 10.117.32.36:9334  markVolumeReadonly 154 on 10.117.32.34:9334  markVolumeReadonly 154 on 10.117.32.35:9334    delete volume 154 from 10.117.32.36:9334 delete volume 154 from 10.117.32.35:9334 delete volume 154 from 10.117.32.35:9334  > 10.117.32.35 delete execute repeated, 10.117.32.34 not delete **System Setup** any cluster with more than 2 replica, for example: -defaultReplication=020 **Screenshots** ![image](https://github.com/seaweedfs/seaweedfs/assets/44025291/281e95b6-0e68-4ccc-a576-7faf2c528c34) **Additional context** i think this caused by the shared memory of the locations slice.While iterating through the locations and deleting the original volume, the master client will also update the members in the locations. **reproduce**: add a sleep within the loop. file: weed/shell/command_ec_encode.go, line: 185 ![image](https://github.com/seaweedfs/seaweedfs/assets/44025291/f3a89a70-952c-476a-8533-318eb5b58377) source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
6497,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6497,Using PUT object with bucket of invalid name leads to unremovable bucket," root@Hepatitis:~# s3cmd put ab s3://aa/a upload: 'ab' -> 's3://aa/a' [1 of 1] 0 of 0 0% in 0s 0.00 B/s done WARNING: Upload failed: /a (500 (InternalError): We encountered an internal error, please try again.) WARNING: Waiting 3 sec upload: 'ab' -> 's3://aa/a' [1 of 1] 0 of 0 0% in 0s 0.00 B/s done WARNING: Upload failed: /a (500 (InternalError): We encountered an internal error, please try again.) WARNING: Waiting 6 sec ^CSee ya! root@Hepatitis:~# s3cmd put ab s3://aa  The created aa bucket can then not be removed even via ``weed shell`` due to the invalid bucket name of ``aa``",source-file | test-file | source-file,"Using PUT object with bucket of invalid name leads to unremovable bucket  root@Hepatitis:~# s3cmd put ab s3://aa/a upload: 'ab' -> 's3://aa/a' [1 of 1] 0 of 0 0% in 0s 0.00 B/s done WARNING: Upload failed: /a (500 (InternalError): We encountered an internal error, please try again.) WARNING: Waiting 3 sec upload: 'ab' -> 's3://aa/a' [1 of 1] 0 of 0 0% in 0s 0.00 B/s done WARNING: Upload failed: /a (500 (InternalError): We encountered an internal error, please try again.) WARNING: Waiting 6 sec ^CSee ya! root@Hepatitis:~# s3cmd put ab s3://aa  The created aa bucket can then not be removed even via ``weed shell`` due to the invalid bucket name of ``aa`` source-file test-file source-file",bug,0.85
3083,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3083,[hashicorp raft] bug: sometimes peers are deleted after master change,"**Describe the bug** sometimes but regularly peers are deleted after master change **System Setup**  3.04   weed master -resumeState=true -raftHashicorp  **Expected behavior** after changing the master, the list of peers was unchanged **Additional context** raft logs:  May 20, 2022 @ 12:39:21.877 2022-05-20T07:39:21.877Z [WARN] raft: failed to contact: server-id=slow-master-0.dc2:9333 time=317.196538ms slow-master-1(node9-dc1) May 20, 2022 @ 12:39:21.999 2022-05-20T07:39:21.999Z [WARN] raft: heartbeat timeout reached, starting election: last-leader-addr=slow-master-1.dc1:9333 last-leader-id= slow-master-0(node9-dc2) May 20, 2022 @ 12:39:22.001 2022-05-20T07:39:22.001Z [WARN] raft: rejecting vote request since we have a leader: from=slow-master-0.dc2:9333 leader=slow-master-1.dc1:9333 leader-id="""" slow-master-0(node3-dc2) May 20, 2022 @ 12:39:22.002 2022-05-20T07:39:22.000Z [WARN] raft: rejecting vote request since we have a leader: from=slow-master-0.dc2:9333 leader=slow-master-1.dc1:9333 leader-id=slow-master-1.dc1:9333 slow-master-1(node9-dc1) May 20, 2022 @ 12:39:22.164 2022-05-20T07:39:22.163Z [WARN] raft: failed to contact: server-id=slow-master-0.dc2:9333 time=602.853871ms slow-master-1(node9-dc1) May 20, 2022 @ 12:39:22.199 2022-05-20T07:39:22.198Z [ERROR] raft: peer has newer term, stopping replication: peer=""{Voter slow-master-0.dc2:9333 slow-master-0.dc2:19333}"" slow-master-1(node9-dc1) May 20, 2022 @ 12:39:22.754 2022-05-20T07:39:22.754Z [WARN] raft: heartbeat timeout reached, starting election: last-leader-addr=slow-master-1.dc1:9333 last-leader-id= slow-master-0(node3-dc1) May 20, 2022 @ 13:51:23.826 2022-05-20T08:51:23.825Z [WARN] raft: heartbeat timeout reached, not part of a stable configuration or a non-voter, not triggering a leader election slow-master-1(node9-dc1) May 20, 2022 @ 13:51:24.259 2022-05-20T08:51:24.257Z [WARN] raft: not part of stable configuration, aborting election slow-master-0(node9-dc2)  weed shell  > cluster.raft.ps the raft cluster has 1 servers * slow-master-0.dc1:9333 slow-master-0.dc1:19333 (Voter) >  https://github.com/hashicorp/raft/issues/506",source-file,"[hashicorp raft] bug: sometimes peers are deleted after master change **Describe the bug** sometimes but regularly peers are deleted after master change **System Setup**  3.04   weed master -resumeState=true -raftHashicorp  **Expected behavior** after changing the master, the list of peers was unchanged **Additional context** raft logs:  May 20, 2022 @ 12:39:21.877 2022-05-20T07:39:21.877Z [WARN] raft: failed to contact: server-id=slow-master-0.dc2:9333 time=317.196538ms slow-master-1(node9-dc1) May 20, 2022 @ 12:39:21.999 2022-05-20T07:39:21.999Z [WARN] raft: heartbeat timeout reached, starting election: last-leader-addr=slow-master-1.dc1:9333 last-leader-id= slow-master-0(node9-dc2) May 20, 2022 @ 12:39:22.001 2022-05-20T07:39:22.001Z [WARN] raft: rejecting vote request since we have a leader: from=slow-master-0.dc2:9333 leader=slow-master-1.dc1:9333 leader-id="""" slow-master-0(node3-dc2) May 20, 2022 @ 12:39:22.002 2022-05-20T07:39:22.000Z [WARN] raft: rejecting vote request since we have a leader: from=slow-master-0.dc2:9333 leader=slow-master-1.dc1:9333 leader-id=slow-master-1.dc1:9333 slow-master-1(node9-dc1) May 20, 2022 @ 12:39:22.164 2022-05-20T07:39:22.163Z [WARN] raft: failed to contact: server-id=slow-master-0.dc2:9333 time=602.853871ms slow-master-1(node9-dc1) May 20, 2022 @ 12:39:22.199 2022-05-20T07:39:22.198Z [ERROR] raft: peer has newer term, stopping replication: peer=""{Voter slow-master-0.dc2:9333 slow-master-0.dc2:19333}"" slow-master-1(node9-dc1) May 20, 2022 @ 12:39:22.754 2022-05-20T07:39:22.754Z [WARN] raft: heartbeat timeout reached, starting election: last-leader-addr=slow-master-1.dc1:9333 last-leader-id= slow-master-0(node3-dc1) May 20, 2022 @ 13:51:23.826 2022-05-20T08:51:23.825Z [WARN] raft: heartbeat timeout reached, not part of a stable configuration or a non-voter, not triggering a leader election slow-master-1(node9-dc1) May 20, 2022 @ 13:51:24.259 2022-05-20T08:51:24.257Z [WARN] raft: not part of stable configuration, aborting election slow-master-0(node9-dc2)  weed shell  > cluster.raft.ps the raft cluster has 1 servers * slow-master-0.dc1:9333 slow-master-0.dc1:19333 (Voter) >  https://github.com/hashicorp/raft/issues/506 source-file",no-bug,0.9
1957,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1957,"Failed to reply metadata change pq: relation ""iso5"" does not exist","**Describe the bug** I put file to backet ""iso5"" using s3cmd `s3cmd put /mnt/bigdisk/iso/virtio-win-0.1.185.iso s3://iso5/` <details> <summary>S3cmd output</summary> <p> bash upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 1 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 3s 4.54 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 2 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.30 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 3 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.26 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 4 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.15 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 5 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 3s 4.94 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 6 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 3s 4.94 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 7 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.33 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 8 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.52 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 9 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.36 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 10 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.31 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 11 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.42 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 12 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.47 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 13 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.33 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 14 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.66 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 15 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.74 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 16 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.85 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 17 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.67 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 18 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.70 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 19 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.32 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 20 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.39 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 21 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.62 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 22 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.59 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 23 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.35 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 24 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.26 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 25 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.18 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 26 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 4s 3.70 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 27 of 27, 3MB] [1 of 1] 3534848 of 3534848 100% in 1s 3.21 MB/s done  </p> </details> _The file upload is successful, but one of the two filers crashes and restarts._ <details> <summary>See d01server04t filer1 log</summary> <p> bash  02 09:52:49 d01server04t systemd[1]: Started weed filer server of cluster.  02 09:52:55 d01server04t weed-filer[37643]: I0402 09:52:55 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:52:56 d01server04t weed-filer[37643]: I0402 09:52:56 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:52:57 d01server04t weed-filer[37643]: I0402 09:52:57 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:52:58 d01server04t weed-filer[37643]: I0402 09:52:58 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:52:59 d01server04t weed-filer[37643]: I0402 09:52:59 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:53:00 d01server04t weed-filer[37643]: I0402 09:53:00 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 masterclient.go:126] redirected to leader 10.11.10.72:9333  02 09:53:20 d01server04t weed-filer[37643]: W0402 09:53:20 37643 filer_server.go:117] skipping default store dir in /var/lib/seaweedfs/filer/filerldb2  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 filer.go:101] existing filer.store.id = 541754507  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 configuration.go:28] configured filer store to postgres2  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 meta_aggregator.go:67] connecting to peer filer 10.10.10.148:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 filer.go:196] Start Seaweed Filer 30GB 2.36 6b7aa96 at 10.10.10.148:8888  02 09:53:21 d01server04t weed-filer[37643]: I0402 09:53:21 37643 meta_aggregator.go:191] readOffset 10.11.10.76:8888 : 1617346219824758635  02 09:53:21 d01server04t weed-filer[37643]: I0402 09:53:21 37643 meta_aggregator.go:78] follow peer: 10.11.10.76:8888, last 2021-04-02 09:50:19.824758635 +0300 MSK (1617346219824758635)  02 09:53:21 d01server04t weed-filer[37643]: I0402 09:53:21 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 filer_grpc_server_sub_meta.go:196] + listener filer:10.10.10.148:8888@10.10.10.148:39244  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 filer_grpc_server_sub_meta.go:77] filer:10.10.10.148:8888@10.10.10.148:39244 local subscribe / from 2021-04-02 09:52:20.885337245 +0300 MSK  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 s3.go:162] S3 read filer buckets dir: /buckets  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 s3.go:169] connected to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:53:22 d01server04t weed-filer[37643]: W0402 09:53:22 37643 auth_credentials.go:48] fail to load config: read S3 config: http://10.10.10.148:8888/etc/iam/identity.json: 404 Not Found  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 s3.go:201] Start Seaweed S3 API Server 30GB 2.36 6b7aa96 at https port 443  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 filer_grpc_server_sub_meta.go:196] + listener s3@10.10.10.148:39244  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 filer_grpc_server_sub_meta.go:26] s3@10.10.10.148:39244 starts to subscribe /etc/iam/identity.json from 2021-04-02 09:53:22.432694589 +0300 MSK  02 09:53:24 d01server04t weed-filer[37643]: I0402 09:53:24 37643 filer_grpc_server_sub_meta.go:196] + listener filer:10.11.10.76:8888@10.11.10.76:59222  02 09:53:24 d01server04t weed-filer[37643]: I0402 09:53:24 37643 filer_grpc_server_sub_meta.go:77] filer:10.11.10.76:8888@10.11.10.76:59222 local subscribe / from 2021-04-01 13:40:24.386199338 +0300 MSK  02 10:21:20 d01server04t weed-filer[37643]: I0402 10:21:20 37643 meta_aggregator.go:93] synced with 10.11.10.76:8888  02 10:21:20 d01server04t weed-filer[37643]: E0402 10:21:20 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads: pq: relation ""iso5"" does not exist  02 10:21:20 d01server04t weed-filer[37643]: E0402 10:21:20 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6: pq: relation ""iso5"" does not exist  02 10:21:24 d01server04t weed-filer[37643]: E0402 10:21:24 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0001.part: pq: relation ""iso5"" does not exist  02 10:21:28 d01server04t weed-filer[37643]: E0402 10:21:28 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0002.part: pq: relation ""iso5"" does not exist  02 10:21:32 d01server04t weed-filer[37643]: E0402 10:21:32 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0003.part: pq: relation ""iso5"" does not exist  02 10:21:38 d01server04t weed-filer[37643]: E0402 10:21:38 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0004.part: pq: relation ""iso5"" does not exist  02 10:21:44 d01server04t weed-filer[37643]: E0402 10:21:44 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0005.part: pq: relation ""iso5"" does not exist  02 10:21:51 d01server04t weed-filer[37643]: E0402 10:21:51 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0006.part: pq: relation ""iso5"" does not exist  02 10:21:58 d01server04t weed-filer[37643]: E0402 10:21:58 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0007.part: pq: relation ""iso5"" does not exist  02 10:22:05 d01server04t weed-filer[37643]: E0402 10:22:05 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0008.part: pq: relation ""iso5"" does not exist  02 10:22:11 d01server04t weed-filer[37643]: E0402 10:22:11 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0009.part: pq: relation ""iso5"" does not exist  02 10:22:18 d01server04t weed-filer[37643]: E0402 10:22:18 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0010.part: pq: relation ""iso5"" does not exist  02 10:22:24 d01server04t weed-filer[37643]: E0402 10:22:24 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0011.part: pq: relation ""iso5"" does not exist  02 10:22:30 d01server04t weed-filer[37643]: E0402 10:22:30 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0012.part: pq: relation ""iso5"" does not exist  02 10:22:36 d01server04t weed-filer[37643]: E0402 10:22:36 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0013.part: pq: relation ""iso5"" does not exist  02 10:22:41 d01server04t weed-filer[37643]: E0402 10:22:41 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0014.part: pq: relation ""iso5"" does not exist  02 10:22:46 d01server04t weed-filer[37643]: E0402 10:22:46 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0015.part: pq: relation ""iso5"" does not exist  02 10:22:52 d01server04t weed-filer[37643]: E0402 10:22:52 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0016.part: pq: relation ""iso5"" does not exist  02 10:22:57 d01server04t weed-filer[37643]: E0402 10:22:57 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0017.part: pq: relation ""iso5"" does not exist  02 10:23:01 d01server04t weed-filer[37643]: E0402 10:23:01 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0018.part: pq: relation ""iso5"" does not exist  02 10:23:05 d01server04t weed-filer[37643]: E0402 10:23:05 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0019.part: pq: relation ""iso5"" does not exist  02 10:23:10 d01server04t weed-filer[37643]: E0402 10:23:10 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0020.part: pq: relation ""iso5"" does not exist  02 10:23:14 d01server04t weed-filer[37643]: E0402 10:23:14 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0021.part: pq: relation ""iso5"" does not exist  02 10:23:19 d01server04t weed-filer[37643]: E0402 10:23:19 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0022.part: pq: relation ""iso5"" does not exist  02 10:23:25 d01server04t weed-filer[37643]: E0402 10:23:25 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0023.part: pq: relation ""iso5"" does not exist  02 10:23:32 d01server04t weed-filer[37643]: E0402 10:23:32 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0024.part: pq: relation ""iso5"" does not exist  02 10:23:38 d01server04t weed-filer[37643]: E0402 10:23:38 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0025.part: pq: relation ""iso5"" does not exist  02 10:23:42 d01server04t weed-filer[37643]: E0402 10:23:42 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0026.part: pq: relation ""iso5"" does not exist  02 10:23:43 d01server04t weed-filer[37643]: E0402 10:23:43 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0027.part: pq: relation ""iso5"" does not exist  02 10:23:43 d01server04t weed-filer[37643]: E0402 10:23:43 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/virtio-win-0.1.185.iso: pq: relation ""iso5"" does not exist  02 10:23:43 d01server04t weed-filer[37643]: panic: runtime error: invalid memory address or nil pointer dereference  02 10:23:43 d01server04t weed-filer[37643]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x118 pc=0xec9c8d]  02 10:23:43 d01server04t weed-filer[37643]: goroutine 125 [running]:  02 10:23:43 d01server04t weed-filer[37643]: github.com/chrislusf/seaweedfs/weed/filer.(*FilerStoreWrapper).DeleteEntry(0xc000625980, 0x2621610, 0xc000050080, 0xc0006405f0, 0x45, 0x0, 0x0)  02 10:23:43 d01server04t systemd[1]: weed-filer.service: main process exited, code=exited, status=2/INVALIDARGUMENT  02 10:23:43 d01server04t systemd[1]: Unit weed-filer.service entered failed state.  02 10:23:43 d01server04t systemd[1]: weed-filer.service failed.  02 10:24:13 d01server04t systemd[1]: weed-filer.service holdoff time over, scheduling restart.  02 10:24:13 d01server04t systemd[1]: Stopped weed filer server of cluster.  02 10:24:13 d01server04t systemd[1]: Started weed filer server of cluster.  02 10:24:19 d01server04t weed-filer[43721]: I0402 10:24:19 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:20 d01server04t weed-filer[43721]: I0402 10:24:20 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:21 d01server04t weed-filer[43721]: I0402 10:24:21 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:22 d01server04t weed-filer[43721]: I0402 10:24:22 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:23 d01server04t weed-filer[43721]: I0402 10:24:23 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:24 d01server04t weed-filer[43721]: I0402 10:24:24 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:25 d01server04t weed-filer[43721]: I0402 10:24:25 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:26 d01server04t weed-filer[43721]: I0402 10:24:26 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:27 d01server04t weed-filer[43721]: I0402 10:24:27 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:28 d01server04t weed-filer[43721]: I0402 10:24:28 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:29 d01server04t weed-filer[43721]: I0402 10:24:29 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:30 d01server04t weed-filer[43721]: I0402 10:24:30 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:31 d01server04t weed-filer[43721]: I0402 10:24:31 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:32 d01server04t weed-filer[43721]: I0402 10:24:32 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:33 d01server04t weed-filer[43721]: I0402 10:24:33 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:34 d01server04t weed-filer[43721]: I0402 10:24:34 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:35 d01server04t weed-filer[43721]: I0402 10:24:35 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:36 d01server04t weed-filer[43721]: I0402 10:24:36 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:37 d01server04t weed-filer[43721]: I0402 10:24:37 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:38 d01server04t weed-filer[43721]: I0402 10:24:38 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:39 d01server04t weed-filer[43721]: I0402 10:24:39 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:40 d01server04t weed-filer[43721]: I0402 10:24:40 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:41 d01server04t weed-filer[43721]: I0402 10:24:41 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:42 d01server04t weed-filer[43721]: I0402 10:24:42 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:43 d01server04t weed-filer[43721]: I0402 10:24:43 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:44 d01server04t weed-filer[43721]: I0402 10:24:44 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 masterclient.go:126] redirected to leader 10.11.10.72:9333  02 10:24:45 d01server04t weed-filer[43721]: W0402 10:24:45 43721 filer_server.go:117] skipping default store dir in /var/lib/seaweedfs/filer/filerldb2  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 filer.go:101] existing filer.store.id = 541754507  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 configuration.go:28] configured filer store to postgres2  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 meta_aggregator.go:67] connecting to peer filer 10.10.10.148:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 filer.go:196] Start Seaweed Filer 30GB 2.36 6b7aa96 at 10.10.10.148:8888  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 meta_aggregator.go:191] readOffset 10.11.10.76:8888 : 1617348080880875447  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 meta_aggregator.go:78] follow peer: 10.11.10.76:8888, last 2021-04-02 10:21:20.880875447 +0300 MSK (1617348080880875447)  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 s3.go:162] S3 read filer buckets dir: /buckets  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 s3.go:169] connected to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:45 d01server04t weed-filer[43721]: W0402 10:24:45 43721 auth_credentials.go:48] fail to load config: read S3 config: http://10.10.10.148:8888/etc/iam/identity.json: 404 Not Found  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 s3.go:201] Start Seaweed S3 API Server 30GB 2.36 6b7aa96 at https port 443  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 filer_grpc_server_sub_meta.go:196] + listener s3@10.10.10.148:43326  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 filer_grpc_server_sub_meta.go:26] s3@10.10.10.148:43326 starts to subscribe /etc/iam/identity.json from 2021-04-02 10:24:45.663820992 +0300 MSK  02 10:24:46 d01server04t weed-filer[43721]: I0402 10:24:46 43721 filer_grpc_server_sub_meta.go:196] + listener filer:10.10.10.148:8888@10.10.10.148:43326  02 10:24:46 d01server04t weed-filer[43721]: I0402 10:24:46 43721 filer_grpc_server_sub_meta.go:77] filer:10.10.10.148:8888@10.10.10.148:43326 local subscribe / from 2021-04-02 10:23:45.095542048 +0300 MSK  02 10:24:52 d01server04t weed-filer[43721]: I0402 10:24:52 43721 filer_grpc_server_sub_meta.go:196] + listener filer:10.11.10.76:8888@10.11.10.76:35024  02 10:24:52 d01server04t weed-filer[43721]: I0402 10:24:52 43721 filer_grpc_server_sub_meta.go:77] filer:10.11.10.76:8888@10.11.10.76:35024 local subscribe / from 2021-04-01 13:40:24.386199338 +0300 MSK  02 12:33:37 d01server04t weed-filer[43721]: I0402 12:33:37 43721 meta_aggregator.go:93] synced with 10.11.10.76:8888  </p> </details> <details> <summary>See d02server05t filer2 log</summary> <p> bash  02 10:21:24 d02server05t weed-filer[114137]: I0402 10:21:24 14137 filer_grpc_server_sub_meta.go:201] - listener filer:10.10.10.148:8888@10.10.10.148:39402  02 10:23:43 d02server05t weed-filer[114137]: I0402 10:23:43 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: rpc error: code = Unavailable desc = transport is closing  02 10:23:45 d02server05t weed-filer[114137]: I0402 10:23:45 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:46 d02server05t weed-filer[114137]: I0402 10:23:46 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:48 d02server05t weed-filer[114137]: I0402 10:23:48 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:50 d02server05t weed-filer[114137]: I0402 10:23:50 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:51 d02server05t weed-filer[114137]: I0402 10:23:51 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:53 d02server05t weed-filer[114137]: I0402 10:23:53 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:55 d02server05t weed-filer[114137]: I0402 10:23:55 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:57 d02server05t weed-filer[114137]: I0402 10:23:57 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:58 d02server05t weed-filer[114137]: I0402 10:23:58 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:00 d02server05t weed-filer[114137]: I0402 10:24:00 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:02 d02server05t weed-filer[114137]: I0402 10:24:02 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:04 d02server05t weed-filer[114137]: I0402 10:24:04 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:05 d02server05t weed-filer[114137]: I0402 10:24:05 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:07 d02server05t weed-filer[114137]: I0402 10:24:07 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:09 d02server05t weed-filer[114137]: I0402 10:24:09 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:11 d02server05t weed-filer[114137]: I0402 10:24:11 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:12 d02server05t weed-filer[114137]: I0402 10:24:12 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:14 d02server05t weed-filer[114137]: I0402 10:24:14 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:16 d02server05t weed-filer[114137]: I0402 10:24:16 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:17 d02server05t weed-filer[114137]: I0402 10:24:17 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:19 d02server05t weed-filer[114137]: I0402 10:24:19 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:21 d02server05t weed-filer[114137]: I0402 10:24:21 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:23 d02server05t weed-filer[114137]: I0402 10:24:23 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:24 d02server05t weed-filer[114137]: I0402 10:24:24 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:26 d02server05t weed-filer[114137]: I0402 10:24:26 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:28 d02server05t weed-filer[114137]: I0402 10:24:28 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:30 d02server05t weed-filer[114137]: I0402 10:24:30 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:31 d02server05t weed-filer[114137]: I0402 10:24:31 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:33 d02server05t weed-filer[114137]: I0402 10:24:33 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:35 d02server05t weed-filer[114137]: I0402 10:24:35 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:37 d02server05t weed-filer[114137]: I0402 10:24:37 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:38 d02server05t weed-filer[114137]: I0402 10:24:38 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:40 d02server05t weed-filer[114137]: I0402 10:24:40 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:42 d02server05t weed-filer[114137]: I0402 10:24:42 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:44 d02server05t weed-filer[114137]: I0402 10:24:44 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:45 d02server05t weed-filer[114137]: I0402 10:24:45 14137 filer_grpc_server_sub_meta.go:196] + listener filer:10.10.10.148:8888@10.10.10.148:47746  02 10:24:45 d02server05t weed-filer[114137]: I0402 10:24:45 14137 filer_grpc_server_sub_meta.go:77] filer:10.10.10.148:8888@10.10.10.148:47746 local subscribe / from 2021-04-02 10:21:20.880875447 +0300 MSK  02 10:24:45 d02server05t weed-filer[114137]: I0402 10:24:45 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:47 d02server05t weed-filer[114137]: I0402 10:24:47 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:49 d02server05t weed-filer[114137]: I0402 10:24:49 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:50 d02server05t weed-filer[114137]: I0402 10:24:50 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 11:54:05 d02server05t weed-filer[114137]: E0402 11:54:05 14137 auth_credentials_subscribe.go:66] subscribing filer meta change: rpc error: code = Unavailable desc = transport is closing  02 11:54:05 d02server05t weed-filer[114137]: I0402 11:54:05 14137 meta_aggregator.go:151] subscribing remote 10.11.10.76:8888 meta change: rpc error: code = Unavailable desc = transport is closing  02 11:54:06 d02server05t weed-filer[114137]: I0402 11:54:06 14137 filer_grpc_server_sub_meta.go:196] + listener s3@10.11.10.76:45624  02 11:54:06 d02server05t weed-filer[114137]: I0402 11:54:06 14137 filer_grpc_server_sub_meta.go:26] s3@10.11.10.76:45624 starts to subscribe /etc/iam/identity.json from 2021-04-01 16:59:46.479385901 +0300 MSK  02 11:54:07 d02server05t weed-filer[114137]: I0402 11:54:07 14137 filer_grpc_server_sub_meta.go:196] + listener filer:10.11.10.76:8888@10.11.10.76:45624  02 11:54:07 d02server05t weed-filer[114137]: I0402 11:54:07 14137 filer_grpc_server_sub_meta.go:77] filer:10.11.10.76:8888@10.11.10.76:45624 local subscribe / from 2021-04-02 10:23:43.287381707 +0300 MSK  02 12:33:37 d02server05t weed-filer[114137]: I0402 12:33:37 14137 filer_grpc_server_sub_meta.go:187] => client filer:10.10.10.148:8888@10.10.10.148:43660: rpc error: code = Unavailable desc = transport is closing  02 12:33:37 d02server05t weed-filer[114137]: I0402 12:33:37 14137 filer_grpc_server_sub_meta.go:187] => client filer:10.11.10.76:8888@10.11.10.76:59254: rpc error: code = Unavailable desc = transport is closing  02 12:33:37 d02server05t weed-filer[114137]: E0402 12:33:37 14137 filer_grpc_server_sub_meta.go:110] processed to 2021-04-02 12:33:37.150608013 +0300 MSK: rpc error: code = Unavailable desc = transport is closing  02 12:33:37 d02server05t weed-filer[114137]: E0402 12:33:37 14137 filer_grpc_server_sub_meta.go:110] processed to 2021-04-02 12:33:37.150608013 +0300 MSK: rpc error: code = Unavailable desc = transport is closing  02 12:33:40 d02server05t weed-filer[114137]: I0402 12:33:40 14137 filer_grpc_server_sub_meta.go:201] - listener filer:10.11.10.76:8888@10.11.10.76:59254  02 12:33:40 d02server05t weed-filer[114137]: I0402 12:33:40 14137 filer_grpc_server_sub_meta.go:201]  </p> </details> My configuration.  defaultreplication = '101' masters = 10.10.10.145:9333,10.10.10.146:9333,10.10.10.148:9333,10.11.10.72:9333,10.11.10.73:9333,10.11.10.74:9333,10.12.10.20:9333 volumes = 10.10.10.145:8080,10.10.10.146:8080,10.10.10.148:8080,10.10.10.150:8080,10.11.10.72:8080,10.11.10.73:8080,10.11.10.74:8080,10.11.10.75:8080,10.11.10.76:8080,10.11.10.77:8080 filers = 10.11.10.76:8888,10.10.10.148:8888 filers have peers = 10.11.10.76:8888,10.10.10.148:8888   filer1 - d01server04t - 10.10.10.148 - posgresql 9.6 store filer2 - d02server05t - 10.11.10.76 - other posgresql 9.6 store  **System Setup** - OS version CentOS Linux release 7.6.1810 - output of `weed version` version 30GB 2.36 6b7aa96 linux amd64 - if using filer, show the content of `filer.toml` **Filer1** <details> <summary>Filer1 filer.toml</summary> <p>  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml  # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false # directories under this folder will be automatically creating a separate bucket buckets_folder = ""/buckets""  # The following are filer store options  [postgres2] enabled = true createTable =  CREATE TABLE IF NOT EXISTS ""%s"" ( dirhash BIGINT, name VARCHAR(65535), directory VARCHAR(65535), meta bytea, PRIMARY KEY (dirhash, name) );  hostname = ""10.11.10.253"" port = 5432 username = ""seaweedfs"" password = ""pass"" database = ""seaweedfs"" # create or use an existing database schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0  </p> </details> **Filer2** <details> <summary>Filer1 filer.toml</summary> <p>  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml  # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false # directories under this folder will be automatically creating a separate bucket buckets_folder = ""/buckets""  # The following are filer store options  [postgres2] enabled = true createTable =  CREATE TABLE IF NOT EXISTS ""%s"" ( dirhash BIGINT, name VARCHAR(65535), directory VARCHAR(65535), meta bytea, PRIMARY KEY (dirhash, name) );  hostname = ""10.10.10.110"" port = 5432 username = ""seaweedfs"" password = ""pass"" database = ""seaweedfs"" # create or use an existing database schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0  </p> </details> **Expected behavior** A clear and concise description of what you expected to happen. Synchronization of metadata without errors",source-file | source-file,"Failed to reply metadata change pq: relation ""iso5"" does not exist **Describe the bug** I put file to backet ""iso5"" using s3cmd `s3cmd put /mnt/bigdisk/iso/virtio-win-0.1.185.iso s3://iso5/` <details> <summary>S3cmd output</summary> <p> bash upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 1 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 3s 4.54 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 2 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.30 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 3 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.26 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 4 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.15 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 5 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 3s 4.94 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 6 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 3s 4.94 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 7 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.33 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 8 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.52 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 9 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.36 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 10 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.31 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 11 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.42 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 12 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.47 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 13 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.33 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 14 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.66 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 15 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.74 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 16 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.85 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 17 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.67 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 18 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.70 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 19 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.32 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 20 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.39 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 21 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.62 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 22 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.59 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 23 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.35 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 24 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.26 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 25 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 2s 5.18 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 26 of 27, 15MB] [1 of 1] 15728640 of 15728640 100% in 4s 3.70 MB/s done upload: '/mnt/bigdisk/iso/virtio-win-0.1.185.iso' -> 's3://iso5/virtio-win-0.1.185.iso' [part 27 of 27, 3MB] [1 of 1] 3534848 of 3534848 100% in 1s 3.21 MB/s done  </p> </details> _The file upload is successful, but one of the two filers crashes and restarts._ <details> <summary>See d01server04t filer1 log</summary> <p> bash  02 09:52:49 d01server04t systemd[1]: Started weed filer server of cluster.  02 09:52:55 d01server04t weed-filer[37643]: I0402 09:52:55 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:52:56 d01server04t weed-filer[37643]: I0402 09:52:56 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:52:57 d01server04t weed-filer[37643]: I0402 09:52:57 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:52:58 d01server04t weed-filer[37643]: I0402 09:52:58 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:52:59 d01server04t weed-filer[37643]: I0402 09:52:59 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:53:00 d01server04t weed-filer[37643]: I0402 09:53:00 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 masterclient.go:126] redirected to leader 10.11.10.72:9333  02 09:53:20 d01server04t weed-filer[37643]: W0402 09:53:20 37643 filer_server.go:117] skipping default store dir in /var/lib/seaweedfs/filer/filerldb2  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 filer.go:101] existing filer.store.id = 541754507  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 configuration.go:28] configured filer store to postgres2  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 meta_aggregator.go:67] connecting to peer filer 10.10.10.148:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 09:53:20 d01server04t weed-filer[37643]: I0402 09:53:20 37643 filer.go:196] Start Seaweed Filer 30GB 2.36 6b7aa96 at 10.10.10.148:8888  02 09:53:21 d01server04t weed-filer[37643]: I0402 09:53:21 37643 meta_aggregator.go:191] readOffset 10.11.10.76:8888 : 1617346219824758635  02 09:53:21 d01server04t weed-filer[37643]: I0402 09:53:21 37643 meta_aggregator.go:78] follow peer: 10.11.10.76:8888, last 2021-04-02 09:50:19.824758635 +0300 MSK (1617346219824758635)  02 09:53:21 d01server04t weed-filer[37643]: I0402 09:53:21 37643 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 filer_grpc_server_sub_meta.go:196] + listener filer:10.10.10.148:8888@10.10.10.148:39244  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 filer_grpc_server_sub_meta.go:77] filer:10.10.10.148:8888@10.10.10.148:39244 local subscribe / from 2021-04-02 09:52:20.885337245 +0300 MSK  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 s3.go:162] S3 read filer buckets dir: /buckets  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 s3.go:169] connected to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 09:53:22 d01server04t weed-filer[37643]: W0402 09:53:22 37643 auth_credentials.go:48] fail to load config: read S3 config: http://10.10.10.148:8888/etc/iam/identity.json: 404 Not Found  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 s3.go:201] Start Seaweed S3 API Server 30GB 2.36 6b7aa96 at https port 443  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 filer_grpc_server_sub_meta.go:196] + listener s3@10.10.10.148:39244  02 09:53:22 d01server04t weed-filer[37643]: I0402 09:53:22 37643 filer_grpc_server_sub_meta.go:26] s3@10.10.10.148:39244 starts to subscribe /etc/iam/identity.json from 2021-04-02 09:53:22.432694589 +0300 MSK  02 09:53:24 d01server04t weed-filer[37643]: I0402 09:53:24 37643 filer_grpc_server_sub_meta.go:196] + listener filer:10.11.10.76:8888@10.11.10.76:59222  02 09:53:24 d01server04t weed-filer[37643]: I0402 09:53:24 37643 filer_grpc_server_sub_meta.go:77] filer:10.11.10.76:8888@10.11.10.76:59222 local subscribe / from 2021-04-01 13:40:24.386199338 +0300 MSK  02 10:21:20 d01server04t weed-filer[37643]: I0402 10:21:20 37643 meta_aggregator.go:93] synced with 10.11.10.76:8888  02 10:21:20 d01server04t weed-filer[37643]: E0402 10:21:20 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads: pq: relation ""iso5"" does not exist  02 10:21:20 d01server04t weed-filer[37643]: E0402 10:21:20 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6: pq: relation ""iso5"" does not exist  02 10:21:24 d01server04t weed-filer[37643]: E0402 10:21:24 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0001.part: pq: relation ""iso5"" does not exist  02 10:21:28 d01server04t weed-filer[37643]: E0402 10:21:28 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0002.part: pq: relation ""iso5"" does not exist  02 10:21:32 d01server04t weed-filer[37643]: E0402 10:21:32 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0003.part: pq: relation ""iso5"" does not exist  02 10:21:38 d01server04t weed-filer[37643]: E0402 10:21:38 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0004.part: pq: relation ""iso5"" does not exist  02 10:21:44 d01server04t weed-filer[37643]: E0402 10:21:44 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0005.part: pq: relation ""iso5"" does not exist  02 10:21:51 d01server04t weed-filer[37643]: E0402 10:21:51 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0006.part: pq: relation ""iso5"" does not exist  02 10:21:58 d01server04t weed-filer[37643]: E0402 10:21:58 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0007.part: pq: relation ""iso5"" does not exist  02 10:22:05 d01server04t weed-filer[37643]: E0402 10:22:05 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0008.part: pq: relation ""iso5"" does not exist  02 10:22:11 d01server04t weed-filer[37643]: E0402 10:22:11 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0009.part: pq: relation ""iso5"" does not exist  02 10:22:18 d01server04t weed-filer[37643]: E0402 10:22:18 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0010.part: pq: relation ""iso5"" does not exist  02 10:22:24 d01server04t weed-filer[37643]: E0402 10:22:24 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0011.part: pq: relation ""iso5"" does not exist  02 10:22:30 d01server04t weed-filer[37643]: E0402 10:22:30 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0012.part: pq: relation ""iso5"" does not exist  02 10:22:36 d01server04t weed-filer[37643]: E0402 10:22:36 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0013.part: pq: relation ""iso5"" does not exist  02 10:22:41 d01server04t weed-filer[37643]: E0402 10:22:41 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0014.part: pq: relation ""iso5"" does not exist  02 10:22:46 d01server04t weed-filer[37643]: E0402 10:22:46 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0015.part: pq: relation ""iso5"" does not exist  02 10:22:52 d01server04t weed-filer[37643]: E0402 10:22:52 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0016.part: pq: relation ""iso5"" does not exist  02 10:22:57 d01server04t weed-filer[37643]: E0402 10:22:57 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0017.part: pq: relation ""iso5"" does not exist  02 10:23:01 d01server04t weed-filer[37643]: E0402 10:23:01 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0018.part: pq: relation ""iso5"" does not exist  02 10:23:05 d01server04t weed-filer[37643]: E0402 10:23:05 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0019.part: pq: relation ""iso5"" does not exist  02 10:23:10 d01server04t weed-filer[37643]: E0402 10:23:10 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0020.part: pq: relation ""iso5"" does not exist  02 10:23:14 d01server04t weed-filer[37643]: E0402 10:23:14 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0021.part: pq: relation ""iso5"" does not exist  02 10:23:19 d01server04t weed-filer[37643]: E0402 10:23:19 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0022.part: pq: relation ""iso5"" does not exist  02 10:23:25 d01server04t weed-filer[37643]: E0402 10:23:25 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0023.part: pq: relation ""iso5"" does not exist  02 10:23:32 d01server04t weed-filer[37643]: E0402 10:23:32 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0024.part: pq: relation ""iso5"" does not exist  02 10:23:38 d01server04t weed-filer[37643]: E0402 10:23:38 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0025.part: pq: relation ""iso5"" does not exist  02 10:23:42 d01server04t weed-filer[37643]: E0402 10:23:42 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0026.part: pq: relation ""iso5"" does not exist  02 10:23:43 d01server04t weed-filer[37643]: E0402 10:23:43 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/.uploads/51378ef3-f6be-47f7-8793-c289f33ae4f6/0027.part: pq: relation ""iso5"" does not exist  02 10:23:43 d01server04t weed-filer[37643]: E0402 10:23:43 37643 meta_aggregator.go:83] failed to reply metadata change from 10.11.10.76:8888: upsert /buckets/iso5/virtio-win-0.1.185.iso: pq: relation ""iso5"" does not exist  02 10:23:43 d01server04t weed-filer[37643]: panic: runtime error: invalid memory address or nil pointer dereference  02 10:23:43 d01server04t weed-filer[37643]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x118 pc=0xec9c8d]  02 10:23:43 d01server04t weed-filer[37643]: goroutine 125 [running]:  02 10:23:43 d01server04t weed-filer[37643]: github.com/chrislusf/seaweedfs/weed/filer.(*FilerStoreWrapper).DeleteEntry(0xc000625980, 0x2621610, 0xc000050080, 0xc0006405f0, 0x45, 0x0, 0x0)  02 10:23:43 d01server04t systemd[1]: weed-filer.service: main process exited, code=exited, status=2/INVALIDARGUMENT  02 10:23:43 d01server04t systemd[1]: Unit weed-filer.service entered failed state.  02 10:23:43 d01server04t systemd[1]: weed-filer.service failed.  02 10:24:13 d01server04t systemd[1]: weed-filer.service holdoff time over, scheduling restart.  02 10:24:13 d01server04t systemd[1]: Stopped weed filer server of cluster.  02 10:24:13 d01server04t systemd[1]: Started weed filer server of cluster.  02 10:24:19 d01server04t weed-filer[43721]: I0402 10:24:19 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:20 d01server04t weed-filer[43721]: I0402 10:24:20 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:21 d01server04t weed-filer[43721]: I0402 10:24:21 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:22 d01server04t weed-filer[43721]: I0402 10:24:22 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:23 d01server04t weed-filer[43721]: I0402 10:24:23 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:24 d01server04t weed-filer[43721]: I0402 10:24:24 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:25 d01server04t weed-filer[43721]: I0402 10:24:25 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:26 d01server04t weed-filer[43721]: I0402 10:24:26 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:27 d01server04t weed-filer[43721]: I0402 10:24:27 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:28 d01server04t weed-filer[43721]: I0402 10:24:28 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:29 d01server04t weed-filer[43721]: I0402 10:24:29 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:30 d01server04t weed-filer[43721]: I0402 10:24:30 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:31 d01server04t weed-filer[43721]: I0402 10:24:31 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:32 d01server04t weed-filer[43721]: I0402 10:24:32 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:33 d01server04t weed-filer[43721]: I0402 10:24:33 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:34 d01server04t weed-filer[43721]: I0402 10:24:34 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:35 d01server04t weed-filer[43721]: I0402 10:24:35 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:36 d01server04t weed-filer[43721]: I0402 10:24:36 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:37 d01server04t weed-filer[43721]: I0402 10:24:37 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:38 d01server04t weed-filer[43721]: I0402 10:24:38 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:39 d01server04t weed-filer[43721]: I0402 10:24:39 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:40 d01server04t weed-filer[43721]: I0402 10:24:40 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:41 d01server04t weed-filer[43721]: I0402 10:24:41 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:42 d01server04t weed-filer[43721]: I0402 10:24:42 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:43 d01server04t weed-filer[43721]: I0402 10:24:43 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:44 d01server04t weed-filer[43721]: I0402 10:24:44 43721 s3.go:166] wait to connect to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 masterclient.go:126] redirected to leader 10.11.10.72:9333  02 10:24:45 d01server04t weed-filer[43721]: W0402 10:24:45 43721 filer_server.go:117] skipping default store dir in /var/lib/seaweedfs/filer/filerldb2  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 filer.go:101] existing filer.store.id = 541754507  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 configuration.go:28] configured filer store to postgres2  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 meta_aggregator.go:67] connecting to peer filer 10.10.10.148:8888: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 filer.go:196] Start Seaweed Filer 30GB 2.36 6b7aa96 at 10.10.10.148:8888  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 meta_aggregator.go:191] readOffset 10.11.10.76:8888 : 1617348080880875447  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 meta_aggregator.go:78] follow peer: 10.11.10.76:8888, last 2021-04-02 10:21:20.880875447 +0300 MSK (1617348080880875447)  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 s3.go:162] S3 read filer buckets dir: /buckets  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 s3.go:169] connected to filer 10.10.10.148:8888 grpc address 10.10.10.148:18888  02 10:24:45 d01server04t weed-filer[43721]: W0402 10:24:45 43721 auth_credentials.go:48] fail to load config: read S3 config: http://10.10.10.148:8888/etc/iam/identity.json: 404 Not Found  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 s3.go:201] Start Seaweed S3 API Server 30GB 2.36 6b7aa96 at https port 443  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 filer_grpc_server_sub_meta.go:196] + listener s3@10.10.10.148:43326  02 10:24:45 d01server04t weed-filer[43721]: I0402 10:24:45 43721 filer_grpc_server_sub_meta.go:26] s3@10.10.10.148:43326 starts to subscribe /etc/iam/identity.json from 2021-04-02 10:24:45.663820992 +0300 MSK  02 10:24:46 d01server04t weed-filer[43721]: I0402 10:24:46 43721 filer_grpc_server_sub_meta.go:196] + listener filer:10.10.10.148:8888@10.10.10.148:43326  02 10:24:46 d01server04t weed-filer[43721]: I0402 10:24:46 43721 filer_grpc_server_sub_meta.go:77] filer:10.10.10.148:8888@10.10.10.148:43326 local subscribe / from 2021-04-02 10:23:45.095542048 +0300 MSK  02 10:24:52 d01server04t weed-filer[43721]: I0402 10:24:52 43721 filer_grpc_server_sub_meta.go:196] + listener filer:10.11.10.76:8888@10.11.10.76:35024  02 10:24:52 d01server04t weed-filer[43721]: I0402 10:24:52 43721 filer_grpc_server_sub_meta.go:77] filer:10.11.10.76:8888@10.11.10.76:35024 local subscribe / from 2021-04-01 13:40:24.386199338 +0300 MSK  02 12:33:37 d01server04t weed-filer[43721]: I0402 12:33:37 43721 meta_aggregator.go:93] synced with 10.11.10.76:8888  </p> </details> <details> <summary>See d02server05t filer2 log</summary> <p> bash  02 10:21:24 d02server05t weed-filer[114137]: I0402 10:21:24 14137 filer_grpc_server_sub_meta.go:201] - listener filer:10.10.10.148:8888@10.10.10.148:39402  02 10:23:43 d02server05t weed-filer[114137]: I0402 10:23:43 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: rpc error: code = Unavailable desc = transport is closing  02 10:23:45 d02server05t weed-filer[114137]: I0402 10:23:45 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:46 d02server05t weed-filer[114137]: I0402 10:23:46 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:48 d02server05t weed-filer[114137]: I0402 10:23:48 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:50 d02server05t weed-filer[114137]: I0402 10:23:50 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:51 d02server05t weed-filer[114137]: I0402 10:23:51 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:53 d02server05t weed-filer[114137]: I0402 10:23:53 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:55 d02server05t weed-filer[114137]: I0402 10:23:55 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:57 d02server05t weed-filer[114137]: I0402 10:23:57 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:23:58 d02server05t weed-filer[114137]: I0402 10:23:58 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:00 d02server05t weed-filer[114137]: I0402 10:24:00 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:02 d02server05t weed-filer[114137]: I0402 10:24:02 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:04 d02server05t weed-filer[114137]: I0402 10:24:04 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:05 d02server05t weed-filer[114137]: I0402 10:24:05 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:07 d02server05t weed-filer[114137]: I0402 10:24:07 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:09 d02server05t weed-filer[114137]: I0402 10:24:09 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:11 d02server05t weed-filer[114137]: I0402 10:24:11 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:12 d02server05t weed-filer[114137]: I0402 10:24:12 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:14 d02server05t weed-filer[114137]: I0402 10:24:14 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:16 d02server05t weed-filer[114137]: I0402 10:24:16 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:17 d02server05t weed-filer[114137]: I0402 10:24:17 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:19 d02server05t weed-filer[114137]: I0402 10:24:19 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:21 d02server05t weed-filer[114137]: I0402 10:24:21 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:23 d02server05t weed-filer[114137]: I0402 10:24:23 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:24 d02server05t weed-filer[114137]: I0402 10:24:24 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:26 d02server05t weed-filer[114137]: I0402 10:24:26 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:28 d02server05t weed-filer[114137]: I0402 10:24:28 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:30 d02server05t weed-filer[114137]: I0402 10:24:30 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:31 d02server05t weed-filer[114137]: I0402 10:24:31 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:33 d02server05t weed-filer[114137]: I0402 10:24:33 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:35 d02server05t weed-filer[114137]: I0402 10:24:35 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:37 d02server05t weed-filer[114137]: I0402 10:24:37 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:38 d02server05t weed-filer[114137]: I0402 10:24:38 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:40 d02server05t weed-filer[114137]: I0402 10:24:40 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:42 d02server05t weed-filer[114137]: I0402 10:24:42 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:44 d02server05t weed-filer[114137]: I0402 10:24:44 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:45 d02server05t weed-filer[114137]: I0402 10:24:45 14137 filer_grpc_server_sub_meta.go:196] + listener filer:10.10.10.148:8888@10.10.10.148:47746  02 10:24:45 d02server05t weed-filer[114137]: I0402 10:24:45 14137 filer_grpc_server_sub_meta.go:77] filer:10.10.10.148:8888@10.10.10.148:47746 local subscribe / from 2021-04-02 10:21:20.880875447 +0300 MSK  02 10:24:45 d02server05t weed-filer[114137]: I0402 10:24:45 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:47 d02server05t weed-filer[114137]: I0402 10:24:47 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:49 d02server05t weed-filer[114137]: I0402 10:24:49 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 10:24:50 d02server05t weed-filer[114137]: I0402 10:24:50 14137 meta_aggregator.go:151] subscribing remote 10.10.10.148:8888 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.10.10.148:18888: connect: connection refused""  02 11:54:05 d02server05t weed-filer[114137]: E0402 11:54:05 14137 auth_credentials_subscribe.go:66] subscribing filer meta change: rpc error: code = Unavailable desc = transport is closing  02 11:54:05 d02server05t weed-filer[114137]: I0402 11:54:05 14137 meta_aggregator.go:151] subscribing remote 10.11.10.76:8888 meta change: rpc error: code = Unavailable desc = transport is closing  02 11:54:06 d02server05t weed-filer[114137]: I0402 11:54:06 14137 filer_grpc_server_sub_meta.go:196] + listener s3@10.11.10.76:45624  02 11:54:06 d02server05t weed-filer[114137]: I0402 11:54:06 14137 filer_grpc_server_sub_meta.go:26] s3@10.11.10.76:45624 starts to subscribe /etc/iam/identity.json from 2021-04-01 16:59:46.479385901 +0300 MSK  02 11:54:07 d02server05t weed-filer[114137]: I0402 11:54:07 14137 filer_grpc_server_sub_meta.go:196] + listener filer:10.11.10.76:8888@10.11.10.76:45624  02 11:54:07 d02server05t weed-filer[114137]: I0402 11:54:07 14137 filer_grpc_server_sub_meta.go:77] filer:10.11.10.76:8888@10.11.10.76:45624 local subscribe / from 2021-04-02 10:23:43.287381707 +0300 MSK  02 12:33:37 d02server05t weed-filer[114137]: I0402 12:33:37 14137 filer_grpc_server_sub_meta.go:187] => client filer:10.10.10.148:8888@10.10.10.148:43660: rpc error: code = Unavailable desc = transport is closing  02 12:33:37 d02server05t weed-filer[114137]: I0402 12:33:37 14137 filer_grpc_server_sub_meta.go:187] => client filer:10.11.10.76:8888@10.11.10.76:59254: rpc error: code = Unavailable desc = transport is closing  02 12:33:37 d02server05t weed-filer[114137]: E0402 12:33:37 14137 filer_grpc_server_sub_meta.go:110] processed to 2021-04-02 12:33:37.150608013 +0300 MSK: rpc error: code = Unavailable desc = transport is closing  02 12:33:37 d02server05t weed-filer[114137]: E0402 12:33:37 14137 filer_grpc_server_sub_meta.go:110] processed to 2021-04-02 12:33:37.150608013 +0300 MSK: rpc error: code = Unavailable desc = transport is closing  02 12:33:40 d02server05t weed-filer[114137]: I0402 12:33:40 14137 filer_grpc_server_sub_meta.go:201] - listener filer:10.11.10.76:8888@10.11.10.76:59254  02 12:33:40 d02server05t weed-filer[114137]: I0402 12:33:40 14137 filer_grpc_server_sub_meta.go:201]  </p> </details> My configuration.  defaultreplication = '101' masters = 10.10.10.145:9333,10.10.10.146:9333,10.10.10.148:9333,10.11.10.72:9333,10.11.10.73:9333,10.11.10.74:9333,10.12.10.20:9333 volumes = 10.10.10.145:8080,10.10.10.146:8080,10.10.10.148:8080,10.10.10.150:8080,10.11.10.72:8080,10.11.10.73:8080,10.11.10.74:8080,10.11.10.75:8080,10.11.10.76:8080,10.11.10.77:8080 filers = 10.11.10.76:8888,10.10.10.148:8888 filers have peers = 10.11.10.76:8888,10.10.10.148:8888   filer1 - d01server04t - 10.10.10.148 - posgresql 9.6 store filer2 - d02server05t - 10.11.10.76 - other posgresql 9.6 store  **System Setup** - OS version CentOS Linux release 7.6.1810 - output of `weed version` version 30GB 2.36 6b7aa96 linux amd64 - if using filer, show the content of `filer.toml` **Filer1** <details> <summary>Filer1 filer.toml</summary> <p>  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml  # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false # directories under this folder will be automatically creating a separate bucket buckets_folder = ""/buckets""  # The following are filer store options  [postgres2] enabled = true createTable =  CREATE TABLE IF NOT EXISTS ""%s"" ( dirhash BIGINT, name VARCHAR(65535), directory VARCHAR(65535), meta bytea, PRIMARY KEY (dirhash, name) );  hostname = ""10.11.10.253"" port = 5432 username = ""seaweedfs"" password = ""pass"" database = ""seaweedfs"" # create or use an existing database schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0  </p> </details> **Filer2** <details> <summary>Filer1 filer.toml</summary> <p>  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml  # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false # directories under this folder will be automatically creating a separate bucket buckets_folder = ""/buckets""  # The following are filer store options  [postgres2] enabled = true createTable =  CREATE TABLE IF NOT EXISTS ""%s"" ( dirhash BIGINT, name VARCHAR(65535), directory VARCHAR(65535), meta bytea, PRIMARY KEY (dirhash, name) );  hostname = ""10.10.10.110"" port = 5432 username = ""seaweedfs"" password = ""pass"" database = ""seaweedfs"" # create or use an existing database schema = """" sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 connection_max_lifetime_seconds = 0  </p> </details> **Expected behavior** A clear and concise description of what you expected to happen. Synchronization of metadata without errors source-file source-file",no-bug,0.8
5424,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5424,Credentials leaking in logs,"**Describe the bug** It's not a bug but more a small security issue. When a database connection fails for `filer`, the credentials are logged into the console. For instance, I have set up a test deployment with a Postgres. In case of a connection error to the DB, the username and password are logged into the console as plain test. This is not a critical thing, so it could be done with any upcoming release, I guess. **System Setup** Any running `filer` with an external database (postgres in this case), which cannot connect to the DB. For instance provide an unreachable IP or something like this. **Expected behavior** I would suggest to either not log the `password` at all, or log it with `debug` or `trace` level only, so it would normally not show up. **Screenshots** ![grafik](https://github.com/seaweedfs/seaweedfs/assets/62848396/fad3f51f-8b8e-4381-96c6-c9a4ad92e27f)",source-file | source-file | source-file,"Credentials leaking in logs **Describe the bug** It's not a bug but more a small security issue. When a database connection fails for `filer`, the credentials are logged into the console. For instance, I have set up a test deployment with a Postgres. In case of a connection error to the DB, the username and password are logged into the console as plain test. This is not a critical thing, so it could be done with any upcoming release, I guess. **System Setup** Any running `filer` with an external database (postgres in this case), which cannot connect to the DB. For instance provide an unreachable IP or something like this. **Expected behavior** I would suggest to either not log the `password` at all, or log it with `debug` or `trace` level only, so it would normally not show up. **Screenshots** ![grafik](https://github.com/seaweedfs/seaweedfs/assets/62848396/fad3f51f-8b8e-4381-96c6-c9a4ad92e27f) source-file source-file source-file",no-bug,0.9
1418,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1418,listObjectslistObjectsV2,"file/topic/2020-08-08/ file/topic/2020-08-08/0574046b06ee4c24939e950dd0351c03b1.mp4 file/topic/2020-08-08/27b09a28b0ae45159c3b91d35593c776b1.mp4 file/topic/2020-08-08/test/1.jpg file/topic/2020-08-08/APIminioS3 file/topic/2020-08-08/0574046b06ee4c24939e950dd0351c03b1.mp4 file/topic/2020-08-08/27b09a28b0ae45159c3b91d35593c776b1.mp4 listObjectsV2maxKeysfile/topic/2020-08-08/10maxKeys(2)1maxKeys(6)4 API S3Client s3Client =  ListObjectsRequest listObjectsRequest = ListObjectsRequest.builder() .bucket(""testbucket"").prefix(""file/topic/2020-08-08/"").build(); ListObjectsResponse objectsResponse = s3Client.listObjects(listObjectsRequest); while (true) { for (Iterator<?> iterator = objectsResponse.contents().iterator(); iterator.hasNext(); ) { S3Object s3Object = (S3Object)iterator.next(); System.out.println(""-- ""+s3Object.key()); } if (objectsResponse.isTruncated()) { objectsResponse = s3Client.listObjects(listObjectsRequest); continue; } break; };  ListObjectsV2Request listObjectsReqManual = ListObjectsV2Request.builder() .bucket(""testbucket"") .maxKeys(10) .prefix(""file/topic/2020-08-08/"") .build(); boolean done = false; while (!done) { ListObjectsV2Response listObjResponse = s3Client.listObjectsV2(listObjectsReqManual); for (S3Object content : listObjResponse.contents()) { System.out.println(content.key()); } if (listObjResponse.nextContinuationToken() == null) { done = true; } System.out.println(""""); listObjectsReqManual = listObjectsReqManual.toBuilder() .continuationToken(listObjResponse.nextContinuationToken()) .build(); }",source-file,"listObjectslistObjectsV2 file/topic/2020-08-08/ file/topic/2020-08-08/0574046b06ee4c24939e950dd0351c03b1.mp4 file/topic/2020-08-08/27b09a28b0ae45159c3b91d35593c776b1.mp4 file/topic/2020-08-08/test/1.jpg file/topic/2020-08-08/APIminioS3 file/topic/2020-08-08/0574046b06ee4c24939e950dd0351c03b1.mp4 file/topic/2020-08-08/27b09a28b0ae45159c3b91d35593c776b1.mp4 listObjectsV2maxKeysfile/topic/2020-08-08/10maxKeys(2)1maxKeys(6)4 API S3Client s3Client =  ListObjectsRequest listObjectsRequest = ListObjectsRequest.builder() .bucket(""testbucket"").prefix(""file/topic/2020-08-08/"").build(); ListObjectsResponse objectsResponse = s3Client.listObjects(listObjectsRequest); while (true) { for (Iterator<?> iterator = objectsResponse.contents().iterator(); iterator.hasNext(); ) { S3Object s3Object = (S3Object)iterator.next(); System.out.println(""-- ""+s3Object.key()); } if (objectsResponse.isTruncated()) { objectsResponse = s3Client.listObjects(listObjectsRequest); continue; } break; };  ListObjectsV2Request listObjectsReqManual = ListObjectsV2Request.builder() .bucket(""testbucket"") .maxKeys(10) .prefix(""file/topic/2020-08-08/"") .build(); boolean done = false; while (!done) { ListObjectsV2Response listObjResponse = s3Client.listObjectsV2(listObjectsReqManual); for (S3Object content : listObjResponse.contents()) { System.out.println(content.key()); } if (listObjResponse.nextContinuationToken() == null) { done = true; } System.out.println(""""); listObjectsReqManual = listObjectsReqManual.toBuilder() .continuationToken(listObjResponse.nextContinuationToken()) .build(); } source-file",no-bug,0.8
3620,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3620,[aligo] optimization topology struct,https://github.com/essentialkaos/aligo  go install github.com/essentialkaos/aligo aligo check weed/topology   Struct Collection (collection.go:12) fields order can be optimized (40  33) type Collection struct { Name string volumeSizeLimit uint64 storageType2VolumeLayout *util.ConcurrentReadMap replicationAsMin bool } Struct NodeImpl (node.go:40) fields order can be optimized (112  108) type NodeImpl struct { id NodeId // - parent Node // - nodeType string // - value interface{} // - diskUsages *DiskUsages // - children map[NodeId]Node // - RWMutex sync.RWMutex // lock children maxVolumeId needle.VolumeId // - } Struct Topology (topology.go:26) fields order can be optimized (304  297) type Topology struct { NodeImpl NodeImpl Sequence sequence.Sequencer RaftServer raft.Server vacuumLockCounter int64 collectionMap *util.ConcurrentReadMap ecShardMap map[needle.VolumeId]*..EcShardL pulse int64 volumeSizeLimit uint64 chanFullVolumes chan storage.VolumeInfo chanCrowdedVolumes chan storage.VolumeInfo Configuration *Configuration HashicorpRaft *hashicorpRaft.Raft UuidMap map[string][]string ecShardMapLock sync.RWMutex RaftServerAccessLock sync.RWMutex UuidAccessLock sync.RWMutex replicationAsMin bool } Struct VolumeLayout (volume_layout.go:106) fields order can be optimized (156  149) type VolumeLayout struct { growRequestTime time.Time // - writables []needle.VolumeId // transient array of writable volume id diskType storage/types.DiskType // - rp *super_block.ReplicaPlacement // - ttl *storage/needle.TTL // - vid2location map[storage/needle.VolumeId]*.. // - crowded map[storage/needle.VolumeId]str // - readonlyVolumes *volumesBinaryState // readonly volumes oversizedVolumes *volumesBinaryState // oversized volumes volumeSizeLimit uint64 // - accessLock sync.RWMutex // - growRequestCount int32 // - replicationAsMin bool // - }  ,source-file | source-file | source-file | source-file,[aligo] optimization topology struct https://github.com/essentialkaos/aligo  go install github.com/essentialkaos/aligo aligo check weed/topology   Struct Collection (collection.go:12) fields order can be optimized (40  33) type Collection struct { Name string volumeSizeLimit uint64 storageType2VolumeLayout *util.ConcurrentReadMap replicationAsMin bool } Struct NodeImpl (node.go:40) fields order can be optimized (112  108) type NodeImpl struct { id NodeId // - parent Node // - nodeType string // - value interface{} // - diskUsages *DiskUsages // - children map[NodeId]Node // - RWMutex sync.RWMutex // lock children maxVolumeId needle.VolumeId // - } Struct Topology (topology.go:26) fields order can be optimized (304  297) type Topology struct { NodeImpl NodeImpl Sequence sequence.Sequencer RaftServer raft.Server vacuumLockCounter int64 collectionMap *util.ConcurrentReadMap ecShardMap map[needle.VolumeId]*..EcShardL pulse int64 volumeSizeLimit uint64 chanFullVolumes chan storage.VolumeInfo chanCrowdedVolumes chan storage.VolumeInfo Configuration *Configuration HashicorpRaft *hashicorpRaft.Raft UuidMap map[string][]string ecShardMapLock sync.RWMutex RaftServerAccessLock sync.RWMutex UuidAccessLock sync.RWMutex replicationAsMin bool } Struct VolumeLayout (volume_layout.go:106) fields order can be optimized (156  149) type VolumeLayout struct { growRequestTime time.Time // - writables []needle.VolumeId // transient array of writable volume id diskType storage/types.DiskType // - rp *super_block.ReplicaPlacement // - ttl *storage/needle.TTL // - vid2location map[storage/needle.VolumeId]*.. // - crowded map[storage/needle.VolumeId]str // - readonlyVolumes *volumesBinaryState // readonly volumes oversizedVolumes *volumesBinaryState // oversized volumes volumeSizeLimit uint64 // - accessLock sync.RWMutex // - growRequestCount int32 // - replicationAsMin bool // - }   source-file source-file source-file source-file,no-bug,0.95
274,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/274,weed filervolume url," weedfsfiler bar.jshttp://127.0.0.1:8888/test/  2016-03-31 16:38:05 INFO WeedFSClientTest1 (WeedFSClientTest1.java:166) - - {""name"":""sitemapindex.xml"",""size"":32675}  {""name"":""bar.js"",""size"":32675,""fid"":""2,125de60a06"",**""url"":""127.0.0.1:8080"",""publicUrl"":""localhost:8080""**} url+fid http://127.0.0.1:8888/test/{""Directory"":""/test/"",""Files"":[{""name"":""bar.js"",""fid"":""2,026605fd23""}]}  ",source-file,"weed filervolume url  weedfsfiler bar.jshttp://127.0.0.1:8888/test/  2016-03-31 16:38:05 INFO WeedFSClientTest1 (WeedFSClientTest1.java:166) - - {""name"":""sitemapindex.xml"",""size"":32675}  {""name"":""bar.js"",""size"":32675,""fid"":""2,125de60a06"",**""url"":""127.0.0.1:8080"",""publicUrl"":""localhost:8080""**} url+fid http://127.0.0.1:8888/test/{""Directory"":""/test/"",""Files"":[{""name"":""bar.js"",""fid"":""2,026605fd23""}]}   source-file",no-bug,0.7
380,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/380,MastersLeaderfollower,,source-file | source-file | source-file | source-file | source-file,MastersLeaderfollower  source-file source-file source-file source-file source-file,no-bug,0.2
3795,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3795,[master] Transfer leadership on shutdown,avoid https://github.com/hashicorp/raft/issues/472 at regular stop master do stress test 1. `make hashicorp_raft` 2. stress test  for i in {1..100}; do sleep 2; docker exec -it seaweedfs_master2_1 kill -s HUP 1; docker exec -it seaweedfs_master1_1 kill -s HUP 1;docker exec -it seaweedfs_master0_1 kill -s HUP 1;done  3. Stop leader `docker stop seaweedfs_master2_1` PR https://github.com/seaweedfs/seaweedfs/pull/3797,source-file | source-file,[master] Transfer leadership on shutdown avoid https://github.com/hashicorp/raft/issues/472 at regular stop master do stress test 1. `make hashicorp_raft` 2. stress test  for i in {1..100}; do sleep 2; docker exec -it seaweedfs_master2_1 kill -s HUP 1; docker exec -it seaweedfs_master1_1 kill -s HUP 1;docker exec -it seaweedfs_master0_1 kill -s HUP 1;done  3. Stop leader `docker stop seaweedfs_master2_1` PR https://github.com/seaweedfs/seaweedfs/pull/3797 source-file source-file,no-bug,0.9
3852,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3852,`AppendAtNs` is not guaranteed to monotonically increase.,"Is not guaranteed that `AppendAtNs` will increase for each sequential entry. Sequential records may contain the same `AppendAtNs` or even decreasing ones. Although such events are not very likely, they may cause `tailVolume` to malfunction and cause loss of data during synchronization. Each new `AppendAtNs` should not be generated using `uint64(time.Now().UnixNano())` but `max(uint64(time.Now().UnixNano()), lastAppendAtNs+1)` here and in few more places around the codebase https://github.com/seaweedfs/seaweedfs/blob/824f7ad9e192c1999fdb5da3a9af8c112904cc66/weed/storage/volume_write.go#L159-L166",source-file | source-file | source-file | source-file,"`AppendAtNs` is not guaranteed to monotonically increase. Is not guaranteed that `AppendAtNs` will increase for each sequential entry. Sequential records may contain the same `AppendAtNs` or even decreasing ones. Although such events are not very likely, they may cause `tailVolume` to malfunction and cause loss of data during synchronization. Each new `AppendAtNs` should not be generated using `uint64(time.Now().UnixNano())` but `max(uint64(time.Now().UnixNano()), lastAppendAtNs+1)` here and in few more places around the codebase https://github.com/seaweedfs/seaweedfs/blob/824f7ad9e192c1999fdb5da3a9af8c112904cc66/weed/storage/volume_write.go#L159-L166 source-file source-file source-file source-file",no-bug,0.9
77,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/77,How to migrate volume from server `A` to `B`?,"Suppose we've got 3 volume servers (`A`, `B`, `C`) with `001` replication type. We wan't to remove volume server `C`. We have to migrate all volumes located on volume server `C` to `A` and `B`. Is it possible to migrate volume with id `X` from server `A` to server `B`?",test-file | config-file | documentation-file | container-file | container-file | config-file | other-file | other-file | documentation-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"How to migrate volume from server `A` to `B`? Suppose we've got 3 volume servers (`A`, `B`, `C`) with `001` replication type. We wan't to remove volume server `C`. We have to migrate all volumes located on volume server `C` to `A` and `B`. Is it possible to migrate volume with id `X` from server `A` to server `B`? test-file config-file documentation-file container-file container-file config-file other-file other-file documentation-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
4170,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4170,"There is a problem with S3 MultipartUpload, only generated_ COPYING_ file","**Describe the bug** There is a problem with S3 MultipartUpload, only generated_ COPYING_ file For example, I use the S3 interface to MultipartUpload a 200M file in blocks, it will only generate_ COPYING_ File, no real target file will be generatedand then it faild **System Setup** seaweed version is 3.39 **Expected behavior** Can MultipartUpload files normally",source-file,"There is a problem with S3 MultipartUpload, only generated_ COPYING_ file **Describe the bug** There is a problem with S3 MultipartUpload, only generated_ COPYING_ file For example, I use the S3 interface to MultipartUpload a 200M file in blocks, it will only generate_ COPYING_ File, no real target file will be generatedand then it faild **System Setup** seaweed version is 3.39 **Expected behavior** Can MultipartUpload files normally source-file",no-bug,0.8
1995,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1995,[shell] does not return to the terminal by timeout,"**Describe the bug** - I run the command weed shell on a machine where master/filer is missing or make a mistake with the ports, then the terminal hangs - If I interrupt the running with Ctrl + C, then it returns to the terminal, but the cursor is not displayed **System Setup** - CentOS Linux release 7.9.2009 - GNU bash, version 4.2.46(2)-release (x86_64-redhat-linux-gnu) - weed version 30GB 2.39 742ab1e linux amd64 - run weed shell master: localhost: 9333 filer: localhost: 8888 **Expected behavior** - Completion of the command by timeout in the absence of a connection to master/filer - If I interrupt forcibly, then display the cursor.",source-file,"[shell] does not return to the terminal by timeout **Describe the bug** - I run the command weed shell on a machine where master/filer is missing or make a mistake with the ports, then the terminal hangs - If I interrupt the running with Ctrl + C, then it returns to the terminal, but the cursor is not displayed **System Setup** - CentOS Linux release 7.9.2009 - GNU bash, version 4.2.46(2)-release (x86_64-redhat-linux-gnu) - weed version 30GB 2.39 742ab1e linux amd64 - run weed shell master: localhost: 9333 filer: localhost: 8888 **Expected behavior** - Completion of the command by timeout in the absence of a connection to master/filer - If I interrupt forcibly, then display the cursor. source-file",no-bug,0.9
915,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/915,filer.copyvolume,"./weed filer.copy /files/ http://127.0.0.1:8888/xxx/ upload data 44776s.jpg to http://127.0.0.1:8888/xxx/44/44776/44776.jpg: update fh: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:18888: connect: cannot assign requested address"" ",source-file | source-file,"filer.copyvolume ./weed filer.copy /files/ http://127.0.0.1:8888/xxx/ upload data 44776s.jpg to http://127.0.0.1:8888/xxx/44/44776/44776.jpg: update fh: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = ""transport: Error while dialing dial tcp 127.0.0.1:18888: connect: cannot assign requested address""  source-file source-file",no-bug,0.8
2434,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2434,[s3] HeadBucketHandler forbidden if is not super Admin or Owner,"**Describe the bug** HeadBucketHandler forbidden if is not super Admin  I1110 17:30:03 1 auth_credentials.go:225] user name: bennu actions: [Admin:bennu-*], action: Admin I1110 17:30:03 1 s3api_bucket_handlers.go:171] HeadBucketHandler bennu-client-files I1110 17:30:03 1 error_handler.go:79] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>AccessDenied</Code><Message>Access Denied.</Message><Resource>/</Resource><RequestId>1636565403160014337</RequestId><BucketName>bennu-client-files</BucketName></Error>   aws --profile bennu --endpoint-url http://localhost:8333 s3api head-bucket --bucket bennu-client-files --debug  I don't quite understand what is being cheked here https://github.com/chrislusf/seaweedfs/blob/35c37562bc34393853de1c54ed06740bdffdf919/weed/s3api/s3api_bucket_handlers.go#L195  > fs.meta.cat /buckets/bennu-client-files { ""name"": ""bennu-client-files"", ""isDirectory"": true, ""chunks"": [ ], ""attributes"": { ""fileSize"": ""0"", ""mtime"": ""1633508622"", ""fileMode"": 2147484159, ""uid"": 0, ""gid"": 0, ""crtime"": ""1633508622"", ""mime"": """", ""replication"": """", ""collection"": """", ""ttlSec"": 0, ""userName"": """", ""groupName"": [ ], ""symlinkTarget"": """", ""md5"": null, ""diskType"": """" }, ""extended"": { ""s3-identity-id"": ""c2VydmljZS1saWJyYXJ5"" }, ""hardLinkId"": null, ""hardLinkCounter"": 0, ""content"": null, ""remoteEntry"": null }  **System Setup**  2.75 ",source-file,"[s3] HeadBucketHandler forbidden if is not super Admin or Owner **Describe the bug** HeadBucketHandler forbidden if is not super Admin  I1110 17:30:03 1 auth_credentials.go:225] user name: bennu actions: [Admin:bennu-*], action: Admin I1110 17:30:03 1 s3api_bucket_handlers.go:171] HeadBucketHandler bennu-client-files I1110 17:30:03 1 error_handler.go:79] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>AccessDenied</Code><Message>Access Denied.</Message><Resource>/</Resource><RequestId>1636565403160014337</RequestId><BucketName>bennu-client-files</BucketName></Error>   aws --profile bennu --endpoint-url http://localhost:8333 s3api head-bucket --bucket bennu-client-files --debug  I don't quite understand what is being cheked here https://github.com/chrislusf/seaweedfs/blob/35c37562bc34393853de1c54ed06740bdffdf919/weed/s3api/s3api_bucket_handlers.go#L195  > fs.meta.cat /buckets/bennu-client-files { ""name"": ""bennu-client-files"", ""isDirectory"": true, ""chunks"": [ ], ""attributes"": { ""fileSize"": ""0"", ""mtime"": ""1633508622"", ""fileMode"": 2147484159, ""uid"": 0, ""gid"": 0, ""crtime"": ""1633508622"", ""mime"": """", ""replication"": """", ""collection"": """", ""ttlSec"": 0, ""userName"": """", ""groupName"": [ ], ""symlinkTarget"": """", ""md5"": null, ""diskType"": """" }, ""extended"": { ""s3-identity-id"": ""c2VydmljZS1saWJyYXJ5"" }, ""hardLinkId"": null, ""hardLinkCounter"": 0, ""content"": null, ""remoteEntry"": null }  **System Setup**  2.75  source-file",bug,0.9
568,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/568,Multi master server setup failure,"Hi, Chirslusf. I have encountered a problem when setting up a multi master server cluster according the wiki. I have 3 vm:  vm1: 10.100.35.21 vm2: 10.100.35.20 vm3: 10.100.35.22  I start weed master server one by one in below order:  vm1: ./weed master -ip 10.100.35.21 -port=9333 -mdir=./master vm2: ./weed master -ip 10.100.35.20 -port=9333 -mdir=./master -peers=10.100.35.21:9333 vm3: ./weed master -ip 10.100.35.22 -port=9333 -mdir=./master -peers=10.100.35.20:9333  And then we can see the log output of each start:  vm1: # ./weed master -ip 10.100.35.21 -port=9333 -mdir=./master I0927 15:13:02 14610 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:02 14610 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:02 14610 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:02 14610 raft_server.go:56] Peers Change: [10.100.35.21:9333] => [] I0927 15:13:02 14610 raft_server.go:98] Initializing new cluster I0927 15:13:02 14610 master_server.go:95] [ 10.100.35.21:9333 ] I am the leader! I0927 15:13:12 14610 raft_server_handlers.go:16] Processing incoming join. Current Leader 10.100.35.21:9333 Self 10.100.35.21:9333 Peers map[] I0927 15:13:12 14610 raft_server_handlers.go:20] Command:{""name"":""10.100.35.20:9333"",""connectionString"":""http://10.100.35.20:9333""} I0927 15:13:12 14610 raft_server_handlers.go:27] join command from Name 10.100.35.20:9333 Connection http://10.100.35.20:9333 vm2: # ./weed master -ip 10.100.35.20 -port=9333 -mdir=./master -peers=10.100.35.21:9333 I0927 15:13:11 3117 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:11 3117 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:11 3117 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:11 3117 raft_server.go:56] Peers Change: [10.100.35.20:9333] => [10.100.35.21:9333] I0927 15:13:11 3117 raft_server.go:78] Joining cluster: 10.100.35.21:9333 I0927 15:13:12 3117 raft_server.go:166] Attempting to connect to: http://10.100.35.21:9333/cluster/join I0927 15:13:12 3117 raft_server.go:211] Post returned status: 200 I0927 15:13:52 3117 raft_server_handlers.go:16] Processing incoming join. Current Leader 10.100.35.21:9333 Self 10.100.35.20:9333 Peers map[10.100.35.21:9333:0xc42021fa40] I0927 15:13:52 3117 raft_server_handlers.go:20] Command:{""name"":""10.100.35.22:9333"",""connectionString"":""http://10.100.35.22:9333""} I0927 15:13:52 3117 raft_server_handlers.go:27] join command from Name 10.100.35.22:9333 Connection http://10.100.35.22:9333 I0927 15:13:52 3117 raft_server_handlers.go:47] Redirecting to 301 http://10.100.35.21:9333/cluster/join vm3: # ./weed master -ip 10.100.35.22 -port=9333 -mdir=./master -peers=10.100.35.20:9333 I0927 15:13:51 2964 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:51 2964 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:51 2964 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:51 2964 raft_server.go:56] Peers Change: [] => [10.100.35.20:9333] I0927 15:13:51 2964 raft_server.go:78] Joining cluster: 10.100.35.20:9333 I0927 15:13:52 2964 raft_server.go:166] Attempting to connect to: http://10.100.35.20:9333/cluster/join I0927 15:13:52 2964 raft_server.go:211] Post returned status: 404 404 page not found I0927 15:13:52 2964 raft_server.go:171] Post returned error: 404 page not found I0927 15:13:52 2964 raft_server.go:82] No existing server found. Starting as leader in the new cluster. I0927 15:13:52 2964 master_server.go:95] [ 10.100.35.22:9333 ] I am the leader!  It seems that the weed master on vm3 did not handle the 301 redirect to connect to the master(current leader) on vm1. Is this a bug? looking forward to your reply. 3ks.",source-file | source-file,"Multi master server setup failure Hi, Chirslusf. I have encountered a problem when setting up a multi master server cluster according the wiki. I have 3 vm:  vm1: 10.100.35.21 vm2: 10.100.35.20 vm3: 10.100.35.22  I start weed master server one by one in below order:  vm1: ./weed master -ip 10.100.35.21 -port=9333 -mdir=./master vm2: ./weed master -ip 10.100.35.20 -port=9333 -mdir=./master -peers=10.100.35.21:9333 vm3: ./weed master -ip 10.100.35.22 -port=9333 -mdir=./master -peers=10.100.35.20:9333  And then we can see the log output of each start:  vm1: # ./weed master -ip 10.100.35.21 -port=9333 -mdir=./master I0927 15:13:02 14610 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:02 14610 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:02 14610 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:02 14610 raft_server.go:56] Peers Change: [10.100.35.21:9333] => [] I0927 15:13:02 14610 raft_server.go:98] Initializing new cluster I0927 15:13:02 14610 master_server.go:95] [ 10.100.35.21:9333 ] I am the leader! I0927 15:13:12 14610 raft_server_handlers.go:16] Processing incoming join. Current Leader 10.100.35.21:9333 Self 10.100.35.21:9333 Peers map[] I0927 15:13:12 14610 raft_server_handlers.go:20] Command:{""name"":""10.100.35.20:9333"",""connectionString"":""http://10.100.35.20:9333""} I0927 15:13:12 14610 raft_server_handlers.go:27] join command from Name 10.100.35.20:9333 Connection http://10.100.35.20:9333 vm2: # ./weed master -ip 10.100.35.20 -port=9333 -mdir=./master -peers=10.100.35.21:9333 I0927 15:13:11 3117 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:11 3117 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:11 3117 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:11 3117 raft_server.go:56] Peers Change: [10.100.35.20:9333] => [10.100.35.21:9333] I0927 15:13:11 3117 raft_server.go:78] Joining cluster: 10.100.35.21:9333 I0927 15:13:12 3117 raft_server.go:166] Attempting to connect to: http://10.100.35.21:9333/cluster/join I0927 15:13:12 3117 raft_server.go:211] Post returned status: 200 I0927 15:13:52 3117 raft_server_handlers.go:16] Processing incoming join. Current Leader 10.100.35.21:9333 Self 10.100.35.20:9333 Peers map[10.100.35.21:9333:0xc42021fa40] I0927 15:13:52 3117 raft_server_handlers.go:20] Command:{""name"":""10.100.35.22:9333"",""connectionString"":""http://10.100.35.22:9333""} I0927 15:13:52 3117 raft_server_handlers.go:27] join command from Name 10.100.35.22:9333 Connection http://10.100.35.22:9333 I0927 15:13:52 3117 raft_server_handlers.go:47] Redirecting to 301 http://10.100.35.21:9333/cluster/join vm3: # ./weed master -ip 10.100.35.22 -port=9333 -mdir=./master -peers=10.100.35.20:9333 I0927 15:13:51 2964 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:51 2964 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:51 2964 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:51 2964 raft_server.go:56] Peers Change: [] => [10.100.35.20:9333] I0927 15:13:51 2964 raft_server.go:78] Joining cluster: 10.100.35.20:9333 I0927 15:13:52 2964 raft_server.go:166] Attempting to connect to: http://10.100.35.20:9333/cluster/join I0927 15:13:52 2964 raft_server.go:211] Post returned status: 404 404 page not found I0927 15:13:52 2964 raft_server.go:171] Post returned error: 404 page not found I0927 15:13:52 2964 raft_server.go:82] No existing server found. Starting as leader in the new cluster. I0927 15:13:52 2964 master_server.go:95] [ 10.100.35.22:9333 ] I am the leader!  It seems that the weed master on vm3 did not handle the 301 redirect to connect to the master(current leader) on vm1. Is this a bug? looking forward to your reply. 3ks. source-file source-file",bug,0.9
30,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/30,benchmark not working properly,"on my mac, call ./weed benchmark -server=localhost:9333 then got the following, it seems stuck at ""Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s"" and does not exit Completed 964638 of 1048576 requests, 92.0% 5197.2/s 5.2MB/s Completed 970089 of 1048576 requests, 92.5% 5452.4/s 5.5MB/s Completed 976989 of 1048576 requests, 93.2% 6889.6/s 6.9MB/s Completed 984025 of 1048576 requests, 93.8% 7034.8/s 7.1MB/s Completed 991143 of 1048576 requests, 94.5% 7118.4/s 7.2MB/s Completed 998137 of 1048576 requests, 95.2% 6979.6/s 7.0MB/s Completed 1005152 of 1048576 requests, 95.9% 7023.3/s 7.1MB/s Completed 1012222 of 1048576 requests, 96.5% 7069.1/s 7.1MB/s Completed 1019163 of 1048576 requests, 97.2% 6938.4/s 7.0MB/s Completed 1026164 of 1048576 requests, 97.9% 6989.8/s 7.0MB/s Completed 1033175 of 1048576 requests, 98.5% 7026.3/s 7.1MB/s Completed 1039418 of 1048576 requests, 99.1% 6240.1/s 6.3MB/s Completed 1046381 of 1048576 requests, 99.8% 6942.4/s 7.0MB/s Completed 1048181 of 1048576 requests, 100.0% 1803.5/s 1.8MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s",container-file | container-file | source-file | source-file,"benchmark not working properly on my mac, call ./weed benchmark -server=localhost:9333 then got the following, it seems stuck at ""Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s"" and does not exit Completed 964638 of 1048576 requests, 92.0% 5197.2/s 5.2MB/s Completed 970089 of 1048576 requests, 92.5% 5452.4/s 5.5MB/s Completed 976989 of 1048576 requests, 93.2% 6889.6/s 6.9MB/s Completed 984025 of 1048576 requests, 93.8% 7034.8/s 7.1MB/s Completed 991143 of 1048576 requests, 94.5% 7118.4/s 7.2MB/s Completed 998137 of 1048576 requests, 95.2% 6979.6/s 7.0MB/s Completed 1005152 of 1048576 requests, 95.9% 7023.3/s 7.1MB/s Completed 1012222 of 1048576 requests, 96.5% 7069.1/s 7.1MB/s Completed 1019163 of 1048576 requests, 97.2% 6938.4/s 7.0MB/s Completed 1026164 of 1048576 requests, 97.9% 6989.8/s 7.0MB/s Completed 1033175 of 1048576 requests, 98.5% 7026.3/s 7.1MB/s Completed 1039418 of 1048576 requests, 99.1% 6240.1/s 6.3MB/s Completed 1046381 of 1048576 requests, 99.8% 6942.4/s 7.0MB/s Completed 1048181 of 1048576 requests, 100.0% 1803.5/s 1.8MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s Completed 1048181 of 1048576 requests, 100.0% 0.0/s 0.0MB/s container-file container-file source-file source-file",no-bug,0.9
4531,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4531,[shell] cmd volume.deleteEmpty deletes newly created volumes,"**Describe the bug** A clear and concise description of what the bug is. **System Setup**  3.51  **Expected behavior** deletes only old empty volumes **Additional context** logs:  | Jun 3, 2023 @ 02:00:06.534 | I0602 21:00:06.534668 raft_server.go:81 max volume id 6796 ==> 6797 | fast-master-0 | Jun 3, 2023 @ 02:00:06.535 | I0602 21:00:06.534957 store.go:166 In dir /data adds volume:6797 collection:monitoring-thanos replicaPlacement:000 ttl: | fast-volume-2 | Jun 3, 2023 @ 02:00:06.538 | I0602 21:00:06.538425 volume_grpc_client_to_master.go:179 volume server fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 adds volume 6797 | fast-volume-2 | Jun 3, 2023 @ 02:00:06.538 | I0602 21:00:06.538328 store.go:170 add volume 6797 | fast-volume-2 | Jun 3, 2023 @ 02:00:06.539 | I0602 21:00:06.539199 volume_layout.go:393 Volume 6797 becomes writable | fast-master-0 | Jun 3, 2023 @ 02:00:06.539 | I0602 21:00:06.539111 volume_growth.go:244 Created Volume 6797 on topo:dcvcs:pre-paas-k8s-node5-dcvcs:fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 | fast-master-0 | Jun 3, 2023 @ 02:00:06.539 | I0602 21:00:06.539229 volume_growth.go:257 Registered Volume 6797 on topo:dcvcs:pre-paas-k8s-node5-dcvcs:fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 | fast-master-0 | Jun 3, 2023 @ 02:00:10.248 | 2023/06/02 21:00:10 deleting empty volume 6797 from fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 | fast-cronjob-28095660-bkqld | Jun 3, 2023 @ 02:00:10.350 | I0602 21:00:10.350828 volume_grpc_client_to_master.go:210 volume server fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 deletes volume 6797 | fast-volume-2 | Jun 3, 2023 @ 02:00:10.350 | I0602 21:00:10.342554 store.go:526 DeleteVolume 6797 | fast-volume-2 | Jun 3, 2023 @ 02:00:10.352 | I0602 21:00:10.352070 volume_layout.go:228 volume 6797 remove from writable | fast-master-0 | Jun 3, 2023 @ 02:00:10.352 | I0602 21:00:10.352083 volume_layout.go:380 Volume 6797 becomes unwritable | fast-master-0 | Jun 3, 2023 @ 02:00:10.352 | I0602 21:00:10.352041 volume_layout.go:223 volume 6797 does not have enough copies | fast-master-0 ",source-file | source-file | source-file | source-file | source-file | source-file,"[shell] cmd volume.deleteEmpty deletes newly created volumes **Describe the bug** A clear and concise description of what the bug is. **System Setup**  3.51  **Expected behavior** deletes only old empty volumes **Additional context** logs:  | Jun 3, 2023 @ 02:00:06.534 | I0602 21:00:06.534668 raft_server.go:81 max volume id 6796 ==> 6797 | fast-master-0 | Jun 3, 2023 @ 02:00:06.535 | I0602 21:00:06.534957 store.go:166 In dir /data adds volume:6797 collection:monitoring-thanos replicaPlacement:000 ttl: | fast-volume-2 | Jun 3, 2023 @ 02:00:06.538 | I0602 21:00:06.538425 volume_grpc_client_to_master.go:179 volume server fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 adds volume 6797 | fast-volume-2 | Jun 3, 2023 @ 02:00:06.538 | I0602 21:00:06.538328 store.go:170 add volume 6797 | fast-volume-2 | Jun 3, 2023 @ 02:00:06.539 | I0602 21:00:06.539199 volume_layout.go:393 Volume 6797 becomes writable | fast-master-0 | Jun 3, 2023 @ 02:00:06.539 | I0602 21:00:06.539111 volume_growth.go:244 Created Volume 6797 on topo:dcvcs:pre-paas-k8s-node5-dcvcs:fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 | fast-master-0 | Jun 3, 2023 @ 02:00:06.539 | I0602 21:00:06.539229 volume_growth.go:257 Registered Volume 6797 on topo:dcvcs:pre-paas-k8s-node5-dcvcs:fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 | fast-master-0 | Jun 3, 2023 @ 02:00:10.248 | 2023/06/02 21:00:10 deleting empty volume 6797 from fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 | fast-cronjob-28095660-bkqld | Jun 3, 2023 @ 02:00:10.350 | I0602 21:00:10.350828 volume_grpc_client_to_master.go:210 volume server fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 deletes volume 6797 | fast-volume-2 | Jun 3, 2023 @ 02:00:10.350 | I0602 21:00:10.342554 store.go:526 DeleteVolume 6797 | fast-volume-2 | Jun 3, 2023 @ 02:00:10.352 | I0602 21:00:10.352070 volume_layout.go:228 volume 6797 remove from writable | fast-master-0 | Jun 3, 2023 @ 02:00:10.352 | I0602 21:00:10.352083 volume_layout.go:380 Volume 6797 becomes unwritable | fast-master-0 | Jun 3, 2023 @ 02:00:10.352 | I0602 21:00:10.352041 volume_layout.go:223 volume 6797 does not have enough copies | fast-master-0  source-file source-file source-file source-file source-file source-file",no-bug,0.9
399,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/399,weed backup tool would miss syncing the updated fids,"Chris: The weed backup tool now only remove the fids which the src do not have but dest have, and add the ones which src have but desc does not have at the backup place. For those files which are updated many times, I think that the backup tool will do nothing for them. If this is a bug, do you have any good suggestion to fix it? e.g . Add the file crc32 checksum value in fetchVolumeFileEntries() function(This need to scan the whole volume and get it from each needle),and for the fid keys in both src and dest index, if the corresponding file size and checksum value are both same, ignore syncing. Hope for your suggestions.Thanks!",source-file | source-file | source-file | source-file | source-file | source-file,"weed backup tool would miss syncing the updated fids Chris: The weed backup tool now only remove the fids which the src do not have but dest have, and add the ones which src have but desc does not have at the backup place. For those files which are updated many times, I think that the backup tool will do nothing for them. If this is a bug, do you have any good suggestion to fix it? e.g . Add the file crc32 checksum value in fetchVolumeFileEntries() function(This need to scan the whole volume and get it from each needle),and for the fid keys in both src and dest index, if the corresponding file size and checksum value are both same, ignore syncing. Hope for your suggestions.Thanks! source-file source-file source-file source-file source-file source-file",no-bug,0.9
3567,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3567,[filer] filler entry is created when the file could not be replicated,"**Describe the bug** When trying to replace a file, the filler deleted the file due to a replication error  E0901 08:52:06.822605 filer_replication.go:107 replicate /buckets/jupyterhub-cloud/shared/OsK/df_test.csv: LookupFileId volume id 499: rpc error: code = Unavailable desc = error reading from server: read tcp 172.24.196.35:35436->172.19.38.164:19090: read: connection reset by peer E0901 08:53:57.476085 filer_replication.go:112 replicated /buckets/jupyterhub-cloud/shared/OsK//df_test.csv E0901 08:53:57.702945 filer_replication.go:104 modify: /buckets/jupyterhub-cloud/shared/OsK//df_test.csv E0901 08:54:01.456402 filer_util.go:65 delete entry /buckets/jupyterhub-cloud/shared/OsK/df_test.csv: directory:""/buckets/jupyterhub-cloud/shared/OsK"" name:""df_test.csv"" is_delete_data:true ignore_recursive_error:true   Sep 1, 2022 @ 13:54:47.103 | s3-fast-api.query.consul-test/jupyterhub-cloud?delete | 200 | POST | 844  **Expected behavior** Delete only the version of the file that could not be saved to volume file **System Setup**  3.24 dev  ![Screenshot 2022-09-01 at 15 33 52](https://user-images.githubusercontent.com/9497591/187894396-d9692ff1-1e4c-41c1-a06a-f6c28cb7aaf8.png) ![Screenshot 2022-09-01 at 15 37 00](https://user-images.githubusercontent.com/9497591/187894720-7f00303b-a196-41e6-8fff-6ddd62e68c84.png)",source-file | source-file,"[filer] filler entry is created when the file could not be replicated **Describe the bug** When trying to replace a file, the filler deleted the file due to a replication error  E0901 08:52:06.822605 filer_replication.go:107 replicate /buckets/jupyterhub-cloud/shared/OsK/df_test.csv: LookupFileId volume id 499: rpc error: code = Unavailable desc = error reading from server: read tcp 172.24.196.35:35436->172.19.38.164:19090: read: connection reset by peer E0901 08:53:57.476085 filer_replication.go:112 replicated /buckets/jupyterhub-cloud/shared/OsK//df_test.csv E0901 08:53:57.702945 filer_replication.go:104 modify: /buckets/jupyterhub-cloud/shared/OsK//df_test.csv E0901 08:54:01.456402 filer_util.go:65 delete entry /buckets/jupyterhub-cloud/shared/OsK/df_test.csv: directory:""/buckets/jupyterhub-cloud/shared/OsK"" name:""df_test.csv"" is_delete_data:true ignore_recursive_error:true   Sep 1, 2022 @ 13:54:47.103 | s3-fast-api.query.consul-test/jupyterhub-cloud?delete | 200 | POST | 844  **Expected behavior** Delete only the version of the file that could not be saved to volume file **System Setup**  3.24 dev  ![Screenshot 2022-09-01 at 15 33 52](https://user-images.githubusercontent.com/9497591/187894396-d9692ff1-1e4c-41c1-a06a-f6c28cb7aaf8.png) ![Screenshot 2022-09-01 at 15 37 00](https://user-images.githubusercontent.com/9497591/187894720-7f00303b-a196-41e6-8fff-6ddd62e68c84.png) source-file source-file",no-bug,0.85
5617,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5617,Weed shell incorretly resolves volume grpc port,"**Describe the bug** I'm using dynamic port allocation in the Nomad. When I try to remove orphaned data from volume servers, the weed shell requests `<http port> + 10000` instead of the grpc port that is specified when starting volume servers. **System Setup**  Command line `options.dat` is empty on both servers.  Master: hcl [ ""master"", ""-ip.bind=0.0.0.0"", ""-ip=100.70.149.82"", ""-port=29274"", ""-port.grpc=27089"", ""-options=/local/config/options.dat"" ]   Volume: json [ ""volume"", ""-ip.bind=0.0.0.0"", ""-ip=100.108.234.121"", ""-port=30607"", ""-port.grpc=24973"", ""-dir=/local/data"", ""-rack=vixie"", ""-dataCenter=muttias"", ""-options=/local/config/options.dat"", ""-mserver=100.70.149.82:29274.27089"" ]  All servers are running version 3.67 inside docker containers on Debian 12 nodes. **Expected behavior** The weed shell uses the correct port provided by the volume server and successfully deletes the orphaned data. **Screenshots** ![image](https://github.com/seaweedfs/seaweedfs/assets/64592097/7ecc9a7f-7a17-4858-8460-b1e6b16671fb)",source-file | source-file | source-file,"Weed shell incorretly resolves volume grpc port **Describe the bug** I'm using dynamic port allocation in the Nomad. When I try to remove orphaned data from volume servers, the weed shell requests `<http port> + 10000` instead of the grpc port that is specified when starting volume servers. **System Setup**  Command line `options.dat` is empty on both servers.  Master: hcl [ ""master"", ""-ip.bind=0.0.0.0"", ""-ip=100.70.149.82"", ""-port=29274"", ""-port.grpc=27089"", ""-options=/local/config/options.dat"" ]   Volume: json [ ""volume"", ""-ip.bind=0.0.0.0"", ""-ip=100.108.234.121"", ""-port=30607"", ""-port.grpc=24973"", ""-dir=/local/data"", ""-rack=vixie"", ""-dataCenter=muttias"", ""-options=/local/config/options.dat"", ""-mserver=100.70.149.82:29274.27089"" ]  All servers are running version 3.67 inside docker containers on Debian 12 nodes. **Expected behavior** The weed shell uses the correct port provided by the volume server and successfully deletes the orphaned data. **Screenshots** ![image](https://github.com/seaweedfs/seaweedfs/assets/64592097/7ecc9a7f-7a17-4858-8460-b1e6b16671fb) source-file source-file source-file",no-bug,0.9
1277,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1277,heartbeat to 9333 19333 failed,"i run weed 1.7 on ubuntu 18.04 my install step: 1.start master server ./weed master -mdir=""./mdata"" >master_stdout.log 2>&1 & 2.start vloume server ./weed volume -max=100 -mserver=""localhost:9333"" -dir=""./data"" >volume_stdout.log 2>&1 & 3.start filer ./weed scaffold -config=filer -output=""."" vi filer.toml [leveldb] enabled = true dir = ""./leveldb"" # directory to store level db files mkdir leveldb ./weed filer > filer_stdout.log 2>&1 & weed not work after running some days. and i can't find why. i upload master server, volume server ,filer output log for you, hope fix this issue for log attachment [filer_stdout.log.zip](https://github.com/chrislusf/seaweedfs/files/4481374/filer_stdout.log.zip) [master_stdout.log.zip](https://github.com/chrislusf/seaweedfs/files/4481375/master_stdout.log.zip) [volume_stdout.log.zip](https://github.com/chrislusf/seaweedfs/files/4481376/volume_stdout.log.zip)",source-file,"heartbeat to 9333 19333 failed i run weed 1.7 on ubuntu 18.04 my install step: 1.start master server ./weed master -mdir=""./mdata"" >master_stdout.log 2>&1 & 2.start vloume server ./weed volume -max=100 -mserver=""localhost:9333"" -dir=""./data"" >volume_stdout.log 2>&1 & 3.start filer ./weed scaffold -config=filer -output=""."" vi filer.toml [leveldb] enabled = true dir = ""./leveldb"" # directory to store level db files mkdir leveldb ./weed filer > filer_stdout.log 2>&1 & weed not work after running some days. and i can't find why. i upload master server, volume server ,filer output log for you, hope fix this issue for log attachment [filer_stdout.log.zip](https://github.com/chrislusf/seaweedfs/files/4481374/filer_stdout.log.zip) [master_stdout.log.zip](https://github.com/chrislusf/seaweedfs/files/4481375/master_stdout.log.zip) [volume_stdout.log.zip](https://github.com/chrislusf/seaweedfs/files/4481376/volume_stdout.log.zip) source-file",no-bug,0.3
3565,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3565,[filer] DATA RACE on doSubscribeToOneFiler,https://github.com/seaweedfs/seaweedfs/issues/3507   WARNING: DATA RACE Read at 0x00c0000004f4 by goroutine 2579: github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).doSubscribeToOneFiler.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:197 +0x124 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:264 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:262 +0xc9 github.com/seaweedfs/seaweedfs/weed/pb.WithFilerClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:256 +0x85e github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).doSubscribeToOneFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:194 +0x41 github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).loopSubscribeToOneFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:97 +0x2fe github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:61 +0xce Previous write at 0x00c0000004f4 by goroutine 2578: github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).doSubscribeToOneFiler.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:197 +0x144 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:264 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:262 +0xc9 github.com/seaweedfs/seaweedfs/weed/pb.WithFilerClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:256 +0x85e github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).doSubscribeToOneFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:194 +0x41 github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).loopSubscribeToOneFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:97 +0x2fe github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:61 +0xce Goroutine 2579 (running) created at: github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:61 +0x404 github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate-fm() <autogenerated>:1 +0x72 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:250 +0x203b github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:173 +0x27e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:164 +0x10e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:128 +0x129 github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39 Goroutine 2578 (running) created at: github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:61 +0x404 github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate-fm() <autogenerated>:1 +0x72 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:250 +0x203b github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:173 +0x27e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:164 +0x10e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:128 +0x129 github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39  ,source-file | source-file,[filer] DATA RACE on doSubscribeToOneFiler https://github.com/seaweedfs/seaweedfs/issues/3507   WARNING: DATA RACE Read at 0x00c0000004f4 by goroutine 2579: github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).doSubscribeToOneFiler.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:197 +0x124 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:264 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:262 +0xc9 github.com/seaweedfs/seaweedfs/weed/pb.WithFilerClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:256 +0x85e github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).doSubscribeToOneFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:194 +0x41 github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).loopSubscribeToOneFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:97 +0x2fe github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:61 +0xce Previous write at 0x00c0000004f4 by goroutine 2578: github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).doSubscribeToOneFiler.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:197 +0x144 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:264 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcFilerClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:262 +0xc9 github.com/seaweedfs/seaweedfs/weed/pb.WithFilerClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:256 +0x85e github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).doSubscribeToOneFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:194 +0x41 github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).loopSubscribeToOneFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:97 +0x2fe github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:61 +0xce Goroutine 2579 (running) created at: github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:61 +0x404 github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate-fm() <autogenerated>:1 +0x72 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:250 +0x203b github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:173 +0x27e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:164 +0x10e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:128 +0x129 github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39 Goroutine 2578 (running) created at: github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/meta_aggregator.go:61 +0x404 github.com/seaweedfs/seaweedfs/weed/filer.(*MetaAggregator).OnPeerUpdate-fm() <autogenerated>:1 +0x72 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:250 +0x203b github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:173 +0x27e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:164 +0x10e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:128 +0x129 github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39   source-file source-file,no-bug,0.95
1239,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1239,filler does not pass query params to volume server,Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** requests to filer like http://172.18.0.18:8888/test/1.jpg?width=200 didnt resize image it looks like something was broken in version 1.59 (1.58 works as expected) **System Setup** version 30GB 1.64 linux amd64,source-file | source-file | source-file,filler does not pass query params to volume server Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** requests to filer like http://172.18.0.18:8888/test/1.jpg?width=200 didnt resize image it looks like something was broken in version 1.59 (1.58 works as expected) **System Setup** version 30GB 1.64 linux amd64 source-file source-file source-file,bug,0.9
2194,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2194,[volume.balance] gracefull move volumes during active recording,"**Describe the bug** In a regulat task runs  lock volume.check.disk -v -force volume.fix.replication volume.balance -collection EACH_COLLECTION -force volume.check.disk -v -force unlock | weed shell  logs  > > load collection xxxxxxx-store volume 110 index size 42080 from fast-volume-0.s3-fast-volume.dc2:8080  load collection xxxxxxx-store volume 110 index size 42080 from fast-volume-2.s3-fast-volume.dc1:8080  volume 110 fast-volume-0.s3-fast-volume.dc2:8080 has 2630 entries, fast-volume-2.s3-fast-volume.dc1:8080 missed 0 entries volume 110 fast-volume-2.s3-fast-volume.dc1:8080 has 2630 entries, fast-volume-0.s3-fast-volume.dc2:8080 missed 0 entries load collection xxxxxxx-store volume 111 index size 43376 from fast-volume-3.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 111 index size 43376 from fast-volume-2.s3-fast-volume.dc2:8080  volume 111 fast-volume-3.s3-fast-volume.dc1:8080 has 2711 entries, fast-volume-2.s3-fast-volume.dc2:8080 missed 0 entries volume 111 fast-volume-2.s3-fast-volume.dc2:8080 has 2711 entries, fast-volume-3.s3-fast-volume.dc1:8080 missed 0 entries load collection xxxxxxx-store volume 113 index size 1632 from fast-volume-1.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 113 index size 1632 from fast-volume-1.s3-fast-volume.dc2:8080  volume 113 fast-volume-1.s3-fast-volume.dc1:8080 has 102 entries, fast-volume-1.s3-fast-volume.dc2:8080 missed 0 entries volume 113 fast-volume-1.s3-fast-volume.dc2:8080 has 102 entries, fast-volume-1.s3-fast-volume.dc1:8080 missed 0 entries > > moving volume xxxxxxx-store_112 fast-volume-1.s3-fast-volume.dc2:8080 => fast-volume-0.s3-fast-volume.dc2:8080 2021/07/13 09:26:11 copying volume 112 from fast-volume-1.s3-fast-volume.dc2:8080 to fast-volume-0.s3-fast-volume.dc2:8080 I0713 09:26:11 8 masterclient.go:139] adminShell: fast-volume-0.s3-fast-volume.dc2:8080 masterClient adds volume 112 2021/07/13 09:26:11 tailing volume 112 from fast-volume-1.s3-fast-volume.dc2:8080 to fast-volume-0.s3-fast-volume.dc2:8080 2021/07/13 09:26:23 deleting volume 112 from fast-volume-1.s3-fast-volume.dc2:8080 2021/07/13 09:26:23 moved volume 112 from fast-volume-1.s3-fast-volume.dc2:8080 to fast-volume-0.s3-fast-volume.dc2:8080 2021/07/13 09:26:23 copying volume 113 from fast-volume-1.s3-fast-volume.dc1:8080 to fast-volume-3.s3-fast-volume.dc1:8080 moving volume xxxxxxx-store_113 fast-volume-1.s3-fast-volume.dc1:8080 => fast-volume-3.s3-fast-volume.dc1:8080 I0713 09:26:23 8 masterclient.go:143] adminShell: fast-volume-1.s3-fast-volume.dc2:8080 masterClient removes volume 112 I0713 09:26:23 8 masterclient.go:139] adminShell: fast-volume-3.s3-fast-volume.dc1:8080 masterClient adds volume 113 2021/07/13 09:26:23 tailing volume 113 from fast-volume-1.s3-fast-volume.dc1:8080 to fast-volume-3.s3-fast-volume.dc1:8080 2021/07/13 09:26:35 deleting volume 113 from fast-volume-1.s3-fast-volume.dc1:8080 2021/07/13 09:26:35 moved volume 113 from fast-volume-1.s3-fast-volume.dc1:8080 to fast-volume-3.s3-fast-volume.dc1:8080 I0713 09:26:35 8 masterclient.go:143] adminShell: fast-volume-1.s3-fast-volume.dc1:8080 masterClient removes volume 113 > load collection xxxxxxx-store volume 110 index size 42384 from fast-volume-0.s3-fast-volume.dc2:8080  load collection xxxxxxx-store volume 110 index size 42384 from fast-volume-2.s3-fast-volume.dc1:8080  volume 110 fast-volume-0.s3-fast-volume.dc2:8080 has 2649 entries, fast-volume-2.s3-fast-volume.dc1:8080 missed 0 entries volume 110 fast-volume-2.s3-fast-volume.dc1:8080 has 2649 entries, fast-volume-0.s3-fast-volume.dc2:8080 missed 0 entries load collection xxxxxxx-store volume 112 index size 1504 from fast-volume-0.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 112 index size 1408 from fast-volume-0.s3-fast-volume.dc2:8080  volume 112 fast-volume-0.s3-fast-volume.dc1:8080 has 94 entries, fast-volume-0.s3-fast-volume.dc2:8080 missed 6 entries read 112,3539333463 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333464 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333630 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333634 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333636 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333665 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 volume 112 fast-volume-0.s3-fast-volume.dc2:8080 has 88 entries, fast-volume-0.s3-fast-volume.dc1:8080 missed 0 entries load collection xxxxxxx-store volume 109 index size 43280 from fast-volume-1.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 109 index size 43280 from fast-volume-1.s3-fast-volume.dc2:8080  volume 109 fast-volume-1.s3-fast-volume.dc1:8080 has 2705 entries, fast-volume-1.s3-fast-volume.dc2:8080 missed 0 entries volume 109 fast-volume-1.s3-fast-volume.dc2:8080 has 2705 entries, fast-volume-1.s3-fast-volume.dc1:8080 missed 0 entries load collection xxxxxxx-store volume 111 index size 43760 from fast-volume-3.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 111 index size 43760 from fast-volume-2.s3-fast-volume.dc2:8080  volume 111 fast-volume-3.s3-fast-volume.dc1:8080 has 2735 entries, fast-volume-2.s3-fast-volume.dc2:8080 missed 0 entries volume 111 fast-volume-2.s3-fast-volume.dc2:8080 has 2735 entries, fast-volume-3.s3-fast-volume.dc1:8080 missed 0 entries  then catch errors  E0713 09:27:42 1 filer_server_handlers_read.go:168] failed to stream content /buckets/xxxxx-store/files/2021/07/13/117b4ac7-c197-430b-abf4-c6046a51a0ec: read chunk: http://fast-volume-0.s3-fast-volume.dc2:8080/112,0593aec3661828?readDeleted=true: 404 Not Found E0713 09:27:53 1 filer_server_handlers_read.go:168] failed to stream content /buckets/xxxxx-store/files/2021/07/13/117b4ac7-c197-430b-abf4-c6046a51a0ec: read chunk: http://fast-volume-0.s3-fast-volume.dc2:8080/112,0593aec3661828?readDeleted=true: 404 Not Found  **System Setup**  2.53  **Expected behavior** moving without read chunk errors",source-file,"[volume.balance] gracefull move volumes during active recording **Describe the bug** In a regulat task runs  lock volume.check.disk -v -force volume.fix.replication volume.balance -collection EACH_COLLECTION -force volume.check.disk -v -force unlock | weed shell  logs  > > load collection xxxxxxx-store volume 110 index size 42080 from fast-volume-0.s3-fast-volume.dc2:8080  load collection xxxxxxx-store volume 110 index size 42080 from fast-volume-2.s3-fast-volume.dc1:8080  volume 110 fast-volume-0.s3-fast-volume.dc2:8080 has 2630 entries, fast-volume-2.s3-fast-volume.dc1:8080 missed 0 entries volume 110 fast-volume-2.s3-fast-volume.dc1:8080 has 2630 entries, fast-volume-0.s3-fast-volume.dc2:8080 missed 0 entries load collection xxxxxxx-store volume 111 index size 43376 from fast-volume-3.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 111 index size 43376 from fast-volume-2.s3-fast-volume.dc2:8080  volume 111 fast-volume-3.s3-fast-volume.dc1:8080 has 2711 entries, fast-volume-2.s3-fast-volume.dc2:8080 missed 0 entries volume 111 fast-volume-2.s3-fast-volume.dc2:8080 has 2711 entries, fast-volume-3.s3-fast-volume.dc1:8080 missed 0 entries load collection xxxxxxx-store volume 113 index size 1632 from fast-volume-1.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 113 index size 1632 from fast-volume-1.s3-fast-volume.dc2:8080  volume 113 fast-volume-1.s3-fast-volume.dc1:8080 has 102 entries, fast-volume-1.s3-fast-volume.dc2:8080 missed 0 entries volume 113 fast-volume-1.s3-fast-volume.dc2:8080 has 102 entries, fast-volume-1.s3-fast-volume.dc1:8080 missed 0 entries > > moving volume xxxxxxx-store_112 fast-volume-1.s3-fast-volume.dc2:8080 => fast-volume-0.s3-fast-volume.dc2:8080 2021/07/13 09:26:11 copying volume 112 from fast-volume-1.s3-fast-volume.dc2:8080 to fast-volume-0.s3-fast-volume.dc2:8080 I0713 09:26:11 8 masterclient.go:139] adminShell: fast-volume-0.s3-fast-volume.dc2:8080 masterClient adds volume 112 2021/07/13 09:26:11 tailing volume 112 from fast-volume-1.s3-fast-volume.dc2:8080 to fast-volume-0.s3-fast-volume.dc2:8080 2021/07/13 09:26:23 deleting volume 112 from fast-volume-1.s3-fast-volume.dc2:8080 2021/07/13 09:26:23 moved volume 112 from fast-volume-1.s3-fast-volume.dc2:8080 to fast-volume-0.s3-fast-volume.dc2:8080 2021/07/13 09:26:23 copying volume 113 from fast-volume-1.s3-fast-volume.dc1:8080 to fast-volume-3.s3-fast-volume.dc1:8080 moving volume xxxxxxx-store_113 fast-volume-1.s3-fast-volume.dc1:8080 => fast-volume-3.s3-fast-volume.dc1:8080 I0713 09:26:23 8 masterclient.go:143] adminShell: fast-volume-1.s3-fast-volume.dc2:8080 masterClient removes volume 112 I0713 09:26:23 8 masterclient.go:139] adminShell: fast-volume-3.s3-fast-volume.dc1:8080 masterClient adds volume 113 2021/07/13 09:26:23 tailing volume 113 from fast-volume-1.s3-fast-volume.dc1:8080 to fast-volume-3.s3-fast-volume.dc1:8080 2021/07/13 09:26:35 deleting volume 113 from fast-volume-1.s3-fast-volume.dc1:8080 2021/07/13 09:26:35 moved volume 113 from fast-volume-1.s3-fast-volume.dc1:8080 to fast-volume-3.s3-fast-volume.dc1:8080 I0713 09:26:35 8 masterclient.go:143] adminShell: fast-volume-1.s3-fast-volume.dc1:8080 masterClient removes volume 113 > load collection xxxxxxx-store volume 110 index size 42384 from fast-volume-0.s3-fast-volume.dc2:8080  load collection xxxxxxx-store volume 110 index size 42384 from fast-volume-2.s3-fast-volume.dc1:8080  volume 110 fast-volume-0.s3-fast-volume.dc2:8080 has 2649 entries, fast-volume-2.s3-fast-volume.dc1:8080 missed 0 entries volume 110 fast-volume-2.s3-fast-volume.dc1:8080 has 2649 entries, fast-volume-0.s3-fast-volume.dc2:8080 missed 0 entries load collection xxxxxxx-store volume 112 index size 1504 from fast-volume-0.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 112 index size 1408 from fast-volume-0.s3-fast-volume.dc2:8080  volume 112 fast-volume-0.s3-fast-volume.dc1:8080 has 94 entries, fast-volume-0.s3-fast-volume.dc2:8080 missed 6 entries read 112,3539333463 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333464 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333630 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333634 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333636 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 read 112,3539333665 fast-volume-0.s3-fast-volume.dc1:8080 => fast-volume-0.s3-fast-volume.dc2:8080 volume 112 fast-volume-0.s3-fast-volume.dc2:8080 has 88 entries, fast-volume-0.s3-fast-volume.dc1:8080 missed 0 entries load collection xxxxxxx-store volume 109 index size 43280 from fast-volume-1.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 109 index size 43280 from fast-volume-1.s3-fast-volume.dc2:8080  volume 109 fast-volume-1.s3-fast-volume.dc1:8080 has 2705 entries, fast-volume-1.s3-fast-volume.dc2:8080 missed 0 entries volume 109 fast-volume-1.s3-fast-volume.dc2:8080 has 2705 entries, fast-volume-1.s3-fast-volume.dc1:8080 missed 0 entries load collection xxxxxxx-store volume 111 index size 43760 from fast-volume-3.s3-fast-volume.dc1:8080  load collection xxxxxxx-store volume 111 index size 43760 from fast-volume-2.s3-fast-volume.dc2:8080  volume 111 fast-volume-3.s3-fast-volume.dc1:8080 has 2735 entries, fast-volume-2.s3-fast-volume.dc2:8080 missed 0 entries volume 111 fast-volume-2.s3-fast-volume.dc2:8080 has 2735 entries, fast-volume-3.s3-fast-volume.dc1:8080 missed 0 entries  then catch errors  E0713 09:27:42 1 filer_server_handlers_read.go:168] failed to stream content /buckets/xxxxx-store/files/2021/07/13/117b4ac7-c197-430b-abf4-c6046a51a0ec: read chunk: http://fast-volume-0.s3-fast-volume.dc2:8080/112,0593aec3661828?readDeleted=true: 404 Not Found E0713 09:27:53 1 filer_server_handlers_read.go:168] failed to stream content /buckets/xxxxx-store/files/2021/07/13/117b4ac7-c197-430b-abf4-c6046a51a0ec: read chunk: http://fast-volume-0.s3-fast-volume.dc2:8080/112,0593aec3661828?readDeleted=true: 404 Not Found  **System Setup**  2.53  **Expected behavior** moving without read chunk errors source-file",no-bug,0.8
4270,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4270,filer api should return client error (4XX) code instead 500 if dir already exists,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** Right now if `dir` (filer.path) exists and `/POST` request is sent to that dir, filer returns `500 internal server error` with message `{""error"":""dir /foo already exists""}`. Ideally here filer should return Client Error (4XX) code like `409` instead of `500`. **System Setup** Setup contains empty storage with default settings started using below commands  weed master -mdir=""."" -ip=localhost weed volume -max=100 -mserver=""localhost:9333"" -dir=""./data"" weed filer -ip=localhost -port=8888 -master=localhost:9333  Weed version is `version 30GB 3.33 ee7bf69c0396098bce2d030f24dba5085c392b7c linux amd64`. Below are steps to reproduce  curl -vvv -X POST ""http://localhost:8888/foo/"" * Trying 127.0.0.1:8888 * Connected to localhost (127.0.0.1) port 8888 (#0) > POST /foo/ HTTP/1.1 > Host: localhost:8888 > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 201 Created < Content-Type: application/json < Server: SeaweedFS Filer 30GB 3.33 < Date: Sun, 05 Mar 2023 07:25:46 GMT < Content-Length: 14 < * Connection #0 to host localhost left intact {""name"":""foo""} % curl -vvv -X POST ""http://localhost:8888/foo/"" * Trying 127.0.0.1:8888 * Connected to localhost (127.0.0.1) port 8888 (#0) > POST /foo/ HTTP/1.1 > Host: localhost:8888 > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 500 Internal Server Error < Content-Type: application/json < Server: SeaweedFS Filer 30GB 3.33 < Date: Sun, 05 Mar 2023 07:27:18 GMT < Content-Length: 35 < * Connection #0 to host localhost left intact {""error"":""dir /foo already exists""}%  **Expected behavior** filer should return Client Error (4XX) code like `409` instead of `500`",source-file | source-file,"filer api should return client error (4XX) code instead 500 if dir already exists Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** Right now if `dir` (filer.path) exists and `/POST` request is sent to that dir, filer returns `500 internal server error` with message `{""error"":""dir /foo already exists""}`. Ideally here filer should return Client Error (4XX) code like `409` instead of `500`. **System Setup** Setup contains empty storage with default settings started using below commands  weed master -mdir=""."" -ip=localhost weed volume -max=100 -mserver=""localhost:9333"" -dir=""./data"" weed filer -ip=localhost -port=8888 -master=localhost:9333  Weed version is `version 30GB 3.33 ee7bf69c0396098bce2d030f24dba5085c392b7c linux amd64`. Below are steps to reproduce  curl -vvv -X POST ""http://localhost:8888/foo/"" * Trying 127.0.0.1:8888 * Connected to localhost (127.0.0.1) port 8888 (#0) > POST /foo/ HTTP/1.1 > Host: localhost:8888 > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 201 Created < Content-Type: application/json < Server: SeaweedFS Filer 30GB 3.33 < Date: Sun, 05 Mar 2023 07:25:46 GMT < Content-Length: 14 < * Connection #0 to host localhost left intact {""name"":""foo""} % curl -vvv -X POST ""http://localhost:8888/foo/"" * Trying 127.0.0.1:8888 * Connected to localhost (127.0.0.1) port 8888 (#0) > POST /foo/ HTTP/1.1 > Host: localhost:8888 > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 500 Internal Server Error < Content-Type: application/json < Server: SeaweedFS Filer 30GB 3.33 < Date: Sun, 05 Mar 2023 07:27:18 GMT < Content-Length: 35 < * Connection #0 to host localhost left intact {""error"":""dir /foo already exists""}%  **Expected behavior** filer should return Client Error (4XX) code like `409` instead of `500` source-file source-file",bug,0.95
3514,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3514,[master] DATA RACE on adds volume id,https://github.com/seaweedfs/seaweedfs/issues/3507  volume_1 | I0825 10:41:47.232196 store.go:147 add volume 64 volume_1 | I0825 10:41:47.232755 volume_grpc_client_to_master.go:172 volume server volume:8080 adds volume 64 master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe3c0 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:103 +0x11e master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe3c0 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:103 +0x153 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe3f0 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:103 +0x11e master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe3f0 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:103 +0x153 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe430 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:105 +0x1cc master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe430 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:105 +0x208 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe438 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:106 +0x227 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe438 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:106 +0x264 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe4a0 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:107 +0x284 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe4a0 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:107 +0x2c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 | I0825 10:41:47.255734 volume_layout.go:391 Volume 64 becomes writable master_1 | I0825 10:41:47.255969 volume_growth.go:245 Created Volume 64 on topo:DefaultDataCenter:DefaultRack:volume:8080 ,source-file,[master] DATA RACE on adds volume id https://github.com/seaweedfs/seaweedfs/issues/3507  volume_1 | I0825 10:41:47.232196 store.go:147 add volume 64 volume_1 | I0825 10:41:47.232755 volume_grpc_client_to_master.go:172 volume server volume:8080 adds volume 64 master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe3c0 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:103 +0x11e master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe3c0 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:103 +0x153 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe3f0 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:103 +0x11e master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe3f0 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:103 +0x153 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe430 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:105 +0x1cc master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe430 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:105 +0x208 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe438 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:106 +0x227 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe438 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:106 +0x264 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0005fe4a0 by goroutine 3493: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:107 +0x284 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:165 +0x5c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*Disk).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:149 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).doAddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:58 +0x7a master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AddOrUpdateVolume() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:43 +0xe4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:243 +0x224 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xf1 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1de master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x11d master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0x1b7 master_1 | master_1 | Previous write at 0x00c0005fe4a0 by goroutine 109: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DiskUsageCounts).addDiskUsageCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/disk.go:107 +0x2c4 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:193 +0x119 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*NodeImpl).UpAdjustDiskUsageDelta() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/node.go:196 +0x341 master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*DataNode).AdjustMaxVolumeCounts() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/data_node.go:150 +0x2a4 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).SendHeartbeat() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server.go:135 +0x92b master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_SendHeartbeat_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:351 +0xc5 master_1 | google.golang.org/grpc.(*Server).processStreamingRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1558 +0x1c01 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1640 +0xfae master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Goroutine 3493 (running) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 | master_1 | Goroutine 109 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 |  master_1 | I0825 10:41:47.255734 volume_layout.go:391 Volume 64 becomes writable master_1 | I0825 10:41:47.255969 volume_growth.go:245 Created Volume 64 on topo:DefaultDataCenter:DefaultRack:volume:8080  source-file,no-bug,0.95
5306,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5306,panic: unaligned 64-bit atomic operation in weed mount on arm when reading a file,"**Describe the bug** - Running a cluster of 3 arm and 2 arm64 nodes. The issue only happens on arm. - `weed mount` crashes when reading a file. - It does not crash when writing a file, reading or writing directories. **System Setup** - Command line: `weed mount -filer=peer2:8888 -dir=/mnt/weed` - OS version: Debian 12 (armbian) - output of `weed version`: `version 30GB 3.62 59b8af99b0aca1b9e88fec7b5f27c7d15e5e8604 linux arm` - Server command line:  weed server -ip=peer2 -dir=/mnt/disk/weed -master.peers=peer2:9333,peer3:9333,peer4:9333,peer5:9333,peer1:9333 -filer  **Expected behavior** Obviously, no panic. **Screenshots**  weed-client.sh[22296]: panic: unaligned 64-bit atomic operation weed-client.sh[22296]: goroutine 112 [running]: weed-client.sh[22296]: runtime/internal/atomic.panicUnaligned() weed-client.sh[22296]: /usr/local/go/src/runtime/internal/atomic/unaligned.go:8 +0x24 weed-client.sh[22296]: runtime/internal/atomic.Store64(0x3db0894, 0x17b3dfd71c975816) weed-client.sh[22296]: /usr/local/go/src/runtime/internal/atomic/atomic_arm.s:291 +0x14 weed-client.sh[22296]: github.com/seaweedfs/seaweedfs/weed/filer.(*SingleChunkCacher).startCaching(0x3db0840) weed-client.sh[22296]: /github/workspace/weed/filer/reader_cache.go:183 +0x3c8 weed-client.sh[22296]: created by github.com/seaweedfs/seaweedfs/weed/filer.(*ReaderCache).ReadChunkAt in goroutine 1 weed-client.sh[22296]: /github/workspace/weed/filer/reader_cache.go:117 +0x3ec ",source-file | source-file,"panic: unaligned 64-bit atomic operation in weed mount on arm when reading a file **Describe the bug** - Running a cluster of 3 arm and 2 arm64 nodes. The issue only happens on arm. - `weed mount` crashes when reading a file. - It does not crash when writing a file, reading or writing directories. **System Setup** - Command line: `weed mount -filer=peer2:8888 -dir=/mnt/weed` - OS version: Debian 12 (armbian) - output of `weed version`: `version 30GB 3.62 59b8af99b0aca1b9e88fec7b5f27c7d15e5e8604 linux arm` - Server command line:  weed server -ip=peer2 -dir=/mnt/disk/weed -master.peers=peer2:9333,peer3:9333,peer4:9333,peer5:9333,peer1:9333 -filer  **Expected behavior** Obviously, no panic. **Screenshots**  weed-client.sh[22296]: panic: unaligned 64-bit atomic operation weed-client.sh[22296]: goroutine 112 [running]: weed-client.sh[22296]: runtime/internal/atomic.panicUnaligned() weed-client.sh[22296]: /usr/local/go/src/runtime/internal/atomic/unaligned.go:8 +0x24 weed-client.sh[22296]: runtime/internal/atomic.Store64(0x3db0894, 0x17b3dfd71c975816) weed-client.sh[22296]: /usr/local/go/src/runtime/internal/atomic/atomic_arm.s:291 +0x14 weed-client.sh[22296]: github.com/seaweedfs/seaweedfs/weed/filer.(*SingleChunkCacher).startCaching(0x3db0840) weed-client.sh[22296]: /github/workspace/weed/filer/reader_cache.go:183 +0x3c8 weed-client.sh[22296]: created by github.com/seaweedfs/seaweedfs/weed/filer.(*ReaderCache).ReadChunkAt in goroutine 1 weed-client.sh[22296]: /github/workspace/weed/filer/reader_cache.go:117 +0x3ec  source-file source-file",no-bug,0.95
1094,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1094,"1.44/FUSE3: Unable to ""mount"" / unknown option 'nonempty'", $ weed mount -dir=/mnt/weed This is SeaweedFS version 8000GB 1.44 linux amd64 mount point owner uid=1000 gid=1000 mode=drwxr-xr-x 2019-10-27 21:06:47.946233 I | mount helper error: fusermount: unsafe option suid ignored 2019-10-27 21:06:47.946258 I | mount helper error: fusermount: unknown option 'nonempty' F1027 21:06:47 22621 mount_std.go:116] fusermount: exit status 1   $ fusermount -V fusermount3 version: 3.4.1 ,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"1.44/FUSE3: Unable to ""mount"" / unknown option 'nonempty'  $ weed mount -dir=/mnt/weed This is SeaweedFS version 8000GB 1.44 linux amd64 mount point owner uid=1000 gid=1000 mode=drwxr-xr-x 2019-10-27 21:06:47.946233 I | mount helper error: fusermount: unsafe option suid ignored 2019-10-27 21:06:47.946258 I | mount helper error: fusermount: unknown option 'nonempty' F1027 21:06:47 22621 mount_std.go:116] fusermount: exit status 1   $ fusermount -V fusermount3 version: 3.4.1  source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2191,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2191,[feature request] auto retry for `volume.fix.replication` and `volumeServer.evacuate`,"When the network is not exactly 100% stable, these two commands may fail mid-way and abort without the operator noticing anything. It would be nice if they can at least attempt to retry the failed operation at least once before aborting.",source-file,"[feature request] auto retry for `volume.fix.replication` and `volumeServer.evacuate` When the network is not exactly 100% stable, these two commands may fail mid-way and abort without the operator noticing anything. It would be nice if they can at least attempt to retry the failed operation at least once before aborting. source-file",no-bug,0.9
447,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/447,Store.VolumeSizeLimit is always 0?,This makes every write operation triggers a log. bash $ weed server -dir=./weed -volume.max=10 I0123 11:43:28 7219 file_util.go:20] Folder ./weed Permission: -rwxrwxr-x I0123 11:43:28 7219 file_util.go:20] Folder ./weed Permission: -rwxrwxr-x I0123 11:43:28 7219 topology.go:81] Using default configurations. I0123 11:43:28 7219 master_server.go:67] Volume Size Limit is 30000 MB I0123 11:43:28 7219 server.go:217] Start Seaweed Master 0.74 at localhost:9333 I0123 11:43:28 7219 raft_server.go:56] Peers Change: [localhost:9333] => [] I0123 11:43:28 7219 raft_server.go:98] Initializing new cluster I0123 11:43:28 7219 master_server.go:100] [ localhost:9333 ] I am the leader! I0123 11:43:28 7219 disk_location.go:106] Store started on dir: ./weed with 0 volumes max 10 I0123 11:43:28 7219 server.go:290] Start Seaweed volume server 0.74 at localhost:8080 I0123 11:43:28 7219 volume_grpc_client.go:17] Volume server bootstraps with master localhost:9333 I0123 11:43:28 7219 volume_grpc_client.go:52] Heartbeat to localhost:9333 I0123 11:43:28 7219 node.go:223] topo adds child DefaultDataCenter I0123 11:43:28 7219 node.go:223] topo:DefaultDataCenter adds child DefaultRack I0123 11:43:28 7219 node.go:223] topo:DefaultDataCenter:DefaultRack adds child localhost:8080 I0123 11:43:28 7219 master_grpc_server.go:36] added volume server localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:1 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_1.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 1 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:2 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_2.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 2 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:3 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_3.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 3 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:4 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_4.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 4 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:5 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_5.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 5 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:6 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_6.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 6 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:7 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_7.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 7 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:279] volume 3 size 48 will exceed limit 0 I0123 11:43:30 7219 store.go:279] volume 3 size 96 will exceed limit 0 I0123 11:43:31 7219 store.go:279] volume 5 size 48 will exceed limit 0 I0123 11:43:31 7219 store.go:279] volume 7 size 67 will exceed limit 0 I0123 11:43:31 7219 store.go:279] volume 7 size 155 will exceed limit 0 I0123 11:43:31 7219 store.go:279] volume 1 size 89 will exceed limit 0 I0123 11:43:33 7219 volume_server.go:93] Shutting down volume server I0123 11:43:33 7219 volume_server.go:95] Shut down successfully! ,source-file | source-file,Store.VolumeSizeLimit is always 0? This makes every write operation triggers a log. bash $ weed server -dir=./weed -volume.max=10 I0123 11:43:28 7219 file_util.go:20] Folder ./weed Permission: -rwxrwxr-x I0123 11:43:28 7219 file_util.go:20] Folder ./weed Permission: -rwxrwxr-x I0123 11:43:28 7219 topology.go:81] Using default configurations. I0123 11:43:28 7219 master_server.go:67] Volume Size Limit is 30000 MB I0123 11:43:28 7219 server.go:217] Start Seaweed Master 0.74 at localhost:9333 I0123 11:43:28 7219 raft_server.go:56] Peers Change: [localhost:9333] => [] I0123 11:43:28 7219 raft_server.go:98] Initializing new cluster I0123 11:43:28 7219 master_server.go:100] [ localhost:9333 ] I am the leader! I0123 11:43:28 7219 disk_location.go:106] Store started on dir: ./weed with 0 volumes max 10 I0123 11:43:28 7219 server.go:290] Start Seaweed volume server 0.74 at localhost:8080 I0123 11:43:28 7219 volume_grpc_client.go:17] Volume server bootstraps with master localhost:9333 I0123 11:43:28 7219 volume_grpc_client.go:52] Heartbeat to localhost:9333 I0123 11:43:28 7219 node.go:223] topo adds child DefaultDataCenter I0123 11:43:28 7219 node.go:223] topo:DefaultDataCenter adds child DefaultRack I0123 11:43:28 7219 node.go:223] topo:DefaultDataCenter:DefaultRack adds child localhost:8080 I0123 11:43:28 7219 master_grpc_server.go:36] added volume server localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:1 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_1.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 1 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:2 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_2.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 2 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:3 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_3.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 3 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:4 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_4.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 4 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:5 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_5.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 5 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:6 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_6.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 6 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:169] In dir ./weed adds volume:7 collection:IMAGE_STORE_default replicaPlacement:000 ttl: I0123 11:43:30 7219 volume_loading.go:73] loading index file weed/IMAGE_STORE_default_7.idx readonly false I0123 11:43:30 7219 volume_growth.go:205] Created Volume 7 on topo:DefaultDataCenter:DefaultRack:localhost:8080 I0123 11:43:30 7219 store.go:279] volume 3 size 48 will exceed limit 0 I0123 11:43:30 7219 store.go:279] volume 3 size 96 will exceed limit 0 I0123 11:43:31 7219 store.go:279] volume 5 size 48 will exceed limit 0 I0123 11:43:31 7219 store.go:279] volume 7 size 67 will exceed limit 0 I0123 11:43:31 7219 store.go:279] volume 7 size 155 will exceed limit 0 I0123 11:43:31 7219 store.go:279] volume 1 size 89 will exceed limit 0 I0123 11:43:33 7219 volume_server.go:93] Shutting down volume server I0123 11:43:33 7219 volume_server.go:95] Shut down successfully!  source-file source-file,no-bug,0.9
6672,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6672,errors when reading uncached files from cloud drive,"When I'm reading an uncached file from remote volumes via fuse (weed mount), the returned file is the correct size but contain all 0's. Reading it a 2nd time or cache the file beforehand using remote.cache fixes the problem. Also using curl to retrieve the uncached file from a filer has no problems either. The following patch fixes the problem but I'm not sure it's an acceptable solution.  diff --git a/weed/mount/filehandle_read.go b/weed/mount/filehandle_read.go index a609c97cc..ce5f96341 100644  a/weed/mount/filehandle_read.go  b/weed/mount/filehandle_read.go @@ -89,7 +89,7 @@ func (fh *FileHandle) downloadRemoteEntry(entry *LockedEntry) error { return fmt.Errorf(""CacheRemoteObjectToLocalCluster file %s: %v"", fileFullPath, err) } - entry.SetEntry(resp.Entry) + fh.SetEntry(resp.Entry) fh.wfs.metaCache.InsertEntry(context.Background(), filer.FromPbEntry(request.Directory, resp.Entry)) ",source-file | source-file,"errors when reading uncached files from cloud drive When I'm reading an uncached file from remote volumes via fuse (weed mount), the returned file is the correct size but contain all 0's. Reading it a 2nd time or cache the file beforehand using remote.cache fixes the problem. Also using curl to retrieve the uncached file from a filer has no problems either. The following patch fixes the problem but I'm not sure it's an acceptable solution.  diff --git a/weed/mount/filehandle_read.go b/weed/mount/filehandle_read.go index a609c97cc..ce5f96341 100644  a/weed/mount/filehandle_read.go  b/weed/mount/filehandle_read.go @@ -89,7 +89,7 @@ func (fh *FileHandle) downloadRemoteEntry(entry *LockedEntry) error { return fmt.Errorf(""CacheRemoteObjectToLocalCluster file %s: %v"", fileFullPath, err) } - entry.SetEntry(resp.Entry) + fh.SetEntry(resp.Entry) fh.wfs.metaCache.InsertEntry(context.Background(), filer.FromPbEntry(request.Directory, resp.Entry))  source-file source-file",no-bug,0.9
5456,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5456,Master panic: runtime error: invalid memory address or nil pointer dereference,"**Describe the bug** Master crushed after running for 10 hours. I run seaweedfs in docker [using docker-compose like this](https://github.com/seaweedfs/seaweedfs/blob/master/docker/seaweedfs-compose.yml). Logs: _Master_: go I0330 07:59:37.912270 volume_growth.go:245 Created Volume 122218 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.912410 volume_layout.go:406 Volume 122218 becomes writable I0330 07:59:37.912458 volume_growth.go:258 Registered Volume 122218 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.920959 volume_growth.go:245 Created Volume 122219 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.921033 volume_layout.go:406 Volume 122219 becomes writable I0330 07:59:37.921053 volume_growth.go:258 Registered Volume 122219 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.933584 volume_growth.go:245 Created Volume 122220 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.933643 volume_layout.go:406 Volume 122220 becomes writable I0330 07:59:37.933698 volume_growth.go:258 Registered Volume 122220 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.965262 volume_growth.go:245 Created Volume 122221 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:38.109072 data_node.go:80 Deleting volume id: 122218 I0330 07:59:38.125827 data_node.go:80 Deleting volume id: 122219 I0330 07:59:38.128064 data_node.go:80 Deleting volume id: 122220 I0330 07:59:38.129798 data_node.go:80 Deleting volume id: 122221 I0330 07:59:38.273993 topology.go:276 removing volume info: Id:122218, Size:0, ReplicaPlacement:000, Collection:bucket-name, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from volume:8080 I0330 07:59:38.275046 volume_layout.go:225 volume 122218 does not have enough copies I0330 07:59:38.275073 volume_layout.go:230 volume 122218 remove from writable I0330 07:59:38.275082 volume_layout.go:393 Volume 122218 becomes unwritable I0330 07:59:38.275102 topology.go:276 removing volume info: Id:122219, Size:0, ReplicaPlacement:000, Collection:bucket-name, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from volume:8080 I0330 07:59:38.275147 volume_layout.go:225 volume 122219 does not have enough copies I0330 07:59:38.275155 volume_layout.go:230 volume 122219 remove from writable I0330 07:59:38.275162 volume_layout.go:393 Volume 122219 becomes unwritable I0330 07:59:38.275173 topology.go:276 removing volume info: Id:122220, Size:0, ReplicaPlacement:000, Collection:bucket-name, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from volume:8080 I0330 07:59:38.275191 volume_layout.go:225 volume 122220 does not have enough copies I0330 07:59:38.275199 volume_layout.go:230 volume 122220 remove from writable I0330 07:59:38.275205 volume_layout.go:393 Volume 122220 becomes unwritable I0330 07:59:38.275213 topology.go:276 removing volume info: Id:122221, Size:0, ReplicaPlacement:000, Collection:bucket-name, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from volume:8080 I0330 07:59:38.275226 volume_layout.go:225 volume 122221 does not have enough copies I0330 07:59:38.275233 volume_layout.go:230 volume 122221 remove from writable I0330 07:59:38.275256 master_grpc_server.go:203 master see deleted volume 122218 from volume:8080 I0330 07:59:38.275270 master_grpc_server.go:203 master see deleted volume 122219 from volume:8080 I0330 07:59:38.275275 master_grpc_server.go:203 master see deleted volume 122220 from volume:8080 I0330 07:59:38.275280 master_grpc_server.go:203 master see deleted volume 122221 from volume:8080 I0330 07:59:38.275315 volume_layout.go:225 volume 122221 does not have enough copies panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: bucker-name code=0x1 addr=0x0 pc=0x1938a9c] goroutine 63079999 [running]: github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).isAllWritable(0x3f86300?, 0x1dd6d) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:236 +0x3c github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).ensureCorrectWritables(0xc003de6480, 0x1dd6d) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:227 +0x1a5 github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).EnsureCorrectWritables(0xc003de6480, 0xc0019b78f8) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:215 +0x77 github.com/seaweedfs/seaweedfs/weed/topology.(*Topology).RegisterVolumeLayout(0xc000d1a3c0, {0x1dd6d, 0x0, 0xc007592000, 0x3feb658, {0x0, 0x0}, {0xc004906010, 0x9}, 0x3, }, ) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/topology.go:273 +0x94 github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow(0xc000d1a3c0?, {0x2bea520, 0xc00019b878}, 0xc000d1a3c0, 0x1dd6d, 0xc004ae4000, {0xc006aaa068, 0x1, 0x0?}) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:257 +0x7ee github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow(0xc00082ada0, {0x2bea520, 0xc00019b878}, 0xc000d1a3c0, 0xc004ae4000) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xbf github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType(0xc00082ada0, {0x2bea520, 0xc00019b878}, 0x7, 0xc004ae4000, 0xc000d1a3c0) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1b9 github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType(0xc00082ada0?, 0xc004ae4000, {0x2bea520?, 0xc00019b878?}, 0xc000d1a3c0?, 0xc000141e90?) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x8b github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0xe9 created by github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1 in goroutine 108 /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x1e5  _Volume_: go I0330 07:59:37.911957 volume_grpc_client_to_master.go:179 volume server volume:8080 adds volume 122218 I0330 07:59:37.912847 store.go:166 In dir /data adds volume:122219 collection:bucket-name replicaPlacement:000 ttl: I0330 07:59:37.920284 volume_loading.go:142 loading memory index /data/bucket-name_122219.idx to memory I0330 07:59:37.920790 store.go:170 add volume 122219 I0330 07:59:37.920832 volume_grpc_client_to_master.go:179 volume server volume:8080 adds volume 122219 I0330 07:59:37.921325 store.go:166 In dir /data adds volume:122220 collection:bucket-name replicaPlacement:000 ttl: I0330 07:59:37.932998 volume_loading.go:142 loading memory index /data/bucket-name_122220.idx to memory I0330 07:59:37.933446 store.go:170 add volume 122220 I0330 07:59:37.933483 volume_grpc_client_to_master.go:179 volume server volume:8080 adds volume 122220 I0330 07:59:37.934153 store.go:166 In dir /data adds volume:122221 collection:bucket-name replicaPlacement:000 ttl: I0330 07:59:37.964371 volume_loading.go:142 loading memory index /data/bucket-name_122221.idx to memory I0330 07:59:37.965020 store.go:170 add volume 122221 I0330 07:59:37.965087 volume_grpc_client_to_master.go:179 volume server volume:8080 adds volume 122221 I0330 07:59:38.321696 volume_grpc_client_to_master.go:71 heartbeat to master:9333 error: rpc error: code = Unavailable desc = error reading from server: EOF I0330 07:59:43.324408 volume_grpc_client_to_master.go:106 SendHeartbeat to master:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp: lookup master on 127.0.0.11:53: server misbehaving"" I0330 07:59:43.324527 volume_grpc_client_to_master.go:71 heartbeat to master:9333 error: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp: lookup master on 127.0.0.11:53: server misbehaving"" I0330 07:59:48.328150 volume_grpc_client_to_master.go:106 SendHeartbeat to master:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp: lookup master on 127.0.0.11:53: server misbehaving"" I0330 07:59:48.328267 volume_grpc_client_to_master.go:71 heartbeat to master:9333 error: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp: lookup master on 127.0.0.11:53: server misbehaving""  _S3_: go I0328 19:12:05.348781 s3.go:206 wait to connect to filer filer:8888 grpc address filer:18888 I0328 19:12:06.350729 s3.go:206 wait to connect to filer filer:8888 grpc address filer:18888 I0328 19:12:07.355579 s3.go:202 S3 read filer buckets dir: /buckets I0328 19:12:07.355607 s3.go:209 connected to filer filer:8888 grpc address filer:18888 I0328 19:12:07.357890 s3api_circuit_breaker.go:35 s3 circuit breaker not configured I0328 19:12:07.365203 s3.go:354 Start Seaweed S3 API Server 8000GB 3.64 b74e8082b at http port 8333 E0330 07:59:38.323736 s3api_object_handlers.go:519 upload to filer error: rpc error: code = Unavailable desc = error reading from server: read tcp 172.27.0.4:33092->172.27.0.2:19333: read: connection reset by peer E0330 07:59:38.323743 s3api_object_handlers.go:519 upload to filer error: rpc error: code = Unavailable desc = error reading from server: read tcp 172.27.0.4:33092->172.27.0.2:19333: read: connection reset by peer  _filer.toml_: go [leveldb2] enabled = true dir = ""/data/filerldb2""  _webdav is removed from docker-compose_ **System Setup** - Host OS: Ubuntu 22.04.1 LTS - Inside docker-compose, all images (master, volume, filer, s3) are chrislusf/seaweedfs:3.64_large_disk - `weed version`: version 8000GB 3.64 b74e8082b linux amd64 - Content of `filer.toml` - default, see above **Additional context** It works fine after restarting docker-compose",source-file | source-file,"Master panic: runtime error: invalid memory address or nil pointer dereference **Describe the bug** Master crushed after running for 10 hours. I run seaweedfs in docker [using docker-compose like this](https://github.com/seaweedfs/seaweedfs/blob/master/docker/seaweedfs-compose.yml). Logs: _Master_: go I0330 07:59:37.912270 volume_growth.go:245 Created Volume 122218 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.912410 volume_layout.go:406 Volume 122218 becomes writable I0330 07:59:37.912458 volume_growth.go:258 Registered Volume 122218 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.920959 volume_growth.go:245 Created Volume 122219 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.921033 volume_layout.go:406 Volume 122219 becomes writable I0330 07:59:37.921053 volume_growth.go:258 Registered Volume 122219 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.933584 volume_growth.go:245 Created Volume 122220 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.933643 volume_layout.go:406 Volume 122220 becomes writable I0330 07:59:37.933698 volume_growth.go:258 Registered Volume 122220 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:37.965262 volume_growth.go:245 Created Volume 122221 on topo:DefaultDataCenter:DefaultRack:volume:8080 I0330 07:59:38.109072 data_node.go:80 Deleting volume id: 122218 I0330 07:59:38.125827 data_node.go:80 Deleting volume id: 122219 I0330 07:59:38.128064 data_node.go:80 Deleting volume id: 122220 I0330 07:59:38.129798 data_node.go:80 Deleting volume id: 122221 I0330 07:59:38.273993 topology.go:276 removing volume info: Id:122218, Size:0, ReplicaPlacement:000, Collection:bucket-name, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from volume:8080 I0330 07:59:38.275046 volume_layout.go:225 volume 122218 does not have enough copies I0330 07:59:38.275073 volume_layout.go:230 volume 122218 remove from writable I0330 07:59:38.275082 volume_layout.go:393 Volume 122218 becomes unwritable I0330 07:59:38.275102 topology.go:276 removing volume info: Id:122219, Size:0, ReplicaPlacement:000, Collection:bucket-name, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from volume:8080 I0330 07:59:38.275147 volume_layout.go:225 volume 122219 does not have enough copies I0330 07:59:38.275155 volume_layout.go:230 volume 122219 remove from writable I0330 07:59:38.275162 volume_layout.go:393 Volume 122219 becomes unwritable I0330 07:59:38.275173 topology.go:276 removing volume info: Id:122220, Size:0, ReplicaPlacement:000, Collection:bucket-name, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from volume:8080 I0330 07:59:38.275191 volume_layout.go:225 volume 122220 does not have enough copies I0330 07:59:38.275199 volume_layout.go:230 volume 122220 remove from writable I0330 07:59:38.275205 volume_layout.go:393 Volume 122220 becomes unwritable I0330 07:59:38.275213 topology.go:276 removing volume info: Id:122221, Size:0, ReplicaPlacement:000, Collection:bucket-name, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from volume:8080 I0330 07:59:38.275226 volume_layout.go:225 volume 122221 does not have enough copies I0330 07:59:38.275233 volume_layout.go:230 volume 122221 remove from writable I0330 07:59:38.275256 master_grpc_server.go:203 master see deleted volume 122218 from volume:8080 I0330 07:59:38.275270 master_grpc_server.go:203 master see deleted volume 122219 from volume:8080 I0330 07:59:38.275275 master_grpc_server.go:203 master see deleted volume 122220 from volume:8080 I0330 07:59:38.275280 master_grpc_server.go:203 master see deleted volume 122221 from volume:8080 I0330 07:59:38.275315 volume_layout.go:225 volume 122221 does not have enough copies panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: bucker-name code=0x1 addr=0x0 pc=0x1938a9c] goroutine 63079999 [running]: github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).isAllWritable(0x3f86300?, 0x1dd6d) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:236 +0x3c github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).ensureCorrectWritables(0xc003de6480, 0x1dd6d) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:227 +0x1a5 github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).EnsureCorrectWritables(0xc003de6480, 0xc0019b78f8) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:215 +0x77 github.com/seaweedfs/seaweedfs/weed/topology.(*Topology).RegisterVolumeLayout(0xc000d1a3c0, {0x1dd6d, 0x0, 0xc007592000, 0x3feb658, {0x0, 0x0}, {0xc004906010, 0x9}, 0x3, }, ) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/topology.go:273 +0x94 github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).grow(0xc000d1a3c0?, {0x2bea520, 0xc00019b878}, 0xc000d1a3c0, 0x1dd6d, 0xc004ae4000, {0xc006aaa068, 0x1, 0x0?}) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:257 +0x7ee github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).findAndGrow(0xc00082ada0, {0x2bea520, 0xc00019b878}, 0xc000d1a3c0, 0xc004ae4000) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:115 +0xbf github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).GrowByCountAndType(0xc00082ada0, {0x2bea520, 0xc00019b878}, 0x7, 0xc004ae4000, 0xc000d1a3c0) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:96 +0x1b9 github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeGrowth).AutomaticGrowByType(0xc00082ada0?, 0xc004ae4000, {0x2bea520?, 0xc00019b878?}, 0xc000d1a3c0?, 0xc000141e90?) /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_growth.go:85 +0x8b github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:55 +0xe9 created by github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1 in goroutine 108 /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x1e5  _Volume_: go I0330 07:59:37.911957 volume_grpc_client_to_master.go:179 volume server volume:8080 adds volume 122218 I0330 07:59:37.912847 store.go:166 In dir /data adds volume:122219 collection:bucket-name replicaPlacement:000 ttl: I0330 07:59:37.920284 volume_loading.go:142 loading memory index /data/bucket-name_122219.idx to memory I0330 07:59:37.920790 store.go:170 add volume 122219 I0330 07:59:37.920832 volume_grpc_client_to_master.go:179 volume server volume:8080 adds volume 122219 I0330 07:59:37.921325 store.go:166 In dir /data adds volume:122220 collection:bucket-name replicaPlacement:000 ttl: I0330 07:59:37.932998 volume_loading.go:142 loading memory index /data/bucket-name_122220.idx to memory I0330 07:59:37.933446 store.go:170 add volume 122220 I0330 07:59:37.933483 volume_grpc_client_to_master.go:179 volume server volume:8080 adds volume 122220 I0330 07:59:37.934153 store.go:166 In dir /data adds volume:122221 collection:bucket-name replicaPlacement:000 ttl: I0330 07:59:37.964371 volume_loading.go:142 loading memory index /data/bucket-name_122221.idx to memory I0330 07:59:37.965020 store.go:170 add volume 122221 I0330 07:59:37.965087 volume_grpc_client_to_master.go:179 volume server volume:8080 adds volume 122221 I0330 07:59:38.321696 volume_grpc_client_to_master.go:71 heartbeat to master:9333 error: rpc error: code = Unavailable desc = error reading from server: EOF I0330 07:59:43.324408 volume_grpc_client_to_master.go:106 SendHeartbeat to master:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp: lookup master on 127.0.0.11:53: server misbehaving"" I0330 07:59:43.324527 volume_grpc_client_to_master.go:71 heartbeat to master:9333 error: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp: lookup master on 127.0.0.11:53: server misbehaving"" I0330 07:59:48.328150 volume_grpc_client_to_master.go:106 SendHeartbeat to master:9333: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp: lookup master on 127.0.0.11:53: server misbehaving"" I0330 07:59:48.328267 volume_grpc_client_to_master.go:71 heartbeat to master:9333 error: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing: dial tcp: lookup master on 127.0.0.11:53: server misbehaving""  _S3_: go I0328 19:12:05.348781 s3.go:206 wait to connect to filer filer:8888 grpc address filer:18888 I0328 19:12:06.350729 s3.go:206 wait to connect to filer filer:8888 grpc address filer:18888 I0328 19:12:07.355579 s3.go:202 S3 read filer buckets dir: /buckets I0328 19:12:07.355607 s3.go:209 connected to filer filer:8888 grpc address filer:18888 I0328 19:12:07.357890 s3api_circuit_breaker.go:35 s3 circuit breaker not configured I0328 19:12:07.365203 s3.go:354 Start Seaweed S3 API Server 8000GB 3.64 b74e8082b at http port 8333 E0330 07:59:38.323736 s3api_object_handlers.go:519 upload to filer error: rpc error: code = Unavailable desc = error reading from server: read tcp 172.27.0.4:33092->172.27.0.2:19333: read: connection reset by peer E0330 07:59:38.323743 s3api_object_handlers.go:519 upload to filer error: rpc error: code = Unavailable desc = error reading from server: read tcp 172.27.0.4:33092->172.27.0.2:19333: read: connection reset by peer  _filer.toml_: go [leveldb2] enabled = true dir = ""/data/filerldb2""  _webdav is removed from docker-compose_ **System Setup** - Host OS: Ubuntu 22.04.1 LTS - Inside docker-compose, all images (master, volume, filer, s3) are chrislusf/seaweedfs:3.64_large_disk - `weed version`: version 8000GB 3.64 b74e8082b linux amd64 - Content of `filer.toml` - default, see above **Additional context** It works fine after restarting docker-compose source-file source-file",no-bug,0.9
150,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/150,build failed," # github.com/chrislusf/weed-fs/go/weed src/github.com/chrislusf/weed-fs/go/weed/mount_std.go:75: cannot use File literal (type File) as type fs.Node in return argument: File does not implement fs.Node (wrong type for Attr method) have Attr(*fuse.Attr) want Attr(""golang.org/x/net/context"".Context, *fuse.Attr) error src/github.com/chrislusf/weed-fs/go/weed/mount_std.go:83: cannot use Dir literal (type Dir) as type fs.Node in return argument: Dir does not implement fs.Node (wrong type for Attr method) have Attr(*fuse.Attr) want Attr(""golang.org/x/net/context"".Context, *fuse.Attr) error # github.com/chrislusf/weed-fs/go/weed ./mount_std.go:75: cannot use File literal (type File) as type fs.Node in return argument: File does not implement fs.Node (wrong type for Attr method) have Attr(*fuse.Attr) want Attr(""golang.org/x/net/context"".Context, *fuse.Attr) error ./mount_std.go:83: cannot use Dir literal (type Dir) as type fs.Node in return argument: Dir does not implement fs.Node (wrong type for Attr method) have Attr(*fuse.Attr) want Attr(""golang.org/x/net/context"".Context, *fuse.Attr) error ",source-file,"build failed  # github.com/chrislusf/weed-fs/go/weed src/github.com/chrislusf/weed-fs/go/weed/mount_std.go:75: cannot use File literal (type File) as type fs.Node in return argument: File does not implement fs.Node (wrong type for Attr method) have Attr(*fuse.Attr) want Attr(""golang.org/x/net/context"".Context, *fuse.Attr) error src/github.com/chrislusf/weed-fs/go/weed/mount_std.go:83: cannot use Dir literal (type Dir) as type fs.Node in return argument: Dir does not implement fs.Node (wrong type for Attr method) have Attr(*fuse.Attr) want Attr(""golang.org/x/net/context"".Context, *fuse.Attr) error # github.com/chrislusf/weed-fs/go/weed ./mount_std.go:75: cannot use File literal (type File) as type fs.Node in return argument: File does not implement fs.Node (wrong type for Attr method) have Attr(*fuse.Attr) want Attr(""golang.org/x/net/context"".Context, *fuse.Attr) error ./mount_std.go:83: cannot use Dir literal (type Dir) as type fs.Node in return argument: Dir does not implement fs.Node (wrong type for Attr method) have Attr(*fuse.Attr) want Attr(""golang.org/x/net/context"".Context, *fuse.Attr) error  source-file",no-bug,0.95
1184,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1184,weed panic,"**Describe the bug** Some hours after upgrading from 1.45 to 1.50 i had a panic:  Jan 21 14:09:09 photol-108 weed[31469]: panic: runtime error: invalid memory address or nil pointer dereference Jan 21 14:09:09 photol-108 weed[31469]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x30 pc=0xa25d69] Jan 21 14:09:09 photol-108 weed[31469]: goroutine 351366 [running]: Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage/needle.ReadNeedleBlob(0x0, 0x0, 0x8, 0x3000c4581, 0xc1ad191d60, 0x1, 0xc09ee0f658, 0x4fd8ec, 0xc2659b2000) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/needle/needle_read_write.go:158 +0x79 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage/needle.(*Needle).ReadData(0xc09ee0f780, 0x0, 0x0, 0x8, 0x3000c4581, 0xc1a691fef0, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/needle/needle_read_write.go:195 +0x54 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage.(*Volume).copyDataBasedOnIndexFile.func1(0x3bb7dae5, 0xc458101000000, 0x4, 0xc4581) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/volume_vacuum.go:386 +0x17b Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage/needle_map.(*MemDb).AscendingVisit(0xc01195a588, 0xc09ee0f928, 0x8, 0x8) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/needle_map/memdb.go:73 +0x163 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage.(*Volume).copyDataBasedOnIndexFile(0xc17faacc30, 0xc067995200, 0x2e, 0xc067995260, 0x2e, 0x0, 0x0, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/volume_vacuum.go:377 +0x298 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage.(*Volume).Compact2(0xc17faacc30, 0x0, 0x0, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/volume_vacuum.go:75 +0x2b8 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage.(*Store).CompactVolume(0xc000488180, 0x20b5, 0x0, 0x3200000, 0x1dbb2e0, 0x1e3c620) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/store_vacuum.go:19 +0x54 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).VacuumVolumeCompact(0xc0003d46e0, 0x217aa60, 0xc1d0119560, 0xc3b80202f0, 0xc0003d46e0, 0xc1d0119470, 0x1b68520) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/server/volume_grpc_vacuum.go:31 +0x81 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/pb/volume_server_pb._VolumeServer_VacuumVolumeCompact_Handler(0x1e3c620, 0xc0003d46e0, 0x217aa60, 0xc1d0119560, 0xc0c8686000, 0x0, 0x0, 0x0, 0xc3b80202e8, 0x3) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/pb/volume_server_pb/volume_server.pb.go:2673 +0x23e Jan 21 14:09:09 photol-108 weed[31469]: google.golang.org/grpc.(*Server).processUnaryRPC(0xc00035a2c0, 0x218c860, 0xc01413b080, 0xc0e7f97400, 0xc2c37b8ab0, 0x347d810, 0x0, 0x0, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /root/go/pkg/mod/google.golang.org/grpc@v1.23.0/server.go:995 +0x485 Jan 21 14:09:09 photol-108 weed[31469]: google.golang.org/grpc.(*Server).handleStream(0xc00035a2c0, 0x218c860, 0xc01413b080, 0xc0e7f97400, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /root/go/pkg/mod/google.golang.org/grpc@v1.23.0/server.go:1275 +0xe02 Jan 21 14:09:09 photol-108 weed[31469]: google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc1803ea5a0, 0xc00035a2c0, 0x218c860, 0xc01413b080, 0xc0e7f97400) Jan 21 14:09:09 photol-108 weed[31469]: /root/go/pkg/mod/google.golang.org/grpc@v1.23.0/server.go:710 +0x9f Jan 21 14:09:09 photol-108 weed[31469]: created by google.golang.org/grpc.(*Server).serveStreams.func1 Jan 21 14:09:09 photol-108 weed[31469]: /root/go/pkg/mod/google.golang.org/grpc@v1.23.0/server.go:708 +0xa1  **System Setup**  - /usr/local/bin/weed -logtostderr master -mdir=/mnt/data01/meta -ip=10.1.21.18 -defaultReplication=010 -volumePreallocate -volumeSizeLimitMB 30000 -pulseSeconds 10 -peers=10.1.21.17:9333,10.1.21.18:9333,10.1.21.19:9333 - /usr/local/bin/weed -logtostderr -v=1 volume -compactionMBps=50 -port=8080 -mserver=10.1.21.17:9333,10.1.21.18:9333,10.1.21.19:9333 -dir=/mnt/data01/data,/mnt/data02/data -index leveldb -max 3866,3866 -ip 10.1.21.18 -rack photol-108 - version 30GB 1.50 linux amd64 - Ubuntu 16.04  **Additional context** Running force gc at 0.10",source-file,"weed panic **Describe the bug** Some hours after upgrading from 1.45 to 1.50 i had a panic:  Jan 21 14:09:09 photol-108 weed[31469]: panic: runtime error: invalid memory address or nil pointer dereference Jan 21 14:09:09 photol-108 weed[31469]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x30 pc=0xa25d69] Jan 21 14:09:09 photol-108 weed[31469]: goroutine 351366 [running]: Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage/needle.ReadNeedleBlob(0x0, 0x0, 0x8, 0x3000c4581, 0xc1ad191d60, 0x1, 0xc09ee0f658, 0x4fd8ec, 0xc2659b2000) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/needle/needle_read_write.go:158 +0x79 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage/needle.(*Needle).ReadData(0xc09ee0f780, 0x0, 0x0, 0x8, 0x3000c4581, 0xc1a691fef0, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/needle/needle_read_write.go:195 +0x54 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage.(*Volume).copyDataBasedOnIndexFile.func1(0x3bb7dae5, 0xc458101000000, 0x4, 0xc4581) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/volume_vacuum.go:386 +0x17b Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage/needle_map.(*MemDb).AscendingVisit(0xc01195a588, 0xc09ee0f928, 0x8, 0x8) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/needle_map/memdb.go:73 +0x163 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage.(*Volume).copyDataBasedOnIndexFile(0xc17faacc30, 0xc067995200, 0x2e, 0xc067995260, 0x2e, 0x0, 0x0, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/volume_vacuum.go:377 +0x298 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage.(*Volume).Compact2(0xc17faacc30, 0x0, 0x0, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/volume_vacuum.go:75 +0x2b8 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/storage.(*Store).CompactVolume(0xc000488180, 0x20b5, 0x0, 0x3200000, 0x1dbb2e0, 0x1e3c620) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/storage/store_vacuum.go:19 +0x54 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).VacuumVolumeCompact(0xc0003d46e0, 0x217aa60, 0xc1d0119560, 0xc3b80202f0, 0xc0003d46e0, 0xc1d0119470, 0x1b68520) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/server/volume_grpc_vacuum.go:31 +0x81 Jan 21 14:09:09 photol-108 weed[31469]: github.com/chrislusf/seaweedfs/weed/pb/volume_server_pb._VolumeServer_VacuumVolumeCompact_Handler(0x1e3c620, 0xc0003d46e0, 0x217aa60, 0xc1d0119560, 0xc0c8686000, 0x0, 0x0, 0x0, 0xc3b80202e8, 0x3) Jan 21 14:09:09 photol-108 weed[31469]: /src/github.com/chrislusf/seaweedfs/weed/pb/volume_server_pb/volume_server.pb.go:2673 +0x23e Jan 21 14:09:09 photol-108 weed[31469]: google.golang.org/grpc.(*Server).processUnaryRPC(0xc00035a2c0, 0x218c860, 0xc01413b080, 0xc0e7f97400, 0xc2c37b8ab0, 0x347d810, 0x0, 0x0, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /root/go/pkg/mod/google.golang.org/grpc@v1.23.0/server.go:995 +0x485 Jan 21 14:09:09 photol-108 weed[31469]: google.golang.org/grpc.(*Server).handleStream(0xc00035a2c0, 0x218c860, 0xc01413b080, 0xc0e7f97400, 0x0) Jan 21 14:09:09 photol-108 weed[31469]: /root/go/pkg/mod/google.golang.org/grpc@v1.23.0/server.go:1275 +0xe02 Jan 21 14:09:09 photol-108 weed[31469]: google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc1803ea5a0, 0xc00035a2c0, 0x218c860, 0xc01413b080, 0xc0e7f97400) Jan 21 14:09:09 photol-108 weed[31469]: /root/go/pkg/mod/google.golang.org/grpc@v1.23.0/server.go:710 +0x9f Jan 21 14:09:09 photol-108 weed[31469]: created by google.golang.org/grpc.(*Server).serveStreams.func1 Jan 21 14:09:09 photol-108 weed[31469]: /root/go/pkg/mod/google.golang.org/grpc@v1.23.0/server.go:708 +0xa1  **System Setup**  - /usr/local/bin/weed -logtostderr master -mdir=/mnt/data01/meta -ip=10.1.21.18 -defaultReplication=010 -volumePreallocate -volumeSizeLimitMB 30000 -pulseSeconds 10 -peers=10.1.21.17:9333,10.1.21.18:9333,10.1.21.19:9333 - /usr/local/bin/weed -logtostderr -v=1 volume -compactionMBps=50 -port=8080 -mserver=10.1.21.17:9333,10.1.21.18:9333,10.1.21.19:9333 -dir=/mnt/data01/data,/mnt/data02/data -index leveldb -max 3866,3866 -ip 10.1.21.18 -rack photol-108 - version 30GB 1.50 linux amd64 - Ubuntu 16.04  **Additional context** Running force gc at 0.10 source-file",no-bug,0.9
2433,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2433,[s3] force overwrite s3-is-admin,"Internal header s3-is-admin is not safe now It needs to be reset on an incoming request This code gives any superadmin  type AddHeaderTransport struct { T http.RoundTripper } func (adt *AddHeaderTransport) RoundTrip(req *http.Request) (*http.Response, error) { req.Header.Add(""s3-is-admin"", ""true"") return adt.T.RoundTrip(req) } func NewAddHeaderTransport(T http.RoundTripper) *AddHeaderTransport { if T == nil { T = http.DefaultTransport } return &AddHeaderTransport{T} } httpClient = &http.Client{Transport: NewAddHeaderTransport(nil)} s3Client := s3.NewFromConfig(aws.Config{HTTPClient: httpClient}) ",source-file,"[s3] force overwrite s3-is-admin Internal header s3-is-admin is not safe now It needs to be reset on an incoming request This code gives any superadmin  type AddHeaderTransport struct { T http.RoundTripper } func (adt *AddHeaderTransport) RoundTrip(req *http.Request) (*http.Response, error) { req.Header.Add(""s3-is-admin"", ""true"") return adt.T.RoundTrip(req) } func NewAddHeaderTransport(T http.RoundTripper) *AddHeaderTransport { if T == nil { T = http.DefaultTransport } return &AddHeaderTransport{T} } httpClient = &http.Client{Transport: NewAddHeaderTransport(nil)} s3Client := s3.NewFromConfig(aws.Config{HTTPClient: httpClient})  source-file",no-bug,0.8
2945,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2945,[fix] scan .dat File: cannot read needle header at offset,"**Describe the bug** fix return panic **System Setup**  2.99  **Expected behavior** fix re-create the index .idx file **Additional context** volume.lits  volume id:256 size:257705512 collection:""documents"" file_count:188 delete_count:168 deleted_byte_count:6034807 read_only:true replica_placement:10 version:3 modified_at_second:1642471870  panic logs  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960240 I0420 14:10:36 82 volume_read.go:131] new entry needle size:98 rest:112 I0420 14:10:36 82 fix.go:51] key 3060820471888067997 offset 256960240 size 98 disk_size 128 compressed false I0420 14:10:36 82 fix.go:54] saved 98 with error <nil> I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960368 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067993 offset 256960368 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960400 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067994 offset 256960400 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960432 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067995 offset 256960432 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960464 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067996 offset 256960464 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960496 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067997 offset 256960496 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960528 I0420 14:10:36 82 volume_read.go:131] new entry needle size:228 rest:248 I0420 14:10:36 82 fix.go:51] key 3060820471888067984 offset 256960528 size 228 disk_size 264 compressed false I0420 14:10:36 82 fix.go:54] saved 228 with error <nil> I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960792 I0420 14:10:36 82 volume_read.go:131] new entry needle size:-1754292226 rest:-1754292200 I0420 14:10:36 82 fix.go:51] key 18340839113111895790 offset 256960792 size -1754292226 disk_size -1754292184 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset -1497331392 F0420 14:10:36 82 fix.go:125] scan .dat File: cannot read needle header at offset -1497331392: readat /data/documents_256.dat: negative offset goroutine 1 [running]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0x0) /Users/tochka/GolandProjects/seaweedfs/weed/glog/glog.go:767 +0x8a github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x457b640, 0x3, 0xc0005ba000, {0x36f7b94?, 0xc000921d18?}, 0x1?, 0x0) /Users/tochka/GolandProjects/seaweedfs/weed/glog/glog.go:718 +0x3ab github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x7fff30538499?, 0x2?, {0x29c1b66, 0x12}, {0xc000921d18, 0x1, 0x1}) /Users/tochka/GolandProjects/seaweedfs/weed/glog/glog.go:656 +0x110 github.com/chrislusf/seaweedfs/weed/glog.Fatalf() /Users/tochka/GolandProjects/seaweedfs/weed/glog/glog.go:1149 github.com/chrislusf/seaweedfs/weed/command.doFixOneVolume({0x7fff30538499, 0x6}, {0xc00013fac0?, 0x40?}, {0xc00013fac0, 0x12}, 0x100) /Users/tochka/GolandProjects/seaweedfs/weed/command/fix.go:125 +0x1d7 github.com/chrislusf/seaweedfs/weed/command.runFix(0x455a898?, {0xc00004c0d0?, 0x1, 0x3?}) /Users/tochka/GolandProjects/seaweedfs/weed/command/fix.go:106 +0x48d main.main() /Users/tochka/GolandProjects/seaweedfs/weed/weed.go:81 +0x383 ",source-file,"[fix] scan .dat File: cannot read needle header at offset **Describe the bug** fix return panic **System Setup**  2.99  **Expected behavior** fix re-create the index .idx file **Additional context** volume.lits  volume id:256 size:257705512 collection:""documents"" file_count:188 delete_count:168 deleted_byte_count:6034807 read_only:true replica_placement:10 version:3 modified_at_second:1642471870  panic logs  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960240 I0420 14:10:36 82 volume_read.go:131] new entry needle size:98 rest:112 I0420 14:10:36 82 fix.go:51] key 3060820471888067997 offset 256960240 size 98 disk_size 128 compressed false I0420 14:10:36 82 fix.go:54] saved 98 with error <nil> I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960368 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067993 offset 256960368 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960400 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067994 offset 256960400 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960432 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067995 offset 256960432 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960464 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067996 offset 256960464 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960496 I0420 14:10:36 82 volume_read.go:131] new entry needle size:0 rest:16 I0420 14:10:36 82 fix.go:51] key 3060820471888067997 offset 256960496 size 0 disk_size 32 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960528 I0420 14:10:36 82 volume_read.go:131] new entry needle size:228 rest:248 I0420 14:10:36 82 fix.go:51] key 3060820471888067984 offset 256960528 size 228 disk_size 264 compressed false I0420 14:10:36 82 fix.go:54] saved 228 with error <nil> I0420 14:10:36 82 volume_read.go:124] ==> new entry offset 256960792 I0420 14:10:36 82 volume_read.go:131] new entry needle size:-1754292226 rest:-1754292200 I0420 14:10:36 82 fix.go:51] key 18340839113111895790 offset 256960792 size -1754292226 disk_size -1754292184 compressed false I0420 14:10:36 82 fix.go:56] skipping deleted file  I0420 14:10:36 82 volume_read.go:124] ==> new entry offset -1497331392 F0420 14:10:36 82 fix.go:125] scan .dat File: cannot read needle header at offset -1497331392: readat /data/documents_256.dat: negative offset goroutine 1 [running]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0x0) /Users/tochka/GolandProjects/seaweedfs/weed/glog/glog.go:767 +0x8a github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x457b640, 0x3, 0xc0005ba000, {0x36f7b94?, 0xc000921d18?}, 0x1?, 0x0) /Users/tochka/GolandProjects/seaweedfs/weed/glog/glog.go:718 +0x3ab github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x7fff30538499?, 0x2?, {0x29c1b66, 0x12}, {0xc000921d18, 0x1, 0x1}) /Users/tochka/GolandProjects/seaweedfs/weed/glog/glog.go:656 +0x110 github.com/chrislusf/seaweedfs/weed/glog.Fatalf() /Users/tochka/GolandProjects/seaweedfs/weed/glog/glog.go:1149 github.com/chrislusf/seaweedfs/weed/command.doFixOneVolume({0x7fff30538499, 0x6}, {0xc00013fac0?, 0x40?}, {0xc00013fac0, 0x12}, 0x100) /Users/tochka/GolandProjects/seaweedfs/weed/command/fix.go:125 +0x1d7 github.com/chrislusf/seaweedfs/weed/command.runFix(0x455a898?, {0xc00004c0d0?, 0x1, 0x3?}) /Users/tochka/GolandProjects/seaweedfs/weed/command/fix.go:106 +0x48d main.main() /Users/tochka/GolandProjects/seaweedfs/weed/weed.go:81 +0x383  source-file",no-bug,0.95
2541,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2541,Download from s3 is interrupted if client downloads data at low speed,"Hello, If filler and s3 are running on the same host, then the download of the file may be interrupted if the download speed of the client is very slow. (limit-rate 100K) My Test via docker I brought up the seaweed via docker-compose, I create a file and upload it, and ran curl for downloading, and it crashed again. Server: SeaweedFS Filer 30GB 2.83 Error curl: (18) transfer closed with 396369981 bytes remaining to read check.sh  #!/bin/bash DOCKER_HOST=""127.0.0.1"" FILER_URL=""http://${DOCKER_HOST}:8888"" S3_URL=""http://${DOCKER_HOST}:8333"" BUCKET=test FILE_NAME=$(date ""+%Y-%m-%d_%H-%M-%S"").bin DOWNLOAD_URL=${S3_URL}/${BUCKET}/${FILE_NAME} ERRORS=errors.log function prepareFile() { dd if=/dev/zero of=${FILE_NAME} bs=100M count=1 curl -v \ -F ""file=@${FILE_NAME}"" \ ""${FILER_URL}/buckets/${BUCKET}/"" rm ""${FILE_NAME}"" } function dl() { curl -v $DOWNLOAD_URL \ --limit-rate 100K \ --http1.0 \ --insecure \ --output /dev/null \ -H ""Connection: close"" \ -w ""%{time_total},%{size_download},%{speed_download}\n"" \ || echo ""Exit code for request $1 is $?"" >> $ERRORS } echo ""Failed requests:"" > $ERRORS prepareFile dl 1 & dl 2 & dl 3 & dl 4 & dl 5 & dl 6 & dl 7 & dl 8 & dl 9 & dl 10 & wait  docker-compose.yml  version: '2' services: master: image: chrislusf/seaweedfs # use a remote image ports: - 9333:9333 - 19333:19333 command: ""master -ip=master"" volume: image: chrislusf/seaweedfs # use a remote image ports: - 8080:8080 - 18080:18080 - 9325:9325 command: 'volume -mserver=""master:9333"" -port=8080 -metricsPort=9325' depends_on: - master filer: image: chrislusf/seaweedfs # use a remote image ports: - 8888:8888 - 18888:18888 - 9326:9326 command: 'filer -master=""master:9333"" -metricsPort=9326' tty: true stdin_open: true depends_on: - master - volume s3: image: chrislusf/seaweedfs # use a remote image ports: - 8333:8333 - 9327:9327 command: 's3 -filer=""filer:8888"" -metricsPort=9327' depends_on: - master - volume - filer  @chrislusf Please try to do similar steps on your own. Do you download a file using curl? _Originally posted by @AlekseyFicht in https://github.com/chrislusf/seaweedfs/issues/2538#issuecomment-1002071323_",source-file | source-file | source-file | source-file | source-file,"Download from s3 is interrupted if client downloads data at low speed Hello, If filler and s3 are running on the same host, then the download of the file may be interrupted if the download speed of the client is very slow. (limit-rate 100K) My Test via docker I brought up the seaweed via docker-compose, I create a file and upload it, and ran curl for downloading, and it crashed again. Server: SeaweedFS Filer 30GB 2.83 Error curl: (18) transfer closed with 396369981 bytes remaining to read check.sh  #!/bin/bash DOCKER_HOST=""127.0.0.1"" FILER_URL=""http://${DOCKER_HOST}:8888"" S3_URL=""http://${DOCKER_HOST}:8333"" BUCKET=test FILE_NAME=$(date ""+%Y-%m-%d_%H-%M-%S"").bin DOWNLOAD_URL=${S3_URL}/${BUCKET}/${FILE_NAME} ERRORS=errors.log function prepareFile() { dd if=/dev/zero of=${FILE_NAME} bs=100M count=1 curl -v \ -F ""file=@${FILE_NAME}"" \ ""${FILER_URL}/buckets/${BUCKET}/"" rm ""${FILE_NAME}"" } function dl() { curl -v $DOWNLOAD_URL \ --limit-rate 100K \ --http1.0 \ --insecure \ --output /dev/null \ -H ""Connection: close"" \ -w ""%{time_total},%{size_download},%{speed_download}\n"" \ || echo ""Exit code for request $1 is $?"" >> $ERRORS } echo ""Failed requests:"" > $ERRORS prepareFile dl 1 & dl 2 & dl 3 & dl 4 & dl 5 & dl 6 & dl 7 & dl 8 & dl 9 & dl 10 & wait  docker-compose.yml  version: '2' services: master: image: chrislusf/seaweedfs # use a remote image ports: - 9333:9333 - 19333:19333 command: ""master -ip=master"" volume: image: chrislusf/seaweedfs # use a remote image ports: - 8080:8080 - 18080:18080 - 9325:9325 command: 'volume -mserver=""master:9333"" -port=8080 -metricsPort=9325' depends_on: - master filer: image: chrislusf/seaweedfs # use a remote image ports: - 8888:8888 - 18888:18888 - 9326:9326 command: 'filer -master=""master:9333"" -metricsPort=9326' tty: true stdin_open: true depends_on: - master - volume s3: image: chrislusf/seaweedfs # use a remote image ports: - 8333:8333 - 9327:9327 command: 's3 -filer=""filer:8888"" -metricsPort=9327' depends_on: - master - volume - filer  @chrislusf Please try to do similar steps on your own. Do you download a file using curl? _Originally posted by @AlekseyFicht in https://github.com/chrislusf/seaweedfs/issues/2538#issuecomment-1002071323_ source-file source-file source-file source-file source-file",no-bug,0.8
3557,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3557,[filer] DATA RACE on uploadReaderToChunks.fileChunks,https://github.com/seaweedfs/seaweedfs/issues/3507  s3_1 |  s3_1 | WARNING: DATA RACE s3_1 | Write at 0x00c00b104288 by goroutine 11089: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:120 +0x391 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:124 +0x47 s3_1 | s3_1 | Previous read at 0x00c00b104288 by goroutine 11092: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:122 +0x3f9 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:124 +0x47 s3_1 | s3_1 | Goroutine 11089 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:102 +0xfeb s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 11092 (finished) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:102 +0xfeb s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 |  ,source-file | source-file,[filer] DATA RACE on uploadReaderToChunks.fileChunks https://github.com/seaweedfs/seaweedfs/issues/3507  s3_1 |  s3_1 | WARNING: DATA RACE s3_1 | Write at 0x00c00b104288 by goroutine 11089: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:120 +0x391 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:124 +0x47 s3_1 | s3_1 | Previous read at 0x00c00b104288 by goroutine 11092: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:122 +0x3f9 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:124 +0x47 s3_1 | s3_1 | Goroutine 11089 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:102 +0xfeb s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 11092 (finished) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:102 +0xfeb s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 |   source-file source-file,no-bug,0.8
3512,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3512,[s3] DATA RACE on upload error,"https://github.com/seaweedfs/seaweedfs/issues/3507  s3_1 |  s3_1 | WARNING: DATA RACE s3_1 | Write at 0x00c00f7b1318 by goroutine 11274: s3_1 | sync/atomic.AddInt64() s3_1 | /usr/local/go/src/runtime/race_amd64.s:289 +0xb s3_1 | sync/atomic.AddInt64() s3_1 | <autogenerated>:1 +0x1b s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:117 +0x47 s3_1 | s3_1 | Previous read at 0x00c00f7b1318 by goroutine 11219: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:67 +0x894 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 11274 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:99 +0xf9d s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 11219 (running) created at: s3_1 | net/http.(*Server).Serve() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x837 s3_1 | github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:308 +0x1b1 s3_1 |  s3_1 | E0825 10:10:38.293265 filer_server_handlers_write.go:47 failing to assign a file id: rpc error: code = Unknown desc = no free volumes left for {""collection"":""yournamehere-s76ig1ydq6z9vg3z-123"",""replication"":{},""ttl"":{""Count"":0,""Unit"":0},""preallocate"":16777216} s3_1 | E0825 10:10:38.293416 filer_server_handlers_write_upload.go:191 upload error: rpc error: code = Unknown desc = no free volumes left for {""collection"":""yournamehere-s76ig1ydq6z9vg3z-123"",""replication"":{},""ttl"":{""Count"":0,""Unit"":0},""preallocate"":16777216} s3_1 |  s3_1 | WARNING: DATA RACE s3_1 | Write at 0x00c00f5ff540 by goroutine 11277: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:109 +0x230 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:117 +0x47 s3_1 | s3_1 | Previous write at 0x00c00f5ff540 by goroutine 11274: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:109 +0x230 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:117 +0x47 s3_1 | s3_1 | Goroutine 11277 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:99 +0xf9d s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 11274 (finished) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:99 +0xf9d s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 |  s3_1 | I0825 10:10:38.294075 common.go:70 response method:PUT URL:/buckets/yournamehere-s76ig1ydq6z9vg3z-123/.uploads/4c29144909cf70f256bc53fae09a4aea53877e22/0001.part with httpStatus:500 and JSON:{""error"":""rpc error: code = Unknown desc = no free volumes left for {\""collection\"":\""yournamehere-s76ig1ydq6z9vg3z-123\"",\""replication\"":{},\""ttl\"":{\""Count\"":0,\""Unit\"":0},\""preallocate\"":16777216}""} s ",source-file,"[s3] DATA RACE on upload error https://github.com/seaweedfs/seaweedfs/issues/3507  s3_1 |  s3_1 | WARNING: DATA RACE s3_1 | Write at 0x00c00f7b1318 by goroutine 11274: s3_1 | sync/atomic.AddInt64() s3_1 | /usr/local/go/src/runtime/race_amd64.s:289 +0xb s3_1 | sync/atomic.AddInt64() s3_1 | <autogenerated>:1 +0x1b s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:117 +0x47 s3_1 | s3_1 | Previous read at 0x00c00f7b1318 by goroutine 11219: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:67 +0x894 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 11274 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:99 +0xf9d s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 11219 (running) created at: s3_1 | net/http.(*Server).Serve() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x837 s3_1 | github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:308 +0x1b1 s3_1 |  s3_1 | E0825 10:10:38.293265 filer_server_handlers_write.go:47 failing to assign a file id: rpc error: code = Unknown desc = no free volumes left for {""collection"":""yournamehere-s76ig1ydq6z9vg3z-123"",""replication"":{},""ttl"":{""Count"":0,""Unit"":0},""preallocate"":16777216} s3_1 | E0825 10:10:38.293416 filer_server_handlers_write_upload.go:191 upload error: rpc error: code = Unknown desc = no free volumes left for {""collection"":""yournamehere-s76ig1ydq6z9vg3z-123"",""replication"":{},""ttl"":{""Count"":0,""Unit"":0},""preallocate"":16777216} s3_1 |  s3_1 | WARNING: DATA RACE s3_1 | Write at 0x00c00f5ff540 by goroutine 11277: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:109 +0x230 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:117 +0x47 s3_1 | s3_1 | Previous write at 0x00c00f5ff540 by goroutine 11274: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:109 +0x230 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks.func3() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:117 +0x47 s3_1 | s3_1 | Goroutine 11277 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:99 +0xf9d s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 | s3_1 | Goroutine 11274 (finished) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).uploadReaderToChunks() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_upload.go:99 +0xf9d s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).doPutAutoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:108 +0x224 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).autoChunk() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write_autochunk.go:46 +0x31c s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).PostHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_write.go:103 +0xe6a s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:84 +0x1168 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() s3_1 | <autogenerated>:1 +0x57 s3_1 | net/http.HandlerFunc.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d s3_1 | net/http.(*ServeMux).ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 s3_1 | net/http.serverHandler.ServeHTTP() s3_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 s3_1 | net/http.(*conn).serve() s3_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 s3_1 | net/http.(*Server).Serve.func3() s3_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 s3_1 |  s3_1 | I0825 10:10:38.294075 common.go:70 response method:PUT URL:/buckets/yournamehere-s76ig1ydq6z9vg3z-123/.uploads/4c29144909cf70f256bc53fae09a4aea53877e22/0001.part with httpStatus:500 and JSON:{""error"":""rpc error: code = Unknown desc = no free volumes left for {\""collection\"":\""yournamehere-s76ig1ydq6z9vg3z-123\"",\""replication\"":{},\""ttl\"":{\""Count\"":0,\""Unit\"":0},\""preallocate\"":16777216}""} s  source-file",no-bug,0.9
1758,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1758,Feature Request: add volume.fix.replication arguments,"Hi Chris, because when running volume.fix.replication all missing volumes are been copied (multi TB operation usually) really can't run it on a cronjob, immediately as one volume server is down, we start copying all data to other volume servers can we at least add a -collection parameter so we can choose which collection MUST be always replicated, same as in volume.balance nice to have: -collectionRegEx so we can use regEx to match multiple collections. Regards.",source-file,"Feature Request: add volume.fix.replication arguments Hi Chris, because when running volume.fix.replication all missing volumes are been copied (multi TB operation usually) really can't run it on a cronjob, immediately as one volume server is down, we start copying all data to other volume servers can we at least add a -collection parameter so we can choose which collection MUST be always replicated, same as in volume.balance nice to have: -collectionRegEx so we can use regEx to match multiple collections. Regards. source-file",no-bug,0.95
318,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/318,volume replicate occasionally failed,"When I upload a lot of files(about 100-200/s), volume replicate occasionally failed. Some files lost. The bug is very dangerous.",other-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file,"volume replicate occasionally failed When I upload a lot of files(about 100-200/s), volume replicate occasionally failed. Some files lost. The bug is very dangerous. other-file other-file source-file other-file source-file source-file source-file source-file other-file source-file source-file",no-bug,0.7
841,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/841,when i create volumethere is a error,heartbeat error: fail to dial localhost:9333 : context deadline exceededthe version is 1.21. I have try in the 0.76 of version.it work well.,source-file | source-file | source-file | source-file | source-file | source-file | source-file,when i create volumethere is a error heartbeat error: fail to dial localhost:9333 : context deadline exceededthe version is 1.21. I have try in the 0.76 of version.it work well. source-file source-file source-file source-file source-file source-file source-file,no-bug,0.7
1999,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1999,[export] huge error output for non-existent volumeId,"**Screenshots** <img width=""1442"" alt=""Screenshot 2021-04-14 at 18 22 40"" src=""https://user-images.githubusercontent.com/9688322/114702666-8f2c7f00-9d4e-11eb-94e0-dccba0df3605.png"">",source-file,"[export] huge error output for non-existent volumeId **Screenshots** <img width=""1442"" alt=""Screenshot 2021-04-14 at 18 22 40"" src=""https://user-images.githubusercontent.com/9688322/114702666-8f2c7f00-9d4e-11eb-94e0-dccba0df3605.png""> source-file",bug,0.8
12,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/12,How can I append file,"I have a file has uploaded , I want to append this files content, how can do it ?",documentation-file | documentation-file | config-file | other-file | config-file | source-file | config-file | config-file | source-file | source-file | config-file | config-file | source-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file,"How can I append file I have a file has uploaded , I want to append this files content, how can do it ? documentation-file documentation-file config-file other-file config-file source-file config-file config-file source-file source-file config-file config-file source-file source-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file test-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file test-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file",no-bug,0.9
3315,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3315,"slice bounds out of range, v 3.15","Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/chrislusf/seaweedfs/discussions example of a good issue report: https://github.com/chrislusf/seaweedfs/issues/1005 example of a bad issue report: https://github.com/chrislusf/seaweedfs/issues/1008 **Describe the bug** Running 3.15, 30GB across the whole system. Running `fio --filename=/mnt/testing --rw=randrw --blocksize_range=4k-128k --runtime=60 --numjobs=4 --time_based --group_reporting --name=randrw --size=4096M` on a SeaweedFS mount causes the mount to fail with a panic: runtime error: slice bounds out of range.  I0715 00:44:12 03703 dirty_pages_chunked.go:89] /testing/testing saveToStorage 1,5b08fc55c4d0 [2172055552,2172084224) I0715 00:44:12 03703 upload_pipeline.go:166] uploaderCount 4 --> 3 I0715 00:44:12 03703 upload_pipeline.go:39] Free sealed chunk: finished uploading chunk 198 I0715 00:44:12 03703 dirty_pages_chunked.go:89] /testing/testing saveToStorage 2,5b0db0b598a0 [3604611072,3604672512) I0715 00:44:12 03703 slot_pool.go:60] --> 3 I0715 00:44:12 03703 upload_pipeline.go:166] uploaderCount 3 --> 2 I0715 00:44:12 03703 upload_pipeline.go:39] Free sealed chunk: finished uploading chunk 1718 I0715 00:44:12 03703 slot_pool.go:60] --> 4 I0715 00:44:12 03703 upload_pipeline.go:166] uploaderCount 2 --> 1 I0715 00:44:12 03703 upload_pipeline.go:39] Free sealed chunk: finished uploading chunk 1035 I0715 00:44:12 03703 slot_pool.go:60] --> 2 I0715 00:44:12 03703 slot_pool.go:60] --> 1 I0715 00:44:12 03703 slot_pool.go:49] ++> 2 I0715 00:44:12 03703 page_writer.go:54] ReadDirtyDataAt 1 [1931128832, 1931243520) I0715 00:44:12 03703 slot_pool.go:49] ++> 3 I0715 00:44:12 03703 filehandle.go:95] /testing/testing existing 2162 chunks adds 1 more I0715 00:44:12 03703 page_writer.go:54] ReadDirtyDataAt 1 [274632704, 274640896) I0715 00:44:12 03703 dirty_pages_chunked.go:89] /testing/testing saveToStorage 1,5b117c9bf387 [2696278016,2696335360) I0715 00:44:12 03703 slot_pool.go:60] --> 2 I0715 00:44:12 03703 upload_pipeline.go:166] uploaderCount 1 --> 0 I0715 00:44:12 03703 upload_pipeline.go:39] Free sealed chunk: finished uploading chunk 1285 I0715 00:44:12 03703 page_writer.go:34] 1 AddPage [2420527104, 2420637696) I0715 00:44:12 03703 dirty_pages_chunked.go:44] 1 memory AddPage [2420527104, 2420637696) I0715 00:44:12 03703 upload_pipeline.go:144] uploaderCount 0 ++> 1 I0715 00:44:12 03703 slot_pool.go:49] ++> 3 I0715 00:44:12 03703 slot_pool.go:60] --> 2 I0715 00:44:12 03703 slot_pool.go:60] --> 1 I0715 00:44:12 03703 slot_pool.go:49] ++> 2 I0715 00:44:12 03703 page_writer.go:54] ReadDirtyDataAt 1 [1739399168, 1739468800) I0715 00:44:12 03703 slot_pool.go:49] ++> 3 I0715 00:44:12 03703 filehandle.go:95] /testing/testing existing 2163 chunks adds 1 more panic: runtime error: slice bounds out of range [647168:0] goroutine 89 [running]: github.com/chrislusf/seaweedfs/weed/filer.(*SingleChunkCacher).readChunkAt(0xc00058c480, {0xc0006e6000, 0x13000, 0xe?}, 0x9e000) /github/workspace/weed/filer/reader_cache.go:197 +0x1f7 github.com/chrislusf/seaweedfs/weed/filer.(*ReaderCache).ReadChunkAt(0xc001670120, {0xc0006e6000, 0x13000, 0x13000}, {0xc00173c800, 0xe}, {0xc00171a4e0, 0x20, 0x20}, 0x0, ) /github/workspace/weed/filer/reader_cache.go:79 +0x2bb github.com/chrislusf/seaweedfs/weed/filer.(*ChunkReadAt).readChunkSliceAt(0xc001bb0730, {0xc0006e6000?, 0x1?, 0x1?}, 0xc001bae3c0, {0xc001ba5c80, 0x70, 0x270}, 0xc000692601?) /github/workspace/weed/filer/reader_at.go:174 +0xbe github.com/chrislusf/seaweedfs/weed/filer.(*ChunkReadAt).doReadAt(0xc001bb0730, {0xc0006e6000, 0x13000, 0x13000}, 0xf1e9e000) /github/workspace/weed/filer/reader_at.go:137 +0x3ca github.com/chrislusf/seaweedfs/weed/filer.(*ChunkReadAt).ReadAt(0xc000818eb8?, {0xc0006e6000?, 0x348b320?, 0x391dae0?}, 0x1661bc?) /github/workspace/weed/filer/reader_at.go:107 +0x10c github.com/chrislusf/seaweedfs/weed/mount.(*FileHandle).readFromChunks(0xc000818ea0, {0xc0006e6000, 0x13000, 0x13000}, 0xf1e9e000) /github/workspace/weed/mount/filehandle_read.go:77 +0x8e5 github.com/chrislusf/seaweedfs/weed/mount.(*WFS).Read(0x20080?, 0xc000324000?, 0xc000324198, {0xc0006e6000, 0x13000, 0x13000}) /github/workspace/weed/mount/weedfs_file_read.go:44 +0x12e github.com/hanwen/go-fuse/v2/fuse.doRead(0xc00028e000, 0xc000324000) /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/opcode.go:374 +0x83 github.com/hanwen/go-fuse/v2/fuse.(*Server).handleRequest(0xc00028e000, 0xc000324000) /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:514 +0x1f3 github.com/hanwen/go-fuse/v2/fuse.(*Server).loop(0xc00028e000, 0x0?) /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:487 +0x108 created by github.com/hanwen/go-fuse/v2/fuse.(*Server).readRequest /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:354 +0x52b  **System Setup** 3 x masters:  /usr/local/bin/weed -logtostderr master \ -ip 192.168.8.50 -ip.bind 0.0.0.0 \ -port 9333 -port.grpc 19333 \ -mdir=/var/seaweedfs/master -defaultReplication=001 \ -volumeSizeLimitMB=10000 \ -peers=192.168.8.50:9333,192.168.8.51:9333,192.168.8.52:9333  master.toml  [master.maintenance] scripts =  lock ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force ec.balance -force volume.deleteEmpty -quietFor=24h -force volume.balance -force volume.fix.replication s3.clean.uploads -timeAgo=24h unlock  sleep_minutes = 17 [master.sequencer] type = ""raft"" # Choose [raft|snowflake] type for storing the file id sequence # when sequencer.type = snowflake, the snowflake id must be different from other masters sequencer_snowflake_id = 0 # any number between 1~1023 # create this number of logical volumes if no more writable volumes # count_x means how many copies of data. # e.g.: # 000 has only one copy, copy_1 # 010 and 001 has two copies, copy_2 # 011 has only 3 copies, copy_3 [master.volume_growth] copy_1 = 2 copy_2 = 2 copy_3 = 2 copy_other = 1 [master.replication] treat_replication_as_minimums = false  3 x volume servers (Ips .50, .51, .52):  /usr/local/bin/weed -logtostderr volume \ -ip 192.168.8.50 -ip.bind 0.0.0.0 \ -port 8080 -port.grpc 18080 \ -max 0 -index leveldb \ -dir /srv/seaweedfs \ -mserver=192.168.8.50:9333,192.168.8.51:9333,192.168.8.52:9333  1 x filer:  /usr/local/bin/weed -logtostderr filer -ip 192.168.8.50 -ip.bind 0.0.0.0 -port 8888 -port.grpc 18888 -defaultReplicaPlacement=001 -encryptVolumeData -s3 -s3.port 8333 -s3.port.grpc 18333 -master=192.168.8.50:9333,192.168.8.51:9333,192.168.8.52:9333  filer.toml  [filer.options] recursive_delete = false [leveldb3] enabled = false dir = ""/var/seaweedfs/filer"" [mysql2] # or memsql, tidb enabled = true createTable =  CREATE TABLE IF NOT EXISTS `%s` ( dirhash BIGINT, name VARCHAR(1000) BINARY, directory TEXT BINARY, meta LONGBLOB, PRIMARY KEY (dirhash, name) ) DEFAULT CHARSET=utf8;  hostname = ""192.168.8.29"" port = 3306 username = ""seaweedfs"" password = ""password"" database = ""seaweedfs"" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 connection_max_lifetime_seconds = 0 interpolateParams = false # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO `%s` (dirhash,name,directory,meta) VALUES(?,?,?,?) ON DUPLICATE KEY UPDATE meta = VALUES(meta)  Mount  weed -logtostderr -v 4 mount -filer=192.168.8.50:8888,192.168.8.51:8888,192.168..52:8888 -filer.path=/testing -replication=001 -collection=testing -cacheCapacityMB=6096 -dir /mnt/  The filer is connected to a mysql 8 database, it's a clean install setup just for testing. There's no errors generated from anything other than mount. I did try swapping to leveldb3 and it behaved the same. Also checked and I have plenty of storage space. **Expected behavior** fio should run to completion. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** Add any other context about the problem here.",source-file,"slice bounds out of range, v 3.15 Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/chrislusf/seaweedfs/discussions example of a good issue report: https://github.com/chrislusf/seaweedfs/issues/1005 example of a bad issue report: https://github.com/chrislusf/seaweedfs/issues/1008 **Describe the bug** Running 3.15, 30GB across the whole system. Running `fio --filename=/mnt/testing --rw=randrw --blocksize_range=4k-128k --runtime=60 --numjobs=4 --time_based --group_reporting --name=randrw --size=4096M` on a SeaweedFS mount causes the mount to fail with a panic: runtime error: slice bounds out of range.  I0715 00:44:12 03703 dirty_pages_chunked.go:89] /testing/testing saveToStorage 1,5b08fc55c4d0 [2172055552,2172084224) I0715 00:44:12 03703 upload_pipeline.go:166] uploaderCount 4 --> 3 I0715 00:44:12 03703 upload_pipeline.go:39] Free sealed chunk: finished uploading chunk 198 I0715 00:44:12 03703 dirty_pages_chunked.go:89] /testing/testing saveToStorage 2,5b0db0b598a0 [3604611072,3604672512) I0715 00:44:12 03703 slot_pool.go:60] --> 3 I0715 00:44:12 03703 upload_pipeline.go:166] uploaderCount 3 --> 2 I0715 00:44:12 03703 upload_pipeline.go:39] Free sealed chunk: finished uploading chunk 1718 I0715 00:44:12 03703 slot_pool.go:60] --> 4 I0715 00:44:12 03703 upload_pipeline.go:166] uploaderCount 2 --> 1 I0715 00:44:12 03703 upload_pipeline.go:39] Free sealed chunk: finished uploading chunk 1035 I0715 00:44:12 03703 slot_pool.go:60] --> 2 I0715 00:44:12 03703 slot_pool.go:60] --> 1 I0715 00:44:12 03703 slot_pool.go:49] ++> 2 I0715 00:44:12 03703 page_writer.go:54] ReadDirtyDataAt 1 [1931128832, 1931243520) I0715 00:44:12 03703 slot_pool.go:49] ++> 3 I0715 00:44:12 03703 filehandle.go:95] /testing/testing existing 2162 chunks adds 1 more I0715 00:44:12 03703 page_writer.go:54] ReadDirtyDataAt 1 [274632704, 274640896) I0715 00:44:12 03703 dirty_pages_chunked.go:89] /testing/testing saveToStorage 1,5b117c9bf387 [2696278016,2696335360) I0715 00:44:12 03703 slot_pool.go:60] --> 2 I0715 00:44:12 03703 upload_pipeline.go:166] uploaderCount 1 --> 0 I0715 00:44:12 03703 upload_pipeline.go:39] Free sealed chunk: finished uploading chunk 1285 I0715 00:44:12 03703 page_writer.go:34] 1 AddPage [2420527104, 2420637696) I0715 00:44:12 03703 dirty_pages_chunked.go:44] 1 memory AddPage [2420527104, 2420637696) I0715 00:44:12 03703 upload_pipeline.go:144] uploaderCount 0 ++> 1 I0715 00:44:12 03703 slot_pool.go:49] ++> 3 I0715 00:44:12 03703 slot_pool.go:60] --> 2 I0715 00:44:12 03703 slot_pool.go:60] --> 1 I0715 00:44:12 03703 slot_pool.go:49] ++> 2 I0715 00:44:12 03703 page_writer.go:54] ReadDirtyDataAt 1 [1739399168, 1739468800) I0715 00:44:12 03703 slot_pool.go:49] ++> 3 I0715 00:44:12 03703 filehandle.go:95] /testing/testing existing 2163 chunks adds 1 more panic: runtime error: slice bounds out of range [647168:0] goroutine 89 [running]: github.com/chrislusf/seaweedfs/weed/filer.(*SingleChunkCacher).readChunkAt(0xc00058c480, {0xc0006e6000, 0x13000, 0xe?}, 0x9e000) /github/workspace/weed/filer/reader_cache.go:197 +0x1f7 github.com/chrislusf/seaweedfs/weed/filer.(*ReaderCache).ReadChunkAt(0xc001670120, {0xc0006e6000, 0x13000, 0x13000}, {0xc00173c800, 0xe}, {0xc00171a4e0, 0x20, 0x20}, 0x0, ) /github/workspace/weed/filer/reader_cache.go:79 +0x2bb github.com/chrislusf/seaweedfs/weed/filer.(*ChunkReadAt).readChunkSliceAt(0xc001bb0730, {0xc0006e6000?, 0x1?, 0x1?}, 0xc001bae3c0, {0xc001ba5c80, 0x70, 0x270}, 0xc000692601?) /github/workspace/weed/filer/reader_at.go:174 +0xbe github.com/chrislusf/seaweedfs/weed/filer.(*ChunkReadAt).doReadAt(0xc001bb0730, {0xc0006e6000, 0x13000, 0x13000}, 0xf1e9e000) /github/workspace/weed/filer/reader_at.go:137 +0x3ca github.com/chrislusf/seaweedfs/weed/filer.(*ChunkReadAt).ReadAt(0xc000818eb8?, {0xc0006e6000?, 0x348b320?, 0x391dae0?}, 0x1661bc?) /github/workspace/weed/filer/reader_at.go:107 +0x10c github.com/chrislusf/seaweedfs/weed/mount.(*FileHandle).readFromChunks(0xc000818ea0, {0xc0006e6000, 0x13000, 0x13000}, 0xf1e9e000) /github/workspace/weed/mount/filehandle_read.go:77 +0x8e5 github.com/chrislusf/seaweedfs/weed/mount.(*WFS).Read(0x20080?, 0xc000324000?, 0xc000324198, {0xc0006e6000, 0x13000, 0x13000}) /github/workspace/weed/mount/weedfs_file_read.go:44 +0x12e github.com/hanwen/go-fuse/v2/fuse.doRead(0xc00028e000, 0xc000324000) /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/opcode.go:374 +0x83 github.com/hanwen/go-fuse/v2/fuse.(*Server).handleRequest(0xc00028e000, 0xc000324000) /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:514 +0x1f3 github.com/hanwen/go-fuse/v2/fuse.(*Server).loop(0xc00028e000, 0x0?) /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:487 +0x108 created by github.com/hanwen/go-fuse/v2/fuse.(*Server).readRequest /go/pkg/mod/github.com/hanwen/go-fuse/v2@v2.1.1-0.20220627082937-d01fda7edf17/fuse/server.go:354 +0x52b  **System Setup** 3 x masters:  /usr/local/bin/weed -logtostderr master \ -ip 192.168.8.50 -ip.bind 0.0.0.0 \ -port 9333 -port.grpc 19333 \ -mdir=/var/seaweedfs/master -defaultReplication=001 \ -volumeSizeLimitMB=10000 \ -peers=192.168.8.50:9333,192.168.8.51:9333,192.168.8.52:9333  master.toml  [master.maintenance] scripts =  lock ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force ec.balance -force volume.deleteEmpty -quietFor=24h -force volume.balance -force volume.fix.replication s3.clean.uploads -timeAgo=24h unlock  sleep_minutes = 17 [master.sequencer] type = ""raft"" # Choose [raft|snowflake] type for storing the file id sequence # when sequencer.type = snowflake, the snowflake id must be different from other masters sequencer_snowflake_id = 0 # any number between 1~1023 # create this number of logical volumes if no more writable volumes # count_x means how many copies of data. # e.g.: # 000 has only one copy, copy_1 # 010 and 001 has two copies, copy_2 # 011 has only 3 copies, copy_3 [master.volume_growth] copy_1 = 2 copy_2 = 2 copy_3 = 2 copy_other = 1 [master.replication] treat_replication_as_minimums = false  3 x volume servers (Ips .50, .51, .52):  /usr/local/bin/weed -logtostderr volume \ -ip 192.168.8.50 -ip.bind 0.0.0.0 \ -port 8080 -port.grpc 18080 \ -max 0 -index leveldb \ -dir /srv/seaweedfs \ -mserver=192.168.8.50:9333,192.168.8.51:9333,192.168.8.52:9333  1 x filer:  /usr/local/bin/weed -logtostderr filer -ip 192.168.8.50 -ip.bind 0.0.0.0 -port 8888 -port.grpc 18888 -defaultReplicaPlacement=001 -encryptVolumeData -s3 -s3.port 8333 -s3.port.grpc 18333 -master=192.168.8.50:9333,192.168.8.51:9333,192.168.8.52:9333  filer.toml  [filer.options] recursive_delete = false [leveldb3] enabled = false dir = ""/var/seaweedfs/filer"" [mysql2] # or memsql, tidb enabled = true createTable =  CREATE TABLE IF NOT EXISTS `%s` ( dirhash BIGINT, name VARCHAR(1000) BINARY, directory TEXT BINARY, meta LONGBLOB, PRIMARY KEY (dirhash, name) ) DEFAULT CHARSET=utf8;  hostname = ""192.168.8.29"" port = 3306 username = ""seaweedfs"" password = ""password"" database = ""seaweedfs"" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 connection_max_lifetime_seconds = 0 interpolateParams = false # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO `%s` (dirhash,name,directory,meta) VALUES(?,?,?,?) ON DUPLICATE KEY UPDATE meta = VALUES(meta)  Mount  weed -logtostderr -v 4 mount -filer=192.168.8.50:8888,192.168.8.51:8888,192.168..52:8888 -filer.path=/testing -replication=001 -collection=testing -cacheCapacityMB=6096 -dir /mnt/  The filer is connected to a mysql 8 database, it's a clean install setup just for testing. There's no errors generated from anything other than mount. I did try swapping to leveldb3 and it behaved the same. Also checked and I have plenty of storage space. **Expected behavior** fio should run to completion. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** Add any other context about the problem here. source-file",no-bug,0.9
535,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/535,Failed to write with error,"when I use ./weed benchmark -collection=""benchmark"" -c=20 -size=150000 -n=10000 -server=""node74:9333"" there are some error (eg Failed to write with error:Failed to write to local disk (Volume Size Limit 104857600000 Exceeded! Current size is 34359748705) Mycluster has 5 master and 15 volume about 5 nodes",source-file | source-file | source-file | source-file,"Failed to write with error when I use ./weed benchmark -collection=""benchmark"" -c=20 -size=150000 -n=10000 -server=""node74:9333"" there are some error (eg Failed to write with error:Failed to write to local disk (Volume Size Limit 104857600000 Exceeded! Current size is 34359748705) Mycluster has 5 master and 15 volume about 5 nodes source-file source-file source-file source-file",no-bug,0.9
1765,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1765,[weed mount] Cannot perceive write failure when no writable volume,"**Describe the bug** when there is no writable volume server, copy file to file system mounted by `weed mount`, no error message output below the copy command, file's metadata is written to filer store. This misled users and made they think that the copy command works. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # setup root@dev-4:~/swfs# weed master -port=9333 -mdir=/tmp/master root@dev-4:~/swfs# weed volume -port=8080 -dir=/tmp/volume -max=3 -ip=127.0.0.1 -mserver=127.0.0.1:9333 root@dev-4:~/swfs# weed filer -port=8888 -ip=127.0.0.1 -master=127.0.0.1:9333 root@dev-4:~/swfs# weed mount -filer=127.0.0.1:8888 -cacheDir=/tmp/cache001 -dir=./mnt # shut down volume server use `ctrl + C` # copy a directory to ./mnt root@dev-4:~/swfs/mnt# cp -r /root/mydir ./  - OS version `Ubuntu 18.04.4 LTS` - output of `weed version` `version 30GB 2.13 0e99531 linux amd64` - if using filer, show the content of `filer.toml` `default` **Expected behavior** output error message & no metadata is written to filer store **Screenshots** ![image](https://user-images.githubusercontent.com/28077875/106119887-ab2d7500-6190-11eb-9876-044f87a21192.png) ![image](https://user-images.githubusercontent.com/28077875/106119668-6acdf700-6190-11eb-816d-715059ae1c48.png) **Additional context** Actually i deploy 1 master  1filer 3 volume server in k8sand replication is `002`. After shutting down a volume server, copy a directory containing some files and subdirectories to seaweed file system mounted by `weed mount`can not work because there are only two online volume servers). There are some error messages below the copy command:  cp: failed to close './gemini-deploy/deployments/.git/FETCH_HEAD': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/pack/pack-9478e6d33308f94e72fd38dd453797ccd336e19c.pack': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/87/ecbacadd04041fcacae06b9c046a9fb38e1642': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/1f/5581bebc24038154af768df5a1265cf68a22c1': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/8a/b97b4f4bfe39da43799ff2481194ca6a670a81': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/5f/13ade836541df7aca38e9e124ea50e8c3e2496': Input/output error  But not every file has an error message.",source-file | source-file,"[weed mount] Cannot perceive write failure when no writable volume **Describe the bug** when there is no writable volume server, copy file to file system mounted by `weed mount`, no error message output below the copy command, file's metadata is written to filer store. This misled users and made they think that the copy command works. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # setup root@dev-4:~/swfs# weed master -port=9333 -mdir=/tmp/master root@dev-4:~/swfs# weed volume -port=8080 -dir=/tmp/volume -max=3 -ip=127.0.0.1 -mserver=127.0.0.1:9333 root@dev-4:~/swfs# weed filer -port=8888 -ip=127.0.0.1 -master=127.0.0.1:9333 root@dev-4:~/swfs# weed mount -filer=127.0.0.1:8888 -cacheDir=/tmp/cache001 -dir=./mnt # shut down volume server use `ctrl + C` # copy a directory to ./mnt root@dev-4:~/swfs/mnt# cp -r /root/mydir ./  - OS version `Ubuntu 18.04.4 LTS` - output of `weed version` `version 30GB 2.13 0e99531 linux amd64` - if using filer, show the content of `filer.toml` `default` **Expected behavior** output error message & no metadata is written to filer store **Screenshots** ![image](https://user-images.githubusercontent.com/28077875/106119887-ab2d7500-6190-11eb-9876-044f87a21192.png) ![image](https://user-images.githubusercontent.com/28077875/106119668-6acdf700-6190-11eb-816d-715059ae1c48.png) **Additional context** Actually i deploy 1 master  1filer 3 volume server in k8sand replication is `002`. After shutting down a volume server, copy a directory containing some files and subdirectories to seaweed file system mounted by `weed mount`can not work because there are only two online volume servers). There are some error messages below the copy command:  cp: failed to close './gemini-deploy/deployments/.git/FETCH_HEAD': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/pack/pack-9478e6d33308f94e72fd38dd453797ccd336e19c.pack': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/87/ecbacadd04041fcacae06b9c046a9fb38e1642': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/1f/5581bebc24038154af768df5a1265cf68a22c1': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/8a/b97b4f4bfe39da43799ff2481194ca6a670a81': Input/output error cp: failed to close './gemini-deploy/deployments/.git/objects/5f/13ade836541df7aca38e9e124ea50e8c3e2496': Input/output error  But not every file has an error message. source-file source-file",no-bug,0.8
549,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/549,"weed upload not support flag ""server"" but the doc show wrong example.","It looks command ""weed upload"" not support flag -server any more, but the doc for this command still show an example ""weed upload -server=localhost:9333 -dir=one_directory -include=*.pdf"". Because we use a earlier version of seaweedfs, and we use '-server' frequent, hope there still support '-server' or at least keep the right doc . Thanks for the awesome seaweedfs",source-file,"weed upload not support flag ""server"" but the doc show wrong example. It looks command ""weed upload"" not support flag -server any more, but the doc for this command still show an example ""weed upload -server=localhost:9333 -dir=one_directory -include=*.pdf"". Because we use a earlier version of seaweedfs, and we use '-server' frequent, hope there still support '-server' or at least keep the right doc . Thanks for the awesome seaweedfs source-file",no-bug,0.9
4194,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4194,[filer.remote.sync] Transport connection broken error,"**Describe the bug** Running `filer.remote.sync` returns an error and does not copy file to the remote (Azure Storage) **System Setup**  > lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.5 LTS Release: 20.04 Codename: focal   > weed version version 30GB 3.42 8821d6b1619b7a55b515a98391193297e77cbe52 linux amd64   # Weed server /usr/local/bin/weed server -volume.max=16 -s3 # Adding and mounting the remote echo ""remote.configure -name=azure -type=azure -azure.account_name=seaweedsa -azure.account_key=rwexf8Tt4ss9MQ=="" | weed shell echo ""remote.mount -remote=azure/seaweed -dir=/buckets/seaweed"" | weed shell # Weed filer.remote.sync, in a separate cmd tab /usr/local/bin/weed filer.remote.sync -dir=/buckets/seaweed  **Expected behavior** Running a simple weed server, with a remote pointing to Azure Storage, and running a filer.remote.sync. Uploading a file to Filer UI (http://localhost:8888/buckets/seaweed) uploads the filer to Filer, but its not being copied to remote **Screenshots** filer.remote.sync logs:  Put ""https://seaweedsa.blob.core.windows.net/seaweed/13-53.36204a77?timeout=61"": net/http: HTTP/1.x transport connection broken: http: ContentLength=704 with Body length 0 I0209 10:22:04.822710 filer_remote_sync_dir.go:193 create azure/seaweed/13-53.36204a77 I0209 10:22:51.855969 retry.go:25 retry writeFile: err: azure upload to seaweed/13-53.36204a77: -> github.com/Azure/azure-pipeline-go/pipeline.NewError, /go/pkg/mod/github.com/!azure/azure-pipeline-go@v0.2.3/pipeline/error.go:157 HTTP request failed  Referencing a similar ticket here https://github.com/seaweedfs/seaweedfs/issues/4180",source-file,"[filer.remote.sync] Transport connection broken error **Describe the bug** Running `filer.remote.sync` returns an error and does not copy file to the remote (Azure Storage) **System Setup**  > lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.5 LTS Release: 20.04 Codename: focal   > weed version version 30GB 3.42 8821d6b1619b7a55b515a98391193297e77cbe52 linux amd64   # Weed server /usr/local/bin/weed server -volume.max=16 -s3 # Adding and mounting the remote echo ""remote.configure -name=azure -type=azure -azure.account_name=seaweedsa -azure.account_key=rwexf8Tt4ss9MQ=="" | weed shell echo ""remote.mount -remote=azure/seaweed -dir=/buckets/seaweed"" | weed shell # Weed filer.remote.sync, in a separate cmd tab /usr/local/bin/weed filer.remote.sync -dir=/buckets/seaweed  **Expected behavior** Running a simple weed server, with a remote pointing to Azure Storage, and running a filer.remote.sync. Uploading a file to Filer UI (http://localhost:8888/buckets/seaweed) uploads the filer to Filer, but its not being copied to remote **Screenshots** filer.remote.sync logs:  Put ""https://seaweedsa.blob.core.windows.net/seaweed/13-53.36204a77?timeout=61"": net/http: HTTP/1.x transport connection broken: http: ContentLength=704 with Body length 0 I0209 10:22:04.822710 filer_remote_sync_dir.go:193 create azure/seaweed/13-53.36204a77 I0209 10:22:51.855969 retry.go:25 retry writeFile: err: azure upload to seaweed/13-53.36204a77: -> github.com/Azure/azure-pipeline-go/pipeline.NewError, /go/pkg/mod/github.com/!azure/azure-pipeline-go@v0.2.3/pipeline/error.go:157 HTTP request failed  Referencing a similar ticket here https://github.com/seaweedfs/seaweedfs/issues/4180 source-file",no-bug,0.9
9,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/9,Public port & url,"Use case: I have a weed servers:  s1.hostname.com:8080 s2.hostname.com:8080  I can place them behind reverse-proxy (nginx), and they will be accessible as  hostname.com/media/s1/:80 hostname.com/media/s2/:80  or even  hostname.com/media:80  or even  hostname.com/media:443  Which is  http://hostname.com/media https://hostname.com/media  In case of 100 replication enabled on master server. Now i can achieve this only with manual rewrite rules for s1 and s2. It could be like  weed volume -port 8080 -publicPort 80 -publicPort 443 -publicURL ""hostname.com/media""  Or something like this",source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | documentation-file | source-file,"Public port & url Use case: I have a weed servers:  s1.hostname.com:8080 s2.hostname.com:8080  I can place them behind reverse-proxy (nginx), and they will be accessible as  hostname.com/media/s1/:80 hostname.com/media/s2/:80  or even  hostname.com/media:80  or even  hostname.com/media:443  Which is  http://hostname.com/media https://hostname.com/media  In case of 100 replication enabled on master server. Now i can achieve this only with manual rewrite rules for s1 and s2. It could be like  weed volume -port 8080 -publicPort 80 -publicPort 443 -publicURL ""hostname.com/media""  Or something like this source-file source-file source-file source-file source-file source-file documentation-file documentation-file source-file",no-bug,0.9
804,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/804,"Benchmark  ""compression"" aspect unclear.","**Describe the bug (feature?)** When running a benchmark (weed 1.15) the storage result is clearly ""compressed"" data. But the documentation claims:  [root@korora-01 v_1_15]# ./weed help benchmark Usage: weed benchmark -server=localhost:9333 -c=10 -n=100000 benchmark on an empty SeaweedFS file system. Two tests during benchmark: 1) write lots of small files to the system 2) read the files out The file content is mostly zero, but no compression is done. ..  So either - the code is not creating ""uncompressible"" data - the help text is ambiguous about the meaning of ""no compression is done"". **System Setup** I start a master:  ./weed master -volumeSizeLimitMB=10 -defaultReplication=000 -ip 192.168.1.31 -mdir /var/zones/seaweed-m01/data  a volume  ./weed volume -mserver=192.168.1.31:9333 -max=150 -port=8080 -dataCenter=dc1 -rack=rackA -ip 192.168.1.31 -dir /var/zones/seaweed-v01/data  and then run the benchmark  ./weed benchmark -master=""192.168.1.31:9333"" -c=16 -size=1024000 -n=10000  Which runs as expected. **Expected behavior** If I want to benchmark the system read/write IO performance I want to have ""no compression is done"" feature .. otherwise I would be testing the CPUs compression/decompression speed. With the above settings I would expect  10000 * 1 MB = 10 GB of data in the storage. But I see:  [root@korora-01 data]# ls -la total 10720 drwxr-xr-x. 2 root root 4096 Dec 27 17:24 . drwxr-xr-x. 3 root root 18 Dec 21 01:03 .. -rw-r--r--. 1 root root 1545048 Dec 27 17:26 benchmark_1.dat -rw-r--r--. 1 root root 22912 Dec 27 17:26 benchmark_1.idx -rw-r--r--. 1 root root 1521288 Dec 27 17:26 benchmark_2.dat -rw-r--r--. 1 root root 22560 Dec 27 17:26 benchmark_2.idx -rw-r--r--. 1 root root 1493424 Dec 27 17:26 benchmark_3.dat -rw-r--r--. 1 root root 22144 Dec 27 17:26 benchmark_3.idx -rw-r--r--. 1 root root 1600376 Dec 27 17:26 benchmark_4.dat -rw-r--r--. 1 root root 23728 Dec 27 17:26 benchmark_4.idx -rw-r--r--. 1 root root 1559296 Dec 27 17:26 benchmark_5.dat -rw-r--r--. 1 root root 23120 Dec 27 17:26 benchmark_5.idx -rw-r--r--. 1 root root 1503064 Dec 27 17:26 benchmark_6.dat -rw-r--r--. 1 root root 22288 Dec 27 17:26 benchmark_6.idx -rw-r--r--. 1 root root 1567888 Dec 27 17:26 benchmark_7.dat -rw-r--r--. 1 root root 23248 Dec 27 17:26 benchmark_7.idx [root@korora-01 data]# du -sk . 10720 .  only about 10 MB of stored data. Since all 10000 files have been written (according to the ID log file) the files are compressed .. which can be confirmed by checking the data:  [root@korora-01 v_1_15]# ./weed export -limit 10 -dir /var/zones/seaweed-v01/data -volumeId 1 -collection benchmark key name size gzip mime modified ttl deleted 1,0f2f6dae19 . 1031 true 2018-12-27T17:24:56 false 1,19196d8240 . 1031 true 2018-12-27T17:24:56 false 1,2a375165dd . 1031 true 2018-12-27T17:24:56 false 1,23806f4708 . 1031 true 2018-12-27T17:24:56 false 1,2d37824cd4 . 1031 true 2018-12-27T17:24:56 false 1,386297bd30 . 1029 true 2018-12-27T17:24:56 false ..  **Additional context** Perhaps it makes sense to allow both options for the benchmark  compressed and uncompressed storage  in order to allow testing both behaviors. But if CPU compression should be the test target then the test data needs to represent the ""final"" test data way better than ""all zero"" or ""all random"". So in the current form it seems to me more plausible to have ""no compression is done"" apply to the volume servers storage behavior. I would assume that this should be achievable if the data uploaded was marked as ""gzip"" content.",source-file,"Benchmark  ""compression"" aspect unclear. **Describe the bug (feature?)** When running a benchmark (weed 1.15) the storage result is clearly ""compressed"" data. But the documentation claims:  [root@korora-01 v_1_15]# ./weed help benchmark Usage: weed benchmark -server=localhost:9333 -c=10 -n=100000 benchmark on an empty SeaweedFS file system. Two tests during benchmark: 1) write lots of small files to the system 2) read the files out The file content is mostly zero, but no compression is done. ..  So either - the code is not creating ""uncompressible"" data - the help text is ambiguous about the meaning of ""no compression is done"". **System Setup** I start a master:  ./weed master -volumeSizeLimitMB=10 -defaultReplication=000 -ip 192.168.1.31 -mdir /var/zones/seaweed-m01/data  a volume  ./weed volume -mserver=192.168.1.31:9333 -max=150 -port=8080 -dataCenter=dc1 -rack=rackA -ip 192.168.1.31 -dir /var/zones/seaweed-v01/data  and then run the benchmark  ./weed benchmark -master=""192.168.1.31:9333"" -c=16 -size=1024000 -n=10000  Which runs as expected. **Expected behavior** If I want to benchmark the system read/write IO performance I want to have ""no compression is done"" feature .. otherwise I would be testing the CPUs compression/decompression speed. With the above settings I would expect  10000 * 1 MB = 10 GB of data in the storage. But I see:  [root@korora-01 data]# ls -la total 10720 drwxr-xr-x. 2 root root 4096 Dec 27 17:24 . drwxr-xr-x. 3 root root 18 Dec 21 01:03 .. -rw-r--r--. 1 root root 1545048 Dec 27 17:26 benchmark_1.dat -rw-r--r--. 1 root root 22912 Dec 27 17:26 benchmark_1.idx -rw-r--r--. 1 root root 1521288 Dec 27 17:26 benchmark_2.dat -rw-r--r--. 1 root root 22560 Dec 27 17:26 benchmark_2.idx -rw-r--r--. 1 root root 1493424 Dec 27 17:26 benchmark_3.dat -rw-r--r--. 1 root root 22144 Dec 27 17:26 benchmark_3.idx -rw-r--r--. 1 root root 1600376 Dec 27 17:26 benchmark_4.dat -rw-r--r--. 1 root root 23728 Dec 27 17:26 benchmark_4.idx -rw-r--r--. 1 root root 1559296 Dec 27 17:26 benchmark_5.dat -rw-r--r--. 1 root root 23120 Dec 27 17:26 benchmark_5.idx -rw-r--r--. 1 root root 1503064 Dec 27 17:26 benchmark_6.dat -rw-r--r--. 1 root root 22288 Dec 27 17:26 benchmark_6.idx -rw-r--r--. 1 root root 1567888 Dec 27 17:26 benchmark_7.dat -rw-r--r--. 1 root root 23248 Dec 27 17:26 benchmark_7.idx [root@korora-01 data]# du -sk . 10720 .  only about 10 MB of stored data. Since all 10000 files have been written (according to the ID log file) the files are compressed .. which can be confirmed by checking the data:  [root@korora-01 v_1_15]# ./weed export -limit 10 -dir /var/zones/seaweed-v01/data -volumeId 1 -collection benchmark key name size gzip mime modified ttl deleted 1,0f2f6dae19 . 1031 true 2018-12-27T17:24:56 false 1,19196d8240 . 1031 true 2018-12-27T17:24:56 false 1,2a375165dd . 1031 true 2018-12-27T17:24:56 false 1,23806f4708 . 1031 true 2018-12-27T17:24:56 false 1,2d37824cd4 . 1031 true 2018-12-27T17:24:56 false 1,386297bd30 . 1029 true 2018-12-27T17:24:56 false ..  **Additional context** Perhaps it makes sense to allow both options for the benchmark  compressed and uncompressed storage  in order to allow testing both behaviors. But if CPU compression should be the test target then the test data needs to represent the ""final"" test data way better than ""all zero"" or ""all random"". So in the current form it seems to me more plausible to have ""no compression is done"" apply to the volume servers storage behavior. I would assume that this should be achievable if the data uploaded was marked as ""gzip"" content. source-file",no-bug,0.9
499,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/499,lost volume server always after Volume xyz becomes unwritable,"Hi We're seeing very frequest volume server disconnects. I've tried running the master with different pulseSeconds. The latest attempt was master with pulseSeconds=60 and volumes with pulseSeconds=1 ( based on https://github.com/chrislusf/seaweedfs/issues/408 ) As far as I can tell it always happens after volumes become unwritable: I0523 20:52:43 12295 volume_layout.go:203] Volume 188233 becomes unwritable I0523 20:52:43 12295 volume_layout.go:203] Volume 188232 becomes unwritable I0523 20:52:43 12295 volume_layout.go:203] Volume 188234 becomes unwritable I0523 20:52:43 12295 volume_layout.go:203] Volume 188235 becomes unwritable I0523 20:52:43 12295 volume_layout.go:203] Volume 188236 becomes unwritable I0523 20:52:44 12295 master_grpc_server.go:63] lost volume server 10.1.14.22:8082 I0523 20:52:44 12295 topology_event_handling.go:52] Removing Volume 1241 from the dead volume server 10.1.14.22:8082 I0523 20:52:44 12295 volume_layout.go:227] Volume 1241 has 0 replica, less than required 2 I0523 20:52:44 12295 topology_event_handling.go:52] Removing Volume 1541 from the dead volume server 10.1.14.22:8082 I0523 20:52:44 12295 volume_layout.go:227] Volume 1541 has 1 replica, less than required 2 . . I0523 20:53:59 12295 node.go:237] topo:DefaultDataCenter:DefaultRack removes 10.1.14.22:8082 . . I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188240 on 10.1.14.27:8080 I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188241 on topo:DefaultDataCenter:DefaultRack:10.1.14.24:8081 I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188241 on topo:DefaultDataCenter:DefaultRack:10.1.14.23:8081 I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188242 on topo:DefaultDataCenter:DefaultRack:10.1.14.23:8083 I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188242 on topo:DefaultDataCenter:DefaultRack:10.1.14.27:8083 I0523 20:54:00 12295 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 10.1.14.22:8082 I0523 20:54:00 12295 master_grpc_server.go:36] added volume server 10.1.14.22:8082 I0523 20:54:00 12295 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 10.1.14.24:8083 I0523 20:54:00 12295 master_grpc_server.go:36] added volume server 10.1.14.24:8083 I0523 20:54:00 12295 volume_layout.go:203] Volume 187989 becomes unwritable I0523 20:54:00 12295 volume_layout.go:203] Volume 187519 becomes unwritable I0523 20:54:01 12295 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 10.1.14.27:8080 I0523 20:54:01 12295 master_grpc_server.go:36] added volume server 10.1.14.27:8080",source-file,"lost volume server always after Volume xyz becomes unwritable Hi We're seeing very frequest volume server disconnects. I've tried running the master with different pulseSeconds. The latest attempt was master with pulseSeconds=60 and volumes with pulseSeconds=1 ( based on https://github.com/chrislusf/seaweedfs/issues/408 ) As far as I can tell it always happens after volumes become unwritable: I0523 20:52:43 12295 volume_layout.go:203] Volume 188233 becomes unwritable I0523 20:52:43 12295 volume_layout.go:203] Volume 188232 becomes unwritable I0523 20:52:43 12295 volume_layout.go:203] Volume 188234 becomes unwritable I0523 20:52:43 12295 volume_layout.go:203] Volume 188235 becomes unwritable I0523 20:52:43 12295 volume_layout.go:203] Volume 188236 becomes unwritable I0523 20:52:44 12295 master_grpc_server.go:63] lost volume server 10.1.14.22:8082 I0523 20:52:44 12295 topology_event_handling.go:52] Removing Volume 1241 from the dead volume server 10.1.14.22:8082 I0523 20:52:44 12295 volume_layout.go:227] Volume 1241 has 0 replica, less than required 2 I0523 20:52:44 12295 topology_event_handling.go:52] Removing Volume 1541 from the dead volume server 10.1.14.22:8082 I0523 20:52:44 12295 volume_layout.go:227] Volume 1541 has 1 replica, less than required 2 . . I0523 20:53:59 12295 node.go:237] topo:DefaultDataCenter:DefaultRack removes 10.1.14.22:8082 . . I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188240 on 10.1.14.27:8080 I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188241 on topo:DefaultDataCenter:DefaultRack:10.1.14.24:8081 I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188241 on topo:DefaultDataCenter:DefaultRack:10.1.14.23:8081 I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188242 on topo:DefaultDataCenter:DefaultRack:10.1.14.23:8083 I0523 20:54:00 12295 volume_growth.go:205] Created Volume 188242 on topo:DefaultDataCenter:DefaultRack:10.1.14.27:8083 I0523 20:54:00 12295 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 10.1.14.22:8082 I0523 20:54:00 12295 master_grpc_server.go:36] added volume server 10.1.14.22:8082 I0523 20:54:00 12295 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 10.1.14.24:8083 I0523 20:54:00 12295 master_grpc_server.go:36] added volume server 10.1.14.24:8083 I0523 20:54:00 12295 volume_layout.go:203] Volume 187989 becomes unwritable I0523 20:54:00 12295 volume_layout.go:203] Volume 187519 becomes unwritable I0523 20:54:01 12295 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 10.1.14.27:8080 I0523 20:54:01 12295 master_grpc_server.go:36] added volume server 10.1.14.27:8080 source-file",no-bug,0.9
4074,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4074,S3 Gateway fails to start when installed via Helm,**Describe the bug** Installing Seaweed on Kubernetes using Helm chart fails to start the S3 Gateway. This is because the S3 gateway command is binding to localhost when it should be listening on all interfaces. **System Setup** Installing from latest master (at time of this issue) version of charts using a k3s cluster (v1.26.0+k3s1). **Expected Behaviour** S3 Gateway should start and be accessible from other pods either via Service or directly hitting the Pod.,documentation-file | documentation-file | documentation-file | documentation-file,S3 Gateway fails to start when installed via Helm **Describe the bug** Installing Seaweed on Kubernetes using Helm chart fails to start the S3 Gateway. This is because the S3 gateway command is binding to localhost when it should be listening on all interfaces. **System Setup** Installing from latest master (at time of this issue) version of charts using a k3s cluster (v1.26.0+k3s1). **Expected Behaviour** S3 Gateway should start and be accessible from other pods either via Service or directly hitting the Pod. documentation-file documentation-file documentation-file documentation-file,no-bug,0.9
1810,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1810,s3-tests include in the docker compose file,"https://github.com/splunk/s3-tests `S3TEST_CONF=s3tests.conf venv/bin/nosetests --verbose --logging-level=ERROR --with-xunit --failure-detail s3tests_boto3.functional.test_s3 -a '!tagging,!fails_on_aws,!encryption,!bucket-policy,!versioning,!fails_on_rgw,!bucket-policy,!fails_with_subdomain,!policy_status,!object-lock,!lifecycle,!cors,!user-policy' -e '(bucket_list_delimiter_basic|bucket_listv2_delimiter_basic|bucket_listv2_encoding_basic|bucket_list_encoding_basic|bucket_list_delimiter_prefix|bucket_listv2_delimiter_prefix_ends_with_delimiter|bucket_list_delimiter_prefix_ends_with_delimiter|bucket_list_delimiter_alt|bucket_listv2_delimiter_alt|bucket_list_delimiter_prefix_underscore|bucket_list_delimiter_percentage|bucket_listv2_delimiter_percentage|bucket_list_delimiter_whitespace|bucket_listv2_delimiter_whitespace|bucket_list_delimiter_dot|bucket_listv2_delimiter_dot|bucket_list_delimiter_unreadable|bucket_listv2_delimiter_unreadable|bucket_listv2_fetchowner_defaultempty|bucket_listv2_fetchowner_empty|bucket_list_delimiter_not_skip_special|bucket_list_prefix_delimiter_alt|bucket_listv2_prefix_delimiter_alt|bucket_list_prefix_delimiter_prefix_not_exist|bucket_listv2_prefix_delimiter_prefix_not_exist|bucket_list_prefix_delimiter_delimiter_not_exist|bucket_listv2_prefix_delimiter_delimiter_not_exist|bucket_list_prefix_delimiter_prefix_delimiter_not_exist|bucket_listv2_prefix_delimiter_prefix_delimiter_not_exist|bucket_list_maxkeys_none|bucket_listv2_maxkeys_none|bucket_list_maxkeys_invalid|bucket_listv2_continuationtoken_empty|bucket_list_return_data|bucket_list_objects_anonymous|bucket_listv2_objects_anonymous|bucket_notexist|bucketv2_notexist|bucket_delete_nonempty|bucket_concurrent_set_canned_acl|object_write_to_nonexist_bucket|object_requestid_matches_header_on_error|object_head_zero_bytes|object_write_cache_control|object_write_expires|object_set_get_metadata_none_to_good|object_set_get_metadata_none_to_empty|object_set_get_metadata_overwrite_to_empty|post_object_anonymous_request|post_object_authenticated_request|post_object_authenticated_no_content_type|post_object_authenticated_request_bad_access_key|post_object_set_success_code|post_object_set_invalid_success_code|post_object_upload_larger_than_chunk|post_object_set_key_from_filename|post_object_ignored_header|post_object_case_insensitive_condition_fields|post_object_escaped_field_values|post_object_success_redirect_action|post_object_invalid_signature|post_object_invalid_access_key|post_object_missing_policy_condition|post_object_user_specified_header|post_object_request_missing_policy_specified_field|post_object_expired_policy|post_object_invalid_request_field_value|get_object_ifmatch_failed|get_object_ifunmodifiedsince_good|put_object_ifmatch_failed|object_raw_get|object_raw_get_bucket_gone|object_delete_key_bucket_gone|object_raw_get_bucket_acl|object_raw_get_object_acl|object_raw_authenticated|object_raw_response_headers|object_raw_authenticated_bucket_acl|object_raw_authenticated_object_acl|object_raw_authenticated_bucket_gone|object_raw_get_x_amz_expires_not_expired|object_raw_get_x_amz_expires_out_max_range|object_raw_get_x_amz_expires_out_positive_range|object_anon_put_write_access|object_raw_put_authenticated_expired|bucket_create_naming_bad_short_one|bucket_create_naming_bad_short_two|bucket_create_exists|bucket_get_location|bucket_acl_default|bucket_acl_canned|bucket_acl_canned_publicreadwrite|bucket_acl_canned_authenticatedread|object_acl_default|object_acl_canned_during_create|object_acl_canned|object_acl_canned_publicreadwrite|object_acl_canned_authenticatedread|object_acl_canned_bucketownerread|object_acl_canned_bucketownerfullcontrol|object_acl_full_control_verify_attributes|bucket_acl_canned_private_to_private|bucket_acl_grant_nonexist_user|bucket_acl_no_grants|bucket_acl_grant_email_not_exist|bucket_acl_revoke_all|bucket_recreate_not_overriding|bucket_create_special_key_names|object_copy_zero_size|object_copy_verify_contenttype|object_copy_to_itself|object_copy_to_itself_with_metadata|object_copy_not_owned_bucket|object_copy_not_owned_object_bucket|object_copy_retaining_metadata|object_copy_replacing_metadata|multipart_upload_empty|multipart_copy_invalid_range|multipart_copy_special_names|multipart_upload_resend_part|multipart_upload_size_too_small|abort_multipart_upload_not_found|multipart_upload_missing_part|multipart_upload_incorrect_etag|100_continue|ranged_request_invalid_range|ranged_request_empty_object|access_bucket)'`  s3tests_boto3.functional.test_s3.test_bucket_list_empty  ok s3tests_boto3.functional.test_s3.test_bucket_list_distinct  ok s3tests_boto3.functional.test_s3.test_bucket_list_many  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_many  ok s3tests_boto3.functional.test_s3.test_basic_key_count  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_prefix  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_prefix_underscore  ok s3tests_boto3.functional.test_s3.test_bucket_list_delimiter_empty  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_empty  ok s3tests_boto3.functional.test_s3.test_bucket_list_delimiter_none  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_none  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_fetchowner_notempty  ok s3tests_boto3.functional.test_s3.test_bucket_list_delimiter_not_exist  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_not_exist  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_basic  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_basic  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_alt  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_alt  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_empty  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_empty  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_none  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_none  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_not_exist  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_not_exist  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_unreadable  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_unreadable  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_delimiter_basic  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_delimiter_basic  ok s3tests_boto3.functional.test_s3.test_bucket_list_maxkeys_one  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_maxkeys_one  ok s3tests_boto3.functional.test_s3.test_bucket_list_maxkeys_zero  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_maxkeys_zero  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_none  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_empty  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_continuationtoken  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_both_continuationtoken_startafter  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_unreadable  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_startafter_unreadable  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_not_in_list  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_startafter_not_in_list  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_after_list  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_startafter_after_list  ok s3tests_boto3.functional.test_s3.test_bucket_delete_notexist  ok s3tests_boto3.functional.test_s3.test_bucket_create_delete  ok s3tests_boto3.functional.test_s3.test_object_read_not_exist  ok s3tests_boto3.functional.test_s3.test_multi_object_delete  ok s3tests_boto3.functional.test_s3.test_multi_objectv2_delete  ok s3tests_boto3.functional.test_s3.test_object_write_check_etag  ok s3tests_boto3.functional.test_s3.test_object_write_read_update_read_delete  ok s3tests_boto3.functional.test_s3.test_object_set_get_non_utf8_metadata  ok s3tests_boto3.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_prefix  ok s3tests_boto3.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_suffix  ok s3tests_boto3.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_infix  ok s3tests_boto3.functional.test_s3.test_object_metadata_replaced_on_put  ok s3tests_boto3.functional.test_s3.test_object_write_file  ok s3tests_boto3.functional.test_s3.test_post_object_invalid_date_format  ok s3tests_boto3.functional.test_s3.test_post_object_no_key_specified  ok s3tests_boto3.functional.test_s3.test_post_object_missing_signature  ok s3tests_boto3.functional.test_s3.test_post_object_condition_is_case_sensitive  ok s3tests_boto3.functional.test_s3.test_post_object_expires_is_case_sensitive  ok s3tests_boto3.functional.test_s3.test_post_object_missing_expires_condition  ok s3tests_boto3.functional.test_s3.test_post_object_missing_conditions_list  ok s3tests_boto3.functional.test_s3.test_post_object_upload_size_limit_exceeded  ok s3tests_boto3.functional.test_s3.test_post_object_missing_content_length_argument  ok s3tests_boto3.functional.test_s3.test_post_object_invalid_content_length_argument  ok s3tests_boto3.functional.test_s3.test_post_object_upload_size_below_minimum  ok s3tests_boto3.functional.test_s3.test_post_object_empty_conditions  ok s3tests_boto3.functional.test_s3.test_get_object_ifmatch_good  ok s3tests_boto3.functional.test_s3.test_get_object_ifnonematch_good  ok s3tests_boto3.functional.test_s3.test_get_object_ifnonematch_failed  ok s3tests_boto3.functional.test_s3.test_get_object_ifmodifiedsince_good  ok s3tests_boto3.functional.test_s3.test_get_object_ifmodifiedsince_failed  ok s3tests_boto3.functional.test_s3.test_get_object_ifunmodifiedsince_failed  ok s3tests_boto3.functional.test_s3.test_bucket_head  ok s3tests_boto3.functional.test_s3.test_bucket_head_notexist  ok s3tests_boto3.functional.test_s3.test_object_anon_put  ok s3tests_boto3.functional.test_s3.test_object_put_authenticated  ok s3tests_boto3.functional.test_s3.test_bucket_recreate_overwrite_acl  ok s3tests_boto3.functional.test_s3.test_bucket_recreate_new_acl  ok s3tests_boto3.functional.test_s3.test_buckets_create_then_list  ok s3tests_boto3.functional.test_s3.test_list_buckets_invalid_auth  ok s3tests_boto3.functional.test_s3.test_list_buckets_bad_auth  ok s3tests_boto3.functional.test_s3.test_bucket_create_naming_good_starts_alpha  ok s3tests_boto3.functional.test_s3.test_bucket_create_naming_good_starts_digit  ok s3tests_boto3.functional.test_s3.test_bucket_create_naming_good_contains_period  ok s3tests_boto3.functional.test_s3.test_bucket_create_naming_good_contains_hyphen  ok s3tests_boto3.functional.test_s3.test_bucket_list_special_prefix  ok s3tests_boto3.functional.test_s3.test_object_copy_same_bucket  ok s3tests_boto3.functional.test_s3.test_object_copy_diff_bucket  ok s3tests_boto3.functional.test_s3.test_object_copy_canned_acl  ok s3tests_boto3.functional.test_s3.test_object_copy_bucket_not_found  ok s3tests_boto3.functional.test_s3.test_object_copy_key_not_found  ok s3tests_boto3.functional.test_s3.test_multipart_upload_small  ok s3tests_boto3.functional.test_s3.test_multipart_copy_small  ok s3tests_boto3.functional.test_s3.test_multipart_copy_without_range  ok s3tests_boto3.functional.test_s3.test_multipart_upload_multiple_sizes  ok s3tests_boto3.functional.test_s3.test_multipart_copy_multiple_sizes  ok s3tests_boto3.functional.test_s3.test_multipart_upload_contents  ok s3tests_boto3.functional.test_s3.test_multipart_upload_overwrite_existing_object  ok s3tests_boto3.functional.test_s3.test_abort_multipart_upload  ok s3tests_boto3.functional.test_s3.test_list_multipart_upload  ok s3tests_boto3.functional.test_s3.test_atomic_read_1mb  ok s3tests_boto3.functional.test_s3.test_atomic_read_4mb  ok s3tests_boto3.functional.test_s3.test_atomic_read_8mb  ok s3tests_boto3.functional.test_s3.test_atomic_write_1mb  ok s3tests_boto3.functional.test_s3.test_atomic_write_4mb  ok s3tests_boto3.functional.test_s3.test_atomic_write_8mb  ok s3tests_boto3.functional.test_s3.test_atomic_dual_write_1mb  ok s3tests_boto3.functional.test_s3.test_atomic_dual_write_4mb  ok s3tests_boto3.functional.test_s3.test_atomic_dual_write_8mb  ok s3tests_boto3.functional.test_s3.test_atomic_multipart_upload_write  ok s3tests_boto3.functional.test_s3.test_multipart_resend_first_finishes_last  ok s3tests_boto3.functional.test_s3.test_ranged_request_response_code  ok s3tests_boto3.functional.test_s3.test_ranged_big_request_response_code  ok s3tests_boto3.functional.test_s3.test_ranged_request_skip_leading_bytes_response_code  ok s3tests_boto3.functional.test_s3.test_ranged_request_return_trailing_bytes_response_code  ok s3tests_boto3.functional.test_s3.test_copy_object_ifmatch_good  ok s3tests_boto3.functional.test_s3.test_copy_object_ifnonematch_failed  ok  XML: s3-tests/nosetests.xml  Ran 118 tests in 46.761s OK ",test-file | test-file,"s3-tests include in the docker compose file https://github.com/splunk/s3-tests `S3TEST_CONF=s3tests.conf venv/bin/nosetests --verbose --logging-level=ERROR --with-xunit --failure-detail s3tests_boto3.functional.test_s3 -a '!tagging,!fails_on_aws,!encryption,!bucket-policy,!versioning,!fails_on_rgw,!bucket-policy,!fails_with_subdomain,!policy_status,!object-lock,!lifecycle,!cors,!user-policy' -e '(bucket_list_delimiter_basic|bucket_listv2_delimiter_basic|bucket_listv2_encoding_basic|bucket_list_encoding_basic|bucket_list_delimiter_prefix|bucket_listv2_delimiter_prefix_ends_with_delimiter|bucket_list_delimiter_prefix_ends_with_delimiter|bucket_list_delimiter_alt|bucket_listv2_delimiter_alt|bucket_list_delimiter_prefix_underscore|bucket_list_delimiter_percentage|bucket_listv2_delimiter_percentage|bucket_list_delimiter_whitespace|bucket_listv2_delimiter_whitespace|bucket_list_delimiter_dot|bucket_listv2_delimiter_dot|bucket_list_delimiter_unreadable|bucket_listv2_delimiter_unreadable|bucket_listv2_fetchowner_defaultempty|bucket_listv2_fetchowner_empty|bucket_list_delimiter_not_skip_special|bucket_list_prefix_delimiter_alt|bucket_listv2_prefix_delimiter_alt|bucket_list_prefix_delimiter_prefix_not_exist|bucket_listv2_prefix_delimiter_prefix_not_exist|bucket_list_prefix_delimiter_delimiter_not_exist|bucket_listv2_prefix_delimiter_delimiter_not_exist|bucket_list_prefix_delimiter_prefix_delimiter_not_exist|bucket_listv2_prefix_delimiter_prefix_delimiter_not_exist|bucket_list_maxkeys_none|bucket_listv2_maxkeys_none|bucket_list_maxkeys_invalid|bucket_listv2_continuationtoken_empty|bucket_list_return_data|bucket_list_objects_anonymous|bucket_listv2_objects_anonymous|bucket_notexist|bucketv2_notexist|bucket_delete_nonempty|bucket_concurrent_set_canned_acl|object_write_to_nonexist_bucket|object_requestid_matches_header_on_error|object_head_zero_bytes|object_write_cache_control|object_write_expires|object_set_get_metadata_none_to_good|object_set_get_metadata_none_to_empty|object_set_get_metadata_overwrite_to_empty|post_object_anonymous_request|post_object_authenticated_request|post_object_authenticated_no_content_type|post_object_authenticated_request_bad_access_key|post_object_set_success_code|post_object_set_invalid_success_code|post_object_upload_larger_than_chunk|post_object_set_key_from_filename|post_object_ignored_header|post_object_case_insensitive_condition_fields|post_object_escaped_field_values|post_object_success_redirect_action|post_object_invalid_signature|post_object_invalid_access_key|post_object_missing_policy_condition|post_object_user_specified_header|post_object_request_missing_policy_specified_field|post_object_expired_policy|post_object_invalid_request_field_value|get_object_ifmatch_failed|get_object_ifunmodifiedsince_good|put_object_ifmatch_failed|object_raw_get|object_raw_get_bucket_gone|object_delete_key_bucket_gone|object_raw_get_bucket_acl|object_raw_get_object_acl|object_raw_authenticated|object_raw_response_headers|object_raw_authenticated_bucket_acl|object_raw_authenticated_object_acl|object_raw_authenticated_bucket_gone|object_raw_get_x_amz_expires_not_expired|object_raw_get_x_amz_expires_out_max_range|object_raw_get_x_amz_expires_out_positive_range|object_anon_put_write_access|object_raw_put_authenticated_expired|bucket_create_naming_bad_short_one|bucket_create_naming_bad_short_two|bucket_create_exists|bucket_get_location|bucket_acl_default|bucket_acl_canned|bucket_acl_canned_publicreadwrite|bucket_acl_canned_authenticatedread|object_acl_default|object_acl_canned_during_create|object_acl_canned|object_acl_canned_publicreadwrite|object_acl_canned_authenticatedread|object_acl_canned_bucketownerread|object_acl_canned_bucketownerfullcontrol|object_acl_full_control_verify_attributes|bucket_acl_canned_private_to_private|bucket_acl_grant_nonexist_user|bucket_acl_no_grants|bucket_acl_grant_email_not_exist|bucket_acl_revoke_all|bucket_recreate_not_overriding|bucket_create_special_key_names|object_copy_zero_size|object_copy_verify_contenttype|object_copy_to_itself|object_copy_to_itself_with_metadata|object_copy_not_owned_bucket|object_copy_not_owned_object_bucket|object_copy_retaining_metadata|object_copy_replacing_metadata|multipart_upload_empty|multipart_copy_invalid_range|multipart_copy_special_names|multipart_upload_resend_part|multipart_upload_size_too_small|abort_multipart_upload_not_found|multipart_upload_missing_part|multipart_upload_incorrect_etag|100_continue|ranged_request_invalid_range|ranged_request_empty_object|access_bucket)'`  s3tests_boto3.functional.test_s3.test_bucket_list_empty  ok s3tests_boto3.functional.test_s3.test_bucket_list_distinct  ok s3tests_boto3.functional.test_s3.test_bucket_list_many  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_many  ok s3tests_boto3.functional.test_s3.test_basic_key_count  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_prefix  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_prefix_underscore  ok s3tests_boto3.functional.test_s3.test_bucket_list_delimiter_empty  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_empty  ok s3tests_boto3.functional.test_s3.test_bucket_list_delimiter_none  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_none  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_fetchowner_notempty  ok s3tests_boto3.functional.test_s3.test_bucket_list_delimiter_not_exist  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_delimiter_not_exist  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_basic  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_basic  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_alt  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_alt  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_empty  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_empty  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_none  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_none  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_not_exist  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_not_exist  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_unreadable  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_unreadable  ok s3tests_boto3.functional.test_s3.test_bucket_list_prefix_delimiter_basic  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_prefix_delimiter_basic  ok s3tests_boto3.functional.test_s3.test_bucket_list_maxkeys_one  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_maxkeys_one  ok s3tests_boto3.functional.test_s3.test_bucket_list_maxkeys_zero  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_maxkeys_zero  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_none  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_empty  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_continuationtoken  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_both_continuationtoken_startafter  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_unreadable  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_startafter_unreadable  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_not_in_list  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_startafter_not_in_list  ok s3tests_boto3.functional.test_s3.test_bucket_list_marker_after_list  ok s3tests_boto3.functional.test_s3.test_bucket_listv2_startafter_after_list  ok s3tests_boto3.functional.test_s3.test_bucket_delete_notexist  ok s3tests_boto3.functional.test_s3.test_bucket_create_delete  ok s3tests_boto3.functional.test_s3.test_object_read_not_exist  ok s3tests_boto3.functional.test_s3.test_multi_object_delete  ok s3tests_boto3.functional.test_s3.test_multi_objectv2_delete  ok s3tests_boto3.functional.test_s3.test_object_write_check_etag  ok s3tests_boto3.functional.test_s3.test_object_write_read_update_read_delete  ok s3tests_boto3.functional.test_s3.test_object_set_get_non_utf8_metadata  ok s3tests_boto3.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_prefix  ok s3tests_boto3.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_suffix  ok s3tests_boto3.functional.test_s3.test_object_set_get_metadata_empty_to_unreadable_infix  ok s3tests_boto3.functional.test_s3.test_object_metadata_replaced_on_put  ok s3tests_boto3.functional.test_s3.test_object_write_file  ok s3tests_boto3.functional.test_s3.test_post_object_invalid_date_format  ok s3tests_boto3.functional.test_s3.test_post_object_no_key_specified  ok s3tests_boto3.functional.test_s3.test_post_object_missing_signature  ok s3tests_boto3.functional.test_s3.test_post_object_condition_is_case_sensitive  ok s3tests_boto3.functional.test_s3.test_post_object_expires_is_case_sensitive  ok s3tests_boto3.functional.test_s3.test_post_object_missing_expires_condition  ok s3tests_boto3.functional.test_s3.test_post_object_missing_conditions_list  ok s3tests_boto3.functional.test_s3.test_post_object_upload_size_limit_exceeded  ok s3tests_boto3.functional.test_s3.test_post_object_missing_content_length_argument  ok s3tests_boto3.functional.test_s3.test_post_object_invalid_content_length_argument  ok s3tests_boto3.functional.test_s3.test_post_object_upload_size_below_minimum  ok s3tests_boto3.functional.test_s3.test_post_object_empty_conditions  ok s3tests_boto3.functional.test_s3.test_get_object_ifmatch_good  ok s3tests_boto3.functional.test_s3.test_get_object_ifnonematch_good  ok s3tests_boto3.functional.test_s3.test_get_object_ifnonematch_failed  ok s3tests_boto3.functional.test_s3.test_get_object_ifmodifiedsince_good  ok s3tests_boto3.functional.test_s3.test_get_object_ifmodifiedsince_failed  ok s3tests_boto3.functional.test_s3.test_get_object_ifunmodifiedsince_failed  ok s3tests_boto3.functional.test_s3.test_bucket_head  ok s3tests_boto3.functional.test_s3.test_bucket_head_notexist  ok s3tests_boto3.functional.test_s3.test_object_anon_put  ok s3tests_boto3.functional.test_s3.test_object_put_authenticated  ok s3tests_boto3.functional.test_s3.test_bucket_recreate_overwrite_acl  ok s3tests_boto3.functional.test_s3.test_bucket_recreate_new_acl  ok s3tests_boto3.functional.test_s3.test_buckets_create_then_list  ok s3tests_boto3.functional.test_s3.test_list_buckets_invalid_auth  ok s3tests_boto3.functional.test_s3.test_list_buckets_bad_auth  ok s3tests_boto3.functional.test_s3.test_bucket_create_naming_good_starts_alpha  ok s3tests_boto3.functional.test_s3.test_bucket_create_naming_good_starts_digit  ok s3tests_boto3.functional.test_s3.test_bucket_create_naming_good_contains_period  ok s3tests_boto3.functional.test_s3.test_bucket_create_naming_good_contains_hyphen  ok s3tests_boto3.functional.test_s3.test_bucket_list_special_prefix  ok s3tests_boto3.functional.test_s3.test_object_copy_same_bucket  ok s3tests_boto3.functional.test_s3.test_object_copy_diff_bucket  ok s3tests_boto3.functional.test_s3.test_object_copy_canned_acl  ok s3tests_boto3.functional.test_s3.test_object_copy_bucket_not_found  ok s3tests_boto3.functional.test_s3.test_object_copy_key_not_found  ok s3tests_boto3.functional.test_s3.test_multipart_upload_small  ok s3tests_boto3.functional.test_s3.test_multipart_copy_small  ok s3tests_boto3.functional.test_s3.test_multipart_copy_without_range  ok s3tests_boto3.functional.test_s3.test_multipart_upload_multiple_sizes  ok s3tests_boto3.functional.test_s3.test_multipart_copy_multiple_sizes  ok s3tests_boto3.functional.test_s3.test_multipart_upload_contents  ok s3tests_boto3.functional.test_s3.test_multipart_upload_overwrite_existing_object  ok s3tests_boto3.functional.test_s3.test_abort_multipart_upload  ok s3tests_boto3.functional.test_s3.test_list_multipart_upload  ok s3tests_boto3.functional.test_s3.test_atomic_read_1mb  ok s3tests_boto3.functional.test_s3.test_atomic_read_4mb  ok s3tests_boto3.functional.test_s3.test_atomic_read_8mb  ok s3tests_boto3.functional.test_s3.test_atomic_write_1mb  ok s3tests_boto3.functional.test_s3.test_atomic_write_4mb  ok s3tests_boto3.functional.test_s3.test_atomic_write_8mb  ok s3tests_boto3.functional.test_s3.test_atomic_dual_write_1mb  ok s3tests_boto3.functional.test_s3.test_atomic_dual_write_4mb  ok s3tests_boto3.functional.test_s3.test_atomic_dual_write_8mb  ok s3tests_boto3.functional.test_s3.test_atomic_multipart_upload_write  ok s3tests_boto3.functional.test_s3.test_multipart_resend_first_finishes_last  ok s3tests_boto3.functional.test_s3.test_ranged_request_response_code  ok s3tests_boto3.functional.test_s3.test_ranged_big_request_response_code  ok s3tests_boto3.functional.test_s3.test_ranged_request_skip_leading_bytes_response_code  ok s3tests_boto3.functional.test_s3.test_ranged_request_return_trailing_bytes_response_code  ok s3tests_boto3.functional.test_s3.test_copy_object_ifmatch_good  ok s3tests_boto3.functional.test_s3.test_copy_object_ifnonematch_failed  ok  XML: s3-tests/nosetests.xml  Ran 118 tests in 46.761s OK  test-file test-file",no-bug,0.95
1511,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1511,S3 Ability to disable listing on a bucket,"**Describe the bug** I want seaweedfs to serve read-only files by link, which is a Read operation. But also I wish to disable the ability of a non-authorized user to get file listing in a bucket. Currently it seems to be impossible. Could this be implemented somehow?",source-file | source-file,"S3 Ability to disable listing on a bucket **Describe the bug** I want seaweedfs to serve read-only files by link, which is a Read operation. But also I wish to disable the ability of a non-authorized user to get file listing in a bucket. Currently it seems to be impossible. Could this be implemented somehow? source-file source-file",no-bug,0.8
376,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/376,Https Support,"I wonder if seaweedFS support https or other API, such as grpc?",source-file,"Https Support I wonder if seaweedFS support https or other API, such as grpc? source-file",no-bug,0.9
1286,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1286,Filer cannot upload files to the new deployed free volume,"Hi I use `docker-compose` to setup a bunch of application for `seaweedfs`. Let's just say I have 2 Linux Server(CN0, CN1) and they all contains `Docker` Here's my environment: - CN0: I deployed 5 services: `master`, `volume`, `filer`, `kafka` and `etcd`. The `volume` bind to `/data/disk1` which contains 1G free space in `xfs` format. - CN1: I deployed 1 service: `volume`. The `volume` bind to `/data/disk1` which contains 1G free space in `xfs` format. First I deploy CN0, and upload many files in order to make it full. When CN0's `volume` has only `600k~800k` (according to http://CN0:8080/ui/index.html), I can not upload files through `filer` anymore. Then I deploy CN1 (add `volume` only), I want to enlarge my `seaweedfs`'s free space. When it's done, I still cannot upload any files through CN0's `filer`. At this time, `filer` and `master` has no error log or normal log printed. But in CN0's `volume`, it print `failed to write to local disk: write /data/1.dat: no space left on device`. It seems that `filer` is not upload my files to the free CN1 `volume` but upload to the CN0 `volume` which is out of space. I've also tried restart `master`, `filer` but no luck. I upload files through `filer`. I use `etcd` as `filer`'s database (also tried origin `leveldb2` but no luck). Here's my info:  docker-compose.yml > CN0 yaml version: '3.6' services: master: image: ${IMAGE} # use a remote image restart: always ports: - 9333:9333 - 19333:19333 command: 'master -ip=${CN0IP} -ip.bind=""0.0.0.0""' container_name: weedfs_master ulimits: nproc: 65535 volume: image: ${IMAGE} # use a remote image restart: always ports: - 8080:8080 - 18080:18080 command: 'volume -mserver=""${CN0IP}:9333"" -ip=${CN0IP} -ip.bind=""0.0.0.0"" -dataCenter=EuDataCenter -port=8080' container_name: weedfs_volume ulimits: nproc: 65535 volumes: - type: bind source: ${DATAPATH} target: /data depends_on: - master filer: image: ${IMAGE} # use a remote image restart: always ulimits: nproc: 65535 ports: - 8888:8888 - 18888:18888 command: 'filer -master=""${MASTERIP}:9333"" -port=8888 -dataCenter=EuDataCenter' container_name: weedfs_filer tty: true stdin_open: true volumes: - type: bind source: /data/leveldb2 target: /data/filerleveldb2 environment: RABBIT_SERVER_URL: '${RABBIT_SERVER_URL}' depends_on: - master - volume  > CN1 yml version: '3.6' services: volume: image: ${IMAGE} # use a remote image restart: always ports: - 8080:8080 - 18080:18080 command: 'volume -mserver=""${CN0IP}:9333"" -ip=${CN1IP} -ip.bind=""0.0.0.0"" -dataCenter=EuDataCenter -port=8080' container_name: weedfs_volume ulimits: nproc: 65535 volumes: - type: bind source: ${DATAPATH} target: /data   *.tomls > notification.toml toml [notification.kafka] enabled = true hosts = [ ""{EUDIC_KAFKA_ADDRESS}:9092"" #10.117.2.80:9092 ] topic = ""seaweedfs_replication"" offsetFile = ""/notification/last.offset"" offsetSaveIntervalSeconds = 10  > filer.toml toml [filer.options] recursive_delete = false buckets_folder = ""/"" #changed, origin is /bucket buckets_fsync = [ ""important_bucket"", ""should_always_fsync"", ] [leveldb2] enabled = false dir = ""/data/filerldb2"" # directory to store level db files [etcd] enabled = true servers = ""{CN0IP}:2379"" timeout = ""3s""  > master.toml toml [master.maintenance] scripts =  ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force ec.balance -force volume.balance -collection=ALL_COLLECTIONS -force volume.fix.replication  sleep_minutes = 1 # changed, origin is 19 [master.filer] default = ""{CN0}:8888"" # used by maintenance scripts if the scripts needs to use fs related commands [master.sequencer] type = ""etcd"" # changed, origin is memory. but if I change it back to memory it still the same sequencer_etcd_urls = ""http://{CN0}:2379""  > replication.toml toml [source.filer] enabled = true grpcAddress = ""{CN0}:18888"" #localhost:18888 # all files under this directory tree are replicated. # this is not a directory on your hard drive, but on your filer. # i.e., all files with this ""prefix"" are sent to notification message queue. directory = ""/"" [sink.filer] enabled = true grpcAddress = ""{CN2}:18888"" #localhost:18888 # all replicated files are under this directory tree # this is not a directory on your hard drive, but on your filer. # i.e., all received files will be ""prefixed"" to this directory. directory = ""/"" replication = """" collection = """" ttlSec = 0  Tested `seaweedfs` version: 1.74~1.75 What's the best practice of enlarge `seaweedfs`'s free space and make `filer` to upload my files to the right `volume`? Thanks for your time!",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Filer cannot upload files to the new deployed free volume Hi I use `docker-compose` to setup a bunch of application for `seaweedfs`. Let's just say I have 2 Linux Server(CN0, CN1) and they all contains `Docker` Here's my environment: - CN0: I deployed 5 services: `master`, `volume`, `filer`, `kafka` and `etcd`. The `volume` bind to `/data/disk1` which contains 1G free space in `xfs` format. - CN1: I deployed 1 service: `volume`. The `volume` bind to `/data/disk1` which contains 1G free space in `xfs` format. First I deploy CN0, and upload many files in order to make it full. When CN0's `volume` has only `600k~800k` (according to http://CN0:8080/ui/index.html), I can not upload files through `filer` anymore. Then I deploy CN1 (add `volume` only), I want to enlarge my `seaweedfs`'s free space. When it's done, I still cannot upload any files through CN0's `filer`. At this time, `filer` and `master` has no error log or normal log printed. But in CN0's `volume`, it print `failed to write to local disk: write /data/1.dat: no space left on device`. It seems that `filer` is not upload my files to the free CN1 `volume` but upload to the CN0 `volume` which is out of space. I've also tried restart `master`, `filer` but no luck. I upload files through `filer`. I use `etcd` as `filer`'s database (also tried origin `leveldb2` but no luck). Here's my info:  docker-compose.yml > CN0 yaml version: '3.6' services: master: image: ${IMAGE} # use a remote image restart: always ports: - 9333:9333 - 19333:19333 command: 'master -ip=${CN0IP} -ip.bind=""0.0.0.0""' container_name: weedfs_master ulimits: nproc: 65535 volume: image: ${IMAGE} # use a remote image restart: always ports: - 8080:8080 - 18080:18080 command: 'volume -mserver=""${CN0IP}:9333"" -ip=${CN0IP} -ip.bind=""0.0.0.0"" -dataCenter=EuDataCenter -port=8080' container_name: weedfs_volume ulimits: nproc: 65535 volumes: - type: bind source: ${DATAPATH} target: /data depends_on: - master filer: image: ${IMAGE} # use a remote image restart: always ulimits: nproc: 65535 ports: - 8888:8888 - 18888:18888 command: 'filer -master=""${MASTERIP}:9333"" -port=8888 -dataCenter=EuDataCenter' container_name: weedfs_filer tty: true stdin_open: true volumes: - type: bind source: /data/leveldb2 target: /data/filerleveldb2 environment: RABBIT_SERVER_URL: '${RABBIT_SERVER_URL}' depends_on: - master - volume  > CN1 yml version: '3.6' services: volume: image: ${IMAGE} # use a remote image restart: always ports: - 8080:8080 - 18080:18080 command: 'volume -mserver=""${CN0IP}:9333"" -ip=${CN1IP} -ip.bind=""0.0.0.0"" -dataCenter=EuDataCenter -port=8080' container_name: weedfs_volume ulimits: nproc: 65535 volumes: - type: bind source: ${DATAPATH} target: /data   *.tomls > notification.toml toml [notification.kafka] enabled = true hosts = [ ""{EUDIC_KAFKA_ADDRESS}:9092"" #10.117.2.80:9092 ] topic = ""seaweedfs_replication"" offsetFile = ""/notification/last.offset"" offsetSaveIntervalSeconds = 10  > filer.toml toml [filer.options] recursive_delete = false buckets_folder = ""/"" #changed, origin is /bucket buckets_fsync = [ ""important_bucket"", ""should_always_fsync"", ] [leveldb2] enabled = false dir = ""/data/filerldb2"" # directory to store level db files [etcd] enabled = true servers = ""{CN0IP}:2379"" timeout = ""3s""  > master.toml toml [master.maintenance] scripts =  ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force ec.balance -force volume.balance -collection=ALL_COLLECTIONS -force volume.fix.replication  sleep_minutes = 1 # changed, origin is 19 [master.filer] default = ""{CN0}:8888"" # used by maintenance scripts if the scripts needs to use fs related commands [master.sequencer] type = ""etcd"" # changed, origin is memory. but if I change it back to memory it still the same sequencer_etcd_urls = ""http://{CN0}:2379""  > replication.toml toml [source.filer] enabled = true grpcAddress = ""{CN0}:18888"" #localhost:18888 # all files under this directory tree are replicated. # this is not a directory on your hard drive, but on your filer. # i.e., all files with this ""prefix"" are sent to notification message queue. directory = ""/"" [sink.filer] enabled = true grpcAddress = ""{CN2}:18888"" #localhost:18888 # all replicated files are under this directory tree # this is not a directory on your hard drive, but on your filer. # i.e., all received files will be ""prefixed"" to this directory. directory = ""/"" replication = """" collection = """" ttlSec = 0  Tested `seaweedfs` version: 1.74~1.75 What's the best practice of enlarge `seaweedfs`'s free space and make `filer` to upload my files to the right `volume`? Thanks for your time! source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
2591,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2591,Parallel migration between tiers?,"We've been using tiered storage for a quite time already, even in production. But as our storage grows, we have faced the bottleneck in the current scheme. Hot storage is filling up quite fast, and as far as `volume.tier.move ` move one volume at time, `master` script simply can't keep up with that pace. I've already disabled almost all other operations on cluster and forced script rerun to every 30 minutes, but still. So it would be cool to be able to move volumes to another tier in parallel. Say, I have 3 ssd servers and 6 hdd servers. I think I can move up to 3 volumes at time without greatly affecting performance. Could this be implemented or I have missed something and it can be done already?",source-file,"Parallel migration between tiers? We've been using tiered storage for a quite time already, even in production. But as our storage grows, we have faced the bottleneck in the current scheme. Hot storage is filling up quite fast, and as far as `volume.tier.move ` move one volume at time, `master` script simply can't keep up with that pace. I've already disabled almost all other operations on cluster and forced script rerun to every 30 minutes, but still. So it would be cool to be able to move volumes to another tier in parallel. Say, I have 3 ssd servers and 6 hdd servers. I think I can move up to 3 volumes at time without greatly affecting performance. Could this be implemented or I have missed something and it can be done already? source-file",no-bug,0.9
1468,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1468,use weed webdav service cpu over 50% and has been occupied,"use weed webdav service download file size is very large case 4G ,result computer cpu over 50% and has been occupied .",source-file,"use weed webdav service cpu over 50% and has been occupied use weed webdav service download file size is very large case 4G ,result computer cpu over 50% and has been occupied . source-file",no-bug,0.9
37,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/37,redirectOnRead goes to localhost,"I've got it running as a server: ./weed server -filer.redirectOnRead -filer Here's the curl. Note the hostname in the Location header: bash-3.2$ curl -vI http://weed1:8888/path/to/sources/README.md > /dev/null > HEAD /path/to/sources/README.md HTTP/1.1 > User-Agent: curl/7.30.0 > Host: weed1:8888 > Accept: _/_ > > < HTTP/1.1 302 Found > < Location: http://localhost:8080/5,01afbd8c36 > < Date: Sat, 20 Dec 2014 17:15:34 GMT > < Content-Type: text/plain; charset=utf-8 > < > 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 > - Connection #0 to host weed1 left intact > bash-3.2$",config-file | other-file | other-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | source-file | source-file | other-file | config-file | source-file | source-file | config-file | config-file | config-file | config-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"redirectOnRead goes to localhost I've got it running as a server: ./weed server -filer.redirectOnRead -filer Here's the curl. Note the hostname in the Location header: bash-3.2$ curl -vI http://weed1:8888/path/to/sources/README.md > /dev/null > HEAD /path/to/sources/README.md HTTP/1.1 > User-Agent: curl/7.30.0 > Host: weed1:8888 > Accept: _/_ > > < HTTP/1.1 302 Found > < Location: http://localhost:8080/5,01afbd8c36 > < Date: Sat, 20 Dec 2014 17:15:34 GMT > < Content-Type: text/plain; charset=utf-8 > < > 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 > - Connection #0 to host weed1 left intact > bash-3.2$ config-file other-file other-file documentation-file documentation-file config-file other-file config-file source-file source-file source-file other-file config-file source-file source-file config-file config-file config-file config-file source-file source-file test-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.9
885,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/885,filer mode start error,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** when execute  docker run --rm -it chrislusf/seaweedfs server -filer=true  there's an error occur  I0315 06:33:49 1 file_util.go:19] Folder /data Permission: -rwxr-xr-x I0315 06:33:49 1 master_server.go:76] Volume Size Limit is 30000 MB I0315 06:33:49 1 server.go:178] Start Seaweed Master 1.26 at 172.17.0.3:9333 I0315 06:33:49 1 raft_server.go:44] Starting RaftServer with 172.17.0.3:9333 I0315 06:33:49 1 raft_server.go:48] Peers Change: [] => [] I0315 06:33:49 1 raft_server.go:71] Initializing new cluster I0315 06:33:49 1 raft_server.go:84] current cluster leader: 172.17.0.3:9333 I0315 06:33:49 1 master_server.go:115] [ 172.17.0.3:9333 ] I am the leader! I0315 06:33:49 1 server.go:199] grpc config <nil> I0315 06:33:49 1 server.go:205] Start Seaweed Master 1.26 grpc server at 172.17.0.3:19333 I0315 06:33:49 1 file_util.go:19] Folder /data Permission: -rwxr-xr-x I0315 06:33:49 1 disk_location.go:106] Store started on dir: /data with 0 volumes max 7 I0315 06:33:49 1 volume.go:163] Start Seaweed volume server 1.26 at 0.0.0.0:8080 I0315 06:33:49 1 volume_grpc_client_to_master.go:21] Volume server start with masters: [172.17.0.3:9333] I0315 06:33:49 1 volume_grpc_client_to_master.go:62] Heartbeat to: 172.17.0.3:9333 I0315 06:33:49 1 node.go:223] topo adds child DefaultDataCenter I0315 06:33:49 1 node.go:223] topo:DefaultDataCenter adds child DefaultRack I0315 06:33:49 1 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 172.17.0.3:8080 I0315 06:33:49 1 master_grpc_server.go:67] added volume server 172.17.0.3:8080 I0315 06:33:50 1 masterclient.go:46] filer bootstraps with masters [localhost:9333] I0315 06:33:50 1 masterclient.go:55] Connecting to master localhost:9333 I0315 06:33:50 1 leveldb_store.go:36] filer store dir: /data/filerdb F0315 06:33:50 1 configuration.go:22] Failed to initialize store for leveldb: Check Level Folder /data/filerdb Writable: github.com/chrislusf/seaweedfs/weed/filer2/leveldb.(*LevelDBStore).initialize /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/leveldb/leveldb_store.go:38 - stat /data/filerdb: no such file or directory goroutine 27 [running]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0xc000395d00, 0xc000294000, 0x168, 0x285) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:767 +0xad github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x2193aa0, 0xc000000003, 0xc00047b3b0, 0x212c219, 0x10, 0x16, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:718 +0x351 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x2193aa0, 0x3, 0x1447eb5, 0x26, 0xc0003a9d18, 0x2, 0x2) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:656 +0x14e github.com/chrislusf/seaweedfs/weed/glog.Fatalf() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:1149 github.com/chrislusf/seaweedfs/weed/filer2.(*Filer).LoadConfiguration(0xc0005984c0, 0xc000122200) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/configuration.go:22 +0x48f github.com/chrislusf/seaweedfs/weed/server.NewFilerServer(0xc000598400, 0xc000598400, 0xc0001360e0, 0x1, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/filer_server.go:70 +0x1b2 github.com/chrislusf/seaweedfs/weed/command.(*FilerOptions).startFiler(0x21937e0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:101 +0x21a github.com/chrislusf/seaweedfs/weed/command.runServer.func1() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/server.go:161 +0x3a created by github.com/chrislusf/seaweedfs/weed/command.runServer /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/server.go:158 +0x4c9  **System Setup**  docker run --rm -it chrislusf/seaweedfs server -filer=true  **Expected behavior** start normally",container-file | source-file,"filer mode start error Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** when execute  docker run --rm -it chrislusf/seaweedfs server -filer=true  there's an error occur  I0315 06:33:49 1 file_util.go:19] Folder /data Permission: -rwxr-xr-x I0315 06:33:49 1 master_server.go:76] Volume Size Limit is 30000 MB I0315 06:33:49 1 server.go:178] Start Seaweed Master 1.26 at 172.17.0.3:9333 I0315 06:33:49 1 raft_server.go:44] Starting RaftServer with 172.17.0.3:9333 I0315 06:33:49 1 raft_server.go:48] Peers Change: [] => [] I0315 06:33:49 1 raft_server.go:71] Initializing new cluster I0315 06:33:49 1 raft_server.go:84] current cluster leader: 172.17.0.3:9333 I0315 06:33:49 1 master_server.go:115] [ 172.17.0.3:9333 ] I am the leader! I0315 06:33:49 1 server.go:199] grpc config <nil> I0315 06:33:49 1 server.go:205] Start Seaweed Master 1.26 grpc server at 172.17.0.3:19333 I0315 06:33:49 1 file_util.go:19] Folder /data Permission: -rwxr-xr-x I0315 06:33:49 1 disk_location.go:106] Store started on dir: /data with 0 volumes max 7 I0315 06:33:49 1 volume.go:163] Start Seaweed volume server 1.26 at 0.0.0.0:8080 I0315 06:33:49 1 volume_grpc_client_to_master.go:21] Volume server start with masters: [172.17.0.3:9333] I0315 06:33:49 1 volume_grpc_client_to_master.go:62] Heartbeat to: 172.17.0.3:9333 I0315 06:33:49 1 node.go:223] topo adds child DefaultDataCenter I0315 06:33:49 1 node.go:223] topo:DefaultDataCenter adds child DefaultRack I0315 06:33:49 1 node.go:223] topo:DefaultDataCenter:DefaultRack adds child 172.17.0.3:8080 I0315 06:33:49 1 master_grpc_server.go:67] added volume server 172.17.0.3:8080 I0315 06:33:50 1 masterclient.go:46] filer bootstraps with masters [localhost:9333] I0315 06:33:50 1 masterclient.go:55] Connecting to master localhost:9333 I0315 06:33:50 1 leveldb_store.go:36] filer store dir: /data/filerdb F0315 06:33:50 1 configuration.go:22] Failed to initialize store for leveldb: Check Level Folder /data/filerdb Writable: github.com/chrislusf/seaweedfs/weed/filer2/leveldb.(*LevelDBStore).initialize /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/leveldb/leveldb_store.go:38 - stat /data/filerdb: no such file or directory goroutine 27 [running]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0xc000395d00, 0xc000294000, 0x168, 0x285) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:767 +0xad github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x2193aa0, 0xc000000003, 0xc00047b3b0, 0x212c219, 0x10, 0x16, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:718 +0x351 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x2193aa0, 0x3, 0x1447eb5, 0x26, 0xc0003a9d18, 0x2, 0x2) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:656 +0x14e github.com/chrislusf/seaweedfs/weed/glog.Fatalf() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:1149 github.com/chrislusf/seaweedfs/weed/filer2.(*Filer).LoadConfiguration(0xc0005984c0, 0xc000122200) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/configuration.go:22 +0x48f github.com/chrislusf/seaweedfs/weed/server.NewFilerServer(0xc000598400, 0xc000598400, 0xc0001360e0, 0x1, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/filer_server.go:70 +0x1b2 github.com/chrislusf/seaweedfs/weed/command.(*FilerOptions).startFiler(0x21937e0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:101 +0x21a github.com/chrislusf/seaweedfs/weed/command.runServer.func1() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/server.go:161 +0x3a created by github.com/chrislusf/seaweedfs/weed/command.runServer /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/server.go:158 +0x4c9  **System Setup**  docker run --rm -it chrislusf/seaweedfs server -filer=true  **Expected behavior** start normally container-file source-file",no-bug,0.9
266,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/266,how to weed mount accurately?,"1,weed mount weed mount -filer=""localhost:8888"" -dir=""/data/seaweedclient"" -debug=true This is SeaweedFS version 0.70 beta linux amd64 2,check it ll /data d ? ? ? ? ? seaweedclient why the owner and group of /data/seaweedclient is ""?"" ?",source-file | source-file | source-file | source-file,"how to weed mount accurately? 1,weed mount weed mount -filer=""localhost:8888"" -dir=""/data/seaweedclient"" -debug=true This is SeaweedFS version 0.70 beta linux amd64 2,check it ll /data d ? ? ? ? ? seaweedclient why the owner and group of /data/seaweedclient is ""?"" ? source-file source-file source-file source-file",no-bug,0.9
46,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/46,Docker build not working,"Seems like it can't `opkg-install curl`  Shell $ docker build -t weedfs . Sending build context to Docker daemon 50.78 MB Sending build context to Docker daemon Step 0 : FROM progrium/busybox Pulling repository progrium/busybox 6f114d3139e3: Download complete 511136ea3c5a: Download complete e2fb46397934: Download complete 015fb409be0d: Download complete 21082221cb6e: Download complete bbd692fe2ca1: Download complete 8db8f013bfca: Download complete 7fff0c6f0b8d: Download complete 7acf13620725: Download complete Status: Downloaded newer image for progrium/busybox:latest > 6f114d3139e3 Step 1 : WORKDIR /opt/weed > Running in 028351e07e71 > d1d57d22ef4d Removing intermediate container 028351e07e71 Step 2 : RUN opkg-install curl > Running in 2fd9079c8d42 wget: bad address 'downloads.openwrt.org' wget: bad address 'downloads.openwrt.org' Downloading http://downloads.openwrt.org/snapshots/trunk/x86_64/packages/base/Packages.gz. Downloading http://downloads.openwrt.org/snapshots/trunk/x86_64/packages/packages/Packages.gz. Collected errors: * opkg_download: Failed to download http://downloads.openwrt.org/snapshots/trunk/x86_64/packages/base/Packages.gz, wget returned 1. * opkg_download: Failed to download http://downloads.openwrt.org/snapshots/trunk/x86_64/packages/packages/Packages.gz, wget returned 1. Unknown package 'curl'. Collected errors: * opkg_install_cmd: Cannot install package curl. > 958aa12283bc Removing intermediate container 2fd9079c8d42 Step 3 : RUN echo insecure >> ~/.curlrc > Running in 576c9f7a23d3 > c39d8579e570 Removing intermediate container 576c9f7a23d3 Step 4 : RUN curl -Lks https://bintray.com$(curl -Lk http://bintray.com/chrislusf/Weed-FS/seaweed/_latestVersion | grep linux_amd64.tar.gz | sed -n ""/href/ s/.*href=['\""]\([^'\""]*\)['\""].*/\1/gp"") | gunzip | tar -xf - -C /opt/weed/ && mv weed_* bin && chmod +x ./bin/weed > Running in 5d84f61c0e11 /bin/sh: curl: not found /bin/sh: curl: not found gunzip: invalid magic tar: short read INFO[0095] The command [/bin/sh -c curl -Lks https://bintray.com$(curl -Lk http://bintray.com/chrislusf/Weed-FS/seaweed/_latestVersion | grep linux_amd64.tar.gz | sed -n ""/href/ s/.*href=['\""]\([^'\""]*\)['\""].*/\1/gp"") | gunzip | tar -xf - -C /opt/weed/ && mv weed_* bin && chmod +x ./bin/weed] returned a non-zero code: 1   Shell $ docker --version Docker version 1.4.1, build 5bc2ff8 ",container-file,"Docker build not working Seems like it can't `opkg-install curl`  Shell $ docker build -t weedfs . Sending build context to Docker daemon 50.78 MB Sending build context to Docker daemon Step 0 : FROM progrium/busybox Pulling repository progrium/busybox 6f114d3139e3: Download complete 511136ea3c5a: Download complete e2fb46397934: Download complete 015fb409be0d: Download complete 21082221cb6e: Download complete bbd692fe2ca1: Download complete 8db8f013bfca: Download complete 7fff0c6f0b8d: Download complete 7acf13620725: Download complete Status: Downloaded newer image for progrium/busybox:latest > 6f114d3139e3 Step 1 : WORKDIR /opt/weed > Running in 028351e07e71 > d1d57d22ef4d Removing intermediate container 028351e07e71 Step 2 : RUN opkg-install curl > Running in 2fd9079c8d42 wget: bad address 'downloads.openwrt.org' wget: bad address 'downloads.openwrt.org' Downloading http://downloads.openwrt.org/snapshots/trunk/x86_64/packages/base/Packages.gz. Downloading http://downloads.openwrt.org/snapshots/trunk/x86_64/packages/packages/Packages.gz. Collected errors: * opkg_download: Failed to download http://downloads.openwrt.org/snapshots/trunk/x86_64/packages/base/Packages.gz, wget returned 1. * opkg_download: Failed to download http://downloads.openwrt.org/snapshots/trunk/x86_64/packages/packages/Packages.gz, wget returned 1. Unknown package 'curl'. Collected errors: * opkg_install_cmd: Cannot install package curl. > 958aa12283bc Removing intermediate container 2fd9079c8d42 Step 3 : RUN echo insecure >> ~/.curlrc > Running in 576c9f7a23d3 > c39d8579e570 Removing intermediate container 576c9f7a23d3 Step 4 : RUN curl -Lks https://bintray.com$(curl -Lk http://bintray.com/chrislusf/Weed-FS/seaweed/_latestVersion | grep linux_amd64.tar.gz | sed -n ""/href/ s/.*href=['\""]\([^'\""]*\)['\""].*/\1/gp"") | gunzip | tar -xf - -C /opt/weed/ && mv weed_* bin && chmod +x ./bin/weed > Running in 5d84f61c0e11 /bin/sh: curl: not found /bin/sh: curl: not found gunzip: invalid magic tar: short read INFO[0095] The command [/bin/sh -c curl -Lks https://bintray.com$(curl -Lk http://bintray.com/chrislusf/Weed-FS/seaweed/_latestVersion | grep linux_amd64.tar.gz | sed -n ""/href/ s/.*href=['\""]\([^'\""]*\)['\""].*/\1/gp"") | gunzip | tar -xf - -C /opt/weed/ && mv weed_* bin && chmod +x ./bin/weed] returned a non-zero code: 1   Shell $ docker --version Docker version 1.4.1, build 5bc2ff8  container-file",no-bug,0.95
160,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/160,current glog module in seaweedfs can not work correctly if -log-dir is a relative directory,"When I started weed with `-log_dir=master1/`, weed created logs as follows:  lrwxrwxrwx 1 root root 63 Jul 2 09:33 weed.INFO -> master1/weed.ubuntu-blade7.root.log.INFO.20150702-093324.112469 -rw-r--r-- 1 root root 2146 Jul 2 09:34 weed.ubuntu-blade7.root.log.INFO.20150702-093324.112469  Symbol-link `weed.INFO` should not use `master1/` in its destination. I use `github.com/golang/glog`, which works correctly:  # mkdir master1 # ./test_glog -log_dir=master1/ # ll master1 total 32 drwxr-xr-x 2 root root 4096 Jul 2 14:11 ./ drwxr-xr-x 18 root root 4096 Jul 2 14:11 ../ lrwxrwxrwx 1 root root 61 Jul 2 14:11 test_glog.ERROR -> test_glog.ubuntu-blade8.root.log.ERROR.20150702-141130.180932 lrwxrwxrwx 1 root root 60 Jul 2 14:11 test_glog.INFO -> test_glog.ubuntu-blade8.root.log.INFO.20150702-141130.180932 -rw-r--r-- 1 root root 302 Jul 2 14:11 test_glog.ubuntu-blade8.root.log.ERROR.20150702-141130.180932 -rw-r--r-- 1 root root 593 Jul 2 14:11 test_glog.ubuntu-blade8.root.log.INFO.20150702-141130.180932 -rw-r--r-- 1 root root 419 Jul 2 14:11 test_glog.ubuntu-blade8.root.log.WARNING.20150702-141130.180932 lrwxrwxrwx 1 root root 63 Jul 2 14:11 test_glog.WARNING -> test_glog.ubuntu-blade8.root.log.WARNING.20150702-141130.180932 ",source-file,"current glog module in seaweedfs can not work correctly if -log-dir is a relative directory When I started weed with `-log_dir=master1/`, weed created logs as follows:  lrwxrwxrwx 1 root root 63 Jul 2 09:33 weed.INFO -> master1/weed.ubuntu-blade7.root.log.INFO.20150702-093324.112469 -rw-r--r-- 1 root root 2146 Jul 2 09:34 weed.ubuntu-blade7.root.log.INFO.20150702-093324.112469  Symbol-link `weed.INFO` should not use `master1/` in its destination. I use `github.com/golang/glog`, which works correctly:  # mkdir master1 # ./test_glog -log_dir=master1/ # ll master1 total 32 drwxr-xr-x 2 root root 4096 Jul 2 14:11 ./ drwxr-xr-x 18 root root 4096 Jul 2 14:11 ../ lrwxrwxrwx 1 root root 61 Jul 2 14:11 test_glog.ERROR -> test_glog.ubuntu-blade8.root.log.ERROR.20150702-141130.180932 lrwxrwxrwx 1 root root 60 Jul 2 14:11 test_glog.INFO -> test_glog.ubuntu-blade8.root.log.INFO.20150702-141130.180932 -rw-r--r-- 1 root root 302 Jul 2 14:11 test_glog.ubuntu-blade8.root.log.ERROR.20150702-141130.180932 -rw-r--r-- 1 root root 593 Jul 2 14:11 test_glog.ubuntu-blade8.root.log.INFO.20150702-141130.180932 -rw-r--r-- 1 root root 419 Jul 2 14:11 test_glog.ubuntu-blade8.root.log.WARNING.20150702-141130.180932 lrwxrwxrwx 1 root root 63 Jul 2 14:11 test_glog.WARNING -> test_glog.ubuntu-blade8.root.log.WARNING.20150702-141130.180932  source-file",no-bug,0.9
1093,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1093,Server disconnects when volumes become unwritable,"**Describe the bug** Time to time servers disconnect when volumes become unwritable. **System Setup** Master server command  master  Volume server command  volume -max=50 -mserver=""scrooge-weed-master:9333"" -publicUrl=""10.178.3.20:8081"" -port=8081  **Expected behavior** Servers never disconnect. **Logs** Master logs:  I1023 08:35:42 1 master_grpc_server.go:24] unregister disconnected volume server 172.16.238.50:8081 I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 5 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 5 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 5 becomes unwritable I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 3 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 3 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 3 becomes unwritable I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 4 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 4 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 4 becomes unwritable I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 2 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 2 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 2 becomes unwritable I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 1 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 1 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 1 becomes unwritable I1023 08:35:42 1 node.go:256] topo:DefaultDataCenter:DefaultRack removes 172.16.238.50:8081 I1023 08:36:02 1 node.go:241] topo:DefaultDataCenter:DefaultRack adds child 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:72] added volume server 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 5 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 3 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 4 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 2 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 1 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:148] master send to master172.16.238.75:54168: url:""172.16.238.50:8081"" public_url:""10.26.111.25:8081"" new_vids:5 new_vids:3 new_vids:4 new_vids:2 new_vids:1 I1023 08:36:02 1 master_grpc_server.go:24] unregister disconnected volume server 172.16.238.50:8081 I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 5 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 5 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 5 becomes unwritable I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 3 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 3 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 3 becomes unwritable I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 4 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 4 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 4 becomes unwritable I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 2 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 2 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 2 becomes unwritable I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 1 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 1 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 1 becomes unwritable I1023 08:36:02 1 node.go:256] topo:DefaultDataCenter:DefaultRack removes 172.16.238.50:8081 I1023 08:36:02 1 node.go:241] topo:DefaultDataCenter:DefaultRack adds child 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:72] added volume server 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 3 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 4 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 2 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 1 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 5 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:148] master send to master172.16.238.75:54168: url:""172.16.238.50:8081"" public_url:""10.26.111.25:8081"" new_vids:3 new_vids:4 new_vids:2 new_vids:1 new_vids:5  Volume logs:  I1023 08:35:57 1 volume_grpc_client_to_master.go:160] Volume Server Failed to talk with master 172.16.238.75:9333: EOF I1023 08:35:57 1 volume_grpc_client_to_master.go:45] heartbeat error: EOF I1023 08:36:02 1 volume_grpc_client_to_master.go:68] Heartbeat to: scrooge-weed-master:9333 I1023 08:36:02 1 volume_grpc_client_to_master.go:84] Volume Server found a new master newLeader: 172.16.238.75:9333 instead of scrooge-weed-master:9333 I1023 08:36:02 1 volume_grpc_client_to_master.go:68] Heartbeat to: 172.16.238.75:9333  Possible related to #499  dell  ~ weed version version 30GB 1.44 linux amd64 ",source-file,"Server disconnects when volumes become unwritable **Describe the bug** Time to time servers disconnect when volumes become unwritable. **System Setup** Master server command  master  Volume server command  volume -max=50 -mserver=""scrooge-weed-master:9333"" -publicUrl=""10.178.3.20:8081"" -port=8081  **Expected behavior** Servers never disconnect. **Logs** Master logs:  I1023 08:35:42 1 master_grpc_server.go:24] unregister disconnected volume server 172.16.238.50:8081 I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 5 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 5 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 5 becomes unwritable I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 3 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 3 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 3 becomes unwritable I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 4 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 4 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 4 becomes unwritable I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 2 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 2 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 2 becomes unwritable I1023 08:35:42 1 topology_event_handling.go:57] Removing Volume 1 from the dead volume server 172.16.238.50:8081 I1023 08:35:42 1 volume_layout.go:261] Volume 1 has 0 replica, less than required 1 I1023 08:35:42 1 volume_layout.go:237] Volume 1 becomes unwritable I1023 08:35:42 1 node.go:256] topo:DefaultDataCenter:DefaultRack removes 172.16.238.50:8081 I1023 08:36:02 1 node.go:241] topo:DefaultDataCenter:DefaultRack adds child 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:72] added volume server 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 5 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 3 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 4 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 2 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 1 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:148] master send to master172.16.238.75:54168: url:""172.16.238.50:8081"" public_url:""10.26.111.25:8081"" new_vids:5 new_vids:3 new_vids:4 new_vids:2 new_vids:1 I1023 08:36:02 1 master_grpc_server.go:24] unregister disconnected volume server 172.16.238.50:8081 I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 5 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 5 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 5 becomes unwritable I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 3 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 3 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 3 becomes unwritable I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 4 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 4 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 4 becomes unwritable I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 2 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 2 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 2 becomes unwritable I1023 08:36:02 1 topology_event_handling.go:57] Removing Volume 1 from the dead volume server 172.16.238.50:8081 I1023 08:36:02 1 volume_layout.go:261] Volume 1 has 0 replica, less than required 1 I1023 08:36:02 1 volume_layout.go:237] Volume 1 becomes unwritable I1023 08:36:02 1 node.go:256] topo:DefaultDataCenter:DefaultRack removes 172.16.238.50:8081 I1023 08:36:02 1 node.go:241] topo:DefaultDataCenter:DefaultRack adds child 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:72] added volume server 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 3 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 4 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 2 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 1 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:102] master see new volume 5 from 172.16.238.50:8081 I1023 08:36:02 1 master_grpc_server.go:148] master send to master172.16.238.75:54168: url:""172.16.238.50:8081"" public_url:""10.26.111.25:8081"" new_vids:3 new_vids:4 new_vids:2 new_vids:1 new_vids:5  Volume logs:  I1023 08:35:57 1 volume_grpc_client_to_master.go:160] Volume Server Failed to talk with master 172.16.238.75:9333: EOF I1023 08:35:57 1 volume_grpc_client_to_master.go:45] heartbeat error: EOF I1023 08:36:02 1 volume_grpc_client_to_master.go:68] Heartbeat to: scrooge-weed-master:9333 I1023 08:36:02 1 volume_grpc_client_to_master.go:84] Volume Server found a new master newLeader: 172.16.238.75:9333 instead of scrooge-weed-master:9333 I1023 08:36:02 1 volume_grpc_client_to_master.go:68] Heartbeat to: 172.16.238.75:9333  Possible related to #499  dell  ~ weed version version 30GB 1.44 linux amd64  source-file",no-bug,0.9
2966,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2966,[volume.check.disk] sync volume : rpc error: code = ResourceExhausted desc = grpc: trying to send message larger than max (1291232846 vs. 1073741824,"logs  > volume.check.disk -v -force -nonRepairThreshold 0.6 load collection logs-prod volume 567 index size 243219 from slow-volume-18.dc1:8080  load collection logs-prod volume 567 index size 243185 from slow-volume-15.dc2:8080  volume 567 slow-volume-15.dc2:8080 has 8464 entries, slow-volume-18.dc1:8080 missed 4611 entries read 567,333337663263323161 slow-volume-15.dc2:8080 => slow-volume-18.dc1:8080 read 567,383038663263323161 slow-volume-15.dc2:8080 => slow-volume-18.dc1:8080 read 567,31366163663263323161 slow-volume-15.dc2:8080 => slow-volume-18.dc1:8080 sync volume 567 on slow-volume-18.dc1.consul:8080 and slow-volume-15.dc2.consul:8080: doVolumeCheckDisk source:id:""slow-volume-15.dc2.consul:8080"" diskInfos:{} grpc_port:18080 volume 567: rpc error: code = ResourceExhausted desc = grpc: trying to send message larger than max (1291232846 vs. 1073741824) ",other-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[volume.check.disk] sync volume : rpc error: code = ResourceExhausted desc = grpc: trying to send message larger than max (1291232846 vs. 1073741824 logs  > volume.check.disk -v -force -nonRepairThreshold 0.6 load collection logs-prod volume 567 index size 243219 from slow-volume-18.dc1:8080  load collection logs-prod volume 567 index size 243185 from slow-volume-15.dc2:8080  volume 567 slow-volume-15.dc2:8080 has 8464 entries, slow-volume-18.dc1:8080 missed 4611 entries read 567,333337663263323161 slow-volume-15.dc2:8080 => slow-volume-18.dc1:8080 read 567,383038663263323161 slow-volume-15.dc2:8080 => slow-volume-18.dc1:8080 read 567,31366163663263323161 slow-volume-15.dc2:8080 => slow-volume-18.dc1:8080 sync volume 567 on slow-volume-18.dc1.consul:8080 and slow-volume-15.dc2.consul:8080: doVolumeCheckDisk source:id:""slow-volume-15.dc2.consul:8080"" diskInfos:{} grpc_port:18080 volume 567: rpc error: code = ResourceExhausted desc = grpc: trying to send message larger than max (1291232846 vs. 1073741824)  other-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
4878,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4878,Panic in lock_table_test on 32-bit,"**Describe the bug** Hello, while running the test suite of SeaweedFS 3.57 on x86, i encountered a panic in lock_table_test.go:  Now we need to generate a 256-bit key for AES 256 GCM -- Executing third function -- -- Executing first function -- -- Executing second function -- -- Third Function finished -- -- Executing fourth function -- -- Second Function finished -- -- Executing fifth function -- -- First Function finished -- 1 2 3 -- Fourth fifth finished -- -- Fourth Function finished -- 4 5 panic: unaligned 64-bit atomic operation goroutine 111 [running]: runtime/internal/atomic.panicUnaligned() runtime/internal/atomic/unaligned.go:8 +0x38 runtime/internal/atomic.Xadd64(0x58e0a15c, 0x1) runtime/internal/atomic/atomic_386.s:125 +0x11 github.com/seaweedfs/seaweedfs/weed/util.(*LockTable[]).NewActiveLock(0x56e3de00, {0x0, 0x0}, 0x1) github.com/seaweedfs/seaweedfs/weed/util/lock_table.go:47 +0x3b github.com/seaweedfs/seaweedfs/weed/util.(*LockTable[]).AcquireLock(0x56e3de00, {0x0, 0x0}, {0x56c36fc5, 0x8}, 0x1) github.com/seaweedfs/seaweedfs/weed/util/lock_table.go:63 +0x1a2 github.com/seaweedfs/seaweedfs/weed/util.TestOrderedLock.func1(0x32) github.com/seaweedfs/seaweedfs/weed/util/lock_table_test.go:27 +0xcc created by github.com/seaweedfs/seaweedfs/weed/util.TestOrderedLock in goroutine 61 github.com/seaweedfs/seaweedfs/weed/util/lock_table_test.go:18 +0x9b FAIL github.com/seaweedfs/seaweedfs/weed/util 0.130s  **System Setup** - OS version: Alpine Linux edge - Go version: 1.21.1 **Expected behavior** The test passes like it does on x86_64.",source-file | source-file,"Panic in lock_table_test on 32-bit **Describe the bug** Hello, while running the test suite of SeaweedFS 3.57 on x86, i encountered a panic in lock_table_test.go:  Now we need to generate a 256-bit key for AES 256 GCM -- Executing third function -- -- Executing first function -- -- Executing second function -- -- Third Function finished -- -- Executing fourth function -- -- Second Function finished -- -- Executing fifth function -- -- First Function finished -- 1 2 3 -- Fourth fifth finished -- -- Fourth Function finished -- 4 5 panic: unaligned 64-bit atomic operation goroutine 111 [running]: runtime/internal/atomic.panicUnaligned() runtime/internal/atomic/unaligned.go:8 +0x38 runtime/internal/atomic.Xadd64(0x58e0a15c, 0x1) runtime/internal/atomic/atomic_386.s:125 +0x11 github.com/seaweedfs/seaweedfs/weed/util.(*LockTable[]).NewActiveLock(0x56e3de00, {0x0, 0x0}, 0x1) github.com/seaweedfs/seaweedfs/weed/util/lock_table.go:47 +0x3b github.com/seaweedfs/seaweedfs/weed/util.(*LockTable[]).AcquireLock(0x56e3de00, {0x0, 0x0}, {0x56c36fc5, 0x8}, 0x1) github.com/seaweedfs/seaweedfs/weed/util/lock_table.go:63 +0x1a2 github.com/seaweedfs/seaweedfs/weed/util.TestOrderedLock.func1(0x32) github.com/seaweedfs/seaweedfs/weed/util/lock_table_test.go:27 +0xcc created by github.com/seaweedfs/seaweedfs/weed/util.TestOrderedLock in goroutine 61 github.com/seaweedfs/seaweedfs/weed/util/lock_table_test.go:18 +0x9b FAIL github.com/seaweedfs/seaweedfs/weed/util 0.130s  **System Setup** - OS version: Alpine Linux edge - Go version: 1.21.1 **Expected behavior** The test passes like it does on x86_64. source-file source-file",no-bug,0.95
1929,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1929,FUSE growing RAM footprint,"**Describe the bug** Ever growing RAM footprint of FUSE mount. Here are the files [pprof.zip](https://github.com/chrislusf/seaweedfs/files/6181826/pprof.zip) **System Setup** - `version 8000GB 2.34 9672f9e linux amd64` **Expected behavior** A smaller, non-growing RAM footprint. Or at least something that does not explode.",source-file | source-file,"FUSE growing RAM footprint **Describe the bug** Ever growing RAM footprint of FUSE mount. Here are the files [pprof.zip](https://github.com/chrislusf/seaweedfs/files/6181826/pprof.zip) **System Setup** - `version 8000GB 2.34 9672f9e linux amd64` **Expected behavior** A smaller, non-growing RAM footprint. Or at least something that does not explode. source-file source-file",no-bug,0.9
342,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/342,Chunking large files with Filer service,"I've been trying to use the large file / chunking feature. Should this work with the Filer service, or is it only supported when using the direct API? Thanks! Mike",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Chunking large files with Filer service I've been trying to use the large file / chunking feature. Should this work with the Filer service, or is it only supported when using the direct API? Thanks! Mike source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.7
3128,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3128,Volumes not created on pristine fast/slow drive setup,"**Describe the bug** no active volumes are generated on a pristine fast/slow disk setup. **System Setup** Master:  usr/local/sbin/weed master -ip.bind 0.0.0.0 -ip 10.11.11.182 \ -defaultReplication 000 \ -volumeSizeLimitMB 1024 \ -mdir /srv/data_fast/weed.dei.privat/master \ -volumePreallocate  Volume:  /usr/local/sbin/weed volume -port 8080 -publicUrl http://weed.dei.privat -max 100 \ -ip.bind 0.0.0.0 -ip 10.11.11.182 \ -mserver 10.11.11.182:9333 \ -disk hdd,ssd -dir /srv/data/weed.dei.privat/volume,/srv/data_fast/weed.dei.privat/volume \ -compactionMBps 30 -minFreeSpace 1 -dataCenter DefaultDataCenter -rack DefaultRack  Filer:  /usr/local/sbin/weed filer -port 8888 -ip.bind 0.0.0.0 -ip 10.11.11.182 \ -master 10.11.11.182:9333 \ -dataCenter DefaultDataCenter -rack DefaultRack \ -s3 -s3.config=/srv/data/weed.dei.privat/.seaweedfs/s3.json  Status-Data:  > cluster.ps the cluster has 1 filers * 10.11.11.182:8888 (30GB 3.07 fbd99d53c1e45ef12c49ad1ec043c918f4da94e8) signature: 411477689 > cluster.check Topology volumeSizeLimit:1024 MB hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) error: Need to a hdd disk type! > fs.configure { } > volume.list Topology volumeSizeLimit:1024 MB hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) DataCenter DefaultDataCenter hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) Rack DefaultRack hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) DataNode 10.11.11.182:8080 hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) Disk hdd(volume:0/100 active:0 free:100 remote:0) Disk hdd total size:0 file_count:0 Disk ssd(volume:0/100 active:0 free:100 remote:0) Disk ssd total size:0 file_count:0 DataNode 10.11.11.182:8080 total size:0 file_count:0 Rack DefaultRack total size:0 file_count:0 DataCenter DefaultDataCenter total size:0 file_count:0 total size:0 file_count:0 >  - OS version Debian 11 bullseye - output of `weed version` version 30GB 3.07 fbd99d53c1e45ef12c49ad1ec043c918f4da94e8 linux amd64 also on latest 3.06, 30GB - if using filer, show the content of `filer.toml` none **Expected behavior** like in singe volume setup before, Volumes get generated and used. **Additional context** I'm modifying an ansible role to setup a one-host weed-cluster, running in a LXContainer (@proxmox). the filer with 2 mounted host-zfs-drives, with two diff. TAGs. Always removing the old setup before rerun. While using only on drive, everything works as expected. when using two drives, no volumes get created. in the one volume setup, only `/srv/data/weed.dei.privat/volume,` was used. no `-disk` option. two disk setup: first try: -disk ssd,nvme -dir /srv/data/weed.dei.privat/volume,/srv/data_fast/weed.dei.privat/volume according to my misinterpretation of the error message (s.u.) from 'cluster.check': `error: Need to a hdd disk type!`, I changed to: -disk hdd,ssd -dir /srv/data/weed.dei.privat/volume,/srv/data_fast/weed.dei.privat/volume with out effect Dir-structure on /srv/  tree */weed.dei.* -L 3 data_fast/weed.dei.privat  master   conf   log   snapshot  volume  vol_dir.uuid data/weed.dei.privat  filer   filerldb2   00   01   02   03   04   05   06   07  volume  vol_dir.uuid ",source-file,"Volumes not created on pristine fast/slow drive setup **Describe the bug** no active volumes are generated on a pristine fast/slow disk setup. **System Setup** Master:  usr/local/sbin/weed master -ip.bind 0.0.0.0 -ip 10.11.11.182 \ -defaultReplication 000 \ -volumeSizeLimitMB 1024 \ -mdir /srv/data_fast/weed.dei.privat/master \ -volumePreallocate  Volume:  /usr/local/sbin/weed volume -port 8080 -publicUrl http://weed.dei.privat -max 100 \ -ip.bind 0.0.0.0 -ip 10.11.11.182 \ -mserver 10.11.11.182:9333 \ -disk hdd,ssd -dir /srv/data/weed.dei.privat/volume,/srv/data_fast/weed.dei.privat/volume \ -compactionMBps 30 -minFreeSpace 1 -dataCenter DefaultDataCenter -rack DefaultRack  Filer:  /usr/local/sbin/weed filer -port 8888 -ip.bind 0.0.0.0 -ip 10.11.11.182 \ -master 10.11.11.182:9333 \ -dataCenter DefaultDataCenter -rack DefaultRack \ -s3 -s3.config=/srv/data/weed.dei.privat/.seaweedfs/s3.json  Status-Data:  > cluster.ps the cluster has 1 filers * 10.11.11.182:8888 (30GB 3.07 fbd99d53c1e45ef12c49ad1ec043c918f4da94e8) signature: 411477689 > cluster.check Topology volumeSizeLimit:1024 MB hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) error: Need to a hdd disk type! > fs.configure { } > volume.list Topology volumeSizeLimit:1024 MB hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) DataCenter DefaultDataCenter hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) Rack DefaultRack hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) DataNode 10.11.11.182:8080 hdd(volume:0/100 active:0 free:100 remote:0) ssd(volume:0/100 active:0 free:100 remote:0) Disk hdd(volume:0/100 active:0 free:100 remote:0) Disk hdd total size:0 file_count:0 Disk ssd(volume:0/100 active:0 free:100 remote:0) Disk ssd total size:0 file_count:0 DataNode 10.11.11.182:8080 total size:0 file_count:0 Rack DefaultRack total size:0 file_count:0 DataCenter DefaultDataCenter total size:0 file_count:0 total size:0 file_count:0 >  - OS version Debian 11 bullseye - output of `weed version` version 30GB 3.07 fbd99d53c1e45ef12c49ad1ec043c918f4da94e8 linux amd64 also on latest 3.06, 30GB - if using filer, show the content of `filer.toml` none **Expected behavior** like in singe volume setup before, Volumes get generated and used. **Additional context** I'm modifying an ansible role to setup a one-host weed-cluster, running in a LXContainer (@proxmox). the filer with 2 mounted host-zfs-drives, with two diff. TAGs. Always removing the old setup before rerun. While using only on drive, everything works as expected. when using two drives, no volumes get created. in the one volume setup, only `/srv/data/weed.dei.privat/volume,` was used. no `-disk` option. two disk setup: first try: -disk ssd,nvme -dir /srv/data/weed.dei.privat/volume,/srv/data_fast/weed.dei.privat/volume according to my misinterpretation of the error message (s.u.) from 'cluster.check': `error: Need to a hdd disk type!`, I changed to: -disk hdd,ssd -dir /srv/data/weed.dei.privat/volume,/srv/data_fast/weed.dei.privat/volume with out effect Dir-structure on /srv/  tree */weed.dei.* -L 3 data_fast/weed.dei.privat  master   conf   log   snapshot  volume  vol_dir.uuid data/weed.dei.privat  filer   filerldb2   00   01   02   03   04   05   06   07  volume  vol_dir.uuid  source-file",no-bug,0.9
14,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/14,expose http GET only,"Is there currently a way to expose the GET resource separately from the other GETs & POSTs? ie: I would like to (publicly) provide access to  GET http://server1.example.com:8080/3,238ceaa9a7  but not to  POST http://server1.example.com:8080/3,238ceaa9a7  nor  GET http://server1.example.com:8080/status (etc)  Right now my alternatives seem to be: - iptable string matching (which doesn't seem very fun) - proxy server (extra hop + defeats the purpose of fully concurrent reads) I think a reasonable solution would be to provide some alternative ip:port binding for just the resource GETs.",source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file,"expose http GET only Is there currently a way to expose the GET resource separately from the other GETs & POSTs? ie: I would like to (publicly) provide access to  GET http://server1.example.com:8080/3,238ceaa9a7  but not to  POST http://server1.example.com:8080/3,238ceaa9a7  nor  GET http://server1.example.com:8080/status (etc)  Right now my alternatives seem to be: - iptable string matching (which doesn't seem very fun) - proxy server (extra hop + defeats the purpose of fully concurrent reads) I think a reasonable solution would be to provide some alternative ip:port binding for just the resource GETs. source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file",no-bug,0.8
5417,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5417,[volume] panic: runtime error: invalid memory address or nil pointer dereference,"**Describe the bug**  [signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0x19f879b] github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).VolumeStatus(0xc0009c3440, {0xc006921680?, 0x569e86?}, 0xc006921680) /builds/infrastructure/utils/storage/seaweedfs/weed/server/volume_grpc_admin.go:240 +0x5b github.com/seaweedfs/seaweedfs/weed/pb/volume_server_pb._VolumeServer_VolumeStatus_Handler({0x23627e0?, 0xc0009c3440}, {0x2a3d320, 0xc0069> /builds/infrastructure/utils/storage/seaweedfs/weed/pb/volume_server_pb/volume_server_grpc.pb.go:1216 +0x16c google.golang.org/grpc.(*Server).processUnaryRPC(0xc0006f0c00, {0x2a3d320, 0xc006921440}, {0x2a4ab00, 0xc000cf61a0}, 0xc0034f87e0, 0xc0008> /go/pkg/mod/google.golang.org/grpc@v1.60.1/server.go:1372 +0xe03 google.golang.org/grpc.(*Server).handleStream(0xc0006f0c00, {0x2a4ab00, 0xc000cf61a0}, 0xc0034f87e0) /go/pkg/mod/google.golang.org/grpc@v1.60.1/server.go:1783 +0xfec google.golang.org/grpc.(*Server).serveStreams.func2.1() /go/pkg/mod/google.golang.org/grpc@v1.60.1/server.go:1016 +0x59 created by google.golang.org/grpc.(*Server).serveStreams.func2 in goroutine 33267022 /go/pkg/mod/google.golang.org/grpc@v1.60.1/server.go:1027 +0x115 seaweedfs-volume60.service: Main process exited, code=exited, status=2/INVALIDARGUMENT seaweedfs-volume60.service: Failed with result 'exit-code'.  **System Setup**  weed version version 8000GB 3.62 a1d3f756 linux amd64 ",source-file,"[volume] panic: runtime error: invalid memory address or nil pointer dereference **Describe the bug**  [signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0x19f879b] github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).VolumeStatus(0xc0009c3440, {0xc006921680?, 0x569e86?}, 0xc006921680) /builds/infrastructure/utils/storage/seaweedfs/weed/server/volume_grpc_admin.go:240 +0x5b github.com/seaweedfs/seaweedfs/weed/pb/volume_server_pb._VolumeServer_VolumeStatus_Handler({0x23627e0?, 0xc0009c3440}, {0x2a3d320, 0xc0069> /builds/infrastructure/utils/storage/seaweedfs/weed/pb/volume_server_pb/volume_server_grpc.pb.go:1216 +0x16c google.golang.org/grpc.(*Server).processUnaryRPC(0xc0006f0c00, {0x2a3d320, 0xc006921440}, {0x2a4ab00, 0xc000cf61a0}, 0xc0034f87e0, 0xc0008> /go/pkg/mod/google.golang.org/grpc@v1.60.1/server.go:1372 +0xe03 google.golang.org/grpc.(*Server).handleStream(0xc0006f0c00, {0x2a4ab00, 0xc000cf61a0}, 0xc0034f87e0) /go/pkg/mod/google.golang.org/grpc@v1.60.1/server.go:1783 +0xfec google.golang.org/grpc.(*Server).serveStreams.func2.1() /go/pkg/mod/google.golang.org/grpc@v1.60.1/server.go:1016 +0x59 created by google.golang.org/grpc.(*Server).serveStreams.func2 in goroutine 33267022 /go/pkg/mod/google.golang.org/grpc@v1.60.1/server.go:1027 +0x115 seaweedfs-volume60.service: Main process exited, code=exited, status=2/INVALIDARGUMENT seaweedfs-volume60.service: Failed with result 'exit-code'.  **System Setup**  weed version version 8000GB 3.62 a1d3f756 linux amd64  source-file",no-bug,0.9
5153,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5153,Filer v3.60: panic: runtime error: invalid memory address or nil pointer dereference,"**Describe the bug** I upgraded the platform from 3.59 to 3.60, everything seems to work fine, only the filers will not start. I get the error:  panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2747a75]  I've no issues when I do a rollback to 3.59 **System Setup** * weed masters: - version 8000GB 3.60 d4e91b6ad9cda07c9ad790e82593caba975cc8e8 linux amd64 - /usr/local/bin/weed -v=4 -logdir=/data/logs/master master -mdir=/data/seaweedfs/master -ip=10.0.9.17 -port=9333 -peers=10.0.9.17:9333,10.0.9.17:9334,10.0.9.17:9335 -metrics.address=192.168.2.17:9091 -defaultReplication=002 -volumePreallocate - /usr/local/bin/weed -v=3 -logdir=/data/logs/master2 master -mdir=/data/seaweedfs/master2 -ip=10.0.9.17 -port=9334 -peers=10.0.9.17:9333,10.0.9.17:9334,10.0.9.17:9335 -metrics.address=10.0.9.17:9091 -defaultReplication=002 -volumePreallocate - /usr/local/bin/weed -v=3 -logdir=/data/logs/master3 master -mdir=/data/seaweedfs/master3 -ip=10.0.9.17 -port=9335 -peers=10.0.9.17:9333,10.0.9.17:9334,10.0.9.17:9335 -metrics.address=10.0.9.17:9091 -defaultReplication=002 -volumePreallocate * weed volumes ( 7 servers ): - version 8000GB 3.60 d4e91b6ad9cda07c9ad790e82593caba975cc8e8 linux amd64 - /usr/local/bin/weed -v=4 -logdir=/data/logs volume -index=leveldb -mserver=10.0.9.17:9333,,10.0.9.17:9334,10.0.9.17:9335 -dir=/data/volumes/b31a481e9f10,/data/volumes/b58e1eeceb47,/data/volumes/db1fe9e78843,/data/volumes/095ed4389bae,/data/volumes/5efb87c6c49a,/data/volumes/3a0cf7f47b2c,/data/volumes/31f3abfafbfe,/data/volumes/b1a03d59f5af,/data/volumes/94abb1a088a6,/data/volumes/bdcb41df6f4e,/data/volumes/2fec28eff631,/data/volumes/8767ac0c4ef5,/data/volumes/db5243c4ff56,/data/volumes/cea31e3f1f7c,/data/volumes/7e524df6cc6e,/data/volumes/483c153731ed,/data/volumes/65aeae444f8a,/data/volumes/cd4a26bfd638,/data/volumes/d2c55ab877e5,/data/volumes/1e49b8543ba6,/data/volumes/68e9f111d0be,/data/volumes/7f43f61f3e29,/data/volumes/a1de5bfdc104,/data/volumes/eaadda777b85,/data/volumes/2653fead368a,/data/volumes/268b8d365eca,/data/volumes/f66ce8dc1c89,/data/volumes/221eca264652,/data/volumes/0dcc7bc3e8cf,/data/volumes/f500845c7c10,/data/volumes/ff8b2a740a99,/data/volumes/65ccfe3439c3,/data/volumes/4046c9008a57,/data/volumes/4e952b1360c0,/data/volumes/be44b201038b,/data/volumes/47ff61529c59,/data/volumes/101cefa28717,/data/volumes/441e19fddd26,/data/volumes/3e825a5f09b5,/data/volumes/6e609c3c3b11,/data/volumes/bb8ea974e2f8,/data/volumes/3b9bf86dc069,/data/volumes/4c947e27c295,/data/volumes/ec5273d113eb,/data/volumes/3c79dd433faa,/data/volumes/ab00a1f9af77,/data/volumes/ba59f13eac18,/data/volumes/f80513da9ce2,/data/volumes/d2ef6dc2aca6,/data/volumes/f2671a03ebae,/data/volumes/8b314b6694b0,/data/volumes/72cc4054836d,/data/volumes/73ab2c752dcb,/data/volumes/7948242749c0,/data/volumes/a55accfcf3cb,/data/volumes/d8d0b4f55a77,/data/volumes/6bedb541df1a,/data/volumes/4993a9c7eaea,/data/volumes/164e2943aabe,/data/volumes/159c9c5d6665,/data/volumes/4f619c60c18c,/data/volumes/d6562d823d51,/data/volumes/1e174630b4e8,/data/volumes/f34e1e9b5854,/data/volumes/ad0b8ab46dcf,/data/volumes/758fab37bc7c,/data/volumes/79286864603b,/data/volumes/810d48b78c5f,/data/volumes/2de4da264c67,/data/volumes/ba981f1d4fc4,/data/volumes/6bcf6998cb9c,/data/volumes/f7624ded9880,/data/volumes/b0a6b3997448,/data/volumes/679665018276,/data/volumes/8800e6bfe5f6,/data/volumes/63361210035b,/data/volumes/7776dadcabf9,/data/volumes/e1ec38933a0b,/data/volumes/489209d183e4,/data/volumes/c3a76626c40d,/data/volumes/8758c57b0fcd,/data/volumes/81f18074dd47,/data/volumes/8ce731230e6f,/data/volumes/9946f0de1fb4,/data/volumes/a854cf4bb686,/data/volumes/fe273af5bcff,/data/volumes/4784d55dbe64,/data/volumes/add9fce8011a,/data/volumes/9d757ab0dd18,/data/volumes/2d269829b67c,/data/volumes/b56f2c990bbe,/data/volumes/4fead3377ee6,/data/volumes/40865ee79135,/data/volumes/1eecbde0ca92,/data/volumes/81879145f7ef,/data/volumes/e74266795999,/data/volumes/24e7391a3059,/data/volumes/b04afa283b69,/data/volumes/7db00666fab5,/data/volumes/ce420ed08e92,/data/volumes/4b280ce7fd2d,/data/volumes/9b9d483f6b36,/data/volumes/e53405e1d819,/data/volumes/584ae3fb50cb,/data/volumes/8956416d95d9,/data/volumes/a065387d42d1,/data/volumes/200892ba9a67,/data/volumes/a7ebaee1c3b5 -max=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 -concurrentDownloadLimitMB=16384 -concurrentUploadLimitMB=16384 -hasSlowRead=true * weed filers (4 servers): - version 8000GB 3.60 d4e91b6ad9cda07c9ad790e82593caba975cc8e8 linux amd64 - /usr/local/bin/weed -v=4 -logdir=/data/logs filer -master=10.0.9.17:9333,10.0.9.17:9334,10.0.9.17:9335 -s3 - filer.toml   # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false #max_file_name_length = 255 [cassandra] # CREATE TABLE filemeta ( # directory varchar, # name varchar, # meta blob, # PRIMARY KEY (directory, name) # ) WITH CLUSTERING ORDER BY (name ASC); enabled = true keyspace = ""seaweedfs"" hosts = [ ""192.168.2.21:9042"", ""192.168.2.22:9042"", ""192.168.2.23:9042"", ] username = """" password = """" # This changes the data layout. Only add new directories. Removing/Updating will cause data loss. superLargeDirectories = [] # Name of the datacenter local to this filer, used as host selection fallback. localDC = """" # Gocql connection timeout, default: 600ms connection_timeout_millisecond = 600  * OS Version (all servers): - Debian GNU/Linux 10 (buster) - Linux node02 4.19.0-25-amd64 #1 SMP Debian 4.19.289-2 (2023-08-08) x86_64 GNU/Linux **Expected behavior** After the upgrade I start weed filer application, it only crashes on startup (on all 4 filer servers). I don't have this issue with the previous version. **Additional context** logging of version: version 8000GB 3.60 d4e91b6ad9cda07c9ad790e82593caba975cc8e8 linux amd64    Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849438 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 2572 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849447 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 4235 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849456 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 560 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849464 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 1127 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849472 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 721 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849480 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 2 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849487 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 3615 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849498 masterclient.go:294 updateVidMap(DefaultDataCenter) .filer: 10.0.9.1:8080 volume add: 5616, del: 0, add ec: 0 del ec: 0 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849585 masterclient.go:247 + filer@192.168.2.12:8888 noticed .filer 192.168.2.12:8888 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.046867 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.2.12:8888 start from 2024-01-02 14:28:57.306787028 +0100 CET 1704202137306787028 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.048901 meta_aggregator.go:189 subscribing remote 192.168.2.12:8888 meta change: 2024-01-02 14:28:57.306787028 +0100 CET, clientId:150394752 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.049627 filer_grpc_server_sub_meta.go:296 + local listener filer:192.168.2.12:8888@192.168.2.12:42514 clientId -150394752 clientEpoch 1 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.049654 filer_grpc_server_sub_meta.go:117 + filer:192.168.2.12:8888@192.168.2.12:42514 local subscribe / from 2024-01-02 14:28:57.306787028 +0100 CET clientId:-150394752 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.049673 filer_grpc_server_sub_meta.go:130 read on disk filer:192.168.2.12:8888@192.168.2.12:42514 local subscribe / from 2024-01-02 14:28:57.306787028 +0100 CET Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.072442 filer_grpc_server_sub_meta.go:149 read in memory filer:192.168.2.12:8888@192.168.2.12:42514 local subscribe / from 2024-01-02 14:28:57.306787028 +0100 CET Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.096790 s3.go:202 S3 read filer buckets dir: /buckets Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.096822 s3.go:209 connected to filer 192.168.2.12:8888 grpc address 192.168.2.12:18888 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.096925 metrics.go:277 s3 server sends metrics to 10.0.9.17:9091 every 15 seconds Jan 2 14:29:59 node02 seaweedfs-filer[18835]: panic: runtime error: invalid memory address or nil pointer dereference Jan 2 14:29:59 node02 seaweedfs-filer[18835]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2747a75] Jan 2 14:29:59 node02 seaweedfs-filer[18835]: goroutine 99 [running]: Jan 2 14:29:59 node02 seaweedfs-filer[18835]: github.com/seaweedfs/seaweedfs/weed/command.(*S3Options).startS3Server(0x5343500) Jan 2 14:29:59 node02 seaweedfs-filer[18835]: #011/github/workspace/weed/command/s3.go:226 +0x495 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: github.com/seaweedfs/seaweedfs/weed/command.runFiler.func1(0x0?) Jan 2 14:29:59 node02 seaweedfs-filer[18835]: #011/github/workspace/weed/command/filer.go:185 +0x26 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: created by github.com/seaweedfs/seaweedfs/weed/command.runFiler in goroutine 1 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: #011/github/workspace/weed/command/filer.go:183 +0x2aa Jan 2 14:29:59 node02 systemd[1]: seaweedfiler.service: Main process exited, code=exited, status=2/INVALIDARGUMENT Jan 2 14:29:59 node02 systemd[1]: seaweedfiler.service: Failed with result 'exit-code'. root@node02:/data/logs#  Logging of version: version 8000GB 3.59 27b34f37935fb3eddb9c7759acf397dbae20eb03 linux amd64    Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993826 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 2664 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993833 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 1255 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993841 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 6596 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993848 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 1491 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993856 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 4393 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993864 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 3797 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993876 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 721 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993884 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 2 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993891 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 3615 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993901 masterclient.go:294 updateVidMap(DefaultDataCenter) .filer: 10.0.9.7:8080 volume add: 3425, del: 0, add ec: 0 del ec: 0 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993989 masterclient.go:247 + filer@192.168.2.12:8888 noticed .filer 192.168.2.12:8888 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.354939 s3.go:199 S3 read filer buckets dir: /buckets Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.354962 s3.go:206 connected to filer 192.168.2.12:8888 grpc address 192.168.2.12:18888 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.355096 metrics.go:278 s3 server sends metrics to 10.0.9.17:9091 every 15 seconds Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.358030 s3api_circuit_breaker.go:35 s3 circuit breaker not configured Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.361678 s3.go:350 Start Seaweed S3 API Server 8000GB 3.59 27b34f37935fb3eddb9c7759acf397dbae20eb03 at http port 8333 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.362375 filer_grpc_server_sub_meta.go:296 + listener s3@192.168.2.12:38064 clientId -586500568 clientEpoch 2 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.362399 filer_grpc_server_sub_meta.go:36 s3@192.168.2.12:38064 starts to subscribe /etc/ from 2024-01-02 14:32:57.361181409 +0100 CET Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.373332 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.2.12:8888 start from 2024-01-02 14:31:55.596143708 +0100 CET 1704202315596143708 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.374653 meta_aggregator.go:189 subscribing remote 192.168.2.12:8888 meta change: 2024-01-02 14:31:55.596143708 +0100 CET, clientId:771085792 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.375750 filer_grpc_server_sub_meta.go:296 + local listener filer:192.168.2.12:8888@192.168.2.12:38078 clientId -771085792 clientEpoch 1 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.375770 filer_grpc_server_sub_meta.go:117 + filer:192.168.2.12:8888@192.168.2.12:38078 local subscribe / from 2024-01-02 14:31:55.596143708 +0100 CET clientId:-771085792 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.375790 filer_grpc_server_sub_meta.go:130 read on disk filer:192.168.2.12:8888@192.168.2.12:38078 local subscribe / from 2024-01-02 14:31:55.596143708 +0100 CET Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.394722 filer_grpc_server_sub_meta.go:149 read in memory filer:192.168.2.12:8888@192.168.2.12:38078 local subscribe / from 2024-01-02 14:31:55.596143708 +0100 CET Jan 2 14:33:19 node02 seaweedfs-filer[4463]: I0102 14:33:19.014458 http_util.go:439 request leftover 1 bytes root@node02:/data/logs# ",source-file,"Filer v3.60: panic: runtime error: invalid memory address or nil pointer dereference **Describe the bug** I upgraded the platform from 3.59 to 3.60, everything seems to work fine, only the filers will not start. I get the error:  panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2747a75]  I've no issues when I do a rollback to 3.59 **System Setup** * weed masters: - version 8000GB 3.60 d4e91b6ad9cda07c9ad790e82593caba975cc8e8 linux amd64 - /usr/local/bin/weed -v=4 -logdir=/data/logs/master master -mdir=/data/seaweedfs/master -ip=10.0.9.17 -port=9333 -peers=10.0.9.17:9333,10.0.9.17:9334,10.0.9.17:9335 -metrics.address=192.168.2.17:9091 -defaultReplication=002 -volumePreallocate - /usr/local/bin/weed -v=3 -logdir=/data/logs/master2 master -mdir=/data/seaweedfs/master2 -ip=10.0.9.17 -port=9334 -peers=10.0.9.17:9333,10.0.9.17:9334,10.0.9.17:9335 -metrics.address=10.0.9.17:9091 -defaultReplication=002 -volumePreallocate - /usr/local/bin/weed -v=3 -logdir=/data/logs/master3 master -mdir=/data/seaweedfs/master3 -ip=10.0.9.17 -port=9335 -peers=10.0.9.17:9333,10.0.9.17:9334,10.0.9.17:9335 -metrics.address=10.0.9.17:9091 -defaultReplication=002 -volumePreallocate * weed volumes ( 7 servers ): - version 8000GB 3.60 d4e91b6ad9cda07c9ad790e82593caba975cc8e8 linux amd64 - /usr/local/bin/weed -v=4 -logdir=/data/logs volume -index=leveldb -mserver=10.0.9.17:9333,,10.0.9.17:9334,10.0.9.17:9335 -dir=/data/volumes/b31a481e9f10,/data/volumes/b58e1eeceb47,/data/volumes/db1fe9e78843,/data/volumes/095ed4389bae,/data/volumes/5efb87c6c49a,/data/volumes/3a0cf7f47b2c,/data/volumes/31f3abfafbfe,/data/volumes/b1a03d59f5af,/data/volumes/94abb1a088a6,/data/volumes/bdcb41df6f4e,/data/volumes/2fec28eff631,/data/volumes/8767ac0c4ef5,/data/volumes/db5243c4ff56,/data/volumes/cea31e3f1f7c,/data/volumes/7e524df6cc6e,/data/volumes/483c153731ed,/data/volumes/65aeae444f8a,/data/volumes/cd4a26bfd638,/data/volumes/d2c55ab877e5,/data/volumes/1e49b8543ba6,/data/volumes/68e9f111d0be,/data/volumes/7f43f61f3e29,/data/volumes/a1de5bfdc104,/data/volumes/eaadda777b85,/data/volumes/2653fead368a,/data/volumes/268b8d365eca,/data/volumes/f66ce8dc1c89,/data/volumes/221eca264652,/data/volumes/0dcc7bc3e8cf,/data/volumes/f500845c7c10,/data/volumes/ff8b2a740a99,/data/volumes/65ccfe3439c3,/data/volumes/4046c9008a57,/data/volumes/4e952b1360c0,/data/volumes/be44b201038b,/data/volumes/47ff61529c59,/data/volumes/101cefa28717,/data/volumes/441e19fddd26,/data/volumes/3e825a5f09b5,/data/volumes/6e609c3c3b11,/data/volumes/bb8ea974e2f8,/data/volumes/3b9bf86dc069,/data/volumes/4c947e27c295,/data/volumes/ec5273d113eb,/data/volumes/3c79dd433faa,/data/volumes/ab00a1f9af77,/data/volumes/ba59f13eac18,/data/volumes/f80513da9ce2,/data/volumes/d2ef6dc2aca6,/data/volumes/f2671a03ebae,/data/volumes/8b314b6694b0,/data/volumes/72cc4054836d,/data/volumes/73ab2c752dcb,/data/volumes/7948242749c0,/data/volumes/a55accfcf3cb,/data/volumes/d8d0b4f55a77,/data/volumes/6bedb541df1a,/data/volumes/4993a9c7eaea,/data/volumes/164e2943aabe,/data/volumes/159c9c5d6665,/data/volumes/4f619c60c18c,/data/volumes/d6562d823d51,/data/volumes/1e174630b4e8,/data/volumes/f34e1e9b5854,/data/volumes/ad0b8ab46dcf,/data/volumes/758fab37bc7c,/data/volumes/79286864603b,/data/volumes/810d48b78c5f,/data/volumes/2de4da264c67,/data/volumes/ba981f1d4fc4,/data/volumes/6bcf6998cb9c,/data/volumes/f7624ded9880,/data/volumes/b0a6b3997448,/data/volumes/679665018276,/data/volumes/8800e6bfe5f6,/data/volumes/63361210035b,/data/volumes/7776dadcabf9,/data/volumes/e1ec38933a0b,/data/volumes/489209d183e4,/data/volumes/c3a76626c40d,/data/volumes/8758c57b0fcd,/data/volumes/81f18074dd47,/data/volumes/8ce731230e6f,/data/volumes/9946f0de1fb4,/data/volumes/a854cf4bb686,/data/volumes/fe273af5bcff,/data/volumes/4784d55dbe64,/data/volumes/add9fce8011a,/data/volumes/9d757ab0dd18,/data/volumes/2d269829b67c,/data/volumes/b56f2c990bbe,/data/volumes/4fead3377ee6,/data/volumes/40865ee79135,/data/volumes/1eecbde0ca92,/data/volumes/81879145f7ef,/data/volumes/e74266795999,/data/volumes/24e7391a3059,/data/volumes/b04afa283b69,/data/volumes/7db00666fab5,/data/volumes/ce420ed08e92,/data/volumes/4b280ce7fd2d,/data/volumes/9b9d483f6b36,/data/volumes/e53405e1d819,/data/volumes/584ae3fb50cb,/data/volumes/8956416d95d9,/data/volumes/a065387d42d1,/data/volumes/200892ba9a67,/data/volumes/a7ebaee1c3b5 -max=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 -concurrentDownloadLimitMB=16384 -concurrentUploadLimitMB=16384 -hasSlowRead=true * weed filers (4 servers): - version 8000GB 3.60 d4e91b6ad9cda07c9ad790e82593caba975cc8e8 linux amd64 - /usr/local/bin/weed -v=4 -logdir=/data/logs filer -master=10.0.9.17:9333,10.0.9.17:9334,10.0.9.17:9335 -s3 - filer.toml   # Customizable filer server options  [filer.options] # with http DELETE, by default the filer would check whether a folder is empty. # recursive_delete will delete all sub folders and files, similar to ""rm -Rf"" recursive_delete = false #max_file_name_length = 255 [cassandra] # CREATE TABLE filemeta ( # directory varchar, # name varchar, # meta blob, # PRIMARY KEY (directory, name) # ) WITH CLUSTERING ORDER BY (name ASC); enabled = true keyspace = ""seaweedfs"" hosts = [ ""192.168.2.21:9042"", ""192.168.2.22:9042"", ""192.168.2.23:9042"", ] username = """" password = """" # This changes the data layout. Only add new directories. Removing/Updating will cause data loss. superLargeDirectories = [] # Name of the datacenter local to this filer, used as host selection fallback. localDC = """" # Gocql connection timeout, default: 600ms connection_timeout_millisecond = 600  * OS Version (all servers): - Debian GNU/Linux 10 (buster) - Linux node02 4.19.0-25-amd64 #1 SMP Debian 4.19.289-2 (2023-08-08) x86_64 GNU/Linux **Expected behavior** After the upgrade I start weed filer application, it only crashes on startup (on all 4 filer servers). I don't have this issue with the previous version. **Additional context** logging of version: version 8000GB 3.60 d4e91b6ad9cda07c9ad790e82593caba975cc8e8 linux amd64    Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849438 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 2572 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849447 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 4235 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849456 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 560 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849464 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 1127 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849472 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 721 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849480 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 2 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849487 masterclient.go:279 .filer: 10.0.9.1:8080 masterClient adds volume 3615 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849498 masterclient.go:294 updateVidMap(DefaultDataCenter) .filer: 10.0.9.1:8080 volume add: 5616, del: 0, add ec: 0 del ec: 0 Jan 2 14:29:58 node02 seaweedfs-filer[18835]: I0102 14:29:58.849585 masterclient.go:247 + filer@192.168.2.12:8888 noticed .filer 192.168.2.12:8888 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.046867 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.2.12:8888 start from 2024-01-02 14:28:57.306787028 +0100 CET 1704202137306787028 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.048901 meta_aggregator.go:189 subscribing remote 192.168.2.12:8888 meta change: 2024-01-02 14:28:57.306787028 +0100 CET, clientId:150394752 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.049627 filer_grpc_server_sub_meta.go:296 + local listener filer:192.168.2.12:8888@192.168.2.12:42514 clientId -150394752 clientEpoch 1 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.049654 filer_grpc_server_sub_meta.go:117 + filer:192.168.2.12:8888@192.168.2.12:42514 local subscribe / from 2024-01-02 14:28:57.306787028 +0100 CET clientId:-150394752 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.049673 filer_grpc_server_sub_meta.go:130 read on disk filer:192.168.2.12:8888@192.168.2.12:42514 local subscribe / from 2024-01-02 14:28:57.306787028 +0100 CET Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.072442 filer_grpc_server_sub_meta.go:149 read in memory filer:192.168.2.12:8888@192.168.2.12:42514 local subscribe / from 2024-01-02 14:28:57.306787028 +0100 CET Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.096790 s3.go:202 S3 read filer buckets dir: /buckets Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.096822 s3.go:209 connected to filer 192.168.2.12:8888 grpc address 192.168.2.12:18888 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: I0102 14:29:59.096925 metrics.go:277 s3 server sends metrics to 10.0.9.17:9091 every 15 seconds Jan 2 14:29:59 node02 seaweedfs-filer[18835]: panic: runtime error: invalid memory address or nil pointer dereference Jan 2 14:29:59 node02 seaweedfs-filer[18835]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2747a75] Jan 2 14:29:59 node02 seaweedfs-filer[18835]: goroutine 99 [running]: Jan 2 14:29:59 node02 seaweedfs-filer[18835]: github.com/seaweedfs/seaweedfs/weed/command.(*S3Options).startS3Server(0x5343500) Jan 2 14:29:59 node02 seaweedfs-filer[18835]: #011/github/workspace/weed/command/s3.go:226 +0x495 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: github.com/seaweedfs/seaweedfs/weed/command.runFiler.func1(0x0?) Jan 2 14:29:59 node02 seaweedfs-filer[18835]: #011/github/workspace/weed/command/filer.go:185 +0x26 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: created by github.com/seaweedfs/seaweedfs/weed/command.runFiler in goroutine 1 Jan 2 14:29:59 node02 seaweedfs-filer[18835]: #011/github/workspace/weed/command/filer.go:183 +0x2aa Jan 2 14:29:59 node02 systemd[1]: seaweedfiler.service: Main process exited, code=exited, status=2/INVALIDARGUMENT Jan 2 14:29:59 node02 systemd[1]: seaweedfiler.service: Failed with result 'exit-code'. root@node02:/data/logs#  Logging of version: version 8000GB 3.59 27b34f37935fb3eddb9c7759acf397dbae20eb03 linux amd64    Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993826 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 2664 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993833 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 1255 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993841 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 6596 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993848 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 1491 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993856 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 4393 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993864 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 3797 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993876 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 721 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993884 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 2 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993891 masterclient.go:279 .filer: 10.0.9.7:8080 masterClient adds volume 3615 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993901 masterclient.go:294 updateVidMap(DefaultDataCenter) .filer: 10.0.9.7:8080 volume add: 3425, del: 0, add ec: 0 del ec: 0 Jan 2 14:32:56 node02 seaweedfs-filer[4463]: I0102 14:32:56.993989 masterclient.go:247 + filer@192.168.2.12:8888 noticed .filer 192.168.2.12:8888 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.354939 s3.go:199 S3 read filer buckets dir: /buckets Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.354962 s3.go:206 connected to filer 192.168.2.12:8888 grpc address 192.168.2.12:18888 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.355096 metrics.go:278 s3 server sends metrics to 10.0.9.17:9091 every 15 seconds Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.358030 s3api_circuit_breaker.go:35 s3 circuit breaker not configured Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.361678 s3.go:350 Start Seaweed S3 API Server 8000GB 3.59 27b34f37935fb3eddb9c7759acf397dbae20eb03 at http port 8333 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.362375 filer_grpc_server_sub_meta.go:296 + listener s3@192.168.2.12:38064 clientId -586500568 clientEpoch 2 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.362399 filer_grpc_server_sub_meta.go:36 s3@192.168.2.12:38064 starts to subscribe /etc/ from 2024-01-02 14:32:57.361181409 +0100 CET Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.373332 meta_aggregator.go:92 loopSubscribeToOneFiler read 192.168.2.12:8888 start from 2024-01-02 14:31:55.596143708 +0100 CET 1704202315596143708 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.374653 meta_aggregator.go:189 subscribing remote 192.168.2.12:8888 meta change: 2024-01-02 14:31:55.596143708 +0100 CET, clientId:771085792 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.375750 filer_grpc_server_sub_meta.go:296 + local listener filer:192.168.2.12:8888@192.168.2.12:38078 clientId -771085792 clientEpoch 1 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.375770 filer_grpc_server_sub_meta.go:117 + filer:192.168.2.12:8888@192.168.2.12:38078 local subscribe / from 2024-01-02 14:31:55.596143708 +0100 CET clientId:-771085792 Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.375790 filer_grpc_server_sub_meta.go:130 read on disk filer:192.168.2.12:8888@192.168.2.12:38078 local subscribe / from 2024-01-02 14:31:55.596143708 +0100 CET Jan 2 14:32:57 node02 seaweedfs-filer[4463]: I0102 14:32:57.394722 filer_grpc_server_sub_meta.go:149 read in memory filer:192.168.2.12:8888@192.168.2.12:38078 local subscribe / from 2024-01-02 14:31:55.596143708 +0100 CET Jan 2 14:33:19 node02 seaweedfs-filer[4463]: I0102 14:33:19.014458 http_util.go:439 request leftover 1 bytes root@node02:/data/logs#  source-file",no-bug,0.9
780,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/780,volume had run out of disk space but still write successfully,"**Describe the bug** Version: 1.08 one master, one volume( -max=100) volume's dir is in the mount path whose disk space is 500GB, when volume run out of disk space but not reach the volume limit size, master can assgin fileid and volume write needle successfully. And use the fileid to retreive the uploaded content, volume server return not found. **System Setup** weed master -port=9333 -defaultReplication=000 weed volume -port=8080 -max=100 -dir=/mnt/weed/volume **Expected behavior** When volume dir run out of disk space, write needle should return err",source-file | source-file | source-file | source-file,"volume had run out of disk space but still write successfully **Describe the bug** Version: 1.08 one master, one volume( -max=100) volume's dir is in the mount path whose disk space is 500GB, when volume run out of disk space but not reach the volume limit size, master can assgin fileid and volume write needle successfully. And use the fileid to retreive the uploaded content, volume server return not found. **System Setup** weed master -port=9333 -defaultReplication=000 weed volume -port=8080 -max=100 -dir=/mnt/weed/volume **Expected behavior** When volume dir run out of disk space, write needle should return err source-file source-file source-file source-file",no-bug,0.9
6379,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6379,S3 DeleteMultipleObjectsHandler does not honour AllowEmptyFolder setting,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** When running the S3 DeleteMultipleObjectsHandler function, the setting ""AllowEmptyFolder"" is not honoured. In circumstances where the filer folders are mistakenly identified as being empty, this causes the entire bucket contents to be deleted. **System Setup** - We setup an integrated Filer + S3 handler, using ""leveldb2"" driver - Photon Linux 5 - Weed version 3.79 **Expected behavior** When AllowEmptyFolder setting is set to true, only the items specified in the DeleteMultipleObjectsHandler call should have been deleted. **Additional context** The environment on which this runs is suspected to have very slow disk access, which we believe to be the cause for the folders being identified as empty.",source-file | source-file,"S3 DeleteMultipleObjectsHandler does not honour AllowEmptyFolder setting Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** When running the S3 DeleteMultipleObjectsHandler function, the setting ""AllowEmptyFolder"" is not honoured. In circumstances where the filer folders are mistakenly identified as being empty, this causes the entire bucket contents to be deleted. **System Setup** - We setup an integrated Filer + S3 handler, using ""leveldb2"" driver - Photon Linux 5 - Weed version 3.79 **Expected behavior** When AllowEmptyFolder setting is set to true, only the items specified in the DeleteMultipleObjectsHandler call should have been deleted. **Additional context** The environment on which this runs is suspected to have very slow disk access, which we believe to be the cause for the folders being identified as empty. source-file source-file",bug,0.85
4532,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4532,Update to using Go-Redis v9,"Go-Redis has updated to v9 and is now an official Redis client. The import statements need to be updated to take advantage of the new release and future ones as well. Old v8: `import ""github.com/go-redis/redis/v8""` New v9: `import ""github.com/redis/go-redis/v9""` The blog post announcing the change can be found at https://redis.com/blog/go-redis-official-redis-client/.",other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Update to using Go-Redis v9 Go-Redis has updated to v9 and is now an official Redis client. The import statements need to be updated to take advantage of the new release and future ones as well. Old v8: `import ""github.com/go-redis/redis/v8""` New v9: `import ""github.com/redis/go-redis/v9""` The blog post announcing the change can be found at https://redis.com/blog/go-redis-official-redis-client/. other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
2753,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2753,Configurable configuration dir,"I'd like to use podman secrets to manage the `filer.toml`, but the secret files are always mounted under `/run/secret/` and there seems to be no way to add a config path, looking at https://github.com/chrislusf/seaweedfs/blob/dce1f02c9efcf78f05e7f81f3cc116e594591642/weed/util/config.go#L20-L27",source-file,"Configurable configuration dir I'd like to use podman secrets to manage the `filer.toml`, but the secret files are always mounted under `/run/secret/` and there seems to be no way to add a config path, looking at https://github.com/chrislusf/seaweedfs/blob/dce1f02c9efcf78f05e7f81f3cc116e594591642/weed/util/config.go#L20-L27 source-file",no-bug,0.9
3453,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3453,Empty buckets with out-TTLed data report EiB data sizes,"**Describe the bug** We are using buckets in a rolling manner. Our app creates per day or per hour buckets with fixed TTL. After TTL is expired, whole data from the bucket is wiped, so it doesn't contain any volumes in it. But `SeaweedFS_volumeServer_total_disk_size` metric reports EiB sizes. **Expected behavior** Metric should report 0 for empty buckets **Screenshots** ![image](https://user-images.githubusercontent.com/3438036/184947358-1fcff65c-7f0a-45f7-96c2-ea48237b965d.png) ![image](https://user-images.githubusercontent.com/3438036/184947174-4581008a-2d94-4fee-a738-75cac2b744e4.png)",source-file,"Empty buckets with out-TTLed data report EiB data sizes **Describe the bug** We are using buckets in a rolling manner. Our app creates per day or per hour buckets with fixed TTL. After TTL is expired, whole data from the bucket is wiped, so it doesn't contain any volumes in it. But `SeaweedFS_volumeServer_total_disk_size` metric reports EiB sizes. **Expected behavior** Metric should report 0 for empty buckets **Screenshots** ![image](https://user-images.githubusercontent.com/3438036/184947358-1fcff65c-7f0a-45f7-96c2-ea48237b965d.png) ![image](https://user-images.githubusercontent.com/3438036/184947174-4581008a-2d94-4fee-a738-75cac2b744e4.png) source-file",no-bug,0.8
4934,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4934,volume.configure.replication seems to not work,"**Describe the bug** When using volume.configure.replication, the actual volume files still retain their old configuration. **Test case** Start a weed master (defaultReplication=020) and 3 volume servers:  weed master -defaultReplication=020 weed volume -port=8081 -dir=/tmp/volume1 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack1 weed volume -port=8082 -dir=/tmp/volume2 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack2 weed volume -port=8083 -dir=/tmp/volume3 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack3  Create some volumes:  curl http://localhost:9333/dir/assign  It should look like this: ![Screenshot from 2023-10-23 16-49-42](https://github.com/seaweedfs/seaweedfs/assets/7746192/e9eea85c-6f77-4d12-9b48-740d0cd94c59) Now, let's change the replication settings using weed shell:  weed shell volume.configure.replication -collectionPattern * -replication 010  The volume servers correctly show the change in the logs:  I1023 14:52:01.272205 disk_location.go:182 data file /tmp/volume2/1.dat, replication=010 v=3 size=8 ttl=  The API also thinks, it is changed:  $ curl http://localhost:9333/vol/status?pretty=y|grep ""ReplicaPlacement"" -A 2 ""ReplicaPlacement"": { ""rack"": 1 },  But when we look at the .dat files using `change_superblock.go`, we see that it is still 020:  $ go run change_superblock.go -volumeId=1 -dir=/tmp/volume1 Current Volume Replication: 020 Current Volume TTL:  Just to make sure, we run some tests. First, we fix the replication:  $ weed shell lock volume.fix.replication > volume 2 replication 010, but over replicated +3 > volume 3 replication 010, but over replicated +3 > volume 1 replication 010, but over replicated +3 > deleting volume 2 from 10.23.1.43:8083  > deleting volume 3 from 10.23.1.43:8083  > deleting volume 1 from 10.23.1.43:8083   Looks good. We now have 2 copies of every volume file: ![Screenshot from 2023-10-23 16-58-31](https://github.com/seaweedfs/seaweedfs/assets/7746192/58ec1a28-2cde-4d3d-a590-127338fcd9ca) If we delete one and fix replication again, it should add it back.  weed shell lock volume.delete -node 10.23.1.43:8081 -volumeId 1 volume.fix.replication > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > error: replicas volume 1 mismatch in topology  It did restore the missing copy but showed the error `error: replicas volume 1 mismatch in topology`. The volume server log shows that it added the volume with replication 020:  I1023 15:03:29.264620 disk_location.go:182 data file /tmp/volume3/1.dat, replication=020 v=3 size=8 ttl=  If we query the API, it now also shows replication 020 for the restored copy:  curl http://localhost:9333/vol/status?pretty=y|grep ""ReplicaPlacement"" -A 2 ""ReplicaPlacement"": { ""rack"": 1 }, ""ReplicaPlacement"": { ""rack"": 2 },  **System Setup** - Ubuntu 22.04 - output of `weed version`: version 30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559 linux amd64 **Expected behavior** `volume.configure.replication` changes the replication setting in the volume files.",source-file | source-file | source-file,"volume.configure.replication seems to not work **Describe the bug** When using volume.configure.replication, the actual volume files still retain their old configuration. **Test case** Start a weed master (defaultReplication=020) and 3 volume servers:  weed master -defaultReplication=020 weed volume -port=8081 -dir=/tmp/volume1 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack1 weed volume -port=8082 -dir=/tmp/volume2 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack2 weed volume -port=8083 -dir=/tmp/volume3 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack3  Create some volumes:  curl http://localhost:9333/dir/assign  It should look like this: ![Screenshot from 2023-10-23 16-49-42](https://github.com/seaweedfs/seaweedfs/assets/7746192/e9eea85c-6f77-4d12-9b48-740d0cd94c59) Now, let's change the replication settings using weed shell:  weed shell volume.configure.replication -collectionPattern * -replication 010  The volume servers correctly show the change in the logs:  I1023 14:52:01.272205 disk_location.go:182 data file /tmp/volume2/1.dat, replication=010 v=3 size=8 ttl=  The API also thinks, it is changed:  $ curl http://localhost:9333/vol/status?pretty=y|grep ""ReplicaPlacement"" -A 2 ""ReplicaPlacement"": { ""rack"": 1 },  But when we look at the .dat files using `change_superblock.go`, we see that it is still 020:  $ go run change_superblock.go -volumeId=1 -dir=/tmp/volume1 Current Volume Replication: 020 Current Volume TTL:  Just to make sure, we run some tests. First, we fix the replication:  $ weed shell lock volume.fix.replication > volume 2 replication 010, but over replicated +3 > volume 3 replication 010, but over replicated +3 > volume 1 replication 010, but over replicated +3 > deleting volume 2 from 10.23.1.43:8083  > deleting volume 3 from 10.23.1.43:8083  > deleting volume 1 from 10.23.1.43:8083   Looks good. We now have 2 copies of every volume file: ![Screenshot from 2023-10-23 16-58-31](https://github.com/seaweedfs/seaweedfs/assets/7746192/58ec1a28-2cde-4d3d-a590-127338fcd9ca) If we delete one and fix replication again, it should add it back.  weed shell lock volume.delete -node 10.23.1.43:8081 -volumeId 1 volume.fix.replication > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > error: replicas volume 1 mismatch in topology  It did restore the missing copy but showed the error `error: replicas volume 1 mismatch in topology`. The volume server log shows that it added the volume with replication 020:  I1023 15:03:29.264620 disk_location.go:182 data file /tmp/volume3/1.dat, replication=020 v=3 size=8 ttl=  If we query the API, it now also shows replication 020 for the restored copy:  curl http://localhost:9333/vol/status?pretty=y|grep ""ReplicaPlacement"" -A 2 ""ReplicaPlacement"": { ""rack"": 1 }, ""ReplicaPlacement"": { ""rack"": 2 },  **System Setup** - Ubuntu 22.04 - output of `weed version`: version 30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559 linux amd64 **Expected behavior** `volume.configure.replication` changes the replication setting in the volume files. source-file source-file source-file",bug,0.9
409,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/409,seaweedfs should support 0-size file uploading and downloading,"Now, 0-size text file can be uploaded and download successfully. But, 0-size jpg file(or other not isGzippable()) can not be uploaded, report `{""name"":""empty.doc"",""error"":""Failed to write to local disk""}`. I suggest seaweedfs should support 0-size all format file unploading and downloading, or return `400 bad request` when being uploaded. 0-size text file uploaded successfully:  # curl -F file=@empty.txt 192.168.4.18:28083/45,6c8916e496119e -v * Hostname was NOT found in DNS cache * Trying 192.168.4.18 * Connected to 192.168.4.18 (192.168.4.18) port 28083 (#0) > POST /45,6c8916e496119e HTTP/1.1 > User-Agent: curl/7.35.0 > Host: 192.168.4.18:28083 > Accept: */* > Content-Length: 187 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=bcba47b57757d366 > < HTTP/1.1 100 Continue < HTTP/1.1 201 Created < Content-Type: application/json < Date: Tue, 06 Dec 2016 07:34:49 GMT < Content-Length: 30 < * Connection #0 to host 192.168.4.18 left intact {""name"":""empty.txt"",""size"":23}  0-size doc file uploaded unsuccessfully:  # curl -F file=@empty.doc 192.168.4.18:28083/45,6c8916e496119e -v * Hostname was NOT found in DNS cache * Trying 192.168.4.18 * Connected to 192.168.4.18 (192.168.4.18) port 28083 (#0) > POST /45,6c8916e496119e HTTP/1.1 > User-Agent: curl/7.35.0 > Host: 192.168.4.18:28083 > Accept: */* > Content-Length: 201 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=8228c550c48374e5 > < HTTP/1.1 100 Continue < HTTP/1.1 500 Internal Server Error < Content-Type: application/json < Date: Tue, 06 Dec 2016 07:30:34 GMT < Content-Length: 60 * HTTP error before end of send, stop sending < * Closing connection 0 {""name"":""empty.doc"",""error"":""Failed to write to local disk""} ",source-file,"seaweedfs should support 0-size file uploading and downloading Now, 0-size text file can be uploaded and download successfully. But, 0-size jpg file(or other not isGzippable()) can not be uploaded, report `{""name"":""empty.doc"",""error"":""Failed to write to local disk""}`. I suggest seaweedfs should support 0-size all format file unploading and downloading, or return `400 bad request` when being uploaded. 0-size text file uploaded successfully:  # curl -F file=@empty.txt 192.168.4.18:28083/45,6c8916e496119e -v * Hostname was NOT found in DNS cache * Trying 192.168.4.18 * Connected to 192.168.4.18 (192.168.4.18) port 28083 (#0) > POST /45,6c8916e496119e HTTP/1.1 > User-Agent: curl/7.35.0 > Host: 192.168.4.18:28083 > Accept: */* > Content-Length: 187 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=bcba47b57757d366 > < HTTP/1.1 100 Continue < HTTP/1.1 201 Created < Content-Type: application/json < Date: Tue, 06 Dec 2016 07:34:49 GMT < Content-Length: 30 < * Connection #0 to host 192.168.4.18 left intact {""name"":""empty.txt"",""size"":23}  0-size doc file uploaded unsuccessfully:  # curl -F file=@empty.doc 192.168.4.18:28083/45,6c8916e496119e -v * Hostname was NOT found in DNS cache * Trying 192.168.4.18 * Connected to 192.168.4.18 (192.168.4.18) port 28083 (#0) > POST /45,6c8916e496119e HTTP/1.1 > User-Agent: curl/7.35.0 > Host: 192.168.4.18:28083 > Accept: */* > Content-Length: 201 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=8228c550c48374e5 > < HTTP/1.1 100 Continue < HTTP/1.1 500 Internal Server Error < Content-Type: application/json < Date: Tue, 06 Dec 2016 07:30:34 GMT < Content-Length: 60 * HTTP error before end of send, stop sending < * Closing connection 0 {""name"":""empty.doc"",""error"":""Failed to write to local disk""}  source-file",bug,0.95
524,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/524,hanged when run weed master,"  tmp git:(master)  weed master -peers 10.64.7.106:9444,10.4.23.114:9444,10.4.23.115:9444 -ip 10.64.7.106 -ip.bind 10.64.7.106 -port 9444 I0703 19:46:40 39010 file_util.go:20] Folder /tmp Permission: -rwxrwxrwx I0703 19:46:40 39010 master_server.go:62] Volume Size Limit is 30000 MB I0703 19:46:40 39010 master.go:87] Start Seaweed Master 0.76 at 10.64.7.106:9444 I0703 19:46:40 39010 raft_server.go:56] Peers Change: [] => [10.64.7.106:9444 10.4.23.114:9444 10.4.23.115:9444] I0703 19:46:40 39010 raft_server.go:78] Joining cluster: 10.64.7.106:9444,10.4.23.114:9444,10.4.23.115:9444 I0703 19:46:41 39010 raft_server.go:166] Attempting to connect to: http://10.4.23.114:9444/cluster/join  using browser open this url , crashed.  2017/07/03 19:47:13 http: panic serving 10.232.4.175:59240: runtime error: invalid memory address or nil pointer dereference goroutine 55 [running]: net/http.(*conn).serve.func1(0xc4202d6140) /home/jinlei1/os/go/src/net/http/server.go:1721 +0xd0 panic(0xbab320, 0x10782f0) /home/jinlei1/os/go/src/runtime/panic.go:489 +0x2cf github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).uiStatusHandler(0xc4201e2380, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/chrislusf/seaweedfs/weed/server/master_server_handlers_ui.go:24 +0x13b github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).(github.com/chrislusf/seaweedfs/weed/server.uiStatusHandler)-fm(0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/chrislusf/seaweedfs/weed/server/master_server.go:66 +0x48 net/http.HandlerFunc.ServeHTTP(0xc4201c7010, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/os/go/src/net/http/server.go:1942 +0x44 github.com/gorilla/mux.(*Router).ServeHTTP(0xc4201ce960, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/gorilla/mux/mux.go:114 +0x10c net/http.serverHandler.ServeHTTP(0xc4202049a0, 0x1047400, 0xc42030a000, 0xc4202de300) /home/jinlei1/os/go/src/net/http/server.go:2568 +0x92 net/http.(*conn).serve(0xc4202d6140, 0x1047f00, 0xc4202b0340) /home/jinlei1/os/go/src/net/http/server.go:1825 +0x612 created by net/http.(*Server).Serve /home/jinlei1/os/go/src/net/http/server.go:2668 +0x2ce ",source-file | source-file,"hanged when run weed master   tmp git:(master)  weed master -peers 10.64.7.106:9444,10.4.23.114:9444,10.4.23.115:9444 -ip 10.64.7.106 -ip.bind 10.64.7.106 -port 9444 I0703 19:46:40 39010 file_util.go:20] Folder /tmp Permission: -rwxrwxrwx I0703 19:46:40 39010 master_server.go:62] Volume Size Limit is 30000 MB I0703 19:46:40 39010 master.go:87] Start Seaweed Master 0.76 at 10.64.7.106:9444 I0703 19:46:40 39010 raft_server.go:56] Peers Change: [] => [10.64.7.106:9444 10.4.23.114:9444 10.4.23.115:9444] I0703 19:46:40 39010 raft_server.go:78] Joining cluster: 10.64.7.106:9444,10.4.23.114:9444,10.4.23.115:9444 I0703 19:46:41 39010 raft_server.go:166] Attempting to connect to: http://10.4.23.114:9444/cluster/join  using browser open this url , crashed.  2017/07/03 19:47:13 http: panic serving 10.232.4.175:59240: runtime error: invalid memory address or nil pointer dereference goroutine 55 [running]: net/http.(*conn).serve.func1(0xc4202d6140) /home/jinlei1/os/go/src/net/http/server.go:1721 +0xd0 panic(0xbab320, 0x10782f0) /home/jinlei1/os/go/src/runtime/panic.go:489 +0x2cf github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).uiStatusHandler(0xc4201e2380, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/chrislusf/seaweedfs/weed/server/master_server_handlers_ui.go:24 +0x13b github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).(github.com/chrislusf/seaweedfs/weed/server.uiStatusHandler)-fm(0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/chrislusf/seaweedfs/weed/server/master_server.go:66 +0x48 net/http.HandlerFunc.ServeHTTP(0xc4201c7010, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/os/go/src/net/http/server.go:1942 +0x44 github.com/gorilla/mux.(*Router).ServeHTTP(0xc4201ce960, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/gorilla/mux/mux.go:114 +0x10c net/http.serverHandler.ServeHTTP(0xc4202049a0, 0x1047400, 0xc42030a000, 0xc4202de300) /home/jinlei1/os/go/src/net/http/server.go:2568 +0x92 net/http.(*conn).serve(0xc4202d6140, 0x1047f00, 0xc4202b0340) /home/jinlei1/os/go/src/net/http/server.go:1825 +0x612 created by net/http.(*Server).Serve /home/jinlei1/os/go/src/net/http/server.go:2668 +0x2ce  source-file source-file",bug,0.9
90,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/90,"i uploaded tar.gz file but when i downloaded this file, size is different","i uploaded tar.gz file but when i downloaded this file, size is different maybe i think this files is untar.",source-file,"i uploaded tar.gz file but when i downloaded this file, size is different i uploaded tar.gz file but when i downloaded this file, size is different maybe i think this files is untar. source-file",no-bug,0.7
3407,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3407,[stats] weed mount displays wrong data in output.,"**Describe the bug** weed mounts statistics displayed via df command doesn't respond to real data from volume server. We have 2 volume servers with 13 10Gb volumes on each and replication 010. According to the weed shell volume.list we use around 70Gb on each data node: `DataNode 10.120.214.8:8080 total size:70776755152 file_count:39229 deleted_file:4238 deleted_bytes:297263094` `DataNode 10.120.214.7:8080 total size:70799440000 file_count:39684 deleted_file:4689 deleted_bytes:315723235` On client: `df -h /mnt/app Filesystem Size Used Avail Use% Mounted on 10.120.214.8:8988+10.120.214.7:8988:/ 260G -8.0Z -2.7G 100% /mnt/app` **System Setup** 1. master: /usr/local/bin/weed -v=1 -logdir=/var/log/seaweedfs/master master -peers=10.120.214.8:9333,10.120.214.7:9333,10.120.214.9:9333 -ip=10.120.214.7 -defaultReplication=010 -mdir=/opt/seaweedfs/master/meta -volumeSizeLimitMB=10240 -resumeState=true -ip.bind=0.0.0.0 2. volume: /usr/local/bin/weed -v=1 -logdir=/var/log/seaweedfs/volume volume -mserver=10.120.214.8:9333,10.120.214.7:9333,10.120.214.9:9333 -ip=10.120.214.7 -port=8080 -rack=rack2 -dataCenter=dc1 -index=leveldb -dir=/mnt/seaweedfs -max=0 -ip.bind=0.0.0.0 3. filer: /usr/local/bin/weed -v=1 -logdir=/var/log/seaweedfs/filer filer -master=10.120.214.8:9333,10.120.214.7:9333,10.120.214.9:9333 -ip=10.120.214.7 -rack=rack2 -dataCenter=dc1 -collection=default -maxMB=4 -saveToFilerLimit=0 -defaultReplicaPlacement=010 -encryptVolumeData=true -ip.bind=0.0.0.0 4. mount: weed fuse /mnt/app -o rw,nodev,nosuid,allowOthers=true,dataCenter=dc1,collection=default,concurrentWriters=128,readRetryTime=30s,filer='10.120.214.8:8988,10.120.214.7:8988',cacheDir=/var/cache/seaweedfs/mnt-app,cacheCapacityMB=0,filer.path=/ -o child - OS version: Oracle Linux Server 8.6 - version 30GB 3.14 3c79c770562ef4f7c0d4e57a88f616eb3671b9cd linux amd64 - filer.toml  [filer.options] recursive_delete = false [leveldb2] enabled = true dir = ""/opt/seaweedfs/filer""  **Expected behavior** https://seaweedfs.slack.com/archives/C9MGUC1UG/p1659665309805189?thread_ts=1659633210.439099&cid=C9MGUC1UG 26 x 10GB - usedBytes = freeSpace 260Gb - 70Gb * 2 = 120Gb So df should display around 120 Gb of free space.",source-file,"[stats] weed mount displays wrong data in output. **Describe the bug** weed mounts statistics displayed via df command doesn't respond to real data from volume server. We have 2 volume servers with 13 10Gb volumes on each and replication 010. According to the weed shell volume.list we use around 70Gb on each data node: `DataNode 10.120.214.8:8080 total size:70776755152 file_count:39229 deleted_file:4238 deleted_bytes:297263094` `DataNode 10.120.214.7:8080 total size:70799440000 file_count:39684 deleted_file:4689 deleted_bytes:315723235` On client: `df -h /mnt/app Filesystem Size Used Avail Use% Mounted on 10.120.214.8:8988+10.120.214.7:8988:/ 260G -8.0Z -2.7G 100% /mnt/app` **System Setup** 1. master: /usr/local/bin/weed -v=1 -logdir=/var/log/seaweedfs/master master -peers=10.120.214.8:9333,10.120.214.7:9333,10.120.214.9:9333 -ip=10.120.214.7 -defaultReplication=010 -mdir=/opt/seaweedfs/master/meta -volumeSizeLimitMB=10240 -resumeState=true -ip.bind=0.0.0.0 2. volume: /usr/local/bin/weed -v=1 -logdir=/var/log/seaweedfs/volume volume -mserver=10.120.214.8:9333,10.120.214.7:9333,10.120.214.9:9333 -ip=10.120.214.7 -port=8080 -rack=rack2 -dataCenter=dc1 -index=leveldb -dir=/mnt/seaweedfs -max=0 -ip.bind=0.0.0.0 3. filer: /usr/local/bin/weed -v=1 -logdir=/var/log/seaweedfs/filer filer -master=10.120.214.8:9333,10.120.214.7:9333,10.120.214.9:9333 -ip=10.120.214.7 -rack=rack2 -dataCenter=dc1 -collection=default -maxMB=4 -saveToFilerLimit=0 -defaultReplicaPlacement=010 -encryptVolumeData=true -ip.bind=0.0.0.0 4. mount: weed fuse /mnt/app -o rw,nodev,nosuid,allowOthers=true,dataCenter=dc1,collection=default,concurrentWriters=128,readRetryTime=30s,filer='10.120.214.8:8988,10.120.214.7:8988',cacheDir=/var/cache/seaweedfs/mnt-app,cacheCapacityMB=0,filer.path=/ -o child - OS version: Oracle Linux Server 8.6 - version 30GB 3.14 3c79c770562ef4f7c0d4e57a88f616eb3671b9cd linux amd64 - filer.toml  [filer.options] recursive_delete = false [leveldb2] enabled = true dir = ""/opt/seaweedfs/filer""  **Expected behavior** https://seaweedfs.slack.com/archives/C9MGUC1UG/p1659665309805189?thread_ts=1659633210.439099&cid=C9MGUC1UG 26 x 10GB - usedBytes = freeSpace 260Gb - 70Gb * 2 = 120Gb So df should display around 120 Gb of free space. source-file",no-bug,0.9
3745,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3745,No local caching of files/chunks on fuse mount,"**Describe the bug** When using ""./weed mount"", the system does not seem to use local caching of the files/chunks only the metadata is cached. Meaning no matter how many times I load/access the same file back-to-back it takes the same time as opposed to only having to pull it from the network once, and after that having fast access from some local on disk cache. This happens with all files I have tried (the range was from 1kb all the way to 10GB), so I do not think it is only a file size issue. Looking at the cacheDir, it looks like only metadata is being downloaded or kept as even when accessing several files over 1GB the files in cacheDir are only in the kilobytes. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version: Redhat Enterprise Linux 7.9 - output of `weed version`: version 30GB 3.29 1ffb1e696e1f651c6294fc34c86b9abb6db1985d linux amd64 - if using filer, show the content of `filer.toml`: using Filer, but did not make a ""filer.toml"" - security.toml: exactly as in wiki, certs made with certstrap - '3 masters set up with: `./weed server -dir=/seaweedFS/ -master.defaultReplication=010 -filer -master.peers=s2.seaweed.swf.local:9333,s3.seaweed.swf.local:9333 -ip.bind=0.0.0.0 -ip=s1.seaweed.swf.local -rack=rack01 -dataCenter=dc1 -master.volumePreallocate &` - one test mount set up with: `sudo ./weed mount -filer=s1.seaweed.swf.local:8888,s2.seaweed.swf.local:8888,s3.seaweed.swf.local:8888 -dir=/seaweed-vol/ -filer.path=/ -cacheCapacityMB=25000 -cacheDir=/var/tmp &` **Expected behavior** Remote file that have been recently accessed should be cached for faster access, and subsequent access attempts should be near to the speed of local disk access. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** I am testing seaweedfs to see if it can be a good replacement for NFS but with added redundancy and security. looking at my data",source-file | source-file,"No local caching of files/chunks on fuse mount **Describe the bug** When using ""./weed mount"", the system does not seem to use local caching of the files/chunks only the metadata is cached. Meaning no matter how many times I load/access the same file back-to-back it takes the same time as opposed to only having to pull it from the network once, and after that having fast access from some local on disk cache. This happens with all files I have tried (the range was from 1kb all the way to 10GB), so I do not think it is only a file size issue. Looking at the cacheDir, it looks like only metadata is being downloaded or kept as even when accessing several files over 1GB the files in cacheDir are only in the kilobytes. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version: Redhat Enterprise Linux 7.9 - output of `weed version`: version 30GB 3.29 1ffb1e696e1f651c6294fc34c86b9abb6db1985d linux amd64 - if using filer, show the content of `filer.toml`: using Filer, but did not make a ""filer.toml"" - security.toml: exactly as in wiki, certs made with certstrap - '3 masters set up with: `./weed server -dir=/seaweedFS/ -master.defaultReplication=010 -filer -master.peers=s2.seaweed.swf.local:9333,s3.seaweed.swf.local:9333 -ip.bind=0.0.0.0 -ip=s1.seaweed.swf.local -rack=rack01 -dataCenter=dc1 -master.volumePreallocate &` - one test mount set up with: `sudo ./weed mount -filer=s1.seaweed.swf.local:8888,s2.seaweed.swf.local:8888,s3.seaweed.swf.local:8888 -dir=/seaweed-vol/ -filer.path=/ -cacheCapacityMB=25000 -cacheDir=/var/tmp &` **Expected behavior** Remote file that have been recently accessed should be cached for faster access, and subsequent access attempts should be near to the speed of local disk access. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** I am testing seaweedfs to see if it can be a good replacement for NFS but with added redundancy and security. looking at my data source-file source-file",no-bug,0.9
5,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5,ReadTheDocs documentation,"Move docs to RTD and extend them with docker examples (This issue is for me, if you want - add me to collaborators and assign it to me)",config-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | other-file | other-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | documentation-file | documentation-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | source-file | config-file | config-file | config-file | config-file | config-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"ReadTheDocs documentation Move docs to RTD and extend them with docker examples (This issue is for me, if you want - add me to collaborators and assign it to me) config-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file other-file other-file test-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file documentation-file documentation-file other-file documentation-file documentation-file documentation-file documentation-file config-file other-file config-file source-file source-file config-file config-file config-file config-file config-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
3524,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3524,[filer] DATA RACE on access to OnPeerUpdate, filer_1 | I0826 11:10:02.084243 iam.go:62 wait to connect to filer 172.19.0.8:8888 grpc address 172.19.0.8:18888 filer_1 | I0826 11:10:02.266301 filer.go:130 existing filer.store.id = 2082541780 filer_1 | I0826 11:10:02.266389 configuration.go:28 configured filer store to leveldb2 filer_1 | I0826 11:10:02.271345 master_client.go:20 the cluster has 1 filer filer_1 |  filer_1 | WARNING: DATA RACE filer_1 | Write at 0x00c00018ab38 by main goroutine: filer_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).AggregateFromPeers() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:99 +0x1b1 filer_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:173 +0x1897 filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | filer_1 | Previous read at 0x00c00018ab38 by goroutine 181: filer_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:222 +0x1bc4 filer_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 filer_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 filer_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 filer_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:154 +0x27e filer_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:144 +0x151 filer_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:108 +0x129 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 filer_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39 filer_1 | filer_1 | Goroutine 181 (running) created at: filer_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0xee4 filer_1 | github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:227 +0xcf7 filer_1 | github.com/seaweedfs/seaweedfs/weed/command.runFiler() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x8ba filer_1 | main.main() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 filer_1 |   https://github.com/seaweedfs/seaweedfs/issues/3507,source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,[filer] DATA RACE on access to OnPeerUpdate  filer_1 | I0826 11:10:02.084243 iam.go:62 wait to connect to filer 172.19.0.8:8888 grpc address 172.19.0.8:18888 filer_1 | I0826 11:10:02.266301 filer.go:130 existing filer.store.id = 2082541780 filer_1 | I0826 11:10:02.266389 configuration.go:28 configured filer store to leveldb2 filer_1 | I0826 11:10:02.271345 master_client.go:20 the cluster has 1 filer filer_1 |  filer_1 | WARNING: DATA RACE filer_1 | Write at 0x00c00018ab38 by main goroutine: filer_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).AggregateFromPeers() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:99 +0x1b1 filer_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:173 +0x1897 filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseNamePtr() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:666 +0x15a filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func1() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:332 +0xed filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta.func2() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:356 +0x124 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).GetMeta() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:407 +0x579 filer_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:140 +0xfd filer_1 | github.com/syndtr/goleveldb/leveldb.Open() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 filer_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | fmt.(*ss).doScanf() filer_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe filer_1 | github.com/syndtr/goleveldb/leveldb.openDB() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 filer_1 | fmt.Fscanf() filer_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 filer_1 | fmt.Sscanf() filer_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 filer_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() filer_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e filer_1 | filer_1 | Previous read at 0x00c00018ab38 by goroutine 181: filer_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:222 +0x1bc4 filer_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 filer_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 filer_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 filer_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:154 +0x27e filer_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:144 +0x151 filer_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:108 +0x129 filer_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 filer_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39 filer_1 | filer_1 | Goroutine 181 (running) created at: filer_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0xee4 filer_1 | github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:227 +0xcf7 filer_1 | github.com/seaweedfs/seaweedfs/weed/command.runFiler() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x8ba filer_1 | main.main() filer_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 filer_1 |   https://github.com/seaweedfs/seaweedfs/issues/3507 source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.95
3,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3,Fix travis-ci badge,"You will need to sign up to https://travis-ci.org/ With your github account Go to your profile Sync with you repos Switch ""on"" chrislusf/weed-fs If you will have questions or difficulties - feel free to ask. P.s. currently build is failing due to compile-time error",other-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | config-file | config-file | config-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | container-file | config-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file,"Fix travis-ci badge You will need to sign up to https://travis-ci.org/ With your github account Go to your profile Sync with you repos Switch ""on"" chrislusf/weed-fs If you will have questions or difficulties - feel free to ask. P.s. currently build is failing due to compile-time error other-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file config-file config-file config-file source-file source-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file container-file config-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file",no-bug,0.95
632,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/632,"weed upload command in windows upload a file and download it, the filename is file_id","in windows when upload a file using weed upload command, the filename is an absolute path, then we download it, the header is as below: ![image](https://user-images.githubusercontent.com/4455405/36660725-21071af4-1b14-11e8-84c9-62a743928069.png) we can see that the filename is an absolute path, so the downloaded name is invalid and finally it show the file_id. By the way, linux has no the problem.",source-file | source-file,"weed upload command in windows upload a file and download it, the filename is file_id in windows when upload a file using weed upload command, the filename is an absolute path, then we download it, the header is as below: ![image](https://user-images.githubusercontent.com/4455405/36660725-21071af4-1b14-11e8-84c9-62a743928069.png) we can see that the filename is an absolute path, so the downloaded name is invalid and finally it show the file_id. By the way, linux has no the problem. source-file source-file",no-bug,0.8
2098,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2098,seaweedfs 2.49 - weed server started with IPv4 address only listens on IPv6,"version 8000GB 2.49 42fb03a linux amd64 I invoke weed server like this (via a systemd service that runs it under a ""seaweedfs"" user): `weed server -rack=aaa -ip=192.168.1.130 -master.defaultReplication=010 -master.peers=192.168.1.130:9333 -filer=true -filer.port=8515 -filer.defaultReplicaPlacement=010 -volume.port=8526 -volume.max=56 -dir=/mnt/seaweedfs ` 192.168.1.130 is also that same machine's IPv4. But this happens:  Log file created at: 2021/05/29 00:29:31 Running on machine: redacted Binary: Built with gc go1.16.4 for linux/amd64 Log line format: [IWEF]mmdd hh:mm:ss threadid file:line] msg I0529 00:29:31 50479 master.go:165] current: 192.168.1.130:9333 peers:192.168.1.130:9333 I0529 00:29:31 50479 file_util.go:23] Folder /mnt/seaweedfs Permission: -rwxr-xr-x I0529 00:29:31 50479 master.go:165] current: 192.168.1.130:9333 peers:192.168.1.130:9333 I0529 00:29:31 50479 file_util.go:23] Folder /mnt/seaweedfs Permission: -rwxr-xr-x I0529 00:29:31 50479 master_server.go:114] Volume Size Limit is 30000 MB I0529 00:29:31 50479 master_server.go:206] adminScripts: lock ec.encode -fullPercent=96 -quietFor=3h ec.rebuild -force ec.balance -force volume.balance -force volume.fix.replication unlock I0529 00:29:31 50479 volume_grpc_client_to_master.go:42] checkWithMaster 192.168.1.130:9333: get master 192.168.1.130:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.1.130:19333: connect: connection refused"" I0529 00:29:31 50479 master.go:120] Start Seaweed Master 8000GB 2.49 42fb03a at :9333 I0529 00:29:31 50479 raft_server.go:70] Starting RaftServer with 192.168.1.130:9333 I0529 00:29:32 50479 raft_server.go:129] current cluster leader: I0529 00:29:32 50479 master.go:143] Start Seaweed Master 8000GB 2.49 42fb03a grpc server at :19333 I0529 00:29:33 50479 masterclient.go:79] No existing leader found! I0529 00:29:33 50479 raft_server.go:154] Initializing new cluster I0529 00:29:33 50479 master_server.go:155] leader change event: => 192.168.1.130:9333 I0529 00:29:33 50479 master_server.go:157] [ 192.168.1.130:9333 ] 192.168.1.130:9333 becomes leader. I0529 00:29:33 50479 volume_grpc_client_to_master.go:42] checkWithMaster 192.168.1.130:9333: get master 192.168.1.130:9333 configuration: rpc error: code = Unavailable desc = connection closed I0529 00:29:35 50479 volume_grpc_client_to_master.go:42] checkWithMaster 192.168.1.130:9333: get master 192.168.1.130:9333 configuration: rpc error: code = Unavailable desc = connection closed I0529 00:29:37 50479 volume_grpc_client_to_master.go:42] checkWithMaster 192.168.1.130:9333: get master 192.168.1.130:9333 configuration: rpc error: code = Unavailable desc = connection closed [Omitted: Many repeats of that last line with newer timestamp]  I observe on ""lsof -i -P -n | grep LISTEN"" that weed seems to have started gRPC on port + 10000, but only listening on IPv6. No mention of IPv4:  [Omitted: Many unrelated ports] weed 49099 seaweedfs 9u IPv6 356380 0t0 TCP *:9333 (LISTEN) weed 49099 seaweedfs 11u IPv6 350869 0t0 TCP *:19333 (LISTEN)  I imagine this is the problem, but I can't figure out what made seaweedfs use IPv6 when an IPv4 address was specified. Nothing was using 9333 or 19333 on IPv4. Perhaps it is a bug?",source-file,"seaweedfs 2.49 - weed server started with IPv4 address only listens on IPv6 version 8000GB 2.49 42fb03a linux amd64 I invoke weed server like this (via a systemd service that runs it under a ""seaweedfs"" user): `weed server -rack=aaa -ip=192.168.1.130 -master.defaultReplication=010 -master.peers=192.168.1.130:9333 -filer=true -filer.port=8515 -filer.defaultReplicaPlacement=010 -volume.port=8526 -volume.max=56 -dir=/mnt/seaweedfs ` 192.168.1.130 is also that same machine's IPv4. But this happens:  Log file created at: 2021/05/29 00:29:31 Running on machine: redacted Binary: Built with gc go1.16.4 for linux/amd64 Log line format: [IWEF]mmdd hh:mm:ss threadid file:line] msg I0529 00:29:31 50479 master.go:165] current: 192.168.1.130:9333 peers:192.168.1.130:9333 I0529 00:29:31 50479 file_util.go:23] Folder /mnt/seaweedfs Permission: -rwxr-xr-x I0529 00:29:31 50479 master.go:165] current: 192.168.1.130:9333 peers:192.168.1.130:9333 I0529 00:29:31 50479 file_util.go:23] Folder /mnt/seaweedfs Permission: -rwxr-xr-x I0529 00:29:31 50479 master_server.go:114] Volume Size Limit is 30000 MB I0529 00:29:31 50479 master_server.go:206] adminScripts: lock ec.encode -fullPercent=96 -quietFor=3h ec.rebuild -force ec.balance -force volume.balance -force volume.fix.replication unlock I0529 00:29:31 50479 volume_grpc_client_to_master.go:42] checkWithMaster 192.168.1.130:9333: get master 192.168.1.130:9333 configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 192.168.1.130:19333: connect: connection refused"" I0529 00:29:31 50479 master.go:120] Start Seaweed Master 8000GB 2.49 42fb03a at :9333 I0529 00:29:31 50479 raft_server.go:70] Starting RaftServer with 192.168.1.130:9333 I0529 00:29:32 50479 raft_server.go:129] current cluster leader: I0529 00:29:32 50479 master.go:143] Start Seaweed Master 8000GB 2.49 42fb03a grpc server at :19333 I0529 00:29:33 50479 masterclient.go:79] No existing leader found! I0529 00:29:33 50479 raft_server.go:154] Initializing new cluster I0529 00:29:33 50479 master_server.go:155] leader change event: => 192.168.1.130:9333 I0529 00:29:33 50479 master_server.go:157] [ 192.168.1.130:9333 ] 192.168.1.130:9333 becomes leader. I0529 00:29:33 50479 volume_grpc_client_to_master.go:42] checkWithMaster 192.168.1.130:9333: get master 192.168.1.130:9333 configuration: rpc error: code = Unavailable desc = connection closed I0529 00:29:35 50479 volume_grpc_client_to_master.go:42] checkWithMaster 192.168.1.130:9333: get master 192.168.1.130:9333 configuration: rpc error: code = Unavailable desc = connection closed I0529 00:29:37 50479 volume_grpc_client_to_master.go:42] checkWithMaster 192.168.1.130:9333: get master 192.168.1.130:9333 configuration: rpc error: code = Unavailable desc = connection closed [Omitted: Many repeats of that last line with newer timestamp]  I observe on ""lsof -i -P -n | grep LISTEN"" that weed seems to have started gRPC on port + 10000, but only listening on IPv6. No mention of IPv4:  [Omitted: Many unrelated ports] weed 49099 seaweedfs 9u IPv6 356380 0t0 TCP *:9333 (LISTEN) weed 49099 seaweedfs 11u IPv6 350869 0t0 TCP *:19333 (LISTEN)  I imagine this is the problem, but I can't figure out what made seaweedfs use IPv6 when an IPv4 address was specified. Nothing was using 9333 or 19333 on IPv4. Perhaps it is a bug? source-file",no-bug,0.9
3629,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3629,[master] Game on masterclient.go:288 updateVidMap,"**Describe the bug** I see such abnormal messages:  I0908 09:27:00.597693 masterclient.go:288 updateVidMap(DefaultDataCenter) .master: :0 volume add: 577, del: 547, add ec: 0 del ec: 0 I0908 09:27:00.585748 master_grpc_server.go:196 master see deleted volume 236 from :0 I0908 09:27:00.599290 master_grpc_server.go:196 master see deleted volume 316 from :0 I0908 09:27:00.599335 master_grpc_server.go:196 master see deleted volume 1293 from :0 I0908 09:27:00.599381 master_grpc_server.go:196 master see deleted volume 1506 from :0 I0908 09:27:00.599416 master_grpc_server.go:196 master see deleted volume 1415 from :0 I0908 09:27:00.599438 master_grpc_server.go:196 master see deleted volume 2587 from :0 I0908 09:27:00.599458 master_grpc_server.go:196 master see deleted volume 1674 from :0 I0908 09:27:00.599478 master_grpc_server.go:196 master see deleted volume 1169 from :0  normal messages:  I0908 09:27:43.339900 masterclient.go:288 updateVidMap(stagedc) .master: fast-volume-2.s3-fast-volume.service.stagedc.consul:8080 volume add: 957, del: 0, add ec: 0 del ec: 0  **System Setup**  3.26 master branch ",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[master] Game on masterclient.go:288 updateVidMap **Describe the bug** I see such abnormal messages:  I0908 09:27:00.597693 masterclient.go:288 updateVidMap(DefaultDataCenter) .master: :0 volume add: 577, del: 547, add ec: 0 del ec: 0 I0908 09:27:00.585748 master_grpc_server.go:196 master see deleted volume 236 from :0 I0908 09:27:00.599290 master_grpc_server.go:196 master see deleted volume 316 from :0 I0908 09:27:00.599335 master_grpc_server.go:196 master see deleted volume 1293 from :0 I0908 09:27:00.599381 master_grpc_server.go:196 master see deleted volume 1506 from :0 I0908 09:27:00.599416 master_grpc_server.go:196 master see deleted volume 1415 from :0 I0908 09:27:00.599438 master_grpc_server.go:196 master see deleted volume 2587 from :0 I0908 09:27:00.599458 master_grpc_server.go:196 master see deleted volume 1674 from :0 I0908 09:27:00.599478 master_grpc_server.go:196 master see deleted volume 1169 from :0  normal messages:  I0908 09:27:43.339900 masterclient.go:288 updateVidMap(stagedc) .master: fast-volume-2.s3-fast-volume.service.stagedc.consul:8080 volume add: 957, del: 0, add ec: 0 del ec: 0  **System Setup**  3.26 master branch  source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
35,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/35,Add gracely restart without downtime,"https://github.com/facebookgo/grace With this, the volume servers can restart without any downtime, while still can load updates.",documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | config-file | other-file | config-file | config-file | config-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file,"Add gracely restart without downtime https://github.com/facebookgo/grace With this, the volume servers can restart without any downtime, while still can load updates. documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file config-file other-file config-file config-file config-file config-file config-file source-file source-file source-file source-file source-file",no-bug,0.9
1726,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1726,memory related bugs of rocksdb implementation,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Hi Chris, I maintained my own rocksdb branch previously, happy to find out it's now offically supported. Here's some small suggestions for the current implementation. 1. Option objects created from `NewDefaultOptions` `NewDefaultReadOptions` `NewDefaultWriteOptions` contain cgo pointers need to be released explicitly. 2. rocksdb_store.go#L96 `entry.FullPath` leads to nil pointer dereference. 3. Rocksdb iterator related keys & values will be freed automatically upon iterator's destruction, so `iter.Close()` ensures no memory leak without `key.Free()` or `value.Free()`. Other possible improvements: 1. Reuse default options when possible. 2. Use `db.Get`(and free by hand) instead of `db.GetBytes` to avoid memory copy when bytes are read only. Gorocksdb `charToByte` use reflect tricks by creating byte slice with underlying C char array to avoid char* to go []byte copy, while `C.GoBytes` performs memory copy.",source-file | source-file | source-file,"memory related bugs of rocksdb implementation Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Hi Chris, I maintained my own rocksdb branch previously, happy to find out it's now offically supported. Here's some small suggestions for the current implementation. 1. Option objects created from `NewDefaultOptions` `NewDefaultReadOptions` `NewDefaultWriteOptions` contain cgo pointers need to be released explicitly. 2. rocksdb_store.go#L96 `entry.FullPath` leads to nil pointer dereference. 3. Rocksdb iterator related keys & values will be freed automatically upon iterator's destruction, so `iter.Close()` ensures no memory leak without `key.Free()` or `value.Free()`. Other possible improvements: 1. Reuse default options when possible. 2. Use `db.Get`(and free by hand) instead of `db.GetBytes` to avoid memory copy when bytes are read only. Gorocksdb `charToByte` use reflect tricks by creating byte slice with underlying C char array to avoid char* to go []byte copy, while `C.GoBytes` performs memory copy. source-file source-file source-file",no-bug,0.9
16,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/16,content type from volume post upload always text/plain?,"I'm assuming the return content-type should be application/json?  $ curl -v -F ""file=@/tmp/test.json;type=application/json"" localhost:8080/7,07a27ee211 > POST /7,07a27ee211 HTTP/1.1 > User-Agent: curl/7.30.0 > Host: localhost:8080 > Accept: */* > Content-Length: 223 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=2f1cf300fd2b > < HTTP/1.1 100 Continue < HTTP/1.1 201 Created < Date: Mon, 29 Sep 2014 20:08:45 GMT < Content-Length: 30 < Content-Type: text/plain; charset=utf-8 < * Connection #0 to host localhost left intact {""name"":""test.json"",""size"":74} ",config-file | documentation-file | documentation-file | other-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"content type from volume post upload always text/plain? I'm assuming the return content-type should be application/json?  $ curl -v -F ""file=@/tmp/test.json;type=application/json"" localhost:8080/7,07a27ee211 > POST /7,07a27ee211 HTTP/1.1 > User-Agent: curl/7.30.0 > Host: localhost:8080 > Accept: */* > Content-Length: 223 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=2f1cf300fd2b > < HTTP/1.1 100 Continue < HTTP/1.1 201 Created < Date: Mon, 29 Sep 2014 20:08:45 GMT < Content-Length: 30 < Content-Type: text/plain; charset=utf-8 < * Connection #0 to host localhost left intact {""name"":""test.json"",""size"":74}  config-file documentation-file documentation-file other-file source-file source-file source-file other-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.9
1884,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1884,S3 upload failed for filenames including '%' character,"**Describe the bug** S3 filer API can't handle files with '%' sign despite it being the valid name (and valid object for s3 and minio, I found plenty of those inside Photo library on Mac):  touch %%test.file.txt touch %%test.file.txt aws --endpoint-url http://rpi4node3:8333/ s3 cp %test.file.txt s3://testbucket/ upload failed: ./%test.file.txt to s3://testbucket/%test.file.txt An error occurred (InternalError) when calling the PutObject operation (reached max retries: 2): We encountered an internal error, please try again.  Upload via weed upload works:  > weed upload -master=""rpi4node3:9333"" %%test.file.txt [{""fileName"":""%%test.file.txt"",""url"":""rpi4node3:8088/13,022beaf4f28a09"",""fid"":""13,022beaf4f28a09""}] > weed upload -master=""rpi4node3:9333"" %test.file.txt [{""fileName"":""%test.file.txt"",""url"":""rpi4node3:8088/6,022beb5bdfd3a2"",""fid"":""6,022beb5bdfd3a2""}]  **System Setup** Master started with:  ~/go/bin/weed server -filer -s3 -ip=rpi4node3 -volume.max=0,0 -master.volumeSizeLimitMB=1024 -volume.port=8088 -dir=/mnt/usbslow/weed,/mnt/usbfast/weed/ -master.dir=/mnt/usbfast/weed/master  Filer config:  [redis_cluster2] enabled = true addresses = [ ""rpi4node1:6379"", ""rpi4node2:6379"", ""rpi4node3:6379"" ] password = """" # allows reads from slave servers or the master, but all writes still go to the master readOnly = false # automatically use the closest Redis server for reads routeByLatency = false # This changes the data layout. Only add new directories. Removing/Updating will cause data loss. superLargeDirectories = []  Volumes:  /usr/local/bin/weed volume -mserver=""rpi4node3:9333"" -max=1000,1000 -port=8088 -disk=hdd,ssd -dir=/mnt/usbslow/weed,/mnt/usbfast/weed/ &  Master weed version:  ~/go/bin/weed version version 30GB 2.29 400de380 linux arm64  Complied from:  commit 400de380f48c44c7700fdf7e8f247bf856662c10 (HEAD -> master, origin/master, origin/HEAD) Author: Chris Lu <chris.lu@gmail.com> Date: Fri Mar 5 02:29:38 2021 -0800 volume server: support tcp direct put/get/delete  **Expected behavior** Successful upload of files via S3. **Additional context** You guessed seaweed fs runs on RPI4 cluster. I found it's a really amazing project and very easy to setup. ",source-file | source-file,"S3 upload failed for filenames including '%' character **Describe the bug** S3 filer API can't handle files with '%' sign despite it being the valid name (and valid object for s3 and minio, I found plenty of those inside Photo library on Mac):  touch %%test.file.txt touch %%test.file.txt aws --endpoint-url http://rpi4node3:8333/ s3 cp %test.file.txt s3://testbucket/ upload failed: ./%test.file.txt to s3://testbucket/%test.file.txt An error occurred (InternalError) when calling the PutObject operation (reached max retries: 2): We encountered an internal error, please try again.  Upload via weed upload works:  > weed upload -master=""rpi4node3:9333"" %%test.file.txt [{""fileName"":""%%test.file.txt"",""url"":""rpi4node3:8088/13,022beaf4f28a09"",""fid"":""13,022beaf4f28a09""}] > weed upload -master=""rpi4node3:9333"" %test.file.txt [{""fileName"":""%test.file.txt"",""url"":""rpi4node3:8088/6,022beb5bdfd3a2"",""fid"":""6,022beb5bdfd3a2""}]  **System Setup** Master started with:  ~/go/bin/weed server -filer -s3 -ip=rpi4node3 -volume.max=0,0 -master.volumeSizeLimitMB=1024 -volume.port=8088 -dir=/mnt/usbslow/weed,/mnt/usbfast/weed/ -master.dir=/mnt/usbfast/weed/master  Filer config:  [redis_cluster2] enabled = true addresses = [ ""rpi4node1:6379"", ""rpi4node2:6379"", ""rpi4node3:6379"" ] password = """" # allows reads from slave servers or the master, but all writes still go to the master readOnly = false # automatically use the closest Redis server for reads routeByLatency = false # This changes the data layout. Only add new directories. Removing/Updating will cause data loss. superLargeDirectories = []  Volumes:  /usr/local/bin/weed volume -mserver=""rpi4node3:9333"" -max=1000,1000 -port=8088 -disk=hdd,ssd -dir=/mnt/usbslow/weed,/mnt/usbfast/weed/ &  Master weed version:  ~/go/bin/weed version version 30GB 2.29 400de380 linux arm64  Complied from:  commit 400de380f48c44c7700fdf7e8f247bf856662c10 (HEAD -> master, origin/master, origin/HEAD) Author: Chris Lu <chris.lu@gmail.com> Date: Fri Mar 5 02:29:38 2021 -0800 volume server: support tcp direct put/get/delete  **Expected behavior** Successful upload of files via S3. **Additional context** You guessed seaweed fs runs on RPI4 cluster. I found it's a really amazing project and very easy to setup.  source-file source-file",bug,0.9
32,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/32,-filer.redirectOnRead should imply -filer,"If I start a 'weed server -filer.redirectOnRead' without specifying -filer, it gives a puzzling error message because the filer does not start. If the user sets -filer.redirectOnRead, make it start the filer too.",other-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | other-file | documentation-file | other-file | config-file | config-file | config-file | other-file | other-file | documentation-file | documentation-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | config-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | documentation-file | documentation-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | other-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file,"-filer.redirectOnRead should imply -filer If I start a 'weed server -filer.redirectOnRead' without specifying -filer, it gives a puzzling error message because the filer does not start. If the user sets -filer.redirectOnRead, make it start the filer too. other-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file other-file documentation-file other-file config-file config-file config-file other-file other-file documentation-file documentation-file other-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file config-file other-file config-file source-file source-file source-file source-file source-file source-file other-file config-file source-file source-file config-file config-file source-file source-file source-file config-file config-file source-file source-file source-file documentation-file documentation-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file other-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file",no-bug,0.9
5126,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5126,weed filler.copy i/o timeout issue,"I'm having issue when running `weed filer.copy `command. Current I'm running seaweedfs locally using docker compose (https://github.com/seaweedfs/seaweedfs/blob/master/docker/seaweedfs-compose.yml) The command I ran: `weed filer.copy -verbose -debug /path/to/my/local/dir http://localhost:8888/path/to/my/mnt/point/` The error I got: **W1222 10:34:47.878728 upload_content.go:170 uploading 2 to http://172.18.0.3:8080/4,128bec02c0: upload .file.jpg.eCwSm0 223807 bytes to http://172.18.0.3:8080/4,128bec02c0: Post ""http://172.18.0.3:8080/4,128bec02c0"": dial tcp 172.18.0.3:8080: i/o timeout** Note that **172.18.0.3** is the internal address of my volume service container, and upon checking, port 8080 of volume service is indeed listening for connections. Any ideas?",source-file,"weed filler.copy i/o timeout issue I'm having issue when running `weed filer.copy `command. Current I'm running seaweedfs locally using docker compose (https://github.com/seaweedfs/seaweedfs/blob/master/docker/seaweedfs-compose.yml) The command I ran: `weed filer.copy -verbose -debug /path/to/my/local/dir http://localhost:8888/path/to/my/mnt/point/` The error I got: **W1222 10:34:47.878728 upload_content.go:170 uploading 2 to http://172.18.0.3:8080/4,128bec02c0: upload .file.jpg.eCwSm0 223807 bytes to http://172.18.0.3:8080/4,128bec02c0: Post ""http://172.18.0.3:8080/4,128bec02c0"": dial tcp 172.18.0.3:8080: i/o timeout** Note that **172.18.0.3** is the internal address of my volume service container, and upon checking, port 8080 of volume service is indeed listening for connections. Any ideas? source-file",no-bug,0.9
1647,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1647,S3 API - enforce recursive delete,"Hi @chrislusf https://github.com/chrislusf/seaweedfs/blob/781585b195bee1ef389a48c3303d93200edd7fab/weed/s3api/s3api_object_handlers.go#L116 can we have it configurable by ENV? in order not to break backward compatibility, maybe have it defaulted to recursive delete, but that's not s3 compatible (s3 delete is only direct, need to do listObjects and send all objects) 10x!",source-file,"S3 API - enforce recursive delete Hi @chrislusf https://github.com/chrislusf/seaweedfs/blob/781585b195bee1ef389a48c3303d93200edd7fab/weed/s3api/s3api_object_handlers.go#L116 can we have it configurable by ENV? in order not to break backward compatibility, maybe have it defaulted to recursive delete, but that's not s3 compatible (s3 delete is only direct, need to do listObjects and send all objects) 10x! source-file",no-bug,0.8
2545,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2545,[bug:filer] Trying to connect to the old filler address,"Trying to connect to the old filler address  I1230 08:30:44 1 meta_aggregator.go:190] subscribing remote 10.106.97.138:9090 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.106.97.138:19090: connect: connection refused""  IP address 10.106.97.138:9090 not in cluster  > cluster.ps the cluster has 8 filers * 10.103.39.184:9090 (8000GB 2.82 b7cd5263) * 10.106.97.170:9090 (8000GB 2.82 b7cd5263) * 10.106.97.173:9090 (8000GB 2.82 b7cd5263) * 10.106.97.221:9090 (8000GB 2.82 b7cd5263) * 10.103.39.160:9090 (8000GB 2.82 b7cd5263) * 10.103.39.190:9090 (8000GB 2.82 b7cd5263) * 10.103.39.151:9090 (8000GB 2.82 b7cd5263) * 10.106.97.152:9090 (8000GB 2.82 b7cd5263) ",source-file | source-file | source-file,"[bug:filer] Trying to connect to the old filler address Trying to connect to the old filler address  I1230 08:30:44 1 meta_aggregator.go:190] subscribing remote 10.106.97.138:9090 meta change: subscribe: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp 10.106.97.138:19090: connect: connection refused""  IP address 10.106.97.138:9090 not in cluster  > cluster.ps the cluster has 8 filers * 10.103.39.184:9090 (8000GB 2.82 b7cd5263) * 10.106.97.170:9090 (8000GB 2.82 b7cd5263) * 10.106.97.173:9090 (8000GB 2.82 b7cd5263) * 10.106.97.221:9090 (8000GB 2.82 b7cd5263) * 10.103.39.160:9090 (8000GB 2.82 b7cd5263) * 10.103.39.190:9090 (8000GB 2.82 b7cd5263) * 10.103.39.151:9090 (8000GB 2.82 b7cd5263) * 10.106.97.152:9090 (8000GB 2.82 b7cd5263)  source-file source-file source-file",no-bug,0.9
1294,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1294,Can weed benchmark generate random text or binary content files?,Can weed benchmark generate random text or binary content files?,source-file,Can weed benchmark generate random text or binary content files? Can weed benchmark generate random text or binary content files? source-file,no-bug,0.9
452,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/452,master panic in SendHeartbeat,"cause: `glog.V(0).Infof(""lost volume server %s:%d"", dn.Ip, dn.Port)` when dn == nil call trace: panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0xa65005] goroutine 60 [running]: github.com/chrislusf/seaweedfs/weed/server.MasterServer.SendHeartbeat(0x2475, 0x0, 0x0, 0x7530, 0x0, 0x5, 0xc6ebe1, 0x3, 0xc6ebde, 0x3, ) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/master_grpc_server.go:62 +0xc85 github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).SendHeartbeat(0xc4201ae300, 0x1015160, 0xc4202da6d0, 0x1005de0, 0xc4201ae300) <autogenerated>:1 +0x9a github.com/chrislusf/seaweedfs/weed/pb._Seaweed_SendHeartbeat_Handler(0xc47520, 0xc4201ae300, 0x1013d80, 0xc4202ec500, 0xc42025ce10, 0xc4202ee900) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/pb/seaweed.pb.go:308 +0xb7 google.golang.org/grpc.(*Server).processStreamingRPC(0xc4201cf6c0, 0x1014800, 0xc4202f42a0, 0xc4202ee900, 0xc42024ee70, 0x103c880, 0xc4202d2d20, 0x0, 0x0) /home/travis/gopath/src/google.golang.org/grpc/server.go:819 +0x7b9 google.golang.org/grpc.(*Server).handleStream(0xc4201cf6c0, 0x1014800, 0xc4202f42a0, 0xc4202ee900, 0xc4202d2d20) /home/travis/gopath/src/google.golang.org/grpc/server.go:909 +0x11fd google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc4202da610, 0xc4201cf6c0, 0x1014800, 0xc4202f42a0, 0xc4202ee900) /home/travis/gopath/src/google.golang.org/grpc/server.go:478 +0xa9 created by google.golang.org/grpc.(*Server).serveStreams.func1 /home/travis/gopath/src/google.golang.org/grpc/server.go:479 +0xa1 all logs before panic: ./weed master -mdir=/home/worker/data/weed/master -ip=FBI-1 I0211 22:22:24 17780 file_util.go:20] Folder /home/worker/data/weed/master Permission: -rwxr-xr-x I0211 22:22:24 17780 topology.go:81] Using default configurations. I0211 22:22:24 17780 master_server.go:67] Volume Size Limit is 30000 MB I0211 22:22:24 17780 master.go:88] Start Seaweed Master 0.74 at 0.0.0.0:9333 I0211 22:22:24 17780 raft_server.go:56] Peers Change: [FBI-1:9333] => [] I0211 22:22:24 17780 raft_server.go:98] Initializing new cluster I0211 22:22:24 17780 master_server.go:100] [ FBI-1:9333 ] I am the leader! I0211 22:22:25 17780 node.go:223] topo adds child DefaultDataCenter I0211 22:22:25 17780 node.go:223] topo:DefaultDataCenter adds child DefaultRack I0211 22:22:25 17780 node.go:223] topo:DefaultDataCenter:DefaultRack adds child FBI-1:8080 I0211 22:22:25 17780 master_grpc_server.go:36] added volume server FBI-1:8080 I0211 22:22:58 17780 master_grpc_server.go:62] lost volume server FBI-1:8080 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 1 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 1 has 0 replica, less than required 2 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 3 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 3 has 0 replica, less than required 2 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 4 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 4 has 0 replica, less than required 2 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 5 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 5 has 0 replica, less than required 2 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 2 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 2 has 0 replica, less than required 2 I0211 22:22:58 17780 node.go:237] topo:DefaultDataCenter:DefaultRack removes FBI-1:8080 I0211 22:23:01 17780 node.go:223] topo:DefaultDataCenter:DefaultRack adds child FBI-1:8080 I0211 22:23:01 17780 master_grpc_server.go:36] added volume server FBI-1:8080",source-file,"master panic in SendHeartbeat cause: `glog.V(0).Infof(""lost volume server %s:%d"", dn.Ip, dn.Port)` when dn == nil call trace: panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0xa65005] goroutine 60 [running]: github.com/chrislusf/seaweedfs/weed/server.MasterServer.SendHeartbeat(0x2475, 0x0, 0x0, 0x7530, 0x0, 0x5, 0xc6ebe1, 0x3, 0xc6ebde, 0x3, ) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/master_grpc_server.go:62 +0xc85 github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).SendHeartbeat(0xc4201ae300, 0x1015160, 0xc4202da6d0, 0x1005de0, 0xc4201ae300) <autogenerated>:1 +0x9a github.com/chrislusf/seaweedfs/weed/pb._Seaweed_SendHeartbeat_Handler(0xc47520, 0xc4201ae300, 0x1013d80, 0xc4202ec500, 0xc42025ce10, 0xc4202ee900) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/pb/seaweed.pb.go:308 +0xb7 google.golang.org/grpc.(*Server).processStreamingRPC(0xc4201cf6c0, 0x1014800, 0xc4202f42a0, 0xc4202ee900, 0xc42024ee70, 0x103c880, 0xc4202d2d20, 0x0, 0x0) /home/travis/gopath/src/google.golang.org/grpc/server.go:819 +0x7b9 google.golang.org/grpc.(*Server).handleStream(0xc4201cf6c0, 0x1014800, 0xc4202f42a0, 0xc4202ee900, 0xc4202d2d20) /home/travis/gopath/src/google.golang.org/grpc/server.go:909 +0x11fd google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc4202da610, 0xc4201cf6c0, 0x1014800, 0xc4202f42a0, 0xc4202ee900) /home/travis/gopath/src/google.golang.org/grpc/server.go:478 +0xa9 created by google.golang.org/grpc.(*Server).serveStreams.func1 /home/travis/gopath/src/google.golang.org/grpc/server.go:479 +0xa1 all logs before panic: ./weed master -mdir=/home/worker/data/weed/master -ip=FBI-1 I0211 22:22:24 17780 file_util.go:20] Folder /home/worker/data/weed/master Permission: -rwxr-xr-x I0211 22:22:24 17780 topology.go:81] Using default configurations. I0211 22:22:24 17780 master_server.go:67] Volume Size Limit is 30000 MB I0211 22:22:24 17780 master.go:88] Start Seaweed Master 0.74 at 0.0.0.0:9333 I0211 22:22:24 17780 raft_server.go:56] Peers Change: [FBI-1:9333] => [] I0211 22:22:24 17780 raft_server.go:98] Initializing new cluster I0211 22:22:24 17780 master_server.go:100] [ FBI-1:9333 ] I am the leader! I0211 22:22:25 17780 node.go:223] topo adds child DefaultDataCenter I0211 22:22:25 17780 node.go:223] topo:DefaultDataCenter adds child DefaultRack I0211 22:22:25 17780 node.go:223] topo:DefaultDataCenter:DefaultRack adds child FBI-1:8080 I0211 22:22:25 17780 master_grpc_server.go:36] added volume server FBI-1:8080 I0211 22:22:58 17780 master_grpc_server.go:62] lost volume server FBI-1:8080 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 1 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 1 has 0 replica, less than required 2 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 3 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 3 has 0 replica, less than required 2 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 4 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 4 has 0 replica, less than required 2 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 5 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 5 has 0 replica, less than required 2 I0211 22:22:58 17780 topology_event_handling.go:52] Removing Volume 2 from the dead volume server FBI-1:8080 I0211 22:22:58 17780 volume_layout.go:221] Volume 2 has 0 replica, less than required 2 I0211 22:22:58 17780 node.go:237] topo:DefaultDataCenter:DefaultRack removes FBI-1:8080 I0211 22:23:01 17780 node.go:223] topo:DefaultDataCenter:DefaultRack adds child FBI-1:8080 I0211 22:23:01 17780 master_grpc_server.go:36] added volume server FBI-1:8080 source-file",no-bug,0.9
1530,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1530,2.04: FUSE mount show empty folders when filer is down,"FUSE mount _pretends_ to work when filer is down: 1. start filer (e.g. `weed filer `) 2. mount `/mnt/weed` (e.g. `weed mount -dir=/mnt/weed `) 3. stop filer 4. `find /mnt/weed | wc -l`: prints `8`, successfully counts files in root and top-level directories. Here is the problem: `find /mnt/weed` is not expected to succeed when the filer is down. It should not be possible to walk directory tree without filer. FUSE mount should have waited for filer but instead it _pretended_ to know the content of the file system and incorrectly reported empty top level directories. 5. start filer again, same as in step 1. 6. `find /mnt/weed | wc -l`: prints `114`, as expected. When the filer became available, the count of files/folders has changed because there are actually some files/folders nested under top level directories. FUSE mount should not lie about file system content. When filer is not available, FUSE mount should wait for filer and never ever return fraudulent/fabricated information about folder's content.",source-file | source-file | source-file | source-file | source-file,"2.04: FUSE mount show empty folders when filer is down FUSE mount _pretends_ to work when filer is down: 1. start filer (e.g. `weed filer `) 2. mount `/mnt/weed` (e.g. `weed mount -dir=/mnt/weed `) 3. stop filer 4. `find /mnt/weed | wc -l`: prints `8`, successfully counts files in root and top-level directories. Here is the problem: `find /mnt/weed` is not expected to succeed when the filer is down. It should not be possible to walk directory tree without filer. FUSE mount should have waited for filer but instead it _pretended_ to know the content of the file system and incorrectly reported empty top level directories. 5. start filer again, same as in step 1. 6. `find /mnt/weed | wc -l`: prints `114`, as expected. When the filer became available, the count of files/folders has changed because there are actually some files/folders nested under top level directories. FUSE mount should not lie about file system content. When filer is not available, FUSE mount should wait for filer and never ever return fraudulent/fabricated information about folder's content. source-file source-file source-file source-file source-file",no-bug,0.9
2476,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2476,Unable to add filer,"**Describe the bug** When trying to add a new filer I1129 04:33:38 16088 meta_aggregator.go:190] subscribing remote IP1:8888 meta change: rpc error: code = Unknown desc = reading from persisted logs: reading /topics/.system/log/2021-11-22/09-56.8ff86979: volume 6 not found **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". S1 /opt/weed -logdir=/var/log/weed filer -ip=IP1 -s3 -defaultReplicaPlacement=000 -dataCenter=DC1 S2 /opt/weed -logdir=/var/log/weed filer -ip=IP2 -s3 -defaultReplicaPlacement=000 -dataCenter=DC1 - output of `weed version` version 8000GB 2.79 f3c789d662eeab2dcc07804cbb665752b3870d65 linux amd64 - if using filer, show the content of `filer.toml`  [leveldb3] # similar to leveldb2. # each bucket has its own meta store. enabled = true dir = ""/srv/filer_leveldb3"" # directory to store level db files  Everything else is ""false"" In ""volume.list"" I also don't see any volume with this id and I do not see missing servers in volume.list. I even checked the presence/consistency of data in other buckets, just in case, and found no problems. So, maybe you have some idea what to do about it?",source-file,"Unable to add filer **Describe the bug** When trying to add a new filer I1129 04:33:38 16088 meta_aggregator.go:190] subscribing remote IP1:8888 meta change: rpc error: code = Unknown desc = reading from persisted logs: reading /topics/.system/log/2021-11-22/09-56.8ff86979: volume 6 not found **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". S1 /opt/weed -logdir=/var/log/weed filer -ip=IP1 -s3 -defaultReplicaPlacement=000 -dataCenter=DC1 S2 /opt/weed -logdir=/var/log/weed filer -ip=IP2 -s3 -defaultReplicaPlacement=000 -dataCenter=DC1 - output of `weed version` version 8000GB 2.79 f3c789d662eeab2dcc07804cbb665752b3870d65 linux amd64 - if using filer, show the content of `filer.toml`  [leveldb3] # similar to leveldb2. # each bucket has its own meta store. enabled = true dir = ""/srv/filer_leveldb3"" # directory to store level db files  Everything else is ""false"" In ""volume.list"" I also don't see any volume with this id and I do not see missing servers in volume.list. I even checked the presence/consistency of data in other buckets, just in case, and found no problems. So, maybe you have some idea what to do about it? source-file",no-bug,0.9
5774,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5774,remote sync unexpected behavior,"Not mounted directory has same prefix as mounted directory pushed to remote storage when running filer.remote.sync. for example, there is two dir, /foo and /foo-bar, only /foo mounted to remote storage remote:/foo, when running: `weed filer.remote.sync -dir=/foo` files in /foo-bar, for example /foo-bar/baz/qux was pushed to remote:/foo/-bar/baz/qux",test-file | source-file | source-file | source-file | source-file | source-file | source-file,"remote sync unexpected behavior Not mounted directory has same prefix as mounted directory pushed to remote storage when running filer.remote.sync. for example, there is two dir, /foo and /foo-bar, only /foo mounted to remote storage remote:/foo, when running: `weed filer.remote.sync -dir=/foo` files in /foo-bar, for example /foo-bar/baz/qux was pushed to remote:/foo/-bar/baz/qux test-file source-file source-file source-file source-file source-file source-file",bug,0.9
25,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/25,"Weedfs cannot lead because ""Old conf,log,snapshot should have been removed"", maybe it should ensure it is removed before starting?","Weed master cannot become the leader if conf, logs and snapshots exist. After deleting them, it can lead. Maybe the raft server should delete these files before starting?",other-file | other-file | config-file | other-file | config-file | source-file | config-file | config-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Weedfs cannot lead because ""Old conf,log,snapshot should have been removed"", maybe it should ensure it is removed before starting? Weed master cannot become the leader if conf, logs and snapshots exist. After deleting them, it can lead. Maybe the raft server should delete these files before starting? other-file other-file config-file other-file config-file source-file config-file config-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
1187,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1187,Error message provides faulty instructions and a 404 link,"**Describe the bug** 1. a 404 link. 2. config=notification does not make filer.toml. 3. both toml files are in current directory why are they not loaded? **System Setup**  > ./weed master -mdir=""$TMP"" -defaultReplication=001 -ip=""${IP}"" -peers=${IP1}:9333,${IP2}:9333,${IP3}:9333 > weed_master.log 2>&1 & > sleep 2 > ./weed volume -dir=""$TMP"" -ip=""${IP}"" -port=8081 -mserver=${IP1}:9333,${IP2}:9333,${IP3}:9333 > weed_volume.log 2>&1 & > sleep 2 > ./weed filer -defaultReplicaPlacement=001 -ip=""${IP}"" -master=${IP1}:9333,${IP2}:9333,${IP3}:9333 weed_filer.log 2>&1 & > sleep 2 > ./weed mount -dir=""$MOUNT"" -replication=001 -filer=""${IP}:8888"" > weed_mount.log 2>&1 & > hostnamectl | grep Operating Operating System: Ubuntu 18.04.3 LTS > ./weed version version 30GB 1.51 linux amd64 > find / -iname filer.toml # no pre existing file  **Expected behavior** A clear and concise description of what is required. **Additional context**  > ./weed scaffold -config=replication -output=. > ./weed scaffold -config=filer -output=. > ./weed filer.replicate I0127 18:05:03 25618 config.go:27] Reading : Config File ""security"" Not Found in ""[/opt /root/.seaweedfs /etc/seaweedfs]"" I0127 18:05:03 25618 config.go:27] Reading : Config File ""notification"" Not Found in ""[/opt /root/.seaweedfs /etc/seaweedfs]"" F0127 18:05:03 25618 config.go:29] Failed to load notification.toml file from current directory, or $HOME/.seaweedfs/, or /etc/seaweedfs/ Please follow this example and add a filer.toml file to current directory, or $HOME/.seaweedfs/, or /etc/seaweedfs/: https://github.com/chrislusf/seaweedfs/blob/master/weed/notification.toml Or use this command to generate the default toml file weed scaffold -config=notification -output=. goroutine 1 [running]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0xc000496b00, 0xc0000d4000, 0x1b8, 0x341) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:767 +0xb8 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x33179c0, 0xc000000003, 0xc000485f80, 0x31b7aa8, 0x9, 0x1d, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:718 +0x351 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x33179c0, 0x3, 0x1f24ac8, 0x177, 0xc0005edbe0, 0x3, 0x3) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:656 +0x14b github.com/chrislusf/seaweedfs/weed/glog.Fatalf() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:1149 github.com/chrislusf/seaweedfs/weed/util.LoadConfiguration(0x1e968c1, 0xc, 0x1, 0xc000344d01) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/util/config.go:29 +0x3ae github.com/chrislusf/seaweedfs/weed/command.runFilerReplicate(0x32e5ca0, 0xc00000c090, 0x0, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/filer_replication.go:41 +0x8c main.main() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/weed.go:66 +0x2f9 > ls -1 *.toml filer.toml replication.toml  Side question: [How do I get the mount points to sync?](https://seaweedfs.slack.com/archives/C9MGUC1UG/p1580053555005400)",source-file,"Error message provides faulty instructions and a 404 link **Describe the bug** 1. a 404 link. 2. config=notification does not make filer.toml. 3. both toml files are in current directory why are they not loaded? **System Setup**  > ./weed master -mdir=""$TMP"" -defaultReplication=001 -ip=""${IP}"" -peers=${IP1}:9333,${IP2}:9333,${IP3}:9333 > weed_master.log 2>&1 & > sleep 2 > ./weed volume -dir=""$TMP"" -ip=""${IP}"" -port=8081 -mserver=${IP1}:9333,${IP2}:9333,${IP3}:9333 > weed_volume.log 2>&1 & > sleep 2 > ./weed filer -defaultReplicaPlacement=001 -ip=""${IP}"" -master=${IP1}:9333,${IP2}:9333,${IP3}:9333 weed_filer.log 2>&1 & > sleep 2 > ./weed mount -dir=""$MOUNT"" -replication=001 -filer=""${IP}:8888"" > weed_mount.log 2>&1 & > hostnamectl | grep Operating Operating System: Ubuntu 18.04.3 LTS > ./weed version version 30GB 1.51 linux amd64 > find / -iname filer.toml # no pre existing file  **Expected behavior** A clear and concise description of what is required. **Additional context**  > ./weed scaffold -config=replication -output=. > ./weed scaffold -config=filer -output=. > ./weed filer.replicate I0127 18:05:03 25618 config.go:27] Reading : Config File ""security"" Not Found in ""[/opt /root/.seaweedfs /etc/seaweedfs]"" I0127 18:05:03 25618 config.go:27] Reading : Config File ""notification"" Not Found in ""[/opt /root/.seaweedfs /etc/seaweedfs]"" F0127 18:05:03 25618 config.go:29] Failed to load notification.toml file from current directory, or $HOME/.seaweedfs/, or /etc/seaweedfs/ Please follow this example and add a filer.toml file to current directory, or $HOME/.seaweedfs/, or /etc/seaweedfs/: https://github.com/chrislusf/seaweedfs/blob/master/weed/notification.toml Or use this command to generate the default toml file weed scaffold -config=notification -output=. goroutine 1 [running]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0xc000496b00, 0xc0000d4000, 0x1b8, 0x341) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:767 +0xb8 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x33179c0, 0xc000000003, 0xc000485f80, 0x31b7aa8, 0x9, 0x1d, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:718 +0x351 github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x33179c0, 0x3, 0x1f24ac8, 0x177, 0xc0005edbe0, 0x3, 0x3) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:656 +0x14b github.com/chrislusf/seaweedfs/weed/glog.Fatalf() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/glog/glog.go:1149 github.com/chrislusf/seaweedfs/weed/util.LoadConfiguration(0x1e968c1, 0xc, 0x1, 0xc000344d01) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/util/config.go:29 +0x3ae github.com/chrislusf/seaweedfs/weed/command.runFilerReplicate(0x32e5ca0, 0xc00000c090, 0x0, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/command/filer_replication.go:41 +0x8c main.main() /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/weed.go:66 +0x2f9 > ls -1 *.toml filer.toml replication.toml  Side question: [How do I get the mount points to sync?](https://seaweedfs.slack.com/archives/C9MGUC1UG/p1580053555005400) source-file",no-bug,0.9
2110,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2110,"Windows: Network drive mapped by Winfsp, can create, modify but can't remove files.","1. Mount a fold from seaweedfs using weed mount on linux. 2. Map the fold as a network drive on windows using [winfsp](https://github.com/billziss-gh/winfsp). sshfs\root@192.168.1.13, input the root password, got a network drive. 3. creating and modifying files in the network drive worked, but can't not delete files. 4. When deleting files, they exist after refresh the folder. But removing directories works well.",source-file | source-file,"Windows: Network drive mapped by Winfsp, can create, modify but can't remove files. 1. Mount a fold from seaweedfs using weed mount on linux. 2. Map the fold as a network drive on windows using [winfsp](https://github.com/billziss-gh/winfsp). sshfs\root@192.168.1.13, input the root password, got a network drive. 3. creating and modifying files in the network drive worked, but can't not delete files. 4. When deleting files, they exist after refresh the folder. But removing directories works well. source-file source-file",no-bug,0.9
4635,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4635,Vacuum: invalid cross-device link,"**Describe the bug** I thought it was a clever idea to have the index files on another hard drive than the data. But that lead to errors while committing vacuum. The files are now shown with 0 bytes. Can I somehow ""restore"" them or are they completely gone?? **System Setup** Two mounted devices: `/meta` is an NVME and `/data` is a ""normal"" SSD. Command: bash weed server -dataCenter=app1 -ip=app1 -master.dir=/meta -master.peers=app1:9333,app2:9333,app3:9333 -dir=/data -volume.dir.idx=/meta -volume.index=leveldbLarge -volume.max=0 -rack=1 -filer.encryptVolumeData -volume.fileSizeLimitMB=4096 -master.volumeSizeLimitMB=1024 -filer.defaultReplicaPlacement=100 -filer.saveToFilerLimit=4096 -filer  Version: 3.52 **Expected behavior** I could live with a warning/error or something but SeaweedFS should try to handle that without losing data at least. **Screenshots** bash topology_vacuum.go:138 Error when committing vacuum 3 on app1:8080: rpc error: code = Unknown desc = rename /meta/3.ldb: rename /data/3.cpldb /meta/3.ldb: invalid cross-device link volume_grpc_vacuum.go:87 failed commit volume 3: rename /meta/3.ldb: rename /data/3.cpldb /meta/3.ldb: invalid cross-device link ",source-file | source-file,"Vacuum: invalid cross-device link **Describe the bug** I thought it was a clever idea to have the index files on another hard drive than the data. But that lead to errors while committing vacuum. The files are now shown with 0 bytes. Can I somehow ""restore"" them or are they completely gone?? **System Setup** Two mounted devices: `/meta` is an NVME and `/data` is a ""normal"" SSD. Command: bash weed server -dataCenter=app1 -ip=app1 -master.dir=/meta -master.peers=app1:9333,app2:9333,app3:9333 -dir=/data -volume.dir.idx=/meta -volume.index=leveldbLarge -volume.max=0 -rack=1 -filer.encryptVolumeData -volume.fileSizeLimitMB=4096 -master.volumeSizeLimitMB=1024 -filer.defaultReplicaPlacement=100 -filer.saveToFilerLimit=4096 -filer  Version: 3.52 **Expected behavior** I could live with a warning/error or something but SeaweedFS should try to handle that without losing data at least. **Screenshots** bash topology_vacuum.go:138 Error when committing vacuum 3 on app1:8080: rpc error: code = Unknown desc = rename /meta/3.ldb: rename /data/3.cpldb /meta/3.ldb: invalid cross-device link volume_grpc_vacuum.go:87 failed commit volume 3: rename /meta/3.ldb: rename /data/3.cpldb /meta/3.ldb: invalid cross-device link  source-file source-file",no-bug,0.9
2064,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2064,seaweedfs FUSE Mount ,"seaweedfs 2.47 linux ubuntu 20.04 samba 4.11.6  seaweedfs files  samba  windows  windows   ->  ->  ->   ![image](https://user-images.githubusercontent.com/48195631/117944261-a8b9ea00-b33f-11eb-9b69-069e7fcffe3e.png)  ->  ->  ->  ->   ![image](https://user-images.githubusercontent.com/48195631/117944342-bbccba00-b33f-11eb-87a8-62cb23f2365b.png) ![image](https://user-images.githubusercontent.com/48195631/117944374-c424f500-b33f-11eb-8bb1-e9027829799a.png)  Linux  `ls`  igmainc@A:~/test$ ls ls:  'xyz':  123  abc xyz  samba   [test] comment = Users profiles path = /home/igmainc/test/ guest ok = yes public = yes browseable = yes writable = yes available = yes admin users = igmainc create mask = 0775 directory mask = 0775 force user = root force group = root  `weed filer.meta.tail`  json {""directory"":""/"",""eventNotification"":{""newEntry"":{""name"":"""",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""}},""deleteChunks"":true,""newParentPath"":""/"",""signatures"":[1307535173,1722882382]},""tsNs"":""1620819698856095691""} {""directory"":""/"",""eventNotification"":{""oldEntry"":{""name"":"""",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""}},""newEntry"":{""name"":"""",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""},""extended"":{""user.DOSATTRIB"":""AAAEAAQAAABRAAAAEAAAABjGHgkjR9cBGMYeCSNH1wE=""}},""deleteChunks"":true,""newParentPath"":""/"",""signatures"":[1307535173,1722882382]},""tsNs"":""1620819698860744775""} {""directory"":""/"",""eventNotification"":{""newEntry"":{""name"":""789"",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""},""extended"":{""user.DOSATTRIB"":""AAAEAAQAAABRAAAAEAAAABjGHgkjR9cBGMYeCSNH1wE=""}},""deleteChunks"":true,""newParentPath"":""/"",""signatures"":[1722882382]},""tsNs"":""1620819703672508703""} {""directory"":""/"",""eventNotification"":{""oldEntry"":{""name"":"""",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""},""extended"":{""user.DOSATTRIB"":""AAAEAAQAAABRAAAAEAAAABjGHgkjR9cBGMYeCSNH1wE=""}},""signatures"":[1722882382]},""tsNs"":""1620819703672550781""} ",source-file | source-file,"seaweedfs FUSE Mount  seaweedfs 2.47 linux ubuntu 20.04 samba 4.11.6  seaweedfs files  samba  windows  windows   ->  ->  ->   ![image](https://user-images.githubusercontent.com/48195631/117944261-a8b9ea00-b33f-11eb-9b69-069e7fcffe3e.png)  ->  ->  ->  ->   ![image](https://user-images.githubusercontent.com/48195631/117944342-bbccba00-b33f-11eb-87a8-62cb23f2365b.png) ![image](https://user-images.githubusercontent.com/48195631/117944374-c424f500-b33f-11eb-8bb1-e9027829799a.png)  Linux  `ls`  igmainc@A:~/test$ ls ls:  'xyz':  123  abc xyz  samba   [test] comment = Users profiles path = /home/igmainc/test/ guest ok = yes public = yes browseable = yes writable = yes available = yes admin users = igmainc create mask = 0775 directory mask = 0775 force user = root force group = root  `weed filer.meta.tail`  json {""directory"":""/"",""eventNotification"":{""newEntry"":{""name"":"""",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""}},""deleteChunks"":true,""newParentPath"":""/"",""signatures"":[1307535173,1722882382]},""tsNs"":""1620819698856095691""} {""directory"":""/"",""eventNotification"":{""oldEntry"":{""name"":"""",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""}},""newEntry"":{""name"":"""",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""},""extended"":{""user.DOSATTRIB"":""AAAEAAQAAABRAAAAEAAAABjGHgkjR9cBGMYeCSNH1wE=""}},""deleteChunks"":true,""newParentPath"":""/"",""signatures"":[1307535173,1722882382]},""tsNs"":""1620819698860744775""} {""directory"":""/"",""eventNotification"":{""newEntry"":{""name"":""789"",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""},""extended"":{""user.DOSATTRIB"":""AAAEAAQAAABRAAAAEAAAABjGHgkjR9cBGMYeCSNH1wE=""}},""deleteChunks"":true,""newParentPath"":""/"",""signatures"":[1722882382]},""tsNs"":""1620819703672508703""} {""directory"":""/"",""eventNotification"":{""oldEntry"":{""name"":"""",""isDirectory"":true,""attributes"":{""mtime"":""1620819698"",""fileMode"":2147484141,""crtime"":""1620819698""},""extended"":{""user.DOSATTRIB"":""AAAEAAQAAABRAAAAEAAAABjGHgkjR9cBGMYeCSNH1wE=""}},""signatures"":[1722882382]},""tsNs"":""1620819703672550781""}  source-file source-file",no-bug,0.9
5465,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5465,Internal Server Error and EIO on fuse mount for remote EC shard read failure.,"**Describe the bug** When a EC shard is compromised on disk, the servers did not try to recover from other shards but gives an 500 internal error.  Apr 03 16:13:02 aries-b02 seaweedfs-volume-0[501258]: I0403 16:13:02.645677 store_ec.go:288 read remote ec shard 1201.5 from 10.8.150.91:8080 Apr 03 16:13:02 aries-b02 seaweedfs-volume-0[501258]: I0403 16:13:02.647847 volume_server_handlers_read.go:160 read /1201,0a4a115622d1530d isNormalVolume false error: readbytes: entry not found: offset 27663713352 found id 34313936356436363739353636653636 size -2007146114, expected size 168275  The problem happens 100% with the file id and the shard at `https://s3-haosu.nrp-nautilus.io/ruoxi-bucket/1201.tar`. **System Setup** - `/usr/local/bin/weed server -volume=0 -filer -dir=/weedfs` - `/usr/local/bin/weed volume -max=400 -dir=/weedfs -mserver=10.8.149.13:9333` on 8 machines different from the master - These commands are done by systemctl services with setups exactly as the wiki page. - OS version: Ubuntu 22.04 - output of `weed version`: version 8000GB 3.63 54d7748a4a54d94a31ce04d05db801faeff4f690 linux amd64 - if using filer, show the content of `filer.toml`: no `filer.toml` - security:  [access] ui = false [grpc] ca = ""/etc/ariesdockerd/certs/Aries_SeaweedFS_CA.crt"" [grpc.volume] cert = ""/etc/ariesdockerd/certs/volume01.crt"" key = ""/etc/ariesdockerd/certs/volume01.key"" [grpc.master] cert = ""/etc/ariesdockerd/certs/master01.crt"" key = ""/etc/ariesdockerd/certs/master01.key"" [grpc.filer] cert = ""/etc/ariesdockerd/certs/filer01.crt"" key = ""/etc/ariesdockerd/certs/filer01.key"" [grpc.client] cert = ""/etc/ariesdockerd/certs/client01.crt"" key = ""/etc/ariesdockerd/certs/client01.key""  - master:  # Put this file to one of the location, with descending priority # ./master.toml # $HOME/.seaweedfs/master.toml # /etc/seaweedfs/master.toml # this file is read by master [master.maintenance] # periodically run these scripts are the same as running them from 'weed shell' scripts =  lock ec.encode -fullPercent=95 -quietFor=1h ec.balance -force volume.deleteEmpty -quietFor=24h -force volume.balance -force unlock  sleep_minutes = 17 # sleep minutes between each script execution [master.sequencer] type = ""raft"" # Choose [raft|snowflake] type for storing the file id sequence # when sequencer.type = snowflake, the snowflake id must be different from other masters sequencer_snowflake_id = 0 # any number between 1~1023 # configurations for tiered cloud storage # old volumes are transparently moved to cloud for cost efficiency [storage.backend] [storage.backend.s3.default] enabled = false aws_access_key_id = """" # if empty, loads from the shared credentials file (~/.aws/credentials). aws_secret_access_key = """" # if empty, loads from the shared credentials file (~/.aws/credentials). region = ""us-east-2"" bucket = ""your_bucket_name"" # an existing bucket endpoint = """" storage_class = ""STANDARD_IA"" # create this number of logical volumes if no more writable volumes # count_x means how many copies of data. # e.g.: # 000 has only one copy, copy_1 # 010 and 001 has two copies, copy_2 # 011 has only 3 copies, copy_3 [master.volume_growth] copy_1 = 7 # create 1 x 7 = 7 actual volumes copy_2 = 6 # create 2 x 6 = 12 actual volumes copy_3 = 3 # create 3 x 3 = 9 actual volumes copy_other = 1 # create n x 1 = n actual volumes # configuration flags for replication [master.replication] # any replication counts should be considered minimums. If you specify 010 and # have 3 different racks, that's still considered writable. Writes will still # try to replicate to all available volumes. You should only use this option # if you are doing your own replication or periodic sync of volumes. treat_replication_as_minimums = false  **Expected behavior** When the EC shard fails, the volume server should try to recover the shard from other shards.",other-file | source-file | test-file,"Internal Server Error and EIO on fuse mount for remote EC shard read failure. **Describe the bug** When a EC shard is compromised on disk, the servers did not try to recover from other shards but gives an 500 internal error.  Apr 03 16:13:02 aries-b02 seaweedfs-volume-0[501258]: I0403 16:13:02.645677 store_ec.go:288 read remote ec shard 1201.5 from 10.8.150.91:8080 Apr 03 16:13:02 aries-b02 seaweedfs-volume-0[501258]: I0403 16:13:02.647847 volume_server_handlers_read.go:160 read /1201,0a4a115622d1530d isNormalVolume false error: readbytes: entry not found: offset 27663713352 found id 34313936356436363739353636653636 size -2007146114, expected size 168275  The problem happens 100% with the file id and the shard at `https://s3-haosu.nrp-nautilus.io/ruoxi-bucket/1201.tar`. **System Setup** - `/usr/local/bin/weed server -volume=0 -filer -dir=/weedfs` - `/usr/local/bin/weed volume -max=400 -dir=/weedfs -mserver=10.8.149.13:9333` on 8 machines different from the master - These commands are done by systemctl services with setups exactly as the wiki page. - OS version: Ubuntu 22.04 - output of `weed version`: version 8000GB 3.63 54d7748a4a54d94a31ce04d05db801faeff4f690 linux amd64 - if using filer, show the content of `filer.toml`: no `filer.toml` - security:  [access] ui = false [grpc] ca = ""/etc/ariesdockerd/certs/Aries_SeaweedFS_CA.crt"" [grpc.volume] cert = ""/etc/ariesdockerd/certs/volume01.crt"" key = ""/etc/ariesdockerd/certs/volume01.key"" [grpc.master] cert = ""/etc/ariesdockerd/certs/master01.crt"" key = ""/etc/ariesdockerd/certs/master01.key"" [grpc.filer] cert = ""/etc/ariesdockerd/certs/filer01.crt"" key = ""/etc/ariesdockerd/certs/filer01.key"" [grpc.client] cert = ""/etc/ariesdockerd/certs/client01.crt"" key = ""/etc/ariesdockerd/certs/client01.key""  - master:  # Put this file to one of the location, with descending priority # ./master.toml # $HOME/.seaweedfs/master.toml # /etc/seaweedfs/master.toml # this file is read by master [master.maintenance] # periodically run these scripts are the same as running them from 'weed shell' scripts =  lock ec.encode -fullPercent=95 -quietFor=1h ec.balance -force volume.deleteEmpty -quietFor=24h -force volume.balance -force unlock  sleep_minutes = 17 # sleep minutes between each script execution [master.sequencer] type = ""raft"" # Choose [raft|snowflake] type for storing the file id sequence # when sequencer.type = snowflake, the snowflake id must be different from other masters sequencer_snowflake_id = 0 # any number between 1~1023 # configurations for tiered cloud storage # old volumes are transparently moved to cloud for cost efficiency [storage.backend] [storage.backend.s3.default] enabled = false aws_access_key_id = """" # if empty, loads from the shared credentials file (~/.aws/credentials). aws_secret_access_key = """" # if empty, loads from the shared credentials file (~/.aws/credentials). region = ""us-east-2"" bucket = ""your_bucket_name"" # an existing bucket endpoint = """" storage_class = ""STANDARD_IA"" # create this number of logical volumes if no more writable volumes # count_x means how many copies of data. # e.g.: # 000 has only one copy, copy_1 # 010 and 001 has two copies, copy_2 # 011 has only 3 copies, copy_3 [master.volume_growth] copy_1 = 7 # create 1 x 7 = 7 actual volumes copy_2 = 6 # create 2 x 6 = 12 actual volumes copy_3 = 3 # create 3 x 3 = 9 actual volumes copy_other = 1 # create n x 1 = n actual volumes # configuration flags for replication [master.replication] # any replication counts should be considered minimums. If you specify 010 and # have 3 different racks, that's still considered writable. Writes will still # try to replicate to all available volumes. You should only use this option # if you are doing your own replication or periodic sync of volumes. treat_replication_as_minimums = false  **Expected behavior** When the EC shard fails, the volume server should try to recover the shard from other shards. other-file source-file test-file",no-bug,0.8
1037,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1037,panic: runtime error: invalid memory address or nil pointer dereference,"we run a 3 nodes cluster, the filer crashed with the logs below: ` I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8086/356,1ceface4bc067f11 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1ceface561ee49ac E0810 09:30:20 50306 filer_server_handlers_write.go:220] failing to connect to volume server /buckets/flying/city_77accf10-de57-4b2a-9290-c454b74855bb_2450ce47-fa12-4675-9178-1a420758a7f4_2019-08-10-09-30-20?collection=flying: Put http://10.1.1.9:8083/358,1cefad550f83e29a: EOF, PUT I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1ceface3c9c41095 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8084/357,1cefaceebf43bfd6 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1cefacec70d021cb I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1cefacea2dc550fc I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.10:8086/355,1cefacf1c7d2c9fc I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8084/357,1cefad18509228e2 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8086/356,1cefacf9cbb94966 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.10:8088/359,1cefad141ac736e7 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.10:8088/359,1cefad26a6f3862d I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8084/357,1cefad3a7c0259cc I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1cefad1a7570d893 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.10:8088/359,1cefaced3a003efa I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1cefad72b0d58766 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0x5ddc4f] goroutine 1891459290 [running]: bufio.(*Writer).Available() /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/bufio/bufio.go:607 bufio.(*Writer).WriteString(0x0, 0x18c2de7, 0x19, 0x10100c00ecbd498, 0x0, 0x8000) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/bufio/bufio.go:688 +0x7f net/http.(*expectContinueReader).Read(0xc00905c1e0, 0xc00a722000, 0x8000, 0x8000, 0xc0130e2c20, 0x44409c, 0x8000) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/server.go:890 +0x13b net/http.transferBodyReader.Read(0xc00eb29cc0, 0xc00a722000, 0x8000, 0x8000, 0x0, 0x2a19e00, 0xc011385ea8) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/transfer.go:62 +0x56 io.copyBuffer(0x7f97ebea0388, 0xc00f992df0, 0x1bd4440, 0xc00eb29cc0, 0xc00a722000, 0x8000, 0x8000, 0x3, 0x1, 0xc0130e2d01) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/io/io.go:402 +0x122 io.Copy() /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/io/io.go:364 net/http.(*transferWriter).writeBody(0xc00eb29cc0, 0x1bce700, 0xc0101f65c0, 0x2, 0x2) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/transfer.go:358 +0x16b net/http.(*Request).write(0xc004719500, 0x1bce700, 0xc0101f65c0, 0x0, 0x0, 0xc00cf8d280, 0x0, 0x0) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/request.go:655 +0x721 net/http.(*persistConn).writeLoop(0xc00003d320) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/transport.go:1979 +0x1b8 created by net/http.(*Transport).dialConn /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/transport.go:1358 +0xb0d`",source-file | source-file | source-file | source-file | source-file | source-file,"panic: runtime error: invalid memory address or nil pointer dereference we run a 3 nodes cluster, the filer crashed with the logs below: ` I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8086/356,1ceface4bc067f11 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1ceface561ee49ac E0810 09:30:20 50306 filer_server_handlers_write.go:220] failing to connect to volume server /buckets/flying/city_77accf10-de57-4b2a-9290-c454b74855bb_2450ce47-fa12-4675-9178-1a420758a7f4_2019-08-10-09-30-20?collection=flying: Put http://10.1.1.9:8083/358,1cefad550f83e29a: EOF, PUT I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1ceface3c9c41095 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8084/357,1cefaceebf43bfd6 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1cefacec70d021cb I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1cefacea2dc550fc I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.10:8086/355,1cefacf1c7d2c9fc I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8084/357,1cefad18509228e2 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8086/356,1cefacf9cbb94966 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.10:8088/359,1cefad141ac736e7 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.10:8088/359,1cefad26a6f3862d I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.8:8084/357,1cefad3a7c0259cc I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1cefad1a7570d893 I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.10:8088/359,1cefaced3a003efa I0810 09:30:20 50306 filer_server_handlers_read.go:110] retrieving from http://10.1.1.9:8083/358,1cefad72b0d58766 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0x5ddc4f] goroutine 1891459290 [running]: bufio.(*Writer).Available() /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/bufio/bufio.go:607 bufio.(*Writer).WriteString(0x0, 0x18c2de7, 0x19, 0x10100c00ecbd498, 0x0, 0x8000) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/bufio/bufio.go:688 +0x7f net/http.(*expectContinueReader).Read(0xc00905c1e0, 0xc00a722000, 0x8000, 0x8000, 0xc0130e2c20, 0x44409c, 0x8000) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/server.go:890 +0x13b net/http.transferBodyReader.Read(0xc00eb29cc0, 0xc00a722000, 0x8000, 0x8000, 0x0, 0x2a19e00, 0xc011385ea8) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/transfer.go:62 +0x56 io.copyBuffer(0x7f97ebea0388, 0xc00f992df0, 0x1bd4440, 0xc00eb29cc0, 0xc00a722000, 0x8000, 0x8000, 0x3, 0x1, 0xc0130e2d01) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/io/io.go:402 +0x122 io.Copy() /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/io/io.go:364 net/http.(*transferWriter).writeBody(0xc00eb29cc0, 0x1bce700, 0xc0101f65c0, 0x2, 0x2) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/transfer.go:358 +0x16b net/http.(*Request).write(0xc004719500, 0x1bce700, 0xc0101f65c0, 0x0, 0x0, 0xc00cf8d280, 0x0, 0x0) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/request.go:655 +0x721 net/http.(*persistConn).writeLoop(0xc00003d320) /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/transport.go:1979 +0x1b8 created by net/http.(*Transport).dialConn /home/travis/.gimme/versions/go1.12.6.linux.amd64/src/net/http/transport.go:1358 +0xb0d` source-file source-file source-file source-file source-file source-file",no-bug,0.8
1353,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1353,Volume server hangs,"**Describe the bug** The volume server http interface is unresponsive. The process is not dead as it is still logging lines like this:  Jun 07 12:08:13 dn-379 weed[38923]: I0607 12:08:13 38923 disk.go:11] read disk size: dir:""/mnt/data-small/data"" all:100000802516992 used:2829158424576 free:97171644092416 percent_free:97.17087 percent_used:2.8291357 Jun 07 12:08:34 dn-379 weed[38923]: I0607 12:08:34 38923 disk.go:11] read disk size: dir:""/mnt/data-small/data"" all:100000802516992 used:2829158424576 free:97171644092416 percent_free:97.17087 percent_used:2.8291357  **System Setup** Same setup as : https://github.com/chrislusf/seaweedfs/issues/1346 5x masters and 5x volume servers:  root 38923 31.5 0.8 11695928 578576 ? Ssl Jun05 770:25 /usr/local/bin/weed -logtostderr -v=1 volume -compactionMBps=50 -port=8080 -mserver=10.1.14.110:9333,10.1.14.111:9333,10.1.14.112:9333,10.1.14.113:9333,10.1.14.114:9333 -dir=/mnt/data-small/data -index leveldb -max 0 -ip 10.1.14.112 -rack dn-379 root 39048 0.4 0.0 5329596 19068 ? Ssl Jun05 11:41 /usr/local/bin/weed -logtostderr master -mdir=/mnt/data-small/meta -ip=10.1.14.112 -defaultReplication=010 -volumePreallocate -volumeSizeLimitMB 30000 -garbageThreshold 0.3 -pulseSeconds 5 -peers=10.1.14.110:9333,10.1.14.111:9333,10.1.14.112:9333,10.1.14.113:9333,10.1.14.114:9333  **Expected behavior** Normal operation **Additional context** The only thing we changed was pulseSeconds from 10 to 5, but now I'm constantly restarting volume servers that hangs. Could it be that the volume server is waiting for replication to go through? I've seen some log lines related to replication failing. This is roughly 30 mins prior to all transfers stopping to the cluster:  Jun 05 21:01:14 dn-379 weed[38923]: I0605 21:01:14 38923 upload_content.go:214] failing to upload to http://10.1.14.110:8080/5172,0e86755ae4c78708?ts=1591383674&ttl=&type=replicate Post http://10.1.14.110:8080/5172,0e86755ae4c78708?ts=1591383674&ttl=&type=replicate: read tcp 10.1.14.112:38402->10.1.14.110:8080: read: connection reset by peer Jun 05 21:01:14 dn-379 weed[38923]: I0605 21:01:14 38923 store_replicate.go:87] failed to write to replicas for volume 5172: [10.1.14.110:8080]: Post http://10.1.14.110:8080/5172,0e86755ae4c78708?ts=1591383674&ttl=&type=replicate: read tcp 10.1.14.112:38402->10.1.14.110:8080: read: connection reset by peer Jun 05 21:01:14 dn-379 weed[38923]: I0605 21:01:14 38923 upload_content.go:214] failing to upload to http://10.1.14.110:8080/5172,0e867549195ab81e?ts=1591383674&ttl=&type=replicate Post http://10.1.14.110:8080/5172,0e867549195ab81e?ts=1591383674&ttl=&type=replicate: read tcp 10.1.14.112:38396->10.1.14.110:8080: read: connection reset by peer Jun 05 21:01:14 dn-379 weed[38923]: I0605 21:01:14 38923 store_replicate.go:87] failed to write to replicas for volume 5172: [10.1.14.110:8080]: Post http://10.1.14.110:8080/5172,0e867549195ab81e?ts=1591383674&ttl=&type=replicate: read tcp 10.1.14.112:38396->10.1.14.110:8080: read: connection reset by peer ",source-file,"Volume server hangs **Describe the bug** The volume server http interface is unresponsive. The process is not dead as it is still logging lines like this:  Jun 07 12:08:13 dn-379 weed[38923]: I0607 12:08:13 38923 disk.go:11] read disk size: dir:""/mnt/data-small/data"" all:100000802516992 used:2829158424576 free:97171644092416 percent_free:97.17087 percent_used:2.8291357 Jun 07 12:08:34 dn-379 weed[38923]: I0607 12:08:34 38923 disk.go:11] read disk size: dir:""/mnt/data-small/data"" all:100000802516992 used:2829158424576 free:97171644092416 percent_free:97.17087 percent_used:2.8291357  **System Setup** Same setup as : https://github.com/chrislusf/seaweedfs/issues/1346 5x masters and 5x volume servers:  root 38923 31.5 0.8 11695928 578576 ? Ssl Jun05 770:25 /usr/local/bin/weed -logtostderr -v=1 volume -compactionMBps=50 -port=8080 -mserver=10.1.14.110:9333,10.1.14.111:9333,10.1.14.112:9333,10.1.14.113:9333,10.1.14.114:9333 -dir=/mnt/data-small/data -index leveldb -max 0 -ip 10.1.14.112 -rack dn-379 root 39048 0.4 0.0 5329596 19068 ? Ssl Jun05 11:41 /usr/local/bin/weed -logtostderr master -mdir=/mnt/data-small/meta -ip=10.1.14.112 -defaultReplication=010 -volumePreallocate -volumeSizeLimitMB 30000 -garbageThreshold 0.3 -pulseSeconds 5 -peers=10.1.14.110:9333,10.1.14.111:9333,10.1.14.112:9333,10.1.14.113:9333,10.1.14.114:9333  **Expected behavior** Normal operation **Additional context** The only thing we changed was pulseSeconds from 10 to 5, but now I'm constantly restarting volume servers that hangs. Could it be that the volume server is waiting for replication to go through? I've seen some log lines related to replication failing. This is roughly 30 mins prior to all transfers stopping to the cluster:  Jun 05 21:01:14 dn-379 weed[38923]: I0605 21:01:14 38923 upload_content.go:214] failing to upload to http://10.1.14.110:8080/5172,0e86755ae4c78708?ts=1591383674&ttl=&type=replicate Post http://10.1.14.110:8080/5172,0e86755ae4c78708?ts=1591383674&ttl=&type=replicate: read tcp 10.1.14.112:38402->10.1.14.110:8080: read: connection reset by peer Jun 05 21:01:14 dn-379 weed[38923]: I0605 21:01:14 38923 store_replicate.go:87] failed to write to replicas for volume 5172: [10.1.14.110:8080]: Post http://10.1.14.110:8080/5172,0e86755ae4c78708?ts=1591383674&ttl=&type=replicate: read tcp 10.1.14.112:38402->10.1.14.110:8080: read: connection reset by peer Jun 05 21:01:14 dn-379 weed[38923]: I0605 21:01:14 38923 upload_content.go:214] failing to upload to http://10.1.14.110:8080/5172,0e867549195ab81e?ts=1591383674&ttl=&type=replicate Post http://10.1.14.110:8080/5172,0e867549195ab81e?ts=1591383674&ttl=&type=replicate: read tcp 10.1.14.112:38396->10.1.14.110:8080: read: connection reset by peer Jun 05 21:01:14 dn-379 weed[38923]: I0605 21:01:14 38923 store_replicate.go:87] failed to write to replicas for volume 5172: [10.1.14.110:8080]: Post http://10.1.14.110:8080/5172,0e867549195ab81e?ts=1591383674&ttl=&type=replicate: read tcp 10.1.14.112:38396->10.1.14.110:8080: read: connection reset by peer  source-file",no-bug,0.9
2637,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2637,Non-replicated volume gets removed because of over replication,"I'm running a cluster with `000` replication and two tiers (ssd and hdd). Some volumes are removed after moving between tiers for some reason yet unknown.  Feb 02 08:31:53 wm-mb-00 weed[19634]: I0202 08:31:53 19634 volume_layout.go:386] Volume 1137830 becomes writable Feb 02 08:31:53 wm-mb-00 weed[19634]: I0202 08:31:53 19634 volume_growth.go:235] Created Volume 1137830 on topo:dc1:hs00:192.168.65.66:8080 Feb 02 08:40:29 wm-mb-00 weed[19634]: I0202 08:40:29 19634 volume_layout.go:449] Volume 1137830 becomes crowded Feb 02 08:41:56 wm-mb-00 weed[19634]: I0202 08:41:56 19634 volume_layout.go:373] Volume 1137830 becomes unwritable Feb 03 02:59:21 wm-mb-00 weed[19634]: tier move volumes: [1137807 1137786 1137819 1137837 1137791 1137821 1137817 1137805 1137813 1137804 1137798 1137827 1137826 1137799 1137820 1137835 1137825 1137824 1137831 1137829 1137834 1137836 1137810 1137811 1137800 1137833 1137796 1137816 1137822 1137802 1137832 1137815 1137830 1137806] Feb 03 03:49:50 wm-mb-00 weed[19634]: moving volume 1137830 from 192.168.65.66:8080 to 192.168.65.51:8080 with disk type hdd  Feb 03 03:49:50 wm-mb-00 weed[19634]: markVolumeReadonly 1137830 on 192.168.65.66:8080  Feb 03 03:49:50 wm-mb-00 weed[19634]: 2022/02/03 03:49:50 copying volume 1137830 from 192.168.65.66:8080 to 192.168.65.51:8080 Feb 03 03:49:51 wm-mb-00 weed[19634]: volume 1137830 processed 136314880 bytes Feb 03 03:49:53 wm-mb-00 weed[19634]: volume 1137830 processed 272629760 bytes Feb 03 03:49:54 wm-mb-00 weed[19634]: volume 1137830 processed 408944640 bytes Feb 03 03:49:55 wm-mb-00 weed[19634]: volume 1137830 processed 545259520 bytes Feb 03 03:49:56 wm-mb-00 weed[19634]: volume 1137830 processed 681574400 bytes Feb 03 03:49:57 wm-mb-00 weed[19634]: volume 1137830 processed 817889280 bytes Feb 03 03:49:59 wm-mb-00 weed[19634]: volume 1137830 processed 954204160 bytes Feb 03 03:50:00 wm-mb-00 weed[19634]: volume 1137830 processed 1090519040 bytes Feb 03 03:50:01 wm-mb-00 weed[19634]: volume 1137830 processed 1226833920 bytes Feb 03 03:50:02 wm-mb-00 weed[19634]: volume 1137830 processed 1363148800 bytes Feb 03 03:50:03 wm-mb-00 weed[19634]: volume 1137830 processed 1499463680 bytes Feb 03 03:50:04 wm-mb-00 weed[19634]: volume 1137830 processed 1635778560 bytes Feb 03 03:50:06 wm-mb-00 weed[19634]: volume 1137830 processed 1772093440 bytes Feb 03 03:50:07 wm-mb-00 weed[19634]: volume 1137830 processed 1908408320 bytes Feb 03 03:50:08 wm-mb-00 weed[19634]: volume 1137830 processed 2044723200 bytes Feb 03 03:50:09 wm-mb-00 weed[19634]: volume 1137830 processed 2181038080 bytes Feb 03 03:50:10 wm-mb-00 weed[19634]: volume 1137830 processed 2317352960 bytes Feb 03 03:50:12 wm-mb-00 weed[19634]: volume 1137830 processed 2453667840 bytes Feb 03 03:50:13 wm-mb-00 weed[19634]: volume 1137830 processed 2589982720 bytes Feb 03 03:50:15 wm-mb-00 weed[19634]: volume 1137830 processed 2726297600 bytes Feb 03 03:50:17 wm-mb-00 weed[19634]: volume 1137830 processed 2862612480 bytes Feb 03 03:50:20 wm-mb-00 weed[19634]: volume 1137830 processed 2998927360 bytes Feb 03 03:50:23 wm-mb-00 weed[19634]: volume 1137830 processed 3135242240 bytes Feb 03 03:51:53 wm-mb-00 weed[19634]: volume 1137830 processed 3271557120 bytes Feb 03 03:51:54 wm-mb-00 weed[19634]: volume 1137830 processed 3407872000 bytes Feb 03 03:51:55 wm-mb-00 weed[19634]: volume 1137830 processed 3544186880 bytes Feb 03 03:51:57 wm-mb-00 weed[19634]: volume 1137830 processed 3680501760 bytes Feb 03 03:51:58 wm-mb-00 weed[19634]: volume 1137830 processed 3816816640 bytes Feb 03 03:51:59 wm-mb-00 weed[19634]: volume 1137830 processed 3953131520 bytes Feb 03 03:52:00 wm-mb-00 weed[19634]: volume 1137830 processed 4089446400 bytes Feb 03 03:52:01 wm-mb-00 weed[19634]: volume 1137830 processed 4225761280 bytes Feb 03 03:52:03 wm-mb-00 weed[19634]: volume 1137830 processed 4362076160 bytes Feb 03 03:52:04 wm-mb-00 weed[19634]: volume 1137830 processed 4498391040 bytes Feb 03 03:52:05 wm-mb-00 weed[19634]: volume 1137830 processed 4634705920 bytes Feb 03 03:52:06 wm-mb-00 weed[19634]: volume 1137830 processed 4771020800 bytes Feb 03 03:52:07 wm-mb-00 weed[19634]: volume 1137830 processed 4907335680 bytes Feb 03 03:52:09 wm-mb-00 weed[19634]: volume 1137830 processed 5043650560 bytes Feb 03 03:52:10 wm-mb-00 weed[19634]: volume 1137830 processed 5179965440 bytes Feb 03 03:52:11 wm-mb-00 weed[19634]: 2022/02/03 03:52:11 tailing volume 1137830 from 192.168.65.66:8080 to 192.168.65.51:8080 Feb 03 03:52:11 wm-mb-00 weed[19634]: I0203 03:52:11 19634 volume_layout.go:386] Volume 1137830 becomes writable Feb 03 03:52:23 wm-mb-00 weed[19634]: 2022/02/03 03:52:23 deleting volume 1137830 from 192.168.65.66:8080 Feb 03 03:52:23 wm-mb-00 weed[19634]: 2022/02/03 03:52:23 moved volume 1137830 from 192.168.65.66:8080 to 192.168.65.51:8080 Feb 03 03:52:23 wm-mb-00 weed[19634]: I0203 03:52:23 19634 topology.go:209] removing volume info: Id:1137830, Size:0, ReplicaPlacement:000, Collection:mb-steps-2022-02-02-08, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from 192.168.65.66:8080 Feb 03 03:52:23 wm-mb-00 weed[19634]: volume 1137830 replication 000, but over replicated +2 Feb 03 03:52:23 wm-mb-00 weed[19634]: deleting volume 1137830 from 192.168.65.51:8080  Feb 03 03:54:35 wm-mb-00 weed[19634]: I0203 03:54:35 19634 volume_layout.go:373] Volume 1137830 becomes unwritable Feb 03 03:55:52 wm-mb-00 weed[19634]: I0203 03:55:52 19634 data_node.go:78] Deleting volume id: 1137830 Feb 03 03:55:52 wm-mb-00 weed[19634]: I0203 03:55:52 19634 topology.go:209] removing volume info: Id:1137830, Size:5283003224, ReplicaPlacement:000, Collection:mb-steps-2022-02-02-08, Version:3, FileCount:176442, DeleteCount:207, DeletedByteCount:5645668, ReadOnly:false from 192.168.65.51:8080 Feb 03 03:55:52 wm-mb-00 weed[19634]: I0203 03:55:52 19634 master_grpc_server.go:125] master see deleted volume 1137830 from 192.168.65.51:8080 Feb 03 03:55:52 wm-mb-00 weed[19634]: I0203 03:55:52 19634 topology.go:209] removing volume info: Id:1137830, Size:0, ReplicaPlacement:000, Collection:mb-steps-2022-02-02-08, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from 192.168.65.51:8080  I might be thinking that latest parallel migration changes are responsible for that, but I can find such records in my log days before the change. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version: Debian 10 - output of `weed version`: `version 30GB 2.88 7270067289802307556d117be422a1e5a208f558 linux amd64`",source-file,"Non-replicated volume gets removed because of over replication I'm running a cluster with `000` replication and two tiers (ssd and hdd). Some volumes are removed after moving between tiers for some reason yet unknown.  Feb 02 08:31:53 wm-mb-00 weed[19634]: I0202 08:31:53 19634 volume_layout.go:386] Volume 1137830 becomes writable Feb 02 08:31:53 wm-mb-00 weed[19634]: I0202 08:31:53 19634 volume_growth.go:235] Created Volume 1137830 on topo:dc1:hs00:192.168.65.66:8080 Feb 02 08:40:29 wm-mb-00 weed[19634]: I0202 08:40:29 19634 volume_layout.go:449] Volume 1137830 becomes crowded Feb 02 08:41:56 wm-mb-00 weed[19634]: I0202 08:41:56 19634 volume_layout.go:373] Volume 1137830 becomes unwritable Feb 03 02:59:21 wm-mb-00 weed[19634]: tier move volumes: [1137807 1137786 1137819 1137837 1137791 1137821 1137817 1137805 1137813 1137804 1137798 1137827 1137826 1137799 1137820 1137835 1137825 1137824 1137831 1137829 1137834 1137836 1137810 1137811 1137800 1137833 1137796 1137816 1137822 1137802 1137832 1137815 1137830 1137806] Feb 03 03:49:50 wm-mb-00 weed[19634]: moving volume 1137830 from 192.168.65.66:8080 to 192.168.65.51:8080 with disk type hdd  Feb 03 03:49:50 wm-mb-00 weed[19634]: markVolumeReadonly 1137830 on 192.168.65.66:8080  Feb 03 03:49:50 wm-mb-00 weed[19634]: 2022/02/03 03:49:50 copying volume 1137830 from 192.168.65.66:8080 to 192.168.65.51:8080 Feb 03 03:49:51 wm-mb-00 weed[19634]: volume 1137830 processed 136314880 bytes Feb 03 03:49:53 wm-mb-00 weed[19634]: volume 1137830 processed 272629760 bytes Feb 03 03:49:54 wm-mb-00 weed[19634]: volume 1137830 processed 408944640 bytes Feb 03 03:49:55 wm-mb-00 weed[19634]: volume 1137830 processed 545259520 bytes Feb 03 03:49:56 wm-mb-00 weed[19634]: volume 1137830 processed 681574400 bytes Feb 03 03:49:57 wm-mb-00 weed[19634]: volume 1137830 processed 817889280 bytes Feb 03 03:49:59 wm-mb-00 weed[19634]: volume 1137830 processed 954204160 bytes Feb 03 03:50:00 wm-mb-00 weed[19634]: volume 1137830 processed 1090519040 bytes Feb 03 03:50:01 wm-mb-00 weed[19634]: volume 1137830 processed 1226833920 bytes Feb 03 03:50:02 wm-mb-00 weed[19634]: volume 1137830 processed 1363148800 bytes Feb 03 03:50:03 wm-mb-00 weed[19634]: volume 1137830 processed 1499463680 bytes Feb 03 03:50:04 wm-mb-00 weed[19634]: volume 1137830 processed 1635778560 bytes Feb 03 03:50:06 wm-mb-00 weed[19634]: volume 1137830 processed 1772093440 bytes Feb 03 03:50:07 wm-mb-00 weed[19634]: volume 1137830 processed 1908408320 bytes Feb 03 03:50:08 wm-mb-00 weed[19634]: volume 1137830 processed 2044723200 bytes Feb 03 03:50:09 wm-mb-00 weed[19634]: volume 1137830 processed 2181038080 bytes Feb 03 03:50:10 wm-mb-00 weed[19634]: volume 1137830 processed 2317352960 bytes Feb 03 03:50:12 wm-mb-00 weed[19634]: volume 1137830 processed 2453667840 bytes Feb 03 03:50:13 wm-mb-00 weed[19634]: volume 1137830 processed 2589982720 bytes Feb 03 03:50:15 wm-mb-00 weed[19634]: volume 1137830 processed 2726297600 bytes Feb 03 03:50:17 wm-mb-00 weed[19634]: volume 1137830 processed 2862612480 bytes Feb 03 03:50:20 wm-mb-00 weed[19634]: volume 1137830 processed 2998927360 bytes Feb 03 03:50:23 wm-mb-00 weed[19634]: volume 1137830 processed 3135242240 bytes Feb 03 03:51:53 wm-mb-00 weed[19634]: volume 1137830 processed 3271557120 bytes Feb 03 03:51:54 wm-mb-00 weed[19634]: volume 1137830 processed 3407872000 bytes Feb 03 03:51:55 wm-mb-00 weed[19634]: volume 1137830 processed 3544186880 bytes Feb 03 03:51:57 wm-mb-00 weed[19634]: volume 1137830 processed 3680501760 bytes Feb 03 03:51:58 wm-mb-00 weed[19634]: volume 1137830 processed 3816816640 bytes Feb 03 03:51:59 wm-mb-00 weed[19634]: volume 1137830 processed 3953131520 bytes Feb 03 03:52:00 wm-mb-00 weed[19634]: volume 1137830 processed 4089446400 bytes Feb 03 03:52:01 wm-mb-00 weed[19634]: volume 1137830 processed 4225761280 bytes Feb 03 03:52:03 wm-mb-00 weed[19634]: volume 1137830 processed 4362076160 bytes Feb 03 03:52:04 wm-mb-00 weed[19634]: volume 1137830 processed 4498391040 bytes Feb 03 03:52:05 wm-mb-00 weed[19634]: volume 1137830 processed 4634705920 bytes Feb 03 03:52:06 wm-mb-00 weed[19634]: volume 1137830 processed 4771020800 bytes Feb 03 03:52:07 wm-mb-00 weed[19634]: volume 1137830 processed 4907335680 bytes Feb 03 03:52:09 wm-mb-00 weed[19634]: volume 1137830 processed 5043650560 bytes Feb 03 03:52:10 wm-mb-00 weed[19634]: volume 1137830 processed 5179965440 bytes Feb 03 03:52:11 wm-mb-00 weed[19634]: 2022/02/03 03:52:11 tailing volume 1137830 from 192.168.65.66:8080 to 192.168.65.51:8080 Feb 03 03:52:11 wm-mb-00 weed[19634]: I0203 03:52:11 19634 volume_layout.go:386] Volume 1137830 becomes writable Feb 03 03:52:23 wm-mb-00 weed[19634]: 2022/02/03 03:52:23 deleting volume 1137830 from 192.168.65.66:8080 Feb 03 03:52:23 wm-mb-00 weed[19634]: 2022/02/03 03:52:23 moved volume 1137830 from 192.168.65.66:8080 to 192.168.65.51:8080 Feb 03 03:52:23 wm-mb-00 weed[19634]: I0203 03:52:23 19634 topology.go:209] removing volume info: Id:1137830, Size:0, ReplicaPlacement:000, Collection:mb-steps-2022-02-02-08, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from 192.168.65.66:8080 Feb 03 03:52:23 wm-mb-00 weed[19634]: volume 1137830 replication 000, but over replicated +2 Feb 03 03:52:23 wm-mb-00 weed[19634]: deleting volume 1137830 from 192.168.65.51:8080  Feb 03 03:54:35 wm-mb-00 weed[19634]: I0203 03:54:35 19634 volume_layout.go:373] Volume 1137830 becomes unwritable Feb 03 03:55:52 wm-mb-00 weed[19634]: I0203 03:55:52 19634 data_node.go:78] Deleting volume id: 1137830 Feb 03 03:55:52 wm-mb-00 weed[19634]: I0203 03:55:52 19634 topology.go:209] removing volume info: Id:1137830, Size:5283003224, ReplicaPlacement:000, Collection:mb-steps-2022-02-02-08, Version:3, FileCount:176442, DeleteCount:207, DeletedByteCount:5645668, ReadOnly:false from 192.168.65.51:8080 Feb 03 03:55:52 wm-mb-00 weed[19634]: I0203 03:55:52 19634 master_grpc_server.go:125] master see deleted volume 1137830 from 192.168.65.51:8080 Feb 03 03:55:52 wm-mb-00 weed[19634]: I0203 03:55:52 19634 topology.go:209] removing volume info: Id:1137830, Size:0, ReplicaPlacement:000, Collection:mb-steps-2022-02-02-08, Version:3, FileCount:0, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from 192.168.65.51:8080  I might be thinking that latest parallel migration changes are responsible for that, but I can find such records in my log days before the change. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version: Debian 10 - output of `weed version`: `version 30GB 2.88 7270067289802307556d117be422a1e5a208f558 linux amd64` source-file",no-bug,0.9
1551,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1551,[Git 6e8c2bfd - 8000GB Build] ec.balance is using incorrect filenames,"I've been testing distribution and error handling, and have been forcing ec's with the following command: > lock > ec.encode -fullPercent=0.001 -quietFor=1s > unlock This has been successfully creating ec shards, but when the balance is run, it's referencing the wrong filename. Excerpt from the log below:  Oct 21 22:24:39 bedb-master1 weed[8055]: I1021 22:24:39 8055 master_server.go:259] error: balance across racks collection fax-mke1 ec shards: copy 14.[7] 10.60.1.213:8080 => 10.60.31.211:8080 : rpc error: code = Unknown desc = VolumeEcShardsCopy volume 14: failed to copy /usr/local/seaweedvol/fax-mke1_14.ec07 file: receiving /usr/local/seaweedvol/fax-mke1_14.ec07: rpc error: code = Unknown desc = CopyFile not found ec volume id 14  The 'fax-mke1_' prefix does not exist on the source volume server  root@mke1-vol3:/usr/local/seaweedvol# ls -al /usr/local/seaweedvol/*14.ec07 -rw-r--r-- 1 www-data www-data 1048576 Oct 21 22:12 /usr/local/seaweedvol/14.ec07 root@mke1-vol3:/usr/local/seaweedvol#  In fact, there is only one file that matches *14.ec07 (as you would expect), and that is not tagged with the fax-mke1 prefix.  [root@xrobau ansible]# ansible seaweed_volservers -i hosts -m shell -a 'ls -al /usr/local/seaweedvol/*14.ec07' 10.60.1.211 | FAILED | rc=2 >> ls: cannot access '/usr/local/seaweedvol/*14.ec07': No such file or directorynon-zero return code 10.60.1.212 | FAILED | rc=2 >> ls: cannot access '/usr/local/seaweedvol/*14.ec07': No such file or directorynon-zero return code 10.60.1.213 | CHANGED | rc=0 >> -rw-r--r-- 1 www-data www-data 1048576 Oct 21 22:12 /usr/local/seaweedvol/14.ec07 10.60.11.212 | FAILED | rc=2 >> ls: cannot access '/usr/local/seaweedvol/*14.ec07': No such file or directorynon-zero return code 10.60.11.211 | FAILED | rc=2 >> ls: cannot access '/usr/local/seaweedvol/*14.ec07': No such file or directorynon-zero return code 10.60.31.211 | CHANGED | rc=0 >> -rw-r--r-- 1 www-data www-data 0 Oct 22 03:24 /usr/local/seaweedvol/fax-mke1_14.ec07 [root@xrobau ansible]#  Note that a zero-byte file was CREATED, but never used. As a possible related point, that 'mke-fax1' collection was originally created using the s3 endpoint, but then was FUSE Mounted and rsync'ed data directly into it.",source-file,"[Git 6e8c2bfd - 8000GB Build] ec.balance is using incorrect filenames I've been testing distribution and error handling, and have been forcing ec's with the following command: > lock > ec.encode -fullPercent=0.001 -quietFor=1s > unlock This has been successfully creating ec shards, but when the balance is run, it's referencing the wrong filename. Excerpt from the log below:  Oct 21 22:24:39 bedb-master1 weed[8055]: I1021 22:24:39 8055 master_server.go:259] error: balance across racks collection fax-mke1 ec shards: copy 14.[7] 10.60.1.213:8080 => 10.60.31.211:8080 : rpc error: code = Unknown desc = VolumeEcShardsCopy volume 14: failed to copy /usr/local/seaweedvol/fax-mke1_14.ec07 file: receiving /usr/local/seaweedvol/fax-mke1_14.ec07: rpc error: code = Unknown desc = CopyFile not found ec volume id 14  The 'fax-mke1_' prefix does not exist on the source volume server  root@mke1-vol3:/usr/local/seaweedvol# ls -al /usr/local/seaweedvol/*14.ec07 -rw-r--r-- 1 www-data www-data 1048576 Oct 21 22:12 /usr/local/seaweedvol/14.ec07 root@mke1-vol3:/usr/local/seaweedvol#  In fact, there is only one file that matches *14.ec07 (as you would expect), and that is not tagged with the fax-mke1 prefix.  [root@xrobau ansible]# ansible seaweed_volservers -i hosts -m shell -a 'ls -al /usr/local/seaweedvol/*14.ec07' 10.60.1.211 | FAILED | rc=2 >> ls: cannot access '/usr/local/seaweedvol/*14.ec07': No such file or directorynon-zero return code 10.60.1.212 | FAILED | rc=2 >> ls: cannot access '/usr/local/seaweedvol/*14.ec07': No such file or directorynon-zero return code 10.60.1.213 | CHANGED | rc=0 >> -rw-r--r-- 1 www-data www-data 1048576 Oct 21 22:12 /usr/local/seaweedvol/14.ec07 10.60.11.212 | FAILED | rc=2 >> ls: cannot access '/usr/local/seaweedvol/*14.ec07': No such file or directorynon-zero return code 10.60.11.211 | FAILED | rc=2 >> ls: cannot access '/usr/local/seaweedvol/*14.ec07': No such file or directorynon-zero return code 10.60.31.211 | CHANGED | rc=0 >> -rw-r--r-- 1 www-data www-data 0 Oct 22 03:24 /usr/local/seaweedvol/fax-mke1_14.ec07 [root@xrobau ansible]#  Note that a zero-byte file was CREATED, but never used. As a possible related point, that 'mke-fax1' collection was originally created using the s3 endpoint, but then was FUSE Mounted and rsync'ed data directly into it. source-file",no-bug,0.9
1461,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1461,ListParts,"version:1.90 seaweedfsserver,ClientListPartsserverParts Client #1432 listPartOutputParts [{ ETag: ""\""d7e02d037f566a94069d42f3424a5184\"""", LastModified: 2020-09-11 07:58:54 +0000 UTC, PartNumber: 1, Size: 5242880 } { ETag: ""\""19516d404b818722bdb3534350f50053\"""", LastModified: 2020-09-11 07:58:54 +0000 UTC, PartNumber: 2, Size: 5242880 } { ETag: ""\""21e6e1deb3b4af85a92b3d4bb5fd190f\"""", LastModified: 2020-09-11 07:58:55 +0000 UTC, PartNumber: 3, Size: 5242880 }] seaweedfsServer Client",test-file | source-file | test-file | source-file | source-file,"ListParts version:1.90 seaweedfsserver,ClientListPartsserverParts Client #1432 listPartOutputParts [{ ETag: ""\""d7e02d037f566a94069d42f3424a5184\"""", LastModified: 2020-09-11 07:58:54 +0000 UTC, PartNumber: 1, Size: 5242880 } { ETag: ""\""19516d404b818722bdb3534350f50053\"""", LastModified: 2020-09-11 07:58:54 +0000 UTC, PartNumber: 2, Size: 5242880 } { ETag: ""\""21e6e1deb3b4af85a92b3d4bb5fd190f\"""", LastModified: 2020-09-11 07:58:55 +0000 UTC, PartNumber: 3, Size: 5242880 }] seaweedfsServer Client test-file source-file test-file source-file source-file",no-bug,0.7
1691,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1691,When updating from 2.15 to 2.16 got panic on filler,"**Describe the bug** When updating from 2.15 to 2.16 got panic on filler **System Setup** 2.16 **Additional context**  I1221 07:45:42 1 filer.go:101] existing filer.store.id = -395420478 I1221 07:45:42 1 configuration.go:28] configured filer for mysql panic: reflect: call of reflect.Value.Elem on zero Value goroutine 1 [running]: reflect.Value.Elem(0x0, 0x0, 0x0, 0x5, 0x37f5fc0, 0x1) /usr/lib/go/src/reflect/value.go:837 +0x1c3 github.com/chrislusf/seaweedfs/weed/filer.(*Filer).LoadConfiguration(0xc000469340, 0xc00023e900) /go/src/github.com/chrislusf/seaweedfs/weed/filer/configuration.go:63 +0x474 github.com/chrislusf/seaweedfs/weed/server.NewFilerServer(0xc000410880, 0xc000410880, 0xc000270000, 0x1, 0x0, 0x0) /go/src/github.com/chrislusf/seaweedfs/weed/server/filer_server.go:121 +0x83b github.com/chrislusf/seaweedfs/weed/command.(*FilerOptions).startFiler(0x37d4b00) /go/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:140 +0x2ed github.com/chrislusf/seaweedfs/weed/command.runFiler(0x372ef00, 0xc00003c1d0, 0x0, 0x0, 0x0) /go/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:116 +0x82 main.main() /go/src/github.com/chrislusf/seaweedfs/weed/weed.go:66 +0x2f9 ",source-file | source-file,"When updating from 2.15 to 2.16 got panic on filler **Describe the bug** When updating from 2.15 to 2.16 got panic on filler **System Setup** 2.16 **Additional context**  I1221 07:45:42 1 filer.go:101] existing filer.store.id = -395420478 I1221 07:45:42 1 configuration.go:28] configured filer for mysql panic: reflect: call of reflect.Value.Elem on zero Value goroutine 1 [running]: reflect.Value.Elem(0x0, 0x0, 0x0, 0x5, 0x37f5fc0, 0x1) /usr/lib/go/src/reflect/value.go:837 +0x1c3 github.com/chrislusf/seaweedfs/weed/filer.(*Filer).LoadConfiguration(0xc000469340, 0xc00023e900) /go/src/github.com/chrislusf/seaweedfs/weed/filer/configuration.go:63 +0x474 github.com/chrislusf/seaweedfs/weed/server.NewFilerServer(0xc000410880, 0xc000410880, 0xc000270000, 0x1, 0x0, 0x0) /go/src/github.com/chrislusf/seaweedfs/weed/server/filer_server.go:121 +0x83b github.com/chrislusf/seaweedfs/weed/command.(*FilerOptions).startFiler(0x37d4b00) /go/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:140 +0x2ed github.com/chrislusf/seaweedfs/weed/command.runFiler(0x372ef00, 0xc00003c1d0, 0x0, 0x0, 0x0) /go/src/github.com/chrislusf/seaweedfs/weed/command/filer.go:116 +0x82 main.main() /go/src/github.com/chrislusf/seaweedfs/weed/weed.go:66 +0x2f9  source-file source-file",no-bug,0.9
2235,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2235,`volume.fix.replication` retries even when there is no error,**Describe the bug** Setting the `-retry` option on `volume.fix.replication` causes it to retry for the given number of times even when there has been no error. **Expected behavior** It should only retry when there is error **Screenshots** ![2021-08-03_19-12](https://user-images.githubusercontent.com/4532423/128006099-bd7b9dea-dd74-40e0-b99d-d073d8fda33a.png) **Additional context** It seems that the `continue` directive [here](https://github.com/chrislusf/seaweedfs/blob/master/weed/shell/command_volume_fix_replication.go#L163) should be `break` instead.,source-file,`volume.fix.replication` retries even when there is no error **Describe the bug** Setting the `-retry` option on `volume.fix.replication` causes it to retry for the given number of times even when there has been no error. **Expected behavior** It should only retry when there is error **Screenshots** ![2021-08-03_19-12](https://user-images.githubusercontent.com/4532423/128006099-bd7b9dea-dd74-40e0-b99d-d073d8fda33a.png) **Additional context** It seems that the `continue` directive [here](https://github.com/chrislusf/seaweedfs/blob/master/weed/shell/command_volume_fix_replication.go#L163) should be `break` instead. source-file,no-bug,0.9
5014,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5014,[filer.backup] avoid backup truncated files,"**Describe the bug** Files from a month ago were synchronized, some of which had already been deleted. **System Setup** `weed filer.backup -filerPath ""/""` `3.57` replication.toml:  [sink.s3] enabled = true aws_access_key_id = ""xxxx"" aws_secret_access_key = ""yyyy"" region = ""us-east-2"" bucket = ""backups"" directory = ""/docs"" endpoint = ""https://storage"" is_incremental = true  **Expected behavior** Skip backup there is a delete_chunks:true flag **Additional context**  E1110 20:37:02.241428 filer_pb_tail.go:89 process directory:""/documents/8/7/2"" event_notification:{ new_entry:{name:""87279e8754b8d728c696c47445ebaf10-thumb-bak"" chunks:{file_id:""8,679a6278ced870"" size:14490 modified_ts_ns:1692373608704630899 e_tag:""zT9IpGyOtAT5/jgfmOD+eg=="" fid:{volume_id:8 file_key:6789730 cookie:2026821744}} attributes:{file_size:14490 mtime:1678822702 file_mode:4 20 uid:990 gid:990 crtime:1692373608 mime:""image/jpeg"" inode:9740092430445530816}} delete_chunks:true new_parent_path:""/documents/8/7/2"" signatures:1520837357 signatures:-1416986718} ts_ns:169237360870954990 1: create entry1 : RequestError: send request failed caused by: Put ""https://storage/backups/docs/2023-03-14/documents/8/7/2/87279e8754b8d728c696c47445ebaf10-thumb-bak"": http://192.168.0.1:8080/8,679a6278ced870?readDeleted=true: 404 Not Found ",source-file,"[filer.backup] avoid backup truncated files **Describe the bug** Files from a month ago were synchronized, some of which had already been deleted. **System Setup** `weed filer.backup -filerPath ""/""` `3.57` replication.toml:  [sink.s3] enabled = true aws_access_key_id = ""xxxx"" aws_secret_access_key = ""yyyy"" region = ""us-east-2"" bucket = ""backups"" directory = ""/docs"" endpoint = ""https://storage"" is_incremental = true  **Expected behavior** Skip backup there is a delete_chunks:true flag **Additional context**  E1110 20:37:02.241428 filer_pb_tail.go:89 process directory:""/documents/8/7/2"" event_notification:{ new_entry:{name:""87279e8754b8d728c696c47445ebaf10-thumb-bak"" chunks:{file_id:""8,679a6278ced870"" size:14490 modified_ts_ns:1692373608704630899 e_tag:""zT9IpGyOtAT5/jgfmOD+eg=="" fid:{volume_id:8 file_key:6789730 cookie:2026821744}} attributes:{file_size:14490 mtime:1678822702 file_mode:4 20 uid:990 gid:990 crtime:1692373608 mime:""image/jpeg"" inode:9740092430445530816}} delete_chunks:true new_parent_path:""/documents/8/7/2"" signatures:1520837357 signatures:-1416986718} ts_ns:169237360870954990 1: create entry1 : RequestError: send request failed caused by: Put ""https://storage/backups/docs/2023-03-14/documents/8/7/2/87279e8754b8d728c696c47445ebaf10-thumb-bak"": http://192.168.0.1:8080/8,679a6278ced870?readDeleted=true: 404 Not Found  source-file",no-bug,0.9
1701,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1701,[filer] Internal looping ListDirectoryPrefixedEntries (Critical),"**Describe the bug** CPU load 100% and internal looping ListDirectoryPrefixedEntries **System Setup** 2.16 from master branch **Additional context**  I1223 16:53:28 1 filerstore_wrapper.go:224] ListDirectoryPrefixedEntries /buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256 from prefix limit 8 I1223 16:53:28 1 filer_client.go:113] read directory: directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filer_client.go:113] read directory: directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filer_grpc_server.go:49] ListEntries directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filerstore_wrapper.go:224] ListDirectoryPrefixedEntries /buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256 from prefix limit 8 I1223 16:53:28 1 filer_client.go:113] read directory: directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filer_grpc_server.go:49] ListEntries directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filerstore_wrapper.go:224] ListDirectoryPrefixedEntries /buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256 from prefix limit 8 I1223 16:53:28 1 filer_client.go:113] read directory: directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 ",source-file | source-file,"[filer] Internal looping ListDirectoryPrefixedEntries (Critical) **Describe the bug** CPU load 100% and internal looping ListDirectoryPrefixedEntries **System Setup** 2.16 from master branch **Additional context**  I1223 16:53:28 1 filerstore_wrapper.go:224] ListDirectoryPrefixedEntries /buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256 from prefix limit 8 I1223 16:53:28 1 filer_client.go:113] read directory: directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filer_client.go:113] read directory: directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filer_grpc_server.go:49] ListEntries directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filerstore_wrapper.go:224] ListDirectoryPrefixedEntries /buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256 from prefix limit 8 I1223 16:53:28 1 filer_client.go:113] read directory: directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filer_grpc_server.go:49] ListEntries directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8 I1223 16:53:28 1 filerstore_wrapper.go:224] ListDirectoryPrefixedEntries /buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256 from prefix limit 8 I1223 16:53:28 1 filer_client.go:113] read directory: directory:""/buckets/registry/docker/registry/v2/repositories/library/seaweedfs/_uploads/22c98200-169f-4535-b013-e87a63c598f8/hashstates/sha256"" limit:8  source-file source-file",no-bug,0.9
211,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/211,"seaweedfs will read the whole content into memory, and duplicate ones for many clients reading the same file","When downloading a file, seaweedfs will read the whole content into memory, and then send that. And if many clients are downloading big files simultaneously, seaweedfs will generate many copies(not cache the content for the same file), and that will cost too much memory, so that linux OOM killer will kill volume process. seaweedfs will generate many copies, and that will cost too much memory, so that OOM killer will kill volume process. There are 2 solutions for this: 1. use NeedleCache, and make sure only one file content stays in memory 2. use syscall.Sendfile for downloading(but that doesnot support the CRC, picture rotating, resizing very well)",source-file | source-file | source-file | source-file,"seaweedfs will read the whole content into memory, and duplicate ones for many clients reading the same file When downloading a file, seaweedfs will read the whole content into memory, and then send that. And if many clients are downloading big files simultaneously, seaweedfs will generate many copies(not cache the content for the same file), and that will cost too much memory, so that linux OOM killer will kill volume process. seaweedfs will generate many copies, and that will cost too much memory, so that OOM killer will kill volume process. There are 2 solutions for this: 1. use NeedleCache, and make sure only one file content stays in memory 2. use syscall.Sendfile for downloading(but that doesnot support the CRC, picture rotating, resizing very well) source-file source-file source-file source-file",no-bug,0.9
1512,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1512,2.03: FUSE read error on graceful volume shutdown,"A simple test setup: one master (started with `-defaultReplication=001`), one filer, two volume servers. Filer started with `-defaultReplicaPlacement=001 -encryptVolumeData -disableHttp`. Mounted file system with FUSE, copied 30 GB to the store, observed symmetric volume data growth on both volume servers. Run CRC check on data and during read operations stopped one volume server gracefully (with Ctrl+C). After 10 seconds, the very moment volume server stopped, got an `Read failed: Input/output error`. FUSE mount reported the following error:  fuse: panic in handler for Read [ID=0x17b830 Node=0x22 Uid=1000 Gid=1000 Pid=96109] 0x1 131072 @0x1607c000 dir=false fl=0 lock=0 ffl=OpenReadOnly: runtime error: slice bounds out of range [:114688] with capacity 0  During CRC check, both volume servers were active (I/O, CPU). I'm not sure whether this problem is incomplete replication or lack of fail-over (to alternative/available volume) in FUSE client. It does not matter which volume server I stop as stopping either of them result in read error on FUSE mount. I tried to re-start CRC check with just one volume server but that failed with read error as well, despite explicit prior `volume.balance` and `volume.fix.replication` given in `weed shell` (both commands did not report anything). It looks like data landed to both volume servers, that have identical size of ""data"" directory roughly matching the amount of data copied to FUSE mount. So replication appears to be working yet I could not read the whole data from FUSE mount when one volume server not running.",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"2.03: FUSE read error on graceful volume shutdown A simple test setup: one master (started with `-defaultReplication=001`), one filer, two volume servers. Filer started with `-defaultReplicaPlacement=001 -encryptVolumeData -disableHttp`. Mounted file system with FUSE, copied 30 GB to the store, observed symmetric volume data growth on both volume servers. Run CRC check on data and during read operations stopped one volume server gracefully (with Ctrl+C). After 10 seconds, the very moment volume server stopped, got an `Read failed: Input/output error`. FUSE mount reported the following error:  fuse: panic in handler for Read [ID=0x17b830 Node=0x22 Uid=1000 Gid=1000 Pid=96109] 0x1 131072 @0x1607c000 dir=false fl=0 lock=0 ffl=OpenReadOnly: runtime error: slice bounds out of range [:114688] with capacity 0  During CRC check, both volume servers were active (I/O, CPU). I'm not sure whether this problem is incomplete replication or lack of fail-over (to alternative/available volume) in FUSE client. It does not matter which volume server I stop as stopping either of them result in read error on FUSE mount. I tried to re-start CRC check with just one volume server but that failed with read error as well, despite explicit prior `volume.balance` and `volume.fix.replication` given in `weed shell` (both commands did not report anything). It looks like data landed to both volume servers, that have identical size of ""data"" directory roughly matching the amount of data copied to FUSE mount. So replication appears to be working yet I could not read the whole data from FUSE mount when one volume server not running. source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.9
4646,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4646,[shell] volume 1415 replication 100 is not well placed [0xc001bed030 0xc001beed00],"If the replica ended up in the same DC, then you need to move the volume, and not delete it  volume 1415 replication 100 is not well placed [0xc001bed030 0xc001beed00] deleting volume 1415 from fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080  I0707 07:03:47.225710 volume_layout.go:226 volume 1415 does not have enough copies I0707 07:03:47.225724 volume_layout.go:231 volume 1415 remove from writable I0707 07:03:47.225732 volume_layout.go:383 Volume 1415 becomes unwritable I0707 07:03:47.227073 volume_grpc_client_to_master.go:210 volume server fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 deletes volume 1415 I0707 07:03:47.226889 store.go:526 DeleteVolume 1415 ",source-file,"[shell] volume 1415 replication 100 is not well placed [0xc001bed030 0xc001beed00] If the replica ended up in the same DC, then you need to move the volume, and not delete it  volume 1415 replication 100 is not well placed [0xc001bed030 0xc001beed00] deleting volume 1415 from fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080  I0707 07:03:47.225710 volume_layout.go:226 volume 1415 does not have enough copies I0707 07:03:47.225724 volume_layout.go:231 volume 1415 remove from writable I0707 07:03:47.225732 volume_layout.go:383 Volume 1415 becomes unwritable I0707 07:03:47.227073 volume_grpc_client_to_master.go:210 volume server fast-volume-2.s3-fast-volume.service.dcvcs.consul:8080 deletes volume 1415 I0707 07:03:47.226889 store.go:526 DeleteVolume 1415  source-file",no-bug,0.9
337,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/337,Setup SeaweedFS with a redis cluster that requires a password,"My Redis cluster requires a password for client libraries to connect to it, does SeaweedFS have the ability to connect to a cluster that requires a password? if not it would be great if it could. I tried this command but it fails: `weed filer -redis.server=localhost:6379 -redis.pass='my password'`",container-file | container-file | other-file | config-file | other-file | other-file | config-file,"Setup SeaweedFS with a redis cluster that requires a password My Redis cluster requires a password for client libraries to connect to it, does SeaweedFS have the ability to connect to a cluster that requires a password? if not it would be great if it could. I tried this command but it fails: `weed filer -redis.server=localhost:6379 -redis.pass='my password'` container-file container-file other-file config-file other-file other-file config-file",no-bug,0.9
840,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/840,volume start error,"I was maked the master and volume started on one server; but when started the volume ,notifyed 0111 03:26:09 3035 volume_grpc_client_to_master.go:32] heartbeat error: fail to dial localhost:9333 : context deadline exceeded go version ,1.11.4 weed version,1.21 what's wrong with the config",source-file | source-file | source-file | source-file | source-file | source-file | source-file,"volume start error I was maked the master and volume started on one server; but when started the volume ,notifyed 0111 03:26:09 3035 volume_grpc_client_to_master.go:32] heartbeat error: fail to dial localhost:9333 : context deadline exceeded go version ,1.11.4 weed version,1.21 what's wrong with the config source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
4289,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4289,File size is different from the sum of chunks (from meta.cat),"**Describe the bug** The Filer has different views on the size of the file, leading to file corruption The file is in a directory that is pointing to an Azure Storage remote. **System Setup**  > weed version version 30GB 3.42 8821d6b1619b7a55b515a98391193297e77cbe52 linux amd64 > /usr/local/bin/weed -v=3 -logdir=/mnt/seaweed_bcminioresearch/logs server -master.dir=/mnt/seaweed_bcminioresearch/master -volume.index=leveldb -volume.max=8 -filer.dirListLimit=10000 -metricsPort=9327 -dir=/mnt/seaweed_bcminioresearch -s3 > lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 22.10 Release: 22.10 Codename: kinetic  **Screenshots**  # in weed shell > meta.cat /buckets/bcminioresearch/models/datasets/credit/global_credit_data_monthly/live/_metadata { ""name"": ""_metadata"", ""isDirectory"": false, ""chunks"": [ { ""fileId"": ""28,4231f9c5edef"", ""offset"": ""0"", ""size"": ""1225797"", ""modifiedTsNs"": ""1678106055"", ""eTag"": ""b53111d5"", ""sourceFileId"": """", ""fid"": { ""volumeId"": 28, ""fileKey"": ""16945"", ""cookie"": 4190498287 }, ""sourceFid"": null, ""cipherKey"": """", ""isCompressed"": false, ""isChunkManifest"": false } ], ""attributes"": { ""fileSize"": ""1236149"", ""mtime"": ""1678264028"", ""fileMode"": 420, ""uid"": 0, ""gid"": 0, ""crtime"": ""0"", ""mime"": """", ""ttlSec"": 0, ""userName"": """", ""groupName"": [], ""symlinkTarget"": """", ""md5"": """", ""rdev"": 0, ""inode"": ""0"" }, ""extended"": {}, ""hardLinkId"": """", ""hardLinkCounter"": 0, ""content"": """", ""remoteEntry"": { ""storageName"": ""azure"", ""lastLocalSyncTsNs"": ""0"", ""remoteETag"": ""0x8DB1FAEE885E3FA"", ""remoteMtime"": ""1678264028"", ""remoteSize"": ""1236149"" }, ""quota"": ""0"" }chunks 1 meta size: 116 gzip:144  You'll notice that `atttributes.fileSize` and `chunks[0].size` are different. **Expected behavior** The file has only one chunk, I would have expected those two to be the same",source-file,"File size is different from the sum of chunks (from meta.cat) **Describe the bug** The Filer has different views on the size of the file, leading to file corruption The file is in a directory that is pointing to an Azure Storage remote. **System Setup**  > weed version version 30GB 3.42 8821d6b1619b7a55b515a98391193297e77cbe52 linux amd64 > /usr/local/bin/weed -v=3 -logdir=/mnt/seaweed_bcminioresearch/logs server -master.dir=/mnt/seaweed_bcminioresearch/master -volume.index=leveldb -volume.max=8 -filer.dirListLimit=10000 -metricsPort=9327 -dir=/mnt/seaweed_bcminioresearch -s3 > lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 22.10 Release: 22.10 Codename: kinetic  **Screenshots**  # in weed shell > meta.cat /buckets/bcminioresearch/models/datasets/credit/global_credit_data_monthly/live/_metadata { ""name"": ""_metadata"", ""isDirectory"": false, ""chunks"": [ { ""fileId"": ""28,4231f9c5edef"", ""offset"": ""0"", ""size"": ""1225797"", ""modifiedTsNs"": ""1678106055"", ""eTag"": ""b53111d5"", ""sourceFileId"": """", ""fid"": { ""volumeId"": 28, ""fileKey"": ""16945"", ""cookie"": 4190498287 }, ""sourceFid"": null, ""cipherKey"": """", ""isCompressed"": false, ""isChunkManifest"": false } ], ""attributes"": { ""fileSize"": ""1236149"", ""mtime"": ""1678264028"", ""fileMode"": 420, ""uid"": 0, ""gid"": 0, ""crtime"": ""0"", ""mime"": """", ""ttlSec"": 0, ""userName"": """", ""groupName"": [], ""symlinkTarget"": """", ""md5"": """", ""rdev"": 0, ""inode"": ""0"" }, ""extended"": {}, ""hardLinkId"": """", ""hardLinkCounter"": 0, ""content"": """", ""remoteEntry"": { ""storageName"": ""azure"", ""lastLocalSyncTsNs"": ""0"", ""remoteETag"": ""0x8DB1FAEE885E3FA"", ""remoteMtime"": ""1678264028"", ""remoteSize"": ""1236149"" }, ""quota"": ""0"" }chunks 1 meta size: 116 gzip:144  You'll notice that `atttributes.fileSize` and `chunks[0].size` are different. **Expected behavior** The file has only one chunk, I would have expected those two to be the same source-file",no-bug,0.9
3511,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3511,[master] DATA RACE on Created Volume,https://github.com/seaweedfs/seaweedfs/issues/3507  master_1 | I0825 10:09:15.382114 volume_layout.go:391 Volume 2 becomes writable master_1 | I0825 10:09:15.382262 volume_growth.go:245 Created Volume 2 on topo:DefaultDataCenter:DefaultRack:volume:8080 master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0001abb60 by goroutine 127: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).HasGrowRequest() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:322 +0x3c master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).Assign() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:145 +0x9c4 master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_Assign_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:426 +0x25a master_1 | google.golang.org/grpc.(*Server).processUnaryRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1295 +0x11c9 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1636 +0xff8 master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Previous write at 0x00c0001abb60 by goroutine 126: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).DoneGrowRequest() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:333 +0x325 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:62 +0x299 master_1 | master_1 | Goroutine 127 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 | master_1 | Goroutine 126 (finished) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 |  ,source-file | source-file,[master] DATA RACE on Created Volume https://github.com/seaweedfs/seaweedfs/issues/3507  master_1 | I0825 10:09:15.382114 volume_layout.go:391 Volume 2 becomes writable master_1 | I0825 10:09:15.382262 volume_growth.go:245 Created Volume 2 on topo:DefaultDataCenter:DefaultRack:volume:8080 master_1 |  master_1 | WARNING: DATA RACE master_1 | Read at 0x00c0001abb60 by goroutine 127: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).HasGrowRequest() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:322 +0x3c master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).Assign() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:145 +0x9c4 master_1 | github.com/seaweedfs/seaweedfs/weed/pb/master_pb._Seaweed_Assign_Handler() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/master_pb/master_grpc.pb.go:426 +0x25a master_1 | google.golang.org/grpc.(*Server).processUnaryRPC() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1295 +0x11c9 master_1 | google.golang.org/grpc.(*Server).handleStream() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:1636 +0xff8 master_1 | google.golang.org/grpc.(*Server).serveStreams.func1.2() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:932 +0xec master_1 | master_1 | Previous write at 0x00c0001abb60 by goroutine 126: master_1 | github.com/seaweedfs/seaweedfs/weed/topology.(*VolumeLayout).DoneGrowRequest() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/volume_layout.go:333 +0x325 master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1.2() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:62 +0x299 master_1 | master_1 | Goroutine 127 (running) created at: master_1 | google.golang.org/grpc.(*Server).serveStreams.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:930 +0x4dd master_1 | google.golang.org/grpc/internal/transport.(*http2Server).operateHeaders() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:603 +0x3329 master_1 | google.golang.org/grpc/internal/transport.(*http2Server).HandleStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/internal/transport/http2_server.go:648 +0x378 master_1 | google.golang.org/grpc.(*Server).serveStreams() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:916 +0x275 master_1 | google.golang.org/grpc.(*Server).handleRawConn.func1() master_1 | /go/pkg/mod/google.golang.org/grpc@v1.48.0/server.go:858 +0x64 master_1 | master_1 | Goroutine 126 (finished) created at: master_1 | github.com/seaweedfs/seaweedfs/weed/server.(*MasterServer).ProcessGrowRequest.func1() master_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/master_grpc_server_volume.go:52 +0x3eb master_1 |   source-file source-file,no-bug,0.9
2125,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2125,[filer] Error delete many files with SQL,"**Describe the bug** Error filer store delete Folder Children See https://fromdual.com/keep-your-galera-cluster-up-and-running-by-all-means  filer_1 | I0611 10:13:05 1 abstract_sql_store.go:282] delete /buckets/registry/docker/registry/v2/blobs/sha256 SQL DELETE FROM `filemeta` WHERE dirhash=? AND directory=? -4910119483806141165 filer_1 | I0611 10:13:05 1 filer_delete_entry.go:39] delete directory /buckets/registry: filer store delete: deleteFolderChildren /buckets/registry/docker/registry/v2/blobs/sha256: Error 1180: wsrep_max_ws_rows exceeded filer_1 | I0611 10:13:05 1 error_handler.go:79] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> filer_1 | <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/registry</Resource><RequestId>1623406385367150308</RequestId><BucketName>registry</BucketName></Error>  **System Setup** master branch **Expected behavior** force small transactions when deleting Folder Children",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"[filer] Error delete many files with SQL **Describe the bug** Error filer store delete Folder Children See https://fromdual.com/keep-your-galera-cluster-up-and-running-by-all-means  filer_1 | I0611 10:13:05 1 abstract_sql_store.go:282] delete /buckets/registry/docker/registry/v2/blobs/sha256 SQL DELETE FROM `filemeta` WHERE dirhash=? AND directory=? -4910119483806141165 filer_1 | I0611 10:13:05 1 filer_delete_entry.go:39] delete directory /buckets/registry: filer store delete: deleteFolderChildren /buckets/registry/docker/registry/v2/blobs/sha256: Error 1180: wsrep_max_ws_rows exceeded filer_1 | I0611 10:13:05 1 error_handler.go:79] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> filer_1 | <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/registry</Resource><RequestId>1623406385367150308</RequestId><BucketName>registry</BucketName></Error>  **System Setup** master branch **Expected behavior** force small transactions when deleting Folder Children source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file",bug,0.9
4193,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4193,About the problem that the doEcEncode execution throws panic: runtime error: index out of range [0] with length 0,"**Describe the bug** A clear and concise description of what the bug is. After running for a period of time, the weed master will stop running. Looking at the log, we found that an exception of panic: runtime error: index out of range [0] with length 0 was thrown.As shown below: ![image](https://user-images.githubusercontent.com/45417436/217765915-d2a460db-b82e-4cbe-aff5-6be31efdccde.png) Print source code to view errors: func doEcEncode(commandEnv *CommandEnv, collection string, vid needle.VolumeId, parallelCopy bool) (err error) { // find volume location locations, found := commandEnv.MasterClient.GetLocations(uint32(vid)) fmt.Printf(""11111111111111111111111 found ec %d shards on %v\n"", vid, locations) fmt.Println() fmt.Printf(""22222222222 found %v "", found) fmt.Println() fmt.Printf(""333333333 location[0]= %v\n"", locations[0]) if !found { fmt.Printf(""55555555 volume %d not found"", vid) fmt.Println() return fmt.Errorf(""volume %d not found"", vid) } // fmt.Printf(""found ec %d shards on %v\n"", vid, locations) // mark the volume as readonly err = markVolumeReplicasWritable(commandEnv.option.GrpcDialOption, vid, locations, false) if err != nil { return fmt.Errorf(""mark volume %d as readonly on %s: %v"", vid, locations[0].Url, err) } // generate ec shards err = generateEcShards(commandEnv.option.GrpcDialOption, vid, collection, locations[0].ServerAddress()) if err != nil { return fmt.Errorf(""generate ec shards for volume %d on %s: %v"", vid, locations[0].Url, err) } // balance the ec shards to current cluster err = spreadEcShards(commandEnv, vid, collection, locations, parallelCopy) if err != nil { return fmt.Errorf(""spread ec shards for volume %d from %s: %v"", vid, locations[0].Url, err) } return nil } When the result locations=[], found=false, the panic: runtime error: index out of range [0] with length 0 exception is thrown, and then the master stops working.As shown below: ![image](https://user-images.githubusercontent.com/45417436/217767453-08526949-c9f2-4600-9edd-575022ffcd11.png) and ""volume %d not found"" this error has never been returned, so I infer that when locations=[], find=false, whether we can consider len(locations) in if !found && len(locations) > 0 {} is removed,To fix the problem. **System Setup** - OS version centos7 - output of `weed version` seaweedfs 3.15",source-file,"About the problem that the doEcEncode execution throws panic: runtime error: index out of range [0] with length 0 **Describe the bug** A clear and concise description of what the bug is. After running for a period of time, the weed master will stop running. Looking at the log, we found that an exception of panic: runtime error: index out of range [0] with length 0 was thrown.As shown below: ![image](https://user-images.githubusercontent.com/45417436/217765915-d2a460db-b82e-4cbe-aff5-6be31efdccde.png) Print source code to view errors: func doEcEncode(commandEnv *CommandEnv, collection string, vid needle.VolumeId, parallelCopy bool) (err error) { // find volume location locations, found := commandEnv.MasterClient.GetLocations(uint32(vid)) fmt.Printf(""11111111111111111111111 found ec %d shards on %v\n"", vid, locations) fmt.Println() fmt.Printf(""22222222222 found %v "", found) fmt.Println() fmt.Printf(""333333333 location[0]= %v\n"", locations[0]) if !found { fmt.Printf(""55555555 volume %d not found"", vid) fmt.Println() return fmt.Errorf(""volume %d not found"", vid) } // fmt.Printf(""found ec %d shards on %v\n"", vid, locations) // mark the volume as readonly err = markVolumeReplicasWritable(commandEnv.option.GrpcDialOption, vid, locations, false) if err != nil { return fmt.Errorf(""mark volume %d as readonly on %s: %v"", vid, locations[0].Url, err) } // generate ec shards err = generateEcShards(commandEnv.option.GrpcDialOption, vid, collection, locations[0].ServerAddress()) if err != nil { return fmt.Errorf(""generate ec shards for volume %d on %s: %v"", vid, locations[0].Url, err) } // balance the ec shards to current cluster err = spreadEcShards(commandEnv, vid, collection, locations, parallelCopy) if err != nil { return fmt.Errorf(""spread ec shards for volume %d from %s: %v"", vid, locations[0].Url, err) } return nil } When the result locations=[], found=false, the panic: runtime error: index out of range [0] with length 0 exception is thrown, and then the master stops working.As shown below: ![image](https://user-images.githubusercontent.com/45417436/217767453-08526949-c9f2-4600-9edd-575022ffcd11.png) and ""volume %d not found"" this error has never been returned, so I infer that when locations=[], find=false, whether we can consider len(locations) in if !found && len(locations) > 0 {} is removed,To fix the problem. **System Setup** - OS version centos7 - output of `weed version` seaweedfs 3.15 source-file",no-bug,0.9
1413,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1413,1.87S3,"S3,1.86 1.87AccessDenied http://127.0.0.1:8333/testbucket/file/2778927da4.jpg",source-file,"1.87S3 S3,1.86 1.87AccessDenied http://127.0.0.1:8333/testbucket/file/2778927da4.jpg source-file",no-bug,0.3
930,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/930,filer use memdb panic,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** start a cluster with a filer use memdb, then executing this command ` ./weed filer.copy -c 32 -master 172.16.10.60:9333 abc/* http://172.16.10.62:8888/abc/`, the filer server is panic.The panic output is below. **System Setup** * start master:  bash root@172-16-10-60:~/seaweeedfs# ./weed master -ip.bind 0.0.0.0 -port 9333 -mdir /data/seaweedfs/meta -i172.17.10.60 -volumePreallocate  * start volume-1:  bash root@172-16-10-60:~/seaweeedfs# ./weed volume -ip.bind 0.0.0.0 -mserver 172.17.10.60:9333 -port 8080 -dir /data/seaweedfs/data/ -max 10 -ip 172.17.10.60 -publicUrl http://172.16.10.60:8080 -port.public 8080  * start volume-2:  bash root@172-16-10-62:~/seaweedfs# ./weed volume -ip.bind 0.0.0.0 -mserver 172.17.10.60:9333 -port 8080 -dir /data/seaweedfs/data/ -max 10 -ip 172.17.10.62 -publicUrl http://172.16.10.62:8080 -port.public 8080  * start filer:  bash ./weed filer -port 8888 -ip 0.0.0.0 -master 172.17.10.60:9333 -redirectOnRead  * filer.toml:  toml # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml [memory] # local in memory, mostly for testing purpose enabled = true  **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** * filer output:  bash root@172-16-10-62:~/seaweedfs# ./weed filer -port 8888 -ip 0.0.0.0 -master 172.17.10.60:9333 -re[94/626] Read I0415 21:30:24 26437 configuration.go:26] Configure filer for memory I0415 21:30:24 26437 filer.go:133] Start Seaweed Filer 30GB 1.30 at 0.0.0.0:8888 panic: interface conversion: btree.Item is nil, not memdb.entryItem goroutine 1394 [running]: github.com/chrislusf/seaweedfs/weed/filer2/memdb.entryItem.Less(0xc00082d340, 0x0, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/memdb/memdb_store.go:25 +0x10 0 github.com/google/btree.items.find.func1(0xe, 0xc0002eb400) /home/travis/gopath/src/github.com/google/btree/btree.go:189 +0x55 sort.Search(0xf, 0xc0002eb4a0, 0xffffffffffffffff) /home/travis/.gimme/versions/go1.12.4.linux.amd64/src/sort/search.go:66 +0x58 github.com/google/btree.items.find(0xc0007bb180, 0xf, 0x1c, 0x18f30c0, 0xc00082d340, 0xc, 0xe) /home/travis/gopath/src/github.com/google/btree/btree.go:188 +0x8a github.com/google/btree.(*node).get(0xc000366bc0, 0x18f30c0, 0xc00082d340, 0x18f30c0, 0xc00082d340) /home/travis/gopath/src/github.com/google/btree/btree.go:337 +0x58 github.com/google/btree.(*node).get(0xc0007b5300, 0x18f30c0, 0xc00082d340, 0x18f30c0, 0xc00082d340) /home/travis/gopath/src/github.com/google/btree/btree.go:341 +0xcf github.com/google/btree.(*node).get(0xc0004358c0, 0x18f30c0, 0xc00082d340, 0x18f30c0, 0xc00082d340) /home/travis/gopath/src/github.com/google/btree/btree.go:341 +0xcf github.com/google/btree.(*node).get(0xc000435940, 0x18f30c0, 0xc00082d340, 0x5cb4877b, 0x1f606afbe51) /home/travis/gopath/src/github.com/google/btree/btree.go:341 +0xcf github.com/google/btree.(*BTree).Get() /home/travis/gopath/src/github.com/google/btree/btree.go:822 github.com/chrislusf/seaweedfs/weed/filer2/memdb.(*MemDbStore).FindEntry(0xc000108130, 0x191a120, 0xc000 6c2cf0, 0xc000741c20, 0x49, 0xc0007506c0, 0x2b, 0x152e5e0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/memdb/memdb_store.go:62 +0xe1 github.com/chrislusf/seaweedfs/weed/filer2.(*Filer).FindEntry(0xc0001a4ac0, 0x191a120, 0xc0006c2cf0, 0xc 000741c20, 0x49, 0xc0007506c0, 0x2b, 0x5) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/filer.go:199 +0x87 github.com/chrislusf/seaweedfs/weed/filer2.(*Filer).CreateEntry(0xc0001a4ac0, 0x191a120, 0xc0006c2cf0, 0 xc00082d260, 0x0, 0xed4467e7b) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/filer.go:152 +0x9a9 github.com/chrislusf/seaweedfs/weed/server.(*FilerServer).CreateEntry(0xc0001a4a40, 0x191a120, 0xc0006c2 cf0, 0xc000763b40, 0xc0001a4a40, 0xc0006c2cf0, 0xc000627ba8) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/filer_grpc_server.go:123 +0x2 5e github.com/chrislusf/seaweedfs/weed/pb/filer_pb._SeaweedFiler_CreateEntry_Handler(0x15e54c0, 0xc0001a4a4 0, 0x191a120, 0xc0006c2cf0, 0xc0007812c0, 0x0, 0x191a120, 0xc0006c2cf0, 0xc0006df860, 0x9a) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/pb/filer_pb/filer.pb.go:1065 +0x23e google.golang.org/grpc.(*Server).processUnaryRPC(0xc0005f4900, 0x192f4a0, 0xc0005d4600, 0xc00073f500, 0x c00041bd40, 0x2545610, 0x0, 0x0, 0x0) /home/travis/gopath/src/google.golang.org/grpc/server.go:972 +0x470 google.golang.org/grpc.(*Server).handleStream(0xc0005f4900, 0x192f4a0, 0xc0005d4600, 0xc00073f500, 0x0) /home/travis/gopath/src/google.golang.org/grpc/server.go:1252 +0xda6 google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc0004aa060, 0xc0005f4900, 0x192f4a0, 0xc0005d460 0, 0xc00073f500) /home/travis/gopath/src/google.golang.org/grpc/server.go:691 +0x9f created by google.golang.org/grpc.(*Server).serveStreams.func1 /home/travis/gopath/src/google.golang.org/grpc/server.go:689 +0xa1 ",source-file,"filer use memdb panic Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** start a cluster with a filer use memdb, then executing this command ` ./weed filer.copy -c 32 -master 172.16.10.60:9333 abc/* http://172.16.10.62:8888/abc/`, the filer server is panic.The panic output is below. **System Setup** * start master:  bash root@172-16-10-60:~/seaweeedfs# ./weed master -ip.bind 0.0.0.0 -port 9333 -mdir /data/seaweedfs/meta -i172.17.10.60 -volumePreallocate  * start volume-1:  bash root@172-16-10-60:~/seaweeedfs# ./weed volume -ip.bind 0.0.0.0 -mserver 172.17.10.60:9333 -port 8080 -dir /data/seaweedfs/data/ -max 10 -ip 172.17.10.60 -publicUrl http://172.16.10.60:8080 -port.public 8080  * start volume-2:  bash root@172-16-10-62:~/seaweedfs# ./weed volume -ip.bind 0.0.0.0 -mserver 172.17.10.60:9333 -port 8080 -dir /data/seaweedfs/data/ -max 10 -ip 172.17.10.62 -publicUrl http://172.16.10.62:8080 -port.public 8080  * start filer:  bash ./weed filer -port 8888 -ip 0.0.0.0 -master 172.17.10.60:9333 -redirectOnRead  * filer.toml:  toml # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" # Put this file to one of the location, with descending priority # ./filer.toml # $HOME/.seaweedfs/filer.toml # /etc/seaweedfs/filer.toml [memory] # local in memory, mostly for testing purpose enabled = true  **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** * filer output:  bash root@172-16-10-62:~/seaweedfs# ./weed filer -port 8888 -ip 0.0.0.0 -master 172.17.10.60:9333 -re[94/626] Read I0415 21:30:24 26437 configuration.go:26] Configure filer for memory I0415 21:30:24 26437 filer.go:133] Start Seaweed Filer 30GB 1.30 at 0.0.0.0:8888 panic: interface conversion: btree.Item is nil, not memdb.entryItem goroutine 1394 [running]: github.com/chrislusf/seaweedfs/weed/filer2/memdb.entryItem.Less(0xc00082d340, 0x0, 0x0, 0x0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/memdb/memdb_store.go:25 +0x10 0 github.com/google/btree.items.find.func1(0xe, 0xc0002eb400) /home/travis/gopath/src/github.com/google/btree/btree.go:189 +0x55 sort.Search(0xf, 0xc0002eb4a0, 0xffffffffffffffff) /home/travis/.gimme/versions/go1.12.4.linux.amd64/src/sort/search.go:66 +0x58 github.com/google/btree.items.find(0xc0007bb180, 0xf, 0x1c, 0x18f30c0, 0xc00082d340, 0xc, 0xe) /home/travis/gopath/src/github.com/google/btree/btree.go:188 +0x8a github.com/google/btree.(*node).get(0xc000366bc0, 0x18f30c0, 0xc00082d340, 0x18f30c0, 0xc00082d340) /home/travis/gopath/src/github.com/google/btree/btree.go:337 +0x58 github.com/google/btree.(*node).get(0xc0007b5300, 0x18f30c0, 0xc00082d340, 0x18f30c0, 0xc00082d340) /home/travis/gopath/src/github.com/google/btree/btree.go:341 +0xcf github.com/google/btree.(*node).get(0xc0004358c0, 0x18f30c0, 0xc00082d340, 0x18f30c0, 0xc00082d340) /home/travis/gopath/src/github.com/google/btree/btree.go:341 +0xcf github.com/google/btree.(*node).get(0xc000435940, 0x18f30c0, 0xc00082d340, 0x5cb4877b, 0x1f606afbe51) /home/travis/gopath/src/github.com/google/btree/btree.go:341 +0xcf github.com/google/btree.(*BTree).Get() /home/travis/gopath/src/github.com/google/btree/btree.go:822 github.com/chrislusf/seaweedfs/weed/filer2/memdb.(*MemDbStore).FindEntry(0xc000108130, 0x191a120, 0xc000 6c2cf0, 0xc000741c20, 0x49, 0xc0007506c0, 0x2b, 0x152e5e0) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/memdb/memdb_store.go:62 +0xe1 github.com/chrislusf/seaweedfs/weed/filer2.(*Filer).FindEntry(0xc0001a4ac0, 0x191a120, 0xc0006c2cf0, 0xc 000741c20, 0x49, 0xc0007506c0, 0x2b, 0x5) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/filer.go:199 +0x87 github.com/chrislusf/seaweedfs/weed/filer2.(*Filer).CreateEntry(0xc0001a4ac0, 0x191a120, 0xc0006c2cf0, 0 xc00082d260, 0x0, 0xed4467e7b) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/filer2/filer.go:152 +0x9a9 github.com/chrislusf/seaweedfs/weed/server.(*FilerServer).CreateEntry(0xc0001a4a40, 0x191a120, 0xc0006c2 cf0, 0xc000763b40, 0xc0001a4a40, 0xc0006c2cf0, 0xc000627ba8) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/filer_grpc_server.go:123 +0x2 5e github.com/chrislusf/seaweedfs/weed/pb/filer_pb._SeaweedFiler_CreateEntry_Handler(0x15e54c0, 0xc0001a4a4 0, 0x191a120, 0xc0006c2cf0, 0xc0007812c0, 0x0, 0x191a120, 0xc0006c2cf0, 0xc0006df860, 0x9a) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/pb/filer_pb/filer.pb.go:1065 +0x23e google.golang.org/grpc.(*Server).processUnaryRPC(0xc0005f4900, 0x192f4a0, 0xc0005d4600, 0xc00073f500, 0x c00041bd40, 0x2545610, 0x0, 0x0, 0x0) /home/travis/gopath/src/google.golang.org/grpc/server.go:972 +0x470 google.golang.org/grpc.(*Server).handleStream(0xc0005f4900, 0x192f4a0, 0xc0005d4600, 0xc00073f500, 0x0) /home/travis/gopath/src/google.golang.org/grpc/server.go:1252 +0xda6 google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc0004aa060, 0xc0005f4900, 0x192f4a0, 0xc0005d460 0, 0xc00073f500) /home/travis/gopath/src/google.golang.org/grpc/server.go:691 +0x9f created by google.golang.org/grpc.(*Server).serveStreams.func1 /home/travis/gopath/src/google.golang.org/grpc/server.go:689 +0xa1  source-file",no-bug,0.9
2529,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2529,"master_server.go:292] error: read buckets: get filer configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp: lookup '' no such host","Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/chrislusf/seaweedfs/discussions **Describe the bug** Hello. I get an error in the leader master log periodically.  master_server.go:292] error: read buckets: get filer configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp: lookup 10.193.86.149:8888,10.5.85.76:8888,10.193.86.150:8888,10.5.85.77: no such host""  I think this is a bug in the admin scripts on the master. weed master logs  I1222 14:04:55 75146 master_server.go:290] executing: lock [] I1222 14:04:55 75146 master_server.go:290] executing: ec.balance [-force] balanceEcVolumes collections 16 balanceEcVolumes collection time-to-live balanceEcVolumes time-to-live balanceEcVolumes collection zabbixdb balanceEcVolumes zabbixdb balanceEcVolumes collection glt-uploads balanceEcVolumes glt-uploads balanceEcVolumes collection gld-uploads balanceEcVolumes gld-uploads balanceEcVolumes collection glt-packages balanceEcVolumes glt-packages balanceEcVolumes collection runners-cache balanceEcVolumes runners-cache balanceEcVolumes collection glt-artifacts balanceEcVolumes glt-artifacts balanceEcVolumes collection testmount balanceEcVolumes testmount balanceEcVolumes collection glt-lfs-objects balanceEcVolumes glt-lfs-objects balanceEcVolumes collection glt-terraform-state balanceEcVolumes glt-terraform-state balanceEcVolumes collection balanceEcVolumes balanceEcVolumes collection glt-pages balanceEcVolumes glt-pages I1222 14:04:55 75146 master_server.go:290] executing: ec.encode [-fullPercent=95 -quietFor=1h] collect volumes quiet for: 3600 seconds ec encode volumes: [] I1222 14:04:55 75146 master_server.go:290] executing: ec.rebuild [-force] rebuildEcVolumes collections 16 rebuildEcVolumes collection glt-uploads rebuildEcVolumes glt-uploads rebuildEcVolumes collection glt-pages rebuildEcVolumes glt-pages rebuildEcVolumes collection time-to-live rebuildEcVolumes time-to-live rebuildEcVolumes collection gld-uploads rebuildEcVolumes gld-uploads rebuildEcVolumes collection glt-artifacts rebuildEcVolumes glt-artifacts rebuildEcVolumes collection glt-terraform-state rebuildEcVolumes glt-terraform-state rebuildEcVolumes collection rebuildEcVolumes rebuildEcVolumes collection zabbixdb rebuildEcVolumes zabbixdb rebuildEcVolumes collection glt-packages rebuildEcVolumes glt-packages rebuildEcVolumes collection runners-cache rebuildEcVolumes runners-cache rebuildEcVolumes collection glt-lfs-objects rebuildEcVolumes glt-lfs-objects rebuildEcVolumes collection testmount rebuildEcVolumes testmount I1222 14:04:55 75146 master_server.go:290] executing: s3.clean.uploads [-timeAgo=24h] I1222 14:04:55 75146 master_server.go:292] error: read buckets: get filer configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp: lookup 10.193.86.149:8888,10.5.85.76:8888,10.193.86.150:8888,10.5.85.77: no such host"" I1222 14:04:55 75146 master_server.go:290] executing: volume.balance [-force] hdd 0.12 0.23:0.01 hdd 0.12 0.23:0.06 hdd 0.12 0.23:0.09 hdd 0.12 0.23:0.09 hdd 0.12 0.23:0.11 hdd 0.01 0.03:0.01 hdd 0.01 0.03:0.01 hdd 0.01 0.03:0.01 hdd 0.02 0.03:0.02 hdd 0.01 0.02:0.01 hdd 0.02 0.04:0.01 hdd 0.02 0.04:0.01 hdd 0.02 0.04:0.01 hdd 0.42 0.46:0.36 hdd 0.42 0.46:0.41 hdd 0.42 0.46:0.42 hdd 0.42 0.46:0.42 hdd 0.20 0.22:0.19 hdd 0.20 0.22:0.19 hdd 0.20 0.22:0.19 hdd 0.20 0.22:0.20 I1222 14:04:55 75146 master_server.go:290] executing: volume.fix.replication [] I1222 14:04:55 75146 master_server.go:290] executing: unlock []  master.toml  [master.maintenance] # periodically run these scripts are the same as running them from 'weed shell' scripts =  lock ec.balance -force ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force s3.clean.uploads -timeAgo=24h volume.balance -force volume.deleteEmpty -quietFor=24h -force volume.fix.replication unlock  sleep_minutes = 17 # sleep minutes between each script execution [master.filer] # used by maintenance scripts if the scripts needs to use fs related commands default = ""10.193.86.149:8888,10.5.85.76:8888,10.193.86.150:8888,10.5.85.77:8888"" [master.sequencer] type = ""raft"" # Choose [raft|snowflake] type for storing the file id sequence # when sequencer.type = snowflake, the snowflake id must be different from other masters # create this number of logical volumes if no more writable volumes # count_x means how many copies of data. # e.g.: # 000 has only one copy, copy_1 # 010 and 001 has two copies, copy_2 # 011 has only 3 copies, copy_3 [master.volume_growth] copy_1 = 7 # create 1 x 7 = 7 actual volumes copy_2 = 6 # create 2 x 6 = 12 actual volumes copy_3 = 3 # create 3 x 3 = 9 actual volumes copy_other = 1 # create n x 1 = n actual volumes # configuration flags for replication [master.replication] # any replication counts should be considered minimums. If you specify 010 and # have 3 different racks, that's still considered writable. Writes will still # try to replicate to all available volumes. You should only use this option # if you are doing your own replication or periodic sync of volumes. treat_replication_as_minimums = false  Maybe the command ""s3.clean.uploads -timeAgo = 24h"" gives this error? **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version - weed version version 30GB 2.82 c3b73ec23b9c7831e31503ebf3a64cc2f0a3c33d linux amd64 **Expected behavior** Work without mistakes. **Additional context** Second problem. Not all log messages are sent according to the glog format. Please correct the output of the messages. This will help parse them correctly.",other-file | source-file | source-file | source-file,"master_server.go:292] error: read buckets: get filer configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp: lookup '' no such host Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/chrislusf/seaweedfs/discussions **Describe the bug** Hello. I get an error in the leader master log periodically.  master_server.go:292] error: read buckets: get filer configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp: lookup 10.193.86.149:8888,10.5.85.76:8888,10.193.86.150:8888,10.5.85.77: no such host""  I think this is a bug in the admin scripts on the master. weed master logs  I1222 14:04:55 75146 master_server.go:290] executing: lock [] I1222 14:04:55 75146 master_server.go:290] executing: ec.balance [-force] balanceEcVolumes collections 16 balanceEcVolumes collection time-to-live balanceEcVolumes time-to-live balanceEcVolumes collection zabbixdb balanceEcVolumes zabbixdb balanceEcVolumes collection glt-uploads balanceEcVolumes glt-uploads balanceEcVolumes collection gld-uploads balanceEcVolumes gld-uploads balanceEcVolumes collection glt-packages balanceEcVolumes glt-packages balanceEcVolumes collection runners-cache balanceEcVolumes runners-cache balanceEcVolumes collection glt-artifacts balanceEcVolumes glt-artifacts balanceEcVolumes collection testmount balanceEcVolumes testmount balanceEcVolumes collection glt-lfs-objects balanceEcVolumes glt-lfs-objects balanceEcVolumes collection glt-terraform-state balanceEcVolumes glt-terraform-state balanceEcVolumes collection balanceEcVolumes balanceEcVolumes collection glt-pages balanceEcVolumes glt-pages I1222 14:04:55 75146 master_server.go:290] executing: ec.encode [-fullPercent=95 -quietFor=1h] collect volumes quiet for: 3600 seconds ec encode volumes: [] I1222 14:04:55 75146 master_server.go:290] executing: ec.rebuild [-force] rebuildEcVolumes collections 16 rebuildEcVolumes collection glt-uploads rebuildEcVolumes glt-uploads rebuildEcVolumes collection glt-pages rebuildEcVolumes glt-pages rebuildEcVolumes collection time-to-live rebuildEcVolumes time-to-live rebuildEcVolumes collection gld-uploads rebuildEcVolumes gld-uploads rebuildEcVolumes collection glt-artifacts rebuildEcVolumes glt-artifacts rebuildEcVolumes collection glt-terraform-state rebuildEcVolumes glt-terraform-state rebuildEcVolumes collection rebuildEcVolumes rebuildEcVolumes collection zabbixdb rebuildEcVolumes zabbixdb rebuildEcVolumes collection glt-packages rebuildEcVolumes glt-packages rebuildEcVolumes collection runners-cache rebuildEcVolumes runners-cache rebuildEcVolumes collection glt-lfs-objects rebuildEcVolumes glt-lfs-objects rebuildEcVolumes collection testmount rebuildEcVolumes testmount I1222 14:04:55 75146 master_server.go:290] executing: s3.clean.uploads [-timeAgo=24h] I1222 14:04:55 75146 master_server.go:292] error: read buckets: get filer configuration: rpc error: code = Unavailable desc = connection error: desc = ""transport: Error while dialing dial tcp: lookup 10.193.86.149:8888,10.5.85.76:8888,10.193.86.150:8888,10.5.85.77: no such host"" I1222 14:04:55 75146 master_server.go:290] executing: volume.balance [-force] hdd 0.12 0.23:0.01 hdd 0.12 0.23:0.06 hdd 0.12 0.23:0.09 hdd 0.12 0.23:0.09 hdd 0.12 0.23:0.11 hdd 0.01 0.03:0.01 hdd 0.01 0.03:0.01 hdd 0.01 0.03:0.01 hdd 0.02 0.03:0.02 hdd 0.01 0.02:0.01 hdd 0.02 0.04:0.01 hdd 0.02 0.04:0.01 hdd 0.02 0.04:0.01 hdd 0.42 0.46:0.36 hdd 0.42 0.46:0.41 hdd 0.42 0.46:0.42 hdd 0.42 0.46:0.42 hdd 0.20 0.22:0.19 hdd 0.20 0.22:0.19 hdd 0.20 0.22:0.19 hdd 0.20 0.22:0.20 I1222 14:04:55 75146 master_server.go:290] executing: volume.fix.replication [] I1222 14:04:55 75146 master_server.go:290] executing: unlock []  master.toml  [master.maintenance] # periodically run these scripts are the same as running them from 'weed shell' scripts =  lock ec.balance -force ec.encode -fullPercent=95 -quietFor=1h ec.rebuild -force s3.clean.uploads -timeAgo=24h volume.balance -force volume.deleteEmpty -quietFor=24h -force volume.fix.replication unlock  sleep_minutes = 17 # sleep minutes between each script execution [master.filer] # used by maintenance scripts if the scripts needs to use fs related commands default = ""10.193.86.149:8888,10.5.85.76:8888,10.193.86.150:8888,10.5.85.77:8888"" [master.sequencer] type = ""raft"" # Choose [raft|snowflake] type for storing the file id sequence # when sequencer.type = snowflake, the snowflake id must be different from other masters # create this number of logical volumes if no more writable volumes # count_x means how many copies of data. # e.g.: # 000 has only one copy, copy_1 # 010 and 001 has two copies, copy_2 # 011 has only 3 copies, copy_3 [master.volume_growth] copy_1 = 7 # create 1 x 7 = 7 actual volumes copy_2 = 6 # create 2 x 6 = 12 actual volumes copy_3 = 3 # create 3 x 3 = 9 actual volumes copy_other = 1 # create n x 1 = n actual volumes # configuration flags for replication [master.replication] # any replication counts should be considered minimums. If you specify 010 and # have 3 different racks, that's still considered writable. Writes will still # try to replicate to all available volumes. You should only use this option # if you are doing your own replication or periodic sync of volumes. treat_replication_as_minimums = false  Maybe the command ""s3.clean.uploads -timeAgo = 24h"" gives this error? **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". - OS version - weed version version 30GB 2.82 c3b73ec23b9c7831e31503ebf3a64cc2f0a3c33d linux amd64 **Expected behavior** Work without mistakes. **Additional context** Second problem. Not all log messages are sent according to the glog format. Please correct the output of the messages. This will help parse them correctly. other-file source-file source-file source-file",no-bug,0.9
1014,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1014,Could not get 1 of 2 files with same key.,"myversion is 30GB 1.31 linux amd64. I get a error when getting fid 82,4cae725bbd3e21. ""request /82,4cae725bbd3e21 with cookie:5bbd3e21 expected:4aba18f3 from 10.64.1.52:52478 agent Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36"" Changed cookie of fid, I can get the file 82,4cae724aba18f3. But it's not the file I wanted.I searched for filer to find both. ![image](https://user-images.githubusercontent.com/42425728/61372015-a49a1e00-a8c8-11e9-925b-f95c218aa747.png) ![image](https://user-images.githubusercontent.com/42425728/61372211-1a9e8500-a8c9-11e9-80c5-eaf8160302d5.png) is that bug? exist two same index key but different cookie fid.",source-file,"Could not get 1 of 2 files with same key. myversion is 30GB 1.31 linux amd64. I get a error when getting fid 82,4cae725bbd3e21. ""request /82,4cae725bbd3e21 with cookie:5bbd3e21 expected:4aba18f3 from 10.64.1.52:52478 agent Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36"" Changed cookie of fid, I can get the file 82,4cae724aba18f3. But it's not the file I wanted.I searched for filer to find both. ![image](https://user-images.githubusercontent.com/42425728/61372015-a49a1e00-a8c8-11e9-925b-f95c218aa747.png) ![image](https://user-images.githubusercontent.com/42425728/61372211-1a9e8500-a8c9-11e9-80c5-eaf8160302d5.png) is that bug? exist two same index key but different cookie fid. source-file",no-bug,0.7
3552,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3552,[s3] DATA RACE on NewS3ApiServer,https://github.com/seaweedfs/seaweedfs/issues/3507  I0830 08:17:15.016626 s3api_circuit_breaker.go:40 s3 circuit breaker not configured: read S3 circuit breaker config: filer: no entry is found in filer store  WARNING: DATA RACE Read at 0x00c00055adb0 by goroutine 46: github.com/seaweedfs/seaweedfs/weed/s3api.NewS3ApiServer() /go/src/github.com/seaweedfs/seaweedfs/weed/s3api/s3api_server.go:62 +0x584 github.com/seaweedfs/seaweedfs/weed/command.(*S3Options).startS3Server() /go/src/github.com/seaweedfs/seaweedfs/weed/command/s3.go:188 +0xa9b github.com/seaweedfs/seaweedfs/weed/command.runFiler.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:178 +0x44 github.com/seaweedfs/seaweedfs/weed/command.runFiler.func6() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:179 +0x47 Previous write at 0x00c00055adb0 by main goroutine: github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:297 +0x1b8b github.com/seaweedfs/seaweedfs/weed/command.runFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x892 main.main() /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 Goroutine 46 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.runFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:176 +0x564 main.main() /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943  ,source-file | source-file | source-file | source-file | source-file,[s3] DATA RACE on NewS3ApiServer https://github.com/seaweedfs/seaweedfs/issues/3507  I0830 08:17:15.016626 s3api_circuit_breaker.go:40 s3 circuit breaker not configured: read S3 circuit breaker config: filer: no entry is found in filer store  WARNING: DATA RACE Read at 0x00c00055adb0 by goroutine 46: github.com/seaweedfs/seaweedfs/weed/s3api.NewS3ApiServer() /go/src/github.com/seaweedfs/seaweedfs/weed/s3api/s3api_server.go:62 +0x584 github.com/seaweedfs/seaweedfs/weed/command.(*S3Options).startS3Server() /go/src/github.com/seaweedfs/seaweedfs/weed/command/s3.go:188 +0xa9b github.com/seaweedfs/seaweedfs/weed/command.runFiler.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:178 +0x44 github.com/seaweedfs/seaweedfs/weed/command.runFiler.func6() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:179 +0x47 Previous write at 0x00c00055adb0 by main goroutine: github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:297 +0x1b8b github.com/seaweedfs/seaweedfs/weed/command.runFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x892 main.main() /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 Goroutine 46 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.runFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:176 +0x564 main.main() /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943   source-file source-file source-file source-file source-file,no-bug,0.9
5871,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5871,remote.uncache minAge parameter is not working as execpted,"**Describe the bug** remote.uncache minAge parameter is not working as describe in document (wiki & help) help says: `remote.uncache -minAge=3600 # uncache files older than 1 hour` but when running: `remote.uncache -minAge=1296000` most recent files are uncached as well. I check the remote.uncache command source code:   ff.minAge = remoteMountCommand.Int64(""minAge"", -1, ""minimum file age in seconds"")  if *ff.minAge != -1 { if entry.Attributes.Crtime < *ff.minAge { return false } }  and fs.meta.cat shows Crtime is epoch time, compare Crtime with minAge parameter seems unreasonable. **Expected behavior** minAge parameter should work as describe. (and maxAge as well)",source-file | source-file,"remote.uncache minAge parameter is not working as execpted **Describe the bug** remote.uncache minAge parameter is not working as describe in document (wiki & help) help says: `remote.uncache -minAge=3600 # uncache files older than 1 hour` but when running: `remote.uncache -minAge=1296000` most recent files are uncached as well. I check the remote.uncache command source code:   ff.minAge = remoteMountCommand.Int64(""minAge"", -1, ""minimum file age in seconds"")  if *ff.minAge != -1 { if entry.Attributes.Crtime < *ff.minAge { return false } }  and fs.meta.cat shows Crtime is epoch time, compare Crtime with minAge parameter seems unreasonable. **Expected behavior** minAge parameter should work as describe. (and maxAge as well) source-file source-file",no-bug,0.9
405,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/405,Making a volume server readOnly & Some other questions,We have 1 master volume and 2 volume servers.. Do we have such parameters that so that we can keep a volume just for read operations and dont write anything on it anymore? One more thing. we had a volume server of 70 TB. We first started it with max 2000 volumes and it had been created 763 and we needed to stop it to create more so we stopped it to 765 max. But it is consuming the total 70 TB. why is it so? other hand we have 2370 max volumes in the same 74TB. why 765 taking all the available space?,source-file | source-file | source-file,Making a volume server readOnly & Some other questions We have 1 master volume and 2 volume servers.. Do we have such parameters that so that we can keep a volume just for read operations and dont write anything on it anymore? One more thing. we had a volume server of 70 TB. We first started it with max 2000 volumes and it had been created 763 and we needed to stop it to create more so we stopped it to 765 max. But it is consuming the total 70 TB. why is it so? other hand we have 2370 max volumes in the same 74TB. why 765 taking all the available space? source-file source-file source-file,no-bug,0.9
2352,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2352,"""weed server"" peer check thinks it's a master when master has been disabled.","**Describe the bug** I'm getting `Only odd number of masters are supported: [node1:9333 node3:9333 node4:9333 node2:9333]` on `weed server -options=/etc/xdg/seaweedfs/server.conf -ip=node2` when there is a master=false flag in the config file. Node2 shouldn't be counted as a master. I suspect it's the `if *isStartingMasterServer {` here removed that's causing the bug https://github.com/chrislusf/seaweedfs/commit/e5fc35ed0c970fea060a5b3b7a3f5efb5af425d6#diff-25bae991aa8050efe57406452575e53bb89eb91244dcfa772587872b05f862aeL170 **Relevant logs** `weed server -options=/etc/xdg/seaweedfs/server.conf -ip=node2` log  Oct 03 20:17:22 node2 systemd[1]: Started Seaweed Master. Oct 03 20:17:22 node2 weed[1015247]: I1003 20:17:22 15247 master.go:170] current: node2:9333 peers:node1:9333,node3:9333,node4:9333 Oct 03 20:17:22 node2 weed[1015247]: F1003 20:17:22 15247 master.go:186] Only odd number of masters are supported: [node1:9333 node3:9333 node4:9333 node2:9333] Oct 03 20:17:22 node2 weed[1015247]: goroutine 1 [running]: Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0x0) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog/glog.go:767 +0xc5 Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x5581706f8620, 0x3, 0xc000262310, {0x55816f9531f3, 0x9}, 0xba, 0x0) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog/glog.go:718 +0x465 Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x5581706f8620, 0x3, {0x55816eaf1622, 0x2d}, {0xc000be38a8, 0x1, 0x1}) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog/glog.go:656 +0x1bb Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog.Fatalf({0x55816eaf1622, 0x2d}, {0xc000be38a8, 0x1, 0x1}) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog/glog.go:1149 +0x57 Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/command.checkPeers({0x7ffd910c4f15, 0x5}, 0x2475, 0x0, {0xc00013436d, 0x20}) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/command/master.go:186 +0x42c Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/command.runServer(0x5581706165a0, {0xc00004e0b0, 0x0, 0x0}) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/command/server.go:174 +0x388 Oct 03 20:17:22 node2 weed[1015247]: main.main() Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/weed.go:78 +0x5b3 Oct 03 20:17:22 node2 systemd[1]: seaweedfs.service: Main process exited, code=exited, status=255/EXCEPTION Oct 03 20:17:22 node2 systemd[1]: seaweedfs.service: Failed with result 'exit-code'. Oct 03 20:17:22 node2 systemd[1]: seaweedfs.service: Scheduled restart job, restart counter is at 5. Oct 03 20:17:22 node2 systemd[1]: Stopped Seaweed Master.  **System Setup** - Arch linux - version 30GB 2.70 linux amd64 - server.conf:  master=false master.defaultReplication=001 volume.dir.idx=index dir=/brick/0 filer=true filer.peers=node1:8888,node2:8888,node3:8888,node4:8888 master.volumePreallocate=true master.peers=node1:9333,node3:9333,node4:9333 rack=rack1 dataCenter=dc1 volume.max=100 volume.concurrentUploadLimitMB=999999 filer.concurrentUploadLimitMB=999999 metrics.address=node3:9091  **Expected behavior** The server should not be counted as a master on `master=false` during peer checking.",source-file,"""weed server"" peer check thinks it's a master when master has been disabled. **Describe the bug** I'm getting `Only odd number of masters are supported: [node1:9333 node3:9333 node4:9333 node2:9333]` on `weed server -options=/etc/xdg/seaweedfs/server.conf -ip=node2` when there is a master=false flag in the config file. Node2 shouldn't be counted as a master. I suspect it's the `if *isStartingMasterServer {` here removed that's causing the bug https://github.com/chrislusf/seaweedfs/commit/e5fc35ed0c970fea060a5b3b7a3f5efb5af425d6#diff-25bae991aa8050efe57406452575e53bb89eb91244dcfa772587872b05f862aeL170 **Relevant logs** `weed server -options=/etc/xdg/seaweedfs/server.conf -ip=node2` log  Oct 03 20:17:22 node2 systemd[1]: Started Seaweed Master. Oct 03 20:17:22 node2 weed[1015247]: I1003 20:17:22 15247 master.go:170] current: node2:9333 peers:node1:9333,node3:9333,node4:9333 Oct 03 20:17:22 node2 weed[1015247]: F1003 20:17:22 15247 master.go:186] Only odd number of masters are supported: [node1:9333 node3:9333 node4:9333 node2:9333] Oct 03 20:17:22 node2 weed[1015247]: goroutine 1 [running]: Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog.stacks(0x0) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog/glog.go:767 +0xc5 Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).output(0x5581706f8620, 0x3, 0xc000262310, {0x55816f9531f3, 0x9}, 0xba, 0x0) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog/glog.go:718 +0x465 Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog.(*loggingT).printf(0x5581706f8620, 0x3, {0x55816eaf1622, 0x2d}, {0xc000be38a8, 0x1, 0x1}) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog/glog.go:656 +0x1bb Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog.Fatalf({0x55816eaf1622, 0x2d}, {0xc000be38a8, 0x1, 0x1}) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/glog/glog.go:1149 +0x57 Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/command.checkPeers({0x7ffd910c4f15, 0x5}, 0x2475, 0x0, {0xc00013436d, 0x20}) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/command/master.go:186 +0x42c Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/command.runServer(0x5581706165a0, {0xc00004e0b0, 0x0, 0x0}) Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/command/server.go:174 +0x388 Oct 03 20:17:22 node2 weed[1015247]: main.main() Oct 03 20:17:22 node2 weed[1015247]: github.com/chrislusf/seaweedfs/weed/weed.go:78 +0x5b3 Oct 03 20:17:22 node2 systemd[1]: seaweedfs.service: Main process exited, code=exited, status=255/EXCEPTION Oct 03 20:17:22 node2 systemd[1]: seaweedfs.service: Failed with result 'exit-code'. Oct 03 20:17:22 node2 systemd[1]: seaweedfs.service: Scheduled restart job, restart counter is at 5. Oct 03 20:17:22 node2 systemd[1]: Stopped Seaweed Master.  **System Setup** - Arch linux - version 30GB 2.70 linux amd64 - server.conf:  master=false master.defaultReplication=001 volume.dir.idx=index dir=/brick/0 filer=true filer.peers=node1:8888,node2:8888,node3:8888,node4:8888 master.volumePreallocate=true master.peers=node1:9333,node3:9333,node4:9333 rack=rack1 dataCenter=dc1 volume.max=100 volume.concurrentUploadLimitMB=999999 filer.concurrentUploadLimitMB=999999 metrics.address=node3:9091  **Expected behavior** The server should not be counted as a master on `master=false` during peer checking. source-file",no-bug,0.9
1917,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1917,[s3] aws s3 copy dir/ fatal error: 'ContentLength',"**Describe the bug**  aws --profile local --endpoint http://127.0.0.1:8333/ s3 cp s3://test/dir /tmp/ fatal error: An error occurred (404) when calling the HeadObject operation: Key ""dir"" does not exist aws --profile local --endpoint http://127.0.0.1:8333/ s3 cp s3://test/dir/ /tmp/ fatal error: 'ContentLength'  **System Setup** `2.34` **Expected behavior** return 404",source-file,"[s3] aws s3 copy dir/ fatal error: 'ContentLength' **Describe the bug**  aws --profile local --endpoint http://127.0.0.1:8333/ s3 cp s3://test/dir /tmp/ fatal error: An error occurred (404) when calling the HeadObject operation: Key ""dir"" does not exist aws --profile local --endpoint http://127.0.0.1:8333/ s3 cp s3://test/dir/ /tmp/ fatal error: 'ContentLength'  **System Setup** `2.34` **Expected behavior** return 404 source-file",bug,0.9
1774,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1774,filer: elasticsearch7 no longer works,"Hello Since 2.21 elasticsearch7 does not work when db already exist. On a new cluster (>=2.21), the 3 indces are created on startup.  indices: .seaweedfs_buckets: green .seaweedfs_topics: green .seaweedfs_kv_entries: green  Filer and s3 are accessibles. But if filer service are restarted, the filer don't restart. filer daemon in not listening on network ports (filer and s3) **cmdline**  weed-filer -logtostderr -v 6 filer -port=8888 -s3 -ip=test-seaweedfs1-f -defaultReplicaPlacement=002 -master=test-seaweedfs1-m:9333,test-seaweedfs2-m:9333,test-seaweedfs3-m:9333,test-seaweedfs4-m:9333,test-seaweedfs5-m:9333 -dataCenter=vau -encryptVolumeData  **filer.toml**  [filer.options] recursive_delete = false [elastic7] enabled = true servers = [ ""http://test-sdv-seaweedfs1-f:9200"", ""http://test-sdv-seaweedfs2-f:9200"", ""http://test-sdv-seaweedfs3-f:9200"", ""http://test-sdv-seaweedfs4-f:9200"", ""http://test-sdv-seaweedfs5-f:9200"", ]  **log for >=2.21**  fvr. 02 17:12:45 test-seaweedfs1 systemd[1]: Started seaweedfs-filer. fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 config.go:29] Reading security.toml from fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 metrics.go:155] filer server sends metrics to test-seaweedfs:9091 every 15 seconds fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 config.go:29] Reading filer.toml from fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: W0202 17:12:45 26971 filer_server.go:115] skipping default store dir in ./filerldb2 fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 config.go:29] Reading notification.toml from fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 config.go:36] Reading : Config File ""notification"" Not Found in ""[/usr/local /var/empty/seaweed/.seaweedfs /usr/local/etc/seaweedfs /etc/seaweedfs]"" fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 elastic_store.go:70] filer store elastic endpoints: [http://test-seaweedfs1-f:9200 http://test-seaweedfs2-f:9200 http://test-seaweedfs3-f:9200 http://test-seaweedfs4-f:9200 http://test-seaweedfs5-f:9200]. fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 filer.go:101] existing filer.store.id = -379500687 fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 configuration.go:28] configured filer store to elastic7 fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 filerstore_wrapper.go:220] ListDirectoryPrefixedEntries /buckets from prefix limit 2147483648  No more log availble :/ The daemon in not listening on network port (filer, s3) With 2.20 the service works and can be restarted, filer and s3 are accessibles. Antoine",source-file,"filer: elasticsearch7 no longer works Hello Since 2.21 elasticsearch7 does not work when db already exist. On a new cluster (>=2.21), the 3 indces are created on startup.  indices: .seaweedfs_buckets: green .seaweedfs_topics: green .seaweedfs_kv_entries: green  Filer and s3 are accessibles. But if filer service are restarted, the filer don't restart. filer daemon in not listening on network ports (filer and s3) **cmdline**  weed-filer -logtostderr -v 6 filer -port=8888 -s3 -ip=test-seaweedfs1-f -defaultReplicaPlacement=002 -master=test-seaweedfs1-m:9333,test-seaweedfs2-m:9333,test-seaweedfs3-m:9333,test-seaweedfs4-m:9333,test-seaweedfs5-m:9333 -dataCenter=vau -encryptVolumeData  **filer.toml**  [filer.options] recursive_delete = false [elastic7] enabled = true servers = [ ""http://test-sdv-seaweedfs1-f:9200"", ""http://test-sdv-seaweedfs2-f:9200"", ""http://test-sdv-seaweedfs3-f:9200"", ""http://test-sdv-seaweedfs4-f:9200"", ""http://test-sdv-seaweedfs5-f:9200"", ]  **log for >=2.21**  fvr. 02 17:12:45 test-seaweedfs1 systemd[1]: Started seaweedfs-filer. fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 config.go:29] Reading security.toml from fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 metrics.go:155] filer server sends metrics to test-seaweedfs:9091 every 15 seconds fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 config.go:29] Reading filer.toml from fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: W0202 17:12:45 26971 filer_server.go:115] skipping default store dir in ./filerldb2 fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 config.go:29] Reading notification.toml from fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 config.go:36] Reading : Config File ""notification"" Not Found in ""[/usr/local /var/empty/seaweed/.seaweedfs /usr/local/etc/seaweedfs /etc/seaweedfs]"" fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 elastic_store.go:70] filer store elastic endpoints: [http://test-seaweedfs1-f:9200 http://test-seaweedfs2-f:9200 http://test-seaweedfs3-f:9200 http://test-seaweedfs4-f:9200 http://test-seaweedfs5-f:9200]. fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 filer.go:101] existing filer.store.id = -379500687 fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 configuration.go:28] configured filer store to elastic7 fvr. 02 17:12:45 test-seaweedfs1 weed-filer[26971]: I0202 17:12:45 26971 filerstore_wrapper.go:220] ListDirectoryPrefixedEntries /buckets from prefix limit 2147483648  No more log availble :/ The daemon in not listening on network port (filer, s3) With 2.20 the service works and can be restarted, filer and s3 are accessibles. Antoine source-file",no-bug,0.8
1019,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1019,Easier migration from leveldb to leveldb2,"Hi, can you please provide a better way to upgrade between these close related filer DB's. using fs.meta.save & fs.meta.load without a specific export name and the unavoidable downtime is cumbersome and problematic. when upgrading the system we need to follow these steps: 1. check if this is a new system (no data exist) or exists leveldb files(upgrade) 2. if new need to create folder filerldb2 like in the Dockerfile (can you please add automatic mkdir?) 3. if old data exists, we need to upgrade, make sure no filer & s3 are not accessible so no new files are been written: - start weed filer with leveldb config - open the weed shell (in the folder you want the export to occur) and do export fs.meta.save / - move files on success (so migration happen once, or use a FLAG) and find the dynamic export filename - close weed filer with the leveldb config - open weed filer with leveldb2 config - open the weed shell and do import fs.meta.load DYNAMIC_EXPORT_FILENAME Can you please suggest me a better or a simple flow to do the upgrade (migrate from leveldb to leveldb2)?, or even support a backward-compatible in leveldb2 that can READ ONLY old leveldb files and new writes to leveldb2, which will enable a seamless migration. Thanks a lot for your hard work, we LOVE seaweedfs, it RULES!",source-file,"Easier migration from leveldb to leveldb2 Hi, can you please provide a better way to upgrade between these close related filer DB's. using fs.meta.save & fs.meta.load without a specific export name and the unavoidable downtime is cumbersome and problematic. when upgrading the system we need to follow these steps: 1. check if this is a new system (no data exist) or exists leveldb files(upgrade) 2. if new need to create folder filerldb2 like in the Dockerfile (can you please add automatic mkdir?) 3. if old data exists, we need to upgrade, make sure no filer & s3 are not accessible so no new files are been written: - start weed filer with leveldb config - open the weed shell (in the folder you want the export to occur) and do export fs.meta.save / - move files on success (so migration happen once, or use a FLAG) and find the dynamic export filename - close weed filer with the leveldb config - open weed filer with leveldb2 config - open the weed shell and do import fs.meta.load DYNAMIC_EXPORT_FILENAME Can you please suggest me a better or a simple flow to do the upgrade (migrate from leveldb to leveldb2)?, or even support a backward-compatible in leveldb2 that can READ ONLY old leveldb files and new writes to leveldb2, which will enable a seamless migration. Thanks a lot for your hard work, we LOVE seaweedfs, it RULES! source-file",no-bug,0.9
36,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/36,Add document into github,Please Add/Copy document from googlecode into github page or wiki. We no need to peeping googlecode.,documentation-file | other-file | config-file | documentation-file | documentation-file | source-file | source-file | source-file | other-file | config-file | test-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file,Add document into github Please Add/Copy document from googlecode into github page or wiki. We no need to peeping googlecode. documentation-file other-file config-file documentation-file documentation-file source-file source-file source-file other-file config-file test-file source-file source-file source-file source-file test-file test-file source-file other-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file,no-bug,0.95
166,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/166,"when the former ttl(upload ttl, not assign ttl) expired, same file uploaded without ttl option, but it can't be downloaded"," # curl -F file=@start_master.sh http://192.168.23.70:18080/xxxx?ttl=1m {""name"":""start_master.sh"",""size"":645} // after 1m # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 404 Not Found Date: Fri, 10 Jul 2015 15:17:47 GMT Content-Length: 0 # curl -F file=@start_master.sh http://192.168.23.70:18080/xxxx {""name"":""start_master.sh"",""size"":645} # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 404 Not Found Date: Fri, 10 Jul 2015 15:18:12 GMT Content-Length: 0  If I uploaded another file, it can be downloaded:  # curl -F file=@start_volume.sh http://192.168.23.70:18080/xxxx {""name"":""start_volume.sh"",""size"":411} # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 200 OK Accept-Ranges: bytes Content-Disposition: filename=""start_volume.sh"" Content-Length: 411 Content-Type: text/x-sh; charset=utf-8 Etag: ""63bdc9b5"" Last-Modified: Fri, 10 Jul 2015 15:19:28 GMT Date: Fri, 10 Jul 2015 15:19:31 GMT <>  I think if file unchanged but ttl changed, needle should be written to data file:  golang func (v *Volume) write(n *Needle) (size uint32, err error) { if v.isFileUnchanged(n) { size = n.DataSize glog.V(4).Infof(""needle is unchanged!"") return } ",source-file | source-file,"when the former ttl(upload ttl, not assign ttl) expired, same file uploaded without ttl option, but it can't be downloaded  # curl -F file=@start_master.sh http://192.168.23.70:18080/xxxx?ttl=1m {""name"":""start_master.sh"",""size"":645} // after 1m # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 404 Not Found Date: Fri, 10 Jul 2015 15:17:47 GMT Content-Length: 0 # curl -F file=@start_master.sh http://192.168.23.70:18080/xxxx {""name"":""start_master.sh"",""size"":645} # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 404 Not Found Date: Fri, 10 Jul 2015 15:18:12 GMT Content-Length: 0  If I uploaded another file, it can be downloaded:  # curl -F file=@start_volume.sh http://192.168.23.70:18080/xxxx {""name"":""start_volume.sh"",""size"":411} # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 200 OK Accept-Ranges: bytes Content-Disposition: filename=""start_volume.sh"" Content-Length: 411 Content-Type: text/x-sh; charset=utf-8 Etag: ""63bdc9b5"" Last-Modified: Fri, 10 Jul 2015 15:19:28 GMT Date: Fri, 10 Jul 2015 15:19:31 GMT <>  I think if file unchanged but ttl changed, needle should be written to data file:  golang func (v *Volume) write(n *Needle) (size uint32, err error) { if v.isFileUnchanged(n) { size = n.DataSize glog.V(4).Infof(""needle is unchanged!"") return }  source-file source-file",bug,0.9
892,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/892,volumes contain multiple duplicate files,"Hi, when I POST a file to the filer server, I noticed that repeated POSTs of the same file do show up in the volumes. Is this because I'm not doing POST by file key? I am currently doing this based on the filer port and the actual file name for easier reading. And if I want to continue using this way for easy reading, should I then do my own checks for file existence? Was wondering about the speed of this check. Thanks for any advice!",source-file,"volumes contain multiple duplicate files Hi, when I POST a file to the filer server, I noticed that repeated POSTs of the same file do show up in the volumes. Is this because I'm not doing POST by file key? I am currently doing this based on the filer port and the actual file name for easier reading. And if I want to continue using this way for easy reading, should I then do my own checks for file existence? Was wondering about the speed of this check. Thanks for any advice! source-file",no-bug,0.8
2992,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2992,volume.tier.upload progress starts negative,"**Describe the bug** The progress report for volume.tier.upload starts at -30% which is very surprising and uninformative. It even shows negative transfer speed.  > volume.tier.upload -dest=s3.aws -fullPercent=0.00001 -quietFor=10s collect volumes quiet for: 10 seconds tier upload volumes: [3 5 7 2 4 6 1] markVolumeReadonly 3 on 192.168.1.210:8081  copied -18.53%, -76955112 bytes, -73.39MB/s copied -17.86%, -74169832 bytes, 2.66MB/s  copied -1.26%, -5225960 bytes, 2.69MB/s copied -0.57%, -2375144 bytes, 2.72MB/s copied 0.04%, 180760 bytes, 2.44MB/s copied 0.77%, 3195416 bytes, 2.88MB/s  copied 98.80%, 410271208 bytes, 2.69MB/s copied 99.49%, 413122024 bytes, 2.72MB/s markVolumeReadonly 5 on 192.168.1.210:8081   **System Setup** * SeaweedFS 3.00 on Ubuntu 20.04 * `version 30GB 3.00 b1dac20c704cf5322c6c516e5f064eb00701aec9 linux amd64` **Expected behavior** Progress goes from 0% to 100%, and sizes and speeds are all positive values.",source-file,"volume.tier.upload progress starts negative **Describe the bug** The progress report for volume.tier.upload starts at -30% which is very surprising and uninformative. It even shows negative transfer speed.  > volume.tier.upload -dest=s3.aws -fullPercent=0.00001 -quietFor=10s collect volumes quiet for: 10 seconds tier upload volumes: [3 5 7 2 4 6 1] markVolumeReadonly 3 on 192.168.1.210:8081  copied -18.53%, -76955112 bytes, -73.39MB/s copied -17.86%, -74169832 bytes, 2.66MB/s  copied -1.26%, -5225960 bytes, 2.69MB/s copied -0.57%, -2375144 bytes, 2.72MB/s copied 0.04%, 180760 bytes, 2.44MB/s copied 0.77%, 3195416 bytes, 2.88MB/s  copied 98.80%, 410271208 bytes, 2.69MB/s copied 99.49%, 413122024 bytes, 2.72MB/s markVolumeReadonly 5 on 192.168.1.210:8081   **System Setup** * SeaweedFS 3.00 on Ubuntu 20.04 * `version 30GB 3.00 b1dac20c704cf5322c6c516e5f064eb00701aec9 linux amd64` **Expected behavior** Progress goes from 0% to 100%, and sizes and speeds are all positive values. source-file",no-bug,0.9
2325,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2325,"large directory with uuid as filename, `CompactionTableSizeMultiplier: 10,` at `leveldb_store.go` make, leveldb.Get operation slow and high cpu usage.","`weed mount`, single directory, millions of files with uuid as name. when copy files into this directory, `weed/filer/leveldb.(*LevelDBStore).FindEntry` cause leveldb slow at `github.com/syndtr/goleveldb/leveldb/table.(*Reader).find`. I have made a issue at upstream, with some codes simulate seaweedfs as benchmark. see https://github.com/syndtr/goleveldb/issues/370 . And finally, I found If I remove `CompactionTableSizeMultiplier: 10` from `leveldb_store.go`, It's as fast as flying. Then I build weed for test: - #2321 I mentiond, After add bloom filter, 3Mbps->30Mbps - After remove `CompactionTableSizeMultiplier: 10,`, copy 30Mbps -> 60Mbps , and weed cpu rate: 100% -> 90.7% I wonder why there is such config? If it is ok, I will make a pull request to increase efficiency for my use case.  bench codes  db dir: `/home/zbcuda9/seaweed_mount_point/cache_dir/leveldb` fs type : `sudo mount -t tmpfs tmpfs ./cache_dir/ -o size=6g` program to make db files before benchmark: `make_leveldb/main.go`  package main import ( ""fmt"" ""github.com/go-basic/uuid"" ""github.com/syndtr/goleveldb/leveldb"" leveldb_errors ""github.com/syndtr/goleveldb/leveldb/errors"" ""github.com/syndtr/goleveldb/leveldb/filter"" ""github.com/syndtr/goleveldb/leveldb/opt"" ""time"" ) func main() { opts := &opt.Options{ BlockCacheCapacity: 32 * 1024 * 1024, // default value is 8MiB WriteBuffer: 16 * 1024 * 1024, // default value is 4MiB CompactionTableSizeMultiplier: 10, Compression: opt.NoCompression, Filter: filter.NewBloomFilter(8), // false positive rate 0.02 } dir:= ""/home/zbcuda9/seaweed_mount_point/cache_dir/leveldb"" var db *leveldb.DB var err error if db, err = leveldb.OpenFile(dir, opts); err != nil { if leveldb_errors.IsCorrupted(err) { db, err = leveldb.RecoverFile(dir, opts) } if err != nil { fmt.Printf(""filer store open dir %s: %v"", dir, err) return } } defer db.Close() // Add 10,000,000 files first fmt.Print(""prepare leveldb data start."") for i := 0; i <= 10; i++ { tb := time.Now() for j := 0; j< 1000000; j++ { key := ""/what/ever/pre/files/dir/what/ever/pre/files/dir/what/ever/pre/files/dir/"" + uuid.New() + "".jpg"" file_meta := ""what_ever_file_meta_data_what_ever_file_meta_data_what_ever_file_meta_data_what_ever_file_meta_data"" err := db.Put([]byte(key), []byte(file_meta), nil) if err != nil { fmt.Printf(""Insert Failed!"") return } } te := time.Now() ts := float32(te.UnixNano() - tb.UnixNano()) / 1000000000.0 fmt.Println(fmt.Sprintf(""%d: cost %f, %f key per second!"", i, ts, 1000000.0 / ts)) } fmt.Print(""prepare leveldb data finish."") }  program to benchmark: `bench_leveldb/main.go`  package main import ( ""fmt"" ""github.com/go-basic/uuid"" ""github.com/syndtr/goleveldb/leveldb"" leveldb_errors ""github.com/syndtr/goleveldb/leveldb/errors"" ""github.com/syndtr/goleveldb/leveldb/filter"" ""github.com/syndtr/goleveldb/leveldb/opt"" ""time"" ) func main() { opts := &opt.Options{ BlockCacheCapacity: 32 * 1024 * 1024, // default value is 8MiB WriteBuffer: 16 * 1024 * 1024, // default value is 4MiB CompactionTableSizeMultiplier: 10, Compression: opt.NoCompression, Filter: filter.NewBloomFilter(8), // false positive rate 0.02 } dir:= ""/home/zbcuda9/seaweed_mount_point/cache_dir/leveldb"" var db *leveldb.DB var err error if db, err = leveldb.OpenFile(dir, opts); err != nil { if leveldb_errors.IsCorrupted(err) { db, err = leveldb.RecoverFile(dir, opts) } if err != nil { fmt.Printf(""filer store open dir %s: %v"", dir, err) return } } defer db.Close() // Test Speed For 5000 files, 10 times // Follow Business Codes Work Slow! for i := 0; i <= 10; i++ { tb := time.Now() for j := 0; j <= 5000; j++ { key := ""/what/ever/pre/files/dir/what/ever/pre/files/dir/what/ever/pre/files/dir/"" + uuid.New() + "".jpg"" file_meta := ""what_ever_file_meta_data_what_ever_file_meta_data_what_ever_file_meta_data_what_ever_file_meta_data"" // other module need check if meta exists! _, err := db.Get([]byte(key), nil) if err == nil { // call other module } // insert or update meta for file err = db.Put([]byte(key), []byte(file_meta), nil) if err != nil { fmt.Printf(""Insert Failed!"") return } } te := time.Now() ts := float32(te.UnixNano() - tb.UnixNano()) / 1000000000.0 fmt.Println(fmt.Sprintf(""cost: %f, %f key per second!"", ts, 5000.0 / ts)) } }  bench command: `perf record -g ./bench_leveldb` console outputs:  cost: 8.144604, 613.903381 key per second! cost: 8.771235, 570.045105 key per second! cost: 8.518530, 586.955750 key per second! cost: 8.361781, 597.958740 key per second! cost: 8.355777, 598.388428 key per second! cost: 8.296440, 602.668152 key per second! cost: 8.431696, 593.000488 key per second! cost: 8.482813, 589.427124 key per second! cost: 7.859915, 636.139160 key per second! cost: 10.497884, 476.286469 key per second! cost: 10.802630, 462.850220 key per second!  perf result:  - 99.85% 0.00% bench_leveldb bench_leveldb [.] runtime.goexit  - runtime.goexit  - 74.15% runtime.main  - 74.14% main.main  - 72.76% github.com/syndtr/goleveldb/leveldb.(*DB).Get  - 72.70% github.com/syndtr/goleveldb/leveldb.(*DB).get  - 72.27% github.com/syndtr/goleveldb/leveldb.(*version).get  - 72.26% github.com/syndtr/goleveldb/leveldb.(*version).walkOverlapping  - 72.15% github.com/syndtr/goleveldb/leveldb.(*version).get.func1  - 72.13% github.com/syndtr/goleveldb/leveldb.(*tOps).find  - 72.02% github.com/syndtr/goleveldb/leveldb/table.(*Reader).find  - 56.02% github.com/syndtr/goleveldb/leveldb/table.(*Reader).getIndexBlock  - github.com/syndtr/goleveldb/leveldb/table.(*Reader).readBlockCached  - 56.01% github.com/syndtr/goleveldb/leveldb/cache.(*Cache).Get  - 55.82% github.com/syndtr/goleveldb/leveldb/table.(*Reader).readBlockCached.func1  - 55.82% github.com/syndtr/goleveldb/leveldb/table.(*Reader).readBlock  - 55.75% github.com/syndtr/goleveldb/leveldb/table.(*Reader).readRawBlock  + 30.04% hash/crc32.Update  + 25.61% github.com/syndtr/goleveldb/leveldb/util.(*BufferPool).Get  + 15.49% github.com/syndtr/goleveldb/leveldb/table.(*Reader).getFilterBlock  + 0.73% github.com/syndtr/goleveldb/leveldb.(*DB).putRec  + 22.44% github.com/syndtr/goleveldb/leveldb.(*DB).tCompaction  + 1.74% runtime.systemstack  + 0.66% runtime.bgscavenge    after remove `CompactionTableSizeMultiplier: 10,` output :  cost: 0.300306, 16649.691406 key per second! cost: 0.186012, 26879.968750 key per second! cost: 0.184360, 27120.880859 key per second! cost: 0.187674, 26642.000000 key per second! cost: 0.187991, 26596.996094 key per second! cost: 0.187910, 26608.505859 key per second! cost: 0.180480, 27703.882812 key per second! cost: 0.179909, 27791.902344 key per second! cost: 0.186478, 26812.777344 key per second! cost: 0.179908, 27792.000000 key per second! cost: 0.179869, 27797.998047 key per second! ",source-file | source-file | source-file | source-file | source-file | source-file,"large directory with uuid as filename, `CompactionTableSizeMultiplier: 10,` at `leveldb_store.go` make, leveldb.Get operation slow and high cpu usage. `weed mount`, single directory, millions of files with uuid as name. when copy files into this directory, `weed/filer/leveldb.(*LevelDBStore).FindEntry` cause leveldb slow at `github.com/syndtr/goleveldb/leveldb/table.(*Reader).find`. I have made a issue at upstream, with some codes simulate seaweedfs as benchmark. see https://github.com/syndtr/goleveldb/issues/370 . And finally, I found If I remove `CompactionTableSizeMultiplier: 10` from `leveldb_store.go`, It's as fast as flying. Then I build weed for test: - #2321 I mentiond, After add bloom filter, 3Mbps->30Mbps - After remove `CompactionTableSizeMultiplier: 10,`, copy 30Mbps -> 60Mbps , and weed cpu rate: 100% -> 90.7% I wonder why there is such config? If it is ok, I will make a pull request to increase efficiency for my use case.  bench codes  db dir: `/home/zbcuda9/seaweed_mount_point/cache_dir/leveldb` fs type : `sudo mount -t tmpfs tmpfs ./cache_dir/ -o size=6g` program to make db files before benchmark: `make_leveldb/main.go`  package main import ( ""fmt"" ""github.com/go-basic/uuid"" ""github.com/syndtr/goleveldb/leveldb"" leveldb_errors ""github.com/syndtr/goleveldb/leveldb/errors"" ""github.com/syndtr/goleveldb/leveldb/filter"" ""github.com/syndtr/goleveldb/leveldb/opt"" ""time"" ) func main() { opts := &opt.Options{ BlockCacheCapacity: 32 * 1024 * 1024, // default value is 8MiB WriteBuffer: 16 * 1024 * 1024, // default value is 4MiB CompactionTableSizeMultiplier: 10, Compression: opt.NoCompression, Filter: filter.NewBloomFilter(8), // false positive rate 0.02 } dir:= ""/home/zbcuda9/seaweed_mount_point/cache_dir/leveldb"" var db *leveldb.DB var err error if db, err = leveldb.OpenFile(dir, opts); err != nil { if leveldb_errors.IsCorrupted(err) { db, err = leveldb.RecoverFile(dir, opts) } if err != nil { fmt.Printf(""filer store open dir %s: %v"", dir, err) return } } defer db.Close() // Add 10,000,000 files first fmt.Print(""prepare leveldb data start."") for i := 0; i <= 10; i++ { tb := time.Now() for j := 0; j< 1000000; j++ { key := ""/what/ever/pre/files/dir/what/ever/pre/files/dir/what/ever/pre/files/dir/"" + uuid.New() + "".jpg"" file_meta := ""what_ever_file_meta_data_what_ever_file_meta_data_what_ever_file_meta_data_what_ever_file_meta_data"" err := db.Put([]byte(key), []byte(file_meta), nil) if err != nil { fmt.Printf(""Insert Failed!"") return } } te := time.Now() ts := float32(te.UnixNano() - tb.UnixNano()) / 1000000000.0 fmt.Println(fmt.Sprintf(""%d: cost %f, %f key per second!"", i, ts, 1000000.0 / ts)) } fmt.Print(""prepare leveldb data finish."") }  program to benchmark: `bench_leveldb/main.go`  package main import ( ""fmt"" ""github.com/go-basic/uuid"" ""github.com/syndtr/goleveldb/leveldb"" leveldb_errors ""github.com/syndtr/goleveldb/leveldb/errors"" ""github.com/syndtr/goleveldb/leveldb/filter"" ""github.com/syndtr/goleveldb/leveldb/opt"" ""time"" ) func main() { opts := &opt.Options{ BlockCacheCapacity: 32 * 1024 * 1024, // default value is 8MiB WriteBuffer: 16 * 1024 * 1024, // default value is 4MiB CompactionTableSizeMultiplier: 10, Compression: opt.NoCompression, Filter: filter.NewBloomFilter(8), // false positive rate 0.02 } dir:= ""/home/zbcuda9/seaweed_mount_point/cache_dir/leveldb"" var db *leveldb.DB var err error if db, err = leveldb.OpenFile(dir, opts); err != nil { if leveldb_errors.IsCorrupted(err) { db, err = leveldb.RecoverFile(dir, opts) } if err != nil { fmt.Printf(""filer store open dir %s: %v"", dir, err) return } } defer db.Close() // Test Speed For 5000 files, 10 times // Follow Business Codes Work Slow! for i := 0; i <= 10; i++ { tb := time.Now() for j := 0; j <= 5000; j++ { key := ""/what/ever/pre/files/dir/what/ever/pre/files/dir/what/ever/pre/files/dir/"" + uuid.New() + "".jpg"" file_meta := ""what_ever_file_meta_data_what_ever_file_meta_data_what_ever_file_meta_data_what_ever_file_meta_data"" // other module need check if meta exists! _, err := db.Get([]byte(key), nil) if err == nil { // call other module } // insert or update meta for file err = db.Put([]byte(key), []byte(file_meta), nil) if err != nil { fmt.Printf(""Insert Failed!"") return } } te := time.Now() ts := float32(te.UnixNano() - tb.UnixNano()) / 1000000000.0 fmt.Println(fmt.Sprintf(""cost: %f, %f key per second!"", ts, 5000.0 / ts)) } }  bench command: `perf record -g ./bench_leveldb` console outputs:  cost: 8.144604, 613.903381 key per second! cost: 8.771235, 570.045105 key per second! cost: 8.518530, 586.955750 key per second! cost: 8.361781, 597.958740 key per second! cost: 8.355777, 598.388428 key per second! cost: 8.296440, 602.668152 key per second! cost: 8.431696, 593.000488 key per second! cost: 8.482813, 589.427124 key per second! cost: 7.859915, 636.139160 key per second! cost: 10.497884, 476.286469 key per second! cost: 10.802630, 462.850220 key per second!  perf result:  - 99.85% 0.00% bench_leveldb bench_leveldb [.] runtime.goexit  - runtime.goexit  - 74.15% runtime.main  - 74.14% main.main  - 72.76% github.com/syndtr/goleveldb/leveldb.(*DB).Get  - 72.70% github.com/syndtr/goleveldb/leveldb.(*DB).get  - 72.27% github.com/syndtr/goleveldb/leveldb.(*version).get  - 72.26% github.com/syndtr/goleveldb/leveldb.(*version).walkOverlapping  - 72.15% github.com/syndtr/goleveldb/leveldb.(*version).get.func1  - 72.13% github.com/syndtr/goleveldb/leveldb.(*tOps).find  - 72.02% github.com/syndtr/goleveldb/leveldb/table.(*Reader).find  - 56.02% github.com/syndtr/goleveldb/leveldb/table.(*Reader).getIndexBlock  - github.com/syndtr/goleveldb/leveldb/table.(*Reader).readBlockCached  - 56.01% github.com/syndtr/goleveldb/leveldb/cache.(*Cache).Get  - 55.82% github.com/syndtr/goleveldb/leveldb/table.(*Reader).readBlockCached.func1  - 55.82% github.com/syndtr/goleveldb/leveldb/table.(*Reader).readBlock  - 55.75% github.com/syndtr/goleveldb/leveldb/table.(*Reader).readRawBlock  + 30.04% hash/crc32.Update  + 25.61% github.com/syndtr/goleveldb/leveldb/util.(*BufferPool).Get  + 15.49% github.com/syndtr/goleveldb/leveldb/table.(*Reader).getFilterBlock  + 0.73% github.com/syndtr/goleveldb/leveldb.(*DB).putRec  + 22.44% github.com/syndtr/goleveldb/leveldb.(*DB).tCompaction  + 1.74% runtime.systemstack  + 0.66% runtime.bgscavenge    after remove `CompactionTableSizeMultiplier: 10,` output :  cost: 0.300306, 16649.691406 key per second! cost: 0.186012, 26879.968750 key per second! cost: 0.184360, 27120.880859 key per second! cost: 0.187674, 26642.000000 key per second! cost: 0.187991, 26596.996094 key per second! cost: 0.187910, 26608.505859 key per second! cost: 0.180480, 27703.882812 key per second! cost: 0.179909, 27791.902344 key per second! cost: 0.186478, 26812.777344 key per second! cost: 0.179908, 27792.000000 key per second! cost: 0.179869, 27797.998047 key per second!  source-file source-file source-file source-file source-file source-file",no-bug,0.9
4015,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4015,[filer] race to remove an empty directory and create an entry with parent directories,"**Describe the bug** If a leaf arrives at the time of uploading the file, then the file, then the directory with the file is deleted recursively. Since the newly created directory is currently empty version:  3.32  nginx log:  Nov 23, 2022 @ 18:01:08.457 | s3-fast-api/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks/000001 | 200 | 200 | PUT | ingress-default-main-8647798d97-kg8nc | 3.122 Nov 23, 2022 @ 18:01:08.689 | s3-fast-api/thanos/?delimiter=%2F&encoding-type=url&fetch-owner=true&list-type=2&prefix= | 200 | 200 | GET | ingress-default-main-8647798d97-kg8nc | 1.223  seaweed log:  Nov 23, 2022 @ 18:01:07.230 | I1123 13:01:07.230080 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:07.230 | I1123 13:01:07.230085 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:07.774 | I1123 13:01:07.773905 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:07.774 | I1123 13:01:07.773883 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:07.897 | I1123 13:01:07.897070 filer_util.go:65 delete entry /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks: directory:""/buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP"" name:""chunks"" is_delete_data:true is_recursive:true ignore_recursive_error:true Nov 23, 2022 @ 18:01:07.897 | I1123 13:01:07.897051 s3api_objects_list_handlers.go:446 deleting empty folder /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:08.193 | I1123 13:01:08.193615 filer_replication.go:100 delete: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:08.193 | I1123 13:01:08.193622 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:08.333 | I1123 13:01:08.333227 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks/000001 Nov 23, 2022 @ 18:01:08.333 | I1123 13:01:08.333183 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks/000001 Nov 23, 2022 @ 18:01:08.390 | I1123 13:01:08.390711 filer_util.go:65 delete entry /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP: directory:""/buckets/thanos"" name:""01GJJ97E75EEWJRN9YM5P0DXNP"" is_delete_data:true is_recursive:true ignore_recursive_error:true Nov 23, 2022 @ 18:01:08.390 | I1123 13:01:08.390685 s3api_objects_list_handlers.go:446 deleting empty folder /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:08.638 | I1123 13:01:08.638063 filer_replication.go:100 delete: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:08.638 | I1123 13:01:08.638095 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:09.701 | I1123 13:01:09.701445 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:09.701 | I1123 13:01:09.701424 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:11.023 | I1123 13:01:11.023666 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/index Nov 23, 2022 @ 18:01:11.023 | I1123 13:01:11.023692 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/index Nov 23, 2022 @ 18:01:12.040 | I1123 13:01:12.040532 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/meta.json Nov 23, 2022 @ 18:01:12.040 | I1123 13:01:12.040519 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/meta.json ",source-file | source-file,"[filer] race to remove an empty directory and create an entry with parent directories **Describe the bug** If a leaf arrives at the time of uploading the file, then the file, then the directory with the file is deleted recursively. Since the newly created directory is currently empty version:  3.32  nginx log:  Nov 23, 2022 @ 18:01:08.457 | s3-fast-api/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks/000001 | 200 | 200 | PUT | ingress-default-main-8647798d97-kg8nc | 3.122 Nov 23, 2022 @ 18:01:08.689 | s3-fast-api/thanos/?delimiter=%2F&encoding-type=url&fetch-owner=true&list-type=2&prefix= | 200 | 200 | GET | ingress-default-main-8647798d97-kg8nc | 1.223  seaweed log:  Nov 23, 2022 @ 18:01:07.230 | I1123 13:01:07.230080 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:07.230 | I1123 13:01:07.230085 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:07.774 | I1123 13:01:07.773905 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:07.774 | I1123 13:01:07.773883 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:07.897 | I1123 13:01:07.897070 filer_util.go:65 delete entry /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks: directory:""/buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP"" name:""chunks"" is_delete_data:true is_recursive:true ignore_recursive_error:true Nov 23, 2022 @ 18:01:07.897 | I1123 13:01:07.897051 s3api_objects_list_handlers.go:446 deleting empty folder /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:08.193 | I1123 13:01:08.193615 filer_replication.go:100 delete: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:08.193 | I1123 13:01:08.193622 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks Nov 23, 2022 @ 18:01:08.333 | I1123 13:01:08.333227 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks/000001 Nov 23, 2022 @ 18:01:08.333 | I1123 13:01:08.333183 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/chunks/000001 Nov 23, 2022 @ 18:01:08.390 | I1123 13:01:08.390711 filer_util.go:65 delete entry /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP: directory:""/buckets/thanos"" name:""01GJJ97E75EEWJRN9YM5P0DXNP"" is_delete_data:true is_recursive:true ignore_recursive_error:true Nov 23, 2022 @ 18:01:08.390 | I1123 13:01:08.390685 s3api_objects_list_handlers.go:446 deleting empty folder /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:08.638 | I1123 13:01:08.638063 filer_replication.go:100 delete: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:08.638 | I1123 13:01:08.638095 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:09.701 | I1123 13:01:09.701445 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:09.701 | I1123 13:01:09.701424 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP Nov 23, 2022 @ 18:01:11.023 | I1123 13:01:11.023666 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/index Nov 23, 2022 @ 18:01:11.023 | I1123 13:01:11.023692 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/index Nov 23, 2022 @ 18:01:12.040 | I1123 13:01:12.040532 filer_replication.go:112 replicated /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/meta.json Nov 23, 2022 @ 18:01:12.040 | I1123 13:01:12.040519 filer_replication.go:102 add: /buckets/thanos/01GJJ97E75EEWJRN9YM5P0DXNP/meta.json  source-file source-file",no-bug,0.9
4530,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4530,Failed to commit new volume file when running vacuum on Windows,"**Describe the bug** When the server is committing new volume file, the old one is still opening and can't be deleted, so the vacuum will fail. **System Setup** - Windows 11 - version 30GB 3.51 4310e1fac4e59a4391159e6c349f45a8e1cd0601 windows amd64 - Start with `weed server` - Upload a file and delete - Trigger the vacuum **Expected behavior** Vacuum completes with no errors. **Additional context**  I0603 03:12:21.420840 volume_vacuum.go:106 Committing volume 5 vacuuming E0603 03:12:21.421865 volume_grpc_vacuum.go:87 failed commit volume 5: remove C:\Users\\AppData\Local\Temp/5.dat: The process cannot access the file because it is being used by another process. ",source-file | source-file | source-file | source-file,"Failed to commit new volume file when running vacuum on Windows **Describe the bug** When the server is committing new volume file, the old one is still opening and can't be deleted, so the vacuum will fail. **System Setup** - Windows 11 - version 30GB 3.51 4310e1fac4e59a4391159e6c349f45a8e1cd0601 windows amd64 - Start with `weed server` - Upload a file and delete - Trigger the vacuum **Expected behavior** Vacuum completes with no errors. **Additional context**  I0603 03:12:21.420840 volume_vacuum.go:106 Committing volume 5 vacuuming E0603 03:12:21.421865 volume_grpc_vacuum.go:87 failed commit volume 5: remove C:\Users\\AppData\Local\Temp/5.dat: The process cannot access the file because it is being used by another process.  source-file source-file source-file source-file",no-bug,0.9
1414,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1414,Volume servers don't notice master change,"We have a constant bug in low load cluster when volume servers don't notice master change. **Our setup** SeaweedFS version - we tryed 1.56 and 1.87 Three hosts 192.168.50.{71,72,73}. There are one master on port 9333 and three volume servers on ports 8081, 8082 8083 per host. All volume servers are in the same DC but are formed in three racks, one rack per host. Commands to start are identical on every host:  /bin/weed -v 0 volume -index=leveldbMedium -dataCenter=dc1 -rack=rack1 -dir=/data/swfs/volume1 -max=300 -ip=192.168.50.71 -port=8081 -port.public=8181 -publicUrl=http://192.168.50.71:8181 -mserver=192.168.50.71:9333,192.168.50.72:9333,192.168.50.73:9333 /bin/weed -v 0 volume -index=leveldbMedium -dataCenter=dc1 -rack=rack1 -dir=/data/swfs/volume3 -max=300 -ip=192.168.50.71 -port=8083 -port.public=8183 -publicUrl=http://192.168.50.71:8183 -mserver=192.168.50.71:9333,192.168.50.72:9333,192.168.50.73:9333 /bin/weed -v 0 volume -index=leveldbMedium -dataCenter=dc1 -rack=rack1 -dir=/data/swfs/volume2 -max=300 -ip=192.168.50.71 -port=8082 -port.public=8182 -publicUrl=http://192.168.50.71:8182 -mserver=192.168.50.71:9333,192.168.50.72:9333,192.168.50.73:9333 /bin/weed -v 0 master -volumeSizeLimitMB=50 -defaultReplication=011 -mdir=/data/swfs/master -ip=192.168.50.71 -port=9333 -peers=192.168.50.71:9333,192.168.50.72:9333,192.168.50.73:9333  **Problem** When master changed all volume servers sometimes don't notice new master and keep connection with old one. As a result new master know nothing about volume servers. Cluster status:  { ""Leader"": ""192.168.50.73:9333"", ""Peers"": [ ""192.168.50.73:9333"", ""192.168.50.72:9333"" ] }  Log from master where we can see new master election:  I0806 00:58:45 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value: prevValue:192.168.50.72:9333} I0806 00:58:46 24607 master_server.go:148] state change: &{typ:stateChange source:0xc0001fa360 value:leader prevValue:candidate} I0806 00:58:46 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value:192.168.50.71:9333 prevValue:} I0806 00:58:46 24607 master_server.go:144] [ 192.168.50.71:9333 ] 192.168.50.71:9333 becomes leader. I0806 01:02:16 24607 master_server.go:148] state change: &{typ:stateChange source:0xc0001fa360 value:follower prevValue:leader} I0806 01:02:20 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value:192.168.50.73:9333 prevValue:} I0806 01:02:20 24607 master_server.go:144] [ 192.168.50.71:9333 ] 192.168.50.73:9333 becomes leader. I0806 01:03:48 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value: prevValue:192.168.50.73:9333} I0806 01:03:48 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value:192.168.50.73:9333 prevValue:} I0806 01:03:48 24607 master_server.go:144] [ 192.168.50.71:9333 ] 192.168.50.73:9333 becomes leader.  Connections list on the host of old master:  ESTAB 0 0 192.168.50.71:60000 192.168.50.71:19333 users:((""weed"",pid=24607,fd=14)) ESTAB 0 0 192.168.50.71:39154 192.168.50.73:18081 users:((""weed"",pid=24607,fd=42)) ESTAB 0 0 192.168.50.71:36896 192.168.50.73:19333 users:((""weed"",pid=24607,fd=22)) ESTAB 0 0 192.168.50.71:41148 192.168.50.71:19333 users:((""weed"",pid=24265,fd=66)) ESTAB 0 0 192.168.50.71:47516 192.168.50.71:18081 users:((""weed"",pid=24607,fd=43)) ESTAB 0 0 192.168.50.71:44232 192.168.50.72:19333 users:((""weed"",pid=24607,fd=20)) ESTAB 0 0 192.168.50.71:54940 192.168.50.72:18082 users:((""weed"",pid=24607,fd=38)) ESTAB 0 0 192.168.50.71:41146 192.168.50.71:19333 users:((""weed"",pid=24264,fd=34)) ESTAB 0 0 192.168.50.71:44190 192.168.50.72:19333 users:((""weed"",pid=24607,fd=13)) ESTAB 0 0 192.168.50.71:39816 192.168.50.72:9333 users:((""weed"",pid=24607,fd=923)) ESTAB 0 0 192.168.50.71:36858 192.168.50.73:19333 users:((""weed"",pid=24607,fd=18)) ESTAB 0 0 192.168.50.71:36884 192.168.50.73:19333 users:((""weed"",pid=24607,fd=21)) ESTAB 0 0 192.168.50.71:60398 192.168.50.71:9333 users:((""weed"",pid=24262,fd=58)) ESTAB 0 0 192.168.50.71:50170 192.168.50.72:18081 users:((""weed"",pid=24607,fd=35)) ESTAB 0 0 192.168.50.71:48738 192.168.50.73:19333 users:((""weed"",pid=24607,fd=24)) ESTAB 0 0 192.168.50.71:41150 192.168.50.71:19333 users:((""weed"",pid=24262,fd=41)) ESTAB 0 0 192.168.50.71:44188 192.168.50.72:19333 users:((""weed"",pid=24607,fd=16)) ESTAB 0 0 192.168.50.71:33368 192.168.50.73:18082 users:((""weed"",pid=24607,fd=41)) ESTAB 0 0 192.168.50.71:48946 192.168.50.71:18082 users:((""weed"",pid=24607,fd=36)) ESTAB 0 0 192.168.50.71:50564 192.168.50.73:18083 users:((""weed"",pid=24607,fd=40)) ESTAB 0 0 192.168.50.71:50906 192.168.50.72:18083 users:((""weed"",pid=24607,fd=39)) ESTAB 0 0 192.168.50.71:33506 192.168.50.73:9333 users:((""weed"",pid=24607,fd=26)) ESTAB 0 0 192.168.50.71:54044 192.168.50.71:18083 users:((""weed"",pid=24607,fd=37)) ESTAB 0 0 192.168.50.71:35770 192.168.50.73:9333 users:((""weed"",pid=24607,fd=931)) ESTAB 0 0 192.168.50.71:36860 192.168.50.73:19333 users:((""weed"",pid=24607,fd=19)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:40678 users:((""weed"",pid=24607,fd=17)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:49992 users:((""weed"",pid=24607,fd=28)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.71]:60398 users:((""weed"",pid=24607,fd=51)) ESTAB 0 0 [::ffff:192.168.50.71]:18082 [::ffff:192.168.50.71]:48946 users:((""weed"",pid=24265,fd=67)) ESTAB 0 0 [::ffff:192.168.50.71]:18081 [::ffff:192.168.50.73]:49072 users:((""weed"",pid=24262,fd=44)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:52480 users:((""weed"",pid=24607,fd=46)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.73]:52468 users:((""weed"",pid=24607,fd=58)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:42828 users:((""weed"",pid=24607,fd=31)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.72]:37546 users:((""weed"",pid=24607,fd=33)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.71]:41148 users:((""weed"",pid=24607,fd=48)) ESTAB 0 0 [::ffff:192.168.50.71]:18083 [::ffff:192.168.50.71]:54044 users:((""weed"",pid=24264,fd=37)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:42830 users:((""weed"",pid=24607,fd=32)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.73]:43658 users:((""weed"",pid=24607,fd=34)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.73]:59592 users:((""weed"",pid=24607,fd=27)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.72]:46924 users:((""weed"",pid=24607,fd=44)) ESTAB 0 0 [::ffff:192.168.50.71]:18083 [::ffff:192.168.50.73]:38330 users:((""weed"",pid=24264,fd=38)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:33472 users:((""weed"",pid=24607,fd=11)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:42826 users:((""weed"",pid=24607,fd=30)) ESTAB 0 0 [::ffff:192.168.50.71]:18082 [::ffff:192.168.50.73]:42020 users:((""weed"",pid=24265,fd=68)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:49994 users:((""weed"",pid=24607,fd=29)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:49990 users:((""weed"",pid=24607,fd=25)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.71]:60000 users:((""weed"",pid=24607,fd=15)) ESTAB 0 0 [::ffff:192.168.50.71]:18081 [::ffff:192.168.50.71]:47516 users:((""weed"",pid=24262,fd=43)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.71]:41146 users:((""weed"",pid=24607,fd=47)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.71]:41150 users:((""weed"",pid=24607,fd=49)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:45288 users:((""weed"",pid=24607,fd=45)) ",source-file | source-file,"Volume servers don't notice master change We have a constant bug in low load cluster when volume servers don't notice master change. **Our setup** SeaweedFS version - we tryed 1.56 and 1.87 Three hosts 192.168.50.{71,72,73}. There are one master on port 9333 and three volume servers on ports 8081, 8082 8083 per host. All volume servers are in the same DC but are formed in three racks, one rack per host. Commands to start are identical on every host:  /bin/weed -v 0 volume -index=leveldbMedium -dataCenter=dc1 -rack=rack1 -dir=/data/swfs/volume1 -max=300 -ip=192.168.50.71 -port=8081 -port.public=8181 -publicUrl=http://192.168.50.71:8181 -mserver=192.168.50.71:9333,192.168.50.72:9333,192.168.50.73:9333 /bin/weed -v 0 volume -index=leveldbMedium -dataCenter=dc1 -rack=rack1 -dir=/data/swfs/volume3 -max=300 -ip=192.168.50.71 -port=8083 -port.public=8183 -publicUrl=http://192.168.50.71:8183 -mserver=192.168.50.71:9333,192.168.50.72:9333,192.168.50.73:9333 /bin/weed -v 0 volume -index=leveldbMedium -dataCenter=dc1 -rack=rack1 -dir=/data/swfs/volume2 -max=300 -ip=192.168.50.71 -port=8082 -port.public=8182 -publicUrl=http://192.168.50.71:8182 -mserver=192.168.50.71:9333,192.168.50.72:9333,192.168.50.73:9333 /bin/weed -v 0 master -volumeSizeLimitMB=50 -defaultReplication=011 -mdir=/data/swfs/master -ip=192.168.50.71 -port=9333 -peers=192.168.50.71:9333,192.168.50.72:9333,192.168.50.73:9333  **Problem** When master changed all volume servers sometimes don't notice new master and keep connection with old one. As a result new master know nothing about volume servers. Cluster status:  { ""Leader"": ""192.168.50.73:9333"", ""Peers"": [ ""192.168.50.73:9333"", ""192.168.50.72:9333"" ] }  Log from master where we can see new master election:  I0806 00:58:45 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value: prevValue:192.168.50.72:9333} I0806 00:58:46 24607 master_server.go:148] state change: &{typ:stateChange source:0xc0001fa360 value:leader prevValue:candidate} I0806 00:58:46 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value:192.168.50.71:9333 prevValue:} I0806 00:58:46 24607 master_server.go:144] [ 192.168.50.71:9333 ] 192.168.50.71:9333 becomes leader. I0806 01:02:16 24607 master_server.go:148] state change: &{typ:stateChange source:0xc0001fa360 value:follower prevValue:leader} I0806 01:02:20 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value:192.168.50.73:9333 prevValue:} I0806 01:02:20 24607 master_server.go:144] [ 192.168.50.71:9333 ] 192.168.50.73:9333 becomes leader. I0806 01:03:48 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value: prevValue:192.168.50.73:9333} I0806 01:03:48 24607 master_server.go:142] event: &{typ:leaderChange source:0xc0001fa360 value:192.168.50.73:9333 prevValue:} I0806 01:03:48 24607 master_server.go:144] [ 192.168.50.71:9333 ] 192.168.50.73:9333 becomes leader.  Connections list on the host of old master:  ESTAB 0 0 192.168.50.71:60000 192.168.50.71:19333 users:((""weed"",pid=24607,fd=14)) ESTAB 0 0 192.168.50.71:39154 192.168.50.73:18081 users:((""weed"",pid=24607,fd=42)) ESTAB 0 0 192.168.50.71:36896 192.168.50.73:19333 users:((""weed"",pid=24607,fd=22)) ESTAB 0 0 192.168.50.71:41148 192.168.50.71:19333 users:((""weed"",pid=24265,fd=66)) ESTAB 0 0 192.168.50.71:47516 192.168.50.71:18081 users:((""weed"",pid=24607,fd=43)) ESTAB 0 0 192.168.50.71:44232 192.168.50.72:19333 users:((""weed"",pid=24607,fd=20)) ESTAB 0 0 192.168.50.71:54940 192.168.50.72:18082 users:((""weed"",pid=24607,fd=38)) ESTAB 0 0 192.168.50.71:41146 192.168.50.71:19333 users:((""weed"",pid=24264,fd=34)) ESTAB 0 0 192.168.50.71:44190 192.168.50.72:19333 users:((""weed"",pid=24607,fd=13)) ESTAB 0 0 192.168.50.71:39816 192.168.50.72:9333 users:((""weed"",pid=24607,fd=923)) ESTAB 0 0 192.168.50.71:36858 192.168.50.73:19333 users:((""weed"",pid=24607,fd=18)) ESTAB 0 0 192.168.50.71:36884 192.168.50.73:19333 users:((""weed"",pid=24607,fd=21)) ESTAB 0 0 192.168.50.71:60398 192.168.50.71:9333 users:((""weed"",pid=24262,fd=58)) ESTAB 0 0 192.168.50.71:50170 192.168.50.72:18081 users:((""weed"",pid=24607,fd=35)) ESTAB 0 0 192.168.50.71:48738 192.168.50.73:19333 users:((""weed"",pid=24607,fd=24)) ESTAB 0 0 192.168.50.71:41150 192.168.50.71:19333 users:((""weed"",pid=24262,fd=41)) ESTAB 0 0 192.168.50.71:44188 192.168.50.72:19333 users:((""weed"",pid=24607,fd=16)) ESTAB 0 0 192.168.50.71:33368 192.168.50.73:18082 users:((""weed"",pid=24607,fd=41)) ESTAB 0 0 192.168.50.71:48946 192.168.50.71:18082 users:((""weed"",pid=24607,fd=36)) ESTAB 0 0 192.168.50.71:50564 192.168.50.73:18083 users:((""weed"",pid=24607,fd=40)) ESTAB 0 0 192.168.50.71:50906 192.168.50.72:18083 users:((""weed"",pid=24607,fd=39)) ESTAB 0 0 192.168.50.71:33506 192.168.50.73:9333 users:((""weed"",pid=24607,fd=26)) ESTAB 0 0 192.168.50.71:54044 192.168.50.71:18083 users:((""weed"",pid=24607,fd=37)) ESTAB 0 0 192.168.50.71:35770 192.168.50.73:9333 users:((""weed"",pid=24607,fd=931)) ESTAB 0 0 192.168.50.71:36860 192.168.50.73:19333 users:((""weed"",pid=24607,fd=19)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:40678 users:((""weed"",pid=24607,fd=17)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:49992 users:((""weed"",pid=24607,fd=28)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.71]:60398 users:((""weed"",pid=24607,fd=51)) ESTAB 0 0 [::ffff:192.168.50.71]:18082 [::ffff:192.168.50.71]:48946 users:((""weed"",pid=24265,fd=67)) ESTAB 0 0 [::ffff:192.168.50.71]:18081 [::ffff:192.168.50.73]:49072 users:((""weed"",pid=24262,fd=44)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:52480 users:((""weed"",pid=24607,fd=46)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.73]:52468 users:((""weed"",pid=24607,fd=58)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:42828 users:((""weed"",pid=24607,fd=31)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.72]:37546 users:((""weed"",pid=24607,fd=33)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.71]:41148 users:((""weed"",pid=24607,fd=48)) ESTAB 0 0 [::ffff:192.168.50.71]:18083 [::ffff:192.168.50.71]:54044 users:((""weed"",pid=24264,fd=37)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:42830 users:((""weed"",pid=24607,fd=32)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.73]:43658 users:((""weed"",pid=24607,fd=34)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.73]:59592 users:((""weed"",pid=24607,fd=27)) ESTAB 0 0 [::ffff:192.168.50.71]:9333 [::ffff:192.168.50.72]:46924 users:((""weed"",pid=24607,fd=44)) ESTAB 0 0 [::ffff:192.168.50.71]:18083 [::ffff:192.168.50.73]:38330 users:((""weed"",pid=24264,fd=38)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:33472 users:((""weed"",pid=24607,fd=11)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:42826 users:((""weed"",pid=24607,fd=30)) ESTAB 0 0 [::ffff:192.168.50.71]:18082 [::ffff:192.168.50.73]:42020 users:((""weed"",pid=24265,fd=68)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:49994 users:((""weed"",pid=24607,fd=29)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.73]:49990 users:((""weed"",pid=24607,fd=25)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.71]:60000 users:((""weed"",pid=24607,fd=15)) ESTAB 0 0 [::ffff:192.168.50.71]:18081 [::ffff:192.168.50.71]:47516 users:((""weed"",pid=24262,fd=43)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.71]:41146 users:((""weed"",pid=24607,fd=47)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.71]:41150 users:((""weed"",pid=24607,fd=49)) ESTAB 0 0 [::ffff:192.168.50.71]:19333 [::ffff:192.168.50.72]:45288 users:((""weed"",pid=24607,fd=45))  source-file source-file",no-bug,0.9
2357,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2357,Server panic: invalid memory address,"**Describe the bug** I got a random `panic: runtime error: invalid memory address or nil pointer dereference` after a 10-hour uptime and it crashed the server. I was running `weed filter.copy` on node1 and node3 at that time since the server was up. I'm honestly not sure if this is reproducible so feel free to close this if you have no idea about this. Not sure if they're related, but 1 out of 4 servers is running a different commit, as stated down below in the system setup section. As a side note, what's up with the `deleting fileIds len=9 error: delete fileId 55,90fa22e53c0185: volume 55 not found on node4:8080` I'm seeing too? Not that they're blocking issues just curious. **Relevant logs** `weed server -options=/etc/xdg/seaweedfs/server.conf -ip=node1` log  Oct 05 03:58:07 node1 weed[3229970]: I1005 03:58:07 29970 filer_grpc_server_sub_meta.go:101] read on disk filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:07 node1 weed[3229970]: I1005 03:58:07 29970 filer_grpc_server_sub_meta.go:246] - listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:07 node1 weed[3229970]: I1005 03:58:07 29970 filer_deletion.go:57] deleting fileIds len=3 error: delete fileId 55,90fa0935601152: volume 55 not found on node2:8080 Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_grpc_server_sub_meta.go:241] + listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_grpc_server_sub_meta.go:89] filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_grpc_server_sub_meta.go:101] read on disk filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_grpc_server_sub_meta.go:246] - listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_deletion.go:57] deleting fileIds len=3 error: delete fileId 55,90fa0b5f04cb61: volume 55 not found on node4:8080 Oct 05 03:58:09 node1 weed[3229970]: I1005 03:58:09 29970 filer_deletion.go:57] deleting fileIds len=3 error: delete fileId 55,90fa167197206a: volume 55 not found on node2:8080 Oct 05 03:58:10 node1 weed[3229970]: I1005 03:58:10 29970 filer_grpc_server_sub_meta.go:241] + listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:10 node1 weed[3229970]: I1005 03:58:10 29970 filer_grpc_server_sub_meta.go:89] filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:10 node1 weed[3229970]: I1005 03:58:10 29970 filer_grpc_server_sub_meta.go:101] read on disk filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:10 node1 weed[3229970]: I1005 03:58:10 29970 filer_grpc_server_sub_meta.go:246] - listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:11 node1 weed[3229970]: I1005 03:58:11 29970 filer_deletion.go:57] deleting fileIds len=4 error: delete fileId 55,90fa263b252be4: volume 55 not found on node2:8080 Oct 05 03:58:11 node1 weed[3229970]: I1005 03:58:11 29970 topology_vacuum.go:83] Complete vacuuming 30 on node1:8080 Oct 05 03:58:11 node1 weed[3229970]: I1005 03:58:11 29970 topology_vacuum.go:107] Start Committing vacuum 30 on node1:8080 Oct 05 03:58:11 node1 weed[3229970]: I1005 03:58:11 29970 volume_vacuum.go:93] Committing volume 30 vacuuming Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 volume_loading.go:86] readSuperBlock volume 30 version 3 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 volume_loading.go:133] loading index /index/30.idx to memory Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_deletion.go:57] deleting fileIds len=9 error: delete fileId 55,90fa22e53c0185: volume 55 not found on node4:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:121] Complete Committing vacuum 30 on node1:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:107] Start Committing vacuum 30 on node2:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_grpc_server_sub_meta.go:241] + listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_grpc_server_sub_meta.go:89] filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_grpc_server_sub_meta.go:101] read on disk filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_grpc_server_sub_meta.go:246] - listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:121] Complete Committing vacuum 30 on node2:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 volume_layout.go:362] Volume 30 becomes writable Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:71] 1 Start vacuuming 76 on node3:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:71] 0 Start vacuuming 76 on node1:8080 Oct 05 03:58:12 node1 weed[3229970]: panic: runtime error: invalid memory address or nil pointer dereference Oct 05 03:58:12 node1 weed[3229970]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x557cb3888bfb] Oct 05 03:58:12 node1 weed[3229970]: goroutine 36721451 [running]: Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/topology.(*VolumeLayout).GetActiveVolumeCount(0xc00d042400, 0xc046482930) Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/topology/volume_layout.go:322 +0x31b Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).shouldVolumeGrow(0xc000306c00, 0xc046482930) Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/server/master_server_handlers_admin.go:137 +0xed Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).Assign(0xc000306c00, {0x557cb486edb8, 0xc041698480}, 0xc00672e790) Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/server/master_grpc_server_volume.go:133 +0x4e5 Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/pb/master_pb._Seaweed_Assign_Handler({0x557cb47a1880, 0xc000306c00}, {0x557cb486edb8, 0xc041698480}, 0xc02952d080, 0x0) Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/pb/master_pb/master.pb.go:4505 +0x385 Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc.(*Server).processUnaryRPC(0xc00044d6c0, {0x557cb48997e8, 0xc00001d080}, 0xc015e8d680, 0xc00986be90, 0x557cb5a987b8, 0x0) Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc@v1.40.0/server.go:1297 +0x14c9 Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc.(*Server).handleStream(0xc00044d6c0, {0x557cb48997e8, 0xc00001d080}, 0xc015e8d680, 0x0) Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc@v1.40.0/server.go:1626 +0x85e Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc.(*Server).serveStreams.func1.2() Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc@v1.40.0/server.go:941 +0x11d Oct 05 03:58:12 node1 weed[3229970]: created by google.golang.org/grpc.(*Server).serveStreams.func1 Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc@v1.40.0/server.go:939 +0x345 Oct 05 04:03:06 node1 systemd[1]: seaweedfs.service: Main process exited, code=exited, status=2/INVALIDARGUMENT Oct 05 04:03:06 node1 systemd[1]: seaweedfs.service: Failed with result 'exit-code'.  **System Setup** - Arch linux - node1, node3, node4 version: b297849147a570af9a5413bd668e786a5897de34 - node2 version: 6a030547a2efa3efe38491aa8fc06f3b7d3acc75 - server.conf:  master.defaultReplication=001 volume.dir.idx=/index dir=/brick/05 filer=true filer.peers=node1:8888,node2:8888,node3:8888,node4:8888 master.volumePreallocate=true master.peers=node1:9333,node3:9333,node4:9333 rack=rack1 dataCenter=dc1 volume.max=10000 volume.concurrentUploadLimitMB=999999 filer.concurrentUploadLimitMB=999999 metrics.address=node3:9091 ",source-file,"Server panic: invalid memory address **Describe the bug** I got a random `panic: runtime error: invalid memory address or nil pointer dereference` after a 10-hour uptime and it crashed the server. I was running `weed filter.copy` on node1 and node3 at that time since the server was up. I'm honestly not sure if this is reproducible so feel free to close this if you have no idea about this. Not sure if they're related, but 1 out of 4 servers is running a different commit, as stated down below in the system setup section. As a side note, what's up with the `deleting fileIds len=9 error: delete fileId 55,90fa22e53c0185: volume 55 not found on node4:8080` I'm seeing too? Not that they're blocking issues just curious. **Relevant logs** `weed server -options=/etc/xdg/seaweedfs/server.conf -ip=node1` log  Oct 05 03:58:07 node1 weed[3229970]: I1005 03:58:07 29970 filer_grpc_server_sub_meta.go:101] read on disk filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:07 node1 weed[3229970]: I1005 03:58:07 29970 filer_grpc_server_sub_meta.go:246] - listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:07 node1 weed[3229970]: I1005 03:58:07 29970 filer_deletion.go:57] deleting fileIds len=3 error: delete fileId 55,90fa0935601152: volume 55 not found on node2:8080 Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_grpc_server_sub_meta.go:241] + listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_grpc_server_sub_meta.go:89] filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_grpc_server_sub_meta.go:101] read on disk filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_grpc_server_sub_meta.go:246] - listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:08 node1 weed[3229970]: I1005 03:58:08 29970 filer_deletion.go:57] deleting fileIds len=3 error: delete fileId 55,90fa0b5f04cb61: volume 55 not found on node4:8080 Oct 05 03:58:09 node1 weed[3229970]: I1005 03:58:09 29970 filer_deletion.go:57] deleting fileIds len=3 error: delete fileId 55,90fa167197206a: volume 55 not found on node2:8080 Oct 05 03:58:10 node1 weed[3229970]: I1005 03:58:10 29970 filer_grpc_server_sub_meta.go:241] + listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:10 node1 weed[3229970]: I1005 03:58:10 29970 filer_grpc_server_sub_meta.go:89] filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:10 node1 weed[3229970]: I1005 03:58:10 29970 filer_grpc_server_sub_meta.go:101] read on disk filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:10 node1 weed[3229970]: I1005 03:58:10 29970 filer_grpc_server_sub_meta.go:246] - listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:11 node1 weed[3229970]: I1005 03:58:11 29970 filer_deletion.go:57] deleting fileIds len=4 error: delete fileId 55,90fa263b252be4: volume 55 not found on node2:8080 Oct 05 03:58:11 node1 weed[3229970]: I1005 03:58:11 29970 topology_vacuum.go:83] Complete vacuuming 30 on node1:8080 Oct 05 03:58:11 node1 weed[3229970]: I1005 03:58:11 29970 topology_vacuum.go:107] Start Committing vacuum 30 on node1:8080 Oct 05 03:58:11 node1 weed[3229970]: I1005 03:58:11 29970 volume_vacuum.go:93] Committing volume 30 vacuuming Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 volume_loading.go:86] readSuperBlock volume 30 version 3 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 volume_loading.go:133] loading index /index/30.idx to memory Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_deletion.go:57] deleting fileIds len=9 error: delete fileId 55,90fa22e53c0185: volume 55 not found on node4:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:121] Complete Committing vacuum 30 on node1:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:107] Start Committing vacuum 30 on node2:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_grpc_server_sub_meta.go:241] + listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_grpc_server_sub_meta.go:89] filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_grpc_server_sub_meta.go:101] read on disk filer:node2:8888@192.168.50.202:48712 local subscribe / from 2021-10-04 07:59:43.536408833 +0800 HKT Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 filer_grpc_server_sub_meta.go:246] - listener filer:node2:8888@192.168.50.202:48712 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:121] Complete Committing vacuum 30 on node2:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 volume_layout.go:362] Volume 30 becomes writable Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:71] 1 Start vacuuming 76 on node3:8080 Oct 05 03:58:12 node1 weed[3229970]: I1005 03:58:12 29970 topology_vacuum.go:71] 0 Start vacuuming 76 on node1:8080 Oct 05 03:58:12 node1 weed[3229970]: panic: runtime error: invalid memory address or nil pointer dereference Oct 05 03:58:12 node1 weed[3229970]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x557cb3888bfb] Oct 05 03:58:12 node1 weed[3229970]: goroutine 36721451 [running]: Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/topology.(*VolumeLayout).GetActiveVolumeCount(0xc00d042400, 0xc046482930) Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/topology/volume_layout.go:322 +0x31b Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).shouldVolumeGrow(0xc000306c00, 0xc046482930) Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/server/master_server_handlers_admin.go:137 +0xed Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).Assign(0xc000306c00, {0x557cb486edb8, 0xc041698480}, 0xc00672e790) Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/server/master_grpc_server_volume.go:133 +0x4e5 Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/pb/master_pb._Seaweed_Assign_Handler({0x557cb47a1880, 0xc000306c00}, {0x557cb486edb8, 0xc041698480}, 0xc02952d080, 0x0) Oct 05 03:58:12 node1 weed[3229970]: github.com/chrislusf/seaweedfs/weed/pb/master_pb/master.pb.go:4505 +0x385 Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc.(*Server).processUnaryRPC(0xc00044d6c0, {0x557cb48997e8, 0xc00001d080}, 0xc015e8d680, 0xc00986be90, 0x557cb5a987b8, 0x0) Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc@v1.40.0/server.go:1297 +0x14c9 Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc.(*Server).handleStream(0xc00044d6c0, {0x557cb48997e8, 0xc00001d080}, 0xc015e8d680, 0x0) Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc@v1.40.0/server.go:1626 +0x85e Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc.(*Server).serveStreams.func1.2() Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc@v1.40.0/server.go:941 +0x11d Oct 05 03:58:12 node1 weed[3229970]: created by google.golang.org/grpc.(*Server).serveStreams.func1 Oct 05 03:58:12 node1 weed[3229970]: google.golang.org/grpc@v1.40.0/server.go:939 +0x345 Oct 05 04:03:06 node1 systemd[1]: seaweedfs.service: Main process exited, code=exited, status=2/INVALIDARGUMENT Oct 05 04:03:06 node1 systemd[1]: seaweedfs.service: Failed with result 'exit-code'.  **System Setup** - Arch linux - node1, node3, node4 version: b297849147a570af9a5413bd668e786a5897de34 - node2 version: 6a030547a2efa3efe38491aa8fc06f3b7d3acc75 - server.conf:  master.defaultReplication=001 volume.dir.idx=/index dir=/brick/05 filer=true filer.peers=node1:8888,node2:8888,node3:8888,node4:8888 master.volumePreallocate=true master.peers=node1:9333,node3:9333,node4:9333 rack=rack1 dataCenter=dc1 volume.max=10000 volume.concurrentUploadLimitMB=999999 filer.concurrentUploadLimitMB=999999 metrics.address=node3:9091  source-file",no-bug,0.9
6034,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6034,[Mount] Unable to start mount,"**Describe the bug** I just updated to commit 2b13d2c083a8cf2e1efc616e3301ce590c78cf11 and mount refuses to start anymore. This is the error:  I0917 11:11:23.922805 needle_map_leveldb.go:67 Loading /mnt/seaweedfs/.docker/cloud_edge/48101edc/c2_2_1.ldb , watermark: 0 I0917 11:11:23.923168 leveldb_store.go:47 filer store dir: /mnt/seaweedfs/.docker/cloud_edge/48101edc/meta I0917 11:11:23.923198 file_util.go:27 Folder /mnt/seaweedfs/.docker/cloud_edge/48101edc/meta Permission: -rwxr-xr-x I0917 11:11:23.931053 wfs_filer_client.go:31 WithFilerClient 0 vpn.katapy.icu:18888: filer: no entry is found in filer store I0917 11:11:23.942884 wfs_filer_client.go:31 WithFilerClient 1 lh1.vpn.katapy.icu:18888: filer: no entry is found in filer store failed to start background tasks: filer: no entry is found in filer store  My guess is it is related to the new WORM patch which added: https://github.com/seaweedfs/seaweedfs/blob/2b13d2c083a8cf2e1efc616e3301ce590c78cf11/weed/mount/weedfs.go#L144  fn, err := wfs.subscribeFilerConfEvents() if err != nil { return err } go fn()  The **remote** filer has data ( tested connecting with shell ) but the **local** filer store used for cache, that is created new, is empty with version change on a new folder, has no data and I think this causes the mount to crash. **System Setup** Commit 2b13d2c083a8cf2e1efc616e3301ce590c78cf11 **Expected behavior** Weed should run normally as before **Additional context** I am going to locally test removing the return error that is causing in my opinion the mount to not work anymore",source-file,"[Mount] Unable to start mount **Describe the bug** I just updated to commit 2b13d2c083a8cf2e1efc616e3301ce590c78cf11 and mount refuses to start anymore. This is the error:  I0917 11:11:23.922805 needle_map_leveldb.go:67 Loading /mnt/seaweedfs/.docker/cloud_edge/48101edc/c2_2_1.ldb , watermark: 0 I0917 11:11:23.923168 leveldb_store.go:47 filer store dir: /mnt/seaweedfs/.docker/cloud_edge/48101edc/meta I0917 11:11:23.923198 file_util.go:27 Folder /mnt/seaweedfs/.docker/cloud_edge/48101edc/meta Permission: -rwxr-xr-x I0917 11:11:23.931053 wfs_filer_client.go:31 WithFilerClient 0 vpn.katapy.icu:18888: filer: no entry is found in filer store I0917 11:11:23.942884 wfs_filer_client.go:31 WithFilerClient 1 lh1.vpn.katapy.icu:18888: filer: no entry is found in filer store failed to start background tasks: filer: no entry is found in filer store  My guess is it is related to the new WORM patch which added: https://github.com/seaweedfs/seaweedfs/blob/2b13d2c083a8cf2e1efc616e3301ce590c78cf11/weed/mount/weedfs.go#L144  fn, err := wfs.subscribeFilerConfEvents() if err != nil { return err } go fn()  The **remote** filer has data ( tested connecting with shell ) but the **local** filer store used for cache, that is created new, is empty with version change on a new folder, has no data and I think this causes the mount to crash. **System Setup** Commit 2b13d2c083a8cf2e1efc616e3301ce590c78cf11 **Expected behavior** Weed should run normally as before **Additional context** I am going to locally test removing the return error that is causing in my opinion the mount to not work anymore source-file",no-bug,0.9
3414,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3414,Turn off output from fs.meta.load / Increase performance,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/seaweedfs/seaweedfs/discussions example of a good issue report: https://github.com/seaweedfs/seaweedfs/issues/1005 example of a bad issue report: https://github.com/seaweedfs/seaweedfs/issues/1008 **Describe the bug** When saving meta data from `weed shell` it's very quick and silent. However when restoring meta data via `weed shell` `fs.meta.load` it's very chatty and outputs the list of files. I have 2.3GB of meta data and after 12hrs it's still scrolling away, I've given up restoring meta data and now reloading the cluster as it's quicker to copy the test data in again. I'm wondering if silencing the output or reducing the output to something like a percentage counter would help with speed? **System Setup** OS Ubuntu 22.04 for master, volume and filers. 3 x masters 3 x filers using CockroachDB or leveldb3 (2 different tests and not at the same time, both systems seem to take far too long to restore the meta data) 6 x volume servers filer.toml  [filer.options] recursive_delete = false [leveldb3] enabled = false dir = ""/var/seaweedfs/filer/filerldb3""  Volume servers:  /usr/local/bin/weed -logtostderr volume \ -ip xxxx -ip.bind 0.0.0.0 \ -port 8080 -port.grpc 18080 \ -max 0 -index leveldb \ -dir /var/seaweedfs/volume \ -dataCenter=syd1 -rack=rack1 -mserver=xxxx:9333,xxxx:9333,xxxx:9333  Masters:  /usr/local/bin/weed -logtostderr master \ -ip xxxx -ip.bind 0.0.0.0 \ -port 9333 -port.grpc 19333 \ -mdir=/var/seaweedfs/master -defaultReplication=001 \ -volumeSizeLimitMB=30000 \ -peers=xxxx:9333,xxxx:9333,xxxx:9333   weed version version 30GB 3.18 475185fb723b50e05f0afe39f7f529302bcee11a linux amd64  **Expected behavior** Meta data should reload in a timely fashion, 12hrs+ for around 2TB of data is too slow. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** I don't see any particular component as having a high load, there's plenty of available RAM, CPU and Disk IO. Hence why I'll looking at getting rid of the output first to see what effect that has. Thanks.",source-file,"Turn off output from fs.meta.load / Increase performance Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/seaweedfs/seaweedfs/discussions example of a good issue report: https://github.com/seaweedfs/seaweedfs/issues/1005 example of a bad issue report: https://github.com/seaweedfs/seaweedfs/issues/1008 **Describe the bug** When saving meta data from `weed shell` it's very quick and silent. However when restoring meta data via `weed shell` `fs.meta.load` it's very chatty and outputs the list of files. I have 2.3GB of meta data and after 12hrs it's still scrolling away, I've given up restoring meta data and now reloading the cluster as it's quicker to copy the test data in again. I'm wondering if silencing the output or reducing the output to something like a percentage counter would help with speed? **System Setup** OS Ubuntu 22.04 for master, volume and filers. 3 x masters 3 x filers using CockroachDB or leveldb3 (2 different tests and not at the same time, both systems seem to take far too long to restore the meta data) 6 x volume servers filer.toml  [filer.options] recursive_delete = false [leveldb3] enabled = false dir = ""/var/seaweedfs/filer/filerldb3""  Volume servers:  /usr/local/bin/weed -logtostderr volume \ -ip xxxx -ip.bind 0.0.0.0 \ -port 8080 -port.grpc 18080 \ -max 0 -index leveldb \ -dir /var/seaweedfs/volume \ -dataCenter=syd1 -rack=rack1 -mserver=xxxx:9333,xxxx:9333,xxxx:9333  Masters:  /usr/local/bin/weed -logtostderr master \ -ip xxxx -ip.bind 0.0.0.0 \ -port 9333 -port.grpc 19333 \ -mdir=/var/seaweedfs/master -defaultReplication=001 \ -volumeSizeLimitMB=30000 \ -peers=xxxx:9333,xxxx:9333,xxxx:9333   weed version version 30GB 3.18 475185fb723b50e05f0afe39f7f529302bcee11a linux amd64  **Expected behavior** Meta data should reload in a timely fashion, 12hrs+ for around 2TB of data is too slow. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** I don't see any particular component as having a high load, there's plenty of available RAM, CPU and Disk IO. Hence why I'll looking at getting rid of the output first to see what effect that has. Thanks. source-file",no-bug,0.9
1359,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1359,weed server -port not work,when use: weed help server Usage: weed server -port=8080 -dir=/tmp -volume.max=5 -ip=server_name then input in cmd: weed server -ip=192.168.0.110 -port=8080 -dir=./data display as follow: flag provided but not defined: -port,source-file,weed server -port not work when use: weed help server Usage: weed server -port=8080 -dir=/tmp -volume.max=5 -ip=server_name then input in cmd: weed server -ip=192.168.0.110 -port=8080 -dir=./data display as follow: flag provided but not defined: -port source-file,no-bug,0.9
2017,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2017,"BUG - ""minFreeSpacePercent"" cause many empty volume, until no more free volume can be created","Hi, tested on SW 2.05 & 2.35 when Volume ""minFreeSpacePercent""- is reached, each request for a ""new"" bucket + upload, creates many empty new volume id's until the volume server is reaching the ""max"" volume limit. that will kill/disable the volume server even if you free space, as you now have thousands of empty volumes in the requested bucket. expected: the volume server should fail the request and not create any more empty volumes. volume log:  I0422 05:13:29 1 store.go:125] In dir /data adds volume:797 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/797.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/797.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/797.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/797.idx I0422 05:13:29 1 store.go:129] add volume 797 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:797 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 797 I0422 05:13:29 1 store.go:125] In dir /data adds volume:798 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/798.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/798.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/798.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/798.idx I0422 05:13:29 1 store.go:129] add volume 798 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:798 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 798 I0422 05:13:29 1 store.go:125] In dir /data adds volume:799 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/799.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/799.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/799.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/799.idx I0422 05:13:29 1 store.go:129] add volume 799 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:799 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 799 I0422 05:13:29 1 store.go:125] In dir /data adds volume:800 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/800.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/800.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/800.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/800.idx I0422 05:13:29 1 store.go:129] add volume 800 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:800 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 800 I0422 05:13:29 1 store.go:125] In dir /data adds volume:801 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/801.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/801.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/801.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/801.idx I0422 05:13:29 1 store.go:129] add volume 801 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:801 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 801 I0422 05:13:29 1 store.go:125] In dir /data adds volume:802 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/802.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/802.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/802.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/802.idx I0422 05:13:29 1 store.go:129] add volume 802 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:802 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 802 I0422 05:13:29 1 store.go:125] In dir /data adds volume:803 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/803.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/803.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/803.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/803.idx I0422 05:13:29 1 store.go:129] add volume 803 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:803 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 803 I0422 05:13:29 1 store_replicate.go:47] failed to write to local disk: volume 800 is read only I0422 05:13:29 1 common.go:53] response method:POST URL:/800,02c27339c402 with httpStatus:500 and JSON:{""size"":568,""error"":""failed to write to local disk: volume 800 is read only"",""eTag"":""fc57e9a0b03e3eed5a47655c1c1f9992""} I0422 05:13:29 1 store_replicate.go:47] failed to write to local disk: volume 800 is read only I0422 05:13:29 1 common.go:53] response method:POST URL:/800,02c27339c402 with httpStatus:500 and JSON:{""size"":568,""error"":""failed to write to local disk: volume 800 is read only"",""eTag"":""d052c899610745c278e2fcd7332c1f35""} I0422 05:13:29 1 store_replicate.go:47] failed to write to local disk: volume 800 is read only I0422 05:13:29 1 common.go:53] response method:POST URL:/800,02c27339c402 with httpStatus:500 and JSON:{""size"":568,""error"":""failed to write to local disk: volume 800 is read only"",""eTag"":""68d9c3f35260ce7bbb7cc91f3cf35f20""}  ls -la | | awk '{print $5,$8,$9}' (size,time,filename):  8 08:05 africa3_100.dat 0 08:05 africa3_100.idx 57 08:05 africa3_100.vif* 8 08:05 africa3_101.dat 0 08:05 africa3_101.idx 57 08:05 africa3_101.vif* 8 08:05 africa3_102.dat 0 08:05 africa3_102.idx 57 08:05 africa3_102.vif* 8 08:05 africa3_103.dat 0 08:05 africa3_103.idx 57 08:05 africa3_103.vif* 8 08:05 africa3_104.dat 0 08:05 africa3_104.idx 57 08:05 africa3_104.vif* 8 08:05 africa3_105.dat 0 08:05 africa3_105.idx 57 08:05 africa3_105.vif* 8 08:05 africa3_106.dat 0 08:05 africa3_106.idx 57 08:05 africa3_106.vif* 8 08:05 africa3_107.dat 0 08:05 africa3_107.idx 57 08:05 africa3_107.vif* 8 08:05 africa3_108.dat 0 08:05 africa3_108.idx 57 08:05 africa3_108.vif* 8 08:05 africa3_109.dat 0 08:05 africa3_109.idx 57 08:05 africa3_109.vif* 8 08:05 africa3_110.dat 0 08:05 africa3_110.idx 57 08:05 africa3_110.vif* 8 08:05 africa3_111.dat 0 08:05 africa3_111.idx 57 08:05 africa3_111.vif* 8 08:05 africa3_112.dat 0 08:05 africa3_112.idx 57 08:05 africa3_112.vif* 8 08:05 africa3_113.dat 0 08:05 africa3_113.idx 57 08:05 africa3_113.vif* 8 08:05 africa3_114.dat 0 08:05 africa3_114.idx 57 08:05 africa3_114.vif* 8 08:05 africa3_115.dat 0 08:05 africa3_115.idx 57 08:05 africa3_115.vif* 8 08:05 africa3_116.dat 0 08:05 africa3_116.idx 57 08:05 africa3_116.vif* 8 08:05 africa3_117.dat 0 08:05 africa3_117.idx 57 08:05 africa3_117.vif* 8 08:05 africa3_118.dat 0 08:05 africa3_118.idx 57 08:05 africa3_118.vif* 8 08:05 africa3_119.dat 0 08:05 africa3_119.idx 57 08:05 africa3_119.vif* 8 08:05 africa3_120.dat 0 08:05 africa3_120.idx 57 08:05 africa3_120.vif* 8 08:05 africa3_121.dat 0 08:05 africa3_121.idx 57 08:05 africa3_121.vif* 8 08:05 africa3_122.dat 0 08:05 africa3_122.idx 57 08:05 africa3_122.vif* 8 08:05 africa3_123.dat 0 08:05 africa3_123.idx 57 08:05 africa3_123.vif* 8 08:05 africa3_124.dat 0 08:05 africa3_124.idx 57 08:05 africa3_124.vif* 8 08:06 africa3_146.dat 0 08:06 africa3_146.idx 57 08:06 africa3_146.vif* 8 08:06 africa3_147.dat 0 08:06 africa3_147.idx 57 08:06 africa3_147.vif* 8 08:06 africa3_148.dat 0 08:06 africa3_148.idx 57 08:06 africa3_148.vif* 8 08:06 africa3_149.dat 0 08:06 africa3_149.idx 57 08:06 africa3_149.vif* 8 08:06 africa3_150.dat 0 08:06 africa3_150.idx 57 08:06 africa3_150.vif* 8 08:06 africa3_151.dat 0 08:06 africa3_151.idx 57 08:06 africa3_151.vif* 8 08:06 africa3_152.dat 0 08:06 africa3_152.idx 57 08:06 africa3_152.vif* 8 08:06 africa3_153.dat 0 08:06 africa3_153.idx 57 08:06 africa3_153.vif* 8 08:06 africa3_154.dat 0 08:06 africa3_154.idx 57 08:06 africa3_154.vif* 8 08:06 africa3_155.dat 0 08:06 africa3_155.idx 57 08:06 africa3_155.vif* 8 08:06 africa3_156.dat 0 08:06 africa3_156.idx 57 08:06 africa3_156.vif* 8 08:06 africa3_157.dat 0 08:06 africa3_157.idx 57 08:06 africa3_157.vif* 8 08:06 africa3_158.dat 0 08:06 africa3_158.idx 57 08:06 africa3_158.vif* 8 08:06 africa3_159.dat 0 08:06 africa3_159.idx 57 08:06 africa3_159.vif* 8 08:06 africa3_167.dat 0 08:06 africa3_167.idx 57 08:06 africa3_167.vif* 8 08:06 africa3_168.dat 0 08:06 africa3_168.idx 57 08:06 africa3_168.vif* 8 08:06 africa3_169.dat 0 08:06 africa3_169.idx 57 08:06 africa3_169.vif* 8 08:06 africa3_170.dat 0 08:06 africa3_170.idx 57 08:06 africa3_170.vif* 8 08:06 africa3_171.dat 0 08:06 africa3_171.idx 57 08:06 africa3_171.vif* 8 08:06 africa3_172.dat 0 08:06 africa3_172.idx 57 08:06 africa3_172.vif* 8 08:06 africa3_173.dat 0 08:06 africa3_173.idx 57 08:06 africa3_173.vif* 8 08:06 africa3_181.dat 0 08:06 africa3_181.idx 57 08:06 africa3_181.vif* 8 08:06 africa3_182.dat 0 08:06 africa3_182.idx 57 08:06 africa3_182.vif* 8 08:06 africa3_183.dat 0 08:06 africa3_183.idx 57 08:06 africa3_183.vif* 8 08:06 africa3_184.dat 0 08:06 africa3_184.idx 57 08:06 africa3_184.vif* 8 08:06 africa3_185.dat 0 08:06 africa3_185.idx 57 08:06 africa3_185.vif* 8 08:06 africa3_186.dat 0 08:06 africa3_186.idx 57 08:06 africa3_186.vif* 8 08:06 africa3_187.dat 0 08:06 africa3_187.idx 57 08:06 africa3_187.vif* 8 08:06 africa3_195.dat 0 08:06 africa3_195.idx 57 08:06 africa3_195.vif* 8 08:06 africa3_196.dat 0 08:06 africa3_196.idx 57 08:06 africa3_196.vif* 8 08:06 africa3_197.dat 0 08:06 africa3_197.idx 57 08:06 africa3_197.vif* 8 08:06 africa3_198.dat 0 08:06 africa3_198.idx 57 08:06 africa3_198.vif* 8 08:06 africa3_199.dat 0 08:06 africa3_199.idx 57 08:06 africa3_199.vif* 8 08:06 africa3_200.dat 0 08:06 africa3_200.idx 57 08:06 africa3_200.vif* 8 08:06 africa3_201.dat 0 08:06 africa3_201.idx 57 08:06 africa3_201.vif* 8 08:05 africa3_97.dat 0 08:05 africa3_97.idx 57 08:05 africa3_97.vif* 8 08:05 africa3_98.dat 0 08:05 africa3_98.idx 57 08:05 africa3_98.vif* 8 08:05 africa3_99.dat 0 08:05 africa3_99.idx 57 08:05 africa3_99.vif*  ""internal"" volumes for sw notification/queues are going ballistic also:  57 08:40 3059.vif* 8 08:07 305.dat 0 08:07 305.idx 57 08:07 305.vif* 8 08:40 3060.dat 0 08:40 3060.idx 57 08:40 3060.vif* 8 08:40 3061.dat 0 08:40 3061.idx 57 08:40 3061.vif* 8 08:40 3062.dat 0 08:40 3062.idx 57 08:40 3062.vif* 8 08:40 3063.dat 0 08:40 3063.idx 57 08:40 3063.vif* 8 08:40 3064.dat 0 08:40 3064.idx 57 08:40 3064.vif* 8 08:40 3065.dat 0 08:40 3065.idx 57 08:40 3065.vif* 8 08:40 3066.dat 0 08:40 3066.idx 57 08:40 3066.vif* 8 08:40 3067.dat 0 08:40 3067.idx 57 08:40 3067.vif* 8 08:40 3068.dat 0 08:40 3068.idx 57 08:40 3068.vif* 8 08:40 3069.dat 0 08:40 3069.idx 57 08:40 3069.vif* 8 08:07 306.dat 0 08:07 306.idx 57 08:07 306.vif* 8 08:40 3070.dat 0 08:40 3070.idx 57 08:40 3070.vif* 8 08:40 3071.dat 0 08:40 3071.idx 57 08:40 3071.vif* 8 08:40 3072.dat 0 08:40 3072.idx 57 08:40 3072.vif* 8 08:40 3073.dat 0 08:40 3073.idx 57 08:40 3073.vif* 8 08:40 3074.dat 0 08:40 3074.idx 57 08:40 3074.vif* 8 08:40 3075.dat 0 08:40 3075.idx 57 08:40 3075.vif* 8 08:40 3076.dat 0 08:40 3076.idx 57 08:40 3076.vif* 8 08:40 3077.dat 0 08:40 3077.idx 57 08:40 3077.vif* 8 08:40 3078.dat 0 08:40 3078.idx 57 08:40 3078.vif* 8 08:40 3079.dat 0 08:40 3079.idx 57 08:40 3079.vif* 8 08:07 307.dat 0 08:07 307.idx 57 08:07 307.vif* 8 08:40 3080.dat 0 08:40 3080.idx 57 08:40 3080.vif* 8 08:40 3081.dat 0 08:40 3081.idx 57 08:40 3081.vif* 8 08:40 3082.dat 0 08:40 3082.idx 57 08:40 3082.vif* 8 08:40 3083.dat 0 08:40 3083.idx 57 08:40 3083.vif* 8 08:40 3084.dat 0 08:40 3084.idx 57 08:40 3084.vif* 8 08:40 3085.dat 0 08:40 3085.idx 57 08:40 3085.vif* 8 08:40 3086.dat 0 08:40 3086.idx 57 08:40 3086.vif* 8 08:40 3087.dat 0 08:40 3087.idx 57 08:40 3087.vif* 8 08:40 3088.dat 0 08:40 3088.idx 57 08:40 3088.vif* 8 08:40 3089.dat 0 08:40 3089.idx 57 08:40 3089.vif* 8 08:07 308.dat 0 08:07 308.idx 57 08:07 308.vif* 8 08:40 3090.dat 0 08:40 3090.idx 57 08:40 3090.vif* 8 08:40 3091.dat 0 08:40 3091.idx 57 08:40 3091.vif* 8 08:40 3092.dat 0 08:40 3092.idx 57 08:40 3092.vif* 8 08:40 3093.dat 0 08:40 3093.idx 57 08:40 3093.vif* 8 08:40 3094.dat 0 08:40 3094.idx 57 08:40 3094.vif* 8 08:40 3095.dat 0 08:40 3095.idx 57 08:40 3095.vif* 8 08:40 3096.dat 0 08:40 3096.idx 57 08:40 3096.vif* 8 08:40 3097.dat 0 08:40 3097.idx 57 08:40 3097.vif* 8 08:40 3098.dat 0 08:40 3098.idx 57 08:40 3098.vif* 8 08:40 3099.dat 0 08:40 3099.idx 57 08:40 3099.vif* 8 08:07 309.dat 0 08:07 309.idx 57 08:07 309.vif* 8 08:40 3100.dat 0 08:40 3100.idx 57 08:40 3100.vif* 8 08:40 3101.dat 0 08:40 3101.idx 57 08:40 3101.vif* 8 08:40 3102.dat 0 08:40 3102.idx 57 08:40 3102.vif* 8 08:40 3103.dat 0 08:40 3103.idx 57 08:40 3103.vif* 8 08:40 3104.dat 0 08:40 3104.idx 57 08:40 3104.vif* 8 08:40 3105.dat 0 08:40 3105.idx 57 08:40 3105.vif* 8 08:40 3106.dat 0 08:40 3106.idx 57 08:40 3106.vif* 8 08:40 3107.dat 0 08:40 3107.idx 57 08:40 3107.vif* 8 08:40 3108.dat 0 08:40 3108.idx 57 08:40 3108.vif* 8 08:40 3109.dat 0 08:40 3109.idx 57 08:40 3109.vif* 8 08:07 310.dat 0 08:07 310.idx 57 08:07 310.vif* 8 08:40 3110.dat 0 08:40 3110.idx 57 08:40 3110.vif* 8 08:40 3111.dat 0 08:40 3111.idx 57 08:40 3111.vif* 8 08:40 3112.dat 0 08:40 3112.idx 57 08:40 3112.vif* 8 08:40 3113.dat 0 08:40 3113.idx 57 08:40 3113.vif* 8 08:41 3114.dat 0 08:41 3114.idx 57 08:41 3114.vif* 8 08:41 3115.dat 0 08:41 3115.idx 57 08:41 3115.vif* 8 08:41 3116.dat 0 08:41 3116.idx 57 08:41 3116.vif* 8 08:41 3117.dat 0 08:41 3117.idx 57 08:41 3117.vif* 8 08:41 3118.dat 0 08:41 3118.idx 57 08:41 3118.vif* 8 08:41 3119.dat 0 08:41 3119.idx 57 08:41 3119.vif* 8 08:07 311.dat 0 08:07 311.idx 57 08:07 311.vif* 8 08:41 3120.dat 0 08:41 3120.idx 57 08:41 3120.vif* 8 08:41 3121.dat 0 08:41 3121.idx 57 08:41 3121.vif* 8 08:41 3122.dat 0 08:41 3122.idx 57 08:41 3122.vif* 8 08:41 3123.dat 0 08:41 3123.idx 57 08:41 3123.vif* 8 08:41 3124.dat 0 08:41 3124.idx 57 08:41 3124.vif* 8 08:41 3125.dat 0 08:41 3125.idx 57 08:41 3125.vif* 8 08:41 3126.dat 0 08:41 3126.idx 57 08:41 3126.vif* 8 08:41 3127.dat 0 08:41 3127.idx 57 08:41 3127.vif* 8 08:41 3128.dat 0 08:41 3128.idx 57 08:41 3128.vif* 8 08:41 3129.dat 0 08:41 3129.idx 57 08:41 3129.vif* 8 08:07 312.dat 0 08:07 312.idx 57 08:07 312.vif* 8 08:41 3130.dat 0 08:41 3130.idx 57 08:41 3130.vif* 8 08:41 3131.dat 0 08:41 3131.idx 57 08:41 3131.vif* 8 08:41 3132.dat 0 08:41 3132.idx 57 08:41 3132.vif* 8 08:41 3133.dat 0 08:41 3133.idx 57 08:41 3133.vif* 8 08:41 3134.dat 0 08:41 3134.idx 57 08:41 3134.vif* 8 08:07 313.dat 0 08:07 313.idx 57 08:07 313.vif* 8 08:07 314.dat 0 08:07 314.idx 57 08:07 314.vif* 8 08:07 315.dat 0 08:07 315.idx 57 08:07 315.vif* 8 08:07 316.dat 0 08:07 316.idx 57 08:07 316.vif* 8 08:07 317.dat 0 08:07 317.idx 57 08:07 317.vif* 8 08:07 318.dat 0 08:07 318.idx 57 08:07 318.vif* 8 08:07 319.dat 0 08:07 319.idx 57 08:07 319.vif* 8 08:07 320.dat 0 08:07 320.idx 57 08:07 320.vif* 8 08:07 321.dat 0 08:07 321.idx 57 08:07 321.vif* 8 08:07 322.dat 0 08:07 322.idx 57 08:07 322.vif* 8 08:07 323.dat 0 08:07 323.idx 57 08:07 323.vif* 8 08:07 324.dat 0 08:07 324.idx 57 08:07 324.vif* 8 08:07 325.dat 0 08:07 325.idx 57 08:07 325.vif* 8 08:07 326.dat 0 08:07 326.idx 57 08:07 326.vif* 8 08:07 327.dat 0 08:07 327.idx 57 08:07 327.vif* 8 08:07 328.dat 0 08:07 328.idx 57 08:07 328.vif* 8 08:07 329.dat 0 08:07 329.idx 57 08:07 329.vif* 8 08:07 330.dat 0 08:07 330.idx 57 08:07 330.vif* 8 08:07 331.dat 0 08:07 331.idx 57 08:07 331.vif* 8 08:07 332.dat 0 08:07 332.idx 57 08:07 332.vif* 8 08:07 333.dat 0 08:07 333.idx 57 08:07 333.vif* 8 08:07 334.dat 0 08:07 334.idx 57 08:07 334.vif* 8 08:07 335.dat 0 08:07 335.idx 57 08:07 335.vif* 8 08:07 336.dat 0 08:07 336.idx 57 08:07 336.vif* 8 08:07 337.dat 0 08:07 337.idx 57 08:07 337.vif* 8 08:07 338.dat 0 08:07 338.idx 57 08:07 338.vif* 8 08:07 339.dat 0 08:07 339.idx 57 08:07 339.vif* 8 08:07 340.dat 0 08:07 340.idx 57 08:07 340.vif* 8 08:07 341.dat 0 08:07 341.idx 57 08:07 341.vif* 8 08:08 342.dat 0 08:08 342.idx 57 08:08 342.vif* 8 08:08 343.dat 0 08:08 343.idx 57 08:08 343.vif* 8 08:08 344.dat 0 08:08 344.idx 57 08:08 344.vif* 8 08:08 345.dat 0 08:08 345.idx 57 08:08 345.vif* 8 08:08 346.dat 0 08:08 346.idx 57 08:08 346.vif* 8 08:08 347.dat 0 08:08 347.idx 57 08:08 347.vif* 8 08:08 348.dat 0 08:08 348.idx 57 08:08 348.vif* 8 08:08 349.dat 0 08:08 349.idx 57 08:08 349.vif* 8 08:08 350.dat 0 08:08 350.idx 57 08:08 350.vif* 8 08:08 351.dat 0 08:08 351.idx 57 08:08 351.vif* 8 08:08 352.dat 0 08:08 352.idx 57 08:08 352.vif* 8 08:08 353.dat 0 08:08 353.idx 57 08:08 353.vif* 8 08:08 354.dat 0 08:08 354.idx 57 08:08 354.vif* 8 08:08 355.dat 0 08:08 355.idx 57 08:08 355.vif* 8 08:08 356.dat 0 08:08 356.idx 57 08:08 356.vif* 8 08:08 357.dat 0 08:08 357.idx 57 08:08 357.vif* 8 08:08 358.dat 0 08:08 358.idx 57 08:08 358.vif* 8 08:08 359.dat 0 08:08 359.idx 57 08:08 359.vif* 8 08:08 360.dat 0 08:08 360.idx 57 08:08 360.vif* 8 08:08 361.dat 0 08:08 361.idx 57 08:08 361.vif* 8 08:08 362.dat 0 08:08 362.idx 57 08:08 362.vif* 8 08:08 363.dat 0 08:08 363.idx 57 08:08 363.vif* 8 08:08 364.dat 0 08:08 364.idx 57 08:08 364.vif* 8 08:08 365.dat 0 08:08 365.idx 57 08:08 365.vif* 8 08:08 366.dat 0 08:08 366.idx 57 08:08 366.vif* 8 08:08 367.dat 0 08:08 367.idx 57 08:08 367.vif* 8 08:08 368.dat 0 08:08 368.idx 57 08:08 368.vif* 8 08:08 369.dat 0 08:08 369.idx 57 08:08 369.vif* 8 08:08 370.dat 0 08:08 370.idx 57 08:08 370.vif* 8 08:08 371.dat 0 08:08 371.idx 57 08:08 371.vif* 8 08:08 372.dat 0 08:08 372.idx 57 08:08 372.vif* 8 08:08 373.dat 0 08:08 373.idx 57 08:08 373.vif* 8 08:08 374.dat 0 08:08 374.idx 57 08:08 374.vif* 8 08:08 375.dat 0 08:08 375.idx 57 08:08 375.vif* 8 08:08 376.dat 0 08:08 376.idx 57 08:08 376.vif* 8 08:08 377.dat 0 08:08 377.idx 57 08:08 377.vif* 8 08:08 378.dat 0 08:08 378.idx 57 08:08 378.vif* 8 08:08 379.dat 0 08:08 379.idx 57 08:08 379.vif* 8 08:08 380.dat 0 08:08 380.idx 57 08:08 380.vif* 8 08:08 381.dat 0 08:08 381.idx 57 08:08 381.vif* 8 08:08 382.dat 0 08:08 382.idx 57 08:08 382.vif* 8 08:08 383.dat 0 08:08 383.idx 57 08:08 383.vif* 8 08:08 384.dat 0 08:08 384.idx 57 08:08 384.vif* 8 08:08 385.dat 0 08:08 385.idx 57 08:08 385.vif* 8 08:08 386.dat 0 08:08 386.idx 57 08:08 386.vif* 8 08:08 387.dat 0 08:08 387.idx 57 08:08 387.vif* 8 08:08 388.dat 0 08:08 388.idx 57 08:08 388.vif* 8 08:08 389.dat 0 08:08 389.idx 57 08:08 389.vif* 8 08:08 390.dat 0 08:08 390.idx 57 08:08 390.vif* 8 08:08 391.dat 0 08:08 391.idx 57 08:08 391.vif* 8 08:08 392.dat 0 08:08 392.idx 57 08:08 392.vif* 8 08:08 393.dat 0 08:08 393.idx 57 08:08 393.vif* 8 08:08 394.dat 0 08:08 394.idx 57 08:08 394.vif* 8 08:08 395.dat 0 08:08 395.idx 57 08:08 395.vif* 8 08:08 396.dat 0 08:08 396.idx 57 08:08 396.vif* 8 08:08 397.dat 0 08:08 397.idx 57 08:08 397.vif* 8 08:08 398.dat 0 08:08 398.idx 57 08:08 398.vif* 8 08:08 399.dat 0 08:08 399.idx 57 08:08 399.vif* 8 08:08 400.dat 0 08:08 400.idx 57 08:08 400.vif* 8 08:08 401.dat 0 08:08 401.idx 57 08:08 401.vif* 8 08:08 402.dat 0 08:08 402.idx 57 08:08 402.vif* 8 08:08 403.dat 0 08:08 403.idx 57 08:08 403.vif* 8 08:08 404.dat 0 08:08 404.idx 57 08:08 404.vif* 8 08:08 405.dat 0 08:08 405.idx 57 08:08 405.vif* 8 08:08 406.dat 0 08:08 406.idx 57 08:08 406.vif* 8 08:08 407.dat 0 08:08 407.idx 57 08:08 407.vif* 8 08:08 408.dat 0 08:08 408.idx 57 08:08 408.vif* 8 08:08 409.dat 0 08:08 409.idx 57 08:08 409.vif* 8 08:08 410.dat 0 08:08 410.idx 57 08:08 410.vif* 8 08:08 411.dat 0 08:08 411.idx 57 08:08 411.vif* 8 08:08 412.dat 0 08:08 412.idx 57 08:08 412.vif* 8 08:08 413.dat 0 08:08 413.idx 57 08:08 413.vif* 8 08:08 414.dat  Thanks.",source-file,"BUG - ""minFreeSpacePercent"" cause many empty volume, until no more free volume can be created Hi, tested on SW 2.05 & 2.35 when Volume ""minFreeSpacePercent""- is reached, each request for a ""new"" bucket + upload, creates many empty new volume id's until the volume server is reaching the ""max"" volume limit. that will kill/disable the volume server even if you free space, as you now have thousands of empty volumes in the requested bucket. expected: the volume server should fail the request and not create any more empty volumes. volume log:  I0422 05:13:29 1 store.go:125] In dir /data adds volume:797 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/797.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/797.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/797.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/797.idx I0422 05:13:29 1 store.go:129] add volume 797 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:797 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 797 I0422 05:13:29 1 store.go:125] In dir /data adds volume:798 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/798.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/798.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/798.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/798.idx I0422 05:13:29 1 store.go:129] add volume 798 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:798 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 798 I0422 05:13:29 1 store.go:125] In dir /data adds volume:799 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/799.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/799.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/799.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/799.idx I0422 05:13:29 1 store.go:129] add volume 799 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:799 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 799 I0422 05:13:29 1 store.go:125] In dir /data adds volume:800 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/800.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/800.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/800.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/800.idx I0422 05:13:29 1 store.go:129] add volume 800 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:800 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 800 I0422 05:13:29 1 store.go:125] In dir /data adds volume:801 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/801.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/801.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/801.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/801.idx I0422 05:13:29 1 store.go:129] add volume 801 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:801 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 801 I0422 05:13:29 1 store.go:125] In dir /data adds volume:802 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/802.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/802.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/802.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/802.idx I0422 05:13:29 1 store.go:129] add volume 802 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:802 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 802 I0422 05:13:29 1 store.go:125] In dir /data adds volume:803 collection: replicaPlacement:000 ttl: I0422 05:13:29 1 volume_info.go:22] maybeLoadVolumeInfo checks /data/803.vif I0422 05:13:29 1 volume_loading.go:116] open to write file /data/803.idx I0422 05:13:29 1 volume_loading.go:133] loading index /data/803.idx to memory I0422 05:13:29 1 needle_map_memory.go:53] max file key: 0 for file: /data/803.idx I0422 05:13:29 1 store.go:129] add volume 803 I0422 05:13:29 1 volume_grpc_admin.go:50] assign volume volume_id:803 replication:""000"" I0422 05:13:29 1 volume_grpc_client_to_master.go:164] volume server seaweedfs-volume-localnode.tls.ai:8080 adds volume 803 I0422 05:13:29 1 store_replicate.go:47] failed to write to local disk: volume 800 is read only I0422 05:13:29 1 common.go:53] response method:POST URL:/800,02c27339c402 with httpStatus:500 and JSON:{""size"":568,""error"":""failed to write to local disk: volume 800 is read only"",""eTag"":""fc57e9a0b03e3eed5a47655c1c1f9992""} I0422 05:13:29 1 store_replicate.go:47] failed to write to local disk: volume 800 is read only I0422 05:13:29 1 common.go:53] response method:POST URL:/800,02c27339c402 with httpStatus:500 and JSON:{""size"":568,""error"":""failed to write to local disk: volume 800 is read only"",""eTag"":""d052c899610745c278e2fcd7332c1f35""} I0422 05:13:29 1 store_replicate.go:47] failed to write to local disk: volume 800 is read only I0422 05:13:29 1 common.go:53] response method:POST URL:/800,02c27339c402 with httpStatus:500 and JSON:{""size"":568,""error"":""failed to write to local disk: volume 800 is read only"",""eTag"":""68d9c3f35260ce7bbb7cc91f3cf35f20""}  ls -la | | awk '{print $5,$8,$9}' (size,time,filename):  8 08:05 africa3_100.dat 0 08:05 africa3_100.idx 57 08:05 africa3_100.vif* 8 08:05 africa3_101.dat 0 08:05 africa3_101.idx 57 08:05 africa3_101.vif* 8 08:05 africa3_102.dat 0 08:05 africa3_102.idx 57 08:05 africa3_102.vif* 8 08:05 africa3_103.dat 0 08:05 africa3_103.idx 57 08:05 africa3_103.vif* 8 08:05 africa3_104.dat 0 08:05 africa3_104.idx 57 08:05 africa3_104.vif* 8 08:05 africa3_105.dat 0 08:05 africa3_105.idx 57 08:05 africa3_105.vif* 8 08:05 africa3_106.dat 0 08:05 africa3_106.idx 57 08:05 africa3_106.vif* 8 08:05 africa3_107.dat 0 08:05 africa3_107.idx 57 08:05 africa3_107.vif* 8 08:05 africa3_108.dat 0 08:05 africa3_108.idx 57 08:05 africa3_108.vif* 8 08:05 africa3_109.dat 0 08:05 africa3_109.idx 57 08:05 africa3_109.vif* 8 08:05 africa3_110.dat 0 08:05 africa3_110.idx 57 08:05 africa3_110.vif* 8 08:05 africa3_111.dat 0 08:05 africa3_111.idx 57 08:05 africa3_111.vif* 8 08:05 africa3_112.dat 0 08:05 africa3_112.idx 57 08:05 africa3_112.vif* 8 08:05 africa3_113.dat 0 08:05 africa3_113.idx 57 08:05 africa3_113.vif* 8 08:05 africa3_114.dat 0 08:05 africa3_114.idx 57 08:05 africa3_114.vif* 8 08:05 africa3_115.dat 0 08:05 africa3_115.idx 57 08:05 africa3_115.vif* 8 08:05 africa3_116.dat 0 08:05 africa3_116.idx 57 08:05 africa3_116.vif* 8 08:05 africa3_117.dat 0 08:05 africa3_117.idx 57 08:05 africa3_117.vif* 8 08:05 africa3_118.dat 0 08:05 africa3_118.idx 57 08:05 africa3_118.vif* 8 08:05 africa3_119.dat 0 08:05 africa3_119.idx 57 08:05 africa3_119.vif* 8 08:05 africa3_120.dat 0 08:05 africa3_120.idx 57 08:05 africa3_120.vif* 8 08:05 africa3_121.dat 0 08:05 africa3_121.idx 57 08:05 africa3_121.vif* 8 08:05 africa3_122.dat 0 08:05 africa3_122.idx 57 08:05 africa3_122.vif* 8 08:05 africa3_123.dat 0 08:05 africa3_123.idx 57 08:05 africa3_123.vif* 8 08:05 africa3_124.dat 0 08:05 africa3_124.idx 57 08:05 africa3_124.vif* 8 08:06 africa3_146.dat 0 08:06 africa3_146.idx 57 08:06 africa3_146.vif* 8 08:06 africa3_147.dat 0 08:06 africa3_147.idx 57 08:06 africa3_147.vif* 8 08:06 africa3_148.dat 0 08:06 africa3_148.idx 57 08:06 africa3_148.vif* 8 08:06 africa3_149.dat 0 08:06 africa3_149.idx 57 08:06 africa3_149.vif* 8 08:06 africa3_150.dat 0 08:06 africa3_150.idx 57 08:06 africa3_150.vif* 8 08:06 africa3_151.dat 0 08:06 africa3_151.idx 57 08:06 africa3_151.vif* 8 08:06 africa3_152.dat 0 08:06 africa3_152.idx 57 08:06 africa3_152.vif* 8 08:06 africa3_153.dat 0 08:06 africa3_153.idx 57 08:06 africa3_153.vif* 8 08:06 africa3_154.dat 0 08:06 africa3_154.idx 57 08:06 africa3_154.vif* 8 08:06 africa3_155.dat 0 08:06 africa3_155.idx 57 08:06 africa3_155.vif* 8 08:06 africa3_156.dat 0 08:06 africa3_156.idx 57 08:06 africa3_156.vif* 8 08:06 africa3_157.dat 0 08:06 africa3_157.idx 57 08:06 africa3_157.vif* 8 08:06 africa3_158.dat 0 08:06 africa3_158.idx 57 08:06 africa3_158.vif* 8 08:06 africa3_159.dat 0 08:06 africa3_159.idx 57 08:06 africa3_159.vif* 8 08:06 africa3_167.dat 0 08:06 africa3_167.idx 57 08:06 africa3_167.vif* 8 08:06 africa3_168.dat 0 08:06 africa3_168.idx 57 08:06 africa3_168.vif* 8 08:06 africa3_169.dat 0 08:06 africa3_169.idx 57 08:06 africa3_169.vif* 8 08:06 africa3_170.dat 0 08:06 africa3_170.idx 57 08:06 africa3_170.vif* 8 08:06 africa3_171.dat 0 08:06 africa3_171.idx 57 08:06 africa3_171.vif* 8 08:06 africa3_172.dat 0 08:06 africa3_172.idx 57 08:06 africa3_172.vif* 8 08:06 africa3_173.dat 0 08:06 africa3_173.idx 57 08:06 africa3_173.vif* 8 08:06 africa3_181.dat 0 08:06 africa3_181.idx 57 08:06 africa3_181.vif* 8 08:06 africa3_182.dat 0 08:06 africa3_182.idx 57 08:06 africa3_182.vif* 8 08:06 africa3_183.dat 0 08:06 africa3_183.idx 57 08:06 africa3_183.vif* 8 08:06 africa3_184.dat 0 08:06 africa3_184.idx 57 08:06 africa3_184.vif* 8 08:06 africa3_185.dat 0 08:06 africa3_185.idx 57 08:06 africa3_185.vif* 8 08:06 africa3_186.dat 0 08:06 africa3_186.idx 57 08:06 africa3_186.vif* 8 08:06 africa3_187.dat 0 08:06 africa3_187.idx 57 08:06 africa3_187.vif* 8 08:06 africa3_195.dat 0 08:06 africa3_195.idx 57 08:06 africa3_195.vif* 8 08:06 africa3_196.dat 0 08:06 africa3_196.idx 57 08:06 africa3_196.vif* 8 08:06 africa3_197.dat 0 08:06 africa3_197.idx 57 08:06 africa3_197.vif* 8 08:06 africa3_198.dat 0 08:06 africa3_198.idx 57 08:06 africa3_198.vif* 8 08:06 africa3_199.dat 0 08:06 africa3_199.idx 57 08:06 africa3_199.vif* 8 08:06 africa3_200.dat 0 08:06 africa3_200.idx 57 08:06 africa3_200.vif* 8 08:06 africa3_201.dat 0 08:06 africa3_201.idx 57 08:06 africa3_201.vif* 8 08:05 africa3_97.dat 0 08:05 africa3_97.idx 57 08:05 africa3_97.vif* 8 08:05 africa3_98.dat 0 08:05 africa3_98.idx 57 08:05 africa3_98.vif* 8 08:05 africa3_99.dat 0 08:05 africa3_99.idx 57 08:05 africa3_99.vif*  ""internal"" volumes for sw notification/queues are going ballistic also:  57 08:40 3059.vif* 8 08:07 305.dat 0 08:07 305.idx 57 08:07 305.vif* 8 08:40 3060.dat 0 08:40 3060.idx 57 08:40 3060.vif* 8 08:40 3061.dat 0 08:40 3061.idx 57 08:40 3061.vif* 8 08:40 3062.dat 0 08:40 3062.idx 57 08:40 3062.vif* 8 08:40 3063.dat 0 08:40 3063.idx 57 08:40 3063.vif* 8 08:40 3064.dat 0 08:40 3064.idx 57 08:40 3064.vif* 8 08:40 3065.dat 0 08:40 3065.idx 57 08:40 3065.vif* 8 08:40 3066.dat 0 08:40 3066.idx 57 08:40 3066.vif* 8 08:40 3067.dat 0 08:40 3067.idx 57 08:40 3067.vif* 8 08:40 3068.dat 0 08:40 3068.idx 57 08:40 3068.vif* 8 08:40 3069.dat 0 08:40 3069.idx 57 08:40 3069.vif* 8 08:07 306.dat 0 08:07 306.idx 57 08:07 306.vif* 8 08:40 3070.dat 0 08:40 3070.idx 57 08:40 3070.vif* 8 08:40 3071.dat 0 08:40 3071.idx 57 08:40 3071.vif* 8 08:40 3072.dat 0 08:40 3072.idx 57 08:40 3072.vif* 8 08:40 3073.dat 0 08:40 3073.idx 57 08:40 3073.vif* 8 08:40 3074.dat 0 08:40 3074.idx 57 08:40 3074.vif* 8 08:40 3075.dat 0 08:40 3075.idx 57 08:40 3075.vif* 8 08:40 3076.dat 0 08:40 3076.idx 57 08:40 3076.vif* 8 08:40 3077.dat 0 08:40 3077.idx 57 08:40 3077.vif* 8 08:40 3078.dat 0 08:40 3078.idx 57 08:40 3078.vif* 8 08:40 3079.dat 0 08:40 3079.idx 57 08:40 3079.vif* 8 08:07 307.dat 0 08:07 307.idx 57 08:07 307.vif* 8 08:40 3080.dat 0 08:40 3080.idx 57 08:40 3080.vif* 8 08:40 3081.dat 0 08:40 3081.idx 57 08:40 3081.vif* 8 08:40 3082.dat 0 08:40 3082.idx 57 08:40 3082.vif* 8 08:40 3083.dat 0 08:40 3083.idx 57 08:40 3083.vif* 8 08:40 3084.dat 0 08:40 3084.idx 57 08:40 3084.vif* 8 08:40 3085.dat 0 08:40 3085.idx 57 08:40 3085.vif* 8 08:40 3086.dat 0 08:40 3086.idx 57 08:40 3086.vif* 8 08:40 3087.dat 0 08:40 3087.idx 57 08:40 3087.vif* 8 08:40 3088.dat 0 08:40 3088.idx 57 08:40 3088.vif* 8 08:40 3089.dat 0 08:40 3089.idx 57 08:40 3089.vif* 8 08:07 308.dat 0 08:07 308.idx 57 08:07 308.vif* 8 08:40 3090.dat 0 08:40 3090.idx 57 08:40 3090.vif* 8 08:40 3091.dat 0 08:40 3091.idx 57 08:40 3091.vif* 8 08:40 3092.dat 0 08:40 3092.idx 57 08:40 3092.vif* 8 08:40 3093.dat 0 08:40 3093.idx 57 08:40 3093.vif* 8 08:40 3094.dat 0 08:40 3094.idx 57 08:40 3094.vif* 8 08:40 3095.dat 0 08:40 3095.idx 57 08:40 3095.vif* 8 08:40 3096.dat 0 08:40 3096.idx 57 08:40 3096.vif* 8 08:40 3097.dat 0 08:40 3097.idx 57 08:40 3097.vif* 8 08:40 3098.dat 0 08:40 3098.idx 57 08:40 3098.vif* 8 08:40 3099.dat 0 08:40 3099.idx 57 08:40 3099.vif* 8 08:07 309.dat 0 08:07 309.idx 57 08:07 309.vif* 8 08:40 3100.dat 0 08:40 3100.idx 57 08:40 3100.vif* 8 08:40 3101.dat 0 08:40 3101.idx 57 08:40 3101.vif* 8 08:40 3102.dat 0 08:40 3102.idx 57 08:40 3102.vif* 8 08:40 3103.dat 0 08:40 3103.idx 57 08:40 3103.vif* 8 08:40 3104.dat 0 08:40 3104.idx 57 08:40 3104.vif* 8 08:40 3105.dat 0 08:40 3105.idx 57 08:40 3105.vif* 8 08:40 3106.dat 0 08:40 3106.idx 57 08:40 3106.vif* 8 08:40 3107.dat 0 08:40 3107.idx 57 08:40 3107.vif* 8 08:40 3108.dat 0 08:40 3108.idx 57 08:40 3108.vif* 8 08:40 3109.dat 0 08:40 3109.idx 57 08:40 3109.vif* 8 08:07 310.dat 0 08:07 310.idx 57 08:07 310.vif* 8 08:40 3110.dat 0 08:40 3110.idx 57 08:40 3110.vif* 8 08:40 3111.dat 0 08:40 3111.idx 57 08:40 3111.vif* 8 08:40 3112.dat 0 08:40 3112.idx 57 08:40 3112.vif* 8 08:40 3113.dat 0 08:40 3113.idx 57 08:40 3113.vif* 8 08:41 3114.dat 0 08:41 3114.idx 57 08:41 3114.vif* 8 08:41 3115.dat 0 08:41 3115.idx 57 08:41 3115.vif* 8 08:41 3116.dat 0 08:41 3116.idx 57 08:41 3116.vif* 8 08:41 3117.dat 0 08:41 3117.idx 57 08:41 3117.vif* 8 08:41 3118.dat 0 08:41 3118.idx 57 08:41 3118.vif* 8 08:41 3119.dat 0 08:41 3119.idx 57 08:41 3119.vif* 8 08:07 311.dat 0 08:07 311.idx 57 08:07 311.vif* 8 08:41 3120.dat 0 08:41 3120.idx 57 08:41 3120.vif* 8 08:41 3121.dat 0 08:41 3121.idx 57 08:41 3121.vif* 8 08:41 3122.dat 0 08:41 3122.idx 57 08:41 3122.vif* 8 08:41 3123.dat 0 08:41 3123.idx 57 08:41 3123.vif* 8 08:41 3124.dat 0 08:41 3124.idx 57 08:41 3124.vif* 8 08:41 3125.dat 0 08:41 3125.idx 57 08:41 3125.vif* 8 08:41 3126.dat 0 08:41 3126.idx 57 08:41 3126.vif* 8 08:41 3127.dat 0 08:41 3127.idx 57 08:41 3127.vif* 8 08:41 3128.dat 0 08:41 3128.idx 57 08:41 3128.vif* 8 08:41 3129.dat 0 08:41 3129.idx 57 08:41 3129.vif* 8 08:07 312.dat 0 08:07 312.idx 57 08:07 312.vif* 8 08:41 3130.dat 0 08:41 3130.idx 57 08:41 3130.vif* 8 08:41 3131.dat 0 08:41 3131.idx 57 08:41 3131.vif* 8 08:41 3132.dat 0 08:41 3132.idx 57 08:41 3132.vif* 8 08:41 3133.dat 0 08:41 3133.idx 57 08:41 3133.vif* 8 08:41 3134.dat 0 08:41 3134.idx 57 08:41 3134.vif* 8 08:07 313.dat 0 08:07 313.idx 57 08:07 313.vif* 8 08:07 314.dat 0 08:07 314.idx 57 08:07 314.vif* 8 08:07 315.dat 0 08:07 315.idx 57 08:07 315.vif* 8 08:07 316.dat 0 08:07 316.idx 57 08:07 316.vif* 8 08:07 317.dat 0 08:07 317.idx 57 08:07 317.vif* 8 08:07 318.dat 0 08:07 318.idx 57 08:07 318.vif* 8 08:07 319.dat 0 08:07 319.idx 57 08:07 319.vif* 8 08:07 320.dat 0 08:07 320.idx 57 08:07 320.vif* 8 08:07 321.dat 0 08:07 321.idx 57 08:07 321.vif* 8 08:07 322.dat 0 08:07 322.idx 57 08:07 322.vif* 8 08:07 323.dat 0 08:07 323.idx 57 08:07 323.vif* 8 08:07 324.dat 0 08:07 324.idx 57 08:07 324.vif* 8 08:07 325.dat 0 08:07 325.idx 57 08:07 325.vif* 8 08:07 326.dat 0 08:07 326.idx 57 08:07 326.vif* 8 08:07 327.dat 0 08:07 327.idx 57 08:07 327.vif* 8 08:07 328.dat 0 08:07 328.idx 57 08:07 328.vif* 8 08:07 329.dat 0 08:07 329.idx 57 08:07 329.vif* 8 08:07 330.dat 0 08:07 330.idx 57 08:07 330.vif* 8 08:07 331.dat 0 08:07 331.idx 57 08:07 331.vif* 8 08:07 332.dat 0 08:07 332.idx 57 08:07 332.vif* 8 08:07 333.dat 0 08:07 333.idx 57 08:07 333.vif* 8 08:07 334.dat 0 08:07 334.idx 57 08:07 334.vif* 8 08:07 335.dat 0 08:07 335.idx 57 08:07 335.vif* 8 08:07 336.dat 0 08:07 336.idx 57 08:07 336.vif* 8 08:07 337.dat 0 08:07 337.idx 57 08:07 337.vif* 8 08:07 338.dat 0 08:07 338.idx 57 08:07 338.vif* 8 08:07 339.dat 0 08:07 339.idx 57 08:07 339.vif* 8 08:07 340.dat 0 08:07 340.idx 57 08:07 340.vif* 8 08:07 341.dat 0 08:07 341.idx 57 08:07 341.vif* 8 08:08 342.dat 0 08:08 342.idx 57 08:08 342.vif* 8 08:08 343.dat 0 08:08 343.idx 57 08:08 343.vif* 8 08:08 344.dat 0 08:08 344.idx 57 08:08 344.vif* 8 08:08 345.dat 0 08:08 345.idx 57 08:08 345.vif* 8 08:08 346.dat 0 08:08 346.idx 57 08:08 346.vif* 8 08:08 347.dat 0 08:08 347.idx 57 08:08 347.vif* 8 08:08 348.dat 0 08:08 348.idx 57 08:08 348.vif* 8 08:08 349.dat 0 08:08 349.idx 57 08:08 349.vif* 8 08:08 350.dat 0 08:08 350.idx 57 08:08 350.vif* 8 08:08 351.dat 0 08:08 351.idx 57 08:08 351.vif* 8 08:08 352.dat 0 08:08 352.idx 57 08:08 352.vif* 8 08:08 353.dat 0 08:08 353.idx 57 08:08 353.vif* 8 08:08 354.dat 0 08:08 354.idx 57 08:08 354.vif* 8 08:08 355.dat 0 08:08 355.idx 57 08:08 355.vif* 8 08:08 356.dat 0 08:08 356.idx 57 08:08 356.vif* 8 08:08 357.dat 0 08:08 357.idx 57 08:08 357.vif* 8 08:08 358.dat 0 08:08 358.idx 57 08:08 358.vif* 8 08:08 359.dat 0 08:08 359.idx 57 08:08 359.vif* 8 08:08 360.dat 0 08:08 360.idx 57 08:08 360.vif* 8 08:08 361.dat 0 08:08 361.idx 57 08:08 361.vif* 8 08:08 362.dat 0 08:08 362.idx 57 08:08 362.vif* 8 08:08 363.dat 0 08:08 363.idx 57 08:08 363.vif* 8 08:08 364.dat 0 08:08 364.idx 57 08:08 364.vif* 8 08:08 365.dat 0 08:08 365.idx 57 08:08 365.vif* 8 08:08 366.dat 0 08:08 366.idx 57 08:08 366.vif* 8 08:08 367.dat 0 08:08 367.idx 57 08:08 367.vif* 8 08:08 368.dat 0 08:08 368.idx 57 08:08 368.vif* 8 08:08 369.dat 0 08:08 369.idx 57 08:08 369.vif* 8 08:08 370.dat 0 08:08 370.idx 57 08:08 370.vif* 8 08:08 371.dat 0 08:08 371.idx 57 08:08 371.vif* 8 08:08 372.dat 0 08:08 372.idx 57 08:08 372.vif* 8 08:08 373.dat 0 08:08 373.idx 57 08:08 373.vif* 8 08:08 374.dat 0 08:08 374.idx 57 08:08 374.vif* 8 08:08 375.dat 0 08:08 375.idx 57 08:08 375.vif* 8 08:08 376.dat 0 08:08 376.idx 57 08:08 376.vif* 8 08:08 377.dat 0 08:08 377.idx 57 08:08 377.vif* 8 08:08 378.dat 0 08:08 378.idx 57 08:08 378.vif* 8 08:08 379.dat 0 08:08 379.idx 57 08:08 379.vif* 8 08:08 380.dat 0 08:08 380.idx 57 08:08 380.vif* 8 08:08 381.dat 0 08:08 381.idx 57 08:08 381.vif* 8 08:08 382.dat 0 08:08 382.idx 57 08:08 382.vif* 8 08:08 383.dat 0 08:08 383.idx 57 08:08 383.vif* 8 08:08 384.dat 0 08:08 384.idx 57 08:08 384.vif* 8 08:08 385.dat 0 08:08 385.idx 57 08:08 385.vif* 8 08:08 386.dat 0 08:08 386.idx 57 08:08 386.vif* 8 08:08 387.dat 0 08:08 387.idx 57 08:08 387.vif* 8 08:08 388.dat 0 08:08 388.idx 57 08:08 388.vif* 8 08:08 389.dat 0 08:08 389.idx 57 08:08 389.vif* 8 08:08 390.dat 0 08:08 390.idx 57 08:08 390.vif* 8 08:08 391.dat 0 08:08 391.idx 57 08:08 391.vif* 8 08:08 392.dat 0 08:08 392.idx 57 08:08 392.vif* 8 08:08 393.dat 0 08:08 393.idx 57 08:08 393.vif* 8 08:08 394.dat 0 08:08 394.idx 57 08:08 394.vif* 8 08:08 395.dat 0 08:08 395.idx 57 08:08 395.vif* 8 08:08 396.dat 0 08:08 396.idx 57 08:08 396.vif* 8 08:08 397.dat 0 08:08 397.idx 57 08:08 397.vif* 8 08:08 398.dat 0 08:08 398.idx 57 08:08 398.vif* 8 08:08 399.dat 0 08:08 399.idx 57 08:08 399.vif* 8 08:08 400.dat 0 08:08 400.idx 57 08:08 400.vif* 8 08:08 401.dat 0 08:08 401.idx 57 08:08 401.vif* 8 08:08 402.dat 0 08:08 402.idx 57 08:08 402.vif* 8 08:08 403.dat 0 08:08 403.idx 57 08:08 403.vif* 8 08:08 404.dat 0 08:08 404.idx 57 08:08 404.vif* 8 08:08 405.dat 0 08:08 405.idx 57 08:08 405.vif* 8 08:08 406.dat 0 08:08 406.idx 57 08:08 406.vif* 8 08:08 407.dat 0 08:08 407.idx 57 08:08 407.vif* 8 08:08 408.dat 0 08:08 408.idx 57 08:08 408.vif* 8 08:08 409.dat 0 08:08 409.idx 57 08:08 409.vif* 8 08:08 410.dat 0 08:08 410.idx 57 08:08 410.vif* 8 08:08 411.dat 0 08:08 411.idx 57 08:08 411.vif* 8 08:08 412.dat 0 08:08 412.idx 57 08:08 412.vif* 8 08:08 413.dat 0 08:08 413.idx 57 08:08 413.vif* 8 08:08 414.dat  Thanks. source-file",no-bug,0.7
3564,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3564,[filer] DATA RACE on signal_handling,https://github.com/seaweedfs/seaweedfs/issues/3507   WARNING: DATA RACE Read at 0x00c0001276d0 by goroutine 36: github.com/seaweedfs/seaweedfs/weed/util/grace.init.0.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/util/grace/signal_handling.go:31 +0xac Previous write at 0x00c0001276d0 by main goroutine: github.com/seaweedfs/seaweedfs/weed/util/grace.OnInterrupt() /go/src/github.com/seaweedfs/seaweedfs/weed/util/grace/signal_handling.go:46 +0xfb github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:179 +0x1999 github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:227 +0xcf7 github.com/seaweedfs/seaweedfs/weed/command.runFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x892 main.main() /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 Goroutine 36 (running) created at: github.com/seaweedfs/seaweedfs/weed/util/grace.init.0() /go/src/github.com/seaweedfs/seaweedfs/weed/util/grace/signal_handling.go:29 +0x18a  Found 3 data race(s) ,source-file | source-file,[filer] DATA RACE on signal_handling https://github.com/seaweedfs/seaweedfs/issues/3507   WARNING: DATA RACE Read at 0x00c0001276d0 by goroutine 36: github.com/seaweedfs/seaweedfs/weed/util/grace.init.0.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/util/grace/signal_handling.go:31 +0xac Previous write at 0x00c0001276d0 by main goroutine: github.com/seaweedfs/seaweedfs/weed/util/grace.OnInterrupt() /go/src/github.com/seaweedfs/seaweedfs/weed/util/grace/signal_handling.go:46 +0xfb github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:179 +0x1999 github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:227 +0xcf7 github.com/seaweedfs/seaweedfs/weed/command.runFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x892 main.main() /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 Goroutine 36 (running) created at: github.com/seaweedfs/seaweedfs/weed/util/grace.init.0() /go/src/github.com/seaweedfs/seaweedfs/weed/util/grace/signal_handling.go:29 +0x18a  Found 3 data race(s)  source-file source-file,no-bug,0.95
4365,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4365,ec.decode: no such file or directory,"**Describe the bug** Trying to ec.encode and ec.decode a volume, but ec.decode fails. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  /usr/local/bin/weed -logtostderr -v=1 master -mdir=/mnt/data01/meta -ip=10.1.21.23 -defaultReplication=010 -volumeSizeLimitMB 30000 -garbageThreshold 0.001 -peers=10.1.21.23:9333,10.1.21.24:9333,10.1.21.25:9333 /usr/local/bin/weed -logtostderr -v=1 volume -pprof -concurrentUploadLimitMB 99999 -concurrentDownloadLimitMB 99999 -minFreeSpace 50GiB -compactionMBps=500 -port=8080 -mserver=10.1.21.23:9333,10.1.21.24:9333,10.1.21.25:9333 -dir=/mnt/data01/data,/mnt/data02/data -index leveldb -max 0,0 -ip 10.1.21.23 -rack photol-110 -dataCenter v12  - OS version Ubuntu 18.04 - output of `weed version` version 30GB 3.44 linux amd64 **Expected behavior** The volume to be converted from ec to regular volume. **Logs**  > ec.encode -volumeId 13228 -collection ""photo-large-prod-005"" markVolumeReadonly 13228 on 10.1.21.23:8080  markVolumeReadonly 13228 on 10.1.21.29:8080  markVolumeReadonly 13228 on 10.1.21.25:8080  generateEcShards photo-large-prod-005 13228 on 10.1.21.23:8080  parallelCopyEcShardsFromSource 13228 10.1.21.23:8080 allocate 13228.[2 6 10] 10.1.21.23:8080 => 10.1.21.23:8080 allocate 13228.[0 4 8 12] 10.1.21.23:8080 => 10.1.21.24:8080 allocate 13228.[3 7 11] 10.1.21.23:8080 => 10.1.21.29:8080 allocate 13228.[1 5 9 13] 10.1.21.23:8080 => 10.1.21.25:8080 mount 13228.[2 6 10] on 10.1.21.23:8080 copy 13228.[0 4 8 12] 10.1.21.23:8080 => 10.1.21.24:8080 copy 13228.[3 7 11] 10.1.21.23:8080 => 10.1.21.29:8080 copy 13228.[1 5 9 13] 10.1.21.23:8080 => 10.1.21.25:8080 mount 13228.[3 7 11] on 10.1.21.29:8080 I0403 12:01:12.004477 command_ec_common.go:98 10.1.21.23:8080 ec volume 13228 deletes shards [3 7 11] mount 13228.[0 4 8 12] on 10.1.21.24:8080 I0403 12:01:22.365045 command_ec_common.go:98 10.1.21.23:8080 ec volume 13228 deletes shards [0 4 8 12] mount 13228.[1 5 9 13] on 10.1.21.25:8080 I0403 12:01:22.614695 command_ec_common.go:98 10.1.21.23:8080 ec volume 13228 deletes shards [1 5 9 13] unmount 13228.[3 7 11 0 4 8 12 1 5 9 13] from 10.1.21.23:8080 delete 13228.[3 7 11 0 4 8 12 1 5 9 13] from 10.1.21.23:8080 delete volume 13228 from 10.1.21.23:8080 delete volume 13228 from 10.1.21.29:8080 delete volume 13228 from 10.1.21.25:8080 > ec.decode -volumeId 13228 -collection ""photo-large-prod-005"" -force ec volume 13228 shard locations: map[10.1.21.23:8080:1092 10.1.21.24:8080:4369 10.1.21.25:8080:8738 10.1.21.29:8080:2184] collectEcShards: ec volume 13228 collect shards to 10.1.21.24:8080 from: map[10.1.21.23:8080:1092 10.1.21.24:8080:4369 10.1.21.25:8080:8738 10.1.21.29:8080:2184] copy 13228.[2 6] 10.1.21.23:8080 => 10.1.21.24:8080 copy 13228.[3 7] 10.1.21.29:8080 => 10.1.21.24:8080 copy 13228.[1 5 9] 10.1.21.25:8080 => 10.1.21.24:8080 generateNormalVolume from ec volume 13228 on 10.1.21.24:8080 error: generate normal volume 13228 on 10.1.21.24:8080: rpc error: code = Unknown desc = WriteEcFiles /mnt/data02/data/photo-large-prod-005_13228: open /mnt/data02/data/photo-large-prod-005_13228.ec01: no such file or directory",source-file | source-file | source-file | source-file | source-file,"ec.decode: no such file or directory **Describe the bug** Trying to ec.encode and ec.decode a volume, but ec.decode fails. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  /usr/local/bin/weed -logtostderr -v=1 master -mdir=/mnt/data01/meta -ip=10.1.21.23 -defaultReplication=010 -volumeSizeLimitMB 30000 -garbageThreshold 0.001 -peers=10.1.21.23:9333,10.1.21.24:9333,10.1.21.25:9333 /usr/local/bin/weed -logtostderr -v=1 volume -pprof -concurrentUploadLimitMB 99999 -concurrentDownloadLimitMB 99999 -minFreeSpace 50GiB -compactionMBps=500 -port=8080 -mserver=10.1.21.23:9333,10.1.21.24:9333,10.1.21.25:9333 -dir=/mnt/data01/data,/mnt/data02/data -index leveldb -max 0,0 -ip 10.1.21.23 -rack photol-110 -dataCenter v12  - OS version Ubuntu 18.04 - output of `weed version` version 30GB 3.44 linux amd64 **Expected behavior** The volume to be converted from ec to regular volume. **Logs**  > ec.encode -volumeId 13228 -collection ""photo-large-prod-005"" markVolumeReadonly 13228 on 10.1.21.23:8080  markVolumeReadonly 13228 on 10.1.21.29:8080  markVolumeReadonly 13228 on 10.1.21.25:8080  generateEcShards photo-large-prod-005 13228 on 10.1.21.23:8080  parallelCopyEcShardsFromSource 13228 10.1.21.23:8080 allocate 13228.[2 6 10] 10.1.21.23:8080 => 10.1.21.23:8080 allocate 13228.[0 4 8 12] 10.1.21.23:8080 => 10.1.21.24:8080 allocate 13228.[3 7 11] 10.1.21.23:8080 => 10.1.21.29:8080 allocate 13228.[1 5 9 13] 10.1.21.23:8080 => 10.1.21.25:8080 mount 13228.[2 6 10] on 10.1.21.23:8080 copy 13228.[0 4 8 12] 10.1.21.23:8080 => 10.1.21.24:8080 copy 13228.[3 7 11] 10.1.21.23:8080 => 10.1.21.29:8080 copy 13228.[1 5 9 13] 10.1.21.23:8080 => 10.1.21.25:8080 mount 13228.[3 7 11] on 10.1.21.29:8080 I0403 12:01:12.004477 command_ec_common.go:98 10.1.21.23:8080 ec volume 13228 deletes shards [3 7 11] mount 13228.[0 4 8 12] on 10.1.21.24:8080 I0403 12:01:22.365045 command_ec_common.go:98 10.1.21.23:8080 ec volume 13228 deletes shards [0 4 8 12] mount 13228.[1 5 9 13] on 10.1.21.25:8080 I0403 12:01:22.614695 command_ec_common.go:98 10.1.21.23:8080 ec volume 13228 deletes shards [1 5 9 13] unmount 13228.[3 7 11 0 4 8 12 1 5 9 13] from 10.1.21.23:8080 delete 13228.[3 7 11 0 4 8 12 1 5 9 13] from 10.1.21.23:8080 delete volume 13228 from 10.1.21.23:8080 delete volume 13228 from 10.1.21.29:8080 delete volume 13228 from 10.1.21.25:8080 > ec.decode -volumeId 13228 -collection ""photo-large-prod-005"" -force ec volume 13228 shard locations: map[10.1.21.23:8080:1092 10.1.21.24:8080:4369 10.1.21.25:8080:8738 10.1.21.29:8080:2184] collectEcShards: ec volume 13228 collect shards to 10.1.21.24:8080 from: map[10.1.21.23:8080:1092 10.1.21.24:8080:4369 10.1.21.25:8080:8738 10.1.21.29:8080:2184] copy 13228.[2 6] 10.1.21.23:8080 => 10.1.21.24:8080 copy 13228.[3 7] 10.1.21.29:8080 => 10.1.21.24:8080 copy 13228.[1 5 9] 10.1.21.25:8080 => 10.1.21.24:8080 generateNormalVolume from ec volume 13228 on 10.1.21.24:8080 error: generate normal volume 13228 on 10.1.21.24:8080: rpc error: code = Unknown desc = WriteEcFiles /mnt/data02/data/photo-large-prod-005_13228: open /mnt/data02/data/photo-large-prod-005_13228.ec01: no such file or directory source-file source-file source-file source-file source-file",no-bug,0.9
1436,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1436,"Volume not found, but it actually exists.","Version: 1.91 There are times that filer return 500 when downloading file. And the error said ""volume 603 not found"". But it actually exists on volume server. Ant when I restart the filer. It will be correct. ![image](https://user-images.githubusercontent.com/11285030/91559504-ca6a7100-e96a-11ea-8ecf-384f7f7cd148.png) ![image](https://user-images.githubusercontent.com/11285030/91559548-dfdf9b00-e96a-11ea-9f41-b85dd81a1a71.png) I didn't open the verbose log on that case. I'm still checking stack trace. I will paste more information here next time it happened",source-file,"Volume not found, but it actually exists. Version: 1.91 There are times that filer return 500 when downloading file. And the error said ""volume 603 not found"". But it actually exists on volume server. Ant when I restart the filer. It will be correct. ![image](https://user-images.githubusercontent.com/11285030/91559504-ca6a7100-e96a-11ea-8ecf-384f7f7cd148.png) ![image](https://user-images.githubusercontent.com/11285030/91559548-dfdf9b00-e96a-11ea-9f41-b85dd81a1a71.png) I didn't open the verbose log on that case. I'm still checking stack trace. I will paste more information here next time it happened source-file",bug,0.85
629,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/629,Raft master election issues when failover occurs,"There seems to be two or possibly more things wrong the the raft implementation: - if a elected master gets isolated it will remain leader after it gets reconnected to the network, resulting in inability to assign uploads to volumes until a new election takes place. - if a non-elected isolated master get reconnected to the network, it will imidiately become elected master, resulting in the former master loosing connection to the volumes. Details  We are currently testing with a three master setup, running each master like this:  weed master -ip 10.1.1.103 -port=9333 -mdir=./master -peers=10.1.1.103:9333,10.1.1.105:9333,10.1.1.105:9334  The inital cluster gets booted, with the first master to start becoming leader. Then we tried to drop all traffic in and out of the first master, which is currently the leader. This results in the isolated master remaining leader:  $ curl localhost:9333/cluster/status {""IsLeader"":true,""Leader"":""10.1.1.103:9333"",""Peers"":[""10.1.1.105:9333"",""10.1.1.105:9334""]}  And the two other masters electing a new leader:  master_server.go:91] [ 10.1.1.105:9334 ] 10.1.1.105:9334 becomes leader.  (Btw, this message only gets logged on the elected leader, even with `v=3`)  $ curl localhost:9334/cluster/status {""IsLeader"":true,""Leader"":""10.1.1.105:9334"",""Peers"":[""10.1.1.103:9333"",""10.1.1.105:9333""]}  After opening up all traffic again, both leaders remain leaders until next election. Doing `weed upload` at this moment result in these messages:  [{""fileName"":""file.tar.gz"",""error"":""/dir/assign result JSON unmarshal error:unexpected end of JSON input, json:""}] [{""fileName"":""file.tar.gz"",""error"":""http://weed-002.site-001.jotta.no:9334/dir/assign : 404 Not Found""}]  After a while, 10-20 seconds, all masters again agree and all continues to work.  If we then try to isolate a master which is not the current leader, nothing happens. But when we introduce it to the network again, that master immediately becomes leader:  master_server.go:91] [ 10.1.1.103:9333 ] 10.1.1.103:9333 becomes leader. node.go:223] topo:DefaultDataCenter:test-105 adds child 10.1.1.105:8080 master_grpc_server.go:36] added volume server 10.1.1.105:8080  The former master logging lost volumes resulting in `{""error"":""No free volumes left!""}` error messages:  master_grpc_server.go:63] lost volume server 10.1.1.105:8080 topology_event_handling.go:52] Removing Volume 54 from the dead volume server 10.1.1.105:8080 volume_layout.go:227] Volume 54 has 1 replica, less than required 2 volume_layout.go:203] Volume 54 becomes unwritable  edit: some typos/clarifications",source-file | source-file | source-file | source-file | source-file | source-file,"Raft master election issues when failover occurs There seems to be two or possibly more things wrong the the raft implementation: - if a elected master gets isolated it will remain leader after it gets reconnected to the network, resulting in inability to assign uploads to volumes until a new election takes place. - if a non-elected isolated master get reconnected to the network, it will imidiately become elected master, resulting in the former master loosing connection to the volumes. Details  We are currently testing with a three master setup, running each master like this:  weed master -ip 10.1.1.103 -port=9333 -mdir=./master -peers=10.1.1.103:9333,10.1.1.105:9333,10.1.1.105:9334  The inital cluster gets booted, with the first master to start becoming leader. Then we tried to drop all traffic in and out of the first master, which is currently the leader. This results in the isolated master remaining leader:  $ curl localhost:9333/cluster/status {""IsLeader"":true,""Leader"":""10.1.1.103:9333"",""Peers"":[""10.1.1.105:9333"",""10.1.1.105:9334""]}  And the two other masters electing a new leader:  master_server.go:91] [ 10.1.1.105:9334 ] 10.1.1.105:9334 becomes leader.  (Btw, this message only gets logged on the elected leader, even with `v=3`)  $ curl localhost:9334/cluster/status {""IsLeader"":true,""Leader"":""10.1.1.105:9334"",""Peers"":[""10.1.1.103:9333"",""10.1.1.105:9333""]}  After opening up all traffic again, both leaders remain leaders until next election. Doing `weed upload` at this moment result in these messages:  [{""fileName"":""file.tar.gz"",""error"":""/dir/assign result JSON unmarshal error:unexpected end of JSON input, json:""}] [{""fileName"":""file.tar.gz"",""error"":""http://weed-002.site-001.jotta.no:9334/dir/assign : 404 Not Found""}]  After a while, 10-20 seconds, all masters again agree and all continues to work.  If we then try to isolate a master which is not the current leader, nothing happens. But when we introduce it to the network again, that master immediately becomes leader:  master_server.go:91] [ 10.1.1.103:9333 ] 10.1.1.103:9333 becomes leader. node.go:223] topo:DefaultDataCenter:test-105 adds child 10.1.1.105:8080 master_grpc_server.go:36] added volume server 10.1.1.105:8080  The former master logging lost volumes resulting in `{""error"":""No free volumes left!""}` error messages:  master_grpc_server.go:63] lost volume server 10.1.1.105:8080 topology_event_handling.go:52] Removing Volume 54 from the dead volume server 10.1.1.105:8080 volume_layout.go:227] Volume 54 has 1 replica, less than required 2 volume_layout.go:203] Volume 54 becomes unwritable  edit: some typos/clarifications source-file source-file source-file source-file source-file source-file",no-bug,0.9
5194,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5194,[filer_sync] DATA RACE runFilerSynchronize,**Describe the bug** steps:  make 2mount CGO_ENABLED=1 go build -race ./weed -v=4 filer.sync -a=127.0.0.1:8888 -b=127.0.0.1:7888 -a.debug -b.debug    WARNING: DATA RACE Read at 0x000107653f74 by goroutine 71: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:153 +0x274 Previous write at 0x000107653f74 by goroutine 72: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize.func2() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:191 +0x88 Goroutine 71 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:144 +0x54c main.main() /Users/whitefox/GolandProjects/seaweedfs/weed/weed.go:80 +0x73c Goroutine 72 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:189 +0x6e4 main.main() /Users/whitefox/GolandProjects/seaweedfs/weed/weed.go:80 +0x73c   **System Setup**  master branch ,config-file | source-file | source-file | source-file | source-file | config-file | source-file | source-file | source-file | source-file,[filer_sync] DATA RACE runFilerSynchronize **Describe the bug** steps:  make 2mount CGO_ENABLED=1 go build -race ./weed -v=4 filer.sync -a=127.0.0.1:8888 -b=127.0.0.1:7888 -a.debug -b.debug    WARNING: DATA RACE Read at 0x000107653f74 by goroutine 71: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize.func1() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:153 +0x274 Previous write at 0x000107653f74 by goroutine 72: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize.func2() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:191 +0x88 Goroutine 71 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:144 +0x54c main.main() /Users/whitefox/GolandProjects/seaweedfs/weed/weed.go:80 +0x73c Goroutine 72 (running) created at: github.com/seaweedfs/seaweedfs/weed/command.runFilerSynchronize() /Users/whitefox/GolandProjects/seaweedfs/weed/command/filer_sync.go:189 +0x6e4 main.main() /Users/whitefox/GolandProjects/seaweedfs/weed/weed.go:80 +0x73c   **System Setup**  master branch  config-file source-file source-file source-file source-file config-file source-file source-file source-file source-file,no-bug,0.9
5954,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5954,WORM (Write once read many) support,"Is there a plan or roadmap to support [WORM (Write once read many)](https://en.wikipedia.org/wiki/Write_once_read_many) ? I find a related issue (https://github.com/seaweedfs/seaweedfs/issues/4268). But that issue discusses S3, while I am more interested in fuse mount.",source-file | source-file | source-file | source-file | source-file,"WORM (Write once read many) support Is there a plan or roadmap to support [WORM (Write once read many)](https://en.wikipedia.org/wiki/Write_once_read_many) ? I find a related issue (https://github.com/seaweedfs/seaweedfs/issues/4268). But that issue discusses S3, while I am more interested in fuse mount. source-file source-file source-file source-file source-file",no-bug,0.9
1989,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1989,About log level for V logs," logging_options -v value log level for V logs  what does 'V logs' mean. and What does ""value"" have. I see the document through execute './weed -h' ,Can I find more detailed documentation by some command or in some place?",source-file,"About log level for V logs  logging_options -v value log level for V logs  what does 'V logs' mean. and What does ""value"" have. I see the document through execute './weed -h' ,Can I find more detailed documentation by some command or in some place? source-file",no-bug,0.9
31,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/31,Can I hide port info from volume publicUrl?,We would like to proxy requests over nginx. So even if volume server accepts requests on `8080` our clients will use `80` port. I was able to change volume `publicUrl` by `-publicIp=` option but it still returns the same (`8080`) port. Is it possible to hide port for publicUrl?,other-file | documentation-file | config-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,Can I hide port info from volume publicUrl? We would like to proxy requests over nginx. So even if volume server accepts requests on `8080` our clients will use `80` port. I was able to change volume `publicUrl` by `-publicIp=` option but it still returns the same (`8080`) port. Is it possible to hide port for publicUrl? other-file documentation-file config-file other-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file,no-bug,0.8
2102,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2102,LXC/LXD on SeaweedFS results in I/O errors,"**Describe the bug** I get I/O errors when running LXC containers on SeaweedFS. Example: I0531 15:53:03 2099 wfs_filer_client.go:29] WithFilerClient 0 10.0.251.1:19533: input/output error I0531 15:53:03 2099 dir_link.go:77] Link /containers/my-container/rootfs/usr/bin/perl -> /containers/my-container/rootfs/usr/bin/perl5.26.1: UpdateEntry: rpc error: code = Unknown desc = not found /containers/my-container/rootfs/usr/bin/perl: filer: no entry is found in filer store Pastebin: https://pastebin.com/raw/E62V7Cuq LXD: snap install lxd --channel=4.0/stable lxc storage create seaweedfs dir source=/mnt/seaweedfs/ (I did mount SeaweedFS before) lxc launch -s seaweedfs ubuntu:18.04 my-container **System Setup** 3 Nodes, 3x Master, 3x Volume, 3x Filer /usr/local/bin/weed master -defaultReplication=001 -ip=10.0.251.1 -ip.bind=10.0.251.1 -port=9333 -mdir=/home/seaweedfs/master -peers=10.0.251.1:9333,10.0.251.2:9333,10.0.251.3:9333 /usr/local/bin/weed volume -ip=10.0.251.1 -ip.bind=10.0.251.1 -port=9433 -dir=/home/seaweedfs/volume -dataCenter=dc1 -rack=rack1 -mserver=10.0.251.1:9333,10.0.251.2:9333,10.0.251.3:9333 /usr/local/bin/weed filer -ip=10.0.251.1 -ip.bind=10.0.251.1 -port=9533 -master=10.0.251.1:9333,10.0.251.2:9333,10.0.251.3:9333 Same on all 3 nodes, only the IP does differ. Used: https://github.com/Ne00n/seaweed-spawner-3000 - Ubuntu 20.04 on arm64 - 2.49 - if using filer, show the content of `filer.toml` ( could not find this one, sorry) **Expected behavior** It should not result in any I/O errors Any idea on this guys?",source-file,"LXC/LXD on SeaweedFS results in I/O errors **Describe the bug** I get I/O errors when running LXC containers on SeaweedFS. Example: I0531 15:53:03 2099 wfs_filer_client.go:29] WithFilerClient 0 10.0.251.1:19533: input/output error I0531 15:53:03 2099 dir_link.go:77] Link /containers/my-container/rootfs/usr/bin/perl -> /containers/my-container/rootfs/usr/bin/perl5.26.1: UpdateEntry: rpc error: code = Unknown desc = not found /containers/my-container/rootfs/usr/bin/perl: filer: no entry is found in filer store Pastebin: https://pastebin.com/raw/E62V7Cuq LXD: snap install lxd --channel=4.0/stable lxc storage create seaweedfs dir source=/mnt/seaweedfs/ (I did mount SeaweedFS before) lxc launch -s seaweedfs ubuntu:18.04 my-container **System Setup** 3 Nodes, 3x Master, 3x Volume, 3x Filer /usr/local/bin/weed master -defaultReplication=001 -ip=10.0.251.1 -ip.bind=10.0.251.1 -port=9333 -mdir=/home/seaweedfs/master -peers=10.0.251.1:9333,10.0.251.2:9333,10.0.251.3:9333 /usr/local/bin/weed volume -ip=10.0.251.1 -ip.bind=10.0.251.1 -port=9433 -dir=/home/seaweedfs/volume -dataCenter=dc1 -rack=rack1 -mserver=10.0.251.1:9333,10.0.251.2:9333,10.0.251.3:9333 /usr/local/bin/weed filer -ip=10.0.251.1 -ip.bind=10.0.251.1 -port=9533 -master=10.0.251.1:9333,10.0.251.2:9333,10.0.251.3:9333 Same on all 3 nodes, only the IP does differ. Used: https://github.com/Ne00n/seaweed-spawner-3000 - Ubuntu 20.04 on arm64 - 2.49 - if using filer, show the content of `filer.toml` ( could not find this one, sorry) **Expected behavior** It should not result in any I/O errors Any idea on this guys? source-file",no-bug,0.9
5677,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5677,file.remote.sync doesn't push objects after network issue,"Hi there, I'm testing seaweedfs 3.67 on a cloud drive with cache configuration. I simulated a network issue (iptables -A OUTPUT -p tcp --dport 443 -m statistic --mode random --probability 1 -j DROP) to check the sync back to S3. After removing the iptables rule, I noticed that when restarting the filer.remote.sync run by ./weed filer.remote.sync -dir=/buckets/bm-factorfx generates an error in the weed server log :  I0617 12:28:01.273906 filer_grpc_server_sub_meta.go:299 + listener filer.remote.sync@127.0.0.1:56244 clientId 1966601686 clientEpoch 1 I0617 12:28:01.273936 filer_grpc_server_sub_meta.go:37 filer.remote.sync@127.0.0.1:56244 starts to subscribe /buckets/bm-factorfx from 2024-06-17 12:19:59.459700712 +0000 UTC I0617 12:28:02.295922 filer_grpc_server_sub_meta.go:271 => client filer.remote.sync@127.0.0.1:33928: rpc error: code = Unavailable desc = transport is closing E0617 12:28:02.296089 log_read.go:122 LoopProcessLogData: aggMeta:filer.remote.sync@127.0.0.1:33928 process log entry 1 ts_ns:1718627282295650113 partition_key_hash:371534054 data:""\n\x14/buckets/bm-factorfx\x12\xc2\x03\n\xd8\x01\n(c16f76b595c41c6135ad1ddd8c8efe669e63671f\x1aF\n\x108,1cfd83b53631b2\x18\x8f\"" \x89\x92\xf2\xec\x17*\x18f++v6teE2RGu0ueBoJGZ7w==:\x0b\x08\x08\x10\x83\xfbs\x1d\xb216\xb5\""$\x08\x8f\""\x10\xf0\xd3\xc0\xb3\x06\x18\xb0\x030\xf0\xd3\xc0\xb3\x06r\x10\x7f\xef\xaf\xea\xd9\x11\xae\xd2\x91\x99\xefR>\n\x05s3ovh\x10\xf9\xc4\xf2\xec\x17\x1a\""\""7fefafead784d911aed2e781a09199ef\"" \x9c\xd5\xc0\xb3\x06(\x8f\""\x12\xc6\x01\n(c16f76b595c41c6135ad1ddd8c8efe669e63671f\x1a4\x18\x8f\"" \x89\x92\xf2\xec\x17*\x18f++v6teE2RGu0ueBoJGZ7w==:\x0b\x08\x08\x10\x83\xfbs\x1d\xb216\xb5\""$\x08\x8f\""\x10\xf0\xd3\xc0\xb3\x06\x18\xb0\x030\xf0\xd3\xc0\xb3\x06r\x10\x7f\xef\xaf\xea\xd9\x11\xae\xd2\x91\x99\xefR>\n\x05s3ovh\x10\x80\xb0\xfb\xb3\x85\xcd\xf2\xec\x17\x1a\""\""7fefafead784d911aed2e781a09199ef\"" \xd2\xd7\xc0\xb3\x06(\x8f\""\x18\x01\""\x14/buckets/bm-factorfx2\x04\xb9\xc2\xd8.\x18\xc1\x85\xcd\xf2\xec\x17"" key:""/buckets/bm-factorfx"": rpc error: code = Unavailable desc = transport is closing E0617 12:28:02.296204 filer_grpc_server_sub_meta.go:79 processed to 2024-06-17 12:28:02.295650113 +0000 UTC: rpc error: code = Unavailable desc = transport is closing  The new writes to the remote S3 were still working. So it looks like all the writings that happened during the network issue where only in seaweed. I managed to get the sync process to put the missing object by adding '-timeAgo 1h' . The issue looks a bit like : https://github.com/seaweedfs/seaweedfs/commit/3d3fa43542dabab77a2c1ade868fcd8dc0e68cd9, maybe the same ? In the filer.remote.sync process, I can see that the last sync timestamp was moving du to the sync of the new objects : I can reproduce the scenario if you need more logs. Thanks a lot,",source-file | source-file | source-file | source-file,"file.remote.sync doesn't push objects after network issue Hi there, I'm testing seaweedfs 3.67 on a cloud drive with cache configuration. I simulated a network issue (iptables -A OUTPUT -p tcp --dport 443 -m statistic --mode random --probability 1 -j DROP) to check the sync back to S3. After removing the iptables rule, I noticed that when restarting the filer.remote.sync run by ./weed filer.remote.sync -dir=/buckets/bm-factorfx generates an error in the weed server log :  I0617 12:28:01.273906 filer_grpc_server_sub_meta.go:299 + listener filer.remote.sync@127.0.0.1:56244 clientId 1966601686 clientEpoch 1 I0617 12:28:01.273936 filer_grpc_server_sub_meta.go:37 filer.remote.sync@127.0.0.1:56244 starts to subscribe /buckets/bm-factorfx from 2024-06-17 12:19:59.459700712 +0000 UTC I0617 12:28:02.295922 filer_grpc_server_sub_meta.go:271 => client filer.remote.sync@127.0.0.1:33928: rpc error: code = Unavailable desc = transport is closing E0617 12:28:02.296089 log_read.go:122 LoopProcessLogData: aggMeta:filer.remote.sync@127.0.0.1:33928 process log entry 1 ts_ns:1718627282295650113 partition_key_hash:371534054 data:""\n\x14/buckets/bm-factorfx\x12\xc2\x03\n\xd8\x01\n(c16f76b595c41c6135ad1ddd8c8efe669e63671f\x1aF\n\x108,1cfd83b53631b2\x18\x8f\"" \x89\x92\xf2\xec\x17*\x18f++v6teE2RGu0ueBoJGZ7w==:\x0b\x08\x08\x10\x83\xfbs\x1d\xb216\xb5\""$\x08\x8f\""\x10\xf0\xd3\xc0\xb3\x06\x18\xb0\x030\xf0\xd3\xc0\xb3\x06r\x10\x7f\xef\xaf\xea\xd9\x11\xae\xd2\x91\x99\xefR>\n\x05s3ovh\x10\xf9\xc4\xf2\xec\x17\x1a\""\""7fefafead784d911aed2e781a09199ef\"" \x9c\xd5\xc0\xb3\x06(\x8f\""\x12\xc6\x01\n(c16f76b595c41c6135ad1ddd8c8efe669e63671f\x1a4\x18\x8f\"" \x89\x92\xf2\xec\x17*\x18f++v6teE2RGu0ueBoJGZ7w==:\x0b\x08\x08\x10\x83\xfbs\x1d\xb216\xb5\""$\x08\x8f\""\x10\xf0\xd3\xc0\xb3\x06\x18\xb0\x030\xf0\xd3\xc0\xb3\x06r\x10\x7f\xef\xaf\xea\xd9\x11\xae\xd2\x91\x99\xefR>\n\x05s3ovh\x10\x80\xb0\xfb\xb3\x85\xcd\xf2\xec\x17\x1a\""\""7fefafead784d911aed2e781a09199ef\"" \xd2\xd7\xc0\xb3\x06(\x8f\""\x18\x01\""\x14/buckets/bm-factorfx2\x04\xb9\xc2\xd8.\x18\xc1\x85\xcd\xf2\xec\x17"" key:""/buckets/bm-factorfx"": rpc error: code = Unavailable desc = transport is closing E0617 12:28:02.296204 filer_grpc_server_sub_meta.go:79 processed to 2024-06-17 12:28:02.295650113 +0000 UTC: rpc error: code = Unavailable desc = transport is closing  The new writes to the remote S3 were still working. So it looks like all the writings that happened during the network issue where only in seaweed. I managed to get the sync process to put the missing object by adding '-timeAgo 1h' . The issue looks a bit like : https://github.com/seaweedfs/seaweedfs/commit/3d3fa43542dabab77a2c1ade868fcd8dc0e68cd9, maybe the same ? In the filer.remote.sync process, I can see that the last sync timestamp was moving du to the sync of the new objects : I can reproduce the scenario if you need more logs. Thanks a lot, source-file source-file source-file source-file",no-bug,0.9
3510,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3510,[s3] DATA RACE on configured filer store to leveldb2,"https://github.com/seaweedfs/seaweedfs/issues/3507  s3_1 | WARNING: DATA RACE s3_1 | Read at 0x00c00018ea00 by main goroutine: s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).WaitUntilConnected() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:98 +0x66 s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).GetMaster() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:87 +0x6e s3_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).GetMaster() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:142 +0x3b s3_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).ListExistingPeerUpdates() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:108 +0x85 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:165 +0x1576 s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | s3_1 | Previous write at 0x00c00018ea00 by goroutine 159: s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:199 +0x19a9 s3_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 s3_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 s3_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:154 +0x27e s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:142 +0xd7 s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:108 +0x129 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39 s3_1 | s3_1 | Goroutine 159 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0xee4 s3_1 | github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:227 +0xcf7 s3_1 | github.com/seaweedfs/seaweedfs/weed/command.runFiler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x8ba s3_1 | main.main() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 s3_1 |  s3_1 | I0825 10:09:03.602528 master_client.go:20 the cluster has 1 filer s3_1 | I0825 10:09:03.602705 filer_server.go:168 172.18.0.5:8888 bootstrap from peers [node_type:""filer"" address:""172.18.0.5:8888"" is_leader:true is_add:true created_at_ns:1661422143534687100] s3_1 | I0825 10:09:03.605282 filer.go:271 Start Seaweed Filer 30GB 3.23 7394f7fe at 172.18.0.5:8888 s3_1 | I0825 10:09:03.605200 meta_aggregator.go:96 loopSubscribeToOneFiler read 172.18.0.5:8888 start from 2022-08-25 10:08:03.6026842 +0000 UTC 1661422083602684200 s3_1 | W0825 10:09:03.606561 tls.go:39 pemfile.NewProvider({ 5h0m0s}) grpc.filer failed: pemfile: at least one credential file needs to be specified s3_1 | I0825 10:09:03.614291 meta_aggregator.go:193 subscribing remote 172.18.0.5:8888 meta change: 2022-08-25 10:08:03.6026842 +0000 UTC, clientId:176700352 s3_1 | I0825 10:09:03.620078 filer_grpc_server_sub_meta.go:268 + listener filer:172.18.0.5:8888@172.18.0.5:47428 s3_1 | I0825 10:09:03.620172 filer_grpc_server_sub_meta.go:106 + filer:172.18.0.5:8888@172.18.0.5:47428 local subscribe / from 2022-08-25 10:08:03.6026842 +0000 UTC clientId:-176700352 s3_1 | I0825 10:09:03.620229 filer_grpc_server_sub_meta.go:119 read on disk filer:172.18.0.5:8888@172.18.0.5:47428 local subscribe / from 2022-08-25 10:08:03.6026842 +0000 UTC s3_1 | I0825 10:09:03.620646 filer_grpc_server_sub_meta.go:138 read in memory filer:172.18.0.5:8888@172.18.0.5:47428 local subscribe / from 2022-08-25 10:08:03.6026842 +0000 UTC ",source-file | source-file,"[s3] DATA RACE on configured filer store to leveldb2 https://github.com/seaweedfs/seaweedfs/issues/3507  s3_1 | WARNING: DATA RACE s3_1 | Read at 0x00c00018ea00 by main goroutine: s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).WaitUntilConnected() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:98 +0x66 s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).GetMaster() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:87 +0x6e s3_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).GetMaster() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:142 +0x3b s3_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).ListExistingPeerUpdates() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:108 +0x85 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:165 +0x1576 s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).checkAndCleanFiles() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db_util.go:52 +0x1fe s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:130 +0x8b5 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:657 +0x16e s3_1 | fmt.(*ss).doScanf() s3_1 | /usr/local/go/src/fmt/scan.go:1230 +0x3fb s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*DB).recoverJournal() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:476 +0xb2 s3_1 | github.com/syndtr/goleveldb/leveldb.openDB() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:125 +0x899 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:197 +0x35c s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x164 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.fsParseName() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:643 +0x26 s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | github.com/syndtr/goleveldb/leveldb.(*session).recover.func1() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/session.go:134 +0xd0 s3_1 | runtime.deferreturn() s3_1 | /usr/local/go/src/runtime/panic.go:476 +0x32 s3_1 | github.com/syndtr/goleveldb/leveldb.Open() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:183 +0x104 s3_1 | github.com/syndtr/goleveldb/leveldb.OpenFile() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/db.go:219 +0x87 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer/leveldb2.(*LevelDB2Store).initialize() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/leveldb2/leveldb2_store.go:57 +0x3cc s3_1 | github.com/syndtr/goleveldb/leveldb/storage.(*fileStorage).List() s3_1 | /go/pkg/mod/github.com/syndtr/goleveldb@v1.0.1-0.20190318030020-c3a204f8e965/leveldb/storage/file_storage.go:458 +0x3e6 s3_1 | fmt.Fscanf() s3_1 | /usr/local/go/src/fmt/scan.go:143 +0xe9 s3_1 | fmt.Sscanf() s3_1 | /usr/local/go/src/fmt/scan.go:114 +0x224 s3_1 | s3_1 | Previous write at 0x00c00018ea00 by goroutine 159: s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:199 +0x19a9 s3_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 s3_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 s3_1 | github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:154 +0x27e s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:142 +0xd7 s3_1 | github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:108 +0x129 s3_1 | github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 s3_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39 s3_1 | s3_1 | Goroutine 159 (running) created at: s3_1 | github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0xee4 s3_1 | github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:227 +0xcf7 s3_1 | github.com/seaweedfs/seaweedfs/weed/command.runFiler() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x8ba s3_1 | main.main() s3_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943 s3_1 |  s3_1 | I0825 10:09:03.602528 master_client.go:20 the cluster has 1 filer s3_1 | I0825 10:09:03.602705 filer_server.go:168 172.18.0.5:8888 bootstrap from peers [node_type:""filer"" address:""172.18.0.5:8888"" is_leader:true is_add:true created_at_ns:1661422143534687100] s3_1 | I0825 10:09:03.605282 filer.go:271 Start Seaweed Filer 30GB 3.23 7394f7fe at 172.18.0.5:8888 s3_1 | I0825 10:09:03.605200 meta_aggregator.go:96 loopSubscribeToOneFiler read 172.18.0.5:8888 start from 2022-08-25 10:08:03.6026842 +0000 UTC 1661422083602684200 s3_1 | W0825 10:09:03.606561 tls.go:39 pemfile.NewProvider({ 5h0m0s}) grpc.filer failed: pemfile: at least one credential file needs to be specified s3_1 | I0825 10:09:03.614291 meta_aggregator.go:193 subscribing remote 172.18.0.5:8888 meta change: 2022-08-25 10:08:03.6026842 +0000 UTC, clientId:176700352 s3_1 | I0825 10:09:03.620078 filer_grpc_server_sub_meta.go:268 + listener filer:172.18.0.5:8888@172.18.0.5:47428 s3_1 | I0825 10:09:03.620172 filer_grpc_server_sub_meta.go:106 + filer:172.18.0.5:8888@172.18.0.5:47428 local subscribe / from 2022-08-25 10:08:03.6026842 +0000 UTC clientId:-176700352 s3_1 | I0825 10:09:03.620229 filer_grpc_server_sub_meta.go:119 read on disk filer:172.18.0.5:8888@172.18.0.5:47428 local subscribe / from 2022-08-25 10:08:03.6026842 +0000 UTC s3_1 | I0825 10:09:03.620646 filer_grpc_server_sub_meta.go:138 read in memory filer:172.18.0.5:8888@172.18.0.5:47428 local subscribe / from 2022-08-25 10:08:03.6026842 +0000 UTC  source-file source-file",no-bug,0.95
2371,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2371,[s3] Content Disposition support,"**Describe the bug** ContentDisposition and ResponseContentDisposition parameters are ignored When using s3 api, ContentDisposition is always set to 'inline; filename=<key>' Example with boto3: Setting ContentDisposition during put: python3 s3.put_object(Bucket='test', Key='test.jpeg', Body='test.jpeg', ContentDisposition='attachment; filename=""test.jpeg') {'ResponseMetadata': {'RequestId': '1633946607781063224', 'HostId': '', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:03:27 GMT', 'content-length': '0', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'x-amz-request-id': '1633946607781063224', 'strict-transport-security': 'max-age=15724800; includeSubDomains', }, 'RetryAttempts': 0}, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""'} s3.get_object(Bucket='test', Key='test.jpeg') {'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:03:45 GMT', 'content-type': 'image/jpeg', 'content-length': '9', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'content-disposition': 'inline; filename=""test.jpeg""', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'last-modified': 'Mon, 11 Oct 2021 10:03:27 GMT', 'strict-transport-security': 'max-age=15724800; includeSubDomains', }, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2021, 10, 11, 10, 3, 27, tzinfo=tzutc()), 'ContentLength': 9, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'ContentDisposition': 'inline; filename=""test.jpeg""', 'ContentType': 'image/jpeg', 'Metadata': {}, 'Body': <botocore.response.StreamingBody at 0x1108820d0>}  Setting ResponseContentDisposition: python3 s3.get_object(Bucket='test', Key='test.jpeg', ResponseContentDisposition='attachment; filename=test.jpeg') {'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:07:56 GMT', 'content-type': 'image/jpeg', 'content-length': '9', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'content-disposition': 'inline; filename=""test.jpeg""', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'last-modified': 'Mon, 11 Oct 2021 10:03:27 GMT', 'strict-transport-security': 'max-age=15724800; includeSubDomains' }, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2021, 10, 11, 10, 3, 27, tzinfo=tzutc()), 'ContentLength': 9, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'ContentDisposition': 'inline; filename=""test.jpeg""', 'ContentType': 'image/jpeg', 'Metadata': {}, 'Body': <botocore.response.StreamingBody at 0x110882340>}  **System Setup** seaweedfs 2.70 **Expected behavior** Setting ContentDisposition parameter during put should set the ContentDisposition in object metadata, setting ResponseContentDisposition during get should only set this in reposnse metadata",source-file | source-file | source-file,"[s3] Content Disposition support **Describe the bug** ContentDisposition and ResponseContentDisposition parameters are ignored When using s3 api, ContentDisposition is always set to 'inline; filename=<key>' Example with boto3: Setting ContentDisposition during put: python3 s3.put_object(Bucket='test', Key='test.jpeg', Body='test.jpeg', ContentDisposition='attachment; filename=""test.jpeg') {'ResponseMetadata': {'RequestId': '1633946607781063224', 'HostId': '', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:03:27 GMT', 'content-length': '0', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'x-amz-request-id': '1633946607781063224', 'strict-transport-security': 'max-age=15724800; includeSubDomains', }, 'RetryAttempts': 0}, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""'} s3.get_object(Bucket='test', Key='test.jpeg') {'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:03:45 GMT', 'content-type': 'image/jpeg', 'content-length': '9', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'content-disposition': 'inline; filename=""test.jpeg""', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'last-modified': 'Mon, 11 Oct 2021 10:03:27 GMT', 'strict-transport-security': 'max-age=15724800; includeSubDomains', }, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2021, 10, 11, 10, 3, 27, tzinfo=tzutc()), 'ContentLength': 9, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'ContentDisposition': 'inline; filename=""test.jpeg""', 'ContentType': 'image/jpeg', 'Metadata': {}, 'Body': <botocore.response.StreamingBody at 0x1108820d0>}  Setting ResponseContentDisposition: python3 s3.get_object(Bucket='test', Key='test.jpeg', ResponseContentDisposition='attachment; filename=test.jpeg') {'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:07:56 GMT', 'content-type': 'image/jpeg', 'content-length': '9', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'content-disposition': 'inline; filename=""test.jpeg""', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'last-modified': 'Mon, 11 Oct 2021 10:03:27 GMT', 'strict-transport-security': 'max-age=15724800; includeSubDomains' }, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2021, 10, 11, 10, 3, 27, tzinfo=tzutc()), 'ContentLength': 9, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'ContentDisposition': 'inline; filename=""test.jpeg""', 'ContentType': 'image/jpeg', 'Metadata': {}, 'Body': <botocore.response.StreamingBody at 0x110882340>}  **System Setup** seaweedfs 2.70 **Expected behavior** Setting ContentDisposition parameter during put should set the ContentDisposition in object metadata, setting ResponseContentDisposition during get should only set this in reposnse metadata source-file source-file source-file",bug,0.95
3086,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3086,[s3] put fakedir/ key object,"required for integration with [NextCloud](https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/primary_storage.html) cmd put key  aws --debug --endpoint-url http://127.0.0.1:8333 s3api put-object --bucket test --key fakedir/ 2022-05-21 13:01:18,267 - MainThread - botocore.endpoint - DEBUG - Sending http request: <AWSPreparedRequest stream_output=False, method=PUT, url=http://127.0.0.1:8333/test/fakedir/, headers={'User-Agent': b'aws-cli/2.5.1 Python/3.9.12 Darwin/20.6.0 source/x86_64 prompt/off command/s3api.put-object', 'Content-MD5': b'1B2M2Y8AsgTpgAmY7PhCfg==', 'X-Amz-Date': b'20220521T080118Z', 'X-Amz-Content-SHA256': b'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855', 'Authorization': b'AWS4-HMAC-SHA256 Credential=some_access_key1/20220521/us-west-2/s3/aws4_request, SignedHeaders=content-md5;host;x-amz-content-sha256;x-amz-date, Signature=0e8e0ad443c9fad591a885de961a475f2fb6979bd22500e3e40940b7dedf5dfc', 'Content-Length': '0'}> 2022-05-21 13:01:18,268 - MainThread - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:8333 2022-05-21 13:01:18,274 - MainThread - urllib3.connectionpool - DEBUG - http://127.0.0.1:8333 ""PUT /test/fakedir/ HTTP/1.1"" 200 0 2022-05-21 13:01:18,274 - MainThread - botocore.parsers - DEBUG - Response headers: {'Accept-Ranges': 'bytes', 'Content-Length': '0', 'Server': 'SeaweedFS S3', 'X-Amz-Request-Id': '1653120078293682028', 'Date': 'Sat, 21 May 2022 08:01:18 GMT'} 2022-05-21 13:01:18,274 - MainThread - botocore.parsers - DEBUG - Response body: b'' 2022-05-21 13:01:18,275 - MainThread - botocore.hooks - DEBUG - Event needs-retry.s3.PutObject: calling handler <bound method RetryHandler.needs_retry of <botocore.retries.standard.RetryHandler object at 0x10816ba00>> 2022-05-21 13:01:18,275 - MainThread - botocore.retries.standard - DEBUG - Not retrying request. 2022-05-21 13:01:18,275 - MainThread - botocore.hooks - DEBUG - Event needs-retry.s3.PutObject: calling handler <bound method S3RegionRedirector.redirect_from_error of <botocore.utils.S3RegionRedirector object at 0x10816ba90>> 2022-05-21 13:01:18,275 - MainThread - botocore.hooks - DEBUG - Event after-call.s3.PutObject: calling handler <function enhance_error_msg at 0x103971280> 2022-05-21 13:01:18,275 - MainThread - botocore.hooks - DEBUG - Event after-call.s3.PutObject: calling handler <bound method RetryQuotaChecker.release_retry_quota of <botocore.retries.standard.RetryQuotaChecker object at 0x10816b5b0>> 2022-05-21 13:01:18,275 - MainThread - awscli.formatter - DEBUG - RequestId: 1653120078293682028  logs put key  s3_1 | I0521 07:58:13 1 s3api_object_handlers.go:49] PutObjectHandler test /fakedir/ s3_1 | I0521 07:58:13 1 filer_client.go:234] mkdir: directory:""/buckets"" entry:{name:""test/fakedir/"" is_directory:true attributes:{mtime:1653119893 file_mode:2147484159 crtime:1653119893}} filer_1 | I0521 07:58:13 1 filer_grpc_server.go:138] CreateEntry /buckets/test/fakedir/ filer_1 | I0521 07:58:13 1 filer.go:190] UpdateEntry /buckets/test/fakedir/: old entry: filer_1 | I0521 07:58:13 1 filer.go:202] CreateEntry /buckets/test/fakedir/: created  cmd get key  aws --debug --endpoint-url http://127.0.0.1:8333 s3api get-object --bucket test --key fakedir/ /tmp/fackedir  logs get key with /  s3_1 | I0521 08:05:50 1 s3api_object_handlers.go:136] GetObjectHandler test /fakedir/ s3_1 | I0521 08:05:50 1 error_handler.go:85] status 501 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> s3_1 | <Error><Code>NotImplemented</Code><Message>A header you provided implies functionality that is not implemented</Message><Resource>/test/fakedir/</Resource><RequestId>1653120350340582368</RequestId><Key>fakedir/</Key><BucketName>test</BucketName></Error>  fs.meta.cat  > fs.meta.cat buckets/test/fakedir { ""name"": ""fakedir"", ""isDirectory"": true, ""chunks"": [ ], ""attributes"": { ""fileSize"": ""0"", ""mtime"": ""1653119827"", ""fileMode"": 2147484159, ""uid"": 0, ""gid"": 0, ""crtime"": ""1653119827"", ""mime"": """", ""replication"": """", ""collection"": """", ""ttlSec"": 0, ""userName"": """", ""groupName"": [ ], ""symlinkTarget"": """", ""md5"": null, ""diskType"": """", ""rdev"": 0, ""inode"": ""0"" }, ""extended"": { }, ""hardLinkId"": null, ""hardLinkCounter"": 0, ""content"": null, ""remoteEntry"": null, ""quota"": ""0"" } chunks 0 meta size: 31 gzip:59   aws --debug --endpoint-url http://127.0.0.1:8333 s3api put-object --bucket test --key ""fakedir/."" s3_1 | I0521 08:40:03 1 s3api_object_handlers.go:49] PutObjectHandler test /fakedir/. s3_1 | I0521 08:40:03 1 s3api_object_handlers.go:100] putToFiler uploadUrl: http://filer:8888/buckets/test/fakedir/. filer_1 | I0521 08:40:03 1 filer_server_handlers_read_dir.go:55] listDirectory /buckets/test/fakedir, last file fakedir, limit 100: 1 items s3_1 | E0521 08:40:03 1 s3api_object_handlers.go:414] failing to read upload to http://filer:8888/buckets/test/fakedir/. : <!DOCTYPE html> s3_1 | I0521 08:40:03 1 error_handler.go:85] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> s3_1 | <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/test/fakedir/.</Resource><RequestId>1653122403355812077</RequestId><Key>fakedir/.</Key><BucketName>test</BucketName></Error>  https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/external_storage_configuration_gui.html  s3_1 | I0525 07:54:09 1 s3api_object_handlers.go:49] PutObjectHandler test /nextcloud_external_dir/ s3_1 | I0525 07:54:09 1 filer_server_handlers_read.go:98] Not found /buckets/test/nextcloud_external_dir: filer: no entry is found in filer store s3_1 | E0525 07:54:09 1 s3api_object_handlers.go:416] failing to read upload to http://172.18.0.4:8888/buckets/test/nextcloud_external_dir/. : s3_1 | I0525 07:54:09 1 error_handler.go:85] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> s3_1 | <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/test/nextcloud_external_dir/</Resource><RequestId>1653465249823314600</RequestId><Key>nextcloud_external_dir/</Key><BucketName>test</BucketName></Error>  minio work:  minio:9000 [REQUEST s3.ListObjectsV2] [2022-05-25T16:36:32:000] [Client IP: 172.18.0.6] minio:9000 GET /nextcloud?list-type=2&prefix=folder%2F&max-keys=1 minio:9000 Proto: HTTP/1.1 minio:9000 Host: minio:9000 minio:9000 Aws-Sdk-Retry: 0/0 minio:9000 Content-Length: 0 minio:9000 X-Amz-Content-Sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 minio:9000 Authorization: AWS4-HMAC-SHA256 Credential=some_access_key1/20220525/eu-west-1/s3/aws4_request, SignedHeaders=host;x-amz-content-sha256;x-amz-date;x-amz-user-agent, Signature=b9b57b5dbee317c10d38e3d6fbed47a5e50e8de58a0722d1aefce620f60e5043 minio:9000 Aws-Sdk-Invocation-Id: 553ad64750d8847d39090f67e71231a5 minio:9000 User-Agent: aws-sdk-php/3.212.2 OS/Linux/5.10.25-linuxkit lang/php/8.0.18 GuzzleHttp/7 minio:9000 X-Amz-Date: 20220525T113632Z minio:9000 X-Amz-User-Agent: aws-sdk-php/3.212.2 minio:9000 minio:9000 [RESPONSE] [2022-05-25T16:36:32:000] [ Duration 684s  130 B  901 B ] minio:9000 200 OK minio:9000 Accept-Ranges: bytes minio:9000 X-Amz-Request-Id: 16F25604EA79315C minio:9000 X-Xss-Protection: 1; mode=block minio:9000 Content-Length: 585 minio:9000 Content-Security-Policy: block-all-mixed-content minio:9000 Content-Type: application/xml minio:9000 Server: MinIO minio:9000 Strict-Transport-Security: max-age=31536000; includeSubDomains minio:9000 Vary: Origin,Accept-Encoding minio:9000 X-Content-Type-Options: nosniff minio:9000 <?xml version=""1.0"" encoding=""UTF-8""?> <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Name>nextcloud</Name><Prefix>folder/</Prefix><KeyCount>1</KeyCount><MaxKeys>1</MaxKeys><Delimiter></Delimiter><IsTruncated>false</IsTruncated><Contents><Key>folder/</Key><LastModified>2022-05-25T11:36:32.178Z</LastModified><ETag>&#34;d41d8cd98f00b204e9800998ecf8427e&#34;</ETag><Size>0</Size><Owner><ID>02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4</ID><DisplayName>minio</DisplayName></Owner><StorageClass>STANDARD</StorageClass></Contents></ListBucketResult> minio:9000 ",other-file | config-file | database-file | source-file | source-file | source-file | test-file | documentation-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file,"[s3] put fakedir/ key object required for integration with [NextCloud](https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/primary_storage.html) cmd put key  aws --debug --endpoint-url http://127.0.0.1:8333 s3api put-object --bucket test --key fakedir/ 2022-05-21 13:01:18,267 - MainThread - botocore.endpoint - DEBUG - Sending http request: <AWSPreparedRequest stream_output=False, method=PUT, url=http://127.0.0.1:8333/test/fakedir/, headers={'User-Agent': b'aws-cli/2.5.1 Python/3.9.12 Darwin/20.6.0 source/x86_64 prompt/off command/s3api.put-object', 'Content-MD5': b'1B2M2Y8AsgTpgAmY7PhCfg==', 'X-Amz-Date': b'20220521T080118Z', 'X-Amz-Content-SHA256': b'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855', 'Authorization': b'AWS4-HMAC-SHA256 Credential=some_access_key1/20220521/us-west-2/s3/aws4_request, SignedHeaders=content-md5;host;x-amz-content-sha256;x-amz-date, Signature=0e8e0ad443c9fad591a885de961a475f2fb6979bd22500e3e40940b7dedf5dfc', 'Content-Length': '0'}> 2022-05-21 13:01:18,268 - MainThread - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:8333 2022-05-21 13:01:18,274 - MainThread - urllib3.connectionpool - DEBUG - http://127.0.0.1:8333 ""PUT /test/fakedir/ HTTP/1.1"" 200 0 2022-05-21 13:01:18,274 - MainThread - botocore.parsers - DEBUG - Response headers: {'Accept-Ranges': 'bytes', 'Content-Length': '0', 'Server': 'SeaweedFS S3', 'X-Amz-Request-Id': '1653120078293682028', 'Date': 'Sat, 21 May 2022 08:01:18 GMT'} 2022-05-21 13:01:18,274 - MainThread - botocore.parsers - DEBUG - Response body: b'' 2022-05-21 13:01:18,275 - MainThread - botocore.hooks - DEBUG - Event needs-retry.s3.PutObject: calling handler <bound method RetryHandler.needs_retry of <botocore.retries.standard.RetryHandler object at 0x10816ba00>> 2022-05-21 13:01:18,275 - MainThread - botocore.retries.standard - DEBUG - Not retrying request. 2022-05-21 13:01:18,275 - MainThread - botocore.hooks - DEBUG - Event needs-retry.s3.PutObject: calling handler <bound method S3RegionRedirector.redirect_from_error of <botocore.utils.S3RegionRedirector object at 0x10816ba90>> 2022-05-21 13:01:18,275 - MainThread - botocore.hooks - DEBUG - Event after-call.s3.PutObject: calling handler <function enhance_error_msg at 0x103971280> 2022-05-21 13:01:18,275 - MainThread - botocore.hooks - DEBUG - Event after-call.s3.PutObject: calling handler <bound method RetryQuotaChecker.release_retry_quota of <botocore.retries.standard.RetryQuotaChecker object at 0x10816b5b0>> 2022-05-21 13:01:18,275 - MainThread - awscli.formatter - DEBUG - RequestId: 1653120078293682028  logs put key  s3_1 | I0521 07:58:13 1 s3api_object_handlers.go:49] PutObjectHandler test /fakedir/ s3_1 | I0521 07:58:13 1 filer_client.go:234] mkdir: directory:""/buckets"" entry:{name:""test/fakedir/"" is_directory:true attributes:{mtime:1653119893 file_mode:2147484159 crtime:1653119893}} filer_1 | I0521 07:58:13 1 filer_grpc_server.go:138] CreateEntry /buckets/test/fakedir/ filer_1 | I0521 07:58:13 1 filer.go:190] UpdateEntry /buckets/test/fakedir/: old entry: filer_1 | I0521 07:58:13 1 filer.go:202] CreateEntry /buckets/test/fakedir/: created  cmd get key  aws --debug --endpoint-url http://127.0.0.1:8333 s3api get-object --bucket test --key fakedir/ /tmp/fackedir  logs get key with /  s3_1 | I0521 08:05:50 1 s3api_object_handlers.go:136] GetObjectHandler test /fakedir/ s3_1 | I0521 08:05:50 1 error_handler.go:85] status 501 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> s3_1 | <Error><Code>NotImplemented</Code><Message>A header you provided implies functionality that is not implemented</Message><Resource>/test/fakedir/</Resource><RequestId>1653120350340582368</RequestId><Key>fakedir/</Key><BucketName>test</BucketName></Error>  fs.meta.cat  > fs.meta.cat buckets/test/fakedir { ""name"": ""fakedir"", ""isDirectory"": true, ""chunks"": [ ], ""attributes"": { ""fileSize"": ""0"", ""mtime"": ""1653119827"", ""fileMode"": 2147484159, ""uid"": 0, ""gid"": 0, ""crtime"": ""1653119827"", ""mime"": """", ""replication"": """", ""collection"": """", ""ttlSec"": 0, ""userName"": """", ""groupName"": [ ], ""symlinkTarget"": """", ""md5"": null, ""diskType"": """", ""rdev"": 0, ""inode"": ""0"" }, ""extended"": { }, ""hardLinkId"": null, ""hardLinkCounter"": 0, ""content"": null, ""remoteEntry"": null, ""quota"": ""0"" } chunks 0 meta size: 31 gzip:59   aws --debug --endpoint-url http://127.0.0.1:8333 s3api put-object --bucket test --key ""fakedir/."" s3_1 | I0521 08:40:03 1 s3api_object_handlers.go:49] PutObjectHandler test /fakedir/. s3_1 | I0521 08:40:03 1 s3api_object_handlers.go:100] putToFiler uploadUrl: http://filer:8888/buckets/test/fakedir/. filer_1 | I0521 08:40:03 1 filer_server_handlers_read_dir.go:55] listDirectory /buckets/test/fakedir, last file fakedir, limit 100: 1 items s3_1 | E0521 08:40:03 1 s3api_object_handlers.go:414] failing to read upload to http://filer:8888/buckets/test/fakedir/. : <!DOCTYPE html> s3_1 | I0521 08:40:03 1 error_handler.go:85] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> s3_1 | <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/test/fakedir/.</Resource><RequestId>1653122403355812077</RequestId><Key>fakedir/.</Key><BucketName>test</BucketName></Error>  https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/external_storage_configuration_gui.html  s3_1 | I0525 07:54:09 1 s3api_object_handlers.go:49] PutObjectHandler test /nextcloud_external_dir/ s3_1 | I0525 07:54:09 1 filer_server_handlers_read.go:98] Not found /buckets/test/nextcloud_external_dir: filer: no entry is found in filer store s3_1 | E0525 07:54:09 1 s3api_object_handlers.go:416] failing to read upload to http://172.18.0.4:8888/buckets/test/nextcloud_external_dir/. : s3_1 | I0525 07:54:09 1 error_handler.go:85] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> s3_1 | <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/test/nextcloud_external_dir/</Resource><RequestId>1653465249823314600</RequestId><Key>nextcloud_external_dir/</Key><BucketName>test</BucketName></Error>  minio work:  minio:9000 [REQUEST s3.ListObjectsV2] [2022-05-25T16:36:32:000] [Client IP: 172.18.0.6] minio:9000 GET /nextcloud?list-type=2&prefix=folder%2F&max-keys=1 minio:9000 Proto: HTTP/1.1 minio:9000 Host: minio:9000 minio:9000 Aws-Sdk-Retry: 0/0 minio:9000 Content-Length: 0 minio:9000 X-Amz-Content-Sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 minio:9000 Authorization: AWS4-HMAC-SHA256 Credential=some_access_key1/20220525/eu-west-1/s3/aws4_request, SignedHeaders=host;x-amz-content-sha256;x-amz-date;x-amz-user-agent, Signature=b9b57b5dbee317c10d38e3d6fbed47a5e50e8de58a0722d1aefce620f60e5043 minio:9000 Aws-Sdk-Invocation-Id: 553ad64750d8847d39090f67e71231a5 minio:9000 User-Agent: aws-sdk-php/3.212.2 OS/Linux/5.10.25-linuxkit lang/php/8.0.18 GuzzleHttp/7 minio:9000 X-Amz-Date: 20220525T113632Z minio:9000 X-Amz-User-Agent: aws-sdk-php/3.212.2 minio:9000 minio:9000 [RESPONSE] [2022-05-25T16:36:32:000] [ Duration 684s  130 B  901 B ] minio:9000 200 OK minio:9000 Accept-Ranges: bytes minio:9000 X-Amz-Request-Id: 16F25604EA79315C minio:9000 X-Xss-Protection: 1; mode=block minio:9000 Content-Length: 585 minio:9000 Content-Security-Policy: block-all-mixed-content minio:9000 Content-Type: application/xml minio:9000 Server: MinIO minio:9000 Strict-Transport-Security: max-age=31536000; includeSubDomains minio:9000 Vary: Origin,Accept-Encoding minio:9000 X-Content-Type-Options: nosniff minio:9000 <?xml version=""1.0"" encoding=""UTF-8""?> <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Name>nextcloud</Name><Prefix>folder/</Prefix><KeyCount>1</KeyCount><MaxKeys>1</MaxKeys><Delimiter></Delimiter><IsTruncated>false</IsTruncated><Contents><Key>folder/</Key><LastModified>2022-05-25T11:36:32.178Z</LastModified><ETag>&#34;d41d8cd98f00b204e9800998ecf8427e&#34;</ETag><Size>0</Size><Owner><ID>02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4</ID><DisplayName>minio</DisplayName></Owner><StorageClass>STANDARD</StorageClass></Contents></ListBucketResult> minio:9000  other-file config-file database-file source-file source-file source-file test-file documentation-file test-file source-file source-file source-file source-file source-file source-file",no-bug,0.7
3560,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3560,[filer] DATA RACE isSameDataCenter,https://github.com/seaweedfs/seaweedfs/issues/3507   WARNING: DATA RACE Read at 0x00c0005f2dc8 by goroutine 5275902: github.com/seaweedfs/seaweedfs/weed/wdclient.(*vidMap).isSameDataCenter() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/vid_map.go:66 +0x47b github.com/seaweedfs/seaweedfs/weed/wdclient.(*vidMap).LookupVolumeServerUrl() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/vid_map.go:85 +0x467 github.com/seaweedfs/seaweedfs/weed/wdclient.(*vidMap).LookupFileId() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/vid_map.go:107 +0x15a github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).LookupFileIdWithFallback() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:60 +0x84 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).LookupFileIdWithFallback-fm() <autogenerated>:1 +0x59 github.com/seaweedfs/seaweedfs/weed/filer.StreamContentWithThrottler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/stream.go:85 +0xdcf github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).GetOrHeadHandler.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_read.go:246 +0x80c github.com/seaweedfs/seaweedfs/weed/server.processRangeRequest() /go/src/github.com/seaweedfs/seaweedfs/weed/server/common.go:286 +0x3f9 github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).GetOrHeadHandler() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_read.go:222 +0x1f0a github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:54 +0x947 github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() <autogenerated>:1 +0x57 net/http.HandlerFunc.ServeHTTP() /usr/local/go/src/net/http/server.go:2109 +0x4d net/http.(*ServeMux).ServeHTTP() /usr/local/go/src/net/http/server.go:2487 +0xc5 net/http.serverHandler.ServeHTTP() /usr/local/go/src/net/http/server.go:2947 +0x641 net/http.(*conn).serve() /usr/local/go/src/net/http/server.go:1991 +0xbe4 net/http.(*Server).Serve.func3() /usr/local/go/src/net/http/server.go:3102 +0x58 Previous write at 0x00c0005f2dc8 by goroutine 126: github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).resetVidMap() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:309 +0x1546 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:216 +0x11f5 github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:173 +0x27e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:162 +0xe4 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:128 +0x129 github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39 Goroutine 5275902 (running) created at: net/http.(*Server).Serve() /usr/local/go/src/net/http/server.go:3102 +0x837 github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler.func3() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:308 +0x1b1 Goroutine 126 (running) created at: github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0xee4 github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:227 +0xcf7 github.com/seaweedfs/seaweedfs/weed/command.runFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x892 main.main() /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943  ,source-file,[filer] DATA RACE isSameDataCenter https://github.com/seaweedfs/seaweedfs/issues/3507   WARNING: DATA RACE Read at 0x00c0005f2dc8 by goroutine 5275902: github.com/seaweedfs/seaweedfs/weed/wdclient.(*vidMap).isSameDataCenter() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/vid_map.go:66 +0x47b github.com/seaweedfs/seaweedfs/weed/wdclient.(*vidMap).LookupVolumeServerUrl() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/vid_map.go:85 +0x467 github.com/seaweedfs/seaweedfs/weed/wdclient.(*vidMap).LookupFileId() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/vid_map.go:107 +0x15a github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).LookupFileIdWithFallback() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:60 +0x84 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).LookupFileIdWithFallback-fm() <autogenerated>:1 +0x59 github.com/seaweedfs/seaweedfs/weed/filer.StreamContentWithThrottler() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/stream.go:85 +0xdcf github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).GetOrHeadHandler.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_read.go:246 +0x80c github.com/seaweedfs/seaweedfs/weed/server.processRangeRequest() /go/src/github.com/seaweedfs/seaweedfs/weed/server/common.go:286 +0x3f9 github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).GetOrHeadHandler() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers_read.go:222 +0x1f0a github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server_handlers.go:54 +0x947 github.com/seaweedfs/seaweedfs/weed/server.(*FilerServer).filerHandler-fm() <autogenerated>:1 +0x57 net/http.HandlerFunc.ServeHTTP() /usr/local/go/src/net/http/server.go:2109 +0x4d net/http.(*ServeMux).ServeHTTP() /usr/local/go/src/net/http/server.go:2487 +0xc5 net/http.serverHandler.ServeHTTP() /usr/local/go/src/net/http/server.go:2947 +0x641 net/http.(*conn).serve() /usr/local/go/src/net/http/server.go:1991 +0xbe4 net/http.(*Server).Serve.func3() /usr/local/go/src/net/http/server.go:3102 +0x58 Previous write at 0x00c0005f2dc8 by goroutine 126: github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).resetVidMap() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:309 +0x1546 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:216 +0x11f5 github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient.func1() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:209 +0x88 github.com/seaweedfs/seaweedfs/weed/pb.WithGrpcClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:149 +0x248 github.com/seaweedfs/seaweedfs/weed/pb.WithMasterClient() /go/src/github.com/seaweedfs/seaweedfs/weed/pb/grpc_client_server.go:207 +0xd1 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryConnectToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:173 +0x27e github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).tryAllMasters() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:162 +0xe4 github.com/seaweedfs/seaweedfs/weed/wdclient.(*MasterClient).KeepConnectedToMaster() /go/src/github.com/seaweedfs/seaweedfs/weed/wdclient/masterclient.go:128 +0x129 github.com/seaweedfs/seaweedfs/weed/filer.(*Filer).KeepMasterClientConnected() /go/src/github.com/seaweedfs/seaweedfs/weed/filer/filer.go:146 +0x45 github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer.func4() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0x39 Goroutine 5275902 (running) created at: net/http.(*Server).Serve() /usr/local/go/src/net/http/server.go:3102 +0x837 github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler.func3() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:308 +0x1b1 Goroutine 126 (running) created at: github.com/seaweedfs/seaweedfs/weed/server.NewFilerServer() /go/src/github.com/seaweedfs/seaweedfs/weed/server/filer_server.go:131 +0xee4 github.com/seaweedfs/seaweedfs/weed/command.(*FilerOptions).startFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:227 +0xcf7 github.com/seaweedfs/seaweedfs/weed/command.runFiler() /go/src/github.com/seaweedfs/seaweedfs/weed/command/filer.go:203 +0x892 main.main() /go/src/github.com/seaweedfs/seaweedfs/weed/weed.go:81 +0x943   source-file,no-bug,0.9
6180,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6180,Chunk was not found after creation,"**Describe the bug** In rare cases chunks are lost on volume. Chronology of events: - writing the object - chunk and meta are created - trying to get an object - we get an error from the volume server: ""404 Not Found"" - deleting an object I'm attaching a log from the filer. 15419,125fdba732959c7a corresponds to the file /buckets/data/commits/9fd45ae7a5f8.tmp [filer.log](https://github.com/user-attachments/files/17574846/filer.log) **System Setup** We have SeaweedFS running on Kubernetes via SeaweedFS Operator. There are 3 Masters, 48 Volume Servers, 32 Filers (with Scylla as its backend) - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"": Master:  weed -logtostderr=true master -volumeSizeLimitMB=30720 -defaultReplication=001 -ip=$(POD_NAME).seaweedfs1-test-master-peer.seaweedfs-test -peers=seaweedfs1-test-master-0.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-1.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-2.seaweedfs1-test-master-peer.seaweedfs-test:9333 -metricsPort=9999`  Volume Server:  weed -logtostderr=true volume -port=8444 -max=0 -ip=$(POD_NAME).seaweedfs1-test-volume-peer.seaweedfs-test -metricsPort=9999 -mserver=seaweedfs1-test-master-0.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-1.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-2.seaweedfs1-test-master-peer.seaweedfs-test:9333 -dir=/data0 -concurrentDownloadLimitMB=0 -concurrentUploadLimitMB=0`  Filer:  weed -logtostderr=true filer -port=8888 -ip=$(POD_NAME).seaweedfs1-test-filer-peer.seaweedfs-test -master=seaweedfs1-test-master-0.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-1.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-2.seaweedfs1-test-master-peer.seaweedfs-test:9333 -metricsPort=9999 -s3 -concurrentUploadLimitMB=0  - OS version: Fedora CoreOS 33.20210426.3.0 - output of `weed version`: version 8000GB 3.77 - if using filer, show the content of `filer.toml`:  [leveldb2] enabled = false [etcd] enabled = false servers = ""seaweed-etcd.seaweedfs:2379"" timeout = ""3s"" [cassandra] enabled = true keyspace=""seaweedfs"" hosts=[ ""seaweed-scylla-client.seaweedfs:9042"", ] superLargeDirectories = [ ]  **Expected behavior** There should be no arbitrary deletion of chunks",source-file | source-file,"Chunk was not found after creation **Describe the bug** In rare cases chunks are lost on volume. Chronology of events: - writing the object - chunk and meta are created - trying to get an object - we get an error from the volume server: ""404 Not Found"" - deleting an object I'm attaching a log from the filer. 15419,125fdba732959c7a corresponds to the file /buckets/data/commits/9fd45ae7a5f8.tmp [filer.log](https://github.com/user-attachments/files/17574846/filer.log) **System Setup** We have SeaweedFS running on Kubernetes via SeaweedFS Operator. There are 3 Masters, 48 Volume Servers, 32 Filers (with Scylla as its backend) - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"": Master:  weed -logtostderr=true master -volumeSizeLimitMB=30720 -defaultReplication=001 -ip=$(POD_NAME).seaweedfs1-test-master-peer.seaweedfs-test -peers=seaweedfs1-test-master-0.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-1.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-2.seaweedfs1-test-master-peer.seaweedfs-test:9333 -metricsPort=9999`  Volume Server:  weed -logtostderr=true volume -port=8444 -max=0 -ip=$(POD_NAME).seaweedfs1-test-volume-peer.seaweedfs-test -metricsPort=9999 -mserver=seaweedfs1-test-master-0.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-1.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-2.seaweedfs1-test-master-peer.seaweedfs-test:9333 -dir=/data0 -concurrentDownloadLimitMB=0 -concurrentUploadLimitMB=0`  Filer:  weed -logtostderr=true filer -port=8888 -ip=$(POD_NAME).seaweedfs1-test-filer-peer.seaweedfs-test -master=seaweedfs1-test-master-0.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-1.seaweedfs1-test-master-peer.seaweedfs-test:9333,seaweedfs1-test-master-2.seaweedfs1-test-master-peer.seaweedfs-test:9333 -metricsPort=9999 -s3 -concurrentUploadLimitMB=0  - OS version: Fedora CoreOS 33.20210426.3.0 - output of `weed version`: version 8000GB 3.77 - if using filer, show the content of `filer.toml`:  [leveldb2] enabled = false [etcd] enabled = false servers = ""seaweed-etcd.seaweedfs:2379"" timeout = ""3s"" [cassandra] enabled = true keyspace=""seaweedfs"" hosts=[ ""seaweed-scylla-client.seaweedfs:9042"", ] superLargeDirectories = [ ]  **Expected behavior** There should be no arbitrary deletion of chunks source-file source-file",no-bug,0.9
2642,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2642,"[Bug]- weed couldn't estimate the free space of destination disks for transferring ec shards even after adjusting ""Max"" option to 0","Hi, @chrislusf Based on our conversation about [this issue](https://github.com/chrislusf/seaweedfs/issues/2606), I reconfigure my cluster config and I adjust the ""Max "" option to ""0"" and weed examined the best number for it based on the disk size, for example, my disk has 7.3 TB of space and weed adjusted max parameter to 73 It's good but in some disks, with the same amount of space it sets the max number to 218 or even more for example weed-volume-005.local:8082 has 7.3TB but weed adjust 218 caused an error for transferring shards. This is because of the count of volumes that were in that specific disks This will cause problems in encoding volumes to ec shards and even concurrency about some volumes of a collection (because volumes of that collection are not filled to weed create a new one and disk is full and weed couldn't accept more objects and files to save on volumes) ![image](https://user-images.githubusercontent.com/43205944/152804414-8f6154cb-2d01-4448-a2cb-b363ac09bd15.png) I test ec.encode again and I got the error about it: weed-volume-005.local:8082 is the one that has 218 volume and cause the following error:  > ec.encode -collection 'Channel_20' -volumeId ""811"" -parallelCopy false markVolumeReadonly 811 on weed-volume-002.local:8085  markVolumeReadonly 811 on weed-volume-001.local:8080  generateEcShards Channel_20 811 on weed-volume-002.local:8085  parallelCopyEcShardsFromSource 811 weed-volume-002.local:8085 allocate 811.[4] weed-volume-002.local:8085 => weed-volume-028.local:8082 copy 811.[4] weed-volume-002.local:8085 => weed-volume-028.local:8082 allocate 811.[11] weed-volume-002.local:8085 => weed-volume-004.local:8083 copy 811.[11] weed-volume-002.local:8085 => weed-volume-004.local:8083 allocate 811.[10] weed-volume-002.local:8085 => weed-volume-013.local:8082 copy 811.[10] weed-volume-002.local:8085 => weed-volume-013.local:8082 allocate 811.[9] weed-volume-002.local:8085 => weed-volume-001.local:8083 copy 811.[9] weed-volume-002.local:8085 => weed-volume-001.local:8083 allocate 811.[0] weed-volume-002.local:8085 => weed-volume-009.local:8081 copy 811.[0] weed-volume-002.local:8085 => weed-volume-009.local:8081 allocate 811.[3] weed-volume-002.local:8085 => weed-volume-006.local:8081 copy 811.[3] weed-volume-002.local:8085 => weed-volume-006.local:8081 allocate 811.[5] weed-volume-002.local:8085 => weed-volume-005.local:8082 copy 811.[5] weed-volume-002.local:8085 => weed-volume-005.local:8082 allocate 811.[13] weed-volume-002.local:8085 => weed-volume-009.local:8080 allocate 811.[8] weed-volume-002.local:8085 => weed-volume-014.local:8082 allocate 811.[1] weed-volume-002.local:8085 => weed-volume-016.local:8086 allocate 811.[2] weed-volume-002.local:8085 => weed-volume-003.local:8086 allocate 811.[6] weed-volume-002.local:8085 => weed-volume-006.local:8085 allocate 811.[7] weed-volume-002.local:8085 => weed-volume-007.local:8080 copy 811.[13] weed-volume-002.local:8085 => weed-volume-009.local:8080 allocate 811.[12] weed-volume-002.local:8085 => weed-volume-004.local:8080 copy 811.[12] weed-volume-002.local:8085 => weed-volume-004.local:8080 copy 811.[8] weed-volume-002.local:8085 => weed-volume-014.local:8082 copy 811.[1] weed-volume-002.local:8085 => weed-volume-016.local:8086 copy 811.[2] weed-volume-002.local:8085 => weed-volume-003.local:8086 copy 811.[6] weed-volume-002.local:8085 => weed-volume-006.local:8085 copy 811.[7] weed-volume-002.local:8085 => weed-volume-007.local:8080 mount 811.[4] on weed-volume-028.local:8082 I0207 17:36:36 11508 command_ec_common.go:95] weed-volume-002.local:8085 ec volume 811 deletes shards [4] unmount 811.[5] from weed-volume-005.local:8082 delete 811.[5] from weed-volume-005.local:8082 remove aborted shards 811.[5] on weed-volume-005.local:8082: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[6] from weed-volume-006.local:8085 delete 811.[6] from weed-volume-006.local:8085 remove aborted shards 811.[6] on weed-volume-006.local:8085: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[7] from weed-volume-007.local:8080 delete 811.[7] from weed-volume-007.local:8080 remove aborted shards 811.[7] on weed-volume-007.local:8080: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[8] from weed-volume-014.local:8082 delete 811.[8] from weed-volume-014.local:8082 remove aborted shards 811.[8] on weed-volume-014.local:8082: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[9] from weed-volume-001.local:8083 delete 811.[9] from weed-volume-001.local:8083 remove aborted shards 811.[9] on weed-volume-001.local:8083: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[10] from weed-volume-013.local:8082 delete 811.[10] from weed-volume-013.local:8082 remove aborted shards 811.[10] on weed-volume-013.local:8082: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[11] from weed-volume-004.local:8083 delete 811.[11] from weed-volume-004.local:8083 remove aborted shards 811.[11] on weed-volume-004.local:8083: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[12] from weed-volume-004.local:8080 delete 811.[12] from weed-volume-004.local:8080 remove aborted shards 811.[12] on weed-volume-004.local:8080: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[13] from weed-volume-009.local:8080 delete 811.[13] from weed-volume-009.local:8080 remove aborted shards 811.[13] on weed-volume-009.local:8080: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[0] from weed-volume-009.local:8081 delete 811.[0] from weed-volume-009.local:8081 remove aborted shards 811.[0] on weed-volume-009.local:8081: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[1] from weed-volume-016.local:8086 delete 811.[1] from weed-volume-016.local:8086 remove aborted shards 811.[1] on weed-volume-016.local:8086: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[2] from weed-volume-003.local:8086 delete 811.[2] from weed-volume-003.local:8086 remove aborted shards 811.[2] on weed-volume-003.local:8086: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[3] from weed-volume-006.local:8081 delete 811.[3] from weed-volume-006.local:8081 remove aborted shards 811.[3] on weed-volume-006.local:8081: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[4] from weed-volume-028.local:8082 delete 811.[4] from weed-volume-028.local:8082 error: spread ec shards for volume 811 from weed-volume-002.local:8085: copy 811.[5] weed-volume-002.local:8085 => weed-volume-005.local:8082 : rpc error: code = Unknown des c = no space left  Why weed is trying to transfer shards to a volume with max number of 218 and is filled with 218 volumes? Isn't better for weed to estimate the free space of destination based on the actual free space, not just the count of volumes?",source-file,"[Bug]- weed couldn't estimate the free space of destination disks for transferring ec shards even after adjusting ""Max"" option to 0 Hi, @chrislusf Based on our conversation about [this issue](https://github.com/chrislusf/seaweedfs/issues/2606), I reconfigure my cluster config and I adjust the ""Max "" option to ""0"" and weed examined the best number for it based on the disk size, for example, my disk has 7.3 TB of space and weed adjusted max parameter to 73 It's good but in some disks, with the same amount of space it sets the max number to 218 or even more for example weed-volume-005.local:8082 has 7.3TB but weed adjust 218 caused an error for transferring shards. This is because of the count of volumes that were in that specific disks This will cause problems in encoding volumes to ec shards and even concurrency about some volumes of a collection (because volumes of that collection are not filled to weed create a new one and disk is full and weed couldn't accept more objects and files to save on volumes) ![image](https://user-images.githubusercontent.com/43205944/152804414-8f6154cb-2d01-4448-a2cb-b363ac09bd15.png) I test ec.encode again and I got the error about it: weed-volume-005.local:8082 is the one that has 218 volume and cause the following error:  > ec.encode -collection 'Channel_20' -volumeId ""811"" -parallelCopy false markVolumeReadonly 811 on weed-volume-002.local:8085  markVolumeReadonly 811 on weed-volume-001.local:8080  generateEcShards Channel_20 811 on weed-volume-002.local:8085  parallelCopyEcShardsFromSource 811 weed-volume-002.local:8085 allocate 811.[4] weed-volume-002.local:8085 => weed-volume-028.local:8082 copy 811.[4] weed-volume-002.local:8085 => weed-volume-028.local:8082 allocate 811.[11] weed-volume-002.local:8085 => weed-volume-004.local:8083 copy 811.[11] weed-volume-002.local:8085 => weed-volume-004.local:8083 allocate 811.[10] weed-volume-002.local:8085 => weed-volume-013.local:8082 copy 811.[10] weed-volume-002.local:8085 => weed-volume-013.local:8082 allocate 811.[9] weed-volume-002.local:8085 => weed-volume-001.local:8083 copy 811.[9] weed-volume-002.local:8085 => weed-volume-001.local:8083 allocate 811.[0] weed-volume-002.local:8085 => weed-volume-009.local:8081 copy 811.[0] weed-volume-002.local:8085 => weed-volume-009.local:8081 allocate 811.[3] weed-volume-002.local:8085 => weed-volume-006.local:8081 copy 811.[3] weed-volume-002.local:8085 => weed-volume-006.local:8081 allocate 811.[5] weed-volume-002.local:8085 => weed-volume-005.local:8082 copy 811.[5] weed-volume-002.local:8085 => weed-volume-005.local:8082 allocate 811.[13] weed-volume-002.local:8085 => weed-volume-009.local:8080 allocate 811.[8] weed-volume-002.local:8085 => weed-volume-014.local:8082 allocate 811.[1] weed-volume-002.local:8085 => weed-volume-016.local:8086 allocate 811.[2] weed-volume-002.local:8085 => weed-volume-003.local:8086 allocate 811.[6] weed-volume-002.local:8085 => weed-volume-006.local:8085 allocate 811.[7] weed-volume-002.local:8085 => weed-volume-007.local:8080 copy 811.[13] weed-volume-002.local:8085 => weed-volume-009.local:8080 allocate 811.[12] weed-volume-002.local:8085 => weed-volume-004.local:8080 copy 811.[12] weed-volume-002.local:8085 => weed-volume-004.local:8080 copy 811.[8] weed-volume-002.local:8085 => weed-volume-014.local:8082 copy 811.[1] weed-volume-002.local:8085 => weed-volume-016.local:8086 copy 811.[2] weed-volume-002.local:8085 => weed-volume-003.local:8086 copy 811.[6] weed-volume-002.local:8085 => weed-volume-006.local:8085 copy 811.[7] weed-volume-002.local:8085 => weed-volume-007.local:8080 mount 811.[4] on weed-volume-028.local:8082 I0207 17:36:36 11508 command_ec_common.go:95] weed-volume-002.local:8085 ec volume 811 deletes shards [4] unmount 811.[5] from weed-volume-005.local:8082 delete 811.[5] from weed-volume-005.local:8082 remove aborted shards 811.[5] on weed-volume-005.local:8082: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[6] from weed-volume-006.local:8085 delete 811.[6] from weed-volume-006.local:8085 remove aborted shards 811.[6] on weed-volume-006.local:8085: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[7] from weed-volume-007.local:8080 delete 811.[7] from weed-volume-007.local:8080 remove aborted shards 811.[7] on weed-volume-007.local:8080: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[8] from weed-volume-014.local:8082 delete 811.[8] from weed-volume-014.local:8082 remove aborted shards 811.[8] on weed-volume-014.local:8082: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[9] from weed-volume-001.local:8083 delete 811.[9] from weed-volume-001.local:8083 remove aborted shards 811.[9] on weed-volume-001.local:8083: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[10] from weed-volume-013.local:8082 delete 811.[10] from weed-volume-013.local:8082 remove aborted shards 811.[10] on weed-volume-013.local:8082: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[11] from weed-volume-004.local:8083 delete 811.[11] from weed-volume-004.local:8083 remove aborted shards 811.[11] on weed-volume-004.local:8083: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[12] from weed-volume-004.local:8080 delete 811.[12] from weed-volume-004.local:8080 remove aborted shards 811.[12] on weed-volume-004.local:8080: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[13] from weed-volume-009.local:8080 delete 811.[13] from weed-volume-009.local:8080 remove aborted shards 811.[13] on weed-volume-009.local:8080: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[0] from weed-volume-009.local:8081 delete 811.[0] from weed-volume-009.local:8081 remove aborted shards 811.[0] on weed-volume-009.local:8081: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[1] from weed-volume-016.local:8086 delete 811.[1] from weed-volume-016.local:8086 remove aborted shards 811.[1] on weed-volume-016.local:8086: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[2] from weed-volume-003.local:8086 delete 811.[2] from weed-volume-003.local:8086 remove aborted shards 811.[2] on weed-volume-003.local:8086: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[3] from weed-volume-006.local:8081 delete 811.[3] from weed-volume-006.local:8081 remove aborted shards 811.[3] on weed-volume-006.local:8081: rpc error: code = Internal desc = grpc: error while marshaling: proto: Marshal called with nil unmount 811.[4] from weed-volume-028.local:8082 delete 811.[4] from weed-volume-028.local:8082 error: spread ec shards for volume 811 from weed-volume-002.local:8085: copy 811.[5] weed-volume-002.local:8085 => weed-volume-005.local:8082 : rpc error: code = Unknown des c = no space left  Why weed is trying to transfer shards to a volume with max number of 218 and is filled with 218 volumes? Isn't better for weed to estimate the free space of destination based on the actual free space, not just the count of volumes? source-file",no-bug,0.9
3467,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3467,"Filer if-modified-since check doesn't fire on ""exact""","**Describe the bug** Filer does not return HTTP 304 if the `if-modified-since` value is exact the same as the `Last-Modfied` header **System Setup** - `weed server -dataCenter=$HOSTNAME -ip=$HOSTNAME -master.dir=/meta -master.peers=""app1:9333,app2:9333,app3:9333"" -dir=/data -volume.dir.idx=/meta -volume.index=leveldbLarge -volume.max=0 -rack=1 -filer.encryptVolumeData -volume.fileSizeLimitMB=4096 -master.volumeSizeLimitMB=1024 -filer.defaultReplicaPlacement=100 -filer.saveToFilerLimit=4096 -filer""` - Ubuntu Server **Expected behavior** Filer should return 304: Not modified to save bandwidth **Screenshots** bash system@app2:~$ curl --head --http1.1 -H 'if-modified-since: Thu, 18 Aug 2022 15:40:16 GMT' 'http://localhost:8888/qr-code.svg' HTTP/1.1 304 Not Modified Last-Modified: Thu, 18 Aug 2022 15:40:15 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Fri, 19 Aug 2022 15:29:42 GMT system@app2:~$ curl --head --http1.1 -H 'if-modified-since: Thu, 18 Aug 2022 15:40:15 GMT' 'http://localhost:8888/qr-code.svg' HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Cache-Control: no-cache Content-Disposition: inline; filename=""qr-code.svg"" Content-Length: 209510 Content-Type: image/svg+xml Etag: ""8ab857fb2ea442f951af494a746b1abf"" Last-Modified: Thu, 18 Aug 2022 15:40:15 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Fri, 19 Aug 2022 15:29:50 GMT  **Additional context** Filer will say `HTTP/1.1 304 Not Modified` with a value later than it's own `Last-Modified` but this will most likely never be the same in the case of a browser. I was testing via filer web ui in chrome.",source-file | source-file,"Filer if-modified-since check doesn't fire on ""exact"" **Describe the bug** Filer does not return HTTP 304 if the `if-modified-since` value is exact the same as the `Last-Modfied` header **System Setup** - `weed server -dataCenter=$HOSTNAME -ip=$HOSTNAME -master.dir=/meta -master.peers=""app1:9333,app2:9333,app3:9333"" -dir=/data -volume.dir.idx=/meta -volume.index=leveldbLarge -volume.max=0 -rack=1 -filer.encryptVolumeData -volume.fileSizeLimitMB=4096 -master.volumeSizeLimitMB=1024 -filer.defaultReplicaPlacement=100 -filer.saveToFilerLimit=4096 -filer""` - Ubuntu Server **Expected behavior** Filer should return 304: Not modified to save bandwidth **Screenshots** bash system@app2:~$ curl --head --http1.1 -H 'if-modified-since: Thu, 18 Aug 2022 15:40:16 GMT' 'http://localhost:8888/qr-code.svg' HTTP/1.1 304 Not Modified Last-Modified: Thu, 18 Aug 2022 15:40:15 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Fri, 19 Aug 2022 15:29:42 GMT system@app2:~$ curl --head --http1.1 -H 'if-modified-since: Thu, 18 Aug 2022 15:40:15 GMT' 'http://localhost:8888/qr-code.svg' HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Cache-Control: no-cache Content-Disposition: inline; filename=""qr-code.svg"" Content-Length: 209510 Content-Type: image/svg+xml Etag: ""8ab857fb2ea442f951af494a746b1abf"" Last-Modified: Thu, 18 Aug 2022 15:40:15 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Fri, 19 Aug 2022 15:29:50 GMT  **Additional context** Filer will say `HTTP/1.1 304 Not Modified` with a value later than it's own `Last-Modified` but this will most likely never be the same in the case of a browser. I was testing via filer web ui in chrome. source-file source-file",bug,0.95
3440,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3440,crash in webdav,**Describe the bug** crash in webdav **System Setup** default docker-compose.yml up centos 7 version 30GB 3.20 0854171d linux amd64 **Expected behavior** Files review in webdav **Screenshots** ![image](https://user-images.githubusercontent.com/3724483/184581614-d524539c-01a9-40a0-92f1-ab2fb2fd7106.png) volume permisions ![image](https://user-images.githubusercontent.com/3724483/184581655-5aae2c06-0f12-4c13-9c2a-31a87edb420d.png),source-file,crash in webdav **Describe the bug** crash in webdav **System Setup** default docker-compose.yml up centos 7 version 30GB 3.20 0854171d linux amd64 **Expected behavior** Files review in webdav **Screenshots** ![image](https://user-images.githubusercontent.com/3724483/184581614-d524539c-01a9-40a0-92f1-ab2fb2fd7106.png) volume permisions ![image](https://user-images.githubusercontent.com/3724483/184581655-5aae2c06-0f12-4c13-9c2a-31a87edb420d.png) source-file,no-bug,0.8
3476,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3476,HTTP Filer truncates uploads which begin with /etc,"The built-in http server in `filer` cannot handle uploads where the root of the path begins with `/etc`. The file is always truncated to `4MB`. Tested using `Docker version 20.10.12-ce, build 459d0dfbbb51` on `openSUSE Leap 15.3`. There is a `Makefile` and attached server log at the end of this post. Uploading files with `curl`  dd if=/dev/urandom of=rands bs=1k count=100k curl -F file=@rands http://10.1.0.8:8889/petc33333/etc3 {""name"":""rands"",""size"":104857600} curl -F file=@rands http://10.1.0.8:8889/etc33333/etc3 {""name"":""rands"",""size"":4194304} curl -F file=@rands http://10.1.0.8:8889/petc932 {""name"":""rands"",""size"":104857600} curl -F file=@rands http://10.1.0.8:8889/etc932 {""name"":""rands"",""size"":4194304}  Running a `HEAD` request against each uploaded file.  curl -I http://10.1.0.8:8889/petc33333/etc3 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc3"" Content-Length: 104857600 Etag: ""3b3a28a324f125fb2423f4aa627c1e74"" Last-Modified: Sun, 21 Aug 2022 19:32:01 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/etc33333/etc3 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc3"" Content-Length: 4194304 Etag: ""1d65cef5475887ca24f320e9d7cb5d9f"" Last-Modified: Sun, 21 Aug 2022 19:32:02 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/petc932 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""petc932"" Content-Length: 104857600 Etag: ""3b3a28a324f125fb2423f4aa627c1e74"" Last-Modified: Sun, 21 Aug 2022 19:32:03 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/etc932 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc932"" Content-Length: 4194304 Etag: ""1d65cef5475887ca24f320e9d7cb5d9f"" Last-Modified: Sun, 21 Aug 2022 19:32:03 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT  Makefile to replicate the behavior makefile .PHONY: example upload heads dev-filer HOST:=http://10.1.0.8:8889 dev-filer: docker run -it --rm --name $@ --entrypoint /usr/bin/weed \ -p 8889:8889 -p 6062:6062 \ chrislusf/seaweedfs:3.22 \ -v 2 server -volume.max=5000 -dir=""/data"" -master.volumeSizeLimitMB=2048 -master.electionTimeout 1s -master.port=9444 -volume.port=9445 \ -filer -ip.bind 0.0.0.0 -filer.port=8889 -debug -debug.port 6062 rands: dd if=/dev/urandom of=rands bs=1k count=100k example: upload heads upload: rands curl -F file=@rands ${HOST}/petc33333/etc3 @echo curl -F file=@rands ${HOST}/etc33333/etc3 @echo curl -F file=@rands ${HOST}/petc932 @echo curl -F file=@rands ${HOST}/etc932 @echo @echo heads: curl -I ${HOST}/petc33333/etc3 curl -I ${HOST}/etc33333/etc3 curl -I ${HOST}/petc932 curl -I ${HOST}/etc932  [log.txt](https://github.com/seaweedfs/seaweedfs/files/9389838/log.txt)",source-file | source-file,"HTTP Filer truncates uploads which begin with /etc The built-in http server in `filer` cannot handle uploads where the root of the path begins with `/etc`. The file is always truncated to `4MB`. Tested using `Docker version 20.10.12-ce, build 459d0dfbbb51` on `openSUSE Leap 15.3`. There is a `Makefile` and attached server log at the end of this post. Uploading files with `curl`  dd if=/dev/urandom of=rands bs=1k count=100k curl -F file=@rands http://10.1.0.8:8889/petc33333/etc3 {""name"":""rands"",""size"":104857600} curl -F file=@rands http://10.1.0.8:8889/etc33333/etc3 {""name"":""rands"",""size"":4194304} curl -F file=@rands http://10.1.0.8:8889/petc932 {""name"":""rands"",""size"":104857600} curl -F file=@rands http://10.1.0.8:8889/etc932 {""name"":""rands"",""size"":4194304}  Running a `HEAD` request against each uploaded file.  curl -I http://10.1.0.8:8889/petc33333/etc3 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc3"" Content-Length: 104857600 Etag: ""3b3a28a324f125fb2423f4aa627c1e74"" Last-Modified: Sun, 21 Aug 2022 19:32:01 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/etc33333/etc3 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc3"" Content-Length: 4194304 Etag: ""1d65cef5475887ca24f320e9d7cb5d9f"" Last-Modified: Sun, 21 Aug 2022 19:32:02 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/petc932 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""petc932"" Content-Length: 104857600 Etag: ""3b3a28a324f125fb2423f4aa627c1e74"" Last-Modified: Sun, 21 Aug 2022 19:32:03 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/etc932 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc932"" Content-Length: 4194304 Etag: ""1d65cef5475887ca24f320e9d7cb5d9f"" Last-Modified: Sun, 21 Aug 2022 19:32:03 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT  Makefile to replicate the behavior makefile .PHONY: example upload heads dev-filer HOST:=http://10.1.0.8:8889 dev-filer: docker run -it --rm --name $@ --entrypoint /usr/bin/weed \ -p 8889:8889 -p 6062:6062 \ chrislusf/seaweedfs:3.22 \ -v 2 server -volume.max=5000 -dir=""/data"" -master.volumeSizeLimitMB=2048 -master.electionTimeout 1s -master.port=9444 -volume.port=9445 \ -filer -ip.bind 0.0.0.0 -filer.port=8889 -debug -debug.port 6062 rands: dd if=/dev/urandom of=rands bs=1k count=100k example: upload heads upload: rands curl -F file=@rands ${HOST}/petc33333/etc3 @echo curl -F file=@rands ${HOST}/etc33333/etc3 @echo curl -F file=@rands ${HOST}/petc932 @echo curl -F file=@rands ${HOST}/etc932 @echo @echo heads: curl -I ${HOST}/petc33333/etc3 curl -I ${HOST}/etc33333/etc3 curl -I ${HOST}/petc932 curl -I ${HOST}/etc932  [log.txt](https://github.com/seaweedfs/seaweedfs/files/9389838/log.txt) source-file source-file",bug,0.95
4088,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4088,It is not possible to request a file via master if the volume is in a read-only state,"I have one master server and one volume server, I have moved one of the volumes to the read-only state. The server has lost information about volumes that are in the read-only state. The file can be requested only from the volume server. Procedure of actions: 1) Uploading a file 2) I make the volume read-only  lock volume.marknode 172.16.202.6:8080 -volumeId 3 -readonly unlock  3) Trying to upload a file  wget 172.16.202.6:9333/3,013c6a774d --2022-12-27 11:52:18-- http://172.16.202.6:9333/3,013c6a774d Connecting to 172.16.202.6:9333 connected. HTTP request sent, awaiting response 404 Not Found 2022-12-27 11:52:18 ERROR 404: Not Found.  **System Setup** ./weed master -ip=172.16.202.6 ./weed -v=4 volume -index=leveldb -pprof=true -max=100 -mserver=""172.16.202.6:9333"" -port=8080 -dir=/storage - ubuntu 22/04 - The problem was found on version 3.37, 3.36, 3.28, the latest version on which it works is 3.26 - version 3.27 have problem with set read-only from shell  volume.mark -node 172.16.202.6:8080 -volumeId 3 -readonly error: rpc error: code = Unknown desc = grpc VolumeMarkReadonly with master: 172.16.202.6:9333%!(EXTRA *errors.errorString=set volume 3 to read only on master: rpc error: code = Unimplemented desc = method VolumeMarkReadonly not implemented)  **Expected behavior** I expect that the master will allow requesting files from volumes that have moved to the read-only state.",source-file | source-file,"It is not possible to request a file via master if the volume is in a read-only state I have one master server and one volume server, I have moved one of the volumes to the read-only state. The server has lost information about volumes that are in the read-only state. The file can be requested only from the volume server. Procedure of actions: 1) Uploading a file 2) I make the volume read-only  lock volume.marknode 172.16.202.6:8080 -volumeId 3 -readonly unlock  3) Trying to upload a file  wget 172.16.202.6:9333/3,013c6a774d --2022-12-27 11:52:18-- http://172.16.202.6:9333/3,013c6a774d Connecting to 172.16.202.6:9333 connected. HTTP request sent, awaiting response 404 Not Found 2022-12-27 11:52:18 ERROR 404: Not Found.  **System Setup** ./weed master -ip=172.16.202.6 ./weed -v=4 volume -index=leveldb -pprof=true -max=100 -mserver=""172.16.202.6:9333"" -port=8080 -dir=/storage - ubuntu 22/04 - The problem was found on version 3.37, 3.36, 3.28, the latest version on which it works is 3.26 - version 3.27 have problem with set read-only from shell  volume.mark -node 172.16.202.6:8080 -volumeId 3 -readonly error: rpc error: code = Unknown desc = grpc VolumeMarkReadonly with master: 172.16.202.6:9333%!(EXTRA *errors.errorString=set volume 3 to read only on master: rpc error: code = Unimplemented desc = method VolumeMarkReadonly not implemented)  **Expected behavior** I expect that the master will allow requesting files from volumes that have moved to the read-only state. source-file source-file",bug,0.9
864,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/864,replicas ttl are possibly different,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** ReplicatedWrite do NOT fill ttl paramemter so ttl of replicas is possibly different with the first written one, in light of the following codes https://github.com/chrislusf/seaweedfs/blob/344caf3cd7d2de00469a61ae3bf597b8e9bab726/weed/topology/store_replicate.go#L48 And setting ts when replicatedWrite makes volume servers strongly depend on ntp https://github.com/chrislusf/seaweedfs/blob/344caf3cd7d2de00469a61ae3bf597b8e9bab726/weed/topology/store_replicate.go#L52 **Expected behavior** - ttl of all replicas are the same - remove ts when ReplicatedWrite",source-file | source-file | source-file,"replicas ttl are possibly different Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** ReplicatedWrite do NOT fill ttl paramemter so ttl of replicas is possibly different with the first written one, in light of the following codes https://github.com/chrislusf/seaweedfs/blob/344caf3cd7d2de00469a61ae3bf597b8e9bab726/weed/topology/store_replicate.go#L48 And setting ts when replicatedWrite makes volume servers strongly depend on ntp https://github.com/chrislusf/seaweedfs/blob/344caf3cd7d2de00469a61ae3bf597b8e9bab726/weed/topology/store_replicate.go#L52 **Expected behavior** - ttl of all replicas are the same - remove ts when ReplicatedWrite source-file source-file source-file",no-bug,0.8
2002,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2002,[shell] volume.check.disk skipping readonly volume loop,**Describe the bug** loop  volume.check.disk skipping readonly volume 339 on slow-volume-8.dc1:8080 and slow-volume-7.dc1:8080 skipping readonly volume 339 on slow-volume-8.dc1:8080 and slow-volume-7.dc1:8080 skipping readonly volume 339 on slow-volume-8.dc1:8080 and slow-volume-7.dc1:8080  **System Setup**  2.35  **Expected behavior**  break loop ,source-file,[shell] volume.check.disk skipping readonly volume loop **Describe the bug** loop  volume.check.disk skipping readonly volume 339 on slow-volume-8.dc1:8080 and slow-volume-7.dc1:8080 skipping readonly volume 339 on slow-volume-8.dc1:8080 and slow-volume-7.dc1:8080 skipping readonly volume 339 on slow-volume-8.dc1:8080 and slow-volume-7.dc1:8080  **System Setup**  2.35  **Expected behavior**  break loop  source-file,no-bug,0.9
2387,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2387,[s3] FAILED tests," 2.72    FAIL: s3tests_boto3.functional.test_s3.test_copy_object_ifnonematch_failed  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 13028, in test_copy_object_ifnonematch_failed eq(body, 'bar') AssertionError: 'bar\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00' != 'bar'    FAIL: s3tests_boto3.functional.test_s3.test_object_write_check_etag  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 2094, in test_object_write_check_etag eq(response['ETag'], '""37b51d194a7513e45b56f6524f2d51f2""') AssertionError: '""9997a36a88a451df9f4c4552f8e884fa""' != '""37b51d194a7513e45b56f6524f2d51f2""' >> raise AssertionError(None or ""%r != %r"" % ('""9997a36a88a451df9f4c4552f8e884fa""', '""37b51d194a7513e45b56f6524f2d51f2""'))    FAIL: s3tests_boto3.functional.test_s3.test_object_head_zero_bytes  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 2083, in test_object_head_zero_bytes eq(response['ContentLength'], 0) AssertionError: 512 != 0 >> raise AssertionError(None or ""%r != %r"" % (512, 0)) ",source-file,"[s3] FAILED tests  2.72    FAIL: s3tests_boto3.functional.test_s3.test_copy_object_ifnonematch_failed  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 13028, in test_copy_object_ifnonematch_failed eq(body, 'bar') AssertionError: 'bar\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00' != 'bar'    FAIL: s3tests_boto3.functional.test_s3.test_object_write_check_etag  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 2094, in test_object_write_check_etag eq(response['ETag'], '""37b51d194a7513e45b56f6524f2d51f2""') AssertionError: '""9997a36a88a451df9f4c4552f8e884fa""' != '""37b51d194a7513e45b56f6524f2d51f2""' >> raise AssertionError(None or ""%r != %r"" % ('""9997a36a88a451df9f4c4552f8e884fa""', '""37b51d194a7513e45b56f6524f2d51f2""'))    FAIL: s3tests_boto3.functional.test_s3.test_object_head_zero_bytes  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 2083, in test_object_head_zero_bytes eq(response['ContentLength'], 0) AssertionError: 512 != 0 >> raise AssertionError(None or ""%r != %r"" % (512, 0))  source-file",bug,0.9
2633,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2633,[volume_info] load volume 16.vif file: unmarshal error: unexpected EOF,"weed version  2.87  I got a lot of errors after restarting volumes logs  | Jan 29, 2022 @ 15:09:18.884 | W0129 10:09:17 1 volume_tier.go:31] load volume 286.vif file: unmarshal error: unexpected EOF | fast-volume-0 | Jan 29, 2022 @ 15:09:18.884 | W0129 10:09:17 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-0 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_tier.go:31] load volume 94.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_tier.go:31] load volume 255.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_tier.go:31] load volume 253.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 173.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 172.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 227.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 263.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 185.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.948 | W0129 15:03:36 1 volume_tier.go:31] load volume 52.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.948 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.948 | W0129 15:03:36 1 volume_tier.go:31] load volume 248.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.948 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 223.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 237.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 35.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 36.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 40.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 97.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 18.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 71.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 16.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 133.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 178.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_tier.go:31] load volume 109.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_tier.go:31] load volume 199.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_tier.go:31] load volume 200.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_tier.go:31] load volume 267.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_tier.go:31] load volume 141.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_tier.go:31] load volume 13.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_tier.go:31] load volume 14.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_tier.go:31] load volume 48.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.954 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.954 | W0129 15:03:36 1 volume_tier.go:31] load volume 163.vif file: unmarshal error: unexpected EOF | fast-volume-1   for f in $(ls *.vif); do fc=$(cat $f); if [[ ""${fc: -1}"" != ""}"" ]];then ls -lu $f;cat $f; echo;fi; done -rw-r--r-- 1 root 99 8 Feb 4 07:50 254.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 95.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 172.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 185.vif { ""fil -rw-rw-r-- 1 root 99 8 Feb 4 07:50 65.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 52.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 50.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 232.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 190.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 40.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 36.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 237.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 223.vif { ""fil -rw-rw-r-- 1 root 99 8 Feb 4 07:50 16.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 133.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 199.vif { ""fil -rw-rw-r-- 1 root 99 8 Feb 4 07:49 259.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 109.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 81.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 141.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 44.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 13.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 274.vif { ""fil -rw-rw-r-- 1 root 99 8 Feb 4 07:49 163.vif { ""fil  It seems that somewhere there is not enough fsync for vif files",source-file | source-file | source-file | source-file | source-file,"[volume_info] load volume 16.vif file: unmarshal error: unexpected EOF weed version  2.87  I got a lot of errors after restarting volumes logs  | Jan 29, 2022 @ 15:09:18.884 | W0129 10:09:17 1 volume_tier.go:31] load volume 286.vif file: unmarshal error: unexpected EOF | fast-volume-0 | Jan 29, 2022 @ 15:09:18.884 | W0129 10:09:17 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-0 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_tier.go:31] load volume 94.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_tier.go:31] load volume 255.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.946 | W0129 15:03:36 1 volume_tier.go:31] load volume 253.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 173.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 172.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 227.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 263.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.947 | W0129 15:03:36 1 volume_tier.go:31] load volume 185.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.948 | W0129 15:03:36 1 volume_tier.go:31] load volume 52.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.948 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.948 | W0129 15:03:36 1 volume_tier.go:31] load volume 248.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.948 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 223.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 237.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 35.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 36.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_tier.go:31] load volume 40.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.949 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 97.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 18.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 71.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 16.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 133.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.950 | W0129 15:03:36 1 volume_tier.go:31] load volume 178.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_tier.go:31] load volume 109.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_tier.go:31] load volume 199.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_tier.go:31] load volume 200.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.951 | W0129 15:03:36 1 volume_tier.go:31] load volume 267.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_tier.go:31] load volume 141.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_tier.go:31] load volume 13.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_tier.go:31] load volume 14.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.953 | W0129 15:03:36 1 volume_tier.go:31] load volume 48.vif file: unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.954 | W0129 15:03:36 1 volume_info.go:48] unmarshal error: unexpected EOF | fast-volume-1 | Jan 29, 2022 @ 20:03:42.954 | W0129 15:03:36 1 volume_tier.go:31] load volume 163.vif file: unmarshal error: unexpected EOF | fast-volume-1   for f in $(ls *.vif); do fc=$(cat $f); if [[ ""${fc: -1}"" != ""}"" ]];then ls -lu $f;cat $f; echo;fi; done -rw-r--r-- 1 root 99 8 Feb 4 07:50 254.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 95.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 172.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 185.vif { ""fil -rw-rw-r-- 1 root 99 8 Feb 4 07:50 65.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 52.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 50.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 232.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 190.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 40.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 36.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 237.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 223.vif { ""fil -rw-rw-r-- 1 root 99 8 Feb 4 07:50 16.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 133.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 199.vif { ""fil -rw-rw-r-- 1 root 99 8 Feb 4 07:49 259.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 109.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 81.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 141.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 44.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 13.vif { ""fil -rw-r--r-- 1 root 99 8 Feb 4 07:50 274.vif { ""fil -rw-rw-r-- 1 root 99 8 Feb 4 07:49 163.vif { ""fil  It seems that somewhere there is not enough fsync for vif files source-file source-file source-file source-file source-file",no-bug,0.9
4607,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4607,Custom gRPC ports not honored by master.peers and weed shell envvars,"**Describe the bug** We have elected to use [custom gRPC ports](https://github.com/seaweedfs/seaweedfs/wiki/FAQ#grpc-ports) for each of `master`, `volume`, and `filer` instances. So far, there are two use-cases where weed unable to interpret the port specifications outlined in the FAQ:  A) List of master peers `weed master -peers 10.0.0.1:9333.9334,10.0.0.2:9333,9334,10.0.0.3:9333,9334` In this case, the master will for example try to connect to `http://10.0.0.1:9333.9334` but then fail. Possibly, after splitting on commas, the code directly interprets each string as `HOST:PORT` , without checking if it's `HOST:PORT.gRPC_PORT`.  B) weed shell `sudo docker run --rm -it -e SHELL_FILER=10.0.0.1:9330.9331 -e SHELL_MASTER=10.0.0.1:9333.9334 chrislusf/seaweedfs:3.52 shell fs.verify -v` In this case, the shell will report that it tried and failed to connect to `http://10.0.0.1:9333.9334` ** Apologies, I'd like to paste in the error output but right now when I try to reproduce, shell responds by printing an endless series of dots and I don't know what it's doing and why **System Setup** `version 30GB 3.52 fb4b61036 linux amd64`",source-file | source-file,"Custom gRPC ports not honored by master.peers and weed shell envvars **Describe the bug** We have elected to use [custom gRPC ports](https://github.com/seaweedfs/seaweedfs/wiki/FAQ#grpc-ports) for each of `master`, `volume`, and `filer` instances. So far, there are two use-cases where weed unable to interpret the port specifications outlined in the FAQ:  A) List of master peers `weed master -peers 10.0.0.1:9333.9334,10.0.0.2:9333,9334,10.0.0.3:9333,9334` In this case, the master will for example try to connect to `http://10.0.0.1:9333.9334` but then fail. Possibly, after splitting on commas, the code directly interprets each string as `HOST:PORT` , without checking if it's `HOST:PORT.gRPC_PORT`.  B) weed shell `sudo docker run --rm -it -e SHELL_FILER=10.0.0.1:9330.9331 -e SHELL_MASTER=10.0.0.1:9333.9334 chrislusf/seaweedfs:3.52 shell fs.verify -v` In this case, the shell will report that it tried and failed to connect to `http://10.0.0.1:9333.9334` ** Apologies, I'd like to paste in the error output but right now when I try to reproduce, shell responds by printing an endless series of dots and I don't know what it's doing and why **System Setup** `version 30GB 3.52 fb4b61036 linux amd64` source-file source-file",no-bug,0.9
3515,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3515,[volume] DATA RACE on Created Volume id,https://github.com/seaweedfs/seaweedfs/issues/3507  volume_1 | I0825 10:41:53.044853 store.go:143 In dir /data adds volume:74 collection:yournamehere-ndnlnnt6gnh6x06j-123 replicaPlacement:000 ttl: volume_1 | I0825 10:41:53.045166 volume_loading.go:140 loading memory index /data/yournamehere-ndnlnnt6gnh6x06j-123_74.idx to memory volume_1 | I0825 10:41:53.048117 store.go:147 add volume 74 volume_1 | I0825 10:41:53.048595 volume_grpc_client_to_master.go:172 volume server volume:8080 adds volume 74 master_1 | I0825 10:41:53.049780 volume_layout.go:391 Volume 74 becomes writable master_1 | I0825 10:41:53.050830 volume_growth.go:245 Created Volume 74 on topo:DefaultDataCenter:DefaultRack:volume:8080 volume_1 |  volume_1 | WARNING: DATA RACE volume_1 | Write at 0x00c000890e58 by goroutine 172: volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).Version() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume.go:101 +0x14a volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).syncWrite() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:96 +0x69 volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).writeNeedle2() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:117 +0x5a4 volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Store).WriteVolumeNeedle() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:363 +0xd5 volume_1 | github.com/seaweedfs/seaweedfs/weed/topology.ReplicatedWrite() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/store_replicate.go:48 +0x272 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).PostHandler() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server_handlers_write.go:48 +0x544 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).PostHandler-fm() volume_1 | <autogenerated>:1 +0x57 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server_handlers.go:97 +0x14c7 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler-fm() volume_1 | <autogenerated>:1 +0x57 volume_1 | net/http.HandlerFunc.ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d volume_1 | net/http.(*ServeMux).ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 volume_1 | net/http.serverHandler.ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 volume_1 | net/http.(*conn).serve() volume_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 volume_1 | net/http.(*Server).Serve.func3() volume_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 volume_1 | volume_1 | Previous write at 0x00c000890e58 by goroutine 3584: volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).Version() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume.go:101 +0x5aa volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).doWriteRequest() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:161 +0x5cc volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).syncWrite() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:106 +0x34c volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).writeNeedle2() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:117 +0x5a4 volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Store).WriteVolumeNeedle() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:363 +0xd5 volume_1 | github.com/seaweedfs/seaweedfs/weed/topology.ReplicatedWrite() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/store_replicate.go:48 +0x272 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).PostHandler() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server_handlers_write.go:48 +0x544 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).PostHandler-fm() volume_1 | <autogenerated>:1 +0x57 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server_handlers.go:97 +0x14c7 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler-fm() volume_1 | <autogenerated>:1 +0x57 volume_1 | net/http.HandlerFunc.ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d volume_1 | net/http.(*ServeMux).ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 volume_1 | net/http.serverHandler.ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 volume_1 | net/http.(*conn).serve() volume_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 volume_1 | net/http.(*Server).Serve.func3() volume_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 volume_1 | volume_1 | Goroutine 172 (running) created at: volume_1 | net/http.(*Server).Serve() volume_1 | /usr/local/go/src/net/http/server.go:3102 +0x837 volume_1 | github.com/seaweedfs/seaweedfs/weed/util/httpdown.(*server).serve() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/util/httpdown/http_down.go:293 +0x217 volume_1 | github.com/seaweedfs/seaweedfs/weed/util/httpdown.HTTP.Serve.func2() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/util/httpdown/http_down.go:110 +0x39 volume_1 | volume_1 | Goroutine 3584 (running) created at: volume_1 | net/http.(*Server).Serve() volume_1 | /usr/local/go/src/net/http/server.go:3102 +0x837 volume_1 | github.com/seaweedfs/seaweedfs/weed/util/httpdown.(*server).serve() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/util/httpdown/http_down.go:293 +0x217 volume_1 | github.com/seaweedfs/seaweedfs/weed/util/httpdown.HTTP.Serve.func2() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/util/httpdown/http_down.go:110 +0x39 volume_1 |  ,source-file | source-file,[volume] DATA RACE on Created Volume id https://github.com/seaweedfs/seaweedfs/issues/3507  volume_1 | I0825 10:41:53.044853 store.go:143 In dir /data adds volume:74 collection:yournamehere-ndnlnnt6gnh6x06j-123 replicaPlacement:000 ttl: volume_1 | I0825 10:41:53.045166 volume_loading.go:140 loading memory index /data/yournamehere-ndnlnnt6gnh6x06j-123_74.idx to memory volume_1 | I0825 10:41:53.048117 store.go:147 add volume 74 volume_1 | I0825 10:41:53.048595 volume_grpc_client_to_master.go:172 volume server volume:8080 adds volume 74 master_1 | I0825 10:41:53.049780 volume_layout.go:391 Volume 74 becomes writable master_1 | I0825 10:41:53.050830 volume_growth.go:245 Created Volume 74 on topo:DefaultDataCenter:DefaultRack:volume:8080 volume_1 |  volume_1 | WARNING: DATA RACE volume_1 | Write at 0x00c000890e58 by goroutine 172: volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).Version() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume.go:101 +0x14a volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).syncWrite() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:96 +0x69 volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).writeNeedle2() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:117 +0x5a4 volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Store).WriteVolumeNeedle() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:363 +0xd5 volume_1 | github.com/seaweedfs/seaweedfs/weed/topology.ReplicatedWrite() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/store_replicate.go:48 +0x272 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).PostHandler() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server_handlers_write.go:48 +0x544 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).PostHandler-fm() volume_1 | <autogenerated>:1 +0x57 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server_handlers.go:97 +0x14c7 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler-fm() volume_1 | <autogenerated>:1 +0x57 volume_1 | net/http.HandlerFunc.ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d volume_1 | net/http.(*ServeMux).ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 volume_1 | net/http.serverHandler.ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 volume_1 | net/http.(*conn).serve() volume_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 volume_1 | net/http.(*Server).Serve.func3() volume_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 volume_1 | volume_1 | Previous write at 0x00c000890e58 by goroutine 3584: volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).Version() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume.go:101 +0x5aa volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).doWriteRequest() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:161 +0x5cc volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).syncWrite() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:106 +0x34c volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).writeNeedle2() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_write.go:117 +0x5a4 volume_1 | github.com/seaweedfs/seaweedfs/weed/storage.(*Store).WriteVolumeNeedle() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:363 +0xd5 volume_1 | github.com/seaweedfs/seaweedfs/weed/topology.ReplicatedWrite() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/topology/store_replicate.go:48 +0x272 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).PostHandler() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server_handlers_write.go:48 +0x544 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).PostHandler-fm() volume_1 | <autogenerated>:1 +0x57 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_server_handlers.go:97 +0x14c7 volume_1 | github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler-fm() volume_1 | <autogenerated>:1 +0x57 volume_1 | net/http.HandlerFunc.ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2109 +0x4d volume_1 | net/http.(*ServeMux).ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2487 +0xc5 volume_1 | net/http.serverHandler.ServeHTTP() volume_1 | /usr/local/go/src/net/http/server.go:2947 +0x641 volume_1 | net/http.(*conn).serve() volume_1 | /usr/local/go/src/net/http/server.go:1991 +0xbe4 volume_1 | net/http.(*Server).Serve.func3() volume_1 | /usr/local/go/src/net/http/server.go:3102 +0x58 volume_1 | volume_1 | Goroutine 172 (running) created at: volume_1 | net/http.(*Server).Serve() volume_1 | /usr/local/go/src/net/http/server.go:3102 +0x837 volume_1 | github.com/seaweedfs/seaweedfs/weed/util/httpdown.(*server).serve() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/util/httpdown/http_down.go:293 +0x217 volume_1 | github.com/seaweedfs/seaweedfs/weed/util/httpdown.HTTP.Serve.func2() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/util/httpdown/http_down.go:110 +0x39 volume_1 | volume_1 | Goroutine 3584 (running) created at: volume_1 | net/http.(*Server).Serve() volume_1 | /usr/local/go/src/net/http/server.go:3102 +0x837 volume_1 | github.com/seaweedfs/seaweedfs/weed/util/httpdown.(*server).serve() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/util/httpdown/http_down.go:293 +0x217 volume_1 | github.com/seaweedfs/seaweedfs/weed/util/httpdown.HTTP.Serve.func2() volume_1 | /go/src/github.com/seaweedfs/seaweedfs/weed/util/httpdown/http_down.go:110 +0x39 volume_1 |   source-file source-file,no-bug,0.9
3255,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3255,[volumeServer.evacuate] evacuate with balance,evacuate moves all volumes to one not the most empty server balance  error: tail volume 560 from fast-volume-1.s3-fast-volume:8080 to fast-volume-7.s3-fast-volume:8080: rpc error: code = Unknown desc = streamFollow: fail to locate by appendAtNs 1656413146000000000: read entry 56: EOF ,source-file,[volumeServer.evacuate] evacuate with balance evacuate moves all volumes to one not the most empty server balance  error: tail volume 560 from fast-volume-1.s3-fast-volume:8080 to fast-volume-7.s3-fast-volume:8080: rpc error: code = Unknown desc = streamFollow: fail to locate by appendAtNs 1656413146000000000: read entry 56: EOF  source-file,no-bug,0.8
6278,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6278,[master] failed to find writable volumes in specific DC and Rack,"**Describe the bug** 6 RPS errors:  I1124 22:23:24.564072 master_grpc_server_assign.go:133 assign count:1 replication:""100"" collection:""js"" data_center:""dc7"" rack:""F14"" {""collection"":""js"",""replication"":{""dc"":1},""ttl"":{""Count"":0,""Unit"":0},""dataCenter"":""dc7"",""rack"":""F14""}: failed to find writable volumes for collection:js replication:100 ttl: error: No writable volumes in DataCenter:dc7 Rack:F14 DataNode:  **System Setup**  3.77  **Expected behavior** We check that there is writable volume in each DC + Rack layout",source-file | source-file | source-file,"[master] failed to find writable volumes in specific DC and Rack **Describe the bug** 6 RPS errors:  I1124 22:23:24.564072 master_grpc_server_assign.go:133 assign count:1 replication:""100"" collection:""js"" data_center:""dc7"" rack:""F14"" {""collection"":""js"",""replication"":{""dc"":1},""ttl"":{""Count"":0,""Unit"":0},""dataCenter"":""dc7"",""rack"":""F14""}: failed to find writable volumes for collection:js replication:100 ttl: error: No writable volumes in DataCenter:dc7 Rack:F14 DataNode:  **System Setup**  3.77  **Expected behavior** We check that there is writable volume in each DC + Rack layout source-file source-file source-file",no-bug,0.9
94,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/94,What is the name of this project?,"I'm looking to create a Docker image for this project, and maybe some OS-level packages as well. The trouble is, the naming around this project, with regards to its binary, its repo, and its documentation, are contradictory: the documentation refers to it as ""Seaweed-FS"", its name on sites like bintray is ""seaweed"", its repo name on GitHub is ""weed-fs"", and the name of its binary is ""weed"". I want to call this project ""seaweed"", while its daemon name is ""weed"", in a similar fashion to how the ""MongoDB"" project's binaries are called ""mongos"" and ""mongod"". With this, the name for Docker images for this would be called ""seaweed"", and the package names to install this would be ""seaweed"". Should there be a different name for external packages? If so, what should this name be?",documentation-file | documentation-file | documentation-file,"What is the name of this project? I'm looking to create a Docker image for this project, and maybe some OS-level packages as well. The trouble is, the naming around this project, with regards to its binary, its repo, and its documentation, are contradictory: the documentation refers to it as ""Seaweed-FS"", its name on sites like bintray is ""seaweed"", its repo name on GitHub is ""weed-fs"", and the name of its binary is ""weed"". I want to call this project ""seaweed"", while its daemon name is ""weed"", in a similar fashion to how the ""MongoDB"" project's binaries are called ""mongos"" and ""mongod"". With this, the name for Docker images for this would be called ""seaweed"", and the package names to install this would be ""seaweed"". Should there be a different name for external packages? If so, what should this name be? documentation-file documentation-file documentation-file",no-bug,0.95
1080,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1080,HCFS -put gives java.lang.NoSuchFieldError: INSTANCE,"**Describe the bug** I started a filer and tried to run -put as follows: `hdfs dfs -Djava.net.preferIPv4Stack=true -Dfs.seaweedfs.impl=seaweed.hdfs.SeaweedFileSystem -libjars ./seaweedfs-hadoop2-client-1.1.6.jar -put /tmp/testing seaweedfs://10.49.74.155:8888/tmp/testing ` And I get this exception `put: java.util.concurrent.ExecutionException: java.lang.NoSuchFieldError: INSTANCE` **System Setup** - Ran ./weed server -filer=true - Centos 7.5 - version 30GB 1.43 linux amd64 - leveldb2 is only thing enabled in `filer.toml`  [leveldb2] enabled = true dir = ""/data0/weed/storage""  **Expected behavior** I'd expect the file to be put into the FS. I do see a reference to INSTANCE here in context of the SSLFactory which is where I believe this is coming from: https://github.com/chrislusf/seaweedfs/blob/cb299dfaa279e14def8bf3f26816913213a91097/other/java/client/src/main/java/seaweedfs/client/FilerSslContext.java#L62  Okay so the above was from using a node with Cloudera CDH Hadoop which is what I'd like to get to work. Potentially could be an issue with multiple jars on the path? When I use a default Apache Hadoop download both hdfs 2 and 3 binaries and run the same hdfs dfs put command I get the below exception (hdfs dfs -ls works on the seaweedfs filer without issue):  put: java.util.concurrent.ExecutionException: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8080 [localhost/127.0.0.1] failed: Connection refused (Connection refused)  The default Apache Hadoop issue with put has something to do with getting the wrong url for the volume server to write to. I ran the put on the same machine as the server/volumes/filer and that went through. I did try setting the publicIP of volume server on starting the weed server but that didn't seem to help.",config-file | source-file | source-file | config-file | config-file | config-file | config-file | config-file | config-file | config-file | config-file | config-file,"HCFS -put gives java.lang.NoSuchFieldError: INSTANCE **Describe the bug** I started a filer and tried to run -put as follows: `hdfs dfs -Djava.net.preferIPv4Stack=true -Dfs.seaweedfs.impl=seaweed.hdfs.SeaweedFileSystem -libjars ./seaweedfs-hadoop2-client-1.1.6.jar -put /tmp/testing seaweedfs://10.49.74.155:8888/tmp/testing ` And I get this exception `put: java.util.concurrent.ExecutionException: java.lang.NoSuchFieldError: INSTANCE` **System Setup** - Ran ./weed server -filer=true - Centos 7.5 - version 30GB 1.43 linux amd64 - leveldb2 is only thing enabled in `filer.toml`  [leveldb2] enabled = true dir = ""/data0/weed/storage""  **Expected behavior** I'd expect the file to be put into the FS. I do see a reference to INSTANCE here in context of the SSLFactory which is where I believe this is coming from: https://github.com/chrislusf/seaweedfs/blob/cb299dfaa279e14def8bf3f26816913213a91097/other/java/client/src/main/java/seaweedfs/client/FilerSslContext.java#L62  Okay so the above was from using a node with Cloudera CDH Hadoop which is what I'd like to get to work. Potentially could be an issue with multiple jars on the path? When I use a default Apache Hadoop download both hdfs 2 and 3 binaries and run the same hdfs dfs put command I get the below exception (hdfs dfs -ls works on the seaweedfs filer without issue):  put: java.util.concurrent.ExecutionException: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8080 [localhost/127.0.0.1] failed: Connection refused (Connection refused)  The default Apache Hadoop issue with put has something to do with getting the wrong url for the volume server to write to. I ran the put on the same machine as the server/volumes/filer and that went through. I did try setting the publicIP of volume server on starting the weed server but that didn't seem to help. config-file source-file source-file config-file config-file config-file config-file config-file config-file config-file config-file config-file",no-bug,0.9
2609,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2609,IO corruption on 2.86,"**Describe the bug** Applying a 'vacuum' to a sqlite database file is enough to corrupt it. Comparing the pread64() and pwrite64() syscalls between the same command run on ext4 and seaweedfs shows differences, particularly in the last byte of a 1024-byte read. **System Setup**  /usr/local/bin/weed master -mdir=/home/weedfs/master -volumePreallocate -volumeSizeLimitMB=30000 -ip 192.168.1.3 -peers 192.168.1.254:9333,192.168.1.253:9333,192.168.1.3:9333 /usr/local/bin/weed volume -dir=/seaweedfs -mserver=192.168.1.253:9333,192.168.1.254:9333,192.168.1.3:9333 -port=8089 -port.grpc=18089 -ip=192.168.1.10 -max=30000 -index=leveldb -dataCenter=shed weed mount -filer=192.168.1.10:8888 -dir=/mnt  OS: archlinux sqlite: v3.37.0  [mysql2] # or memsql, tidb enabled = true createTable =  CREATE TABLE IF NOT EXISTS `%s` ( dirhash BIGINT, name VARCHAR(1000) BINARY, directory TEXT BINARY, meta LONGBLOB, PRIMARY KEY (dirhash, name) ) DEFAULT CHARSET=utf8;  hostname = ""192.168.1.3"" port = 3306 username = ""weedfiler"" password = ""weedfsfiler"" database = ""weedfs"" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 connection_max_lifetime_seconds = 0 interpolateParams = false # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO `%s` (dirhash,name,directory,meta) VALUES(?,?,?,?) ON DUPLICATE KEY UPDATE meta = VALUES(meta)  **Expected behavior** To replicate: 1. Download this sample SQLIte database and unpack it: https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip unzip chinook.zip On weedfs:  $ sqlite3 chinook.db 'vacuum' $ sqlite3 chinook.db '.tables' Error: database disk image is malformed  On ext4:  $ sqlite3 chinook.db 'vacuum' $ sqlite3 chinook.db '.tables' albums employees invoices playlists artists genres media_types tracks customers invoice_items playlist_track  If you unpack chinook.db from the zip file on a non-weedfs and a weedfs filesystem and compare the syscall output, you'll see the byte variations:  strace -e pread64,pwrite64,open,fsync,fdatasync -v -xx -s 8192 -- sqlite3 chinook.db 'vacuum' 2>/root/strace-ext4.txt strace -e pread64,pwrite64,open,fsync,fdatasync -v -xx -s 8192 -- sqlite3 chinook.db 'vacuum' 2>/root/strace-weedfs.txt diff -u /root/strace-ext4.txt /root/strace-weedfs.txt  If you perform the operation twice i.e. unzip, vacuum, the corruption is shown to be consistent i.e. no byte-differences shown by cmp:  unzip chinook.zip cp chinook.db chinook2.db sqlite3 chinook.db 'vacuum; sqlite3 chinook2.db 'vacuum; cmp -l chinook.db chinook2.db  I would expect that comparing the chinook.db between the vacuum performed on ext4 and weedfs should have no byte differences either.",source-file | source-file | source-file,"IO corruption on 2.86 **Describe the bug** Applying a 'vacuum' to a sqlite database file is enough to corrupt it. Comparing the pread64() and pwrite64() syscalls between the same command run on ext4 and seaweedfs shows differences, particularly in the last byte of a 1024-byte read. **System Setup**  /usr/local/bin/weed master -mdir=/home/weedfs/master -volumePreallocate -volumeSizeLimitMB=30000 -ip 192.168.1.3 -peers 192.168.1.254:9333,192.168.1.253:9333,192.168.1.3:9333 /usr/local/bin/weed volume -dir=/seaweedfs -mserver=192.168.1.253:9333,192.168.1.254:9333,192.168.1.3:9333 -port=8089 -port.grpc=18089 -ip=192.168.1.10 -max=30000 -index=leveldb -dataCenter=shed weed mount -filer=192.168.1.10:8888 -dir=/mnt  OS: archlinux sqlite: v3.37.0  [mysql2] # or memsql, tidb enabled = true createTable =  CREATE TABLE IF NOT EXISTS `%s` ( dirhash BIGINT, name VARCHAR(1000) BINARY, directory TEXT BINARY, meta LONGBLOB, PRIMARY KEY (dirhash, name) ) DEFAULT CHARSET=utf8;  hostname = ""192.168.1.3"" port = 3306 username = ""weedfiler"" password = ""weedfsfiler"" database = ""weedfs"" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 connection_max_lifetime_seconds = 0 interpolateParams = false # if insert/upsert failing, you can disable upsert or update query syntax to match your RDBMS syntax: enableUpsert = true upsertQuery = INSERT INTO `%s` (dirhash,name,directory,meta) VALUES(?,?,?,?) ON DUPLICATE KEY UPDATE meta = VALUES(meta)  **Expected behavior** To replicate: 1. Download this sample SQLIte database and unpack it: https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip unzip chinook.zip On weedfs:  $ sqlite3 chinook.db 'vacuum' $ sqlite3 chinook.db '.tables' Error: database disk image is malformed  On ext4:  $ sqlite3 chinook.db 'vacuum' $ sqlite3 chinook.db '.tables' albums employees invoices playlists artists genres media_types tracks customers invoice_items playlist_track  If you unpack chinook.db from the zip file on a non-weedfs and a weedfs filesystem and compare the syscall output, you'll see the byte variations:  strace -e pread64,pwrite64,open,fsync,fdatasync -v -xx -s 8192 -- sqlite3 chinook.db 'vacuum' 2>/root/strace-ext4.txt strace -e pread64,pwrite64,open,fsync,fdatasync -v -xx -s 8192 -- sqlite3 chinook.db 'vacuum' 2>/root/strace-weedfs.txt diff -u /root/strace-ext4.txt /root/strace-weedfs.txt  If you perform the operation twice i.e. unzip, vacuum, the corruption is shown to be consistent i.e. no byte-differences shown by cmp:  unzip chinook.zip cp chinook.db chinook2.db sqlite3 chinook.db 'vacuum; sqlite3 chinook2.db 'vacuum; cmp -l chinook.db chinook2.db  I would expect that comparing the chinook.db between the vacuum performed on ext4 and weedfs should have no byte differences either. source-file source-file source-file",no-bug,0.95
4,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4,go fmt & golint,I think it will be awesome to solve some golint warnings/proposals and make go fmt on all code.,container-file | documentation-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | documentation-file | source-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | source-file | config-file | config-file | source-file | config-file | config-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | documentation-file | config-file | other-file | documentation-file | documentation-file | config-file | config-file | config-file | other-file | other-file | config-file | source-file | source-file | source-file | source-file | source-file | other-file | test-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | test-file | source-file | other-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file,go fmt & golint I think it will be awesome to solve some golint warnings/proposals and make go fmt on all code. container-file documentation-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file documentation-file source-file documentation-file documentation-file config-file other-file config-file source-file source-file config-file config-file source-file config-file config-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file documentation-file config-file other-file documentation-file documentation-file config-file config-file config-file other-file other-file config-file source-file source-file source-file source-file source-file other-file test-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file other-file source-file other-file source-file test-file source-file other-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file,no-bug,0.95
4307,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4307,Single master server takes a long time to start up,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/seaweedfs/seaweedfs/discussions example of a good issue report: https://github.com/seaweedfs/seaweedfs/issues/1005 example of a bad issue report: https://github.com/seaweedfs/seaweedfs/issues/1008 **Describe the bug** I would like to use seaweedfs for testing so the current startup speed is an issue for me. Starting the master server on a single node takes quite a long time (~20s). For example: shell $ mkdir tmp $ weed master -mdir $(readlink -f tmp) -ip localhost -port 9333 I0314 11:41:10.886451 file_util.go:23 Folder /home/stewart/tmp Permission: -rwxr-xr-x I0314 11:41:10.887853 master.go:268 current: localhost:9333 peers: I0314 11:41:10.887920 master_server.go:127 Volume Size Limit is 30000 MB I0314 11:41:10.888133 master.go:149 Start Seaweed Master 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 at localhost:9333 I0314 11:41:10.888407 raft_server.go:119 Starting RaftServer with localhost:9333 I0314 11:41:10.903295 raft_server.go:168 current cluster leader: I0314 11:41:28.904858 master_server.go:215 [localhost:9333] - is the leader. W0314 11:41:28.905130 tls.go:39 pemfile.NewProvider({ 5h0m0s}) grpc.master failed: pemfile: at least one credential file needs to be specified I0314 11:41:28.907455 master.go:200 Start Seaweed Master 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 grpc server at localhost:19333 I0314 11:41:30.408553 masterclient.go:155 No existing leader found! I0314 11:41:30.408613 raft_server.go:190 Initializing new cluster I0314 11:41:30.408659 master_server.go:174 leader change event: => localhost:9333 I0314 11:41:30.408689 master_server.go:177 [localhost:9333] localhost:9333 becomes leader. I0314 11:41:33.911888 master_grpc_server.go:349 + client .master@localhost:9333  The startup process hangs for ~18s between 11:41:10.903295 and 11:41:28.904858. I had a quick dig through the code and it looks like it's something to do with the leader election and Raft. As far as I can tell there isn't a way to configure this startup timeout when running in a single node configuration. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". `weed master` (see above) - OS version Ubuntu 20.04 - output of `weed version` `version 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 linux amd64` - if using filer, show the content of `filer.toml` N/A **Expected behavior** It would be great if there was a flag / configuration option to enable master server start up without waiting for leader election. **Screenshots** N/A see logs above. **Additional context** As mentioned above, I would love to use this in a testing environment for code that would usually hit a Cloud hosted blob/object store like AWS S3.",source-file | source-file | source-file | source-file | other-file | other-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file,"Single master server takes a long time to start up Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs Report issues here. Ask questions here https://stackoverflow.com/questions/tagged/seaweedfs Please ask questions in https://github.com/seaweedfs/seaweedfs/discussions example of a good issue report: https://github.com/seaweedfs/seaweedfs/issues/1005 example of a bad issue report: https://github.com/seaweedfs/seaweedfs/issues/1008 **Describe the bug** I would like to use seaweedfs for testing so the current startup speed is an issue for me. Starting the master server on a single node takes quite a long time (~20s). For example: shell $ mkdir tmp $ weed master -mdir $(readlink -f tmp) -ip localhost -port 9333 I0314 11:41:10.886451 file_util.go:23 Folder /home/stewart/tmp Permission: -rwxr-xr-x I0314 11:41:10.887853 master.go:268 current: localhost:9333 peers: I0314 11:41:10.887920 master_server.go:127 Volume Size Limit is 30000 MB I0314 11:41:10.888133 master.go:149 Start Seaweed Master 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 at localhost:9333 I0314 11:41:10.888407 raft_server.go:119 Starting RaftServer with localhost:9333 I0314 11:41:10.903295 raft_server.go:168 current cluster leader: I0314 11:41:28.904858 master_server.go:215 [localhost:9333] - is the leader. W0314 11:41:28.905130 tls.go:39 pemfile.NewProvider({ 5h0m0s}) grpc.master failed: pemfile: at least one credential file needs to be specified I0314 11:41:28.907455 master.go:200 Start Seaweed Master 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 grpc server at localhost:19333 I0314 11:41:30.408553 masterclient.go:155 No existing leader found! I0314 11:41:30.408613 raft_server.go:190 Initializing new cluster I0314 11:41:30.408659 master_server.go:174 leader change event: => localhost:9333 I0314 11:41:30.408689 master_server.go:177 [localhost:9333] localhost:9333 becomes leader. I0314 11:41:33.911888 master_grpc_server.go:349 + client .master@localhost:9333  The startup process hangs for ~18s between 11:41:10.903295 and 11:41:28.904858. I had a quick dig through the code and it looks like it's something to do with the leader election and Raft. As far as I can tell there isn't a way to configure this startup timeout when running in a single node configuration. **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"". `weed master` (see above) - OS version Ubuntu 20.04 - output of `weed version` `version 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 linux amd64` - if using filer, show the content of `filer.toml` N/A **Expected behavior** It would be great if there was a flag / configuration option to enable master server start up without waiting for leader election. **Screenshots** N/A see logs above. **Additional context** As mentioned above, I would love to use this in a testing environment for code that would usually hit a Cloud hosted blob/object store like AWS S3. source-file source-file source-file source-file other-file other-file source-file other-file other-file source-file source-file source-file source-file",no-bug,0.9
1,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1,Thank you,"Thanks for adding this to Github, even if it's just a mirror. I suggest moving over development here as it will help you gain help and possibly start a community. I plan to give a helping hand at some point in the future, if time allows, and play with it on our servers. There's still a lot of work to be done to catch up with the big guys (gluster, ceph, etc). I really dig the motivation of the project, though (simple, no bullshit, key-value file storage). I hope you're successful in finding a wider user base. :+1:",other-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | test-file | config-file | documentation-file | container-file | container-file | other-file | documentation-file | config-file | config-file | config-file | config-file | config-file | config-file | other-file | other-file | documentation-file | other-file | documentation-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | config-file | source-file | source-file | other-file | config-file | config-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | test-file | other-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | config-file | other-file | config-file | other-file | documentation-file | documentation-file | container-file | container-file | container-file | other-file | documentation-file | config-file | config-file | other-file | config-file | config-file | config-file | config-file | other-file | other-file | documentation-file | other-file | documentation-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | test-file | test-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | documentation-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | documentation-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | source-file | test-file | source-file | other-file | source-file | other-file | source-file | other-file | source-file | test-file | source-file | source-file | other-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | config-file | other-file | config-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | other-file | documentation-file | container-file | other-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | config-file | config-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | other-file | source-file | source-file | source-file | test-file | source-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | config-file | documentation-file | container-file | other-file | other-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | other-file | config-file | config-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | documentation-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | test-file | source-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | documentation-file | container-file | documentation-file | config-file | config-file | config-file | config-file | other-file | other-file | config-file | source-file | source-file | other-file | config-file | config-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | other-file | source-file | test-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | documentation-file | other-file | config-file | other-file | documentation-file | container-file | container-file | config-file | other-file | config-file | config-file | source-file | source-file | source-file | other-file | config-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | test-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | source-file | test-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | other-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"Thank you Thanks for adding this to Github, even if it's just a mirror. I suggest moving over development here as it will help you gain help and possibly start a community. I plan to give a helping hand at some point in the future, if time allows, and play with it on our servers. There's still a lot of work to be done to catch up with the big guys (gluster, ceph, etc). I really dig the motivation of the project, though (simple, no bullshit, key-value file storage). I hope you're successful in finding a wider user base. :+1: other-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file test-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file test-file config-file documentation-file container-file container-file other-file documentation-file config-file config-file config-file config-file config-file config-file other-file other-file documentation-file other-file documentation-file other-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file config-file source-file source-file other-file config-file config-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file other-file source-file other-file source-file test-file other-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file other-file source-file source-file source-file source-file source-file source-file documentation-file config-file other-file config-file other-file documentation-file documentation-file container-file container-file container-file other-file documentation-file config-file config-file other-file config-file config-file config-file config-file other-file other-file documentation-file other-file documentation-file other-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file other-file test-file test-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file documentation-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file test-file source-file test-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file documentation-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file source-file test-file source-file other-file source-file other-file source-file other-file source-file test-file source-file source-file other-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file config-file other-file config-file source-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file source-file source-file source-file source-file source-file config-file other-file documentation-file container-file other-file other-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file config-file other-file config-file source-file source-file source-file source-file source-file source-file other-file config-file config-file source-file source-file source-file config-file config-file source-file source-file source-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file other-file source-file source-file source-file test-file source-file other-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file test-file source-file source-file test-file test-file source-file source-file source-file config-file documentation-file container-file other-file other-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file config-file other-file config-file source-file other-file config-file config-file source-file source-file source-file config-file config-file source-file source-file source-file documentation-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file other-file source-file source-file source-file test-file source-file other-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file test-file source-file source-file test-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file documentation-file container-file documentation-file config-file config-file config-file config-file other-file other-file config-file source-file source-file other-file config-file config-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file other-file source-file test-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file documentation-file config-file other-file config-file source-file source-file source-file source-file source-file source-file config-file source-file source-file config-file config-file source-file source-file source-file config-file config-file source-file source-file source-file source-file source-file documentation-file other-file config-file other-file documentation-file container-file container-file config-file other-file config-file config-file source-file source-file source-file other-file config-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file test-file source-file test-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file source-file test-file other-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file other-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file test-file test-file source-file source-file test-file source-file test-file source-file source-file source-file source-file source-file test-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.95
87,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/87,weed fix loses (some) indices?,"I've got an .dat volume with .idx that I thought might be corrupt. So I backed it up and ran `weed fix ` It produced an idx file that was smaller than the older one, but the weed volume seemed to come up fine. Unfortunately, it seemed like some things (I haven't confirmed if it's just some items or all) returned 404s, whereas the previous index worked. (Against the same .dat file).",source-file | config-file | documentation-file | container-file | container-file | documentation-file | documentation-file | documentation-file | config-file | other-file | config-file | source-file | other-file | config-file | config-file | config-file | config-file | config-file | other-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file | source-file | other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file,"weed fix loses (some) indices? I've got an .dat volume with .idx that I thought might be corrupt. So I backed it up and ran `weed fix ` It produced an idx file that was smaller than the older one, but the weed volume seemed to come up fine. Unfortunately, it seemed like some things (I haven't confirmed if it's just some items or all) returned 404s, whereas the previous index worked. (Against the same .dat file). source-file config-file documentation-file container-file container-file documentation-file documentation-file documentation-file config-file other-file config-file source-file other-file config-file config-file config-file config-file config-file other-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file other-file source-file other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file source-file",no-bug,0.8
2169,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2169,"Running `npm install` in a nodejs project may result in lost data or ""Unknown system error -116"""," Describe the bug When running `npm install` in a NodeJS project that is on a SeaweedFS Fuse mount, unexpected behavior happens. Either it fails with something like the following. One thing to note is that it fails on a different modules.  npm ERR! code Unknown system error -116 npm ERR! syscall rename npm ERR! path /mnt/seaweedfs/tmp/my-app/node_modules/@types/.uglify-js.DELETE/node_modules/source-map npm ERR! dest /mnt/seaweedfs/tmp/my-app/node_modules/@types/uglify-js/node_modules/source-map npm ERR! errno -116 npm ERR! Unknown system error -116: Unknown system error -116, rename '/mnt/seaweedfs/tmp/my-app/node_modules/@types/.uglify-js.DELETE/node_modules/source-map' -> '/mnt/seaweedfs/tmp/my-app/node_modules/@types/uglify-js/node_modules/source-map'  Or it results in **the entire contents of the folder that it was working in being deleted. In one case, it even lost the entire parent folder.**  Reproduction Instructions The following will download NodeJS, and try to create a react application, during that process it runs `npm install`  cd /mnt/seaweedfs mkdir tmp cd tmp wget https://nodejs.org/dist/v14.17.1/node-v14.17.1-linux-x64.tar.xz tar xf node-v14.17.1-linux-x64.tar.xz export PATH=$PATH:`pwd`/node-v14.17.1-linux-x64/bin npx create-react-app my-app  Alternative reproduction (with nodejs still being on the PATH):  cd /tmp npx create-react-app my-app2 rm -rf my-app/node_modules mv my-app2 /mnt/seaweedfs/tmp/ cd /mnt/seaweedfs/tmp/my-app2 npm install   System Setup 3 machines with single master and 3 volume servers. `version 30GB 2.56 a2979aa linux amd64` Master: - `/srv/seaweedfs/weed master -mdir=""/srv/seaweedfs/metadata""` - `/srv/seaweedfs/weed volume -max=30 -mserver=localhost:9333 -dir=/srv/seaweedfs/volumes` - `/srv/seaweedfs/weed filer -s3 -s3.config=/srv/seaweedfs/s3.config.json -master=localhost:9333` - `/srv/seaweedfs/weed mount -umask=000 -dir=/mnt/seaweedfs -collection=storage -filer=localhost:8888` - filer.toml:  [leveldb2] enabled = true dir = ""/srv/seaweedfs/filer""  Volume Servers: - `/srv/seaweedfs/weed volume -max=30 -mserver=10.10.10.22:9333 -dir=/srv/seaweedfs/volumes` - `/srv/seaweedfs/weed mount -umask=000 -dir=/mnt/seaweedfs -collection=storage -filer=10.10.10.22:8888`  Expected behavior `npm install` should finish without any errors and the folder contents should stay where they are in any case.  Additional Context The following lines appear in the error log on the master. This was collected during the reproduction run when the entire /mnt/seaweedfs/tmp folder was lost.  E0630 11:59:59 48653 dir.go:583] UpdateEntry dir /tmp/my-app2/node_modules/.staging/acorn-globals-146eb470: rpc error: code = Unknown desc = not found /tmp/my-app2/node_modules/.staging/acorn-globals-146eb470: filer: no entry is found in filer store E0630 12:00:05 48653 dir.go:583] UpdateEntry dir /tmp/my-app2/node_modules/.staging/@types/webpack-sources-6888de33/lib: rpc error: code = Unknown desc = not found /tmp/my-app2/node_modules/.staging/@types/webpack-sources-6888de33/lib: filer: no entry is found in filer store E0630 12:00:05 48653 meta_cache_subscribe.go:95] subscribing filer meta change: rpc error: code = Canceled desc = grpc: the client connection is closing E0630 12:00:32 48653 dir.go:583] UpdateEntry dir /tmp/my-app2/node_modules/.staging/@types/babel__traverse-25d577b5/ts4.1: rpc error: code = Unknown desc = not found /tmp/my-app2/node_modules/.staging/@types/babel__traverse-25d577b5/ts4.1: filer: no entry is found in filer store ",source-file,"Running `npm install` in a nodejs project may result in lost data or ""Unknown system error -116""  Describe the bug When running `npm install` in a NodeJS project that is on a SeaweedFS Fuse mount, unexpected behavior happens. Either it fails with something like the following. One thing to note is that it fails on a different modules.  npm ERR! code Unknown system error -116 npm ERR! syscall rename npm ERR! path /mnt/seaweedfs/tmp/my-app/node_modules/@types/.uglify-js.DELETE/node_modules/source-map npm ERR! dest /mnt/seaweedfs/tmp/my-app/node_modules/@types/uglify-js/node_modules/source-map npm ERR! errno -116 npm ERR! Unknown system error -116: Unknown system error -116, rename '/mnt/seaweedfs/tmp/my-app/node_modules/@types/.uglify-js.DELETE/node_modules/source-map' -> '/mnt/seaweedfs/tmp/my-app/node_modules/@types/uglify-js/node_modules/source-map'  Or it results in **the entire contents of the folder that it was working in being deleted. In one case, it even lost the entire parent folder.**  Reproduction Instructions The following will download NodeJS, and try to create a react application, during that process it runs `npm install`  cd /mnt/seaweedfs mkdir tmp cd tmp wget https://nodejs.org/dist/v14.17.1/node-v14.17.1-linux-x64.tar.xz tar xf node-v14.17.1-linux-x64.tar.xz export PATH=$PATH:`pwd`/node-v14.17.1-linux-x64/bin npx create-react-app my-app  Alternative reproduction (with nodejs still being on the PATH):  cd /tmp npx create-react-app my-app2 rm -rf my-app/node_modules mv my-app2 /mnt/seaweedfs/tmp/ cd /mnt/seaweedfs/tmp/my-app2 npm install   System Setup 3 machines with single master and 3 volume servers. `version 30GB 2.56 a2979aa linux amd64` Master: - `/srv/seaweedfs/weed master -mdir=""/srv/seaweedfs/metadata""` - `/srv/seaweedfs/weed volume -max=30 -mserver=localhost:9333 -dir=/srv/seaweedfs/volumes` - `/srv/seaweedfs/weed filer -s3 -s3.config=/srv/seaweedfs/s3.config.json -master=localhost:9333` - `/srv/seaweedfs/weed mount -umask=000 -dir=/mnt/seaweedfs -collection=storage -filer=localhost:8888` - filer.toml:  [leveldb2] enabled = true dir = ""/srv/seaweedfs/filer""  Volume Servers: - `/srv/seaweedfs/weed volume -max=30 -mserver=10.10.10.22:9333 -dir=/srv/seaweedfs/volumes` - `/srv/seaweedfs/weed mount -umask=000 -dir=/mnt/seaweedfs -collection=storage -filer=10.10.10.22:8888`  Expected behavior `npm install` should finish without any errors and the folder contents should stay where they are in any case.  Additional Context The following lines appear in the error log on the master. This was collected during the reproduction run when the entire /mnt/seaweedfs/tmp folder was lost.  E0630 11:59:59 48653 dir.go:583] UpdateEntry dir /tmp/my-app2/node_modules/.staging/acorn-globals-146eb470: rpc error: code = Unknown desc = not found /tmp/my-app2/node_modules/.staging/acorn-globals-146eb470: filer: no entry is found in filer store E0630 12:00:05 48653 dir.go:583] UpdateEntry dir /tmp/my-app2/node_modules/.staging/@types/webpack-sources-6888de33/lib: rpc error: code = Unknown desc = not found /tmp/my-app2/node_modules/.staging/@types/webpack-sources-6888de33/lib: filer: no entry is found in filer store E0630 12:00:05 48653 meta_cache_subscribe.go:95] subscribing filer meta change: rpc error: code = Canceled desc = grpc: the client connection is closing E0630 12:00:32 48653 dir.go:583] UpdateEntry dir /tmp/my-app2/node_modules/.staging/@types/babel__traverse-25d577b5/ts4.1: rpc error: code = Unknown desc = not found /tmp/my-app2/node_modules/.staging/@types/babel__traverse-25d577b5/ts4.1: filer: no entry is found in filer store  source-file",no-bug,0.9
6262,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6262,Multipart upload without S3 authentication fails with the wrong message,"**Describe the bug** If S3 authentication is not setup, attempting to upload multipart will fail with the error message: Expected hash not equal to calculated hash While trying to make a minimal reproduction of this behavior to report the bug, I noticed that when using the amazon SDK `TransferUtility`, I get a different error message: Signed request requires setting up SeaweedFS S3 authentication This led me to find the otherwise completely opaque issue at hand. **System Setup** `podman run --name seaweed-12312 --rm -p 12312:12312 docker.io/chrislusf/seaweedfs server -s3 -s3.port 12312` To run seaweed. Then in C#: cs var s3Client = new AmazonS3Client( new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } ); var bucketName = ""my-test-bucket""; var keyName = ""dir/file.txt""; var fakeFileData = new StringBuilder(); fakeFileData.AppendLine(""a,b,c,d,e""); for (var i = 0; i < 10000; i++) { fakeFileData.AppendLine($""a{i},b{i},c{i},d{i},e{i}""); } var cancellationToken = CancellationToken.None; var initiateRequest = new InitiateMultipartUploadRequest { BucketName = bucketName, Key = keyName, }; var initiateResponse = await s3Client.InitiateMultipartUploadAsync(initiateRequest, cancellationToken); var partETags = new List<PartETag>(); using (var fakeFileStream = new MemoryStream(Encoding.UTF8.GetBytes(fakeFileData.ToString( { var uploadRequest = new UploadPartRequest { BucketName = bucketName, Key = keyName, UploadId = initiateResponse.UploadId, PartNumber = 1, PartSize = fakeFileStream.Length, InputStream = fakeFileStream }; var uploadResponse = await s3Client.UploadPartAsync(uploadRequest, cancellationToken); partETags.Add(new PartETag(uploadResponse.PartNumber, uploadResponse.ETag)); } var completeRequest = new CompleteMultipartUploadRequest { BucketName = bucketName, Key = keyName, UploadId = initiateResponse.UploadId, PartETags = partETags }; await s3Client.CompleteMultipartUploadAsync(completeRequest, cancellationToken);  The above fails with `Expected hash not equal to calculated hash`. However, running the code below: cs var s3Client = new AmazonS3Client( new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } ); var bucketName = ""my-test-bucket""; var keyName = ""dir/file.txt""; var fakeFileData = new StringBuilder(); fakeFileData.AppendLine(""a,b,c,d,e""); for (var i = 0; i < 10000; i++) { fakeFileData.AppendLine($""a{i},b{i},c{i},d{i},e{i}""); } var fileTransferUtility = new TransferUtility(s3Client); using (var fakeFileStream = new MemoryStream(Encoding.UTF8.GetBytes(fakeFileData.ToString( { var fileTransferUtilityRequest = new TransferUtilityUploadRequest { BucketName = bucketName, InputStream = fakeFileStream, PartSize = 6*1024*1024, // 6 MB. Key = keyName, // DisablePayloadSigning = true, }; await fileTransferUtility.UploadAsync(fileTransferUtilityRequest); }  This fails with the much more useful `Signed request requires setting up SeaweedFS S3 authentication`. It's important to note, that if I setup seaweed using: `podman run --name seaweed-12312 -v /home/$USER/s3_config.json:/app/:Z --rm -p 12312:12312 docker.io/chrislusf/seaweedfs server -s3 -s3.port 12312 -s3.config ""/app/s3_config.json""` While filling `~/s3_config.json` with:  { ""identities"": [ { ""name"": ""me"", ""credentials"": [ { ""accessKey"": ""seaweed"", ""secretKey"": ""seaweed"" } ], ""actions"": [ ""Read"", ""Write"", ""List"", ""Tagging"", ""Admin"" ] } ] }  And then setting up the client accordingly: cs var s3Client = new AmazonS3Client( new BasicAWSCredentials(""seaweed"", ""seaweed""), new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } );  Both examples work. **Expected behavior** I'd like for the simple case to fail with an informative error message, instead of giving a hash equality message which implies some usage bug. I'm glad I could find the issue eventually, but I could've saved a lot of time with the right error message!",source-file,"Multipart upload without S3 authentication fails with the wrong message **Describe the bug** If S3 authentication is not setup, attempting to upload multipart will fail with the error message: Expected hash not equal to calculated hash While trying to make a minimal reproduction of this behavior to report the bug, I noticed that when using the amazon SDK `TransferUtility`, I get a different error message: Signed request requires setting up SeaweedFS S3 authentication This led me to find the otherwise completely opaque issue at hand. **System Setup** `podman run --name seaweed-12312 --rm -p 12312:12312 docker.io/chrislusf/seaweedfs server -s3 -s3.port 12312` To run seaweed. Then in C#: cs var s3Client = new AmazonS3Client( new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } ); var bucketName = ""my-test-bucket""; var keyName = ""dir/file.txt""; var fakeFileData = new StringBuilder(); fakeFileData.AppendLine(""a,b,c,d,e""); for (var i = 0; i < 10000; i++) { fakeFileData.AppendLine($""a{i},b{i},c{i},d{i},e{i}""); } var cancellationToken = CancellationToken.None; var initiateRequest = new InitiateMultipartUploadRequest { BucketName = bucketName, Key = keyName, }; var initiateResponse = await s3Client.InitiateMultipartUploadAsync(initiateRequest, cancellationToken); var partETags = new List<PartETag>(); using (var fakeFileStream = new MemoryStream(Encoding.UTF8.GetBytes(fakeFileData.ToString( { var uploadRequest = new UploadPartRequest { BucketName = bucketName, Key = keyName, UploadId = initiateResponse.UploadId, PartNumber = 1, PartSize = fakeFileStream.Length, InputStream = fakeFileStream }; var uploadResponse = await s3Client.UploadPartAsync(uploadRequest, cancellationToken); partETags.Add(new PartETag(uploadResponse.PartNumber, uploadResponse.ETag)); } var completeRequest = new CompleteMultipartUploadRequest { BucketName = bucketName, Key = keyName, UploadId = initiateResponse.UploadId, PartETags = partETags }; await s3Client.CompleteMultipartUploadAsync(completeRequest, cancellationToken);  The above fails with `Expected hash not equal to calculated hash`. However, running the code below: cs var s3Client = new AmazonS3Client( new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } ); var bucketName = ""my-test-bucket""; var keyName = ""dir/file.txt""; var fakeFileData = new StringBuilder(); fakeFileData.AppendLine(""a,b,c,d,e""); for (var i = 0; i < 10000; i++) { fakeFileData.AppendLine($""a{i},b{i},c{i},d{i},e{i}""); } var fileTransferUtility = new TransferUtility(s3Client); using (var fakeFileStream = new MemoryStream(Encoding.UTF8.GetBytes(fakeFileData.ToString( { var fileTransferUtilityRequest = new TransferUtilityUploadRequest { BucketName = bucketName, InputStream = fakeFileStream, PartSize = 6*1024*1024, // 6 MB. Key = keyName, // DisablePayloadSigning = true, }; await fileTransferUtility.UploadAsync(fileTransferUtilityRequest); }  This fails with the much more useful `Signed request requires setting up SeaweedFS S3 authentication`. It's important to note, that if I setup seaweed using: `podman run --name seaweed-12312 -v /home/$USER/s3_config.json:/app/:Z --rm -p 12312:12312 docker.io/chrislusf/seaweedfs server -s3 -s3.port 12312 -s3.config ""/app/s3_config.json""` While filling `~/s3_config.json` with:  { ""identities"": [ { ""name"": ""me"", ""credentials"": [ { ""accessKey"": ""seaweed"", ""secretKey"": ""seaweed"" } ], ""actions"": [ ""Read"", ""Write"", ""List"", ""Tagging"", ""Admin"" ] } ] }  And then setting up the client accordingly: cs var s3Client = new AmazonS3Client( new BasicAWSCredentials(""seaweed"", ""seaweed""), new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } );  Both examples work. **Expected behavior** I'd like for the simple case to fail with an informative error message, instead of giving a hash equality message which implies some usage bug. I'm glad I could find the issue eventually, but I could've saved a lot of time with the right error message! source-file",bug,0.9
6576,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6576,Seaweed does not handle x-id,AWS SDK's emit an x-id query parameter which is not supported by seaweed leading to issues handling presigned requests,source-file,Seaweed does not handle x-id AWS SDK's emit an x-id query parameter which is not supported by seaweed leading to issues handling presigned requests source-file,bug,0.85
6290,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6290,[master] avoid timeout when Assigning for main request with filter by DC or rack,"**Describe the bug** in case of [errors in finding the volume](https://github.com/seaweedfs/seaweedfs/issues/6278), we wait too long for a timeout instead of immediately sending an alternative request <img width=""545"" alt=""image"" src=""https://github.com/user-attachments/assets/ea94a786-654e-468e-8494-cecfc258d03f""> **System Setup**  3.77  **Expected behavior** We don't wait for the timeout on the assign fro main request, but immediately send an alternative request",source-file | source-file | source-file | source-file,"[master] avoid timeout when Assigning for main request with filter by DC or rack **Describe the bug** in case of [errors in finding the volume](https://github.com/seaweedfs/seaweedfs/issues/6278), we wait too long for a timeout instead of immediately sending an alternative request <img width=""545"" alt=""image"" src=""https://github.com/user-attachments/assets/ea94a786-654e-468e-8494-cecfc258d03f""> **System Setup**  3.77  **Expected behavior** We don't wait for the timeout on the assign fro main request, but immediately send an alternative request source-file source-file source-file source-file",no-bug,0.8
3882,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3882,[volume] panic: runtime error: makeslice: len out of range,"**Describe the bug** panic on start  panic: runtime error: makeslice: len out of range goroutine 1488 [running]: github.com/seaweedfs/seaweedfs/weed/storage/needle.(*Needle).ReadNeedleMeta(0xc0001519b0, {0x2d0dfb0, 0xc0006cecc0}, 0xfdd920, 0x0, 0x3) /go/src/github.com/seaweedfs/seaweedfs/weed/storage/needle/needle_read_page.go:52 +0x159 github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).readNeedleMetaAt(0xc0027f7180, 0xc0001518f8?, 0xfdd920, 0xfb269a?) /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_read.go:87 +0xce github.com/seaweedfs/seaweedfs/weed/storage.(*Store).ReadVolumeNeedleMetaAt(0x12?, 0x24ef200?, 0xc007ebebe0?, 0xc000151a78?, 0xb547e4?) /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:419 +0x47 github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).ReadNeedleMeta(0xc0006d4b40, {0xc007ebebe0?, 0x535ac6?}, 0xc007ebebe0) /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_read_write.go:41 +0xde github.com/seaweedfs/seaweedfs/weed/pb/volume_server_pb._VolumeServer_ReadNeedleMeta_Handler({0x2665420?, 0xc0006d4b40}, {0x2d02ee0, 0xc007ede8a0}, 0xc00077cbd0, 0x0) /go/src/github.com/seaweedfs/seaweedfs/weed/pb/volume_server_pb/volume_server_grpc.pb.go:1262 +0x170 google.golang.org/grpc.(*Server).processUnaryRPC(0xc000402780, {0x2d12640, 0xc006ff21a0}, 0xc007bfd9e0, 0xc0000a8e10, 0x3faa020, 0x0) /go/pkg/mod/google.golang.org/grpc@v1.50.0/server.go:1318 +0xb2b google.golang.org/grpc.(*Server).handleStream(0xc000402780, {0x2d12640, 0xc006ff21a0}, 0xc007bfd9e0, 0x0) /go/pkg/mod/google.golang.org/grpc@v1.50.0/server.go:1659 +0xa2f google.golang.org/grpc.(*Server).serveStreams.func1.2() /go/pkg/mod/google.golang.org/grpc@v1.50.0/server.go:955 +0x98 created by google.golang.org/grpc.(*Server).serveStreams.func1 /go/pkg/mod/google.golang.org/grpc@v1.50.0/server.go:953 +0x28a  After run `volume.fschk -verify` https://github.com/seaweedfs/seaweedfs/pull/3879 is [line](https://github.com/seaweedfs/seaweedfs/blob/64e75a286ee619893c50ed900adddbd914a5ac43/weed/storage/needle/needle_read_page.go#L52) `metaSlice := make([]byte, int(metaSize))` **System Setup** 3.32",source-file | source-file | source-file | source-file,"[volume] panic: runtime error: makeslice: len out of range **Describe the bug** panic on start  panic: runtime error: makeslice: len out of range goroutine 1488 [running]: github.com/seaweedfs/seaweedfs/weed/storage/needle.(*Needle).ReadNeedleMeta(0xc0001519b0, {0x2d0dfb0, 0xc0006cecc0}, 0xfdd920, 0x0, 0x3) /go/src/github.com/seaweedfs/seaweedfs/weed/storage/needle/needle_read_page.go:52 +0x159 github.com/seaweedfs/seaweedfs/weed/storage.(*Volume).readNeedleMetaAt(0xc0027f7180, 0xc0001518f8?, 0xfdd920, 0xfb269a?) /go/src/github.com/seaweedfs/seaweedfs/weed/storage/volume_read.go:87 +0xce github.com/seaweedfs/seaweedfs/weed/storage.(*Store).ReadVolumeNeedleMetaAt(0x12?, 0x24ef200?, 0xc007ebebe0?, 0xc000151a78?, 0xb547e4?) /go/src/github.com/seaweedfs/seaweedfs/weed/storage/store.go:419 +0x47 github.com/seaweedfs/seaweedfs/weed/server.(*VolumeServer).ReadNeedleMeta(0xc0006d4b40, {0xc007ebebe0?, 0x535ac6?}, 0xc007ebebe0) /go/src/github.com/seaweedfs/seaweedfs/weed/server/volume_grpc_read_write.go:41 +0xde github.com/seaweedfs/seaweedfs/weed/pb/volume_server_pb._VolumeServer_ReadNeedleMeta_Handler({0x2665420?, 0xc0006d4b40}, {0x2d02ee0, 0xc007ede8a0}, 0xc00077cbd0, 0x0) /go/src/github.com/seaweedfs/seaweedfs/weed/pb/volume_server_pb/volume_server_grpc.pb.go:1262 +0x170 google.golang.org/grpc.(*Server).processUnaryRPC(0xc000402780, {0x2d12640, 0xc006ff21a0}, 0xc007bfd9e0, 0xc0000a8e10, 0x3faa020, 0x0) /go/pkg/mod/google.golang.org/grpc@v1.50.0/server.go:1318 +0xb2b google.golang.org/grpc.(*Server).handleStream(0xc000402780, {0x2d12640, 0xc006ff21a0}, 0xc007bfd9e0, 0x0) /go/pkg/mod/google.golang.org/grpc@v1.50.0/server.go:1659 +0xa2f google.golang.org/grpc.(*Server).serveStreams.func1.2() /go/pkg/mod/google.golang.org/grpc@v1.50.0/server.go:955 +0x98 created by google.golang.org/grpc.(*Server).serveStreams.func1 /go/pkg/mod/google.golang.org/grpc@v1.50.0/server.go:953 +0x28a  After run `volume.fschk -verify` https://github.com/seaweedfs/seaweedfs/pull/3879 is [line](https://github.com/seaweedfs/seaweedfs/blob/64e75a286ee619893c50ed900adddbd914a5ac43/weed/storage/needle/needle_read_page.go#L52) `metaSlice := make([]byte, int(metaSize))` **System Setup** 3.32 source-file source-file source-file source-file",no-bug,0.9
4305,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4305,s3.bucket.list file count mismatch,"**Describe the bug** s3.bucket.list file count is not correct **System Setup** - weed server -s3 -ip.bind=0.0.0.0 -dir=/disk/data1/weed,/disk/data2/weed -master.defaultReplication=002 -master.peers=192.168.3.101:9333,192.168.3.102:9333,192.168.3.103:9333,192.168.3.104:9333,192.168.3.105:9333 - Ubuntu 22.04.1 LTS - version 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 linux amd64 - content of `filer.toml`  [leveldb2] enabled = false dir = ""./filerldb2"" # directory to store level db files [tikv] enabled = true pdaddrs = ""pdhost1:2379, pdhost2:2379, pdhost3:2379""  **Expected behavior**  > fs.ls /buckets/kuro3 prometheus.yml redirect.html weed > s3.bucket.list kuro3 size:67565992 file:22  file count should be 3 **Screenshots** ![image](https://user-images.githubusercontent.com/12230174/224946805-9e45e296-35b9-4234-8015-61efb289116b.png) ![image](https://user-images.githubusercontent.com/12230174/224947463-8ca7b206-b065-4d5c-b62a-7adb847caa22.png) **Additional context** It seems that filer slices files into segments of 4MB, and `s3.bucket.list` counts each segment as a separate file.",source-file,"s3.bucket.list file count mismatch **Describe the bug** s3.bucket.list file count is not correct **System Setup** - weed server -s3 -ip.bind=0.0.0.0 -dir=/disk/data1/weed,/disk/data2/weed -master.defaultReplication=002 -master.peers=192.168.3.101:9333,192.168.3.102:9333,192.168.3.103:9333,192.168.3.104:9333,192.168.3.105:9333 - Ubuntu 22.04.1 LTS - version 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 linux amd64 - content of `filer.toml`  [leveldb2] enabled = false dir = ""./filerldb2"" # directory to store level db files [tikv] enabled = true pdaddrs = ""pdhost1:2379, pdhost2:2379, pdhost3:2379""  **Expected behavior**  > fs.ls /buckets/kuro3 prometheus.yml redirect.html weed > s3.bucket.list kuro3 size:67565992 file:22  file count should be 3 **Screenshots** ![image](https://user-images.githubusercontent.com/12230174/224946805-9e45e296-35b9-4234-8015-61efb289116b.png) ![image](https://user-images.githubusercontent.com/12230174/224947463-8ca7b206-b065-4d5c-b62a-7adb847caa22.png) **Additional context** It seems that filer slices files into segments of 4MB, and `s3.bucket.list` counts each segment as a separate file. source-file",bug,0.9
