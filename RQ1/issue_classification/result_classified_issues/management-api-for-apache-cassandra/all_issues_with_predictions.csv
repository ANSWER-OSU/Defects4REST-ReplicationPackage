issue_no,repo,issue_url,title,description,patched_file_types,text_for_topic_modeling,prediction,confidence
455,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/455,Add DSE 6.8.43 to the build matrix,,documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | container-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | container-file | config-file | container-file | config-file | container-file | container-file | container-file | config-file | config-file | source-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | config-file | container-file | config-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | container-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | container-file | config-file | container-file | config-file | container-file | container-file | container-file | config-file | config-file | source-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | config-file | container-file | config-file,Add DSE 6.8.43 to the build matrix  documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file container-file container-file container-file container-file container-file container-file container-file documentation-file container-file config-file container-file config-file container-file container-file container-file config-file config-file source-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file config-file config-file container-file config-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file container-file container-file container-file container-file container-file container-file container-file documentation-file container-file config-file container-file config-file container-file container-file container-file config-file config-file source-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file config-file config-file container-file config-file,no-bug,0.9
517,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/517,Add DSE 6.9.0 to the build matrix,,documentation-file | documentation-file | documentation-file,Add DSE 6.9.0 to the build matrix  documentation-file documentation-file documentation-file,no-bug,0.95
617,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/617,Fix Cassandra trunk builds,Latest Cassandra trunk builds are now failing with  #17 135.6 gen-asciidoc: #17 135.6 [exec] python3 ./scripts/gen-nodetool-docs.py #17 135.6 [exec] make: python3: No such file or directory #17 135.6 [exec] make:  [Makefile:26: gen-asciidoc] Error 127 #17 135.6 #17 135.6 BUILD FAILED #17 135.6 /build/cassandra/build.xml:472: exec returned: 2 #17 135.6 #17 135.6 Total time: 1 minute 24 seconds  Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-108) by [Unito](https://www.unito.io) Issue Number: MAPI-108,documentation-file,Fix Cassandra trunk builds Latest Cassandra trunk builds are now failing with  #17 135.6 gen-asciidoc: #17 135.6 [exec] python3 ./scripts/gen-nodetool-docs.py #17 135.6 [exec] make: python3: No such file or directory #17 135.6 [exec] make:  [Makefile:26: gen-asciidoc] Error 127 #17 135.6 #17 135.6 BUILD FAILED #17 135.6 /build/cassandra/build.xml:472: exec returned: 2 #17 135.6 #17 135.6 Total time: 1 minute 24 seconds  Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-108) by [Unito](https://www.unito.io) Issue Number: MAPI-108 documentation-file,no-bug,0.95
527,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/527,Add Cassandra 4.1.6 to the build matrix,This will likely require a bit more than simply updating version numbers in the Docker release job. See https://github.com/k8ssandra/management-api-for-apache-cassandra/discussions/526,documentation-file,Add Cassandra 4.1.6 to the build matrix This will likely require a bit more than simply updating version numbers in the Docker release job. See https://github.com/k8ssandra/management-api-for-apache-cassandra/discussions/526 documentation-file,no-bug,0.9
465,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/465,Add `tar` to the DSE images,When troubleshooting misbehaving pods it's often required to be able to extract a large number of files from the container outside of it. `tar` is very handy to perform such operations and is present in the Cassandra images but not the DSE ones. We'd need to add `tar` to the DSE images as well. It is also mandatory to be able to use `kubectl cp` commands. [tasklist]  Definition of Done - [ ] `tar` is added to the dse images ,documentation-file,Add `tar` to the DSE images When troubleshooting misbehaving pods it's often required to be able to extract a large number of files from the container outside of it. `tar` is very handy to perform such operations and is present in the Cassandra images but not the DSE ones. We'd need to add `tar` to the DSE images as well. It is also mandatory to be able to use `kubectl cp` commands. [tasklist]  Definition of Done - [ ] `tar` is added to the dse images  documentation-file,no-bug,0.95
566,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/566,Add role list and delete functionality,"Currently, the mgmt-api has ability to create roles, but not list them or delete them. This functionality should be present as well to enable management without going through CQL. Example output would be: Fetch current roles after creating the cluster (same format as ``LIST roles;`` in CQL):  cassandra@cluster2-dc2-r1-sts-0 /]$ curl localhost:8080/api/v0/ops/auth/role [{""datacenters"":""ALL"",""login"":""true"",""name"":""cluster2-superuser"",""options"":""{}"",""super"":""true""},{""datacenters"":""ALL"",""login"":""false"",""name"":""cassandra"",""options"":""{}"",""super"":""false""}] [cassandra@cluster2-dc2-r1-sts-0 /]$  Create role, using the existing functionality:  [cassandra@cluster2-dc2-r1-sts-0 /]$ curl -v -XPOST 'localhost:8080/api/v0/ops/auth/role?username=try&password=hope&can_login=false&is_superuser=false' * Trying ::1 * TCP_NODELAY set * Connected to localhost (::1) port 8080 (#0) > POST /api/v0/ops/auth/role?username=try&password=hope&can_login=false&is_superuser=false HTTP/1.1 > Host: localhost:8080 > User-Agent: curl/7.61.1 > Accept: */* > < HTTP/1.1 200 OK < connection: keep-alive < Content-Type: text/plain;charset=UTF-8 < transfer-encoding: chunked < * Connection #0 to host localhost left intact OK[cassandra@cluster2-dc2-r1-sts-0 /]$  List again:  [cassandra@cluster2-dc2-r1-sts-0 /]$ curl localhost:8080/api/v0/ops/auth/role [{""datacenters"":""ALL"",""login"":""false"",""name"":""try"",""options"":""{}"",""super"":""false""},{""datacenters"":""ALL"",""login"":""true"",""name"":""cluster2-superuser"",""options"":""{}"",""super"":""true""},{""datacenters"":""ALL"",""login"":""false"",""name"":""cassandra"",""options"":""{}"",""super"":""false""}] [cassandra@cluster2-dc2-r1-sts-0 /]  Delete:  [cassandra@cluster2-dc2-r1-sts-0 /]$ curl -XDELETE 'localhost:8080/api/v0/ops/auth/role/drop?username=try' OK[cassandra@cluster2-dc2-r1-sts-0 /]$  And final list:  cassandra@cluster2-dc2-r1-sts-0 /]$ curl localhost:8080/api/v0/ops/auth/role [{""datacenters"":""ALL"",""login"":""true"",""name"":""cluster2-superuser"",""options"":""{}"",""super"":""true""},{""datacenters"":""ALL"",""login"":""false"",""name"":""cassandra"",""options"":""{}"",""super"":""false""}] [cassandra@cluster2-dc2-r1-sts-0 /]$  Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-80) by [Unito](https://www.unito.io) Issue Number: MAPI-80",documentation-file,"Add role list and delete functionality Currently, the mgmt-api has ability to create roles, but not list them or delete them. This functionality should be present as well to enable management without going through CQL. Example output would be: Fetch current roles after creating the cluster (same format as ``LIST roles;`` in CQL):  cassandra@cluster2-dc2-r1-sts-0 /]$ curl localhost:8080/api/v0/ops/auth/role [{""datacenters"":""ALL"",""login"":""true"",""name"":""cluster2-superuser"",""options"":""{}"",""super"":""true""},{""datacenters"":""ALL"",""login"":""false"",""name"":""cassandra"",""options"":""{}"",""super"":""false""}] [cassandra@cluster2-dc2-r1-sts-0 /]$  Create role, using the existing functionality:  [cassandra@cluster2-dc2-r1-sts-0 /]$ curl -v -XPOST 'localhost:8080/api/v0/ops/auth/role?username=try&password=hope&can_login=false&is_superuser=false' * Trying ::1 * TCP_NODELAY set * Connected to localhost (::1) port 8080 (#0) > POST /api/v0/ops/auth/role?username=try&password=hope&can_login=false&is_superuser=false HTTP/1.1 > Host: localhost:8080 > User-Agent: curl/7.61.1 > Accept: */* > < HTTP/1.1 200 OK < connection: keep-alive < Content-Type: text/plain;charset=UTF-8 < transfer-encoding: chunked < * Connection #0 to host localhost left intact OK[cassandra@cluster2-dc2-r1-sts-0 /]$  List again:  [cassandra@cluster2-dc2-r1-sts-0 /]$ curl localhost:8080/api/v0/ops/auth/role [{""datacenters"":""ALL"",""login"":""false"",""name"":""try"",""options"":""{}"",""super"":""false""},{""datacenters"":""ALL"",""login"":""true"",""name"":""cluster2-superuser"",""options"":""{}"",""super"":""true""},{""datacenters"":""ALL"",""login"":""false"",""name"":""cassandra"",""options"":""{}"",""super"":""false""}] [cassandra@cluster2-dc2-r1-sts-0 /]  Delete:  [cassandra@cluster2-dc2-r1-sts-0 /]$ curl -XDELETE 'localhost:8080/api/v0/ops/auth/role/drop?username=try' OK[cassandra@cluster2-dc2-r1-sts-0 /]$  And final list:  cassandra@cluster2-dc2-r1-sts-0 /]$ curl localhost:8080/api/v0/ops/auth/role [{""datacenters"":""ALL"",""login"":""true"",""name"":""cluster2-superuser"",""options"":""{}"",""super"":""true""},{""datacenters"":""ALL"",""login"":""false"",""name"":""cassandra"",""options"":""{}"",""super"":""false""}] [cassandra@cluster2-dc2-r1-sts-0 /]$  Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-80) by [Unito](https://www.unito.io) Issue Number: MAPI-80 documentation-file",no-bug,0.9
419,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/419,Add DSE 6.8.40 to the build matrix,,documentation-file,Add DSE 6.8.40 to the build matrix  documentation-file,no-bug,0.95
604,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/604,Add DSE 6.9.7 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-103) by [Unito](https://www.unito.io) Issue Number: MAPI-103,documentation-file,Add DSE 6.9.7 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-103) by [Unito](https://www.unito.io) Issue Number: MAPI-103 documentation-file,no-bug,0.9
551,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/551,Add Cassandra 5.0.2 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-72) by [Unito](https://www.unito.io) Issue Number: MAPI-72,documentation-file,Add Cassandra 5.0.2 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-72) by [Unito](https://www.unito.io) Issue Number: MAPI-72 documentation-file,no-bug,0.9
577,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/577,Thread Pool metrics for DSE getting truncated,"Thread Pool metrics for DSE getting truncated. Retrieving the metric from http://10.10.10.10:9000/metrics will show:  org_apache_cassandra_metrics_thread_pools_active_tasks{host=""d92991be-3582-43c9-bef9-b2e9f1017c6d"",instance=""10.10.10.10"",cluster=""maac"",datacenter=""Cassandra"",rack=""rack1"",pod_name=""ip-10-10-10-10"",pool_type=""internal"",pool_name=""Repair"",} 0.0 org_apache_cassandra_metrics_thread_pools_active_tasks{host=""d92991be-3582-43c9-bef9-b2e9f1017c6d"",instance=""10.10.10.10"",cluster=""maac"",datacenter=""Cassandra"",rack=""rack1"",pod_name=""ip-10-10-10-10"",pool_type=""internal"",pool_name=""TPC"",} 0.0  However this would be expected to be Repair-Task instead of Repair and instead of TPC be:  TPC/all/BATCH_REMOVE 0 0 (N/A) N/A 24989 N/A 0 TPC/all/EVENTLOOP_PROCESSED_TASKS 0 N/A (N/A) N/A 15246816 N/A N/A TPC/all/EVENTLOOP_SCHEDULED_TASKS 0 N/A (N/A) N/A 26137492 N/A N/A TPC/all/EVENTLOOP_SELECTOR_EVENTS 0 N/A (N/A) N/A 6134785 N/A N/A TPC/all/EVENTLOOP_SELECT_CALLS 1 N/A (N/A) N/A 8991407 N/A N/A TPC/all/EVENTLOOP_SELECT_NOW_CALLS 0 N/A (N/A) N/A 9002688 N/A N/A TPC/all/EVENTLOOP_SPIN 0 N/A (N/A) N/A 80922912 N/A N/A TPC/all/EXECUTE_STATEMENT 0 N/A (N/A) N/A 56 N/A N/A TPC/all/NODESYNC_VALIDATION 0 N/A (N/A) N/A 5194 N/A N/A TPC/all/READ_DISK_ASYNC 0 N/A (N/A) N/A 129 N/A N/A TPC/all/READ_INTERNAL 0 N/A (N/A) N/A 1010946 N/A N/A TPC/all/READ_RANGE_INTERNAL 0 N/A (N/A) N/A 6984 N/A N/A TPC/all/READ_RANGE_LOCAL 0 0 (N/A) N/A 1 N/A 0 TPC/all/READ_RANGE_RESPONSE 0 N/A (N/A) N/A 210 N/A N/A TPC/all/READ_SPECULATE 0 N/A (N/A) N/A 6 N/A N/A TPC/all/READ_RESPONSE 0 N/A (N/A) N/A 1062638 N/A N/A TPC/all/TIMED_TIMEOUT 0 N/A (N/A) N/A 5218530 N/A N/A TPC/all/UNKNOWN 0 N/A (N/A) N/A 1 N/A N/A TPC/all/WRITE_INTERNAL 0 N/A (N/A) N/A 23958 N/A N/A TPC/all/WRITE_LOCAL 0 0 (N/A) N/A 262963 N/A 0 TPC/all/WRITE_REMOTE 0 0 (N/A) N/A 25052 N/A 0 TPC/all/WRITE_MEMTABLE 0 N/A (N/A) N/A 87315 N/A N/A TPC/all/WRITE_RESPONSE 0 N/A (N/A) N/A 536269 N/A N/A  as per https://docs.datastax.com/en/dse/6.8/managing/tools/nodetool/thread-pool-statistics.html It appears that the '-' and '/' characters are not being handled correctly and truncating the metric names. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-87) by [Unito](https://www.unito.io) Issue Number: MAPI-87",documentation-file,"Thread Pool metrics for DSE getting truncated Thread Pool metrics for DSE getting truncated. Retrieving the metric from http://10.10.10.10:9000/metrics will show:  org_apache_cassandra_metrics_thread_pools_active_tasks{host=""d92991be-3582-43c9-bef9-b2e9f1017c6d"",instance=""10.10.10.10"",cluster=""maac"",datacenter=""Cassandra"",rack=""rack1"",pod_name=""ip-10-10-10-10"",pool_type=""internal"",pool_name=""Repair"",} 0.0 org_apache_cassandra_metrics_thread_pools_active_tasks{host=""d92991be-3582-43c9-bef9-b2e9f1017c6d"",instance=""10.10.10.10"",cluster=""maac"",datacenter=""Cassandra"",rack=""rack1"",pod_name=""ip-10-10-10-10"",pool_type=""internal"",pool_name=""TPC"",} 0.0  However this would be expected to be Repair-Task instead of Repair and instead of TPC be:  TPC/all/BATCH_REMOVE 0 0 (N/A) N/A 24989 N/A 0 TPC/all/EVENTLOOP_PROCESSED_TASKS 0 N/A (N/A) N/A 15246816 N/A N/A TPC/all/EVENTLOOP_SCHEDULED_TASKS 0 N/A (N/A) N/A 26137492 N/A N/A TPC/all/EVENTLOOP_SELECTOR_EVENTS 0 N/A (N/A) N/A 6134785 N/A N/A TPC/all/EVENTLOOP_SELECT_CALLS 1 N/A (N/A) N/A 8991407 N/A N/A TPC/all/EVENTLOOP_SELECT_NOW_CALLS 0 N/A (N/A) N/A 9002688 N/A N/A TPC/all/EVENTLOOP_SPIN 0 N/A (N/A) N/A 80922912 N/A N/A TPC/all/EXECUTE_STATEMENT 0 N/A (N/A) N/A 56 N/A N/A TPC/all/NODESYNC_VALIDATION 0 N/A (N/A) N/A 5194 N/A N/A TPC/all/READ_DISK_ASYNC 0 N/A (N/A) N/A 129 N/A N/A TPC/all/READ_INTERNAL 0 N/A (N/A) N/A 1010946 N/A N/A TPC/all/READ_RANGE_INTERNAL 0 N/A (N/A) N/A 6984 N/A N/A TPC/all/READ_RANGE_LOCAL 0 0 (N/A) N/A 1 N/A 0 TPC/all/READ_RANGE_RESPONSE 0 N/A (N/A) N/A 210 N/A N/A TPC/all/READ_SPECULATE 0 N/A (N/A) N/A 6 N/A N/A TPC/all/READ_RESPONSE 0 N/A (N/A) N/A 1062638 N/A N/A TPC/all/TIMED_TIMEOUT 0 N/A (N/A) N/A 5218530 N/A N/A TPC/all/UNKNOWN 0 N/A (N/A) N/A 1 N/A N/A TPC/all/WRITE_INTERNAL 0 N/A (N/A) N/A 23958 N/A N/A TPC/all/WRITE_LOCAL 0 0 (N/A) N/A 262963 N/A 0 TPC/all/WRITE_REMOTE 0 0 (N/A) N/A 25052 N/A 0 TPC/all/WRITE_MEMTABLE 0 N/A (N/A) N/A 87315 N/A N/A TPC/all/WRITE_RESPONSE 0 N/A (N/A) N/A 536269 N/A N/A  as per https://docs.datastax.com/en/dse/6.8/managing/tools/nodetool/thread-pool-statistics.html It appears that the '-' and '/' characters are not being handled correctly and truncating the metric names. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-87) by [Unito](https://www.unito.io) Issue Number: MAPI-87 documentation-file",no-bug,0.9
569,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/569,Add DSE 6.9.4 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-82) by [Unito](https://www.unito.io) Issue Number: MAPI-82,documentation-file,Add DSE 6.9.4 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-82) by [Unito](https://www.unito.io) Issue Number: MAPI-82 documentation-file,no-bug,0.9
511,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/511,Add DSE 6.8.50 to the build matrix,,documentation-file,Add DSE 6.8.50 to the build matrix  documentation-file,no-bug,0.95
593,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/593,Update HCD 1.2 Agent for CC 5.0.2,"Converged Core `5.0.2-94c48ebf299a` was released and pulls in some Cassandra `Dispatcher` class changes that require the HCD 1.2 agent to be updated, similar to changes that went in for the Cassandra 4.1 agent. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-97) by [Unito](https://www.unito.io) Issue Number: MAPI-97",documentation-file,"Update HCD 1.2 Agent for CC 5.0.2 Converged Core `5.0.2-94c48ebf299a` was released and pulls in some Cassandra `Dispatcher` class changes that require the HCD 1.2 agent to be updated, similar to changes that went in for the Cassandra 4.1 agent. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-97) by [Unito](https://www.unito.io) Issue Number: MAPI-97 documentation-file",no-bug,0.9
93,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/93,Remove bintray repo,#92 removed fetching cassandra-bin from jcenter.bintray repo but the repo is still used for resolving com.aries/docker-java-shaded/3.1.1. The artifact is not available in maven central. We need to replace it with unshaded version or find a different repo as according to https://jfrog.com/blog/into-the-sunset-bintray-jcenter-gocenter-and-chartcenter/ bintray shuts down on February 1st 2022.,config-file,Remove bintray repo #92 removed fetching cassandra-bin from jcenter.bintray repo but the repo is still used for resolving com.aries/docker-java-shaded/3.1.1. The artifact is not available in maven central. We need to replace it with unshaded version or find a different repo as according to https://jfrog.com/blog/into-the-sunset-bintray-jcenter-gocenter-and-chartcenter/ bintray shuts down on February 1st 2022. config-file,no-bug,0.9
398,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/398,Make Management API port configurable.,"Currently, the port Management API listens on is [hardcoded to 8080](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/scripts/docker-entrypoint.sh#L182). This could cause port conflicts in certain deployments. [tasklist]  Definition of Done - [ ] All OSS/DSE Docker images are built with a port that is configurable via setting an environment variable - [ ] The current hardcoded port of 8080 should be used if the environment variable is not set/present - [ ] The README is updated to document the environment variable for setting the port. ",documentation-file,"Make Management API port configurable. Currently, the port Management API listens on is [hardcoded to 8080](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/scripts/docker-entrypoint.sh#L182). This could cause port conflicts in certain deployments. [tasklist]  Definition of Done - [ ] All OSS/DSE Docker images are built with a port that is configurable via setting an environment variable - [ ] The current hardcoded port of 8080 should be used if the environment variable is not set/present - [ ] The README is updated to document the environment variable for setting the port.  documentation-file",no-bug,0.9
484,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/484,Rename DSE7 to HCD,DSE7 is rebranded to HCD. We should update the DSE7 artifacts to be labeled HCD.,documentation-file,Rename DSE7 to HCD DSE7 is rebranded to HCD. We should update the DSE7 artifacts to be labeled HCD. documentation-file,no-bug,0.95
522,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/522,Add DSE 6.9.1 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-2) by [Unito](https://www.unito.io) Issue Number: MAPI-2,documentation-file,Add DSE 6.9.1 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-2) by [Unito](https://www.unito.io) Issue Number: MAPI-2 documentation-file,no-bug,0.95
545,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/545,Add Casandra 4.1.7 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-69) by [Unito](https://www.unito.io) Issue Number: MAPI-69,documentation-file,Add Casandra 4.1.7 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-69) by [Unito](https://www.unito.io) Issue Number: MAPI-69 documentation-file,no-bug,0.95
589,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/589,Add DSE 6.9.6 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-95) by [Unito](https://www.unito.io) Issue Number: MAPI-95,documentation-file,Add DSE 6.9.6 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-95) by [Unito](https://www.unito.io) Issue Number: MAPI-95 documentation-file,no-bug,0.95
480,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/480,python 2 missing on ubi cass-management-api images 3.11,"python2(python 2.7) is not included which break cqlsh image: docker.io/k8ssandra/cass-management-api:3.11.16-ubi8 See installed packages here https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/Dockerfile-oss.ubi8#L130  kubectl -n k8ssandra-operator exec -it cluster1-main-az-1a-sts-0 -c cassandra -- /bin/bash [cassandra@cluster1-main-az-1a-sts-0 /]$ cqlsh No appropriate python interpreter found. [cassandra@cluster1-main-az-1a-sts-0 /]$ cat ~/bin/cqlsh #!/bin/sh python -c 'import sys; sys.exit(not (0x020700b0 < sys.hexversion < 0x03000000))' 2>/dev/null \ && exec python ""`python -c ""import os;print(os.path.dirname(os.path.realpath('$0'""`/cqlsh.py"" ""$@"" for pyver in 2.7; do which python$pyver > /dev/null 2>&1 && exec python$pyver ""`python$pyver -c ""import os;print(os.path.dirname(os.path.realpath('$0'""`/cqlsh.py"" ""$@"" done echo ""No appropriate python interpreter found."" >&2 exit 1 [cassandra@cluster1-main-az-1a-sts-0 /]$ rpm -qa | grep python python3-setuptools-wheel-39.2.0-7.el8.noarch platform-python-pip-9.0.3-23.el8.noarch platform-python-3.6.8-56.el8_9.3.x86_64 python3-pip-9.0.3-23.el8.noarch python3-pip-wheel-9.0.3-23.el8.noarch platform-python-setuptools-39.2.0-7.el8.noarch python3-libs-3.6.8-56.el8_9.3.x86_64 python3-setuptools-39.2.0-7.el8.noarch python36-3.6.8-38.module+el8.9.0+20976+d3c38525.x86_64 ",documentation-file,"python 2 missing on ubi cass-management-api images 3.11 python2(python 2.7) is not included which break cqlsh image: docker.io/k8ssandra/cass-management-api:3.11.16-ubi8 See installed packages here https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/Dockerfile-oss.ubi8#L130  kubectl -n k8ssandra-operator exec -it cluster1-main-az-1a-sts-0 -c cassandra -- /bin/bash [cassandra@cluster1-main-az-1a-sts-0 /]$ cqlsh No appropriate python interpreter found. [cassandra@cluster1-main-az-1a-sts-0 /]$ cat ~/bin/cqlsh #!/bin/sh python -c 'import sys; sys.exit(not (0x020700b0 < sys.hexversion < 0x03000000))' 2>/dev/null \ && exec python ""`python -c ""import os;print(os.path.dirname(os.path.realpath('$0'""`/cqlsh.py"" ""$@"" for pyver in 2.7; do which python$pyver > /dev/null 2>&1 && exec python$pyver ""`python$pyver -c ""import os;print(os.path.dirname(os.path.realpath('$0'""`/cqlsh.py"" ""$@"" done echo ""No appropriate python interpreter found."" >&2 exit 1 [cassandra@cluster1-main-az-1a-sts-0 /]$ rpm -qa | grep python python3-setuptools-wheel-39.2.0-7.el8.noarch platform-python-pip-9.0.3-23.el8.noarch platform-python-3.6.8-56.el8_9.3.x86_64 python3-pip-9.0.3-23.el8.noarch python3-pip-wheel-9.0.3-23.el8.noarch platform-python-setuptools-39.2.0-7.el8.noarch python3-libs-3.6.8-56.el8_9.3.x86_64 python3-setuptools-39.2.0-7.el8.noarch python36-3.6.8-38.module+el8.9.0+20976+d3c38525.x86_64  documentation-file",no-bug,0.9
562,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/562,Fix version detection,"The Metrics fix for #560 unfortunately doesn't work for DSE builds:  ERROR [DSE main thread] 2024-10-28 18:34:25,661 MetricsInterceptor.java:92 - Unable to start metrics endpoint java.lang.NoClassDefFoundError: org/apache/cassandra/utils/CassandraVersion at io.k8ssandra.metrics.builder.CassandraMetricRegistryListener.<init>(CassandraMetricRegistryListener.java:89) at io.k8ssandra.metrics.prometheus.CassandraDropwizardExports.<init>(CassandraDropwizardExports.java:42) at io.k8ssandra.metrics.interceptors.MetricsInterceptor.intercept(MetricsInterceptor.java:71) at org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java) at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:559) at org.apache.cassandra.service.CassandraDaemon.activate0(CassandraDaemon.java:830) at org.apache.cassandra.service.CassandraDaemon.access$100(CassandraDaemon.java:93) at org.apache.cassandra.service.CassandraDaemon$3.run(CassandraDaemon.java:738) Caused by: java.lang.ClassNotFoundException: org.apache.cassandra.utils.CassandraVersion at java.net.URLClassLoader.findClass(URLClassLoader.java:387) at java.lang.ClassLoader.loadClass(ClassLoader.java:418) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) at java.lang.ClassLoader.loadClass(ClassLoader.java:351)  8 common frames omitted  Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-78) by [Unito](https://www.unito.io) Issue Number: MAPI-78",documentation-file,"Fix version detection The Metrics fix for #560 unfortunately doesn't work for DSE builds:  ERROR [DSE main thread] 2024-10-28 18:34:25,661 MetricsInterceptor.java:92 - Unable to start metrics endpoint java.lang.NoClassDefFoundError: org/apache/cassandra/utils/CassandraVersion at io.k8ssandra.metrics.builder.CassandraMetricRegistryListener.<init>(CassandraMetricRegistryListener.java:89) at io.k8ssandra.metrics.prometheus.CassandraDropwizardExports.<init>(CassandraDropwizardExports.java:42) at io.k8ssandra.metrics.interceptors.MetricsInterceptor.intercept(MetricsInterceptor.java:71) at org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java) at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:559) at org.apache.cassandra.service.CassandraDaemon.activate0(CassandraDaemon.java:830) at org.apache.cassandra.service.CassandraDaemon.access$100(CassandraDaemon.java:93) at org.apache.cassandra.service.CassandraDaemon$3.run(CassandraDaemon.java:738) Caused by: java.lang.ClassNotFoundException: org.apache.cassandra.utils.CassandraVersion at java.net.URLClassLoader.findClass(URLClassLoader.java:387) at java.lang.ClassLoader.loadClass(ClassLoader.java:418) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) at java.lang.ClassLoader.loadClass(ClassLoader.java:351)  8 common frames omitted  Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-78) by [Unito](https://www.unito.io) Issue Number: MAPI-78 documentation-file",no-bug,0.9
544,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/544,Add Casandra 4.0.14 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-68) by [Unito](https://www.unito.io) Issue Number: MAPI-68,documentation-file,Add Casandra 4.0.14 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-68) by [Unito](https://www.unito.io) Issue Number: MAPI-68 documentation-file,no-bug,0.9
232,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/232,Add Cassandra 4.1 support,,documentation-file | container-file | documentation-file | config-file | documentation-file | container-file | documentation-file | config-file,Add Cassandra 4.1 support  documentation-file container-file documentation-file config-file documentation-file container-file documentation-file config-file,no-bug,0.9
453,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/453,Use a longer driver timeout for drain,"In some scenarios, the drain operation can take longer than 30 seconds (the [configured driver requesttimetout](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-server/src/main/java/com/datastax/mgmtapi/UnixSocketCQLAccess.java#L131)). Ideally, the call to drain a node would be asynchronous and a new endpoint could be added to poll the status of the drain. However, it would maybe be beneficial to simply adding a ""slow"" driver execution profile for this, and change the implementation of drain to make a CQL query with the slow profile enabled (see the [Java driver docs](https://docs.datastax.com/en/developer/java-driver/4.17/manual/core/configuration/#execution-profiles) for more details on execution profiles). This ""slow"" execution profile could also be used for other Management API functions that could take longer than 30 seconds to complete under the hood, with the benefit of being able to make the change to management API and not having to make changes on down-stream projects (like cass-operator).",documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | container-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | container-file | config-file | container-file | config-file | container-file | container-file | container-file | config-file | config-file | source-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | config-file | container-file | config-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | container-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | container-file | config-file | container-file | config-file | container-file | container-file | container-file | config-file | config-file | source-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | config-file | container-file | config-file,"Use a longer driver timeout for drain In some scenarios, the drain operation can take longer than 30 seconds (the [configured driver requesttimetout](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-server/src/main/java/com/datastax/mgmtapi/UnixSocketCQLAccess.java#L131)). Ideally, the call to drain a node would be asynchronous and a new endpoint could be added to poll the status of the drain. However, it would maybe be beneficial to simply adding a ""slow"" driver execution profile for this, and change the implementation of drain to make a CQL query with the slow profile enabled (see the [Java driver docs](https://docs.datastax.com/en/developer/java-driver/4.17/manual/core/configuration/#execution-profiles) for more details on execution profiles). This ""slow"" execution profile could also be used for other Management API functions that could take longer than 30 seconds to complete under the hood, with the benefit of being able to make the change to management API and not having to make changes on down-stream projects (like cass-operator). documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file container-file container-file container-file container-file container-file container-file container-file documentation-file container-file config-file container-file config-file container-file container-file container-file config-file config-file source-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file config-file config-file container-file config-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file container-file container-file container-file container-file container-file container-file container-file documentation-file container-file config-file container-file config-file container-file container-file container-file config-file config-file source-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file config-file config-file container-file config-file",no-bug,0.9
475,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/475,Add DSE 6.8.47 to the build matrix,,documentation-file | container-file | documentation-file | container-file,Add DSE 6.8.47 to the build matrix  documentation-file container-file documentation-file container-file,no-bug,0.95
534,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/534,Add DSE 6.8.51 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-63) by [Unito](https://www.unito.io) Issue Number: MAPI-63,documentation-file,Add DSE 6.8.51 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-63) by [Unito](https://www.unito.io) Issue Number: MAPI-63 documentation-file,no-bug,0.95
520,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/520,Update DSE 6.9.0 dependnecy,"With the v0.1.84 release, the DSE 6.9 agent pom file did not update the dependency version (https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-agent-dse-6.9/pom.xml#L33). It shouldn't cause a problem for now, but it should be updated ASAP. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-3) by [Unito](https://www.unito.io) Issue Number: MAPI-3",documentation-file,"Update DSE 6.9.0 dependnecy With the v0.1.84 release, the DSE 6.9 agent pom file did not update the dependency version (https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-agent-dse-6.9/pom.xml#L33). It shouldn't cause a problem for now, but it should be updated ASAP. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-3) by [Unito](https://www.unito.io) Issue Number: MAPI-3 documentation-file",no-bug,0.9
564,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/564,Fix LatencyMetrics for DSE,"The fix for #560 and #562 still do not correctly handle DSE. DSE metrics for the buckets will still be nanosecond, like Cassandra 3.11/4.0, but the logic treats server versions greater than 4 as Cassandra 4.1/5.0. The logic needs to account for DSE server versions still being in nanosecond resolution Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-79) by [Unito](https://www.unito.io) Issue Number: MAPI-79",documentation-file,"Fix LatencyMetrics for DSE The fix for #560 and #562 still do not correctly handle DSE. DSE metrics for the buckets will still be nanosecond, like Cassandra 3.11/4.0, but the logic treats server versions greater than 4 as Cassandra 4.1/5.0. The logic needs to account for DSE server versions still being in nanosecond resolution Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-79) by [Unito](https://www.unito.io) Issue Number: MAPI-79 documentation-file",no-bug,0.9
463,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/463,Remove `cassandra-topology.properties` from the configuration folder,"In order to avoid some weird and annoying bugs with the GossipPropertyFileSnitch still considering the `cassandra-topology.properties` file in some cases, which could cause unsafe instant topology changes, we should remove the file altogether at runtime. [tasklist]  Definition of Done - [ ] The `cassandra-topology.properties` is deleted from disk before Cassandra starts up ",documentation-file,"Remove `cassandra-topology.properties` from the configuration folder In order to avoid some weird and annoying bugs with the GossipPropertyFileSnitch still considering the `cassandra-topology.properties` file in some cases, which could cause unsafe instant topology changes, we should remove the file altogether at runtime. [tasklist]  Definition of Done - [ ] The `cassandra-topology.properties` is deleted from disk before Cassandra starts up  documentation-file",no-bug,0.9
467,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/467,Add DSE 6.8.44 to the build matrix,,documentation-file,Add DSE 6.8.44 to the build matrix  documentation-file,no-bug,0.95
441,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/441,Replace ShellUtils arbitrary command execution,"The [ShellUtils](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-common/src/main/java/com/datastax/mgmtapi/util/ShellUtils.java) class allows for arbitrary command execution [here](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-common/src/main/java/com/datastax/mgmtapi/util/ShellUtils.java#L112), [here](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-common/src/main/java/com/datastax/mgmtapi/util/ShellUtils.java#L96), and [here](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-common/src/main/java/com/datastax/mgmtapi/util/ShellUtils.java#L120). We should refactor this class so that the commands executed are sanitized, similar to what was done in DSE for [DSP-22272](https://datastax.jira.com/browse/DSP-22272)",documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | container-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | container-file | config-file | container-file | config-file | container-file | container-file | container-file | config-file | config-file | source-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | config-file | container-file | config-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | container-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | container-file | config-file | container-file | config-file | container-file | container-file | container-file | config-file | config-file | source-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | config-file | container-file | config-file,"Replace ShellUtils arbitrary command execution The [ShellUtils](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-common/src/main/java/com/datastax/mgmtapi/util/ShellUtils.java) class allows for arbitrary command execution [here](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-common/src/main/java/com/datastax/mgmtapi/util/ShellUtils.java#L112), [here](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-common/src/main/java/com/datastax/mgmtapi/util/ShellUtils.java#L96), and [here](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-common/src/main/java/com/datastax/mgmtapi/util/ShellUtils.java#L120). We should refactor this class so that the commands executed are sanitized, similar to what was done in DSE for [DSP-22272](https://datastax.jira.com/browse/DSP-22272) documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file container-file container-file container-file container-file container-file container-file container-file documentation-file container-file config-file container-file config-file container-file container-file container-file config-file config-file source-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file config-file config-file container-file config-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file container-file container-file container-file container-file container-file container-file container-file documentation-file container-file config-file container-file config-file container-file container-file container-file config-file config-file source-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file config-file config-file container-file config-file",no-bug,0.9
507,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/507,SSL Context Hot Reloading doesn't work as expected,"[SSLContext reload](https://github.com/k8ssandra/management-api-for-apache-cassandra/pull/376) does not seem to be updated when cert files are changed. It seems that even though a log message is displayed that changes have been detected in the files, the actual SSLContext for the server remains unchanged. Steps to reproduce. 1. Create a short lived cert that will expire in a few minutes to use as a cert for the server 2. Update cert to a longer lived cert 3. Verify the `Detected change in the SSL/TLS certificates, reloading` log occurs 4. Execute a local curl command e.g. `curl --cert tls.crt --key tls.key --cacert ca.crt https://localhost:8080/api/v0/lifecycle/pid` with updated certs 5. Output of above command will be `SSL certificate problem: certificate has expired` even though the certs should have been updated to the long-lived cert Restarting the management api process (and therefore restarting Cassandra) will result in the process picking up the new cert, however, it would be great if the restart was not necessary",documentation-file,"SSL Context Hot Reloading doesn't work as expected [SSLContext reload](https://github.com/k8ssandra/management-api-for-apache-cassandra/pull/376) does not seem to be updated when cert files are changed. It seems that even though a log message is displayed that changes have been detected in the files, the actual SSLContext for the server remains unchanged. Steps to reproduce. 1. Create a short lived cert that will expire in a few minutes to use as a cert for the server 2. Update cert to a longer lived cert 3. Verify the `Detected change in the SSL/TLS certificates, reloading` log occurs 4. Execute a local curl command e.g. `curl --cert tls.crt --key tls.key --cacert ca.crt https://localhost:8080/api/v0/lifecycle/pid` with updated certs 5. Output of above command will be `SSL certificate problem: certificate has expired` even though the certs should have been updated to the long-lived cert Restarting the management api process (and therefore restarting Cassandra) will result in the process picking up the new cert, however, it would be great if the restart was not necessary documentation-file",no-bug,0.9
512,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/512,Dubious metric names in Prometheus,"While inspecting Cassandra related metrics in our Prometheus server, I noticed that some metrics were badly re-labelled from the Cassandra model to the Prometheus model leading to numerous Prometheus metric . For example: * org_apache_cassandra_metrics_connection_large_message_dropped_tasks_201_24_56_224_7000 * org_apache_cassandra_metrics_connection_large_message_dropped_tasks_201_24_110_239_7000 I'm using the new metric endpoint without any additional configuration. Impacted metrics are the following (I stripped the port, ip address, etc. to obtain expected metric name):  io_cassandrareaper_management_ICassandraManagementProxy_connections io_cassandrareaper_management_jmx_JmxCassandraManagementProxy_cpicassandracluster_repairStatusHandlers io_cassandrareaper_service_SegmentRunner_abort org_apache_cassandra_metrics_connection_gossip_message_completed_tasks org_apache_cassandra_metrics_connection_gossip_message_dropped_tasks org_apache_cassandra_metrics_connection_gossip_message_pending_tasks org_apache_cassandra_metrics_connection_large_message_completed_bytes org_apache_cassandra_metrics_connection_large_message_completed_tasks org_apache_cassandra_metrics_connection_large_message_dropped_bytes_due_to_error org_apache_cassandra_metrics_connection_large_message_dropped_bytes_due_to_overload org_apache_cassandra_metrics_connection_large_message_dropped_bytes_due_to_timeout org_apache_cassandra_metrics_connection_large_message_dropped_tasks org_apache_cassandra_metrics_connection_large_message_dropped_tasks_due_to_error org_apache_cassandra_metrics_connection_large_message_dropped_tasks_due_to_overload org_apache_cassandra_metrics_connection_large_message_dropped_tasks_due_to_timeout org_apache_cassandra_metrics_connection_large_message_pending_bytes org_apache_cassandra_metrics_connection_large_message_pending_tasks org_apache_cassandra_metrics_connection_small_message_completed_bytes org_apache_cassandra_metrics_connection_small_message_completed_tasks org_apache_cassandra_metrics_connection_small_message_dropped_bytes_due_to_error org_apache_cassandra_metrics_connection_small_message_dropped_bytes_due_to_overload org_apache_cassandra_metrics_connection_small_message_dropped_bytes_due_to_timeout org_apache_cassandra_metrics_connection_small_message_dropped_tasks org_apache_cassandra_metrics_connection_small_message_dropped_tasks_due_to_error org_apache_cassandra_metrics_connection_small_message_dropped_tasks_due_to_overload org_apache_cassandra_metrics_connection_small_message_dropped_tasks_due_to_timeout org_apache_cassandra_metrics_connection_small_message_pending_bytes org_apache_cassandra_metrics_connection_small_message_pending_tasks org_apache_cassandra_metrics_connection_timeouts_total org_apache_cassandra_metrics_connection_urgent_message_completed_bytes org_apache_cassandra_metrics_connection_urgent_message_completed_tasks org_apache_cassandra_metrics_connection_urgent_message_dropped_bytes_due_to_error org_apache_cassandra_metrics_connection_urgent_message_dropped_bytes_due_to_overload org_apache_cassandra_metrics_connection_urgent_message_dropped_bytes_due_to_timeout org_apache_cassandra_metrics_connection_urgent_message_dropped_tasks org_apache_cassandra_metrics_connection_urgent_message_dropped_tasks_due_to_error org_apache_cassandra_metrics_connection_urgent_message_dropped_tasks_due_to_overload org_apache_cassandra_metrics_connection_urgent_message_dropped_tasks_due_to_timeout org_apache_cassandra_metrics_connection_urgent_message_pending_bytes org_apache_cassandra_metrics_connection_urgent_message_pending_tasks org_apache_cassandra_metrics_hints_service_hint_delays org_apache_cassandra_metrics_hints_service_hint_delays_count org_apache_cassandra_metrics_hints_service_hints_created org_apache_cassandra_metrics_hints_service_hints_not_stored org_apache_cassandra_metrics_inbound_connection_corrupt_frames_recovered org_apache_cassandra_metrics_inbound_connection_corrupt_frames_unrecovered org_apache_cassandra_metrics_inbound_connection_error_bytes org_apache_cassandra_metrics_inbound_connection_error_count org_apache_cassandra_metrics_inbound_connection_expired_bytes org_apache_cassandra_metrics_inbound_connection_expired_count org_apache_cassandra_metrics_inbound_connection_processed_bytes org_apache_cassandra_metrics_inbound_connection_processed_count org_apache_cassandra_metrics_inbound_connection_received_bytes org_apache_cassandra_metrics_inbound_connection_received_count org_apache_cassandra_metrics_inbound_connection_scheduled_bytes org_apache_cassandra_metrics_inbound_connection_scheduled_count org_apache_cassandra_metrics_inbound_connection_throttled_count org_apache_cassandra_metrics_inbound_connection_throttled_nanos  None of those metrics seems documented in https://cassandra.apache.org/doc/stable/cassandra/operating/metrics.html#client-metrics but it's easy to find them in Cassandra source code. Should the default relabel configuration be updated to take those metrics into account or am I doing something wrong?",documentation-file,"Dubious metric names in Prometheus While inspecting Cassandra related metrics in our Prometheus server, I noticed that some metrics were badly re-labelled from the Cassandra model to the Prometheus model leading to numerous Prometheus metric . For example: * org_apache_cassandra_metrics_connection_large_message_dropped_tasks_201_24_56_224_7000 * org_apache_cassandra_metrics_connection_large_message_dropped_tasks_201_24_110_239_7000 I'm using the new metric endpoint without any additional configuration. Impacted metrics are the following (I stripped the port, ip address, etc. to obtain expected metric name):  io_cassandrareaper_management_ICassandraManagementProxy_connections io_cassandrareaper_management_jmx_JmxCassandraManagementProxy_cpicassandracluster_repairStatusHandlers io_cassandrareaper_service_SegmentRunner_abort org_apache_cassandra_metrics_connection_gossip_message_completed_tasks org_apache_cassandra_metrics_connection_gossip_message_dropped_tasks org_apache_cassandra_metrics_connection_gossip_message_pending_tasks org_apache_cassandra_metrics_connection_large_message_completed_bytes org_apache_cassandra_metrics_connection_large_message_completed_tasks org_apache_cassandra_metrics_connection_large_message_dropped_bytes_due_to_error org_apache_cassandra_metrics_connection_large_message_dropped_bytes_due_to_overload org_apache_cassandra_metrics_connection_large_message_dropped_bytes_due_to_timeout org_apache_cassandra_metrics_connection_large_message_dropped_tasks org_apache_cassandra_metrics_connection_large_message_dropped_tasks_due_to_error org_apache_cassandra_metrics_connection_large_message_dropped_tasks_due_to_overload org_apache_cassandra_metrics_connection_large_message_dropped_tasks_due_to_timeout org_apache_cassandra_metrics_connection_large_message_pending_bytes org_apache_cassandra_metrics_connection_large_message_pending_tasks org_apache_cassandra_metrics_connection_small_message_completed_bytes org_apache_cassandra_metrics_connection_small_message_completed_tasks org_apache_cassandra_metrics_connection_small_message_dropped_bytes_due_to_error org_apache_cassandra_metrics_connection_small_message_dropped_bytes_due_to_overload org_apache_cassandra_metrics_connection_small_message_dropped_bytes_due_to_timeout org_apache_cassandra_metrics_connection_small_message_dropped_tasks org_apache_cassandra_metrics_connection_small_message_dropped_tasks_due_to_error org_apache_cassandra_metrics_connection_small_message_dropped_tasks_due_to_overload org_apache_cassandra_metrics_connection_small_message_dropped_tasks_due_to_timeout org_apache_cassandra_metrics_connection_small_message_pending_bytes org_apache_cassandra_metrics_connection_small_message_pending_tasks org_apache_cassandra_metrics_connection_timeouts_total org_apache_cassandra_metrics_connection_urgent_message_completed_bytes org_apache_cassandra_metrics_connection_urgent_message_completed_tasks org_apache_cassandra_metrics_connection_urgent_message_dropped_bytes_due_to_error org_apache_cassandra_metrics_connection_urgent_message_dropped_bytes_due_to_overload org_apache_cassandra_metrics_connection_urgent_message_dropped_bytes_due_to_timeout org_apache_cassandra_metrics_connection_urgent_message_dropped_tasks org_apache_cassandra_metrics_connection_urgent_message_dropped_tasks_due_to_error org_apache_cassandra_metrics_connection_urgent_message_dropped_tasks_due_to_overload org_apache_cassandra_metrics_connection_urgent_message_dropped_tasks_due_to_timeout org_apache_cassandra_metrics_connection_urgent_message_pending_bytes org_apache_cassandra_metrics_connection_urgent_message_pending_tasks org_apache_cassandra_metrics_hints_service_hint_delays org_apache_cassandra_metrics_hints_service_hint_delays_count org_apache_cassandra_metrics_hints_service_hints_created org_apache_cassandra_metrics_hints_service_hints_not_stored org_apache_cassandra_metrics_inbound_connection_corrupt_frames_recovered org_apache_cassandra_metrics_inbound_connection_corrupt_frames_unrecovered org_apache_cassandra_metrics_inbound_connection_error_bytes org_apache_cassandra_metrics_inbound_connection_error_count org_apache_cassandra_metrics_inbound_connection_expired_bytes org_apache_cassandra_metrics_inbound_connection_expired_count org_apache_cassandra_metrics_inbound_connection_processed_bytes org_apache_cassandra_metrics_inbound_connection_processed_count org_apache_cassandra_metrics_inbound_connection_received_bytes org_apache_cassandra_metrics_inbound_connection_received_count org_apache_cassandra_metrics_inbound_connection_scheduled_bytes org_apache_cassandra_metrics_inbound_connection_scheduled_count org_apache_cassandra_metrics_inbound_connection_throttled_count org_apache_cassandra_metrics_inbound_connection_throttled_nanos  None of those metrics seems documented in https://cassandra.apache.org/doc/stable/cassandra/operating/metrics.html#client-metrics but it's easy to find them in Cassandra source code. Should the default relabel configuration be updated to take those metrics into account or am I doing something wrong? documentation-file",no-bug,0.9
422,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/422,Metrics endpoint fails to start for some DSE images,"Some newer DSE images fail to startup the metrics endpoint due to library upgrades:  ERROR [DSE main thread] 2023-11-14 13:13:12,810 MetricsInterceptor.java:92 - Unable to start metrics endpoint java.lang.NoSuchMethodError: org.yaml.snakeyaml.parser.ParserImpl.<init>(Lorg/yaml/snakeyaml/reader/StreamReader;)V at com.fasterxml.jackson.dataformat.yaml.YAMLParser.<init>(YAMLParser.java:178) at com.fasterxml.jackson.dataformat.yaml.YAMLFactory._createParser(YAMLFactory.java:471) at com.fasterxml.jackson.dataformat.yaml.YAMLFactory.createParser(YAMLFactory.java:375) at com.fasterxml.jackson.dataformat.yaml.YAMLFactory.createParser(YAMLFactory.java:15) at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3642) at io.k8ssandra.metrics.config.ConfigReader.readConfig(ConfigReader.java:38) at io.k8ssandra.metrics.interceptors.MetricsInterceptor.intercept(MetricsInterceptor.java:68) at org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java) at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:559) at org.apache.cassandra.service.CassandraDaemon.activate0(CassandraDaemon.java:830) at org.apache.cassandra.service.CassandraDaemon.access$100(CassandraDaemon.java:93) at org.apache.cassandra.service.CassandraDaemon$3.run(CassandraDaemon.java:738) ",documentation-file,"Metrics endpoint fails to start for some DSE images Some newer DSE images fail to startup the metrics endpoint due to library upgrades:  ERROR [DSE main thread] 2023-11-14 13:13:12,810 MetricsInterceptor.java:92 - Unable to start metrics endpoint java.lang.NoSuchMethodError: org.yaml.snakeyaml.parser.ParserImpl.<init>(Lorg/yaml/snakeyaml/reader/StreamReader;)V at com.fasterxml.jackson.dataformat.yaml.YAMLParser.<init>(YAMLParser.java:178) at com.fasterxml.jackson.dataformat.yaml.YAMLFactory._createParser(YAMLFactory.java:471) at com.fasterxml.jackson.dataformat.yaml.YAMLFactory.createParser(YAMLFactory.java:375) at com.fasterxml.jackson.dataformat.yaml.YAMLFactory.createParser(YAMLFactory.java:15) at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3642) at io.k8ssandra.metrics.config.ConfigReader.readConfig(ConfigReader.java:38) at io.k8ssandra.metrics.interceptors.MetricsInterceptor.intercept(MetricsInterceptor.java:68) at org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java) at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:559) at org.apache.cassandra.service.CassandraDaemon.activate0(CassandraDaemon.java:830) at org.apache.cassandra.service.CassandraDaemon.access$100(CassandraDaemon.java:93) at org.apache.cassandra.service.CassandraDaemon$3.run(CassandraDaemon.java:738)  documentation-file",no-bug,0.9
88,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/88,Fix cassandra user's HOME directory,"See [this issue](https://github.com/k8ssandra/k8ssandra/issues/396) Essentially, now that Management API runs as the `cassandra` user, that user's effective HOME directory should exist and be writable by that user. We can either: 1) Create the default HOME directory of `/home/cassandra` and set the correct permissions, or 2) Run a `usermod` command to alter the home directory to `/opt/cassandra` which is already setup with correct permissions.",container-file | container-file | container-file,"Fix cassandra user's HOME directory See [this issue](https://github.com/k8ssandra/k8ssandra/issues/396) Essentially, now that Management API runs as the `cassandra` user, that user's effective HOME directory should exist and be writable by that user. We can either: 1) Create the default HOME directory of `/home/cassandra` and set the correct permissions, or 2) Run a `usermod` command to alter the home directory to `/opt/cassandra` which is already setup with correct permissions. container-file container-file container-file",no-bug,0.95
568,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/568,Add DSE 6.8.52 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-81) by [Unito](https://www.unito.io) Issue Number: MAPI-81,documentation-file,Add DSE 6.8.52 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-81) by [Unito](https://www.unito.io) Issue Number: MAPI-81 documentation-file,no-bug,0.9
413,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/413,UBI8 images do not terminate correctly,"In testing the UBI8 Cassandra images in cass-operator, it was observed that these images don't terminate the same way as the Ubuntu based images. This is likely due to how the image creates the process. [tasklist]  DoD [ ] - UBI8 based images should create the same style process as Ubuntu based images so that termination is the same ",documentation-file,"UBI8 images do not terminate correctly In testing the UBI8 Cassandra images in cass-operator, it was observed that these images don't terminate the same way as the Ubuntu based images. This is likely due to how the image creates the process. [tasklist]  DoD [ ] - UBI8 based images should create the same style process as Ubuntu based images so that termination is the same  documentation-file",no-bug,0.9
486,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/486,Support HCD,"Management API assumes that either Cassandra or DSE is the server database, and that the effective start command is `cassandra` or `dse` (respectively), and that he start command exists in a `bin` directory under the location pointed to by system environment variable `CASSANDRA_HOME` or `DSE_HOME`, again respectively. ## Problem: Since #484, HCD (Hyper-Converged Database) is replacing DSE7. While #485 rebranded DSE7 to HCD, it did not account for new start command binaries or new system environment variables (`hcd` and `HCD_HOME` respectively). ## Solution: Management API server core needs to accommodate the new HCD environment and support new start command binaries and system variables",documentation-file,"Support HCD Management API assumes that either Cassandra or DSE is the server database, and that the effective start command is `cassandra` or `dse` (respectively), and that he start command exists in a `bin` directory under the location pointed to by system environment variable `CASSANDRA_HOME` or `DSE_HOME`, again respectively. ## Problem: Since #484, HCD (Hyper-Converged Database) is replacing DSE7. While #485 rebranded DSE7 to HCD, it did not account for new start command binaries or new system environment variables (`hcd` and `HCD_HOME` respectively). ## Solution: Management API server core needs to accommodate the new HCD environment and support new start command binaries and system variables documentation-file",no-bug,0.9
602,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/602,Add Cassandra 4.0.17 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-101) by [Unito](https://www.unito.io) Issue Number: MAPI-101,documentation-file,Add Cassandra 4.0.17 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-101) by [Unito](https://www.unito.io) Issue Number: MAPI-101 documentation-file,no-bug,0.95
461,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/461,Add Cassandra 5.0-beta1 to the build matrix,,documentation-file,Add Cassandra 5.0-beta1 to the build matrix  documentation-file,no-bug,0.95
608,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/608,Refactor HCD Agents,"The Agents for HCD have been under some fluctuation lately due to Converged Cassandra changes. Currently, HCD 1.1 is based on CC 4, while HCD 1.2 is based on CC 5. However, HCD 1.2 will soon switch back to CC 4. All of the underlying CC versions and changes create compilation and runtime issues for the Agent, which is why we have different Agents for Cassandra 4.0, 4.1 and 5.0, as well as DSE 6.8 and DSE 6.9. Since HCD 1.1 and 1.2 are now going to be CC 4 based, it might be better to refactor the HCD agent modules in this project to reflect the CC version as opposed to the HCD version. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-104) by [Unito](https://www.unito.io) Issue Number: MAPI-104",documentation-file,"Refactor HCD Agents The Agents for HCD have been under some fluctuation lately due to Converged Cassandra changes. Currently, HCD 1.1 is based on CC 4, while HCD 1.2 is based on CC 5. However, HCD 1.2 will soon switch back to CC 4. All of the underlying CC versions and changes create compilation and runtime issues for the Agent, which is why we have different Agents for Cassandra 4.0, 4.1 and 5.0, as well as DSE 6.8 and DSE 6.9. Since HCD 1.1 and 1.2 are now going to be CC 4 based, it might be better to refactor the HCD agent modules in this project to reflect the CC version as opposed to the HCD version. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-104) by [Unito](https://www.unito.io) Issue Number: MAPI-104 documentation-file",no-bug,0.9
590,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/590,Fix Artifact release to also publish HCD 1.2 Agent,"With the v0.1.91 Release, a new HCD 1.2 agent was added, but the artifact was not included in the Release zip bundle. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-96) by [Unito](https://www.unito.io) Issue Number: MAPI-96",documentation-file,"Fix Artifact release to also publish HCD 1.2 Agent With the v0.1.91 Release, a new HCD 1.2 agent was added, but the artifact was not included in the Release zip bundle. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-96) by [Unito](https://www.unito.io) Issue Number: MAPI-96 documentation-file",no-bug,0.9
432,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/432,Improve version management," Issue: The Management API version of releases has been controlled by an automated process that triggers on a tag being pushed. The release process publishes artifacts to Cloudsmith.io where the Maven version is overridden on the command line used to publish the artifacts. It is never actually set in the Maven pom.xml files to anything other than `0.1.0-SNAPSHOT`. In addition to publishing artifacts in Cloudsmith.io, the jarfiles are also zipped up and attached to a GitHub release. However, the zip bundle contains the jarfiles with a version that is still `0.1.0-SNAPSHOT`, making it very difficult to determine which version of the artifact you are using.  Definition of Done * [ ] The release process should update the version in the POM files so that it keeps up with the current version Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-14) by [Unito](https://www.unito.io) Issue Number: MAPI-14",documentation-file,"Improve version management  Issue: The Management API version of releases has been controlled by an automated process that triggers on a tag being pushed. The release process publishes artifacts to Cloudsmith.io where the Maven version is overridden on the command line used to publish the artifacts. It is never actually set in the Maven pom.xml files to anything other than `0.1.0-SNAPSHOT`. In addition to publishing artifacts in Cloudsmith.io, the jarfiles are also zipped up and attached to a GitHub release. However, the zip bundle contains the jarfiles with a version that is still `0.1.0-SNAPSHOT`, making it very difficult to determine which version of the artifact you are using.  Definition of Done * [ ] The release process should update the version in the POM files so that it keeps up with the current version Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-14) by [Unito](https://www.unito.io) Issue Number: MAPI-14 documentation-file",no-bug,0.9
541,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/541,readOnlyRootFilesystem still fails due to some Spark folders in OpenShift,"We've seen that OpenShift is still having some issues with the readOnlyRootFilesystem feature. In the Dockerfile, we create additional directories for Spark: https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/dse/Dockerfile-dse6.8.jdk11#L171-L175 Then in the entrypoint.sh, we create subdirectories for Spark in some of the above directories: https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/dse/files/entrypoint.sh#L15-L18 While this works fine with ""standard"" Kubernetes distributions (including GKE), OpenShift isn't happy about it. Standard distros seem to allow writes to these directories which OpenShift disallows. We should remove the creation of these directories in the Dockerfile and rely on mounts at runtime instead, and have the entrypoint check for the presence of the directories before trying to create the additional subdirectories. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-66) by [Unito](https://www.unito.io) Issue Number: MAPI-66",documentation-file,"readOnlyRootFilesystem still fails due to some Spark folders in OpenShift We've seen that OpenShift is still having some issues with the readOnlyRootFilesystem feature. In the Dockerfile, we create additional directories for Spark: https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/dse/Dockerfile-dse6.8.jdk11#L171-L175 Then in the entrypoint.sh, we create subdirectories for Spark in some of the above directories: https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/dse/files/entrypoint.sh#L15-L18 While this works fine with ""standard"" Kubernetes distributions (including GKE), OpenShift isn't happy about it. Standard distros seem to allow writes to these directories which OpenShift disallows. We should remove the creation of these directories in the Dockerfile and rely on mounts at runtime instead, and have the entrypoint check for the presence of the directories before trying to create the additional subdirectories. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-66) by [Unito](https://www.unito.io) Issue Number: MAPI-66 documentation-file",no-bug,0.9
415,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/415,Some jvm_* metrics aren't labelled correctly,"JVM metrics aren't labelled with common labels that we apply to all the `org_apache_cassandra_metrics*` ones such as: cluster, datacenter, rack, pod_name, node_name. We need all jvm metrics to be labelled appropriately so that we can build consistent dashboards. [tasklist]  Definition of Done - [x] `jvm_*` metrics are labelled like the `org_apache_cassandra_metrics` are ",documentation-file,"Some jvm_* metrics aren't labelled correctly JVM metrics aren't labelled with common labels that we apply to all the `org_apache_cassandra_metrics*` ones such as: cluster, datacenter, rack, pod_name, node_name. We need all jvm metrics to be labelled appropriately so that we can build consistent dashboards. [tasklist]  Definition of Done - [x] `jvm_*` metrics are labelled like the `org_apache_cassandra_metrics` are  documentation-file",no-bug,0.9
531,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/531,Fix DSE 6.9 UBI image agent loading,"Since the change was made to support read-only root filesystems (https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/521), the DSE 6.9 UBI images fail to start because the Management API agent is loaded twice in cassandra-env.sh sh # add the DSE loader JVM_OPTS=""$JVM_OPTS $DSE_OPTS"" JVM_OPTS=""$JVM_OPTS -javaagent:/opt/management-api/datastax-mgmtapi-agent.jar"" JVM_OPTS=""$JVM_OPTS -javaagent:/opt/management-api/datastax-mgmtapi-agent.jar""  This causes the error: sh ERROR [DSE main thread] 2024-09-03 20:23:28,286 DseDaemon.java:564 - Unable to start DSE server. java.lang.AssertionError: Multiple assignments to NodeOps! at com.datastax.mgmtapi.rpc.RpcRegistry.register(RpcRegistry.java:31) at com.datastax.mgmtapi.NodeOpsProvider.register(NodeOpsProvider.java:77) at com.datastax.mgmtapi.interceptors.CassandraDaemonInterceptor.intercept(CassandraDaemonInterceptor.java:54) at org.apache.cassandra.service.CassandraDaemon.start$original$keiSH0P3(CassandraDaemon.java) at org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java) at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:559) at org.apache.cassandra.service.CassandraDaemon.activate0(CassandraDaemon.java:830) at org.apache.cassandra.service.CassandraDaemon$3.run(CassandraDaemon.java:738) ERROR [DSE main thread] 2024-09-03 20:23:28,286 CassandraDaemon.java:959 - Exception encountered during startup java.lang.RuntimeException: java.lang.AssertionError: Multiple assignments to NodeOps! at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:567) at org.apache.cassandra.service.CassandraDaemon.activate0(CassandraDaemon.java:830) at org.apache.cassandra.service.CassandraDaemon$3.run(CassandraDaemon.java:738) Caused by: java.lang.AssertionError: Multiple assignments to NodeOps! at com.datastax.mgmtapi.rpc.RpcRegistry.register(RpcRegistry.java:31) at com.datastax.mgmtapi.NodeOpsProvider.register(NodeOpsProvider.java:77) at com.datastax.mgmtapi.interceptors.CassandraDaemonInterceptor.intercept(CassandraDaemonInterceptor.java:54) at org.apache.cassandra.service.CassandraDaemon.start$original$keiSH0P3(CassandraDaemon.java) at org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java) at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:559)  2 common frames omitted  This happens because the cassandra-env.sh edit that happens in the Dockerfile does not check to see if the agent has already been added to cassandra-env.sh. The reason only the DSE UBI images are affected is because they are built from the DSE 6.9 Ubuntu images as a base image, which already has the line added to load the agent. The Cassandra 4.1 UBI images do not use the 4.1 Ubuntu images as a base image, so the agent line doesn't already exist in those images. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-61) by [Unito](https://www.unito.io) Issue Number: MAPI-61",documentation-file,"Fix DSE 6.9 UBI image agent loading Since the change was made to support read-only root filesystems (https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/521), the DSE 6.9 UBI images fail to start because the Management API agent is loaded twice in cassandra-env.sh sh # add the DSE loader JVM_OPTS=""$JVM_OPTS $DSE_OPTS"" JVM_OPTS=""$JVM_OPTS -javaagent:/opt/management-api/datastax-mgmtapi-agent.jar"" JVM_OPTS=""$JVM_OPTS -javaagent:/opt/management-api/datastax-mgmtapi-agent.jar""  This causes the error: sh ERROR [DSE main thread] 2024-09-03 20:23:28,286 DseDaemon.java:564 - Unable to start DSE server. java.lang.AssertionError: Multiple assignments to NodeOps! at com.datastax.mgmtapi.rpc.RpcRegistry.register(RpcRegistry.java:31) at com.datastax.mgmtapi.NodeOpsProvider.register(NodeOpsProvider.java:77) at com.datastax.mgmtapi.interceptors.CassandraDaemonInterceptor.intercept(CassandraDaemonInterceptor.java:54) at org.apache.cassandra.service.CassandraDaemon.start$original$keiSH0P3(CassandraDaemon.java) at org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java) at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:559) at org.apache.cassandra.service.CassandraDaemon.activate0(CassandraDaemon.java:830) at org.apache.cassandra.service.CassandraDaemon$3.run(CassandraDaemon.java:738) ERROR [DSE main thread] 2024-09-03 20:23:28,286 CassandraDaemon.java:959 - Exception encountered during startup java.lang.RuntimeException: java.lang.AssertionError: Multiple assignments to NodeOps! at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:567) at org.apache.cassandra.service.CassandraDaemon.activate0(CassandraDaemon.java:830) at org.apache.cassandra.service.CassandraDaemon$3.run(CassandraDaemon.java:738) Caused by: java.lang.AssertionError: Multiple assignments to NodeOps! at com.datastax.mgmtapi.rpc.RpcRegistry.register(RpcRegistry.java:31) at com.datastax.mgmtapi.NodeOpsProvider.register(NodeOpsProvider.java:77) at com.datastax.mgmtapi.interceptors.CassandraDaemonInterceptor.intercept(CassandraDaemonInterceptor.java:54) at org.apache.cassandra.service.CassandraDaemon.start$original$keiSH0P3(CassandraDaemon.java) at org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java) at com.datastax.bdp.server.DseDaemon.start(DseDaemon.java:559)  2 common frames omitted  This happens because the cassandra-env.sh edit that happens in the Dockerfile does not check to see if the agent has already been added to cassandra-env.sh. The reason only the DSE UBI images are affected is because they are built from the DSE 6.9 Ubuntu images as a base image, which already has the line added to load the agent. The Cassandra 4.1 UBI images do not use the 4.1 Ubuntu images as a base image, so the agent line doesn't already exist in those images. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-61) by [Unito](https://www.unito.io) Issue Number: MAPI-61 documentation-file",no-bug,0.95
596,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/596,Add symlink to /tmp/dse.sock for DSE images,"Some downstream projects are using the cassandra socket created by the Agent, and for DSE images, are expecting `/tmp/dse.sock` to be available for cqlsh connections. As of version v0.1.80, that socket creation was changed to `/tmp/cassandra.sock` for uniformity. To aleviate issues downstream, a symlink should be created in the DSE images that links `/tmp/dse.sock` to `/tmp/cassandra.sock` Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-98) by [Unito](https://www.unito.io) Issue Number: MAPI-98",documentation-file,"Add symlink to /tmp/dse.sock for DSE images Some downstream projects are using the cassandra socket created by the Agent, and for DSE images, are expecting `/tmp/dse.sock` to be available for cqlsh connections. As of version v0.1.80, that socket creation was changed to `/tmp/cassandra.sock` for uniformity. To aleviate issues downstream, a symlink should be created in the DSE images that links `/tmp/dse.sock` to `/tmp/cassandra.sock` Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-98) by [Unito](https://www.unito.io) Issue Number: MAPI-98 documentation-file",no-bug,0.9
600,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/600,"Add Cassandra 5.0.3, 4.1.8, 4.0.16 to the build matrix",Cassandra just released new versions: - 5.0.3 - 4.1.8 - 4.0.16 Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-100) by [Unito](https://www.unito.io) Issue Number: MAPI-100,documentation-file,"Add Cassandra 5.0.3, 4.1.8, 4.0.16 to the build matrix Cassandra just released new versions: - 5.0.3 - 4.1.8 - 4.0.16 Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-100) by [Unito](https://www.unito.io) Issue Number: MAPI-100 documentation-file",no-bug,0.95
458,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/458,Upgrade MCAC to v0.3.5,,documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | container-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | container-file | config-file | container-file | config-file | container-file | container-file | container-file | config-file | config-file | source-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | config-file | container-file | config-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | documentation-file | container-file | container-file | container-file | container-file | container-file | container-file | container-file | documentation-file | container-file | config-file | container-file | config-file | container-file | container-file | container-file | config-file | config-file | source-file | documentation-file | config-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | config-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | config-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | config-file | container-file | config-file,Upgrade MCAC to v0.3.5  documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file container-file container-file container-file container-file container-file container-file container-file documentation-file container-file config-file container-file config-file container-file container-file container-file config-file config-file source-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file config-file config-file container-file config-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file documentation-file container-file container-file container-file container-file container-file container-file container-file documentation-file container-file config-file container-file config-file container-file container-file container-file config-file config-file source-file documentation-file config-file config-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file config-file source-file documentation-file source-file source-file source-file source-file source-file source-file source-file source-file source-file config-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file test-file config-file config-file container-file config-file,no-bug,0.9
560,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/560,LatencyMetrics processing is incorrect in certain Cassandra versions,"We set our buckets to accommodate for nanoseconds in latency metrics, however this isn't true anymore in newer versions of Cassandra, which are actually storing the dropwizard with microseconds. Thus, we need to modify the timerFiller with nanosecond buckets for 3.11/4.0, but microseconds for 4.1/5.0. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-77) by [Unito](https://www.unito.io) Issue Number: MAPI-77",documentation-file,"LatencyMetrics processing is incorrect in certain Cassandra versions We set our buckets to accommodate for nanoseconds in latency metrics, however this isn't true anymore in newer versions of Cassandra, which are actually storing the dropwizard with microseconds. Thus, we need to modify the timerFiller with nanosecond buckets for 3.11/4.0, but microseconds for 4.1/5.0. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-77) by [Unito](https://www.unito.io) Issue Number: MAPI-77 documentation-file",no-bug,0.9
521,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/521,"Install mgmt-api agent in the Dockerfile, not docker-entrypoint.sh",The cassandra-env.sh should not be modified in the entrypoint.sh if we want to run readOnlyRootFilesystem.,documentation-file,"Install mgmt-api agent in the Dockerfile, not docker-entrypoint.sh The cassandra-env.sh should not be modified in the entrypoint.sh if we want to run readOnlyRootFilesystem. documentation-file",no-bug,0.9
364,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/364,Add operation go get active compactions,,source-file | documentation-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | documentation-file | source-file | source-file | source-file | documentation-file | source-file | source-file,Add operation go get active compactions  source-file documentation-file source-file source-file source-file documentation-file source-file source-file source-file documentation-file source-file source-file source-file documentation-file source-file source-file source-file documentation-file source-file source-file,no-bug,0.8
611,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/611,Fix HCD CC4 Agent for newer Netty,"We have the same ClassCastException issue during startup with newer versions of Netty for HCD using CC4 as we did for Cassandra 5.0 and the HCD CC5 Agent:  ERROR [epollEventLoopGroup-5-2] 2025-02-24 19:29:11,757 ExceptionHandlers.java:206 - Unexpected exception during request; channel = [id: 0xf8a5ce2f, L:/tmp/hcd.sock - R:] io.netty.handler.codec.DecoderException: java.lang.ClassCastException: class io.netty.channel.unix.DomainSocketAddress cannot be cast to class java.net.InetSocketAddress (io.netty.channel.unix.DomainSocketAddress is in unnamed module of loader 'app'; java.net.InetSocketAddress is in module java.base of loader 'bootstrap') at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:500) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799) at io.netty.channel.epoll.EpollDomainSocketChannel$EpollDomainUnsafe.epollInReady(EpollDomainSocketChannel.java:138) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:829) Caused by: java.lang.ClassCastException: class io.netty.channel.unix.DomainSocketAddress cannot be cast to class java.net.InetSocketAddress (io.netty.channel.unix.DomainSocketAddress is in unnamed module of loader 'app'; java.net.InetSocketAddress is in module java.base of loader 'bootstrap') at org.apache.cassandra.service.ClientState.forExternalCalls(ClientState.java:187) at org.apache.cassandra.transport.ServerConnection.<init>(ServerConnection.java:47) at org.apache.cassandra.transport.UnixSocketServerHcd$UnixSocketConnection.<init>(UnixSocketServerHcd.java:176) at org.apache.cassandra.transport.UnixSocketServerHcd$1.lambda$initChannel$0(UnixSocketServerHcd.java:68) at org.apache.cassandra.transport.UnixSocketServerHcd$PipelineChannelInitializer.decode(UnixSocketServerHcd.java:286) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:530) at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:469)  16 common frames omitted  We need to employ the same fix we used when we saw this for C* 5.0 and wrap the Netty Channel class to override the `remoteAddress()` method. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-105) by [Unito](https://www.unito.io) Issue Number: MAPI-105",documentation-file,"Fix HCD CC4 Agent for newer Netty We have the same ClassCastException issue during startup with newer versions of Netty for HCD using CC4 as we did for Cassandra 5.0 and the HCD CC5 Agent:  ERROR [epollEventLoopGroup-5-2] 2025-02-24 19:29:11,757 ExceptionHandlers.java:206 - Unexpected exception during request; channel = [id: 0xf8a5ce2f, L:/tmp/hcd.sock - R:] io.netty.handler.codec.DecoderException: java.lang.ClassCastException: class io.netty.channel.unix.DomainSocketAddress cannot be cast to class java.net.InetSocketAddress (io.netty.channel.unix.DomainSocketAddress is in unnamed module of loader 'app'; java.net.InetSocketAddress is in module java.base of loader 'bootstrap') at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:500) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799) at io.netty.channel.epoll.EpollDomainSocketChannel$EpollDomainUnsafe.epollInReady(EpollDomainSocketChannel.java:138) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:829) Caused by: java.lang.ClassCastException: class io.netty.channel.unix.DomainSocketAddress cannot be cast to class java.net.InetSocketAddress (io.netty.channel.unix.DomainSocketAddress is in unnamed module of loader 'app'; java.net.InetSocketAddress is in module java.base of loader 'bootstrap') at org.apache.cassandra.service.ClientState.forExternalCalls(ClientState.java:187) at org.apache.cassandra.transport.ServerConnection.<init>(ServerConnection.java:47) at org.apache.cassandra.transport.UnixSocketServerHcd$UnixSocketConnection.<init>(UnixSocketServerHcd.java:176) at org.apache.cassandra.transport.UnixSocketServerHcd$1.lambda$initChannel$0(UnixSocketServerHcd.java:68) at org.apache.cassandra.transport.UnixSocketServerHcd$PipelineChannelInitializer.decode(UnixSocketServerHcd.java:286) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:530) at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:469)  16 common frames omitted  We need to employ the same fix we used when we saw this for C* 5.0 and wrap the Netty Channel class to override the `remoteAddress()` method. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-105) by [Unito](https://www.unito.io) Issue Number: MAPI-105 documentation-file",no-bug,0.9
556,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/556,Update Management API dependencies to address CVEs,"A recent Snyk scan showed that some of the libraries bundled in the Management API server jarfile are a little dated and have some High severity CVEs. In particular, `jackson-core`, `jackson-databind`, `netty-codec-http2` and `snakeyaml` libraries. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-76) by [Unito](https://www.unito.io) Issue Number: MAPI-76",documentation-file,"Update Management API dependencies to address CVEs A recent Snyk scan showed that some of the libraries bundled in the Management API server jarfile are a little dated and have some High severity CVEs. In particular, `jackson-core`, `jackson-databind`, `netty-codec-http2` and `snakeyaml` libraries. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-76) by [Unito](https://www.unito.io) Issue Number: MAPI-76 documentation-file",no-bug,0.9
578,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/578,Add DSE 6.9.5 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-88) by [Unito](https://www.unito.io) Issue Number: MAPI-88,documentation-file,Add DSE 6.9.5 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-88) by [Unito](https://www.unito.io) Issue Number: MAPI-88 documentation-file,no-bug,0.9
574,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/574,Add support for -Ddse.consistent_replace when replacing node,"DSE supports the ability to provide consistency setting when replacing a node. While this could be applied through the jvm-server-options already in cass-operator, we could make this setting available for replace process alone also. If no parameter is provided, use the global settings (defaults usually, which is QUORUM). If trying to use this parameter with non-DSE, reject the request. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-86) by [Unito](https://www.unito.io) Issue Number: MAPI-86",documentation-file,"Add support for -Ddse.consistent_replace when replacing node DSE supports the ability to provide consistency setting when replacing a node. While this could be applied through the jvm-server-options already in cass-operator, we could make this setting available for replace process alone also. If no parameter is provided, use the global settings (defaults usually, which is QUORUM). If trying to use this parameter with non-DSE, reject the request. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-86) by [Unito](https://www.unito.io) Issue Number: MAPI-86 documentation-file",no-bug,0.9
529,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/529,Add DSE 6.9.2 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-1) by [Unito](https://www.unito.io) Issue Number: MAPI-1,documentation-file,Add DSE 6.9.2 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-1) by [Unito](https://www.unito.io) Issue Number: MAPI-1 documentation-file,no-bug,0.95
516,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/516,Address warnings in Dockerfiles,"Recent updates to Docker have started showing some warnings with our current set of Dockerfiles, similar to this:  10 warnings found (use --debug to expand): - ConsistentInstructionCasing: Command 'copy' should match the case of the command majority (uppercase) (line 99) - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 8) - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 60) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 12) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 13) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 71) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 72) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 73) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 114) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 115)  They are just warnings, and the images build correctly, but at some point they should be addressed.",documentation-file | documentation-file | documentation-file,"Address warnings in Dockerfiles Recent updates to Docker have started showing some warnings with our current set of Dockerfiles, similar to this:  10 warnings found (use --debug to expand): - ConsistentInstructionCasing: Command 'copy' should match the case of the command majority (uppercase) (line 99) - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 8) - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 60) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 12) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 13) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 71) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 72) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 73) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 114) - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 115)  They are just warnings, and the images build correctly, but at some point they should be addressed. documentation-file documentation-file documentation-file",no-bug,0.95
582,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/582,Add DSE 6.8.53 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-91) by [Unito](https://www.unito.io) Issue Number: MAPI-91,documentation-file,Add DSE 6.8.53 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-91) by [Unito](https://www.unito.io) Issue Number: MAPI-91 documentation-file,no-bug,0.9
487,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/487,"Add DSE 6.8.48, Cassandra 4.1.5 and Cassandra 4.0.13 to the build matrix",,documentation-file,"Add DSE 6.8.48, Cassandra 4.1.5 and Cassandra 4.0.13 to the build matrix  documentation-file",no-bug,0.95
510,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/510,CDC is not working in the OSS images (at least not UBI),"When starting the CDC enabled bundles, we end up with:  [cassandra@test-cluster-dc1-default-sts-0 cassandra]$ cat stdout.log Error occurred during initialization of VM agent library failed to init: instrument [cassandra@test-cluster-dc1-default-sts-0 cassandra]$ cat stderr.log Error opening zip file or JAR manifest missing : /opt/cdc_agent/cdc-agent.jar [cassandra@test-cluster-dc1-default-sts-0 cassandra]$  This works in the DSE images, but not on the OSS UBI images. @Miles-Garnsey",documentation-file,"CDC is not working in the OSS images (at least not UBI) When starting the CDC enabled bundles, we end up with:  [cassandra@test-cluster-dc1-default-sts-0 cassandra]$ cat stdout.log Error occurred during initialization of VM agent library failed to init: instrument [cassandra@test-cluster-dc1-default-sts-0 cassandra]$ cat stderr.log Error opening zip file or JAR manifest missing : /opt/cdc_agent/cdc-agent.jar [cassandra@test-cluster-dc1-default-sts-0 cassandra]$  This works in the DSE images, but not on the OSS UBI images. @Miles-Garnsey documentation-file",no-bug,0.9
571,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/571,Add Cassandra 4.0.15 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-83) by [Unito](https://www.unito.io) Issue Number: MAPI-83,documentation-file,Add Cassandra 4.0.15 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-83) by [Unito](https://www.unito.io) Issue Number: MAPI-83 documentation-file,no-bug,0.95
535,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/535,Add Cassandra 5.0 tot he build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-64) by [Unito](https://www.unito.io) Issue Number: MAPI-64,documentation-file,Add Cassandra 5.0 tot he build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-64) by [Unito](https://www.unito.io) Issue Number: MAPI-64 documentation-file,no-bug,0.95
552,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/552,"Improve ""liveness"" probe implementation","In K8s situations, bad config can cause issue with pod/container lifecycles and make it difficult to understand the root cause. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-73) by [Unito](https://www.unito.io) Issue Number: MAPI-73",documentation-file | documentation-file | container-file | container-file | container-file | source-file | source-file | source-file | documentation-file,"Improve ""liveness"" probe implementation In K8s situations, bad config can cause issue with pod/container lifecycles and make it difficult to understand the root cause. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-73) by [Unito](https://www.unito.io) Issue Number: MAPI-73 documentation-file documentation-file container-file container-file container-file source-file source-file source-file documentation-file",no-bug,0.9
547,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/547,Deprecate Cassandra 3.11 support,"Now that Cassandra 5.0 is GA, we should be able to stop Cassandra 3.11 builds. For the near term, we should leave the code alone, but remove 3.11 builds and testing in CI and remove 3.11 in the release process (jarfiles and images). Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-70) by [Unito](https://www.unito.io) Issue Number: MAPI-70",documentation-file,"Deprecate Cassandra 3.11 support Now that Cassandra 5.0 is GA, we should be able to stop Cassandra 3.11 builds. For the near term, we should leave the code alone, but remove 3.11 builds and testing in CI and remove 3.11 in the release process (jarfiles and images). Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-70) by [Unito](https://www.unito.io) Issue Number: MAPI-70 documentation-file",no-bug,0.9
549,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/549,Add DSE 6.9.3 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-71) by [Unito](https://www.unito.io) Issue Number: MAPI-71,documentation-file,Add DSE 6.9.3 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-71) by [Unito](https://www.unito.io) Issue Number: MAPI-71 documentation-file,no-bug,0.95
474,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/474,Add DSE 6.8.46 to the build matrix,,documentation-file,Add DSE 6.8.46 to the build matrix  documentation-file,no-bug,0.95
361,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/361,Add listTables endpoint that also returns compaction info,"For repair operations, table compaction information is needed that is currently not returned in any of the API endpoints. [tasklist]  Definition of Done - [ ] An endpoint is added that returns table compaction information ",config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | source-file | test-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | documentation-file | source-file | source-file | source-file | test-file | test-file | test-file | config-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | source-file | test-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | documentation-file | source-file | source-file | source-file | test-file | test-file | test-file | config-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | source-file | test-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | documentation-file | source-file | source-file | source-file | test-file | test-file | test-file | config-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | source-file | test-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | documentation-file | source-file | source-file | source-file | test-file | test-file | test-file | config-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | config-file | source-file | source-file | test-file | test-file | config-file | source-file | test-file | config-file | source-file | test-file | documentation-file | source-file | source-file | source-file | test-file | test-file | test-file | config-file,"Add listTables endpoint that also returns compaction info For repair operations, table compaction information is needed that is currently not returned in any of the API endpoints. [tasklist]  Definition of Done - [ ] An endpoint is added that returns table compaction information  config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file source-file test-file test-file config-file source-file test-file config-file source-file test-file documentation-file source-file source-file source-file test-file test-file test-file config-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file source-file test-file test-file config-file source-file test-file config-file source-file test-file documentation-file source-file source-file source-file test-file test-file test-file config-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file source-file test-file test-file config-file source-file test-file config-file source-file test-file documentation-file source-file source-file source-file test-file test-file test-file config-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file source-file test-file test-file config-file source-file test-file config-file source-file test-file documentation-file source-file source-file source-file test-file test-file test-file config-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file test-file config-file source-file source-file test-file test-file config-file source-file test-file config-file source-file test-file documentation-file source-file source-file source-file test-file test-file test-file config-file",no-bug,0.9
603,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/603,Add DSE 6.8.54 to the build matrix,Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-102) by [Unito](https://www.unito.io) Issue Number: MAPI-102,documentation-file,Add DSE 6.8.54 to the build matrix Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-102) by [Unito](https://www.unito.io) Issue Number: MAPI-102 documentation-file,no-bug,0.9
553,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/553,Major compaction tracking metric is broken in 5.0.2,"Currently, we do cast to a OperationType, however this approach will not work in the extended metrics anymore as we use an older version of the class in agent-common. This causes major compactions to be filtered out from metrics due to a IllegalArgumentException (this Exception is not printed in the logs). In 5.0.2, we need a newer version or we need to simply do this filtering through some string handling to get what we want. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-74) by [Unito](https://www.unito.io) Issue Number: MAPI-74",documentation-file,"Major compaction tracking metric is broken in 5.0.2 Currently, we do cast to a OperationType, however this approach will not work in the extended metrics anymore as we use an older version of the class in agent-common. This causes major compactions to be filtered out from metrics due to a IllegalArgumentException (this Exception is not printed in the logs). In 5.0.2, we need a newer version or we need to simply do this filtering through some string handling to get what we want. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-74) by [Unito](https://www.unito.io) Issue Number: MAPI-74 documentation-file",no-bug,0.9
477,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/477,Fix `cassandra-topology.properties` removal,Commit https://github.com/k8ssandra/management-api-for-apache-cassandra/commit/1c79885cec838bfedc73b802f7b63ec6f3c7de0c attempted to remove the topology file from the images by doing so in the entrypoint script. This seems to fail due to ownership/permissions issues in some environments (at least in K8s with cass-operator). We should put the file removal in the Dockerfiles themselves instead of the entrypoint script.,documentation-file | container-file | documentation-file | container-file,Fix `cassandra-topology.properties` removal Commit https://github.com/k8ssandra/management-api-for-apache-cassandra/commit/1c79885cec838bfedc73b802f7b63ec6f3c7de0c attempted to remove the topology file from the images by doing so in the entrypoint script. This seems to fail due to ownership/permissions issues in some environments (at least in K8s with cass-operator). We should put the file removal in the Dockerfiles themselves instead of the entrypoint script. documentation-file container-file documentation-file container-file,no-bug,0.9
598,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/598,Update HCD 1.2 Agent,"The latest HCD 1.2 code is now based on a Converged Core 5 version that has added async processing for the Dispatcher. As such, the UnixSocketServer code in the Agent needs to accommodate this. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-99) by [Unito](https://www.unito.io) Issue Number: MAPI-99",documentation-file,"Update HCD 1.2 Agent The latest HCD 1.2 code is now based on a Converged Core 5 version that has added async processing for the Dispatcher. As such, the UnixSocketServer code in the Agent needs to accommodate this. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-99) by [Unito](https://www.unito.io) Issue Number: MAPI-99 documentation-file",no-bug,0.9
469,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/469,Add Cassandra 3.11.17 to the build matrix,,documentation-file,Add Cassandra 3.11.17 to the build matrix  documentation-file,no-bug,0.95
624,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/624,Add Maven Enforcer plugin to keep dependency versions in sync,Add the Enforcer plugin to Maven so that it reports out of sync dependencies when updating library versions. And fix any dependency conflicts in the process Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-111) by [Unito](https://www.unito.io) Issue Number: MAPI-111,documentation-file,Add Maven Enforcer plugin to keep dependency versions in sync Add the Enforcer plugin to Maven so that it reports out of sync dependencies when updating library versions. And fix any dependency conflicts in the process Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-111) by [Unito](https://www.unito.io) Issue Number: MAPI-111 documentation-file,no-bug,0.95
626,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/626,MCAC bump to 0.3.6,"Since we cannot just drop MCAC #619 , because the k8ssandra-operator needs to stop using it first (after which we probably need some grace period). Until then, we still need to patch the snakeYaml CVEs by bringing in MCAC that has a newever version of that library. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-112) by [Unito](https://www.unito.io) Issue Number: MAPI-112",documentation-file,"MCAC bump to 0.3.6 Since we cannot just drop MCAC #619 , because the k8ssandra-operator needs to stop using it first (after which we probably need some grace period). Until then, we still need to patch the snakeYaml CVEs by bringing in MCAC that has a newever version of that library. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-112) by [Unito](https://www.unito.io) Issue Number: MAPI-112 documentation-file",no-bug,0.9
360,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/360,Support Cassandra 5.0-alpha1,"A recent test showed that Management API fails to start correctly with Cassandra 5.0-alpha1. The following is observed in the Cassandra logs:  WARN [epollEventLoopGroup-5-4] 2023-08-22 19:23:41,004 AbstractChannelHandlerContext.java:355 - An exception 'java.lang.IllegalArgumentException: Unsupported socket address type: class io.netty.channel.unix.DomainSocketAddress' [enable DEBUG level for full stacktrace] was thrown by a user handler's exceptionCaught() method while handling the following exception: io.netty.handler.codec.DecoderException: java.lang.ClassCastException: class io.netty.channel.unix.DomainSocketAddress cannot be cast to class java.net.InetSocketAddress (io.netty.channel.unix.DomainSocketAddress is in unnamed module of loader 'app'; java.net.InetSocketAddress is in module java.base of loader 'bootstrap') at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:499) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:800) at io.netty.channel.epoll.EpollDomainSocketChannel$EpollDomainUnsafe.epollInReady(EpollDomainSocketChannel.java:140) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:509) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:407) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:829) Caused by: java.lang.ClassCastException: class io.netty.channel.unix.DomainSocketAddress cannot be cast to class java.net.InetSocketAddress (io.netty.channel.unix.DomainSocketAddress is in unnamed module of loader 'app'; java.net.InetSocketAddress is in module java.base of loader 'bootstrap') at org.apache.cassandra.service.ClientState.forExternalCalls(ClientState.java:199) at org.apache.cassandra.transport.ServerConnection.<init>(ServerConnection.java:47) at org.apache.cassandra.transport.UnixSocketServer50x$UnixSocketConnection.<init>(UnixSocketServer50x.java:143) at org.apache.cassandra.transport.UnixSocketServer50x$1.lambda$initChannel$0(UnixSocketServer50x.java:68) at org.apache.cassandra.transport.UnixSocketServer50x$PipelineChannelInitializer.decode(UnixSocketServer50x.java:253) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:529) at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:468)  16 common frames omitted ",documentation-file,"Support Cassandra 5.0-alpha1 A recent test showed that Management API fails to start correctly with Cassandra 5.0-alpha1. The following is observed in the Cassandra logs:  WARN [epollEventLoopGroup-5-4] 2023-08-22 19:23:41,004 AbstractChannelHandlerContext.java:355 - An exception 'java.lang.IllegalArgumentException: Unsupported socket address type: class io.netty.channel.unix.DomainSocketAddress' [enable DEBUG level for full stacktrace] was thrown by a user handler's exceptionCaught() method while handling the following exception: io.netty.handler.codec.DecoderException: java.lang.ClassCastException: class io.netty.channel.unix.DomainSocketAddress cannot be cast to class java.net.InetSocketAddress (io.netty.channel.unix.DomainSocketAddress is in unnamed module of loader 'app'; java.net.InetSocketAddress is in module java.base of loader 'bootstrap') at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:499) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:800) at io.netty.channel.epoll.EpollDomainSocketChannel$EpollDomainUnsafe.epollInReady(EpollDomainSocketChannel.java:140) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:509) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:407) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:829) Caused by: java.lang.ClassCastException: class io.netty.channel.unix.DomainSocketAddress cannot be cast to class java.net.InetSocketAddress (io.netty.channel.unix.DomainSocketAddress is in unnamed module of loader 'app'; java.net.InetSocketAddress is in module java.base of loader 'bootstrap') at org.apache.cassandra.service.ClientState.forExternalCalls(ClientState.java:199) at org.apache.cassandra.transport.ServerConnection.<init>(ServerConnection.java:47) at org.apache.cassandra.transport.UnixSocketServer50x$UnixSocketConnection.<init>(UnixSocketServer50x.java:143) at org.apache.cassandra.transport.UnixSocketServer50x$1.lambda$initChannel$0(UnixSocketServer50x.java:68) at org.apache.cassandra.transport.UnixSocketServer50x$PipelineChannelInitializer.decode(UnixSocketServer50x.java:253) at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:529) at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:468)  16 common frames omitted  documentation-file",no-bug,0.9
579,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/579,sstable tools are not in the default path for DSE,"While the tools themselves are in the image, at /opt/dse/resources/cassandra/tools/bin, they're not part of the default path, which requires using them some knowledge from the user. They should be in the default path just like in our Cassandra images. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-89) by [Unito](https://www.unito.io) Issue Number: MAPI-89",documentation-file,"sstable tools are not in the default path for DSE While the tools themselves are in the image, at /opt/dse/resources/cassandra/tools/bin, they're not part of the default path, which requires using them some knowledge from the user. They should be in the default path just like in our Cassandra images. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-89) by [Unito](https://www.unito.io) Issue Number: MAPI-89 documentation-file",no-bug,0.95
470,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/470,Add Cassandra 4.0.12 to the build matrix,,documentation-file,Add Cassandra 4.0.12 to the build matrix  documentation-file,no-bug,0.95
438,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/438,Add Cassandra 5.1 Agent,"Trying the latest nightly images results in  INFO [epollEventLoopGroup-5-4] 2023-12-15 00:10:02,807 RpcMethod50x.java:138 - Failed to execute method NodeOps.checkConsistencyLevel java.lang.reflect.InvocationTargetException: null at jdk.internal.reflect.GeneratedMethodAccessor15.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at com.datastax.mgmtapi.rpc.RpcMethod50x.execute(RpcMethod50x.java:130) at com.datastax.mgmtapi.rpc.RpcMethod50x.execute(RpcMethod50x.java:33) at com.datastax.mgmtapi.interceptors.QueryHandlerInterceptor.lambda$handle$1(QueryHandlerInterceptor.java:120) at com.datastax.mgmtapi.shims.CassandraAPI.handleRpcResult(CassandraAPI.java:73) at com.datastax.mgmtapi.interceptors.QueryHandlerInterceptor.handle(QueryHandlerInterceptor.java:120) at com.datastax.mgmtapi.interceptors.QueryHandlerInterceptor.intercept(QueryHandlerInterceptor.java:80) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java) at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) at org.apache.cassandra.transport.Message$Request.execute(Message.java:256) at org.apache.cassandra.transport.UnixSocketServer50x$UnixSockMessage.channelRead0(UnixSocketServer50x.java:100) at org.apache.cassandra.transport.UnixSocketServer50x$UnixSockMessage.channelRead0(UnixSocketServer50x.java:79) at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:800) at io.netty.channel.epoll.EpollDomainSocketChannel$EpollDomainUnsafe.epollInReady(EpollDomainSocketChannel.java:140) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:509) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:407) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:829) Caused by: java.lang.NoSuchMethodError: 'org.apache.cassandra.locator.TokenMetadata org.apache.cassandra.service.StorageService.getTokenMetadata()' at com.datastax.mgmtapi.shim.CassandraAPI50x.checkConsistencyLevel(CassandraAPI50x.java:112) at com.datastax.mgmtapi.NodeOpsProvider.checkConsistencyLevel(NodeOpsProvider.java:553)  Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-12) by [Unito](https://www.unito.io) Issue Number: MAPI-12",documentation-file,"Add Cassandra 5.1 Agent Trying the latest nightly images results in  INFO [epollEventLoopGroup-5-4] 2023-12-15 00:10:02,807 RpcMethod50x.java:138 - Failed to execute method NodeOps.checkConsistencyLevel java.lang.reflect.InvocationTargetException: null at jdk.internal.reflect.GeneratedMethodAccessor15.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at com.datastax.mgmtapi.rpc.RpcMethod50x.execute(RpcMethod50x.java:130) at com.datastax.mgmtapi.rpc.RpcMethod50x.execute(RpcMethod50x.java:33) at com.datastax.mgmtapi.interceptors.QueryHandlerInterceptor.lambda$handle$1(QueryHandlerInterceptor.java:120) at com.datastax.mgmtapi.shims.CassandraAPI.handleRpcResult(CassandraAPI.java:73) at com.datastax.mgmtapi.interceptors.QueryHandlerInterceptor.handle(QueryHandlerInterceptor.java:120) at com.datastax.mgmtapi.interceptors.QueryHandlerInterceptor.intercept(QueryHandlerInterceptor.java:80) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java) at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) at org.apache.cassandra.transport.Message$Request.execute(Message.java:256) at org.apache.cassandra.transport.UnixSocketServer50x$UnixSockMessage.channelRead0(UnixSocketServer50x.java:100) at org.apache.cassandra.transport.UnixSocketServer50x$UnixSockMessage.channelRead0(UnixSocketServer50x.java:79) at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346) at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:800) at io.netty.channel.epoll.EpollDomainSocketChannel$EpollDomainUnsafe.epollInReady(EpollDomainSocketChannel.java:140) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:509) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:407) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.base/java.lang.Thread.run(Thread.java:829) Caused by: java.lang.NoSuchMethodError: 'org.apache.cassandra.locator.TokenMetadata org.apache.cassandra.service.StorageService.getTokenMetadata()' at com.datastax.mgmtapi.shim.CassandraAPI50x.checkConsistencyLevel(CassandraAPI50x.java:112) at com.datastax.mgmtapi.NodeOpsProvider.checkConsistencyLevel(NodeOpsProvider.java:553)  Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-12) by [Unito](https://www.unito.io) Issue Number: MAPI-12 documentation-file",no-bug,0.9
18,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/18,Unix Socket and TCP socket driver conflict,"`ERROR [nioEventLoopGroup-3-4] 2020-05-29 09:56:16,269 NodeOpsResources.java:240 - Error when executing request java.lang.IllegalArgumentException: Multiple entries with same key: 1c59a723-4cc4-4f16-bc07-d9b29d3eeedc=Node(endPoint=/10.244.217.176:0, hostId=1c59a723-4cc4-4f16-bc07-d9b29d3eeedc, hashCode=172d302f) and 1c59a723-4cc4-4f16-bc07-d9b29d3eeedc=Node(endPoint=/tmp/cassandra.sock, hostId=1c59a723-4cc4-4f16-bc07-d9b29d3eeedc, hashCode=44592dc4) at com.datastax.oss.driver.shaded.guava.common.collect.ImmutableMap.conflictException(ImmutableMap.java:215) at com.datastax.oss.driver.shaded.guava.common.collect.ImmutableMap.checkNoConflict(ImmutableMap.java:209) at com.datastax.oss.driver.shaded.guava.common.collect.RegularImmutableMap.checkNoConflictInKeyBucket(RegularImmutableMap.java:147) at com.datastax.oss.driver.shaded.guava.common.collect.RegularImmutableMap.fromEntryArray(RegularImmutableMap.java:110) at com.datastax.oss.driver.shaded.guava.common.collect.ImmutableMap$Builder.build(ImmutableMap.java:393) at com.datastax.oss.driver.internal.core.metadata.InitialNodeListRefresh.compute(InitialNodeListRefresh.java:81) at com.datastax.oss.driver.internal.core.metadata.MetadataManager.apply(MetadataManager.java:508) at com.datastax.oss.driver.internal.core.metadata.MetadataManager$SingleThreaded.refreshNodes(MetadataManager.java:328) at com.datastax.oss.driver.internal.core.metadata.MetadataManager$SingleThreaded.access$1700(MetadataManager.java:293) at com.datastax.oss.driver.internal.core.metadata.MetadataManager.lambda$refreshNodes$1(MetadataManager.java:166) at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616) at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591) at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:456) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:387) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) INFO [nioEventLoopGroup-2-1] 2020-05-29 09:56:16,269 Cli.java:573 - address=/10.50.50.82:60720 url=/api/v0/probes/readiness status=500 Internal Server Error`",source-file | source-file,"Unix Socket and TCP socket driver conflict `ERROR [nioEventLoopGroup-3-4] 2020-05-29 09:56:16,269 NodeOpsResources.java:240 - Error when executing request java.lang.IllegalArgumentException: Multiple entries with same key: 1c59a723-4cc4-4f16-bc07-d9b29d3eeedc=Node(endPoint=/10.244.217.176:0, hostId=1c59a723-4cc4-4f16-bc07-d9b29d3eeedc, hashCode=172d302f) and 1c59a723-4cc4-4f16-bc07-d9b29d3eeedc=Node(endPoint=/tmp/cassandra.sock, hostId=1c59a723-4cc4-4f16-bc07-d9b29d3eeedc, hashCode=44592dc4) at com.datastax.oss.driver.shaded.guava.common.collect.ImmutableMap.conflictException(ImmutableMap.java:215) at com.datastax.oss.driver.shaded.guava.common.collect.ImmutableMap.checkNoConflict(ImmutableMap.java:209) at com.datastax.oss.driver.shaded.guava.common.collect.RegularImmutableMap.checkNoConflictInKeyBucket(RegularImmutableMap.java:147) at com.datastax.oss.driver.shaded.guava.common.collect.RegularImmutableMap.fromEntryArray(RegularImmutableMap.java:110) at com.datastax.oss.driver.shaded.guava.common.collect.ImmutableMap$Builder.build(ImmutableMap.java:393) at com.datastax.oss.driver.internal.core.metadata.InitialNodeListRefresh.compute(InitialNodeListRefresh.java:81) at com.datastax.oss.driver.internal.core.metadata.MetadataManager.apply(MetadataManager.java:508) at com.datastax.oss.driver.internal.core.metadata.MetadataManager$SingleThreaded.refreshNodes(MetadataManager.java:328) at com.datastax.oss.driver.internal.core.metadata.MetadataManager$SingleThreaded.access$1700(MetadataManager.java:293) at com.datastax.oss.driver.internal.core.metadata.MetadataManager.lambda$refreshNodes$1(MetadataManager.java:166) at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:616) at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591) at java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:456) at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:387) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) INFO [nioEventLoopGroup-2-1] 2020-05-29 09:56:16,269 Cli.java:573 - address=/10.50.50.82:60720 url=/api/v0/probes/readiness status=500 Internal Server Error` source-file source-file",bug,0.9
372,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/372,Add IS_LOCAL field to /metadata/endpoints response,It should denote which of the items in the array of endpoints is actually the local node.,source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file,Add IS_LOCAL field to /metadata/endpoints response It should denote which of the items in the array of endpoints is actually the local node. source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file source-file source-file source-file source-file source-file source-file test-file,no-bug,0.7
101,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/101,DB home is not a writeable path,"Running the API v0.1.24 on GKE fails with: > Running java -Xms128m -Xmx128m -jar /opt/management-api/datastax-mgmtapi-server-0.1.0-SNAPSHOT.jar --cassandra-socket /tmp/cassandra.sock --host tcp://0.0.0.0:8080 --host file:tmp/oss-mgmt.sock --explicit-start true --cassandra-home /var/lib/cassandra/ > Usage error: Option 'db_home' was given value '/var/lib/cassandra/' which is not a writeable path Note: I'm running a slightly modified version of the Management API image because I need to run with a custom C* image instead of pulling the prebuilt one from dockerhub, but other than that my setup is pretty standard so I have no reasons to believe this wouldn't be a problem in general. The issue is that when it mounts the volume /var/lib/cassandra in GKE, the folder ends up being owned by root (regardless of the `chown` that happened earlier). I confirmed that by logging the permissions at the very end of the Dockerfile execution which was correct, and then at the beginning of the entrypoint, which was incorrect. It looks like this is how k8s works: https://github.com/kubernetes/kubernetes/issues/2630 In the entrypoint, it does have another chown call to fix the permissions, but that only happens if the user is root: https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/v0.1.24/scripts/docker-entrypoint.sh#L17 I think we can fix this by removing/reverting the `USER cassandra` directive from the Dockerfile and then run the java command in the entrypoint with gosu.",container-file | config-file,"DB home is not a writeable path Running the API v0.1.24 on GKE fails with: > Running java -Xms128m -Xmx128m -jar /opt/management-api/datastax-mgmtapi-server-0.1.0-SNAPSHOT.jar --cassandra-socket /tmp/cassandra.sock --host tcp://0.0.0.0:8080 --host file:tmp/oss-mgmt.sock --explicit-start true --cassandra-home /var/lib/cassandra/ > Usage error: Option 'db_home' was given value '/var/lib/cassandra/' which is not a writeable path Note: I'm running a slightly modified version of the Management API image because I need to run with a custom C* image instead of pulling the prebuilt one from dockerhub, but other than that my setup is pretty standard so I have no reasons to believe this wouldn't be a problem in general. The issue is that when it mounts the volume /var/lib/cassandra in GKE, the folder ends up being owned by root (regardless of the `chown` that happened earlier). I confirmed that by logging the permissions at the very end of the Dockerfile execution which was correct, and then at the beginning of the entrypoint, which was incorrect. It looks like this is how k8s works: https://github.com/kubernetes/kubernetes/issues/2630 In the entrypoint, it does have another chown call to fix the permissions, but that only happens if the user is root: https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/v0.1.24/scripts/docker-entrypoint.sh#L17 I think we can fix this by removing/reverting the `USER cassandra` directive from the Dockerfile and then run the java command in the entrypoint with gosu. container-file config-file",no-bug,0.9
620,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/620,Update Dependencies,"Netty, Jackson and Guava dependencies should be updated to address security concerns and CVEs Netty -> 4.1.118.Final Jackson -> 2.18.3 Guava -> 33.4.0-jre Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-110) by [Unito](https://www.unito.io) Issue Number: MAPI-110",documentation-file,"Update Dependencies Netty, Jackson and Guava dependencies should be updated to address security concerns and CVEs Netty -> 4.1.118.Final Jackson -> 2.18.3 Guava -> 33.4.0-jre Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-110) by [Unito](https://www.unito.io) Issue Number: MAPI-110 documentation-file",no-bug,0.9
573,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/573,Add support for HCD 1.2,"The HCD agent currently is currently compiled against Converged Core 4 (CC4). However, HCD 1.2 is based on Converged Core 5. It is very likely that the current HCD agent will not work in HCD 1.2 or any HCD version based on CC5. The fix for this is likely to create yet another agent sub-module for HCD 1.2 and change the CC version in the [pom](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-agent-hcd/pom.xml#L75) Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-85) by [Unito](https://www.unito.io) Issue Number: MAPI-85",documentation-file,"Add support for HCD 1.2 The HCD agent currently is currently compiled against Converged Core 4 (CC4). However, HCD 1.2 is based on Converged Core 5. It is very likely that the current HCD agent will not work in HCD 1.2 or any HCD version based on CC5. The fix for this is likely to create yet another agent sub-module for HCD 1.2 and change the CC version in the [pom](https://github.com/k8ssandra/management-api-for-apache-cassandra/blob/master/management-api-agent-hcd/pom.xml#L75) Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-85) by [Unito](https://www.unito.io) Issue Number: MAPI-85 documentation-file",no-bug,0.9
629,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/629,dse command does not function on readOnlyRootFilesystem,"The dse command requires the $HOME to be writable, but that is not allowed by the readOnlyRootFilesystem. We need to patch and remove this requirement. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-113) by [Unito](https://www.unito.io) Issue Number: MAPI-113",documentation-file,"dse command does not function on readOnlyRootFilesystem The dse command requires the $HOME to be writable, but that is not allowed by the readOnlyRootFilesystem. We need to patch and remove this requirement. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-113) by [Unito](https://www.unito.io) Issue Number: MAPI-113 documentation-file",no-bug,0.9
524,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/524,HintsService and ReadCoordination can return incorrect labeling,"As seen in https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/512 there were metrics which have the IP + port in the metricName part itself, since the formatting had ``""org\\.apache\\.cassandra\\.metrics\\.\\.(\\w+)\\.(\\w+)\\.(.+)$""`` instead of ``""org\\.apache\\.cassandra\\.metrics\\.\\.(\\w+)\\.(.+)$""`` HintsService and ReadCoordination are two metrics that do not have this special case taken care of and as such return incorrect metric naming:  # TYPE org_apache_cassandra_metrics_hints_service_hint_delays_10_244_2_14_7000 summary # TYPE org_apache_cassandra_metrics_read_coordination_replica_latency_10_244_3_15_7000 summary ",documentation-file,"HintsService and ReadCoordination can return incorrect labeling As seen in https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/512 there were metrics which have the IP + port in the metricName part itself, since the formatting had ``""org\\.apache\\.cassandra\\.metrics\\.\\.(\\w+)\\.(\\w+)\\.(.+)$""`` instead of ``""org\\.apache\\.cassandra\\.metrics\\.\\.(\\w+)\\.(.+)$""`` HintsService and ReadCoordination are two metrics that do not have this special case taken care of and as such return incorrect metric naming:  # TYPE org_apache_cassandra_metrics_hints_service_hint_delays_10_244_2_14_7000 summary # TYPE org_apache_cassandra_metrics_read_coordination_replica_latency_10_244_3_15_7000 summary  documentation-file",no-bug,0.9
397,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/397,[CVE-2021-44521] Cassandra versions 4.0.11 and 4.1.3 is released,In Cassandra versions minor that 4.0.11 and minor that 4.1.3 have a critial vuln with Apache Cassandra Remote Code Execution. * CVE-2021-44521: Apache Cassandra Remote Code Execution > - https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-44521 > - https://www.vicarius.io/vsociety/posts/cve-2021-44521-apache-cassandra-remote-code-execution Release notes. * https://github.com/apache/cassandra/blob/cassandra-4.0.11/NEWS.txt * https://github.com/apache/cassandra/blob/cassandra-4.1.3/NEWS.txt,documentation-file,[CVE-2021-44521] Cassandra versions 4.0.11 and 4.1.3 is released In Cassandra versions minor that 4.0.11 and minor that 4.1.3 have a critial vuln with Apache Cassandra Remote Code Execution. * CVE-2021-44521: Apache Cassandra Remote Code Execution > - https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-44521 > - https://www.vicarius.io/vsociety/posts/cve-2021-44521-apache-cassandra-remote-code-execution Release notes. * https://github.com/apache/cassandra/blob/cassandra-4.0.11/NEWS.txt * https://github.com/apache/cassandra/blob/cassandra-4.1.3/NEWS.txt documentation-file,no-bug,0.9
543,management-api-for-apache-cassandra,https://github.com/k8ssandra/management-api-for-apache-cassandra/issues/543,Add Cassandra 5.0.0 and 5.0.1 to the build matrix,Cassandra 5.0.0 and 5.0.1 GA versions are released. They should be added to the build matrix. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-67) by [Unito](https://www.unito.io) Issue Number: MAPI-67,documentation-file,Add Cassandra 5.0.0 and 5.0.1 to the build matrix Cassandra 5.0.0 and 5.0.1 GA versions are released. They should be added to the build matrix. Issue is synchronized with this [Jira Story](https://datastax.jira.com/browse/MAPI-67) by [Unito](https://www.unito.io) Issue Number: MAPI-67 documentation-file,no-bug,0.95
