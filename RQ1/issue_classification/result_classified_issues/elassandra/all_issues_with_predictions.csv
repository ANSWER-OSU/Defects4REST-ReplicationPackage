issue_no,repo,issue_url,title,description,patched_file_types,text_for_topic_modeling,prediction,confidence
130,elassandra,https://github.com/strapdata/elassandra/issues/130,"CQL Map types with map<timestamp, text> throws mapper_parsing_exception","**Elasticsearch version**: 5.5.0 **Plugins installed**: [] **JVM version**: 1.8.0_101 **OS version**: macos Sierra **Description of the problem including expected versus actual behavior**: Say I have a a cql map defined like this: `map<timestamp, text>`. If I try to use `discover` to create an index from the existing cassandra table with that map, then it throws a `mapper_parsing_exception`. **Steps to reproduce**: 1. In cqlsh:  CREATE KEYSPACE twitter WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': 1};  2. Using curl:  curl -XPUT 'http://localhost:9200/twitter' -d '{ ""settings"": { ""keyspace"":""twitter"" } }'  3. In cqlsh:  CREATE TABLE twitter.user ( name text, attrs map<timestamp, text>, PRIMARY KEY (name) );  4. Using curl:  curl -XPUT ""http://localhost:9200/twitter/_mapping/user"" -d '{ ""user"" : { ""discover"" : "".*"" }}'  5. An exception is thrown in the previous step:  {""error"":{""root_cause"":[{""type"":""mapper_parsing_exception"",""reason"":""No type specified for field [attrs]""}],""type"":""mapper_parsing_exception"",""reason"":""No type specified for field [attrs]""},""status"":400} ",documentation-file,"CQL Map types with map<timestamp, text> throws mapper_parsing_exception **Elasticsearch version**: 5.5.0 **Plugins installed**: [] **JVM version**: 1.8.0_101 **OS version**: macos Sierra **Description of the problem including expected versus actual behavior**: Say I have a a cql map defined like this: `map<timestamp, text>`. If I try to use `discover` to create an index from the existing cassandra table with that map, then it throws a `mapper_parsing_exception`. **Steps to reproduce**: 1. In cqlsh:  CREATE KEYSPACE twitter WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': 1};  2. Using curl:  curl -XPUT 'http://localhost:9200/twitter' -d '{ ""settings"": { ""keyspace"":""twitter"" } }'  3. In cqlsh:  CREATE TABLE twitter.user ( name text, attrs map<timestamp, text>, PRIMARY KEY (name) );  4. Using curl:  curl -XPUT ""http://localhost:9200/twitter/_mapping/user"" -d '{ ""user"" : { ""discover"" : "".*"" }}'  5. An exception is thrown in the previous step:  {""error"":{""root_cause"":[{""type"":""mapper_parsing_exception"",""reason"":""No type specified for field [attrs]""}],""type"":""mapper_parsing_exception"",""reason"":""No type specified for field [attrs]""},""status"":400}  documentation-file",no-bug,0.9
19,elassandra,https://github.com/strapdata/elassandra/issues/19,java.lang.NullPointerException when starting elassandra,"Hi, while starting elassandra using, `./cassandra -e` i got an error in system.log > 2016-05-19 18:58:09,525 ERROR [main] ElassandraDaemon.java:376 main Exception > java.lang.NullPointerException: null > at org.apache.cassandra.service.ElassandraDaemon.activate(ElassandraDaemon.java:112) ~[elassandra-2.1.1-10.jar:na] > at org.apache.cassandra.service.ElassandraDaemon.main(ElassandraDaemon.java:338) ~[elassandra-2.1.1-10.jar:na] What will be the reason ? Is there any need for another elasticsearch server?",config-file | documentation-file | config-file | config-file | config-file | other-file,"java.lang.NullPointerException when starting elassandra Hi, while starting elassandra using, `./cassandra -e` i got an error in system.log > 2016-05-19 18:58:09,525 ERROR [main] ElassandraDaemon.java:376 main Exception > java.lang.NullPointerException: null > at org.apache.cassandra.service.ElassandraDaemon.activate(ElassandraDaemon.java:112) ~[elassandra-2.1.1-10.jar:na] > at org.apache.cassandra.service.ElassandraDaemon.main(ElassandraDaemon.java:338) ~[elassandra-2.1.1-10.jar:na] What will be the reason ? Is there any need for another elasticsearch server? config-file documentation-file config-file config-file config-file other-file",no-bug,0.9
16,elassandra,https://github.com/strapdata/elassandra/issues/16,Elasticsearch geo_point causes ERROR during insert into Elassandra with CURL,"Hi, I'm trying to run the Kibana Getting Started tutorial with Elassandra 2.1.1-8 and Kibana 4.3.3 (linux-x64). To accomplish the Map Visualization I have launched the following command: \* ELASTICSEARCH COORDINATES DEFINITION  `curl -XPUT http://localhost:9200/logstash_20150520 -d ' { ""mappings"": { ""log"": { ""properties"": { ""geo"": { ""properties"": { ""coordinates"": { ""type"": ""geo_point"" } } } } } } } '; ` and then I've done a bulk insert with the following command: \* ELASTICSEARCH BULK INSERT  `curl -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl ` The bulk fails with the following ERROR (from system.log):   START ERROR 2016-04-28 13:08:41,244 ERROR [elasticsearch[localhost][index][T#4]] InternalCassandraClusterService.java:1479 insertDocument [localhost] [logstash_20150520].[log] failed to parse field geo={dest=IN, src=R U, coordinates={lon=-87.44675972, lat=31.01621528}, srcdest=RU:IN} java.lang.ClassCastException: null 2016-04-28 13:08:41,244 DEBUG [elasticsearch[localhost][index][T#4]] TransportReplicationAction.java:604 performOnPrimary [localhost] [logstash_20150520][0], node[c7610fa4-e08b-405b-b855-c682a935543a], [P] , v[1], s[STARTED], a[id=B0BPlnTrS2-fmliQ7rwABw]: Failed to execute [index {[logstash_20150520][log][test], source[ { ""@timestamp"" : ""2015-05-01T15:57:34.915Z"", ""ip"" : ""166.114.155.140"", ""extension"" : ""jpg"", ""response"" : ""200"", ""geo"" : { ""coordinates"" : { ""lat"" : 31.01621528, ""lon"" : -87.44675972 }, ""src"" : ""RU"", ""dest"" : ""IN"", ""srcdest"" : ""RU:IN"" }, ""@tags"" : [""success"", ""info""], ""utc_time"" : ""2015-05-20T15:57:34.915Z"", ""referer"" : ""http://twitter.com/success/ellison-onizuka"", ""agent"" : ""Mozilla/5.0 (X11; Linux i686) AppleWebKit/534.24 (KHTML, like Gecko) Chrome/11.0.696.50 Safari/534.24"", ""clientip"" : ""166.114.155.140"", ""bytes"" : 6839, ""host"" : ""media-for-the-masses.theacademyofperformingartsandscience.org"", ""request"" : ""/uploads/laurel-b-clark.jpg"", ""url"" : ""https://media-for-the-masses.theacademyofperformingartsandscience.org/uploads/laurel-b-clark.jpg"", ""@message"" : ""166.114.155.140 - - [2015-05-20T15:57:34.915Z] \""GET /uploads/laurel-b-clark.jpg HTTP/1.1\"" 200 6839 \""-\"" \""Mozilla/5.0 (X11; Linux i686) AppleWebKit/534.24 (KHTML, like Gecko) Chrome/11.0.696.50 Safari/534.24\"""", ""spaces"" : ""this is a thing with lots of spaces wwwwoooooo"", ""xss"" : ""<script>console.log(\""xss\"")</script>"", ""headings"" : [""<h3>daniel-burbank</h5>"", ""http://twitter.com/success/john-grunsfeld""], ""links"" : [""terry-virts@www.slate.com"", ""http://www.slate.com/info/curtis-brown"", ""www.www.slate.com""], ""relatedContent"" : [], ""machine"" : { ""os"" : ""win xp"", ""ram"" : 32212254720 }, ""@version"" : ""1"" }]}] java.lang.ClassCastException: null 2016-04-28 13:08:41,244 TRACE [elasticsearch[localhost][index][T#4]] TransportReplicationAction.java:542 finishAsFailed [localhost] operation failed java.lang.ClassCastException: null 2016-04-28 13:08:41,244 TRACE [elasticsearch[localhost][index][T#4]] ChildMemoryCircuitBreaker.java:182 addWithoutBreaking [localhost] [request] Adjusted breaker by [16440] bytes, now [16440] 2016-04-28 13:08:41,245 INFO [elasticsearch[localhost][index][T#4]] BytesRestResponse.java:131 convert /logstash_20150520/log/test Params: {id=test, index=logstash_20150520, type=log} java.lang.ClassCastException: null   END ERROR These are the index definition of Elasticsearch and the Keyspace definition of Cassandra \* ELASTICSEARCH INDEX  ""logstash_20150520"" : { ""state"" : ""open"", ""settings"" : { ""index"" : { ""creation_date"" : ""1461776568462"", ""uuid"" : ""yx1IPFnmT5icKYTcMfZh7w"", ""number_of_replicas"" : ""0"", ""number_of_shards"" : ""1"", ""version"" : { ""created"" : ""2010199"" } } }, ""mappings"" : { ""log"" : { ""properties"" : { ""spaces"" : { ""type"" : ""string"" }, ""relatedContent"" : { ""properties"" : { ""articleTag"" : { ""type"" : ""string"" }, ""twitterCard"" : { ""type"" : ""string"" }, ""ogImageHeight"" : { ""type"" : ""string"" }, ""articlePublished_time"" : { ""format"" : ""strict_date_optional_time||epoch_millis"", ""type"" : ""date"" }, ""twitterSite"" : { ""type"" : ""string"" }, ""ogDescription"" : { ""type"" : ""string"" }, ""url"" : { ""type"" : ""string"" }, ""articleModified_time"" : { ""format"" : ""strict_date_optional_time||epoch_millis"", ""type"" : ""date"" }, ""ogType"" : { ""type"" : ""string"" }, ""twitterImage"" : { ""type"" : ""string"" }, ""ogImageWidth"" : { ""type"" : ""string"" }, ""ogUrl"" : { ""type"" : ""string"" }, ""ogTitle"" : { ""type"" : ""string"" }, ""ogImage"" : { ""type"" : ""string"" }, ""twitterTitle"" : { ""type"" : ""string"" }, ""ogSite_name"" : { ""type"" : ""string"" }, ""twitterDescription"" : { ""type"" : ""string"" }, ""articleSection"" : { ""type"" : ""string"" } } }, ""@message"" : { ""type"" : ""string"" }, ""bytes"" : { ""type"" : ""long"" }, ""geo"" : { ""properties"" : { ""dest"" : { ""type"" : ""string"" }, ""src"" : { ""type"" : ""string"" }, ""coordinates"" : { ""type"" : ""geo_point"" }, ""srcdest"" : { ""type"" : ""string"" } } }, ""host"" : { ""type"" : ""string"" }, ""clientip"" : { ""type"" : ""string"" }, ""@tags"" : { ""type"" : ""string"" }, ""xss"" : { ""type"" : ""string"" }, ""utc_time"" : { ""format"" : ""strict_date_optional_time||epoch_millis"", ""type"" : ""date"" }, ""links"" : { ""type"" : ""string"" }, ""machine"" : { ""properties"" : { ""os"" : { ""type"" : ""string"" }, ""ram"" : { ""type"" : ""long"" } } }, ""@version"" : { ""type"" : ""string"" }, ""agent"" : { ""type"" : ""string"" }, ""url"" : { ""type"" : ""string"" }, ""memory"" : { ""type"" : ""long"" }, ""phpmemory"" : { ""type"" : ""long"" }, ""ip"" : { ""type"" : ""string"" }, ""response"" : { ""type"" : ""string"" }, ""extension"" : { ""type"" : ""string"" }, ""headings"" : { ""type"" : ""string"" }, ""@timestamp"" : { ""format"" : ""strict_date_optional_time||epoch_millis"", ""type"" : ""date"" }, ""request"" : { ""type"" : ""string"" }, ""referer"" : { ""type"" : ""string"" } } } }, ""aliases"" : [ ] }, \* CASSANDRA KEYSPACE  CREATE KEYSPACE logstash_20150520 WITH replication = {'class': 'NetworkTopologyStrategy', 'dc1': '1'} AND durable_writes = true; CREATE TYPE logstash_20150520.log_geo_coordinates ( lat double, lon double ); CREATE TYPE logstash_20150520.log_geo ( coordinates frozen<list<frozen<log_geo_coordinates, srcdest frozen<list<text>>, dest frozen<list<text>>, src frozen<list<text>> ); CREATE TYPE logstash_20150520.log_machine ( ram frozen<list<bigint>>, os frozen<list<text>> ); CREATE TYPE logstash_20150520.""log_relatedContent"" ( ""ogDescription"" frozen<list<text>>, ""twitterDescription"" frozen<list<text>>, ""ogSite_name"" frozen<list<text>>, ""articleSection"" frozen<list<text>>, ""articlePublished_time"" frozen<list<timestamp>>, ""twitterSite"" frozen<list<text>>, ""ogTitle"" frozen<list<text>>, ""twitterTitle"" frozen<list<text>>, ""twitterImage"" frozen<list<text>>, ""ogImageHeight"" frozen<list<text>>, ""articleModified_time"" frozen<list<timestamp>>, url frozen<list<text>>, ""ogType"" frozen<list<text>>, ""ogUrl"" frozen<list<text>>, ""ogImageWidth"" frozen<list<text>>, ""ogImage"" frozen<list<text>>, ""twitterCard"" frozen<list<text>>, ""articleTag"" frozen<list<text>> ); CREATE TABLE logstash_20150520.log ( ""_id"" text PRIMARY KEY, ""@message"" list<text>, ""@tags"" list<text>, ""@timestamp"" list<timestamp>, ""@version"" list<text>, agent list<text>, bytes list<bigint>, clientip list<text>, extension list<text>, geo list<frozen<log_geo>>, headings list<text>, host list<text>, ip list<text>, links list<text>, machine list<frozen<log_machine>>, memory list<bigint>, phpmemory list<bigint>, referer list<text>, ""relatedContent"" list<frozen<log_relatedContent>>, request list<text>, response list<text>, spaces list<text>, url list<text>, utc_time list<timestamp>, xss list<text> ) WITH bloom_filter_fp_chance = 0.01 AND caching = '{""keys"":""ALL"", ""rows_per_partition"":""NONE""}' AND comment = 'Auto-created by Elassandra' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'} AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99.0PERCENTILE'; CREATE CUSTOM INDEX elastic_log_xss_idx ON logstash_20150520.log (xss) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_host_idx ON logstash_20150520.log (host) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log__message_idx ON logstash_20150520.log (""@message"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_extension_idx ON logstash_20150520.log (extension) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_clientip_idx ON logstash_20150520.log (clientip) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_spaces_idx ON logstash_20150520.log (spaces) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_bytes_idx ON logstash_20150520.log (bytes) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_url_idx ON logstash_20150520.log (url) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log__version_idx ON logstash_20150520.log (""@version"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_geo_idx ON logstash_20150520.log (geo) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_ip_idx ON logstash_20150520.log (ip) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_relatedContent_idx ON logstash_20150520.log (""relatedContent"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_memory_idx ON logstash_20150520.log (memory) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log__tags_idx ON logstash_20150520.log (""@tags"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_request_idx ON logstash_20150520.log (request) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_machine_idx ON logstash_20150520.log (machine) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_response_idx ON logstash_20150520.log (response) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_headings_idx ON logstash_20150520.log (headings) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_referer_idx ON logstash_20150520.log (referer) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_links_idx ON logstash_20150520.log (links) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log__timestamp_idx ON logstash_20150520.log (""@timestamp"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_phpmemory_idx ON logstash_20150520.log (phpmemory) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_utc_time_idx ON logstash_20150520.log (utc_time) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_agent_idx ON logstash_20150520.log (agent) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; Maybe I'm doing something wrong? If I don't run the command for the geo_point creation on the Elasticsearch index, the bulk insert goes well but lat and lon are simply doubles (not geo coordinates) and kibana can't show them over the Map. Thanks. Alberto",config-file,"Elasticsearch geo_point causes ERROR during insert into Elassandra with CURL Hi, I'm trying to run the Kibana Getting Started tutorial with Elassandra 2.1.1-8 and Kibana 4.3.3 (linux-x64). To accomplish the Map Visualization I have launched the following command: \* ELASTICSEARCH COORDINATES DEFINITION  `curl -XPUT http://localhost:9200/logstash_20150520 -d ' { ""mappings"": { ""log"": { ""properties"": { ""geo"": { ""properties"": { ""coordinates"": { ""type"": ""geo_point"" } } } } } } } '; ` and then I've done a bulk insert with the following command: \* ELASTICSEARCH BULK INSERT  `curl -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl ` The bulk fails with the following ERROR (from system.log):   START ERROR 2016-04-28 13:08:41,244 ERROR [elasticsearch[localhost][index][T#4]] InternalCassandraClusterService.java:1479 insertDocument [localhost] [logstash_20150520].[log] failed to parse field geo={dest=IN, src=R U, coordinates={lon=-87.44675972, lat=31.01621528}, srcdest=RU:IN} java.lang.ClassCastException: null 2016-04-28 13:08:41,244 DEBUG [elasticsearch[localhost][index][T#4]] TransportReplicationAction.java:604 performOnPrimary [localhost] [logstash_20150520][0], node[c7610fa4-e08b-405b-b855-c682a935543a], [P] , v[1], s[STARTED], a[id=B0BPlnTrS2-fmliQ7rwABw]: Failed to execute [index {[logstash_20150520][log][test], source[ { ""@timestamp"" : ""2015-05-01T15:57:34.915Z"", ""ip"" : ""166.114.155.140"", ""extension"" : ""jpg"", ""response"" : ""200"", ""geo"" : { ""coordinates"" : { ""lat"" : 31.01621528, ""lon"" : -87.44675972 }, ""src"" : ""RU"", ""dest"" : ""IN"", ""srcdest"" : ""RU:IN"" }, ""@tags"" : [""success"", ""info""], ""utc_time"" : ""2015-05-20T15:57:34.915Z"", ""referer"" : ""http://twitter.com/success/ellison-onizuka"", ""agent"" : ""Mozilla/5.0 (X11; Linux i686) AppleWebKit/534.24 (KHTML, like Gecko) Chrome/11.0.696.50 Safari/534.24"", ""clientip"" : ""166.114.155.140"", ""bytes"" : 6839, ""host"" : ""media-for-the-masses.theacademyofperformingartsandscience.org"", ""request"" : ""/uploads/laurel-b-clark.jpg"", ""url"" : ""https://media-for-the-masses.theacademyofperformingartsandscience.org/uploads/laurel-b-clark.jpg"", ""@message"" : ""166.114.155.140 - - [2015-05-20T15:57:34.915Z] \""GET /uploads/laurel-b-clark.jpg HTTP/1.1\"" 200 6839 \""-\"" \""Mozilla/5.0 (X11; Linux i686) AppleWebKit/534.24 (KHTML, like Gecko) Chrome/11.0.696.50 Safari/534.24\"""", ""spaces"" : ""this is a thing with lots of spaces wwwwoooooo"", ""xss"" : ""<script>console.log(\""xss\"")</script>"", ""headings"" : [""<h3>daniel-burbank</h5>"", ""http://twitter.com/success/john-grunsfeld""], ""links"" : [""terry-virts@www.slate.com"", ""http://www.slate.com/info/curtis-brown"", ""www.www.slate.com""], ""relatedContent"" : [], ""machine"" : { ""os"" : ""win xp"", ""ram"" : 32212254720 }, ""@version"" : ""1"" }]}] java.lang.ClassCastException: null 2016-04-28 13:08:41,244 TRACE [elasticsearch[localhost][index][T#4]] TransportReplicationAction.java:542 finishAsFailed [localhost] operation failed java.lang.ClassCastException: null 2016-04-28 13:08:41,244 TRACE [elasticsearch[localhost][index][T#4]] ChildMemoryCircuitBreaker.java:182 addWithoutBreaking [localhost] [request] Adjusted breaker by [16440] bytes, now [16440] 2016-04-28 13:08:41,245 INFO [elasticsearch[localhost][index][T#4]] BytesRestResponse.java:131 convert /logstash_20150520/log/test Params: {id=test, index=logstash_20150520, type=log} java.lang.ClassCastException: null   END ERROR These are the index definition of Elasticsearch and the Keyspace definition of Cassandra \* ELASTICSEARCH INDEX  ""logstash_20150520"" : { ""state"" : ""open"", ""settings"" : { ""index"" : { ""creation_date"" : ""1461776568462"", ""uuid"" : ""yx1IPFnmT5icKYTcMfZh7w"", ""number_of_replicas"" : ""0"", ""number_of_shards"" : ""1"", ""version"" : { ""created"" : ""2010199"" } } }, ""mappings"" : { ""log"" : { ""properties"" : { ""spaces"" : { ""type"" : ""string"" }, ""relatedContent"" : { ""properties"" : { ""articleTag"" : { ""type"" : ""string"" }, ""twitterCard"" : { ""type"" : ""string"" }, ""ogImageHeight"" : { ""type"" : ""string"" }, ""articlePublished_time"" : { ""format"" : ""strict_date_optional_time||epoch_millis"", ""type"" : ""date"" }, ""twitterSite"" : { ""type"" : ""string"" }, ""ogDescription"" : { ""type"" : ""string"" }, ""url"" : { ""type"" : ""string"" }, ""articleModified_time"" : { ""format"" : ""strict_date_optional_time||epoch_millis"", ""type"" : ""date"" }, ""ogType"" : { ""type"" : ""string"" }, ""twitterImage"" : { ""type"" : ""string"" }, ""ogImageWidth"" : { ""type"" : ""string"" }, ""ogUrl"" : { ""type"" : ""string"" }, ""ogTitle"" : { ""type"" : ""string"" }, ""ogImage"" : { ""type"" : ""string"" }, ""twitterTitle"" : { ""type"" : ""string"" }, ""ogSite_name"" : { ""type"" : ""string"" }, ""twitterDescription"" : { ""type"" : ""string"" }, ""articleSection"" : { ""type"" : ""string"" } } }, ""@message"" : { ""type"" : ""string"" }, ""bytes"" : { ""type"" : ""long"" }, ""geo"" : { ""properties"" : { ""dest"" : { ""type"" : ""string"" }, ""src"" : { ""type"" : ""string"" }, ""coordinates"" : { ""type"" : ""geo_point"" }, ""srcdest"" : { ""type"" : ""string"" } } }, ""host"" : { ""type"" : ""string"" }, ""clientip"" : { ""type"" : ""string"" }, ""@tags"" : { ""type"" : ""string"" }, ""xss"" : { ""type"" : ""string"" }, ""utc_time"" : { ""format"" : ""strict_date_optional_time||epoch_millis"", ""type"" : ""date"" }, ""links"" : { ""type"" : ""string"" }, ""machine"" : { ""properties"" : { ""os"" : { ""type"" : ""string"" }, ""ram"" : { ""type"" : ""long"" } } }, ""@version"" : { ""type"" : ""string"" }, ""agent"" : { ""type"" : ""string"" }, ""url"" : { ""type"" : ""string"" }, ""memory"" : { ""type"" : ""long"" }, ""phpmemory"" : { ""type"" : ""long"" }, ""ip"" : { ""type"" : ""string"" }, ""response"" : { ""type"" : ""string"" }, ""extension"" : { ""type"" : ""string"" }, ""headings"" : { ""type"" : ""string"" }, ""@timestamp"" : { ""format"" : ""strict_date_optional_time||epoch_millis"", ""type"" : ""date"" }, ""request"" : { ""type"" : ""string"" }, ""referer"" : { ""type"" : ""string"" } } } }, ""aliases"" : [ ] }, \* CASSANDRA KEYSPACE  CREATE KEYSPACE logstash_20150520 WITH replication = {'class': 'NetworkTopologyStrategy', 'dc1': '1'} AND durable_writes = true; CREATE TYPE logstash_20150520.log_geo_coordinates ( lat double, lon double ); CREATE TYPE logstash_20150520.log_geo ( coordinates frozen<list<frozen<log_geo_coordinates, srcdest frozen<list<text>>, dest frozen<list<text>>, src frozen<list<text>> ); CREATE TYPE logstash_20150520.log_machine ( ram frozen<list<bigint>>, os frozen<list<text>> ); CREATE TYPE logstash_20150520.""log_relatedContent"" ( ""ogDescription"" frozen<list<text>>, ""twitterDescription"" frozen<list<text>>, ""ogSite_name"" frozen<list<text>>, ""articleSection"" frozen<list<text>>, ""articlePublished_time"" frozen<list<timestamp>>, ""twitterSite"" frozen<list<text>>, ""ogTitle"" frozen<list<text>>, ""twitterTitle"" frozen<list<text>>, ""twitterImage"" frozen<list<text>>, ""ogImageHeight"" frozen<list<text>>, ""articleModified_time"" frozen<list<timestamp>>, url frozen<list<text>>, ""ogType"" frozen<list<text>>, ""ogUrl"" frozen<list<text>>, ""ogImageWidth"" frozen<list<text>>, ""ogImage"" frozen<list<text>>, ""twitterCard"" frozen<list<text>>, ""articleTag"" frozen<list<text>> ); CREATE TABLE logstash_20150520.log ( ""_id"" text PRIMARY KEY, ""@message"" list<text>, ""@tags"" list<text>, ""@timestamp"" list<timestamp>, ""@version"" list<text>, agent list<text>, bytes list<bigint>, clientip list<text>, extension list<text>, geo list<frozen<log_geo>>, headings list<text>, host list<text>, ip list<text>, links list<text>, machine list<frozen<log_machine>>, memory list<bigint>, phpmemory list<bigint>, referer list<text>, ""relatedContent"" list<frozen<log_relatedContent>>, request list<text>, response list<text>, spaces list<text>, url list<text>, utc_time list<timestamp>, xss list<text> ) WITH bloom_filter_fp_chance = 0.01 AND caching = '{""keys"":""ALL"", ""rows_per_partition"":""NONE""}' AND comment = 'Auto-created by Elassandra' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'} AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99.0PERCENTILE'; CREATE CUSTOM INDEX elastic_log_xss_idx ON logstash_20150520.log (xss) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_host_idx ON logstash_20150520.log (host) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log__message_idx ON logstash_20150520.log (""@message"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_extension_idx ON logstash_20150520.log (extension) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_clientip_idx ON logstash_20150520.log (clientip) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_spaces_idx ON logstash_20150520.log (spaces) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_bytes_idx ON logstash_20150520.log (bytes) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_url_idx ON logstash_20150520.log (url) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log__version_idx ON logstash_20150520.log (""@version"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_geo_idx ON logstash_20150520.log (geo) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_ip_idx ON logstash_20150520.log (ip) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_relatedContent_idx ON logstash_20150520.log (""relatedContent"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_memory_idx ON logstash_20150520.log (memory) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log__tags_idx ON logstash_20150520.log (""@tags"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_request_idx ON logstash_20150520.log (request) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_machine_idx ON logstash_20150520.log (machine) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_response_idx ON logstash_20150520.log (response) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_headings_idx ON logstash_20150520.log (headings) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_referer_idx ON logstash_20150520.log (referer) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_links_idx ON logstash_20150520.log (links) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log__timestamp_idx ON logstash_20150520.log (""@timestamp"") USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_phpmemory_idx ON logstash_20150520.log (phpmemory) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_utc_time_idx ON logstash_20150520.log (utc_time) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; CREATE CUSTOM INDEX elastic_log_agent_idx ON logstash_20150520.log (agent) USING 'org.elasticsearch.cassandra.ElasticSecondaryIndex'; Maybe I'm doing something wrong? If I don't run the command for the geo_point creation on the Elasticsearch index, the bulk insert goes well but lat and lon are simply doubles (not geo coordinates) and kibana can't show them over the Map. Thanks. Alberto config-file",no-bug,0.8
197,elassandra,https://github.com/strapdata/elassandra/issues/197,Deletion of a List element removes the document on ES,"**Elassandra version**: 5.5.0.16 The problem occurs from a table with a compound key and a list of UDTs. When you remove an element from the list, the entire document is removed from the ES. **Steps to reproduce**: 1. Given the UDT sql CREATE TYPE type_test ( id text );  2. The table sql CREATE TABLE table_test ( id1 text, id2 text, list list<frozen<type_test>>, PRIMARY KEY (id1, id2) );  3. The ES index mapping json { ""settings"": { ""keyspace"": ""ks_test"" }, ""mappings"": { ""table_test"": { ""discover"": "".*"" } } }  4. Insert a row into the table: sql UPDATE table_test SET list = list + [{ id:'foo'}] where id1='1' and id2='2'; UPDATE table_test SET list = list + [{ id:'bar'}] where id1='1' and id2='2';  5. Search the document on ES: shell get ks_test/_search?pretty=true  json { ""took"" : 4, ""timed_out"" : false, ""_shards"" : { ""total"" : 1, ""successful"" : 1, ""failed"" : 0 }, ""hits"" : { ""total"" : 1, ""max_score"" : 1.0, ""hits"" : [ { ""_index"" : ""ks_test"", ""_type"" : ""table_test"", ""_id"" : ""[\""1\"",\""2\""]"", ""_score"" : 1.0, ""_source"" : { ""id2"" : ""2"", ""id1"" : ""1"", ""list"" : [ { ""id"" : ""foo"" }, { ""id"" : ""bar"" } ] } } ] } }  6. Now, remove one of the elements: sql UPDATE table_test SET list = list - [{ id:'bar'}] where id1='1' and id2='2';  7. Do the search again: shell get ks_test/_search?pretty=true  json { ""took"" : 0, ""timed_out"" : false, ""_shards"" : { ""total"" : 1, ""successful"" : 1, ""failed"" : 0 }, ""hits"" : { ""total"" : 0, ""max_score"" : null, ""hits"" : [ ] } }  **Notes** 1. if you reinsert the removed element and search again, the document is returned like in the step 5 2. the problem doesn't occurs on a table with only one key (partition key)",documentation-file | source-file | test-file | test-file | source-file | test-file,"Deletion of a List element removes the document on ES **Elassandra version**: 5.5.0.16 The problem occurs from a table with a compound key and a list of UDTs. When you remove an element from the list, the entire document is removed from the ES. **Steps to reproduce**: 1. Given the UDT sql CREATE TYPE type_test ( id text );  2. The table sql CREATE TABLE table_test ( id1 text, id2 text, list list<frozen<type_test>>, PRIMARY KEY (id1, id2) );  3. The ES index mapping json { ""settings"": { ""keyspace"": ""ks_test"" }, ""mappings"": { ""table_test"": { ""discover"": "".*"" } } }  4. Insert a row into the table: sql UPDATE table_test SET list = list + [{ id:'foo'}] where id1='1' and id2='2'; UPDATE table_test SET list = list + [{ id:'bar'}] where id1='1' and id2='2';  5. Search the document on ES: shell get ks_test/_search?pretty=true  json { ""took"" : 4, ""timed_out"" : false, ""_shards"" : { ""total"" : 1, ""successful"" : 1, ""failed"" : 0 }, ""hits"" : { ""total"" : 1, ""max_score"" : 1.0, ""hits"" : [ { ""_index"" : ""ks_test"", ""_type"" : ""table_test"", ""_id"" : ""[\""1\"",\""2\""]"", ""_score"" : 1.0, ""_source"" : { ""id2"" : ""2"", ""id1"" : ""1"", ""list"" : [ { ""id"" : ""foo"" }, { ""id"" : ""bar"" } ] } } ] } }  6. Now, remove one of the elements: sql UPDATE table_test SET list = list - [{ id:'bar'}] where id1='1' and id2='2';  7. Do the search again: shell get ks_test/_search?pretty=true  json { ""took"" : 0, ""timed_out"" : false, ""_shards"" : { ""total"" : 1, ""successful"" : 1, ""failed"" : 0 }, ""hits"" : { ""total"" : 0, ""max_score"" : null, ""hits"" : [ ] } }  **Notes** 1. if you reinsert the removed element and search again, the document is returned like in the step 5 2. the problem doesn't occurs on a table with only one key (partition key) documentation-file source-file test-file test-file source-file test-file",no-bug,0.8
282,elassandra,https://github.com/strapdata/elassandra/issues/282,Unable to create geo_shape index,"Elassandra version: 6.2.3.13-14 jvm: openjdk version ""1.8.0_212"" OS: Linux 631697ed6903 4.9.0-8-amd64 #1 SMP Debian 4.9.144-3.1 (2019-02-19) x86_64 GNU/Linux docker image: strapdata/elassandra:latest Hello, i'm trying to create geo_shape index for field with following request: PUT http://localhost:9200/weather `{ ""settings"": { ""keyspace"":""weather"" }, ""mappings"": { ""weather_data"" : { ""_source"": { ""enabled"": true }, ""properties"": { ""geom"": { ""type"":""geo_shape"" } } } } }` got the error: `{ ""error"": { ""root_cause"": [ { ""type"": ""mapper_parsing_exception"", ""reason"": ""Failed to execute query:null : Existing column [geom] type [text] mismatch with inferred type [list<text>]"" } ], ""type"": ""mapper_parsing_exception"", ""reason"": ""Failed to execute query:null : Existing column [geom] type [text] mismatch with inferred type [list<text>]"", ""caused_by"": { ""type"": ""configuration_exception"", ""reason"": ""Existing column [geom] type [text] mismatch with inferred type [list<text>]"" } }, ""status"": 400 }` The weather table: `CREATE TABLE weather.weather_data ( id text, updated_at timestamp, alt int, created_at timestamp, es_options text, es_query text, geom text, predict tinyint, radius int, time timestamp, type tinyint, version bigint, weather text, x int, y int, PRIMARY KEY (id, updated_at) ) WITH CLUSTERING ORDER BY (updated_at DESC) AND bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE';` Why geo_shape index needs list<text> type? And if add 'cql_collection' parameter to index request: `{ ""settings"": { ""keyspace"":""weather"" }, ""mappings"": { ""weather_data"" : { ""_source"": { ""enabled"": true }, ""properties"": { ""geom"": { ""type"":""geo_shape"", ""cql_collection"":""singleton"" } } } } }` I got the following error: `{ ""error"": { ""root_cause"": [ { ""type"": ""mapper_parsing_exception"", ""reason"": ""Mapping definition for [geom] has unsupported parameters: [cql_collection : singleton]"" } ], ""type"": ""mapper_parsing_exception"", ""reason"": ""Failed to parse mapping [weather_data]: Mapping definition for [geom] has unsupported parameters: [cql_collection : singleton]"", ""caused_by"": { ""type"": ""mapper_parsing_exception"", ""reason"": ""Mapping definition for [geom] has unsupported parameters: [cql_collection : singleton]"" } }, ""status"": 400 }` How can I create geo_shape index with field type 'text'?",source-file | source-file | test-file,"Unable to create geo_shape index Elassandra version: 6.2.3.13-14 jvm: openjdk version ""1.8.0_212"" OS: Linux 631697ed6903 4.9.0-8-amd64 #1 SMP Debian 4.9.144-3.1 (2019-02-19) x86_64 GNU/Linux docker image: strapdata/elassandra:latest Hello, i'm trying to create geo_shape index for field with following request: PUT http://localhost:9200/weather `{ ""settings"": { ""keyspace"":""weather"" }, ""mappings"": { ""weather_data"" : { ""_source"": { ""enabled"": true }, ""properties"": { ""geom"": { ""type"":""geo_shape"" } } } } }` got the error: `{ ""error"": { ""root_cause"": [ { ""type"": ""mapper_parsing_exception"", ""reason"": ""Failed to execute query:null : Existing column [geom] type [text] mismatch with inferred type [list<text>]"" } ], ""type"": ""mapper_parsing_exception"", ""reason"": ""Failed to execute query:null : Existing column [geom] type [text] mismatch with inferred type [list<text>]"", ""caused_by"": { ""type"": ""configuration_exception"", ""reason"": ""Existing column [geom] type [text] mismatch with inferred type [list<text>]"" } }, ""status"": 400 }` The weather table: `CREATE TABLE weather.weather_data ( id text, updated_at timestamp, alt int, created_at timestamp, es_options text, es_query text, geom text, predict tinyint, radius int, time timestamp, type tinyint, version bigint, weather text, x int, y int, PRIMARY KEY (id, updated_at) ) WITH CLUSTERING ORDER BY (updated_at DESC) AND bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE';` Why geo_shape index needs list<text> type? And if add 'cql_collection' parameter to index request: `{ ""settings"": { ""keyspace"":""weather"" }, ""mappings"": { ""weather_data"" : { ""_source"": { ""enabled"": true }, ""properties"": { ""geom"": { ""type"":""geo_shape"", ""cql_collection"":""singleton"" } } } } }` I got the following error: `{ ""error"": { ""root_cause"": [ { ""type"": ""mapper_parsing_exception"", ""reason"": ""Mapping definition for [geom] has unsupported parameters: [cql_collection : singleton]"" } ], ""type"": ""mapper_parsing_exception"", ""reason"": ""Failed to parse mapping [weather_data]: Mapping definition for [geom] has unsupported parameters: [cql_collection : singleton]"", ""caused_by"": { ""type"": ""mapper_parsing_exception"", ""reason"": ""Mapping definition for [geom] has unsupported parameters: [cql_collection : singleton]"" } }, ""status"": 400 }` How can I create geo_shape index with field type 'text'? source-file source-file test-file",bug,0.9
202,elassandra,https://github.com/strapdata/elassandra/issues/202,Memory lock not working,"I'm using Elassandra-6.2.3.1. I can't enable **memory lock** as it is possible in Elasticsearch 5.x/6.x. I followed Elassandra docs [https://elassandra.readthedocs.io/en/latest/configuration.html#sizing-and-tunning](url) turning swap off and setting Xms and Xmx but  GET _nodes?filter_path=**.mlockall { ""nodes"": { ""c5a17dbd-40ef-4f58-b132-0d977a92f1a1"": { ""process"": { ""mlockall"": false } }, ""f088d009-bd97-4e35-9f20-60006a68b363"": { ""process"": { ""mlockall"": false } }, ""e82191ad-9d9f-459f-9da0-2b0457ad6611"": { ""process"": { ""mlockall"": false } } } }  Is there a way to enable memory lock or Elassandra implicity already has this feature?",source-file,"Memory lock not working I'm using Elassandra-6.2.3.1. I can't enable **memory lock** as it is possible in Elasticsearch 5.x/6.x. I followed Elassandra docs [https://elassandra.readthedocs.io/en/latest/configuration.html#sizing-and-tunning](url) turning swap off and setting Xms and Xmx but  GET _nodes?filter_path=**.mlockall { ""nodes"": { ""c5a17dbd-40ef-4f58-b132-0d977a92f1a1"": { ""process"": { ""mlockall"": false } }, ""f088d009-bd97-4e35-9f20-60006a68b363"": { ""process"": { ""mlockall"": false } }, ""e82191ad-9d9f-459f-9da0-2b0457ad6611"": { ""process"": { ""mlockall"": false } } } }  Is there a way to enable memory lock or Elassandra implicity already has this feature? source-file",no-bug,0.9
70,elassandra,https://github.com/strapdata/elassandra/issues/70,ES DELETE by index/type fails for time-series indices,"There seems to be a possible bug or difference in the way plan indices are handled (ie: test_index) vs. timeseries indices (ie: test-2017.01.01) particularly evident on DELETE actions:  Successful DELETE: test_index <pre> DELETE test_index PUT _template/test_template { ""template"": ""test_index"", ""mappings"": { ""_default_"": { ""properties"": { ""attachment"": { ""type"": ""binary"" }, ""report"": { ""type"": ""boolean"" }, ""payload"": { ""type"": ""object"", ""enabled"": false } } } } } PUT test_index/test_type/test12 { ""@timestamp"": ""2016-12-27T19:14:00.012Z"", ""level"": ""INFO"", ""message"": ""test message"", ""action"": ""test_action"", ""payload"": {}, ""report"": false } DELETE test_index/test_type/test12 </pre>  Failed DELETE on index: test_index-2016.12.29 <pre> DELETE test_index* PUT _template/test_template { ""template"": ""test_index-*"", ""mappings"": { ""_default_"": { ""properties"": { ""attachment"": { ""type"": ""binary"" }, ""report"": { ""type"": ""boolean"" }, ""payload"": { ""type"": ""object"", ""enabled"": false } } } } } PUT test_index-2016.12.29/test_type/test12 { ""@timestamp"": ""2016-12-27T19:14:00.012Z"", ""level"": ""INFO"", ""message"": ""test message"", ""action"": ""test_action"", ""payload"": {}, ""report"": false } GET test_index-2016.12.29/_search DELETE test_index-2016.12.29/test_type/test12 </pre> Which results in the following error: <pre> { ""error"": { ""root_cause"": [ { ""type"": ""action_request_validation_exception"", ""reason"": ""Validation Failed: 1: test_index-2016.12.29.test_type table does not exists;"" } ], ""type"": ""action_request_validation_exception"", ""reason"": ""Validation Failed: 1: test_index-2016.12.29.test_type table does not exists;"" }, ""status"": 400 } </pre> Any suggestion as of what might be causing this?",source-file | source-file | source-file | test-file,"ES DELETE by index/type fails for time-series indices There seems to be a possible bug or difference in the way plan indices are handled (ie: test_index) vs. timeseries indices (ie: test-2017.01.01) particularly evident on DELETE actions:  Successful DELETE: test_index <pre> DELETE test_index PUT _template/test_template { ""template"": ""test_index"", ""mappings"": { ""_default_"": { ""properties"": { ""attachment"": { ""type"": ""binary"" }, ""report"": { ""type"": ""boolean"" }, ""payload"": { ""type"": ""object"", ""enabled"": false } } } } } PUT test_index/test_type/test12 { ""@timestamp"": ""2016-12-27T19:14:00.012Z"", ""level"": ""INFO"", ""message"": ""test message"", ""action"": ""test_action"", ""payload"": {}, ""report"": false } DELETE test_index/test_type/test12 </pre>  Failed DELETE on index: test_index-2016.12.29 <pre> DELETE test_index* PUT _template/test_template { ""template"": ""test_index-*"", ""mappings"": { ""_default_"": { ""properties"": { ""attachment"": { ""type"": ""binary"" }, ""report"": { ""type"": ""boolean"" }, ""payload"": { ""type"": ""object"", ""enabled"": false } } } } } PUT test_index-2016.12.29/test_type/test12 { ""@timestamp"": ""2016-12-27T19:14:00.012Z"", ""level"": ""INFO"", ""message"": ""test message"", ""action"": ""test_action"", ""payload"": {}, ""report"": false } GET test_index-2016.12.29/_search DELETE test_index-2016.12.29/test_type/test12 </pre> Which results in the following error: <pre> { ""error"": { ""root_cause"": [ { ""type"": ""action_request_validation_exception"", ""reason"": ""Validation Failed: 1: test_index-2016.12.29.test_type table does not exists;"" } ], ""type"": ""action_request_validation_exception"", ""reason"": ""Validation Failed: 1: test_index-2016.12.29.test_type table does not exists;"" }, ""status"": 400 } </pre> Any suggestion as of what might be causing this? source-file source-file source-file test-file",bug,0.9
9,elassandra,https://github.com/strapdata/elassandra/issues/9,Cannot create index pattern in Kibana (cluster setup),"Has anyone else experienced any problems while setting up Kibana 4.3 while having multiple nodes? When using elassandra with just a single node, I'm able to setup the index pattern and see my data in Kibana as it's being loaded. However, when I try to do the same thing with several nodes, I cannot create the index (Kibana is able to find the index and recognize the Time-field name, however it doesn't do anything when I click create). Additionally, online it is posted that I should use the sed command as: sed -i .bak -e ""s/type: ${q}index-pattern${q}/type: ${q}index_pattern${q}/g"" -e ""s/type = ${q}index-pattern${q}/type = ${q}index_pattern${q}/g"" -e ""s%${q}index-pattern${q}: ${q}/settings/objects/savedSearches/${q}%${q}index_pattern${q}: ${q}/settings/objects/savedSearches/${q}%g"" optimize/bundles/kibana.bundle.js src/ui/public/index_patterns/_.js src/ui/public/index_patterns/_.js src/ui/public/index_patterns/*.js is repeated twice. In order to get kibana working on a single node, I also used sed on src/plugins/kibana/public/discover/controllers/discover.js. Note: I'm using elassandra 2.1.1",config-file,"Cannot create index pattern in Kibana (cluster setup) Has anyone else experienced any problems while setting up Kibana 4.3 while having multiple nodes? When using elassandra with just a single node, I'm able to setup the index pattern and see my data in Kibana as it's being loaded. However, when I try to do the same thing with several nodes, I cannot create the index (Kibana is able to find the index and recognize the Time-field name, however it doesn't do anything when I click create). Additionally, online it is posted that I should use the sed command as: sed -i .bak -e ""s/type: ${q}index-pattern${q}/type: ${q}index_pattern${q}/g"" -e ""s/type = ${q}index-pattern${q}/type = ${q}index_pattern${q}/g"" -e ""s%${q}index-pattern${q}: ${q}/settings/objects/savedSearches/${q}%${q}index_pattern${q}: ${q}/settings/objects/savedSearches/${q}%g"" optimize/bundles/kibana.bundle.js src/ui/public/index_patterns/_.js src/ui/public/index_patterns/_.js src/ui/public/index_patterns/*.js is repeated twice. In order to get kibana working on a single node, I also used sed on src/plugins/kibana/public/discover/controllers/discover.js. Note: I'm using elassandra 2.1.1 config-file",no-bug,0.8
163,elassandra,https://github.com/strapdata/elassandra/issues/163,Invalid date mapping,"<!-- GitHub is reserved for bug reports and feature requests. The best place to ask a general question is at the Elastic Discourse forums at https://discuss.elastic.co. If you are in fact posting a bug report or a feature request, please include one and only one of the below blocks in your new issue. Note that whether you're filing a bug report or a feature request, ensure that your submission is for an [OS that we support](https://www.elastic.co/support/matrix#show_os). Bug reports on an OS that we do not support or feature requests specific to an OS that we do not support will be closed. --> <!-- If you are filing a bug report, please remove the below feature request block and provide responses for all of the below items. --> **Elasticsearch version**: 5.5.0 **Plugins installed**: [] **JVM version**: 8 **OS version**: **Description of the problem including expected versus actual behavior**: **Steps to reproduce**: 1. create table with date field  create table date_elassandra_test ( id int primary key, somedate date );  2. create mapping on it  PUT http://node:9200/myspace/date_elassandra_test/_mapping { ""date_elassandra_test"": { ""properties"": { ""somedate"": { ""type"": ""date"", ""cql_collection"": ""singleton"" } } } }  3. insert some data `insert into date_elassandra_test (id,somedate) values (1,'2018-02-03');` 4. check search result  POST http://node:9200/myspace/date_elassandra_test/_search  {  ""_source"": { ""somedate"": ""-5877593-07-26T00:00:00.000Z"" }  } As you see - somedate is somehow offseted date for ElasticSearch. But if TIMESTAMP cassandra type is used instead - all is well",source-file | source-file | test-file | documentation-file,"Invalid date mapping <!-- GitHub is reserved for bug reports and feature requests. The best place to ask a general question is at the Elastic Discourse forums at https://discuss.elastic.co. If you are in fact posting a bug report or a feature request, please include one and only one of the below blocks in your new issue. Note that whether you're filing a bug report or a feature request, ensure that your submission is for an [OS that we support](https://www.elastic.co/support/matrix#show_os). Bug reports on an OS that we do not support or feature requests specific to an OS that we do not support will be closed. --> <!-- If you are filing a bug report, please remove the below feature request block and provide responses for all of the below items. --> **Elasticsearch version**: 5.5.0 **Plugins installed**: [] **JVM version**: 8 **OS version**: **Description of the problem including expected versus actual behavior**: **Steps to reproduce**: 1. create table with date field  create table date_elassandra_test ( id int primary key, somedate date );  2. create mapping on it  PUT http://node:9200/myspace/date_elassandra_test/_mapping { ""date_elassandra_test"": { ""properties"": { ""somedate"": { ""type"": ""date"", ""cql_collection"": ""singleton"" } } } }  3. insert some data `insert into date_elassandra_test (id,somedate) values (1,'2018-02-03');` 4. check search result  POST http://node:9200/myspace/date_elassandra_test/_search  {  ""_source"": { ""somedate"": ""-5877593-07-26T00:00:00.000Z"" }  } As you see - somedate is somehow offseted date for ElasticSearch. But if TIMESTAMP cassandra type is used instead - all is well source-file source-file test-file documentation-file",bug,0.9
12,elassandra,https://github.com/strapdata/elassandra/issues/12,add full support for elastic hq,Elastic HQ Plugin: http://www.elastichq.org/support_plugin.html works good. But some variables like CPU and Network.. are not correct / elassandra provide no information here. elasticsearch does.,other-file | config-file | config-file | documentation-file | config-file | config-file,add full support for elastic hq Elastic HQ Plugin: http://www.elastichq.org/support_plugin.html works good. But some variables like CPU and Network.. are not correct / elassandra provide no information here. elasticsearch does. other-file config-file config-file documentation-file config-file config-file,no-bug,0.8
91,elassandra,https://github.com/strapdata/elassandra/issues/91,Timeout when updating mapping due to new field in nested field (c* map),"I have a single node and a table with map<text, text>. When i insert a row via cql, elassandra attempts to update the type mapping (presumably in the elastic_admin.metadata table. I'm getting a timeout in the logs for each field update, like so:  2017-04-10 13:48:14,726 INFO [SharedPool-Worker-2] ElasticSecondaryIndex.java:470 addField updating mapping={""event_structured"":{""properties"":{""strings"":{""type"":""nested"",""cql_struct"":""map"",""cql_collection"":""singleton "",""properties"":{""stringProperty1"":{""type"":""string"" 2017-04-10 13:48:44,727 ERROR [SharedPool-Worker-2] ElasticSecondaryIndex.java:476 addField error while updating mapping org.elasticsearch.ElasticsearchTimeoutException: blocking update timeout at org.elassandra.cluster.InternalCassandraClusterService$BlockingActionListener.waitForUpdate(InternalCassandraClusterService.java:1690) at org.elassandra.cluster.InternalCassandraClusterService.blockingMappingUpdate(InternalCassandraClusterService.java:1717) at org.elassandra.index.ElasticSecondaryIndex$Context.addField(ElasticSecondaryIndex.java:472) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.buildContext(ElasticSecondaryIndex.java:1706) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.buildContext(ElasticSecondaryIndex.java:1264) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1774) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1764) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.index(ElasticSecondaryIndex.java:1264) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer.flush(ElasticSecondaryIndex.java:1307) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer.finish(ElasticSecondaryIndex.java:1496) at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.commit(SecondaryIndexManager.java:869) at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:180) at org.apache.cassandra.db.Memtable.put(Memtable.java:258) at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1189) at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:558) at org.apache.cassandra.db.Keyspace.applyNotDeferrable(Keyspace.java:404) at org.apache.cassandra.db.Mutation.apply(Mutation.java:213) at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1344) at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2516) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) at org.apache.cassandra.concurrent.SEPExecutor.maybeExecuteImmediately(SEPExecutor.java:192) at org.apache.cassandra.service.StorageProxy.performLocally(StorageProxy.java:1338) at org.apache.cassandra.service.StorageProxy.sendToHintedEndpoints(StorageProxy.java:1247) at org.apache.cassandra.service.StorageProxy$2.apply(StorageProxy.java:136) at org.apache.cassandra.service.StorageProxy.performWrite(StorageProxy.java:1053) at org.apache.cassandra.service.StorageProxy.mutate(StorageProxy.java:607) at org.apache.cassandra.service.StorageProxy.mutateWithTriggers(StorageProxy.java:833) at org.apache.cassandra.cql3.statements.ModificationStatement.executeWithoutCondition(ModificationStatement.java:422) at org.apache.cassandra.cql3.statements.ModificationStatement.execute(ModificationStatement.java:408) at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:206) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:237) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:222) at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:115) at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:513) at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:407) at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:292) at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:32) at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:283) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) at java.lang.Thread.run(Thread.java:745)  Here, my map<text,text> column name is 'strings' and the key in the map is 'stringProperty1'. The metadata table does have the initial index settings created using the discover method. I'm able to insert data into my table successfully when it does not have a secondary index. Both my keyspace and the elastic_admin keyspace have the same replication = { 'class' : 'NetworkTopologyStrategy', 'DC1' : 1 } Is this a single node issue perhaps?",source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file,"Timeout when updating mapping due to new field in nested field (c* map) I have a single node and a table with map<text, text>. When i insert a row via cql, elassandra attempts to update the type mapping (presumably in the elastic_admin.metadata table. I'm getting a timeout in the logs for each field update, like so:  2017-04-10 13:48:14,726 INFO [SharedPool-Worker-2] ElasticSecondaryIndex.java:470 addField updating mapping={""event_structured"":{""properties"":{""strings"":{""type"":""nested"",""cql_struct"":""map"",""cql_collection"":""singleton "",""properties"":{""stringProperty1"":{""type"":""string"" 2017-04-10 13:48:44,727 ERROR [SharedPool-Worker-2] ElasticSecondaryIndex.java:476 addField error while updating mapping org.elasticsearch.ElasticsearchTimeoutException: blocking update timeout at org.elassandra.cluster.InternalCassandraClusterService$BlockingActionListener.waitForUpdate(InternalCassandraClusterService.java:1690) at org.elassandra.cluster.InternalCassandraClusterService.blockingMappingUpdate(InternalCassandraClusterService.java:1717) at org.elassandra.index.ElasticSecondaryIndex$Context.addField(ElasticSecondaryIndex.java:472) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.buildContext(ElasticSecondaryIndex.java:1706) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.buildContext(ElasticSecondaryIndex.java:1264) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1774) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1764) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.index(ElasticSecondaryIndex.java:1264) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer.flush(ElasticSecondaryIndex.java:1307) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer.finish(ElasticSecondaryIndex.java:1496) at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.commit(SecondaryIndexManager.java:869) at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:180) at org.apache.cassandra.db.Memtable.put(Memtable.java:258) at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1189) at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:558) at org.apache.cassandra.db.Keyspace.applyNotDeferrable(Keyspace.java:404) at org.apache.cassandra.db.Mutation.apply(Mutation.java:213) at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1344) at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2516) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) at org.apache.cassandra.concurrent.SEPExecutor.maybeExecuteImmediately(SEPExecutor.java:192) at org.apache.cassandra.service.StorageProxy.performLocally(StorageProxy.java:1338) at org.apache.cassandra.service.StorageProxy.sendToHintedEndpoints(StorageProxy.java:1247) at org.apache.cassandra.service.StorageProxy$2.apply(StorageProxy.java:136) at org.apache.cassandra.service.StorageProxy.performWrite(StorageProxy.java:1053) at org.apache.cassandra.service.StorageProxy.mutate(StorageProxy.java:607) at org.apache.cassandra.service.StorageProxy.mutateWithTriggers(StorageProxy.java:833) at org.apache.cassandra.cql3.statements.ModificationStatement.executeWithoutCondition(ModificationStatement.java:422) at org.apache.cassandra.cql3.statements.ModificationStatement.execute(ModificationStatement.java:408) at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:206) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:237) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:222) at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:115) at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:513) at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:407) at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:292) at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:32) at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:283) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) at java.lang.Thread.run(Thread.java:745)  Here, my map<text,text> column name is 'strings' and the key in the map is 'stringProperty1'. The metadata table does have the initial index settings created using the discover method. I'm able to insert data into my table successfully when it does not have a secondary index. Both my keyspace and the elastic_admin keyspace have the same replication = { 'class' : 'NetworkTopologyStrategy', 'DC1' : 1 } Is this a single node issue perhaps? source-file source-file source-file test-file source-file source-file source-file test-file",no-bug,0.9
274,elassandra,https://github.com/strapdata/elassandra/issues/274,Cannot create indexes in case the table has materialized views,"Hello, Using Elassandra version: `v6.2.3.12` I created a keyspace `test_keyspace` and one table that has a view: sql CREATE TABLE numbers(number text, account_uuid timeuuid, type int, state text, country_code text, purchase_date timestamp, release_date timestamp, status int, PRIMARY KEY(number)); CREATE MATERIALIZED VIEW numbers_by_user AS SELECT * FROM numbers WHERE number IS NOT NULL AND account_uuid IS NOT NULL PRIMARY KEY (account_uuid, number);  When trying to create a mapping as follow: sh curl -XPUT ""http://172.17.33.171:9200/test_numbers"" -H 'Content-Type: application/json' -d ' { ""settings"" : { ""keyspace"" : ""test_keyspace"" }, ""mappings"": { ""numbers"": { ""_field_names"": {""enabled"": false}, ""discover"": ""number|type|state|contry_code|status"" } } }'  I get the following error: json {""error"":{""root_cause"":[{""type"":""mapper_parsing_exception"",""reason"":""Multiple entries with same key: numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[ and numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[""}],""type"":""mapper_parsing_exception"",""reason"":""Multiple entries with same key: numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[ and numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=["",""caused_by"":{""type"":""illegal_argument_exception"",""reason"":""Multiple entries with same key: numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[ and numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[""}},""status"":400}  If there is no materialized view created it's working.",source-file | test-file,"Cannot create indexes in case the table has materialized views Hello, Using Elassandra version: `v6.2.3.12` I created a keyspace `test_keyspace` and one table that has a view: sql CREATE TABLE numbers(number text, account_uuid timeuuid, type int, state text, country_code text, purchase_date timestamp, release_date timestamp, status int, PRIMARY KEY(number)); CREATE MATERIALIZED VIEW numbers_by_user AS SELECT * FROM numbers WHERE number IS NOT NULL AND account_uuid IS NOT NULL PRIMARY KEY (account_uuid, number);  When trying to create a mapping as follow: sh curl -XPUT ""http://172.17.33.171:9200/test_numbers"" -H 'Content-Type: application/json' -d ' { ""settings"" : { ""keyspace"" : ""test_keyspace"" }, ""mappings"": { ""numbers"": { ""_field_names"": {""enabled"": false}, ""discover"": ""number|type|state|contry_code|status"" } } }'  I get the following error: json {""error"":{""root_cause"":[{""type"":""mapper_parsing_exception"",""reason"":""Multiple entries with same key: numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[ and numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[""}],""type"":""mapper_parsing_exception"",""reason"":""Multiple entries with same key: numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[ and numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=["",""caused_by"":{""type"":""illegal_argument_exception"",""reason"":""Multiple entries with same key: numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[ and numbers_by_user=org.apache.cassandra.config.ViewDefinition@5cc77036[ksName=test_keyspace,viewName=numbers_by_user,baseTableId=7ba3ee50-5aa7-11e9-b32c-7fa424e5960d,baseTableName=numbers,includeAllColumns=true,whereClause=number IS NOT NULL AND account_uuid IS NOT NULL,metadata=org.apache.cassandra.config.CFMetaData@7429ad08[cfId=8600abe0-5aa7-11e9-b32c-7fa424e5960d,ksName=test_keyspace,cfName=numbers_by_user,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={max_threshold=32, min_threshold=4}}, compression=org.apache.cassandra.schema.CompressionParams@bbfbd591, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [country_code purchase_date release_date state status type]],partitionKeyColumns=[account_uuid],clusteringColumns=[number],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[number, country_code, status, purchase_date, release_date, state, type, account_uuid],droppedColumns={},triggers=[],indexes=[""}},""status"":400}  If there is no materialized view created it's working. source-file test-file",no-bug,0.9
87,elassandra,https://github.com/strapdata/elassandra/issues/87,Unable query null values from elasticsearch in elassandra 2.4.2-6,"I'm using currently elassandra 2.4.2-6 and I cannot build a query to retrieve documents which *have a property with null value* I means, the document in elasticsearch which has not a property. I tried several approach suggested by elasticsearch's documentation * exists query https://www.elastic.co/guide/en/elasticsearch/reference/2.1/query-dsl-exists-query.html * null_value (set a value by default if the data is null) https://www.elastic.co/guide/en/elasticsearch/reference/2.1/null-value.html However in both cases I get no results data. Any suggestion? I try the same queries in Elasticsearch 2.1.1 and they work fine.",source-file | test-file,"Unable query null values from elasticsearch in elassandra 2.4.2-6 I'm using currently elassandra 2.4.2-6 and I cannot build a query to retrieve documents which *have a property with null value* I means, the document in elasticsearch which has not a property. I tried several approach suggested by elasticsearch's documentation * exists query https://www.elastic.co/guide/en/elasticsearch/reference/2.1/query-dsl-exists-query.html * null_value (set a value by default if the data is null) https://www.elastic.co/guide/en/elasticsearch/reference/2.1/null-value.html However in both cases I get no results data. Any suggestion? I try the same queries in Elasticsearch 2.1.1 and they work fine. source-file test-file",no-bug,0.9
6,elassandra,https://github.com/strapdata/elassandra/issues/6,Elassandra Init Script,"Hi, i have added a elassandra init script here for Linux Debian Servers. The stop function does not work at the moment.. Mybe you can use it :-) https://github.com/ChrisFeldmeier/elassandra-init",other-file | config-file | config-file | other-file | container-file | documentation-file | config-file | config-file | config-file | config-file | config-file,"Elassandra Init Script Hi, i have added a elassandra init script here for Linux Debian Servers. The stop function does not work at the moment.. Mybe you can use it :-) https://github.com/ChrisFeldmeier/elassandra-init other-file config-file config-file other-file container-file documentation-file config-file config-file config-file config-file config-file",no-bug,0.9
65,elassandra,https://github.com/strapdata/elassandra/issues/65,java.io.IOException: from is a reserved keyword,"Bonjour Vincent, Using latest build, I am attempting to create custom index mapping including object types resulting in a faceted issue - filing them together as they seem two faces of the same coin so to speak.  java.io.IOException: from is a reserved keyword  PUT watcher { ""mappings"": { ""watch"": { ""properties"": { ""id"": { ""type"": ""string"", ""index"": ""not_analyzed"" }, ""condition"": { ""type"":""object"", ""enabled"": false }, ""input"": { ""type"":""object"", ""enabled"": false }, ""transform"": { ""type"":""object"", ""enabled"": false } } } } }  followed by a document creation attempt:  PUT watcher/watch/test_watch_random { ""disabled"": false, ""id"": ""test_watch_random"", ""trigger"": { ""schedule"": { ""later"": ""every 5 minutes"" } }, ""input"": { ""search"": { ""request"": { ""index"": [], ""body"": {} } } }, ""condition"": { ""script"": { ""script"": ""payload.hits.total > 100"" } }, ""transform"": {}, ""actions"": { ""email_admin"": { ""throttle_period"": ""15m"", ""email"": { ""to"": ""alarm@localhost"", ""from"": ""sentinl@localhost"", ""subject"": ""Sentinl Alarm"", ""priority"": ""high"", ""body"": ""Found {{payload.hits.total}} Events"" } } } }  The first response of Elassandra is:  { ""error"": { ""root_cause"": [ { ""type"": ""runtime_exception"", ""reason"": ""java.io.IOException: from is a reserved keyword"" } ], ""type"": ""runtime_exception"", ""reason"": ""java.io.IOException: from is a reserved keyword"", ""caused_by"": { ""type"": ""i_o_exception"", ""reason"": ""from is a reserved keyword"", ""caused_by"": { ""type"": ""configuration_exception"", ""reason"": ""from is a reserved keyword"" } } }, ""status"": 500 }  with logs:  2016-12-26 08:51:11,257 WARN [elasticsearch[127.0.0.1][http_server_worker][T#3]{New I/O worker #53}] BytesRestResponse.java:134 convert path: /watcher2/watch/test_watch_random, params: {index=watcher2, id=test_watch_random, type=watch} java.lang.RuntimeException: java.io.IOException: from is a reserved keyword at org.elassandra.cluster.InternalCassandraClusterService$BlockingActionListener.waitForUpdate(InternalCassandraClusterService.java:1820) at org.elassandra.cluster.InternalCassandraClusterService.blockingMappingUpdate(InternalCassandraClusterService.java:1842) at org.elassandra.cluster.InternalCassandraClusterService.upsertDocument(InternalCassandraClusterService.java:1879) at org.elassandra.cluster.InternalCassandraClusterService.insertDocument(InternalCassandraClusterService.java:1852) at org.elasticsearch.action.index.TransportXIndexAction.innerExecute(TransportXIndexAction.java:85) at org.elasticsearch.action.index.TransportIndexAction.doExecute(TransportIndexAction.java:120) at org.elasticsearch.action.index.TransportIndexAction.doExecute(TransportIndexAction.java:66) at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:137) at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:85) at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:58) at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:359) at org.elasticsearch.client.FilterClient.doExecute(FilterClient.java:52) at org.elasticsearch.rest.BaseRestHandler$HeadersAndContextCopyClient.doExecute(BaseRestHandler.java:88) at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:359) at org.elasticsearch.client.support.AbstractClient.index(AbstractClient.java:371) at org.elasticsearch.rest.action.index.RestIndexAction.handleRequest(RestIndexAction.java:105) at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:54) at org.elasticsearch.rest.RestController.executeHandler(RestController.java:198) at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:158) at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:153) at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:101) at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:451) at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:61) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.messageReceived(HttpPipeliningHandler.java:60) at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:108) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) Caused by: java.io.IOException: from is a reserved keyword at org.elassandra.cluster.InternalCassandraClusterService.updateTableSchema(InternalCassandraClusterService.java:1185) at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:391) at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:280) at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:540) at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:902) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)  3 common frames omitted Caused by: org.apache.cassandra.exceptions.ConfigurationException: from is a reserved keyword at org.elassandra.cluster.InternalCassandraClusterService.buildUDT(InternalCassandraClusterService.java:795) at org.elassandra.cluster.InternalCassandraClusterService.buildCql(InternalCassandraClusterService.java:744) at org.elassandra.cluster.InternalCassandraClusterService.buildUDT(InternalCassandraClusterService.java:772) at org.elassandra.cluster.InternalCassandraClusterService.buildCql(InternalCassandraClusterService.java:744) at org.elassandra.cluster.InternalCassandraClusterService.buildUDT(InternalCassandraClusterService.java:772) at org.elassandra.cluster.InternalCassandraClusterService.buildCql(InternalCassandraClusterService.java:744) at org.elassandra.cluster.InternalCassandraClusterService.updateTableSchema(InternalCassandraClusterService.java:1093)  9 common frames omitted  Interestingly, attempting the very same insert unchanged, works:  { ""_index"": ""watcher"", ""_type"": ""watch"", ""_id"": ""test_watch_random"", ""_version"": 1, ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 }, ""created"": true }  and gets indexed correctly:  GET watcher/_search { ""took"": 5, ""timed_out"": false, ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 }, ""hits"": { ""total"": 1, ""max_score"": 1, ""hits"": [ { ""_index"": ""watcher"", ""_type"": ""watch"", ""_id"": ""test_watch_random"", ""_score"": 1, ""_source"": { ""input"": ""{\""search\"":{\""request\"":{\""index\"":[],\""body\"":{"", ""condition"": ""{\""script\"":{\""script\"":\""payload.hits.total > 100\""}}"", ""transform"": ""{}"", ""id"": ""test_name"" } } ] } }   Pure Object documents not searchable Attempting to create a mapping without an ""enabled"" field seems to fail harder - the above mapping/document without the ""string"" id field is accepted but returns no search results afterwards. Here's an adapted example to reproduce:  PUT watcher_fail { ""mappings"": { ""watch"": { ""properties"": { ""condition"": { ""type"":""object"", ""enabled"": false }, ""input"": { ""type"":""object"", ""enabled"": false }, ""transform"": { ""type"":""object"", ""enabled"": false } } } } }  followed by a document creation attempt:  PUT watcher_fail/watch/this_doc_will_be_missing { ""trigger"": { ""schedule"": { ""later"": ""every 5 minutes"" } }, ""input"": { ""search"": { ""request"": { ""index"": [], ""body"": {} } } }, ""condition"": { ""script"": { ""script"": ""payload.hits.total > 100"" } }, ""transform"": {}, ""actions"": { ""email_admin"": { ""throttle_period"": ""15m"", ""email"": { ""to"": ""alarm@localhost"", ""from"": ""sentinl@localhost"", ""subject"": ""Sentinl Alarm"", ""priority"": ""high"", ""body"": ""Found {{payload.hits.total}} Events"" } } } }  The above document should get accepted, but will never be available in search:  GET watcher_fail/_search ",source-file,"java.io.IOException: from is a reserved keyword Bonjour Vincent, Using latest build, I am attempting to create custom index mapping including object types resulting in a faceted issue - filing them together as they seem two faces of the same coin so to speak.  java.io.IOException: from is a reserved keyword  PUT watcher { ""mappings"": { ""watch"": { ""properties"": { ""id"": { ""type"": ""string"", ""index"": ""not_analyzed"" }, ""condition"": { ""type"":""object"", ""enabled"": false }, ""input"": { ""type"":""object"", ""enabled"": false }, ""transform"": { ""type"":""object"", ""enabled"": false } } } } }  followed by a document creation attempt:  PUT watcher/watch/test_watch_random { ""disabled"": false, ""id"": ""test_watch_random"", ""trigger"": { ""schedule"": { ""later"": ""every 5 minutes"" } }, ""input"": { ""search"": { ""request"": { ""index"": [], ""body"": {} } } }, ""condition"": { ""script"": { ""script"": ""payload.hits.total > 100"" } }, ""transform"": {}, ""actions"": { ""email_admin"": { ""throttle_period"": ""15m"", ""email"": { ""to"": ""alarm@localhost"", ""from"": ""sentinl@localhost"", ""subject"": ""Sentinl Alarm"", ""priority"": ""high"", ""body"": ""Found {{payload.hits.total}} Events"" } } } }  The first response of Elassandra is:  { ""error"": { ""root_cause"": [ { ""type"": ""runtime_exception"", ""reason"": ""java.io.IOException: from is a reserved keyword"" } ], ""type"": ""runtime_exception"", ""reason"": ""java.io.IOException: from is a reserved keyword"", ""caused_by"": { ""type"": ""i_o_exception"", ""reason"": ""from is a reserved keyword"", ""caused_by"": { ""type"": ""configuration_exception"", ""reason"": ""from is a reserved keyword"" } } }, ""status"": 500 }  with logs:  2016-12-26 08:51:11,257 WARN [elasticsearch[127.0.0.1][http_server_worker][T#3]{New I/O worker #53}] BytesRestResponse.java:134 convert path: /watcher2/watch/test_watch_random, params: {index=watcher2, id=test_watch_random, type=watch} java.lang.RuntimeException: java.io.IOException: from is a reserved keyword at org.elassandra.cluster.InternalCassandraClusterService$BlockingActionListener.waitForUpdate(InternalCassandraClusterService.java:1820) at org.elassandra.cluster.InternalCassandraClusterService.blockingMappingUpdate(InternalCassandraClusterService.java:1842) at org.elassandra.cluster.InternalCassandraClusterService.upsertDocument(InternalCassandraClusterService.java:1879) at org.elassandra.cluster.InternalCassandraClusterService.insertDocument(InternalCassandraClusterService.java:1852) at org.elasticsearch.action.index.TransportXIndexAction.innerExecute(TransportXIndexAction.java:85) at org.elasticsearch.action.index.TransportIndexAction.doExecute(TransportIndexAction.java:120) at org.elasticsearch.action.index.TransportIndexAction.doExecute(TransportIndexAction.java:66) at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:137) at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:85) at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:58) at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:359) at org.elasticsearch.client.FilterClient.doExecute(FilterClient.java:52) at org.elasticsearch.rest.BaseRestHandler$HeadersAndContextCopyClient.doExecute(BaseRestHandler.java:88) at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:359) at org.elasticsearch.client.support.AbstractClient.index(AbstractClient.java:371) at org.elasticsearch.rest.action.index.RestIndexAction.handleRequest(RestIndexAction.java:105) at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:54) at org.elasticsearch.rest.RestController.executeHandler(RestController.java:198) at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:158) at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:153) at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:101) at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:451) at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:61) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.messageReceived(HttpPipeliningHandler.java:60) at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:108) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536) at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435) at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337) at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89) at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) Caused by: java.io.IOException: from is a reserved keyword at org.elassandra.cluster.InternalCassandraClusterService.updateTableSchema(InternalCassandraClusterService.java:1185) at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:391) at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:280) at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:540) at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:902) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)  3 common frames omitted Caused by: org.apache.cassandra.exceptions.ConfigurationException: from is a reserved keyword at org.elassandra.cluster.InternalCassandraClusterService.buildUDT(InternalCassandraClusterService.java:795) at org.elassandra.cluster.InternalCassandraClusterService.buildCql(InternalCassandraClusterService.java:744) at org.elassandra.cluster.InternalCassandraClusterService.buildUDT(InternalCassandraClusterService.java:772) at org.elassandra.cluster.InternalCassandraClusterService.buildCql(InternalCassandraClusterService.java:744) at org.elassandra.cluster.InternalCassandraClusterService.buildUDT(InternalCassandraClusterService.java:772) at org.elassandra.cluster.InternalCassandraClusterService.buildCql(InternalCassandraClusterService.java:744) at org.elassandra.cluster.InternalCassandraClusterService.updateTableSchema(InternalCassandraClusterService.java:1093)  9 common frames omitted  Interestingly, attempting the very same insert unchanged, works:  { ""_index"": ""watcher"", ""_type"": ""watch"", ""_id"": ""test_watch_random"", ""_version"": 1, ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 }, ""created"": true }  and gets indexed correctly:  GET watcher/_search { ""took"": 5, ""timed_out"": false, ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 }, ""hits"": { ""total"": 1, ""max_score"": 1, ""hits"": [ { ""_index"": ""watcher"", ""_type"": ""watch"", ""_id"": ""test_watch_random"", ""_score"": 1, ""_source"": { ""input"": ""{\""search\"":{\""request\"":{\""index\"":[],\""body\"":{"", ""condition"": ""{\""script\"":{\""script\"":\""payload.hits.total > 100\""}}"", ""transform"": ""{}"", ""id"": ""test_name"" } } ] } }   Pure Object documents not searchable Attempting to create a mapping without an ""enabled"" field seems to fail harder - the above mapping/document without the ""string"" id field is accepted but returns no search results afterwards. Here's an adapted example to reproduce:  PUT watcher_fail { ""mappings"": { ""watch"": { ""properties"": { ""condition"": { ""type"":""object"", ""enabled"": false }, ""input"": { ""type"":""object"", ""enabled"": false }, ""transform"": { ""type"":""object"", ""enabled"": false } } } } }  followed by a document creation attempt:  PUT watcher_fail/watch/this_doc_will_be_missing { ""trigger"": { ""schedule"": { ""later"": ""every 5 minutes"" } }, ""input"": { ""search"": { ""request"": { ""index"": [], ""body"": {} } } }, ""condition"": { ""script"": { ""script"": ""payload.hits.total > 100"" } }, ""transform"": {}, ""actions"": { ""email_admin"": { ""throttle_period"": ""15m"", ""email"": { ""to"": ""alarm@localhost"", ""from"": ""sentinl@localhost"", ""subject"": ""Sentinl Alarm"", ""priority"": ""high"", ""body"": ""Found {{payload.hits.total}} Events"" } } } }  The above document should get accepted, but will never be available in search:  GET watcher_fail/_search  source-file",bug,0.9
146,elassandra,https://github.com/strapdata/elassandra/issues/146,Question. Is there a workaround for empty object type?,"[The elassandra doc](http://elassandra.readthedocs.io/en/latest/limitations.html#nested-or-object-types-cannot-be-empty) says: ""Because Elasticsearch nested and object types are backed by a Cassandra User Defined Type, it requires at least one sub-field in the mapping.""; My app currently works with Elasticsearch v5+ and v6+ and [object type](https://www.elastic.co/guide/en/elasticsearch/reference/current/object.html) mapping is used. For example  { ""properties"": { ""input"": { ""type"": ""object"", ""enabled"": false } } }  There are fields where I have a lot of deeply nested objects I don't know beforehand their names or the level of deepness. For example, the `input` above has to support any Elasticsearch query syntax.  { ""properties"": { ""search"": { ""query"": { Elasticsearch query is here } } } }  That's why I need to add the new properties dynamically to the `input`. Is there any workaround to support my case? PS I know that the property can be stringified.",source-file | source-file | test-file,"Question. Is there a workaround for empty object type? [The elassandra doc](http://elassandra.readthedocs.io/en/latest/limitations.html#nested-or-object-types-cannot-be-empty) says: ""Because Elasticsearch nested and object types are backed by a Cassandra User Defined Type, it requires at least one sub-field in the mapping.""; My app currently works with Elasticsearch v5+ and v6+ and [object type](https://www.elastic.co/guide/en/elasticsearch/reference/current/object.html) mapping is used. For example  { ""properties"": { ""input"": { ""type"": ""object"", ""enabled"": false } } }  There are fields where I have a lot of deeply nested objects I don't know beforehand their names or the level of deepness. For example, the `input` above has to support any Elasticsearch query syntax.  { ""properties"": { ""search"": { ""query"": { Elasticsearch query is here } } } }  That's why I need to add the new properties dynamically to the `input`. Is there any workaround to support my case? PS I know that the property can be stringified. source-file source-file test-file",no-bug,0.9
1,elassandra,https://github.com/strapdata/elassandra/issues/1,elasticsearch 2.0 support,How to test elassandra with elasticsearch 2.0. Is the project need a lot of rewrite?,other-file | config-file | config-file | other-file | container-file | documentation-file | config-file | config-file | config-file | config-file | config-file,elasticsearch 2.0 support How to test elassandra with elasticsearch 2.0. Is the project need a lot of rewrite? other-file config-file config-file other-file container-file documentation-file config-file config-file config-file config-file config-file,no-bug,0.9
183,elassandra,https://github.com/strapdata/elassandra/issues/183,Elasticsearch refuses to work when listen_address differs from broadcast_address,"I'm using Elassandra 5.5.0.14 (installed via .deb), and I setup up an 3-node cluster. However, when I try to run the example:  $ curl -XPUT 'http://whirlpool-elassandra-fmt01-01-15-1.f3w.net:9200/twitter/doc/1?pretty' -H 'Content-Type: application/json' -d ' > { > ""user"": ""Poulpy"", > ""post_date"": ""2017/10/4 13:12:00"", > ""message"": ""Elassandra adds dynamic mapping to Cassandra"" > }'  The terminal is stuck, and the `system.log` emits:  2018-04-08 09:01:46,502 INFO [elasticsearch[64.71.145.11][clusterService#updateTask][T#1]] MigrationManager.java:331 announceNewKeyspace Create new Keyspace: KeyspaceMetadata{name=twitter, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.NetworkTopologyStrategy, fmt01=1}}, tables=[], views=[], functions=[], types=[]} 2018-04-08 09:01:50,264 WARN [elasticsearch[64.71.145.11][clusterService#updateTask][T#1]] IndexRoutingTable.java:380 <init> Keyspace not available: java.lang.AssertionError 2018-04-08 09:01:50,273 ERROR [elasticsearch[64.71.145.11][clusterService#updateTask][T#1]] ClusterService.java:1542 publishAndApplyChanges Cassandra issue: java.lang.NullPointerException: null at org.elassandra.discovery.CassandraDiscovery.isNormal(CassandraDiscovery.java:519) at org.elassandra.discovery.CassandraDiscovery.access$900(CassandraDiscovery.java:90) at org.elassandra.discovery.CassandraDiscovery$MetaDataVersionAckListener.lambda$new$0(CassandraDiscovery.java:479) at java.lang.Iterable.forEach(Iterable.java:75) at org.elassandra.discovery.CassandraDiscovery$MetaDataVersionAckListener.<init>(CassandraDiscovery.java:476) at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:1487) at org.elasticsearch.cluster.service.BaseClusterService.runTasks(BaseClusterService.java:583) at org.elasticsearch.cluster.service.BaseClusterService$ClusterServiceTaskBatcher.run(BaseClusterService.java:263) at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) at org.elasticsearch.cluster.service.BaseClusterService$ClusterServiceTaskBatcher$UpdateTask.run(BaseClusterService.java:266) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  Eventually, `curl` returns an error:  { ""error"" : { ""root_cause"" : [ { ""type"" : ""index_not_found_exception"", ""reason"" : ""no such index"", ""resource.type"" : ""index_expression"", ""resource.id"" : ""twitter"", ""index_uuid"" : ""_na_"", ""index"" : ""twitter"" } ], ""type"" : ""index_not_found_exception"", ""reason"" : ""no such index"", ""resource.type"" : ""index_expression"", ""resource.id"" : ""twitter"", ""index_uuid"" : ""_na_"", ""index"" : ""twitter"" }, ""status"" : 404 }  `/_cluster/state`:  { ""cluster_name"" : ""Whirlpool"", ""version"" : 10, ""state_uuid"" : ""UY-PxoWiTIGw6xrSep9jLw"", ""master_node"" : ""81923937-6b7b-4f4e-836c-728a69aa50f3"", ""blocks"" : { }, ""nodes"" : { ""a9ade22a-4ffb-47bd-9087-c8e635af995c"" : { ""name"" : ""2001:470:1:298:c:a:a:0"", ""status"" : ""ALIVE"", ""ephemeral_id"" : ""a9ade22a-4ffb-47bd-9087-c8e635af995c"", ""transport_address"" : ""64.71.145.10:9300"", ""attributes"" : { ""rack"" : ""01-15"", ""dc"" : ""fmt01"" } }, ""3be98785-40dc-44d9-b13f-06603e4f0f5d"" : { ""name"" : ""2001:470:1:298:c:a:a:1"", ""status"" : ""ALIVE"", ""ephemeral_id"" : ""3be98785-40dc-44d9-b13f-06603e4f0f5d"", ""transport_address"" : ""64.71.145.11:9300"", ""attributes"" : { ""rack"" : ""01-15"", ""dc"" : ""fmt01"" } }, ""81923937-6b7b-4f4e-836c-728a69aa50f3"" : { ""name"" : ""64.71.145.12"", ""status"" : ""ALIVE"", ""ephemeral_id"" : ""81923937-6b7b-4f4e-836c-728a69aa50f3"", ""transport_address"" : ""64.71.145.12:9300"", ""attributes"" : { ""rack"" : ""01-15"", ""dc"" : ""fmt01"" } } }, ""metadata"" : { ""version"" : 0, ""cluster_uuid"" : ""a9ade22a-4ffb-47bd-9087-c8e635af995c"", ""templates"" : { }, ""indices"" : { }, ""index-graveyard"" : { ""tombstones"" : [ ] } }, ""routing_table"" : { ""indices"" : { } }, ""routing_nodes"" : { ""unassigned"" : [ ], ""nodes"" : { ""3be98785-40dc-44d9-b13f-06603e4f0f5d"" : [ ], ""a9ade22a-4ffb-47bd-9087-c8e635af995c"" : [ ], ""81923937-6b7b-4f4e-836c-728a69aa50f3"" : [ ] } } }  `nodetool describecluster`:  # nodetool describecluster Cluster Information: Name: Whirlpool Snitch: org.apache.cassandra.locator.GossipingPropertyFileSnitch DynamicEndPointSnitch: enabled Partitioner: org.apache.cassandra.dht.Murmur3Partitioner Schema versions: 3d4b194d-69e2-3d97-b0d0-ae36e5587409: [2001:470:1:298:c:a:a:0, 2001:470:1:298:c:a:a:1, 2001:470:1:298:c:a:a:2]  Please advise.",source-file,"Elasticsearch refuses to work when listen_address differs from broadcast_address I'm using Elassandra 5.5.0.14 (installed via .deb), and I setup up an 3-node cluster. However, when I try to run the example:  $ curl -XPUT 'http://whirlpool-elassandra-fmt01-01-15-1.f3w.net:9200/twitter/doc/1?pretty' -H 'Content-Type: application/json' -d ' > { > ""user"": ""Poulpy"", > ""post_date"": ""2017/10/4 13:12:00"", > ""message"": ""Elassandra adds dynamic mapping to Cassandra"" > }'  The terminal is stuck, and the `system.log` emits:  2018-04-08 09:01:46,502 INFO [elasticsearch[64.71.145.11][clusterService#updateTask][T#1]] MigrationManager.java:331 announceNewKeyspace Create new Keyspace: KeyspaceMetadata{name=twitter, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.NetworkTopologyStrategy, fmt01=1}}, tables=[], views=[], functions=[], types=[]} 2018-04-08 09:01:50,264 WARN [elasticsearch[64.71.145.11][clusterService#updateTask][T#1]] IndexRoutingTable.java:380 <init> Keyspace not available: java.lang.AssertionError 2018-04-08 09:01:50,273 ERROR [elasticsearch[64.71.145.11][clusterService#updateTask][T#1]] ClusterService.java:1542 publishAndApplyChanges Cassandra issue: java.lang.NullPointerException: null at org.elassandra.discovery.CassandraDiscovery.isNormal(CassandraDiscovery.java:519) at org.elassandra.discovery.CassandraDiscovery.access$900(CassandraDiscovery.java:90) at org.elassandra.discovery.CassandraDiscovery$MetaDataVersionAckListener.lambda$new$0(CassandraDiscovery.java:479) at java.lang.Iterable.forEach(Iterable.java:75) at org.elassandra.discovery.CassandraDiscovery$MetaDataVersionAckListener.<init>(CassandraDiscovery.java:476) at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:1487) at org.elasticsearch.cluster.service.BaseClusterService.runTasks(BaseClusterService.java:583) at org.elasticsearch.cluster.service.BaseClusterService$ClusterServiceTaskBatcher.run(BaseClusterService.java:263) at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) at org.elasticsearch.cluster.service.BaseClusterService$ClusterServiceTaskBatcher$UpdateTask.run(BaseClusterService.java:266) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  Eventually, `curl` returns an error:  { ""error"" : { ""root_cause"" : [ { ""type"" : ""index_not_found_exception"", ""reason"" : ""no such index"", ""resource.type"" : ""index_expression"", ""resource.id"" : ""twitter"", ""index_uuid"" : ""_na_"", ""index"" : ""twitter"" } ], ""type"" : ""index_not_found_exception"", ""reason"" : ""no such index"", ""resource.type"" : ""index_expression"", ""resource.id"" : ""twitter"", ""index_uuid"" : ""_na_"", ""index"" : ""twitter"" }, ""status"" : 404 }  `/_cluster/state`:  { ""cluster_name"" : ""Whirlpool"", ""version"" : 10, ""state_uuid"" : ""UY-PxoWiTIGw6xrSep9jLw"", ""master_node"" : ""81923937-6b7b-4f4e-836c-728a69aa50f3"", ""blocks"" : { }, ""nodes"" : { ""a9ade22a-4ffb-47bd-9087-c8e635af995c"" : { ""name"" : ""2001:470:1:298:c:a:a:0"", ""status"" : ""ALIVE"", ""ephemeral_id"" : ""a9ade22a-4ffb-47bd-9087-c8e635af995c"", ""transport_address"" : ""64.71.145.10:9300"", ""attributes"" : { ""rack"" : ""01-15"", ""dc"" : ""fmt01"" } }, ""3be98785-40dc-44d9-b13f-06603e4f0f5d"" : { ""name"" : ""2001:470:1:298:c:a:a:1"", ""status"" : ""ALIVE"", ""ephemeral_id"" : ""3be98785-40dc-44d9-b13f-06603e4f0f5d"", ""transport_address"" : ""64.71.145.11:9300"", ""attributes"" : { ""rack"" : ""01-15"", ""dc"" : ""fmt01"" } }, ""81923937-6b7b-4f4e-836c-728a69aa50f3"" : { ""name"" : ""64.71.145.12"", ""status"" : ""ALIVE"", ""ephemeral_id"" : ""81923937-6b7b-4f4e-836c-728a69aa50f3"", ""transport_address"" : ""64.71.145.12:9300"", ""attributes"" : { ""rack"" : ""01-15"", ""dc"" : ""fmt01"" } } }, ""metadata"" : { ""version"" : 0, ""cluster_uuid"" : ""a9ade22a-4ffb-47bd-9087-c8e635af995c"", ""templates"" : { }, ""indices"" : { }, ""index-graveyard"" : { ""tombstones"" : [ ] } }, ""routing_table"" : { ""indices"" : { } }, ""routing_nodes"" : { ""unassigned"" : [ ], ""nodes"" : { ""3be98785-40dc-44d9-b13f-06603e4f0f5d"" : [ ], ""a9ade22a-4ffb-47bd-9087-c8e635af995c"" : [ ], ""81923937-6b7b-4f4e-836c-728a69aa50f3"" : [ ] } } }  `nodetool describecluster`:  # nodetool describecluster Cluster Information: Name: Whirlpool Snitch: org.apache.cassandra.locator.GossipingPropertyFileSnitch DynamicEndPointSnitch: enabled Partitioner: org.apache.cassandra.dht.Murmur3Partitioner Schema versions: 3d4b194d-69e2-3d97-b0d0-ae36e5587409: [2001:470:1:298:c:a:a:0, 2001:470:1:298:c:a:a:1, 2001:470:1:298:c:a:a:2]  Please advise. source-file",no-bug,0.9
306,elassandra,https://github.com/strapdata/elassandra/issues/306,Can't change search strategy for existing index,"Hi ! Elassandra version: 6.2.3.17 OS version: Ubuntu 18.04.2 LTS  $ java -version openjdk version ""1.8.0_222"" OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)  I'm trying to change search strategy for existing index in the following way:  curl -XPUT -H ""Content-Type: application/json"" ""http://hostname:9200/index_name/_settings"" -d '{ ""settings"" : { ""index.search_strategy_class"":""RandomSearchStrategy"" } }'  And getting the following error:  { ""error"": { ""root_cause"": [ { ""type"": ""illegal_state_exception"", ""reason"": ""rejecting cluster state version [205] uuid [lDkCWhnVRMWTts3x7uMrmA] received from [f9ed38c8-b7e0-4944-a0fe-4af6b5c6eb84]"" } ], ""type"": ""illegal_state_exception"", ""reason"": ""rejecting cluster state version [205] uuid [lDkCWhnVRMWTts3x7uMrmA] received from [f9ed38c8-b7e0-4944-a0fe-4af6b5c6eb84]"" }, ""status"": 500 }  In logs I see the following  2019-09-16 17:42:14,482 WARN [elasticsearch[hostname][masterService#updateTask][T#1]] CassandraDiscovery.java:1100 onNewClusterStateFailed failed while applying cluster state locally source=update-settings java.lang.IllegalStateException: rejecting cluster state version [205] uuid [lDkCWhnVRMWTts3x7uMrmA] received from [f9ed38c8-b7e0-4944-a0fe-4af6b5c6eb84] at org.elassandra.discovery.CassandraDiscovery.processNextCommittedClusterState(CassandraDiscovery.java:1196) at org.elassandra.discovery.CassandraDiscovery.publishLocalUpdate(CassandraDiscovery.java:1110) at org.elassandra.discovery.CassandraDiscovery.publish(CassandraDiscovery.java:883) at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:251) at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:152) at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:573) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:244) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:207) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  I successfully changed search strategy with the same request on Elassandra 5.5.0.24. According to the documentation https://elassandra.readthedocs.io/en/latest/operations.html?highlight=randomsearchstrategy#optimizing-search-requests it should work. Could you please help me with changing of the search strategy ?",source-file,"Can't change search strategy for existing index Hi ! Elassandra version: 6.2.3.17 OS version: Ubuntu 18.04.2 LTS  $ java -version openjdk version ""1.8.0_222"" OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)  I'm trying to change search strategy for existing index in the following way:  curl -XPUT -H ""Content-Type: application/json"" ""http://hostname:9200/index_name/_settings"" -d '{ ""settings"" : { ""index.search_strategy_class"":""RandomSearchStrategy"" } }'  And getting the following error:  { ""error"": { ""root_cause"": [ { ""type"": ""illegal_state_exception"", ""reason"": ""rejecting cluster state version [205] uuid [lDkCWhnVRMWTts3x7uMrmA] received from [f9ed38c8-b7e0-4944-a0fe-4af6b5c6eb84]"" } ], ""type"": ""illegal_state_exception"", ""reason"": ""rejecting cluster state version [205] uuid [lDkCWhnVRMWTts3x7uMrmA] received from [f9ed38c8-b7e0-4944-a0fe-4af6b5c6eb84]"" }, ""status"": 500 }  In logs I see the following  2019-09-16 17:42:14,482 WARN [elasticsearch[hostname][masterService#updateTask][T#1]] CassandraDiscovery.java:1100 onNewClusterStateFailed failed while applying cluster state locally source=update-settings java.lang.IllegalStateException: rejecting cluster state version [205] uuid [lDkCWhnVRMWTts3x7uMrmA] received from [f9ed38c8-b7e0-4944-a0fe-4af6b5c6eb84] at org.elassandra.discovery.CassandraDiscovery.processNextCommittedClusterState(CassandraDiscovery.java:1196) at org.elassandra.discovery.CassandraDiscovery.publishLocalUpdate(CassandraDiscovery.java:1110) at org.elassandra.discovery.CassandraDiscovery.publish(CassandraDiscovery.java:883) at org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:251) at org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:152) at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:573) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:244) at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:207) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  I successfully changed search strategy with the same request on Elassandra 5.5.0.24. According to the documentation https://elassandra.readthedocs.io/en/latest/operations.html?highlight=randomsearchstrategy#optimizing-search-requests it should work. Could you please help me with changing of the search strategy ? source-file",no-bug,0.8
302,elassandra,https://github.com/strapdata/elassandra/issues/302,Remove cassandra column with zero down time,"I need to remove an existing column in zero downtime. I think there is no possibility to remove column in zero downtime. We can remove mapping from elasticsearch but we can not use ""ALTER TABLE **table_name** DROP **column**"" because that column has dependent on secondary index. Is there any way to do it?",source-file | test-file,"Remove cassandra column with zero down time I need to remove an existing column in zero downtime. I think there is no possibility to remove column in zero downtime. We can remove mapping from elasticsearch but we can not use ""ALTER TABLE **table_name** DROP **column**"" because that column has dependent on secondary index. Is there any way to do it? source-file test-file",no-bug,0.9
335,elassandra,https://github.com/strapdata/elassandra/issues/335,performance and consistency issues,"**Elassandra version**: 6.2.3.17-1 **OS version** (`uname -a` if on a Unix-like system): Ubuntu **Description of the problem including expected versus actual behavior**: Hello, I have a 5 node elassandra cluster (6.2.3.17-1) with replication factor 3. I changed the to RandomSearchStrategy and now when I'm doing a request like:  { ""from"": 0, ""size"": 20, ""_source"": [ ""account_uuid"", ""uuid"", ""initiation_time"" ], ""query"": { ""bool"": { ""filter"": [] } }, ""sort"": { ""initiation_time"": ""desc"" } }  On some queries I get:  ""took"": 13, ""timed_out"": false, ""_shards"": { ""total"": 3, ""successful"": 3, ""skipped"": 0, ""failed"": 0 } ""hits"": { ""total"": 141271411,  Some other I get:  ""took"": 13, ""timed_out"": false, ""_shards"": { ""total"": 2, ""successful"": 2, ""skipped"": 0, ""failed"": 0 }, ""hits"": { ""total"": 95191276,   - First problem is that some requests shows 3 shards involved and other 2 (randomly). When I get 3 I see duplicate record as well (same id) - Second is that even when shards.total = 2 the hits.total is different from request to request Problems occurs no matter what node I pick to send the request. Also we run repair on the entire cluster, re-indexed but no change. Moving back to `PrimaryFirstSearchStrategy` I get all the time consistent hits.total = 80013500 which is my real number of documents. But response time grows from 15ms to 1500 ms. Any idea what can be wrong? Silviu",source-file | source-file | source-file | source-file,"performance and consistency issues **Elassandra version**: 6.2.3.17-1 **OS version** (`uname -a` if on a Unix-like system): Ubuntu **Description of the problem including expected versus actual behavior**: Hello, I have a 5 node elassandra cluster (6.2.3.17-1) with replication factor 3. I changed the to RandomSearchStrategy and now when I'm doing a request like:  { ""from"": 0, ""size"": 20, ""_source"": [ ""account_uuid"", ""uuid"", ""initiation_time"" ], ""query"": { ""bool"": { ""filter"": [] } }, ""sort"": { ""initiation_time"": ""desc"" } }  On some queries I get:  ""took"": 13, ""timed_out"": false, ""_shards"": { ""total"": 3, ""successful"": 3, ""skipped"": 0, ""failed"": 0 } ""hits"": { ""total"": 141271411,  Some other I get:  ""took"": 13, ""timed_out"": false, ""_shards"": { ""total"": 2, ""successful"": 2, ""skipped"": 0, ""failed"": 0 }, ""hits"": { ""total"": 95191276,   - First problem is that some requests shows 3 shards involved and other 2 (randomly). When I get 3 I see duplicate record as well (same id) - Second is that even when shards.total = 2 the hits.total is different from request to request Problems occurs no matter what node I pick to send the request. Also we run repair on the entire cluster, re-indexed but no change. Moving back to `PrimaryFirstSearchStrategy` I get all the time consistent hits.total = 80013500 which is my real number of documents. But response time grows from 15ms to 1500 ms. Any idea what can be wrong? Silviu source-file source-file source-file source-file",no-bug,0.9
3,elassandra,https://github.com/strapdata/elassandra/issues/3,Starting Elassandra [ecstart],"Hello, I always get this error if I start Elassandra: What could be the problem? CASSANDRA_HOME is set correct.  Starting with JVM debug address=4242 suspend=n Starting with Elasticsearch enabled. CLASSPATH=/root/elassandra-2.1.1-2//conf:/root/elassandra-2.1.1-2//bin/../lib/HdrHistogram-2.1.6.jar:/root/elassandra-2.1.1-2//bin/../lib/ST4-4.0.8.jar:/root/elassandra-2.1.1-2//bin/../lib/airline-0.6.jar:/root/elassandra-2.1.1-2//bin/../lib/ant-1.8.2.jar:/root/elassandra-2.1.1-2//bin/../lib/antlr-3.5.2.jar:/root/elassandra-2.1.1-2//bin/../lib/antlr-runtime-3.5.jar:/root/elassandra-2.1.1-2//bin/../lib/apache-log4j-extras-1.2.17.jar:/root/elassandra-2.1.1-2//bin/../lib/asm-4.1.jar:/root/elassandra-2.1.1-2//bin/../lib/asm-commons-4.1.jar:/root/elassandra-2.1.1-2//bin/../lib/cassandra-thrift-2.2.4.jar:/root/elassandra-2.1.1-2//bin/../lib/commons-cli-1.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/commons-codec-1.6.jar:/root/elassandra-2.1.1-2//bin/../lib/commons-lang3-3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/commons-math3-3.2.jar:/root/elassandra-2.1.1-2//bin/../lib/compiler-0.8.13.jar:/root/elassandra-2.1.1-2//bin/../lib/compress-lzf-1.0.2.jar:/root/elassandra-2.1.1-2//bin/../lib/concurrentlinkedhashmap-lru-1.4.jar:/root/elassandra-2.1.1-2//bin/../lib/crc32ex-0.1.1.jar:/root/elassandra-2.1.1-2//bin/../lib/disruptor-3.0.1.jar:/root/elassandra-2.1.1-2//bin/../lib/elassandra-2.1.1-2.jar:/root/elassandra-2.1.1-2//bin/../lib/fastutil-6.5.7.jar:/root/elassandra-2.1.1-2//bin/../lib/groovy-all-2.4.4-indy.jar:/root/elassandra-2.1.1-2//bin/../lib/guava-18.0.jar:/root/elassandra-2.1.1-2//bin/../lib/hibernate-validator-4.3.0.Final.jar:/root/elassandra-2.1.1-2//bin/../lib/high-scale-lib-1.0.6.jar:/root/elassandra-2.1.1-2//bin/../lib/hppc-0.7.1.jar:/root/elassandra-2.1.1-2//bin/../lib/httpcore-4.2.4.jar:/root/elassandra-2.1.1-2//bin/../lib/icu4j-54.1.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-core-2.6.2.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-core-asl-1.9.13.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-dataformat-cbor-2.6.2.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-dataformat-smile-2.6.2.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-dataformat-yaml-2.6.2.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-mapper-asl-1.9.13.jar:/root/elassandra-2.1.1-2//bin/../lib/jamm-0.3.0.jar:/root/elassandra-2.1.1-2//bin/../lib/javassist-3.20.0-GA.jar:/root/elassandra-2.1.1-2//bin/../lib/javax.inject-1.jar:/root/elassandra-2.1.1-2//bin/../lib/jbcrypt-0.3m.jar:/root/elassandra-2.1.1-2//bin/../lib/jboss-logging-3.1.0.CR2.jar:/root/elassandra-2.1.1-2//bin/../lib/jcl-over-slf4j-1.7.7.jar:/root/elassandra-2.1.1-2//bin/../lib/jna-4.1.0.jar:/root/elassandra-2.1.1-2//bin/../lib/joda-convert-1.2.jar:/root/elassandra-2.1.1-2//bin/../lib/joda-time-2.8.2.jar:/root/elassandra-2.1.1-2//bin/../lib/json-simple-1.1.jar:/root/elassandra-2.1.1-2//bin/../lib/jsr166e-1.1.0.jar:/root/elassandra-2.1.1-2//bin/../lib/jts-1.13.jar:/root/elassandra-2.1.1-2//bin/../lib/junit-4.10.jar:/root/elassandra-2.1.1-2//bin/../lib/libthrift-0.9.2.jar:/root/elassandra-2.1.1-2//bin/../lib/log4j-1.2.17.jar:/root/elassandra-2.1.1-2//bin/../lib/log4j-over-slf4j-1.7.7.jar:/root/elassandra-2.1.1-2//bin/../lib/logback-classic-1.1.3.jar:/root/elassandra-2.1.1-2//bin/../lib/logback-core-1.1.3.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-common-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-icu-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-kuromoji-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-phonetic-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-smartcn-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-stempel-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-backward-codecs-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-codecs-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-core-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-expressions-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-grouping-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-highlighter-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-join-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-memory-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-misc-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-queries-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-queryparser-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-sandbox-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-spatial-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-spatial3d-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-suggest-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-test-framework-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lz4-1.3.0.jar:/root/elassandra-2.1.1-2//bin/../lib/metrics-core-3.1.0.jar:/root/elassandra-2.1.1-2//bin/../lib/netty-3.10.5.Final.jar:/root/elassandra-2.1.1-2//bin/../lib/netty-all-4.0.23.Final.jar:/root/elassandra-2.1.1-2//bin/../lib/reporter-config-base-3.0.0.jar:/root/elassandra-2.1.1-2//bin/../lib/reporter-config3-3.0.0.jar:/root/elassandra-2.1.1-2//bin/../lib/sigar-1.6.4.jar:/root/elassandra-2.1.1-2//bin/../lib/slf4j-api-1.7.7.jar:/root/elassandra-2.1.1-2//bin/../lib/snakeyaml-1.15.jar:/root/elassandra-2.1.1-2//bin/../lib/snappy-java-1.1.1.7.jar:/root/elassandra-2.1.1-2//bin/../lib/spatial4j-0.5.jar:/root/elassandra-2.1.1-2//bin/../lib/stream-2.5.2.jar:/root/elassandra-2.1.1-2//bin/../lib/super-csv-2.1.0.jar:/root/elassandra-2.1.1-2//bin/../lib/t-digest-3.0.jar:/root/elassandra-2.1.1-2//bin/../lib/thrift-server-0.3.7.jar:/root/elassandra-2.1.1-2//bin/../lib/validation-api-1.0.0.GA.jar root@v22016022703732037:~/elassandra-2.1.1-2/bin# CompilerOracle: inline org/apache/cassandra/db/AbstractNativeCell.compareTo (Lorg/apache/cassandra/db/composites/Composite;)I CompilerOracle: inline org/apache/cassandra/db/composites/AbstractSimpleCellNameType.compareUnsigned (Lorg/apache/cassandra/db/composites/Composite;Lorg/apache/cassandra/db/composites/Composite;)I CompilerOracle: inline org/apache/cassandra/io/util/Memory.checkBounds (JJ)V CompilerOracle: inline org/apache/cassandra/io/util/SafeMemory.checkBounds (JJ)V CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compare (Ljava/nio/ByteBuffer;[B)I CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compare ([BLjava/nio/ByteBuffer;)I CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compareUnsigned (Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)I CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/lang/Object;JILjava/lang/Object;JI)I CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/lang/Object;JILjava/nio/ByteBuffer;)I CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)I Listening for transport dt_socket at address: 4242 {2.1.2-SNAPSHOT}: Setup Failed  - NullPointerException[null value in entry: path.home=null] java.lang.NullPointerException: null value in entry: path.home=null at com.google.common.collect.CollectPreconditions.checkEntryNotNull(CollectPreconditions.java:33) at com.google.common.collect.ImmutableMap.entryOf(ImmutableMap.java:135) at com.google.common.collect.ImmutableSortedMap.fromEntries(ImmutableSortedMap.java:282) at com.google.common.collect.ImmutableSortedMap.copyOfInternal(ImmutableSortedMap.java:275) at com.google.common.collect.ImmutableSortedMap.copyOf(ImmutableSortedMap.java:206) at org.elasticsearch.common.settings.Settings.<init>(Settings.java:83) at org.elasticsearch.common.settings.Settings$Builder.build(Settings.java:1214) at org.apache.cassandra.service.ElassandraDaemon.main(ElassandraDaemon.java:250) ",source-file | config-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file,"Starting Elassandra [ecstart] Hello, I always get this error if I start Elassandra: What could be the problem? CASSANDRA_HOME is set correct.  Starting with JVM debug address=4242 suspend=n Starting with Elasticsearch enabled. CLASSPATH=/root/elassandra-2.1.1-2//conf:/root/elassandra-2.1.1-2//bin/../lib/HdrHistogram-2.1.6.jar:/root/elassandra-2.1.1-2//bin/../lib/ST4-4.0.8.jar:/root/elassandra-2.1.1-2//bin/../lib/airline-0.6.jar:/root/elassandra-2.1.1-2//bin/../lib/ant-1.8.2.jar:/root/elassandra-2.1.1-2//bin/../lib/antlr-3.5.2.jar:/root/elassandra-2.1.1-2//bin/../lib/antlr-runtime-3.5.jar:/root/elassandra-2.1.1-2//bin/../lib/apache-log4j-extras-1.2.17.jar:/root/elassandra-2.1.1-2//bin/../lib/asm-4.1.jar:/root/elassandra-2.1.1-2//bin/../lib/asm-commons-4.1.jar:/root/elassandra-2.1.1-2//bin/../lib/cassandra-thrift-2.2.4.jar:/root/elassandra-2.1.1-2//bin/../lib/commons-cli-1.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/commons-codec-1.6.jar:/root/elassandra-2.1.1-2//bin/../lib/commons-lang3-3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/commons-math3-3.2.jar:/root/elassandra-2.1.1-2//bin/../lib/compiler-0.8.13.jar:/root/elassandra-2.1.1-2//bin/../lib/compress-lzf-1.0.2.jar:/root/elassandra-2.1.1-2//bin/../lib/concurrentlinkedhashmap-lru-1.4.jar:/root/elassandra-2.1.1-2//bin/../lib/crc32ex-0.1.1.jar:/root/elassandra-2.1.1-2//bin/../lib/disruptor-3.0.1.jar:/root/elassandra-2.1.1-2//bin/../lib/elassandra-2.1.1-2.jar:/root/elassandra-2.1.1-2//bin/../lib/fastutil-6.5.7.jar:/root/elassandra-2.1.1-2//bin/../lib/groovy-all-2.4.4-indy.jar:/root/elassandra-2.1.1-2//bin/../lib/guava-18.0.jar:/root/elassandra-2.1.1-2//bin/../lib/hibernate-validator-4.3.0.Final.jar:/root/elassandra-2.1.1-2//bin/../lib/high-scale-lib-1.0.6.jar:/root/elassandra-2.1.1-2//bin/../lib/hppc-0.7.1.jar:/root/elassandra-2.1.1-2//bin/../lib/httpcore-4.2.4.jar:/root/elassandra-2.1.1-2//bin/../lib/icu4j-54.1.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-core-2.6.2.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-core-asl-1.9.13.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-dataformat-cbor-2.6.2.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-dataformat-smile-2.6.2.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-dataformat-yaml-2.6.2.jar:/root/elassandra-2.1.1-2//bin/../lib/jackson-mapper-asl-1.9.13.jar:/root/elassandra-2.1.1-2//bin/../lib/jamm-0.3.0.jar:/root/elassandra-2.1.1-2//bin/../lib/javassist-3.20.0-GA.jar:/root/elassandra-2.1.1-2//bin/../lib/javax.inject-1.jar:/root/elassandra-2.1.1-2//bin/../lib/jbcrypt-0.3m.jar:/root/elassandra-2.1.1-2//bin/../lib/jboss-logging-3.1.0.CR2.jar:/root/elassandra-2.1.1-2//bin/../lib/jcl-over-slf4j-1.7.7.jar:/root/elassandra-2.1.1-2//bin/../lib/jna-4.1.0.jar:/root/elassandra-2.1.1-2//bin/../lib/joda-convert-1.2.jar:/root/elassandra-2.1.1-2//bin/../lib/joda-time-2.8.2.jar:/root/elassandra-2.1.1-2//bin/../lib/json-simple-1.1.jar:/root/elassandra-2.1.1-2//bin/../lib/jsr166e-1.1.0.jar:/root/elassandra-2.1.1-2//bin/../lib/jts-1.13.jar:/root/elassandra-2.1.1-2//bin/../lib/junit-4.10.jar:/root/elassandra-2.1.1-2//bin/../lib/libthrift-0.9.2.jar:/root/elassandra-2.1.1-2//bin/../lib/log4j-1.2.17.jar:/root/elassandra-2.1.1-2//bin/../lib/log4j-over-slf4j-1.7.7.jar:/root/elassandra-2.1.1-2//bin/../lib/logback-classic-1.1.3.jar:/root/elassandra-2.1.1-2//bin/../lib/logback-core-1.1.3.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-common-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-icu-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-kuromoji-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-phonetic-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-smartcn-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-analyzers-stempel-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-backward-codecs-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-codecs-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-core-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-expressions-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-grouping-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-highlighter-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-join-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-memory-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-misc-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-queries-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-queryparser-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-sandbox-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-spatial-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-spatial3d-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-suggest-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lucene-test-framework-5.3.1.jar:/root/elassandra-2.1.1-2//bin/../lib/lz4-1.3.0.jar:/root/elassandra-2.1.1-2//bin/../lib/metrics-core-3.1.0.jar:/root/elassandra-2.1.1-2//bin/../lib/netty-3.10.5.Final.jar:/root/elassandra-2.1.1-2//bin/../lib/netty-all-4.0.23.Final.jar:/root/elassandra-2.1.1-2//bin/../lib/reporter-config-base-3.0.0.jar:/root/elassandra-2.1.1-2//bin/../lib/reporter-config3-3.0.0.jar:/root/elassandra-2.1.1-2//bin/../lib/sigar-1.6.4.jar:/root/elassandra-2.1.1-2//bin/../lib/slf4j-api-1.7.7.jar:/root/elassandra-2.1.1-2//bin/../lib/snakeyaml-1.15.jar:/root/elassandra-2.1.1-2//bin/../lib/snappy-java-1.1.1.7.jar:/root/elassandra-2.1.1-2//bin/../lib/spatial4j-0.5.jar:/root/elassandra-2.1.1-2//bin/../lib/stream-2.5.2.jar:/root/elassandra-2.1.1-2//bin/../lib/super-csv-2.1.0.jar:/root/elassandra-2.1.1-2//bin/../lib/t-digest-3.0.jar:/root/elassandra-2.1.1-2//bin/../lib/thrift-server-0.3.7.jar:/root/elassandra-2.1.1-2//bin/../lib/validation-api-1.0.0.GA.jar root@v22016022703732037:~/elassandra-2.1.1-2/bin# CompilerOracle: inline org/apache/cassandra/db/AbstractNativeCell.compareTo (Lorg/apache/cassandra/db/composites/Composite;)I CompilerOracle: inline org/apache/cassandra/db/composites/AbstractSimpleCellNameType.compareUnsigned (Lorg/apache/cassandra/db/composites/Composite;Lorg/apache/cassandra/db/composites/Composite;)I CompilerOracle: inline org/apache/cassandra/io/util/Memory.checkBounds (JJ)V CompilerOracle: inline org/apache/cassandra/io/util/SafeMemory.checkBounds (JJ)V CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compare (Ljava/nio/ByteBuffer;[B)I CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compare ([BLjava/nio/ByteBuffer;)I CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compareUnsigned (Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)I CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/lang/Object;JILjava/lang/Object;JI)I CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/lang/Object;JILjava/nio/ByteBuffer;)I CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)I Listening for transport dt_socket at address: 4242 {2.1.2-SNAPSHOT}: Setup Failed  - NullPointerException[null value in entry: path.home=null] java.lang.NullPointerException: null value in entry: path.home=null at com.google.common.collect.CollectPreconditions.checkEntryNotNull(CollectPreconditions.java:33) at com.google.common.collect.ImmutableMap.entryOf(ImmutableMap.java:135) at com.google.common.collect.ImmutableSortedMap.fromEntries(ImmutableSortedMap.java:282) at com.google.common.collect.ImmutableSortedMap.copyOfInternal(ImmutableSortedMap.java:275) at com.google.common.collect.ImmutableSortedMap.copyOf(ImmutableSortedMap.java:206) at org.elasticsearch.common.settings.Settings.<init>(Settings.java:83) at org.elasticsearch.common.settings.Settings$Builder.build(Settings.java:1214) at org.apache.cassandra.service.ElassandraDaemon.main(ElassandraDaemon.java:250)  source-file config-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file",no-bug,0.95
323,elassandra,https://github.com/strapdata/elassandra/issues/323,Elassandra mappings with type coercing aren't behaving the same as elasticsearch,"<!-- Bug report --> **Elassandra version**: 6.8.4.0 **JVM version** (`java -version`): docker image **OS version** (`uname -a` if on a Unix-like system): host system is OSx but I also tested it in GKE. **Description of the problem including expected versus actual behavior**: When using a mapping template, that enables type coercing, Elassandra doesn't behave the same as ElasticSearch. Instead it returns a 500 and an exception. **Steps to reproduce**: In both of these examples we'll be inserting a document that has an integer mapping. And in both cases the int field's value will be submitted as a string value.  Testing Elasticsearch 6.8  docker pull docker.elastic.co/elasticsearch/elasticsearch:6.8.6 docker run -p 9200:9200 -p 9300:9300 -e ""discovery.type=single-node"" docker.elastic.co/elasticsearch/elasticsearch:6.8.6 export HOST=localhost export INDEX=ents_type_site1 echo '{ ""index_patterns"": ""ents_*"", ""mappings"": { ""_doc"": { ""properties"": { ""_created"": { ""type"": ""date"" } }, ""dynamic_templates"": [ { ""integer_fields"": { ""match"": ""int_*"", ""mapping"": { ""coerce"": true, ""type"": ""long"" } } } ] } } }' | http PUT http://$HOST:9200/_template/ent_table_template { ""acknowledged"": true } echo '{""int__eventcnt"":""1""}' | http POST http://$HOST:9200/$INDEX/_doc/a1bc=:1cd== { ""_id"": ""a1bc=:1cd=="", ""_index"": ""ents_type_site1"", ""_primary_term"": 1, ""_seq_no"": 0, ""_shards"": { ""failed"": 0, ""successful"": 1, ""total"": 2 }, ""_type"": ""_doc"", ""_version"": 1, ""result"": ""created"" }  * Note that elasticsearch handled the casting of the string to an int.  Testing elassandra 6.8  docker run -p 9200:9200 -p 9300:9300 --name node0 -d strapdata/elassandra:6.8.4.0 export INDEX=ents_type_site1 echo '{ ""index_patterns"": ""ents_*"", ""mappings"": { ""_doc"": { ""properties"": { ""_created"": { ""type"": ""date"" } }, ""dynamic_templates"": [ { ""integer_fields"": { ""match"": ""int_*"", ""mapping"": { ""coerce"": true, ""type"": ""long"" } } } ] } } }' | http PUT http://$HOST:9200/_template/ent_table_template { ""acknowledged"": true } echo '{""int__eventcnt"":""1""}' | http POST http://$HOST:9200/$INDEX/_doc/a1bc=:1cd== { ""error"": { ""reason"": ""java.lang.String cannot be cast to java.lang.Number"", ""root_cause"": [ { ""reason"": ""[172.17.0.2][172.17.0.2:9300][indices:data/write/bulk[s][p]]"", ""type"": ""remote_transport_exception"" } ], ""type"": ""class_cast_exception"" }, ""status"": 500 }  **Please provide the following information**: * elassandra logs (logs/system.logs or /var/lib/cassandra/system.log)  2020-01-10 06:01:40,015 WARN [elasticsearch[172.17.0.2][http_server_worker][T#2]] org.elasticsearch.common.logging.DeprecationLogger.deprecated(DeprecationLogger.java:242) [types removal] The parameter include_type_name should be explicitly specified in put template requests to prepare for 7.0. In 7.0 include_type_name will default to 'false', and requests are expected to omit the type name in mapping definitions. 2020-01-10 06:01:42,691 INFO [elasticsearch[172.17.0.2][generic][T#3]] org.elassandra.shard.CassandraShardStateListener.afterIndexShardStarted(CassandraShardStateListener.java:69) shard [ents_type_site1][0] started 2020-01-10 06:01:42,994 ERROR [elasticsearch[172.17.0.2][write][T#1]] org.elassandra.cluster.QueryManager.upsertDocument(QueryManager.java:842) [java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number].[ents_type_site1] failed to parse field _doc=int__eventcnt 2020-01-10 06:01:43,011 WARN [elasticsearch[172.17.0.2][write][T#1]] org.elasticsearch.rest.BytesRestResponse.build(BytesRestResponse.java:133) path: /ents_type_site1/_doc/a1bc=:1cd==, params: {index=ents_type_site1, id=a1bc=:1cd==, type=_doc} org.elasticsearch.transport.RemoteTransportException: [172.17.0.2][172.17.0.2:9300][indices:data/write/bulk[s][p]] Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$7.cqlValue(NumberFieldMapper.java:870) at org.elasticsearch.index.mapper.NumberFieldMapper$NumberFieldType.cqlValue(NumberFieldMapper.java:1057) at org.elasticsearch.index.mapper.MappedFieldType.cqlValue(MappedFieldType.java:423) at org.elassandra.cluster.Serializer.serialize(Serializer.java:230) at org.elassandra.cluster.Serializer.serialize(Serializer.java:223) at org.elassandra.cluster.QueryManager.upsertDocument(QueryManager.java:840) at org.elassandra.cluster.QueryManager.insertDocument(QueryManager.java:694) at org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:468) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:495) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:464) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:226) at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:169) at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:160) at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:146) at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:83) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1088) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1066) at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:105) at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.runWithPrimaryShardReference(TransportReplicationAction.java:445) at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:387) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:327) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:314) at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:66) at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:696) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  * elasticsearch cluster state (curl http://localhost:9200/_cluster/state) * cassandra schema (cqlsh>DESC KEYSPACE <your_keyspace>) * cassandra gossip state (run: nodetool gossipinfo)",source-file | source-file | test-file | source-file | source-file | test-file,"Elassandra mappings with type coercing aren't behaving the same as elasticsearch <!-- Bug report --> **Elassandra version**: 6.8.4.0 **JVM version** (`java -version`): docker image **OS version** (`uname -a` if on a Unix-like system): host system is OSx but I also tested it in GKE. **Description of the problem including expected versus actual behavior**: When using a mapping template, that enables type coercing, Elassandra doesn't behave the same as ElasticSearch. Instead it returns a 500 and an exception. **Steps to reproduce**: In both of these examples we'll be inserting a document that has an integer mapping. And in both cases the int field's value will be submitted as a string value.  Testing Elasticsearch 6.8  docker pull docker.elastic.co/elasticsearch/elasticsearch:6.8.6 docker run -p 9200:9200 -p 9300:9300 -e ""discovery.type=single-node"" docker.elastic.co/elasticsearch/elasticsearch:6.8.6 export HOST=localhost export INDEX=ents_type_site1 echo '{ ""index_patterns"": ""ents_*"", ""mappings"": { ""_doc"": { ""properties"": { ""_created"": { ""type"": ""date"" } }, ""dynamic_templates"": [ { ""integer_fields"": { ""match"": ""int_*"", ""mapping"": { ""coerce"": true, ""type"": ""long"" } } } ] } } }' | http PUT http://$HOST:9200/_template/ent_table_template { ""acknowledged"": true } echo '{""int__eventcnt"":""1""}' | http POST http://$HOST:9200/$INDEX/_doc/a1bc=:1cd== { ""_id"": ""a1bc=:1cd=="", ""_index"": ""ents_type_site1"", ""_primary_term"": 1, ""_seq_no"": 0, ""_shards"": { ""failed"": 0, ""successful"": 1, ""total"": 2 }, ""_type"": ""_doc"", ""_version"": 1, ""result"": ""created"" }  * Note that elasticsearch handled the casting of the string to an int.  Testing elassandra 6.8  docker run -p 9200:9200 -p 9300:9300 --name node0 -d strapdata/elassandra:6.8.4.0 export INDEX=ents_type_site1 echo '{ ""index_patterns"": ""ents_*"", ""mappings"": { ""_doc"": { ""properties"": { ""_created"": { ""type"": ""date"" } }, ""dynamic_templates"": [ { ""integer_fields"": { ""match"": ""int_*"", ""mapping"": { ""coerce"": true, ""type"": ""long"" } } } ] } } }' | http PUT http://$HOST:9200/_template/ent_table_template { ""acknowledged"": true } echo '{""int__eventcnt"":""1""}' | http POST http://$HOST:9200/$INDEX/_doc/a1bc=:1cd== { ""error"": { ""reason"": ""java.lang.String cannot be cast to java.lang.Number"", ""root_cause"": [ { ""reason"": ""[172.17.0.2][172.17.0.2:9300][indices:data/write/bulk[s][p]]"", ""type"": ""remote_transport_exception"" } ], ""type"": ""class_cast_exception"" }, ""status"": 500 }  **Please provide the following information**: * elassandra logs (logs/system.logs or /var/lib/cassandra/system.log)  2020-01-10 06:01:40,015 WARN [elasticsearch[172.17.0.2][http_server_worker][T#2]] org.elasticsearch.common.logging.DeprecationLogger.deprecated(DeprecationLogger.java:242) [types removal] The parameter include_type_name should be explicitly specified in put template requests to prepare for 7.0. In 7.0 include_type_name will default to 'false', and requests are expected to omit the type name in mapping definitions. 2020-01-10 06:01:42,691 INFO [elasticsearch[172.17.0.2][generic][T#3]] org.elassandra.shard.CassandraShardStateListener.afterIndexShardStarted(CassandraShardStateListener.java:69) shard [ents_type_site1][0] started 2020-01-10 06:01:42,994 ERROR [elasticsearch[172.17.0.2][write][T#1]] org.elassandra.cluster.QueryManager.upsertDocument(QueryManager.java:842) [java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number].[ents_type_site1] failed to parse field _doc=int__eventcnt 2020-01-10 06:01:43,011 WARN [elasticsearch[172.17.0.2][write][T#1]] org.elasticsearch.rest.BytesRestResponse.build(BytesRestResponse.java:133) path: /ents_type_site1/_doc/a1bc=:1cd==, params: {index=ents_type_site1, id=a1bc=:1cd==, type=_doc} org.elasticsearch.transport.RemoteTransportException: [172.17.0.2][172.17.0.2:9300][indices:data/write/bulk[s][p]] Caused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$7.cqlValue(NumberFieldMapper.java:870) at org.elasticsearch.index.mapper.NumberFieldMapper$NumberFieldType.cqlValue(NumberFieldMapper.java:1057) at org.elasticsearch.index.mapper.MappedFieldType.cqlValue(MappedFieldType.java:423) at org.elassandra.cluster.Serializer.serialize(Serializer.java:230) at org.elassandra.cluster.Serializer.serialize(Serializer.java:223) at org.elassandra.cluster.QueryManager.upsertDocument(QueryManager.java:840) at org.elassandra.cluster.QueryManager.insertDocument(QueryManager.java:694) at org.elasticsearch.action.bulk.TransportShardBulkAction.lambda$executeIndexRequestOnPrimary$3(TransportShardBulkAction.java:468) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeOnPrimaryWhileHandlingMappingUpdates(TransportShardBulkAction.java:495) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeIndexRequestOnPrimary(TransportShardBulkAction.java:464) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:226) at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:169) at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:160) at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:146) at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:83) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1088) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1066) at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:105) at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.runWithPrimaryShardReference(TransportReplicationAction.java:445) at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:387) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:327) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:314) at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:66) at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:696) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  * elasticsearch cluster state (curl http://localhost:9200/_cluster/state) * cassandra schema (cqlsh>DESC KEYSPACE <your_keyspace>) * cassandra gossip state (run: nodetool gossipinfo) source-file source-file test-file source-file source-file test-file",bug,0.95
20,elassandra,https://github.com/strapdata/elassandra/issues/20,How to apply filter query?,"Hi, I am trying to apply elasticsearch filter queries to retrieve data. POST request, `http://localhost:9200/twitter/tweet/_search { ""query_string"" : { ""default_field"" : ""message"", ""query"" : ""hi"" } }` But i am getting following error `{ ""error"": { ""root_cause"": [ { ""type"": ""search_parse_exception"", ""reason"": ""failed to parse search source. unknown search element [query_string]"", ""line"": 2, ""col"": 5 } ], ""type"": ""search_phase_execution_exception"", ""reason"": ""all shards failed"", ""phase"": ""query_fetch"", ""grouped"": true, ""failed_shards"": [ { ""shard"": 0, ""index"": ""twitter"", ""node"": ""03ecbd77-ef8f-4502-bcd6-bf453b24d116"", ""reason"": { ""type"": ""search_parse_exception"", ""reason"": ""failed to parse search source. unknown search element [query_string]"", ""line"": 2, ""col"": 5 } } ] }, ""status"": 400 }` Is this possible to apply all the filter queries in elassandra?",config-file | config-file | config-file,"How to apply filter query? Hi, I am trying to apply elasticsearch filter queries to retrieve data. POST request, `http://localhost:9200/twitter/tweet/_search { ""query_string"" : { ""default_field"" : ""message"", ""query"" : ""hi"" } }` But i am getting following error `{ ""error"": { ""root_cause"": [ { ""type"": ""search_parse_exception"", ""reason"": ""failed to parse search source. unknown search element [query_string]"", ""line"": 2, ""col"": 5 } ], ""type"": ""search_phase_execution_exception"", ""reason"": ""all shards failed"", ""phase"": ""query_fetch"", ""grouped"": true, ""failed_shards"": [ { ""shard"": 0, ""index"": ""twitter"", ""node"": ""03ecbd77-ef8f-4502-bcd6-bf453b24d116"", ""reason"": { ""type"": ""search_parse_exception"", ""reason"": ""failed to parse search source. unknown search element [query_string]"", ""line"": 2, ""col"": 5 } } ] }, ""status"": 400 }` Is this possible to apply all the filter queries in elassandra? config-file config-file config-file",no-bug,0.9
83,elassandra,https://github.com/strapdata/elassandra/issues/83,Partitioned index doesn't work after upgraded to v2.4.2-9.2,"I used partitioned index in my service. After I upgraded elassandra to v2.4.2-9.2, partitioned index was created but data was not indexed.",other-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | documentation-file,"Partitioned index doesn't work after upgraded to v2.4.2-9.2 I used partitioned index in my service. After I upgraded elassandra to v2.4.2-9.2, partitioned index was created but data was not indexed. other-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file source-file test-file test-file documentation-file",no-bug,0.7
7,elassandra,https://github.com/strapdata/elassandra/issues/7,Build string on ES startpage is empty,"error show build numer:  { ""name"" : ""abc"", ""cluster_name"" : ""Test Cluster"", ""version"" : { ""number"" : ""2.1.2"", ""build_hash"" : ""${buildNumber}"", ""build_timestamp"" : ""NA"", ""build_snapshot"" : true, ""lucene_version"" : ""5.3.1"" }, ""tagline"" : ""You Know, for Search"" } ",config-file | other-file | other-file | other-file | other-file | other-file | source-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file | other-file,"Build string on ES startpage is empty error show build numer:  { ""name"" : ""abc"", ""cluster_name"" : ""Test Cluster"", ""version"" : { ""number"" : ""2.1.2"", ""build_hash"" : ""${buildNumber}"", ""build_timestamp"" : ""NA"", ""build_snapshot"" : true, ""lucene_version"" : ""5.3.1"" }, ""tagline"" : ""You Know, for Search"" }  config-file other-file other-file other-file other-file other-file source-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file other-file",bug,0.85
133,elassandra,https://github.com/strapdata/elassandra/issues/133,It would be valuable to document the practical benefit of Elassandra over Elasticsearch,"Traditionally one of the big values of Cassandra over Elasticsearch (ES) was is reliability whereas ES was known to lose data it certain situations. Or it's ability to scale linearly with new nodes. Many of these problems have been solved or improved in newer versions of ES (>5). It would be valuable to document somewhere what benefit I'm going to experience by using Elessandra (EL) over ES. Eg, in these failure situations, EL does not lose data whereas ES does. Or, EL can index/search/update X docs/sec and ES can only do Y. In my mind, having two good products merged into one doesn't automatically make it better - did I inherit the benefits of both or the faults of both (or even more faults..)",documentation-file,"It would be valuable to document the practical benefit of Elassandra over Elasticsearch Traditionally one of the big values of Cassandra over Elasticsearch (ES) was is reliability whereas ES was known to lose data it certain situations. Or it's ability to scale linearly with new nodes. Many of these problems have been solved or improved in newer versions of ES (>5). It would be valuable to document somewhere what benefit I'm going to experience by using Elessandra (EL) over ES. Eg, in these failure situations, EL does not lose data whereas ES does. Or, EL can index/search/update X docs/sec and ES can only do Y. In my mind, having two good products merged into one doesn't automatically make it better - did I inherit the benefits of both or the faults of both (or even more faults..) documentation-file",no-bug,0.95
346,elassandra,https://github.com/strapdata/elassandra/issues/346,"Nested objects with inner hits query returns ""extracted source isn't an object or an array""","<!-- Bug report --> **Elassandra version**: Behavior is seen on official docker images [6.8.4.0](https://hub.docker.com/layers/strapdata/elassandra/6.8.4.0/images/sha256-1e004ecccfc506faf806464e4beed1815d3c973ee6d3bb4b88193084397d8491?context=explore) -> [6.8.4.5](https://hub.docker.com/layers/strapdata/elassandra/6.8.4.5/images/sha256-1a7ff3e3c1ee0801f812aa321dfe4ae8a6f959c3ef47b0fbeaa3a4de695eff14?context=explore) **Plugins installed**: None **JVM version** (`java -version`): Docker image of 6.8.4.5 is running openjdk version ""1.8.0_252"" **OS version** (`uname -a` if on a Unix-like system): Running on a container on a host that is running 18.04.1-Ubuntu **Description of the problem including expected versus actual behavior**: I am moving from 6.2.3.28 to 6.8.4.5, and have noticed queries with inner hits on nested objects (as outlined in the steps below) are failing with the following error coming back:  { ""error"": { ""root_cause"": [ { ""type"": ""illegal_state_exception"", ""reason"": ""extracted source isn't an object or an array"" } ], ""type"": ""search_phase_execution_exception"", ""reason"": ""all shards failed"", ""phase"": ""query"", ""grouped"": true, ""failed_shards"": [ { ""shard"": 0, ""index"": ""nested_data"", ""node"": ""5c622bfa-fef0-4dd0-b040-5a68a767beb5"", ""reason"": { ""type"": ""illegal_state_exception"", ""reason"": ""extracted source isn't an object or an array"" } } ], ""caused_by"": { ""type"": ""illegal_state_exception"", ""reason"": ""extracted source isn't an object or an array"", ""caused_by"": { ""type"": ""illegal_state_exception"", ""reason"": ""extracted source isn't an object or an array"" } } }, ""status"": 500 }  **Reasons why I think this is a bug:** 1. When tested against [ES 6.8.4 docker image](https://hub.docker.com/layers/elasticsearch/library/elasticsearch/6.8.4/images/sha256-87538ba78df48470563796df1dbbf2e7bf407e97542830bfd395f912b15c07f0?context=explore) I do not see the same issue. 2. I do not see this issue on Elassandra 6.2.3.28, and assume there is backwards compatibility of query/mapping/docs on non major version releases **Other behaviors I noted:** Removing the inner_hits block of the query stops the issue, and so does turning off the source in the inner_hits block. However neither of these are desirable solutions Something else that seems to resolve the issue while I was triaging is removing `nested-object2` when inserting the data in step 2 below **Steps to reproduce**: 1. Create index at `nested_data` with the following mapping:  { ""mappings"": { ""nested_data"": { ""properties"": { ""parent-nested"": { ""type"": ""nested"", ""properties"": { ""nested-object1"": { ""type"": ""nested"", ""properties"": { ""field1"": { ""type"": ""text"" }, ""field2"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } } } }, ""nested-object2"": { ""type"": ""nested"", ""properties"": { ""field2"": { ""type"": ""text"" } } } } } } } } }  2. Insert the following document in the above created index:  { ""parent-nested"": [ { ""nested-object1"": [ { ""field1"": ""hello"" } ] }, { ""nested-object2"": { } } ] }  3. Run the following query against the index:  { ""query"": { ""bool"": { ""must"": [ { ""nested"": { ""path"": ""parent-nested.nested-object1"", ""inner_hits"": { }, ""query"": { ""bool"": { ""should"": { ""bool"": { ""must"": { ""match"": { ""parent-nested.nested-object1.field1"": ""hello"" } } } } } } } } ] } } }  **Please provide the following information**: * elassandra logs:  elassandra | Elassandra started elassandra | 2020-06-04 17:51:31,748 WARN [elasticsearch[172.18.0.2][http_server_worker][T#2]] org.elasticsearch.common.logging.DeprecationLogger.deprecated(DeprecationLogger.java:242) [types removal] The parameter include_type_name should be explicitly specified in create index requests to prepare for 7.0. In 7.0 include_type_name will default to 'false', and requests are expected to omit the type name in mapping definitions. elassandra | 2020-06-04 17:51:33,174 INFO [elasticsearch[172.18.0.2][generic][T#2]] org.elassandra.shard.CassandraShardStateListener.afterIndexShardStarted(CassandraShardStateListener.java:69) shard [nested_data][0] started elassandra | 2020-06-04 17:51:46,971 WARN [elasticsearch[172.18.0.2][search][T#1]] org.elasticsearch.rest.BytesRestResponse.build(BytesRestResponse.java:133) path: /nested_data/_search, params: {index=nested_data} elassandra | org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:298) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:135) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:261) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:100) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.access$100(InitialSearchPhase.java:48) elassandra | at org.elasticsearch.action.search.InitialSearchPhase$2.lambda$onFailure$1(InitialSearchPhase.java:220) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.maybeFork(InitialSearchPhase.java:174) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.access$000(InitialSearchPhase.java:48) elassandra | at org.elasticsearch.action.search.InitialSearchPhase$2.onFailure(InitialSearchPhase.java:220) elassandra | at org.elasticsearch.action.search.SearchExecutionStatsCollector.onFailure(SearchExecutionStatsCollector.java:73) elassandra | at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:59) elassandra | at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:463) elassandra | at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1118) elassandra | at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1230) elassandra | at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1204) elassandra | at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:60) elassandra | at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:56) elassandra | at org.elasticsearch.search.SearchService$2.onFailure(SearchService.java:368) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:362) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:356) elassandra | at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1114) elassandra | at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) elassandra | at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) elassandra | at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) elassandra | at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) elassandra | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) elassandra | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) elassandra | at java.lang.Thread.run(Thread.java:748) elassandra | Caused by: org.elasticsearch.ElasticsearchException$1: extracted source isn't an object or an array elassandra | at org.elasticsearch.ElasticsearchException.guessRootCauses(ElasticsearchException.java:657) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:133) elassandra |  26 common frames omitted elassandra | Caused by: java.lang.IllegalStateException: extracted source isn't an object or an array elassandra | at org.elasticsearch.search.fetch.FetchPhase.createNestedSearchHit(FetchPhase.java:340) elassandra | at org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:166) elassandra | at org.elasticsearch.search.fetch.subphase.InnerHitsFetchSubPhase.hitsExecute(InnerHitsFetchSubPhase.java:69) elassandra | at org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:184) elassandra | at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:424) elassandra | at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:404) elassandra | at org.elasticsearch.search.SearchService.access$100(SearchService.java:127) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:360) elassandra |  9 common frames omitted elassandra | 2020-06-04 18:06:06,393 WARN [elasticsearch[172.18.0.2][search][T#2]] org.elasticsearch.rest.BytesRestResponse.build(BytesRestResponse.java:133) path: /nested_data/_search, params: {index=nested_data} elassandra | org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:298) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:135) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:261) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:100) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.access$100(InitialSearchPhase.java:48) elassandra | at org.elasticsearch.action.search.InitialSearchPhase$2.lambda$onFailure$1(InitialSearchPhase.java:220) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.maybeFork(InitialSearchPhase.java:174) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.access$000(InitialSearchPhase.java:48) elassandra | at org.elasticsearch.action.search.InitialSearchPhase$2.onFailure(InitialSearchPhase.java:220) elassandra | at org.elasticsearch.action.search.SearchExecutionStatsCollector.onFailure(SearchExecutionStatsCollector.java:73) elassandra | at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:59) elassandra | at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:463) elassandra | at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1118) elassandra | at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1230) elassandra | at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1204) elassandra | at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:60) elassandra | at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:56) elassandra | at org.elasticsearch.search.SearchService$2.onFailure(SearchService.java:368) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:362) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:356) elassandra | at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1114) elassandra | at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) elassandra | at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) elassandra | at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) elassandra | at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) elassandra | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) elassandra | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) elassandra | at java.lang.Thread.run(Thread.java:748) elassandra | Caused by: org.elasticsearch.ElasticsearchException$1: extracted source isn't an object or an array elassandra | at org.elasticsearch.ElasticsearchException.guessRootCauses(ElasticsearchException.java:657) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:133) elassandra |  26 common frames omitted elassandra | Caused by: java.lang.IllegalStateException: extracted source isn't an object or an array elassandra | at org.elasticsearch.search.fetch.FetchPhase.createNestedSearchHit(FetchPhase.java:340) elassandra | at org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:166) elassandra | at org.elasticsearch.search.fetch.subphase.InnerHitsFetchSubPhase.hitsExecute(InnerHitsFetchSubPhase.java:69) elassandra | at org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:184) elassandra | at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:424) elassandra | at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:404) elassandra | at org.elasticsearch.search.SearchService.access$100(SearchService.java:127) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:360) elassandra |  9 common frames omitted  * cassandra schema:  CREATE KEYSPACE nested_data WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '1'} AND durable_writes = true; CREATE TYPE nested_data.nested_data_parent_nested_nested_object1 ( field1 list<text>, field2 list<text> ); CREATE TYPE nested_data.nested_data_parent_nested_nested_object2 ( field2 list<text> ); CREATE TYPE nested_data.nested_data_parent_nested ( ""nested-object1"" list<frozen<nested_data_parent_nested_nested_object1>>, ""nested-object2"" list<frozen<nested_data_parent_nested_nested_object2>> ); CREATE TABLE nested_data.nested_data ( ""_id"" text PRIMARY KEY, ""parent-nested"" list<frozen<nested_data_parent_nested>> ) WITH bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE'; CREATE CUSTOM INDEX elastic_nested_data_idx ON nested_data.nested_data () USING 'org.elassandra.index.ExtendedElasticSecondaryIndex'; ",source-file | source-file | test-file,"Nested objects with inner hits query returns ""extracted source isn't an object or an array"" <!-- Bug report --> **Elassandra version**: Behavior is seen on official docker images [6.8.4.0](https://hub.docker.com/layers/strapdata/elassandra/6.8.4.0/images/sha256-1e004ecccfc506faf806464e4beed1815d3c973ee6d3bb4b88193084397d8491?context=explore) -> [6.8.4.5](https://hub.docker.com/layers/strapdata/elassandra/6.8.4.5/images/sha256-1a7ff3e3c1ee0801f812aa321dfe4ae8a6f959c3ef47b0fbeaa3a4de695eff14?context=explore) **Plugins installed**: None **JVM version** (`java -version`): Docker image of 6.8.4.5 is running openjdk version ""1.8.0_252"" **OS version** (`uname -a` if on a Unix-like system): Running on a container on a host that is running 18.04.1-Ubuntu **Description of the problem including expected versus actual behavior**: I am moving from 6.2.3.28 to 6.8.4.5, and have noticed queries with inner hits on nested objects (as outlined in the steps below) are failing with the following error coming back:  { ""error"": { ""root_cause"": [ { ""type"": ""illegal_state_exception"", ""reason"": ""extracted source isn't an object or an array"" } ], ""type"": ""search_phase_execution_exception"", ""reason"": ""all shards failed"", ""phase"": ""query"", ""grouped"": true, ""failed_shards"": [ { ""shard"": 0, ""index"": ""nested_data"", ""node"": ""5c622bfa-fef0-4dd0-b040-5a68a767beb5"", ""reason"": { ""type"": ""illegal_state_exception"", ""reason"": ""extracted source isn't an object or an array"" } } ], ""caused_by"": { ""type"": ""illegal_state_exception"", ""reason"": ""extracted source isn't an object or an array"", ""caused_by"": { ""type"": ""illegal_state_exception"", ""reason"": ""extracted source isn't an object or an array"" } } }, ""status"": 500 }  **Reasons why I think this is a bug:** 1. When tested against [ES 6.8.4 docker image](https://hub.docker.com/layers/elasticsearch/library/elasticsearch/6.8.4/images/sha256-87538ba78df48470563796df1dbbf2e7bf407e97542830bfd395f912b15c07f0?context=explore) I do not see the same issue. 2. I do not see this issue on Elassandra 6.2.3.28, and assume there is backwards compatibility of query/mapping/docs on non major version releases **Other behaviors I noted:** Removing the inner_hits block of the query stops the issue, and so does turning off the source in the inner_hits block. However neither of these are desirable solutions Something else that seems to resolve the issue while I was triaging is removing `nested-object2` when inserting the data in step 2 below **Steps to reproduce**: 1. Create index at `nested_data` with the following mapping:  { ""mappings"": { ""nested_data"": { ""properties"": { ""parent-nested"": { ""type"": ""nested"", ""properties"": { ""nested-object1"": { ""type"": ""nested"", ""properties"": { ""field1"": { ""type"": ""text"" }, ""field2"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } } } }, ""nested-object2"": { ""type"": ""nested"", ""properties"": { ""field2"": { ""type"": ""text"" } } } } } } } } }  2. Insert the following document in the above created index:  { ""parent-nested"": [ { ""nested-object1"": [ { ""field1"": ""hello"" } ] }, { ""nested-object2"": { } } ] }  3. Run the following query against the index:  { ""query"": { ""bool"": { ""must"": [ { ""nested"": { ""path"": ""parent-nested.nested-object1"", ""inner_hits"": { }, ""query"": { ""bool"": { ""should"": { ""bool"": { ""must"": { ""match"": { ""parent-nested.nested-object1.field1"": ""hello"" } } } } } } } } ] } } }  **Please provide the following information**: * elassandra logs:  elassandra | Elassandra started elassandra | 2020-06-04 17:51:31,748 WARN [elasticsearch[172.18.0.2][http_server_worker][T#2]] org.elasticsearch.common.logging.DeprecationLogger.deprecated(DeprecationLogger.java:242) [types removal] The parameter include_type_name should be explicitly specified in create index requests to prepare for 7.0. In 7.0 include_type_name will default to 'false', and requests are expected to omit the type name in mapping definitions. elassandra | 2020-06-04 17:51:33,174 INFO [elasticsearch[172.18.0.2][generic][T#2]] org.elassandra.shard.CassandraShardStateListener.afterIndexShardStarted(CassandraShardStateListener.java:69) shard [nested_data][0] started elassandra | 2020-06-04 17:51:46,971 WARN [elasticsearch[172.18.0.2][search][T#1]] org.elasticsearch.rest.BytesRestResponse.build(BytesRestResponse.java:133) path: /nested_data/_search, params: {index=nested_data} elassandra | org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:298) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:135) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:261) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:100) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.access$100(InitialSearchPhase.java:48) elassandra | at org.elasticsearch.action.search.InitialSearchPhase$2.lambda$onFailure$1(InitialSearchPhase.java:220) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.maybeFork(InitialSearchPhase.java:174) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.access$000(InitialSearchPhase.java:48) elassandra | at org.elasticsearch.action.search.InitialSearchPhase$2.onFailure(InitialSearchPhase.java:220) elassandra | at org.elasticsearch.action.search.SearchExecutionStatsCollector.onFailure(SearchExecutionStatsCollector.java:73) elassandra | at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:59) elassandra | at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:463) elassandra | at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1118) elassandra | at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1230) elassandra | at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1204) elassandra | at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:60) elassandra | at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:56) elassandra | at org.elasticsearch.search.SearchService$2.onFailure(SearchService.java:368) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:362) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:356) elassandra | at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1114) elassandra | at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) elassandra | at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) elassandra | at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) elassandra | at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) elassandra | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) elassandra | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) elassandra | at java.lang.Thread.run(Thread.java:748) elassandra | Caused by: org.elasticsearch.ElasticsearchException$1: extracted source isn't an object or an array elassandra | at org.elasticsearch.ElasticsearchException.guessRootCauses(ElasticsearchException.java:657) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:133) elassandra |  26 common frames omitted elassandra | Caused by: java.lang.IllegalStateException: extracted source isn't an object or an array elassandra | at org.elasticsearch.search.fetch.FetchPhase.createNestedSearchHit(FetchPhase.java:340) elassandra | at org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:166) elassandra | at org.elasticsearch.search.fetch.subphase.InnerHitsFetchSubPhase.hitsExecute(InnerHitsFetchSubPhase.java:69) elassandra | at org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:184) elassandra | at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:424) elassandra | at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:404) elassandra | at org.elasticsearch.search.SearchService.access$100(SearchService.java:127) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:360) elassandra |  9 common frames omitted elassandra | 2020-06-04 18:06:06,393 WARN [elasticsearch[172.18.0.2][search][T#2]] org.elasticsearch.rest.BytesRestResponse.build(BytesRestResponse.java:133) path: /nested_data/_search, params: {index=nested_data} elassandra | org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:298) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:135) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:261) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:100) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.access$100(InitialSearchPhase.java:48) elassandra | at org.elasticsearch.action.search.InitialSearchPhase$2.lambda$onFailure$1(InitialSearchPhase.java:220) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.maybeFork(InitialSearchPhase.java:174) elassandra | at org.elasticsearch.action.search.InitialSearchPhase.access$000(InitialSearchPhase.java:48) elassandra | at org.elasticsearch.action.search.InitialSearchPhase$2.onFailure(InitialSearchPhase.java:220) elassandra | at org.elasticsearch.action.search.SearchExecutionStatsCollector.onFailure(SearchExecutionStatsCollector.java:73) elassandra | at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:59) elassandra | at org.elasticsearch.action.search.SearchTransportService$ConnectionCountingHandler.handleException(SearchTransportService.java:463) elassandra | at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1118) elassandra | at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1230) elassandra | at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1204) elassandra | at org.elasticsearch.transport.TaskTransportChannel.sendResponse(TaskTransportChannel.java:60) elassandra | at org.elasticsearch.action.support.ChannelActionListener.onFailure(ChannelActionListener.java:56) elassandra | at org.elasticsearch.search.SearchService$2.onFailure(SearchService.java:368) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:362) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:356) elassandra | at org.elasticsearch.search.SearchService$4.doRun(SearchService.java:1114) elassandra | at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) elassandra | at org.elasticsearch.common.util.concurrent.TimedRunnable.doRun(TimedRunnable.java:41) elassandra | at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:751) elassandra | at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) elassandra | at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) elassandra | at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) elassandra | at java.lang.Thread.run(Thread.java:748) elassandra | Caused by: org.elasticsearch.ElasticsearchException$1: extracted source isn't an object or an array elassandra | at org.elasticsearch.ElasticsearchException.guessRootCauses(ElasticsearchException.java:657) elassandra | at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:133) elassandra |  26 common frames omitted elassandra | Caused by: java.lang.IllegalStateException: extracted source isn't an object or an array elassandra | at org.elasticsearch.search.fetch.FetchPhase.createNestedSearchHit(FetchPhase.java:340) elassandra | at org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:166) elassandra | at org.elasticsearch.search.fetch.subphase.InnerHitsFetchSubPhase.hitsExecute(InnerHitsFetchSubPhase.java:69) elassandra | at org.elasticsearch.search.fetch.FetchPhase.execute(FetchPhase.java:184) elassandra | at org.elasticsearch.search.SearchService.executeFetchPhase(SearchService.java:424) elassandra | at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:404) elassandra | at org.elasticsearch.search.SearchService.access$100(SearchService.java:127) elassandra | at org.elasticsearch.search.SearchService$2.onResponse(SearchService.java:360) elassandra |  9 common frames omitted  * cassandra schema:  CREATE KEYSPACE nested_data WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '1'} AND durable_writes = true; CREATE TYPE nested_data.nested_data_parent_nested_nested_object1 ( field1 list<text>, field2 list<text> ); CREATE TYPE nested_data.nested_data_parent_nested_nested_object2 ( field2 list<text> ); CREATE TYPE nested_data.nested_data_parent_nested ( ""nested-object1"" list<frozen<nested_data_parent_nested_nested_object1>>, ""nested-object2"" list<frozen<nested_data_parent_nested_nested_object2>> ); CREATE TABLE nested_data.nested_data ( ""_id"" text PRIMARY KEY, ""parent-nested"" list<frozen<nested_data_parent_nested>> ) WITH bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE'; CREATE CUSTOM INDEX elastic_nested_data_idx ON nested_data.nested_data () USING 'org.elassandra.index.ExtendedElasticSecondaryIndex';  source-file source-file test-file",bug,0.95
139,elassandra,https://github.com/strapdata/elassandra/issues/139,Feature request: Mappings for BigDecimal and BigInteger,"As an elassandra user i want next mappings(at least without index) should be possible. * **BigDecimal** -> **Keyword** * **BigInteger** -> **Keyword** For example, we have next table:  CREATE TABLE IF NOT EXISTS city_budgets ( , state text, city text, budget decimal,  )  I want to search this table by **city** or **state** fields and result entity should contains **budget** field too.",documentation-file | source-file | source-file | source-file | source-file | source-file | test-file,"Feature request: Mappings for BigDecimal and BigInteger As an elassandra user i want next mappings(at least without index) should be possible. * **BigDecimal** -> **Keyword** * **BigInteger** -> **Keyword** For example, we have next table:  CREATE TABLE IF NOT EXISTS city_budgets ( , state text, city text, budget decimal,  )  I want to search this table by **city** or **state** fields and result entity should contains **budget** field too. documentation-file source-file source-file source-file source-file source-file test-file",no-bug,0.9
10,elassandra,https://github.com/strapdata/elassandra/issues/10,Installation process,"Hi, The tool looks promising indeed, Tried to follow the install process but it isn't that clear unfortunately. I am using Ubuntu 14.04. I have already installed elastic and cassandra and it works. But when I try to add the elassandra it doesn't combine them together. Is there a detailed procedure for your installation? Regards",source-file | source-file | source-file | test-file | documentation-file,"Installation process Hi, The tool looks promising indeed, Tried to follow the install process but it isn't that clear unfortunately. I am using Ubuntu 14.04. I have already installed elastic and cassandra and it works. But when I try to add the elassandra it doesn't combine them together. Is there a detailed procedure for your installation? Regards source-file source-file source-file test-file documentation-file",no-bug,0.9
68,elassandra,https://github.com/strapdata/elassandra/issues/68,ES Object Type stringified in search,"When inserting fields mapped as object type contents are returned as strings in search. In comparison my stock ES 2.x returns object fields as a valid JSON objects without escaping.  Steps to Reproduce * Create Mapping: json PUT watcher/watch/_mapping { ""properties"": { ""uuid"": { ""type"": ""string"", ""index"": ""not_analyzed"" }, ""condition"": { ""type"":""object"", ""enabled"": false } } }  * Insert document with object fields json PUT watcher/watch/test_watch_random23 { ""uuid"": ""test"", ""trigger"": { ""schedule"": { ""later"": ""every 1 minutes"" } }, ""condition"": { ""script"": { ""script"": ""payload.hits.total > 1"" } } }  * Query results, objects are returned as strings  GET watcher/_search { ""took"": 6, ""timed_out"": false, ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 }, ""hits"": { ""total"": 1, ""max_score"": 1, ""hits"": [ { ""_index"": ""watcher"", ""_type"": ""watch"", ""_id"": ""test_watch_random23"", ""_score"": 1, ""_source"": { ""condition"": ""{\""script\"":{\""script\"":\""payload.hits.total > 1\""}}"", ""trigger"": { ""schedule"": { ""later"": ""every 1 minutes"" } }, ""uuid"": ""test"" } } ] } } ",source-file | test-file,"ES Object Type stringified in search When inserting fields mapped as object type contents are returned as strings in search. In comparison my stock ES 2.x returns object fields as a valid JSON objects without escaping.  Steps to Reproduce * Create Mapping: json PUT watcher/watch/_mapping { ""properties"": { ""uuid"": { ""type"": ""string"", ""index"": ""not_analyzed"" }, ""condition"": { ""type"":""object"", ""enabled"": false } } }  * Insert document with object fields json PUT watcher/watch/test_watch_random23 { ""uuid"": ""test"", ""trigger"": { ""schedule"": { ""later"": ""every 1 minutes"" } }, ""condition"": { ""script"": { ""script"": ""payload.hits.total > 1"" } } }  * Query results, objects are returned as strings  GET watcher/_search { ""took"": 6, ""timed_out"": false, ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 }, ""hits"": { ""total"": 1, ""max_score"": 1, ""hits"": [ { ""_index"": ""watcher"", ""_type"": ""watch"", ""_id"": ""test_watch_random23"", ""_score"": 1, ""_source"": { ""condition"": ""{\""script\"":{\""script\"":\""payload.hits.total > 1\""}}"", ""trigger"": { ""schedule"": { ""later"": ""every 1 minutes"" } }, ""uuid"": ""test"" } } ] } }  source-file test-file",bug,0.95
112,elassandra,https://github.com/strapdata/elassandra/issues/112,Don't search over SETS,"Assume we have following mapping - with list and set  PUT /es_issue_search_set { ""mappings"": { ""tab_list"": { ""properties"": { ""items"": { ""type"": ""object"", ""cql_collection"": ""list"", ""cql_udt_name"": ""item"", ""properties"": { ""name"": { ""type"": ""string"", ""index"": ""not_analyzed"", ""cql_collection"": ""singleton"" } } }, ""item"": { ""type"": ""object"", ""cql_collection"": ""singleton"", ""cql_udt_name"": ""item"", ""properties"": { ""name"": { ""type"": ""string"", ""index"": ""not_analyzed"", ""cql_collection"": ""singleton"" } } } } }, ""tab_set"": { ""properties"": { ""items"": { ""type"": ""object"", ""cql_collection"": ""set"", ""cql_udt_name"": ""item"", ""properties"": { ""name"": { ""type"": ""string"", ""index"": ""not_analyzed"", ""cql_collection"": ""singleton"" } } }, ""item"": { ""type"": ""object"", ""cql_collection"": ""singleton"", ""cql_udt_name"": ""item"", ""properties"": { ""name"": { ""type"": ""string"", ""index"": ""not_analyzed"", ""cql_collection"": ""singleton"" } } } } } } }  Then we insert some data  use es_issue_search_set; insert into tab_list (""_id"",item,items) values ('1',{name:'hello'},[{name:'world'},{name:'heaven'}]) insert into tab_set (""_id"",item,items) values ('1',{name:'hello'},{{name:'world'},{name:'heaven'}})  Then we execute following search:  POST /es_issue_search_set/_search { ""query"": { ""query_string"": { ""query"": ""hello"" } } }  - as result - it's OK - both items returned (while it's in `item` subobject) But if we try to find with  POST /es_issue_search_set/_search { ""query"": { ""query_string"": { ""query"": ""world"" } } }  - it fails - only `tab_list`'s record returned, while `tab_set` ignored It's not about mapping. It's about real type in CASSANDRA. If you create tables manually with SET as type and create mapping with LIST as mapping-type - it will not search, but if you map LIST as SET - all will be working. Just `DELETE /s32` and recreate it's mapping with swapping LIST and SET - it will be still show recotd from tab_list - sets will be ignored",source-file | test-file,"Don't search over SETS Assume we have following mapping - with list and set  PUT /es_issue_search_set { ""mappings"": { ""tab_list"": { ""properties"": { ""items"": { ""type"": ""object"", ""cql_collection"": ""list"", ""cql_udt_name"": ""item"", ""properties"": { ""name"": { ""type"": ""string"", ""index"": ""not_analyzed"", ""cql_collection"": ""singleton"" } } }, ""item"": { ""type"": ""object"", ""cql_collection"": ""singleton"", ""cql_udt_name"": ""item"", ""properties"": { ""name"": { ""type"": ""string"", ""index"": ""not_analyzed"", ""cql_collection"": ""singleton"" } } } } }, ""tab_set"": { ""properties"": { ""items"": { ""type"": ""object"", ""cql_collection"": ""set"", ""cql_udt_name"": ""item"", ""properties"": { ""name"": { ""type"": ""string"", ""index"": ""not_analyzed"", ""cql_collection"": ""singleton"" } } }, ""item"": { ""type"": ""object"", ""cql_collection"": ""singleton"", ""cql_udt_name"": ""item"", ""properties"": { ""name"": { ""type"": ""string"", ""index"": ""not_analyzed"", ""cql_collection"": ""singleton"" } } } } } } }  Then we insert some data  use es_issue_search_set; insert into tab_list (""_id"",item,items) values ('1',{name:'hello'},[{name:'world'},{name:'heaven'}]) insert into tab_set (""_id"",item,items) values ('1',{name:'hello'},{{name:'world'},{name:'heaven'}})  Then we execute following search:  POST /es_issue_search_set/_search { ""query"": { ""query_string"": { ""query"": ""hello"" } } }  - as result - it's OK - both items returned (while it's in `item` subobject) But if we try to find with  POST /es_issue_search_set/_search { ""query"": { ""query_string"": { ""query"": ""world"" } } }  - it fails - only `tab_list`'s record returned, while `tab_set` ignored It's not about mapping. It's about real type in CASSANDRA. If you create tables manually with SET as type and create mapping with LIST as mapping-type - it will not search, but if you map LIST as SET - all will be working. Just `DELETE /s32` and recreate it's mapping with swapping LIST and SET - it will be still show recotd from tab_list - sets will be ignored source-file test-file",no-bug,0.8
279,elassandra,https://github.com/strapdata/elassandra/issues/279,Returning data into consistent format,"Hello, Not sure if we can call this ""bug"" but here is the problem: If you have a table using ""inet"" and ""timestamp"" data types, when query via cassandra the results are returned as : timestamp - unix timestamp in ms inet - string, example : ""127.0.0.1"" query same values via ELS: timestamp - returned as ISO8601 inet - returned as string but appends ""/"" in front, example: ""/127.0.01"" Any way I can do something to have consistent formatting (other than handle-ing this into the code) Silviu",source-file | test-file,"Returning data into consistent format Hello, Not sure if we can call this ""bug"" but here is the problem: If you have a table using ""inet"" and ""timestamp"" data types, when query via cassandra the results are returned as : timestamp - unix timestamp in ms inet - string, example : ""127.0.0.1"" query same values via ELS: timestamp - returned as ISO8601 inet - returned as string but appends ""/"" in front, example: ""/127.0.01"" Any way I can do something to have consistent formatting (other than handle-ing this into the code) Silviu source-file test-file",no-bug,0.85
271,elassandra,https://github.com/strapdata/elassandra/issues/271,Elassandra assertion error on bulk update,"**Elassandra version**: 6.2.3.10 **Plugins installed**: [] **JVM version** (`java -version`):  openjdk version ""1.8.0_181"" OpenJDK Runtime Environment (build 1.8.0_181-8u181-b13-2~deb9u1-b13) OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode)  **OS version** (`uname -a` if on a Unix-like system): Ubuntu 18.04 **Description of the problem including expected versus actual behavior**: Conditional bulk update fails in elassandra but works in elasticsearch 6.2.3 **Steps to reproduce**: 1. Create an index and add data `curl -XPOST -H 'content-type: application/json' http://172.17.0.3:9200/test_index/user -d '{""projects"":[""p1"", ""p2""]}'` 2. Run the below command  curl -XPOST -H 'content-type: application/json' http://172.17.0.3:9200/_bulk -d ' {""update"":{""_index"":""test_index"",""_type"":""user"",""_id"":""e8druWkBu-AlXJ3uggHp""}} {""script"":{""source"": ""if (!ctx._source.projects.contains(params.project)) {ctx._source.projects.add(params.project)}"",""params"":{""project"":""p3"" ' '  3. Curl statement never gave any response back. I checked the result in elastic seach and found that data got updated but Cassandra system.log shows an AssertionError  2019-03-26 09:56:19,228 ERROR [elasticsearch[172.17.0.3][bulk][T#2]] CassandraDaemon.java:231 uncaughtException Exception in thread Thread[elasticsearch[172.17.0.3][bulk][T#2],5,main] java.lang.AssertionError: failed result should not have a sequence number at org.elasticsearch.action.bulk.TransportShardBulkAction.processUpdateResponse(TransportShardBulkAction.java:289) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeUpdateRequestOnce(TransportShardBulkAction.java:393) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeUpdateRequest(TransportShardBulkAction.java:419) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:250) at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:129) at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:115) at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:73) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1065) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1043) at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:104) at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:331) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:297) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:284) at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:66) at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:661) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:672) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  **Please provide the following information: * elassandra logs (logs/system.logs or /var/lib/cassandra/system.log) : Added above * elasticsearch cluster state (curl http://localhost:9200/_cluster/state):  { ""cluster_name"": ""Test Cluster"", ""compressed_size_in_bytes"": 501, ""version"": 9, ""state_uuid"": ""QtmmOC9dS8SMAGeppPEduw"", ""master_node"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""blocks"": {}, ""nodes"": { ""a8feb81e-270f-4def-8216-4f179bd1f5e2"": { ""name"": ""172.17.0.3"", ""status"": ""ALIVE"", ""ephemeral_id"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""transport_address"": ""172.17.0.3:9300"", ""attributes"": { ""rack"": ""r1"", ""dc"": ""DC1"" } } }, ""metadata"": { ""version"": 2, ""cluster_uuid"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""templates"": {}, ""indices"": { ""test_index"": { ""state"": ""open"", ""settings"": { ""index"": { ""creation_date"": ""1553594023962"", ""number_of_shards"": ""1"", ""number_of_replicas"": ""0"", ""uuid"": ""jKfz0fVyRnKTBrsNuBZeQQ"", ""version"": { ""created"": ""6020399"" }, ""provided_name"": ""test_index"" } }, ""mappings"": { ""user"": { ""properties"": { ""projects"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""ignore_above"": 256, ""type"": ""keyword"" } } } } } }, ""aliases"": [], ""primary_terms"": { ""0"": 0 }, ""in_sync_allocations"": { ""0"": [] } } }, ""index-graveyard"": { ""tombstones"": [] } }, ""routing_table"": { ""indices"": { ""test_index"": { ""shards"": { ""0"": [ { ""state"": ""STARTED"", ""primary"": true, ""node"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""relocating_node"": null, ""shard"": 0, ""index"": ""test_index"", ""token_ranges"": [ ""(-9223372036854775808,9223372036854775807]"" ], ""allocation_id"": { ""id"": ""dummy_alloc_id"" } } ] } } } }, ""routing_nodes"": { ""unassigned"": [], ""nodes"": { ""a8feb81e-270f-4def-8216-4f179bd1f5e2"": [ { ""state"": ""STARTED"", ""primary"": true, ""node"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""relocating_node"": null, ""shard"": 0, ""index"": ""test_index"", ""token_ranges"": [ ""(-9223372036854775808,9223372036854775807]"" ], ""allocation_id"": { ""id"": ""dummy_alloc_id"" } } ] } }, ""snapshot_deletions"": { ""snapshot_deletions"": [] }, ""snapshots"": { ""snapshots"": [] }, ""restore"": { ""snapshots"": [] } }  * cassandra schema (cqlsh>DESC KEYSPACE <your_keyspace>)  CREATE KEYSPACE test_index WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '1'} AND durable_writes = true; CREATE TABLE test_index.user ( ""_id"" text PRIMARY KEY, projects list<text> ) WITH bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE'; CREATE CUSTOM INDEX elastic_user_idx ON test_index.user () USING 'org.elassandra.index.ExtendedElasticSecondaryIndex';  * cassandra gossip state (run: nodetool gossipinfo)  /172.17.0.3 generation:1553592898 heartbeat:1706 STATUS:55:NORMAL,-2180626626081522229 LOAD:1661:113785.0 SCHEMA:1208:ab8b61c6-d700-3c2e-ae37-51b6bc17d07b DC:8:DC1 RACK:10:r1 RELEASE_VERSION:4:3.11.3.5 INTERNAL_IP:6:172.17.0.3 RPC_ADDRESS:3:172.17.0.3 NET_VERSION:1:11 HOST_ID:2:a8feb81e-270f-4def-8216-4f179bd1f5e2 RPC_READY:67:true X1:1205:{""test_index"":3} X2:1210:a8feb81e-270f-4def-8216-4f179bd1f5e2/2 TOKENS:54:<hidden> ",test-file | test-file | test-file | test-file | test-file | test-file | source-file,"Elassandra assertion error on bulk update **Elassandra version**: 6.2.3.10 **Plugins installed**: [] **JVM version** (`java -version`):  openjdk version ""1.8.0_181"" OpenJDK Runtime Environment (build 1.8.0_181-8u181-b13-2~deb9u1-b13) OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode)  **OS version** (`uname -a` if on a Unix-like system): Ubuntu 18.04 **Description of the problem including expected versus actual behavior**: Conditional bulk update fails in elassandra but works in elasticsearch 6.2.3 **Steps to reproduce**: 1. Create an index and add data `curl -XPOST -H 'content-type: application/json' http://172.17.0.3:9200/test_index/user -d '{""projects"":[""p1"", ""p2""]}'` 2. Run the below command  curl -XPOST -H 'content-type: application/json' http://172.17.0.3:9200/_bulk -d ' {""update"":{""_index"":""test_index"",""_type"":""user"",""_id"":""e8druWkBu-AlXJ3uggHp""}} {""script"":{""source"": ""if (!ctx._source.projects.contains(params.project)) {ctx._source.projects.add(params.project)}"",""params"":{""project"":""p3"" ' '  3. Curl statement never gave any response back. I checked the result in elastic seach and found that data got updated but Cassandra system.log shows an AssertionError  2019-03-26 09:56:19,228 ERROR [elasticsearch[172.17.0.3][bulk][T#2]] CassandraDaemon.java:231 uncaughtException Exception in thread Thread[elasticsearch[172.17.0.3][bulk][T#2],5,main] java.lang.AssertionError: failed result should not have a sequence number at org.elasticsearch.action.bulk.TransportShardBulkAction.processUpdateResponse(TransportShardBulkAction.java:289) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeUpdateRequestOnce(TransportShardBulkAction.java:393) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeUpdateRequest(TransportShardBulkAction.java:419) at org.elasticsearch.action.bulk.TransportShardBulkAction.executeBulkItemRequest(TransportShardBulkAction.java:250) at org.elasticsearch.action.bulk.TransportShardBulkAction.performOnPrimary(TransportShardBulkAction.java:129) at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:115) at org.elasticsearch.action.bulk.TransportShardBulkAction.shardOperationOnPrimary(TransportShardBulkAction.java:73) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1065) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryShardReference.perform(TransportReplicationAction.java:1043) at org.elasticsearch.action.support.replication.ReplicationOperation.execute(ReplicationOperation.java:104) at org.elasticsearch.action.support.replication.TransportReplicationAction$AsyncPrimaryAction.doRun(TransportReplicationAction.java:331) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:297) at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:284) at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:66) at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:661) at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:672) at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)  **Please provide the following information: * elassandra logs (logs/system.logs or /var/lib/cassandra/system.log) : Added above * elasticsearch cluster state (curl http://localhost:9200/_cluster/state):  { ""cluster_name"": ""Test Cluster"", ""compressed_size_in_bytes"": 501, ""version"": 9, ""state_uuid"": ""QtmmOC9dS8SMAGeppPEduw"", ""master_node"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""blocks"": {}, ""nodes"": { ""a8feb81e-270f-4def-8216-4f179bd1f5e2"": { ""name"": ""172.17.0.3"", ""status"": ""ALIVE"", ""ephemeral_id"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""transport_address"": ""172.17.0.3:9300"", ""attributes"": { ""rack"": ""r1"", ""dc"": ""DC1"" } } }, ""metadata"": { ""version"": 2, ""cluster_uuid"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""templates"": {}, ""indices"": { ""test_index"": { ""state"": ""open"", ""settings"": { ""index"": { ""creation_date"": ""1553594023962"", ""number_of_shards"": ""1"", ""number_of_replicas"": ""0"", ""uuid"": ""jKfz0fVyRnKTBrsNuBZeQQ"", ""version"": { ""created"": ""6020399"" }, ""provided_name"": ""test_index"" } }, ""mappings"": { ""user"": { ""properties"": { ""projects"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""ignore_above"": 256, ""type"": ""keyword"" } } } } } }, ""aliases"": [], ""primary_terms"": { ""0"": 0 }, ""in_sync_allocations"": { ""0"": [] } } }, ""index-graveyard"": { ""tombstones"": [] } }, ""routing_table"": { ""indices"": { ""test_index"": { ""shards"": { ""0"": [ { ""state"": ""STARTED"", ""primary"": true, ""node"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""relocating_node"": null, ""shard"": 0, ""index"": ""test_index"", ""token_ranges"": [ ""(-9223372036854775808,9223372036854775807]"" ], ""allocation_id"": { ""id"": ""dummy_alloc_id"" } } ] } } } }, ""routing_nodes"": { ""unassigned"": [], ""nodes"": { ""a8feb81e-270f-4def-8216-4f179bd1f5e2"": [ { ""state"": ""STARTED"", ""primary"": true, ""node"": ""a8feb81e-270f-4def-8216-4f179bd1f5e2"", ""relocating_node"": null, ""shard"": 0, ""index"": ""test_index"", ""token_ranges"": [ ""(-9223372036854775808,9223372036854775807]"" ], ""allocation_id"": { ""id"": ""dummy_alloc_id"" } } ] } }, ""snapshot_deletions"": { ""snapshot_deletions"": [] }, ""snapshots"": { ""snapshots"": [] }, ""restore"": { ""snapshots"": [] } }  * cassandra schema (cqlsh>DESC KEYSPACE <your_keyspace>)  CREATE KEYSPACE test_index WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '1'} AND durable_writes = true; CREATE TABLE test_index.user ( ""_id"" text PRIMARY KEY, projects list<text> ) WITH bloom_filter_fp_chance = 0.01 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'} AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND crc_check_chance = 1.0 AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99PERCENTILE'; CREATE CUSTOM INDEX elastic_user_idx ON test_index.user () USING 'org.elassandra.index.ExtendedElasticSecondaryIndex';  * cassandra gossip state (run: nodetool gossipinfo)  /172.17.0.3 generation:1553592898 heartbeat:1706 STATUS:55:NORMAL,-2180626626081522229 LOAD:1661:113785.0 SCHEMA:1208:ab8b61c6-d700-3c2e-ae37-51b6bc17d07b DC:8:DC1 RACK:10:r1 RELEASE_VERSION:4:3.11.3.5 INTERNAL_IP:6:172.17.0.3 RPC_ADDRESS:3:172.17.0.3 NET_VERSION:1:11 HOST_ID:2:a8feb81e-270f-4def-8216-4f179bd1f5e2 RPC_READY:67:true X1:1205:{""test_index"":3} X2:1210:a8feb81e-270f-4def-8216-4f179bd1f5e2/2 TOKENS:54:<hidden>  test-file test-file test-file test-file test-file test-file source-file",no-bug,0.9
8,elassandra,https://github.com/strapdata/elassandra/issues/8,Frozen Columns,Why all columns are frozen columns and not only the data type?,config-file,Frozen Columns Why all columns are frozen columns and not only the data type? config-file,no-bug,0.9
191,elassandra,https://github.com/strapdata/elassandra/issues/191,Elassandra 5.5.0.15,"Team, I updated to 5.5.0.15. It does not start. I roll back to 5.5.0.13 works fine. Here is the log Starting cassandra with org.apache.cassandra.service.ElassandraDaemon 2018-05-09 16:01:50,118 INFO [main] org.apache.cassandra.config.YamlConfigurationLoader.getStorageConfigURL(YamlConfigurationLoader.java:89) Configuration location: file:/opt/elassandra-5.5.0.15/conf/cassandra.yaml 2018-05-09 16:01:50,743 INFO [main] org.apache.cassandra.config.Config.log(Config.java:495) Node configuration:[allocate_tokens_for_keyspace=null; authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=true; auto_snapshot=true; back_pressure_enabled=false; back_pressure_strategy=null; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; broadcast_address=10.233.117.217; broadcast_rpc_address=10.233.117.217; buffer_pool_use_heap_if_exhausted=true; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=null; cdc_total_space_in_mb=0; client_encryption_options=<REDACTED>; cluster_name=Cassandra; column_index_cache_size_in_kb=2; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=null; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_batch_window_in_ms=NaN; commitlog_sync_period_in_ms=10000; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=16; concurrent_compactors=null; concurrent_counter_writes=32; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_writes=32; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=false; data_file_directories=[Ljava.lang.String;@19bb07ed; disk_access_mode=auto; disk_failure_policy=stop; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_materialized_views=true; enable_scripted_user_defined_functions=false; enable_user_defined_functions=false; enable_user_defined_functions_threads=true; encryption_options=null; endpoint_snitch=GossipingPropertyFileSnitch; file_cache_round_up=null; file_cache_size_in_mb=null; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=null; hints_flush_period_in_ms=10000; incremental_backups=false; index_interval=null; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=false; internode_authenticator=null; internode_compression=all; internode_recv_buff_size_in_bytes=0; internode_send_buff_size_in_bytes=0; key_cache_keys_to_save=2147483647; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=10.233.117.217; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=null; memtable_flush_writers=0; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_threads=128; native_transport_port=9042; native_transport_port_ssl=null; num_tokens=8; otc_backlog_expiration_interval_ms=200; otc_coalescing_enough_coalesced_messages=8; otc_coalescing_strategy=DISABLED; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=null; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_scheduler_id=null; request_scheduler_options=null; request_timeout_in_ms=10000; role_manager=CassandraRoleManager; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=0.0.0.0; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; rpc_listen_backlog=50; rpc_max_threads=2147483647; rpc_min_threads=16; rpc_port=9160; rpc_recv_buff_size_in_bytes=null; rpc_send_buff_size_in_bytes=null; rpc_server_type=sync; saved_caches_directory=null; seed_provider=org.apache.cassandra.locator.SimpleSeedProvider{seeds=elassandra-0.elassandra.bigdata.svc.cluster.local}; server_encryption_options=<REDACTED>; slow_query_log_timeout_in_ms=500; snapshot_before_compaction=false; ssl_storage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=false; storage_port=7000; stream_throughput_outbound_megabits_per_sec=200; streaming_keep_alive_period_in_secs=300; streaming_socket_timeout_in_ms=86400000; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; thrift_prepared_statements_cache_size_mb=null; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@10e41621; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; windows_timer_interval=1; write_request_timeout_in_ms=5000] 2018-05-09 16:01:50,744 INFO [main] org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:367) DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap 2018-05-09 16:01:50,745 INFO [main] org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:425) Global memtable on-heap threshold is enabled at 2043MB 2018-05-09 16:01:50,746 INFO [main] org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:429) Global memtable off-heap threshold is enabled at 2043MB 2018-05-09 16:01:50,995 INFO [main] org.apache.cassandra.net.RateBasedBackPressure.<init>(RateBasedBackPressure.java:123) Initialized back-pressure with high ratio: 0.9, factor: 5, flow: FAST, window size: 5000. 2018-05-09 16:01:50,996 INFO [main] org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:729) Back-pressure is disabled with strategy null. 2018-05-09 16:01:51,220 INFO [main] org.apache.cassandra.locator.GossipingPropertyFileSnitch.<init>(GossipingPropertyFileSnitch.java:64) Loaded cassandra-topology.properties for compatibility 2018-05-09 16:01:56,313 INFO [ScheduledTasks:1] org.apache.cassandra.locator.TokenMetadata.updateTopology(TokenMetadata.java:498) Updating topology for all endpoints that have changed 2018-05-09 16:01:58,627 INFO [main] org.apache.cassandra.cql3.QueryProcessor.<clinit>(QueryProcessor.java:116) Initialized prepared statement caches with 31 MB (native) and 31 MB (Thrift) 2018-05-09 16:01:59,970 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.IndexInfo 2018-05-09 16:02:01,729 INFO [SSTableBatchOpen:1] org.apache.cassandra.utils.memory.BufferPool$GlobalPool.<clinit>(BufferPool.java:230) Global buffer pool is enabled, when pool is exhausted (max is 512.000MiB) it will allocate on heap 2018-05-09 16:02:02,075 INFO [main] org.apache.cassandra.service.CacheService.initKeyCache(CacheService.java:112) Initializing key cache with capacity of 100 MBs. 2018-05-09 16:02:02,091 INFO [main] org.apache.cassandra.service.CacheService.initRowCache(CacheService.java:134) Initializing row cache with capacity of 0 MBs 2018-05-09 16:02:02,099 INFO [main] org.apache.cassandra.service.CacheService.initCounterCache(CacheService.java:163) Initializing counter cache with capacity of 50 MBs 2018-05-09 16:02:02,111 INFO [main] org.apache.cassandra.service.CacheService.initCounterCache(CacheService.java:174) Scheduling counter cache save to every 7200 seconds (going to save all keys). 2018-05-09 16:02:02,198 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.batches 2018-05-09 16:02:02,236 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.paxos 2018-05-09 16:02:02,289 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.local 2018-05-09 16:02:02,329 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.peers 2018-05-09 16:02:02,373 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.peer_events 2018-05-09 16:02:02,384 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.range_xfers 2018-05-09 16:02:02,395 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.compaction_history 2018-05-09 16:02:02,421 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.sstable_activity 2018-05-09 16:02:02,452 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.size_estimates 2018-05-09 16:02:02,488 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.available_ranges 2018-05-09 16:02:02,504 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.transferred_ranges 2018-05-09 16:02:02,515 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.views_builds_in_progress 2018-05-09 16:02:02,523 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.built_views 2018-05-09 16:02:02,531 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.hints 2018-05-09 16:02:02,541 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.batchlog 2018-05-09 16:02:02,553 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.prepared_statements 2018-05-09 16:02:02,576 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_keyspaces 2018-05-09 16:02:02,586 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_columnfamilies 2018-05-09 16:02:02,594 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_columns 2018-05-09 16:02:02,602 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_triggers 2018-05-09 16:02:02,611 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_usertypes 2018-05-09 16:02:02,619 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_functions 2018-05-09 16:02:02,628 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_aggregates 2018-05-09 16:02:02,631 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system as storage service is not initialized 2018-05-09 16:02:02,901 INFO [main] org.apache.cassandra.db.monitoring.ApproximateTime.<clinit>(ApproximateTime.java:44) Scheduling approximate time-check task with a precision of 10 milliseconds 2018-05-09 16:02:08,354 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/QHR0roXvQ66LICG3aZltZA] no index state found - ignoring 2018-05-09 16:02:08,358 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/wQc51tfdQYCmPBffGmgykw] no index state found - ignoring 2018-05-09 16:02:08,360 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/Mw5gBIs8Q-2ZRp1REikJCA] no index state found - ignoring 2018-05-09 16:02:08,363 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/ntyLLHQwQmqAy0Kxd3dZfg] no index state found - ignoring 2018-05-09 16:02:08,365 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/nUIEpqJHR8eqweFbrp8hhA] no index state found - ignoring 2018-05-09 16:02:08,369 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/0A5Tb-GXQrSpmN1oeBDhQQ] no index state found - ignoring 2018-05-09 16:02:08,370 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/zUNifXgSRKyiSv_49_FWJg] no index state found - ignoring 2018-05-09 16:02:08,372 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/huOQhYWQT1WO90QXwADvsA] no index state found - ignoring 2018-05-09 16:02:08,379 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/60q4nNzrTqSqTd5ztckASw] no index state found - ignoring 2018-05-09 16:02:08,380 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/cRLgf28HRH-ygrOUywGCtQ] no index state found - ignoring 2018-05-09 16:02:08,381 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/PvumvsazTgyJnPisTHuRFA] no index state found - ignoring 2018-05-09 16:02:08,382 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/_a1JvbgAR3-NPZdRUzywAg] no index state found - ignoring 2018-05-09 16:02:09,090 INFO [main] org.apache.cassandra.utils.JMXServerUtils.logJmxServiceUrl(JMXServerUtils.java:246) Configured JMX server at: service:jmx:rmi://127.0.0.1/jndi/rmi://127.0.0.1:7199/jmxrmi 2018-05-09 16:02:09,119 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:481) Hostname: elassandra-0.elassandra.bigdata.svc.cluster.local 2018-05-09 16:02:09,120 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:488) JVM vendor/version: OpenJDK 64-Bit Server VM/1.8.0_162 2018-05-09 16:02:09,122 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:489) Heap size: 7.980GiB/7.980GiB 2018-05-09 16:02:09,123 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Code Cache Non-heap memory: init = 2555904(2496K) used = 11208128(10945K) committed = 11403264(11136K) max = 251658240(245760K) 2018-05-09 16:02:09,124 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Metaspace Non-heap memory: init = 0(0K) used = 59219680(57831K) committed = 62316544(60856K) max = -1(-1K) 2018-05-09 16:02:09,125 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Compressed Class Space Non-heap memory: init = 0(0K) used = 8428504(8230K) committed = 9531392(9308K) max = 1073741824(1048576K) 2018-05-09 16:02:09,125 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Par Eden Space Heap memory: init = 167772160(163840K) used = 167772160(163840K) committed = 167772160(163840K) max = 167772160(163840K) 2018-05-09 16:02:09,126 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Par Survivor Space Heap memory: init = 20971520(20480K) used = 20971520(20480K) committed = 20971520(20480K) max = 20971520(20480K) 2018-05-09 16:02:09,140 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) CMS Old Gen Heap memory: init = 8380219392(8183808K) used = 23008080(22468K) committed = 8380219392(8183808K) max = 8380219392(8183808K) 2018-05-09 16:02:09,141 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:496) Classpath: /opt/elassandra-5.5.0.15/conf:/opt/elassandra-5.5.0.15/lib/HdrHistogram-2.1.9.jar:/opt/elassandra-5.5.0.15/lib/ST4-4.0.8.jar:/opt/elassandra-5.5.0.15/lib/airline-0.6.jar:/opt/elassandra-5.5.0.15/lib/ant-1.7.0.jar:/opt/elassandra-5.5.0.15/lib/ant-launcher-1.7.0.jar:/opt/elassandra-5.5.0.15/lib/antlr-3.5.2.jar:/opt/elassandra-5.5.0.15/lib/antlr-runtime-3.5.2.jar:/opt/elassandra-5.5.0.15/lib/caffeine-2.2.6.jar:/opt/elassandra-5.5.0.15/lib/cassandra-all-3.11.2.jar:/opt/elassandra-5.5.0.15/lib/cassandra-driver-core-3.0.1-shaded.jar:/opt/elassandra-5.5.0.15/lib/cassandra-thrift-3.11.2.jar:/opt/elassandra-5.5.0.15/lib/commons-cli-1.3.1.jar:/opt/elassandra-5.5.0.15/lib/commons-codec-1.10.jar:/opt/elassandra-5.5.0.15/lib/commons-lang3-3.3.1.jar:/opt/elassandra-5.5.0.15/lib/commons-logging-1.2.jar:/opt/elassandra-5.5.0.15/lib/commons-math3-3.2.jar:/opt/elassandra-5.5.0.15/lib/compress-lzf-0.8.4.jar:/opt/elassandra-5.5.0.15/lib/concurrent-trees-2.4.0.jar:/opt/elassandra-5.5.0.15/lib/concurrentlinkedhashmap-lru-1.4.jar:/opt/elassandra-5.5.0.15/lib/disruptor-3.0.1.jar:/opt/elassandra-5.5.0.15/lib/ecj-4.4.2.jar:/opt/elassandra-5.5.0.15/lib/elasticsearch-5.5.0.jar:/opt/elassandra-5.5.0.15/lib/fastutil-6.5.7.jar:/opt/elassandra-5.5.0.15/lib/guava-19.0.jar:/opt/elassandra-5.5.0.15/lib/hibernate-validator-4.3.0.Final.jar:/opt/elassandra-5.5.0.15/lib/high-scale-lib-1.0.6.jar:/opt/elassandra-5.5.0.15/lib/hppc-0.7.1.jar:/opt/elassandra-5.5.0.15/lib/httpclient-4.5.2.jar:/opt/elassandra-5.5.0.15/lib/httpcore-4.4.5.jar:/opt/elassandra-5.5.0.15/lib/jackson-core-2.8.6.jar:/opt/elassandra-5.5.0.15/lib/jackson-core-asl-1.9.13.jar:/opt/elassandra-5.5.0.15/lib/jackson-dataformat-cbor-2.8.6.jar:/opt/elassandra-5.5.0.15/lib/jackson-dataformat-smile-2.8.6.jar:/opt/elassandra-5.5.0.15/lib/jackson-dataformat-yaml-2.8.6.jar:/opt/elassandra-5.5.0.15/lib/jackson-mapper-asl-1.9.13.jar:/opt/elassandra-5.5.0.15/lib/java-version-checker-5.5.0.jar:/opt/elassandra-5.5.0.15/lib/javassist-3.20.0-GA.jar:/opt/elassandra-5.5.0.15/lib/javax.inject-1.jar:/opt/elassandra-5.5.0.15/lib/jbcrypt-0.3m.jar:/opt/elassandra-5.5.0.15/lib/jboss-logging-3.1.0.CR2.jar:/opt/elassandra-5.5.0.15/lib/jcl-over-slf4j-1.7.7.jar:/opt/elassandra-5.5.0.15/lib/jctools-core-1.2.1.jar:/opt/elassandra-5.5.0.15/lib/jflex-1.6.0.jar:/opt/elassandra-5.5.0.15/lib/jna-4.4.0.jar:/opt/elassandra-5.5.0.15/lib/joda-time-2.9.5.jar:/opt/elassandra-5.5.0.15/lib/jopt-simple-5.0.2.jar:/opt/elassandra-5.5.0.15/lib/json-simple-1.1.jar:/opt/elassandra-5.5.0.15/lib/jts-1.13.jar:/opt/elassandra-5.5.0.15/lib/libthrift-0.9.2.jar:/opt/elassandra-5.5.0.15/lib/log4j-api-2.8.2.jar:/opt/elassandra-5.5.0.15/lib/log4j-core-2.8.2.jar:/opt/elassandra-5.5.0.15/lib/log4j-over-slf4j-1.7.7.jar:/opt/elassandra-5.5.0.15/lib/log4j-to-slf4j-2.8.2.jar:/opt/elassandra-5.5.0.15/lib/logback-classic-1.1.8.jar:/opt/elassandra-5.5.0.15/lib/logback-core-1.1.8.jar:/opt/elassandra-5.5.0.15/lib/lucene-analyzers-common-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-backward-codecs-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-core-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-grouping-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-highlighter-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-join-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-memory-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-misc-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-queries-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-queryparser-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-sandbox-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-spatial-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-spatial-extras-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-spatial3d-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-suggest-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lz4-1.3.0.jar:/opt/elassandra-5.5.0.15/lib/metrics-core-3.1.0.jar:/opt/elassandra-5.5.0.15/lib/metrics-jvm-3.1.0.jar:/opt/elassandra-5.5.0.15/lib/netty-all-4.1.12.Final.jar:/opt/elassandra-5.5.0.15/lib/ohc-core-0.4.4.jar:/opt/elassandra-5.5.0.15/lib/plugin-cli-5.5.0.jar:/opt/elassandra-5.5.0.15/lib/reporter-config-base-3.0.3.jar:/opt/elassandra-5.5.0.15/lib/reporter-config3-3.0.3.jar:/opt/elassandra-5.5.0.15/lib/securesm-1.1.jar:/opt/elassandra-5.5.0.15/lib/sigar-1.6.4.jar:/opt/elassandra-5.5.0.15/lib/slf4j-api-1.7.25.jar:/opt/elassandra-5.5.0.15/lib/snakeyaml-1.15.jar:/opt/elassandra-5.5.0.15/lib/snappy-java-1.1.1.7.jar:/opt/elassandra-5.5.0.15/lib/spatial4j-0.6.jar:/opt/elassandra-5.5.0.15/lib/stream-2.5.2.jar:/opt/elassandra-5.5.0.15/lib/t-digest-3.0.jar:/opt/elassandra-5.5.0.15/lib/thrift-server-0.3.7.jar:/opt/elassandra-5.5.0.15/lib/validation-api-1.0.0.GA.jar:/opt/elassandra-5.5.0.15/lib/jamm-0.3.0.jar 2018-05-09 16:02:09,147 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:498) JVM Arguments: [-Djava.library.path=/opt/elassandra-5.5.0.15/lib/sigar-bin, -Xloggc:/opt/elassandra-5.5.0.15/logs/gc.log, -ea, -XX:+UseThreadPriorities, -XX:ThreadPriorityPolicy=42, -XX:+HeapDumpOnOutOfMemoryError, -Xss256k, -XX:StringTableSize=1000003, -XX:+AlwaysPreTouch, -XX:-UseBiasedLocking, -XX:+UseTLAB, -XX:+ResizeTLAB, -XX:+UseNUMA, -XX:+PerfDisableSharedMem, -Djava.net.preferIPv4Stack=true, -XX:+UseParNewGC, -XX:+UseConcMarkSweepGC, -XX:+CMSParallelRemarkEnabled, -XX:SurvivorRatio=8, -XX:MaxTenuringThreshold=1, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:CMSWaitDuration=10000, -XX:+CMSParallelInitialMarkEnabled, -XX:+CMSEdenChunksRecordAlways, -XX:+CMSClassUnloadingEnabled, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -XX:+PrintHeapAtGC, -XX:+PrintTenuringDistribution, -XX:+PrintGCApplicationStoppedTime, -XX:+PrintPromotionFailure, -XX:+UseGCLogFileRotation, -XX:NumberOfGCLogFiles=10, -XX:GCLogFileSize=10M, -Xms8192M, -Xmx8192M, -Xmn200M, -XX:CompileCommandFile=/opt/elassandra-5.5.0.15/conf/hotspot_compiler, -javaagent:/opt/elassandra-5.5.0.15/lib/jamm-0.3.0.jar, -Dcassandra.jmx.local.port=7199, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.password.file=/etc/cassandra/jmxremote.password, -Djava.library.path=/opt/elassandra-5.5.0.15/lib/sigar-bin, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djdk.io.permissionsUseCanonicalPath=true, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j.skipJansi=true, -Dcassandra.libjemalloc=/usr/lib/x86_64-linux-gnu/libjemalloc.so.1, -Djava.awt.headless=true, -Dlogback.configurationFile=/opt/elassandra-5.5.0.15/conf/logback.xml, -Dcassandra.logdir=/var/log/cassandra, -Dcassandra.storagedir=/opt/elassandra-5.5.0.15/data, -Dcassandra-pidfile=/opt/elassandra-5.5.0.15/cassandra.pid, -Dcassandra-foreground=yes] 2018-05-09 16:02:09,471 INFO [main] org.apache.cassandra.utils.NativeLibrary.tryMlockall(NativeLibrary.java:174) JNA mlockall successful 2018-05-09 16:02:09,490 INFO [main] org.apache.cassandra.service.StartupChecks$1.execute(StartupChecks.java:140) jemalloc seems to be preloaded from /usr/lib/x86_64-linux-gnu/libjemalloc.so.1 2018-05-09 16:02:09,491 WARN [main] org.apache.cassandra.service.StartupChecks$3.execute(StartupChecks.java:169) JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info. 2018-05-09 16:02:09,496 WARN [main] org.apache.cassandra.service.StartupChecks$5.checkOutOfMemoryHandling(StartupChecks.java:220) The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError: -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError=""<cmd args>;<cmd args>"" 2018-05-09 16:02:09,503 INFO [main] org.apache.cassandra.utils.SigarLibrary.<init>(SigarLibrary.java:44) Initializing SIGAR library OpenJDK 64-Bit Server VM warning: You have loaded library /opt/elassandra-5.5.0.15/lib/sigar-bin/libsigar-amd64-linux.so which might have disabled stack guard. The VM will try to fix the stack guard now. It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'. 2018-05-09 16:02:09,534 INFO [main] org.apache.cassandra.utils.SigarLibrary.<init>(SigarLibrary.java:57) Could not initialize SIGAR library org.hyperic.sigar.Sigar.getFileSystemListNative()[Lorg/hyperic/sigar/FileSystem; 2018-05-09 16:02:09,535 INFO [main] org.apache.cassandra.utils.SigarLibrary.warnIfRunningInDegradedMode(SigarLibrary.java:185) Sigar could not be initialized, test for checking degraded mode omitted. 2018-05-09 16:02:09,536 WARN [main] org.apache.cassandra.service.StartupChecks$8.execute(StartupChecks.java:311) Maximum number of memory map areas per process (vm.max_map_count) 65530 is too low, recommended value: 1048575, you can change it with sysctl. 2018-05-09 16:02:10,389 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.keyspaces 2018-05-09 16:02:10,470 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.tables 2018-05-09 16:02:10,541 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.columns 2018-05-09 16:02:10,616 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.triggers 2018-05-09 16:02:10,693 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.dropped_columns 2018-05-09 16:02:10,758 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.views 2018-05-09 16:02:10,838 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.types 2018-05-09 16:02:10,912 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.functions 2018-05-09 16:02:10,982 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.aggregates 2018-05-09 16:02:11,175 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.indexes 2018-05-09 16:02:11,194 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system_schema as storage service is not initialized 2018-05-09 16:02:12,022 INFO [main] org.apache.cassandra.service.StorageService.populateTokenMetadata(StorageService.java:600) Populating token metadata from system tables 2018-05-09 16:02:12,086 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8362130585556172891 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,087 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6791530300178346392 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,088 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -959123631124296270 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,089 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -2906258939937529727 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,090 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5701683067600102763 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,092 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 7776769257334882293 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,092 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 3566883655066165006 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,093 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5633264194489195507 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,100 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -362226123124935217 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,101 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8401438299379969757 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,105 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6275689832852561075 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,109 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4451716466158730928 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,111 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -6090579284089889517 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,114 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4631534558835767927 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,115 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8914019774812791023 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,116 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8592977458636693389 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,117 INFO [main] org.apache.cassandra.service.StorageService.populateTokenMetadata(StorageService.java:607) Token metadata: Normal Tokens: /10.233.90.28:[-8362130585556172891, -2906258939937529727, -959123631124296270, 3566883655066165006, 5633264194489195507, 5701683067600102763, 6791530300178346392, 7776769257334882293] /10.233.97.141:[-8248027387514132260, -7318731352128861107, -861916047897630515, 3049595437829094990, 3681862537357852614, 7941763563148319339, 8234545346034199838, 9073971229396420877] /10.233.114.185:[-9048183706652428987, -5086691515524827064, -4260497491636981485, -4164481151685738517, -1054867843544454931, 4437679225950754397, 5141005615383236012, 6372063045572782995] /10.233.117.217:[-7227302454714817399, -5939375512383729793, -2206250258799490034, 1732568509439143634, 2600887383460939089, 4748189529193459068, 8796692000955143727, 9083020370715658495] /10.233.121.123:[-3299701738014063480, -2539197605680580109, -1839508776458638598, -118864622025183534, 1111019062840381676, 6132333345085630748, 6774441214942613853, 8907766337491345741] /10.233.122.175:[-8592977458636693389, -6090579284089889517, -362226123124935217, 4451716466158730928, 4631534558835767927, 6275689832852561075, 8401438299379969757, 8914019774812791023] 2018-05-09 16:02:13,068 INFO [main] org.apache.cassandra.service.ElassandraDaemon.activateAndWaitShards(ElassandraDaemon.java:366) Activating Elasticsearch, shards starting before opening user keyspaces 2018-05-09 16:02:13,546 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.wmsskuet' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:13,546 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.wmsskuet' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,025 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.carrierperf' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,026 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.carrierperf' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,084 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.bob_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,085 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.bob_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,134 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.prdedi' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,135 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.prdedi' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,195 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.gtnx_shipment_v2' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,196 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.gtnx_shipment_v2' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,321 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.gtnx_shipment_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,322 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.gtnx_shipment_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,416 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.driverperf_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,417 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.driverperf_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,551 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.gtnx_purchase_order' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,559 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.gtnx_purchase_order' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,712 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query..kibana' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,735 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch..kibana' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,975 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.twitter' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,975 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.twitter' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:15,034 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.poc_training' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:15,051 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.poc_training' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:15,302 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.elassandra.gateway.CassandraGatewayService$GatewayRecoveryListener$1.clusterStateProcessed(CassandraGatewayService.java:134) Recovered [11] indices into cluster_state 2018-05-09 16:02:15,312 INFO [main] org.apache.cassandra.service.ElassandraDaemon.activateAndWaitShards(ElassandraDaemon.java:370) Elasticsearch shards started, ready to go on. 2018-05-09 16:02:15,850 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing driverperf.driverperf 2018-05-09 16:02:15,907 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace driverperf as storage service is not initialized 2018-05-09 16:02:15,937 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_traces.events 2018-05-09 16:02:15,966 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_traces.sessions 2018-05-09 16:02:15,983 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system_traces as storage service is not initialized 2018-05-09 16:02:16,002 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing wmsskuet.wmsskuet 2018-05-09 16:02:16,331 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[wmsskuet.wmsskuet] hashCode=1279536741 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:16,337 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace wmsskuet as storage service is not initialized 2018-05-09 16:02:16,350 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[wmsskuet.wmsskuet] initialized, metadata.version=128 mappingInfo.indices=wmsskuet typeName=wmsskuet 2018-05-09 16:02:16,407 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing twitter.tweet 2018-05-09 16:02:16,432 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[twitter.tweet] hashCode=1590802853 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:16,434 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[twitter.tweet] initialized, metadata.version=128 mappingInfo.indices=twitter typeName=tweet 2018-05-09 16:02:16,468 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing twitter.user 2018-05-09 16:02:16,510 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[twitter.user] hashCode=329594950 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:16,512 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[twitter.user] initialized, metadata.version=128 mappingInfo.indices=twitter typeName=user 2018-05-09 16:02:16,515 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace twitter as storage service is not initialized 2018-05-09 16:02:16,544 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_distributed.parent_repair_history 2018-05-09 16:02:16,594 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_distributed.repair_history 2018-05-09 16:02:16,642 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_distributed.view_build_status 2018-05-09 16:02:16,648 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system_distributed as storage service is not initialized 2018-05-09 16:02:16,686 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing prdedi.prdedi 2018-05-09 16:02:17,100 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[prdedi.prdedi] hashCode=964590191 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,102 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[prdedi.prdedi] initialized, metadata.version=128 mappingInfo.indices=prdedi typeName=prdedi 2018-05-09 16:02:17,105 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace prdedi as storage service is not initialized 2018-05-09 16:02:17,124 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing gtnx_shipment_v2.gtnx_shipment_v2 2018-05-09 16:02:17,140 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[gtnx_shipment_v2.gtnx_shipment_v2] hashCode=179287420 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,144 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[gtnx_shipment_v2.gtnx_shipment_v2] initialized, metadata.version=128 mappingInfo.indices=gtnx_shipment_v2 typeName=gtnx_shipment_v2 2018-05-09 16:02:17,145 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace gtnx_shipment_v2 as storage service is not initialized 2018-05-09 16:02:17,182 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing gtnx_purchase_order.gtnx_purchase_order 2018-05-09 16:02:17,229 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[gtnx_purchase_order.gtnx_purchase_order] hashCode=1507866909 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,232 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[gtnx_purchase_order.gtnx_purchase_order] initialized, metadata.version=128 mappingInfo.indices=gtnx_purchase_order typeName=gtnx_purchase_order 2018-05-09 16:02:17,234 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace gtnx_purchase_order as storage service is not initialized 2018-05-09 16:02:17,254 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing driverperf_2.driverperf_2 2018-05-09 16:02:17,272 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace driverperf_2 as storage service is not initialized 2018-05-09 16:02:17,322 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing gtnx_shipment_v1.gtnx_shipment_v1 2018-05-09 16:02:17,349 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[gtnx_shipment_v1.gtnx_shipment_v1] hashCode=1673354607 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,352 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[gtnx_shipment_v1.gtnx_shipment_v1] initialized, metadata.version=128 mappingInfo.indices=gtnx_shipment_v1 typeName=gtnx_shipment_v1 2018-05-09 16:02:17,354 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace gtnx_shipment_v1 as storage service is not initialized 2018-05-09 16:02:17,378 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.config 2018-05-09 16:02:17,407 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.config] hashCode=702217845 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,409 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.config] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=config 2018-05-09 16:02:17,428 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.dashboard 2018-05-09 16:02:17,435 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.dashboard] hashCode=1588181607 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,437 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.dashboard] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=dashboard 2018-05-09 16:02:17,480 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.index_pattern 2018-05-09 16:02:17,527 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.index_pattern] hashCode=114907262 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,529 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.index_pattern] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=index-pattern 2018-05-09 16:02:17,542 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.search 2018-05-09 16:02:17,563 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.search] hashCode=252066799 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,565 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.search] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=search 2018-05-09 16:02:17,585 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.server 2018-05-09 16:02:17,593 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.server] hashCode=1901151532 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,595 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.server] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=server 2018-05-09 16:02:17,610 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.timelion_sheet 2018-05-09 16:02:17,633 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.timelion_sheet] hashCode=1656271843 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,635 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.timelion_sheet] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=timelion-sheet 2018-05-09 16:02:17,646 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.url 2018-05-09 16:02:17,654 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.url] hashCode=787357026 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,655 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.url] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=url 2018-05-09 16:02:17,671 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.visualization 2018-05-09 16:02:17,681 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace _kibana as storage service is not initialized 2018-05-09 16:02:17,681 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.visualization] hashCode=269062675 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,683 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.visualization] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=visualization 2018-05-09 16:02:17,717 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing elastic_admin.metadata 2018-05-09 16:02:17,977 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace elastic_admin as storage service is not initialized 2018-05-09 16:02:18,015 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing driverperf_v1.driverperf_v1 2018-05-09 16:02:18,086 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[driverperf_v1.driverperf_v1] hashCode=1804262683 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,086 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace driverperf_v1 as storage service is not initialized 2018-05-09 16:02:18,088 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[driverperf_v1.driverperf_v1] initialized, metadata.version=128 mappingInfo.indices=driverperf_v1 typeName=driverperf_v1 2018-05-09 16:02:18,129 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing carrierperf.carrierperf 2018-05-09 16:02:18,330 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[carrierperf.carrierperf] hashCode=1284135970 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,330 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace carrierperf as storage service is not initialized 2018-05-09 16:02:18,337 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[carrierperf.carrierperf] initialized, metadata.version=128 mappingInfo.indices=carrierperf typeName=carrierperf 2018-05-09 16:02:18,364 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing bob_v1.bob_v1 2018-05-09 16:02:18,375 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace bob_v1 as storage service is not initialized 2018-05-09 16:02:18,375 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[bob_v1.bob_v1] hashCode=307322332 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,379 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[bob_v1.bob_v1] initialized, metadata.version=128 mappingInfo.indices=bob_v1 typeName=bob_v1 2018-05-09 16:02:18,392 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_auth.resource_role_permissons_index 2018-05-09 16:02:18,401 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_auth.role_members 2018-05-09 16:02:18,420 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_auth.role_permissions 2018-05-09 16:02:18,444 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_auth.roles 2018-05-09 16:02:18,455 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system_auth as storage service is not initialized 2018-05-09 16:02:18,501 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing poc_training.data 2018-05-09 16:02:18,518 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[poc_training.data] hashCode=1309990031 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,520 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[poc_training.data] initialized, metadata.version=128 mappingInfo.indices=poc_training typeName=data 2018-05-09 16:02:18,526 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing poc_training.poc_training 2018-05-09 16:02:18,530 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace poc_training as storage service is not initialized 2018-05-09 16:02:18,530 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[poc_training.poc_training] hashCode=1934340691 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,532 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[poc_training.poc_training] initialized, metadata.version=128 mappingInfo.indices=poc_training typeName=poc_training 2018-05-09 16:02:18,607 INFO [pool-5-thread-1] org.apache.cassandra.cache.AutoSavingCache.loadSaved(AutoSavingCache.java:197) reading saved cache /opt/elassandra-5.5.0.15/data/saved_caches/KeyCache-e.db 2018-05-09 16:02:18,648 INFO [pool-5-thread-1] org.apache.cassandra.cache.AutoSavingCache.loadSaved(AutoSavingCache.java:262) Harmless error reading saved cache /opt/elassandra-5.5.0.15/data/saved_caches/KeyCache-e.db java.lang.RuntimeException: Cache schema version f6b19ed5-914c-3f76-978e-b81754b6ccdf does not match current schema version 6baf79fa-364d-3ad2-bc9a-b75ba1b215ec at org.apache.cassandra.cache.AutoSavingCache.loadSaved(AutoSavingCache.java:206) at org.apache.cassandra.cache.AutoSavingCache$3.call(AutoSavingCache.java:164) at org.apache.cassandra.cache.AutoSavingCache$3.call(AutoSavingCache.java:160) at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108) at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41) at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 2018-05-09 16:02:18,653 INFO [pool-5-thread-1] org.apache.cassandra.cache.AutoSavingCache$4.run(AutoSavingCache.java:173) Completed loading (90 ms; 107 keys) KeyCache cache 2018-05-09 16:02:18,712 INFO [main] org.apache.cassandra.db.commitlog.CommitLog.recoverSegmentsOnDisk(CommitLog.java:157) Replaying /opt/elassandra-5.5.0.15/data/commitlog/CommitLog-6-1525881647282.log 2018-05-09 16:02:18,884 INFO [main] org.apache.cassandra.db.commitlog.CommitLog.recoverSegmentsOnDisk(CommitLog.java:159) Log replay complete, 0 replayed mutations 2018-05-09 16:02:18,889 INFO [main] org.apache.cassandra.service.StorageService.populateTokenMetadata(StorageService.java:600) Populating token metadata from system tables 2018-05-09 16:02:18,926 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8362130585556172891 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,935 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6791530300178346392 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,936 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -959123631124296270 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,936 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -2906258939937529727 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,937 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5701683067600102763 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,937 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 7776769257334882293 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,938 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 3566883655066165006 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,938 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5633264194489195507 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,939 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -362226123124935217 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,940 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8401438299379969757 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,941 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6275689832852561075 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,943 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4451716466158730928 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,943 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -6090579284089889517 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,946 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4631534558835767927 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,947 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8914019774812791023 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,947 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8592977458636693389 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,948 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8362130585556172891 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,948 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6791530300178346392 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,949 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -959123631124296270 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,950 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -2906258939937529727 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,951 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5701683067600102763 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,952 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 7776769257334882293 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,952 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 3566883655066165006 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,952 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5633264194489195507 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,960 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -362226123124935217 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,960 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8401438299379969757 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,961 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6275689832852561075 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,961 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4451716466158730928 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,961 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -6090579284089889517 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,962 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4631534558835767927 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,962 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8914019774812791023 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,962 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8592977458636693389 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,962 INFO [main] org.apache.cassandra.service.StorageService.populateTokenMetadata(StorageService.java:607) Token metadata: Normal Tokens: /10.233.90.28:[-8362130585556172891, -2906258939937529727, -959123631124296270, 3566883655066165006, 5633264194489195507, 5701683067600102763, 6791530300178346392, 7776769257334882293] /10.233.97.141:[-8248027387514132260, -7318731352128861107, -861916047897630515, 3049595437829094990, 3681862537357852614, 7941763563148319339, 8234545346034199838, 9073971229396420877] /10.233.114.185:[-9048183706652428987, -5086691515524827064, -4260497491636981485, -4164481151685738517, -1054867843544454931, 4437679225950754397, 5141005615383236012, 6372063045572782995] /10.233.117.217:[-7227302454714817399, -5939375512383729793, -2206250258799490034, 1732568509439143634, 2600887383460939089, 4748189529193459068, 8796692000955143727, 9083020370715658495] /10.233.121.123:[-3299701738014063480, -2539197605680580109, -1839508776458638598, -118864622025183534, 1111019062840381676, 6132333345085630748, 6774441214942613853, 8907766337491345741] /10.233.122.175:[-8592977458636693389, -6090579284089889517, -362226123124935217, 4451716466158730928, 4631534558835767927, 6275689832852561075, 8401438299379969757, 8914019774812791023] 2018-05-09 16:02:19,376 INFO [main] org.apache.cassandra.cql3.QueryProcessor.preloadPreparedStatement(QueryProcessor.java:163) Preloaded 9 prepared statements 2018-05-09 16:02:19,388 INFO [main] org.apache.cassandra.service.StorageService.initServer(StorageService.java:618) Cassandra version: 3.11.2 2018-05-09 16:02:19,391 INFO [main] org.apache.cassandra.service.StorageService.initServer(StorageService.java:619) Thrift API version: 20.1.0 2018-05-09 16:02:19,392 INFO [main] org.apache.cassandra.service.StorageService.initServer(StorageService.java:620) CQL supported versions: 3.4.4 (default: 3.4.4) 2018-05-09 16:02:19,392 INFO [main] org.apache.cassandra.service.StorageService.initServer(StorageService.java:622) Native protocol supported versions: 3/v3, 4/v4, 5/v5-beta (default: 4/v4) 2018-05-09 16:02:19,592 INFO [main] org.apache.cassandra.io.sstable.IndexSummaryManager.<init>(IndexSummaryManager.java:85) Initializing index summary manager with a memory pool size of 408 MB and a resize interval of 60 minutes 2018-05-09 16:02:19,623 INFO [main] org.apache.cassandra.net.MessagingService.getServerSockets(MessagingService.java:753) Starting Messaging Service on /10.233.117.217:7000 (eth0) 2018-05-09 16:02:19,657 INFO [main] org.apache.cassandra.service.StorageService.loadRingState(StorageService.java:707) Loading persisted ring state 2018-05-09 16:02:19,670 INFO [main] org.apache.cassandra.service.StorageService.prepareToJoin(StorageService.java:825) Starting up server gossip 2018-05-09 16:02:19,907 INFO [main] org.apache.cassandra.locator.TokenMetadata.updateTopology(TokenMetadata.java:479) Updating topology for /10.233.117.217 2018-05-09 16:02:19,911 INFO [main] org.apache.cassandra.locator.TokenMetadata.updateTopology(TokenMetadata.java:479) Updating topology for /10.233.117.217 2018-05-09 16:02:20,131 INFO [main] org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:994) Using saved tokens [-2206250258799490034, -5939375512383729793, -7227302454714817399, 1732568509439143634, 2600887383460939089, 4748189529193459068, 8796692000955143727, 9083020370715658495] 2018-05-09 16:02:20,191 INFO [main] org.apache.cassandra.service.StorageService.setMode(StorageService.java:1455) JOINING: Finish joining ring 2018-05-09 16:02:20,275 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='driverperf', ColumnFamily='driverperf') 2018-05-09 16:02:20,281 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='wmsskuet', ColumnFamily='wmsskuet') 2018-05-09 16:02:20,284 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='twitter', ColumnFamily='user') 2018-05-09 16:02:20,287 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='twitter', ColumnFamily='tweet') 2018-05-09 16:02:20,292 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='prdedi', ColumnFamily='prdedi') 2018-05-09 16:02:20,299 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='gtnx_shipment_v2', ColumnFamily='gtnx_shipment_v2') 2018-05-09 16:02:20,303 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='gtnx_purchase_order', ColumnFamily='gtnx_purchase_order') 2018-05-09 16:02:20,311 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='driverperf_2', ColumnFamily='driverperf_2') 2018-05-09 16:02:20,312 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='gtnx_shipment_v1', ColumnFamily='gtnx_shipment_v1') 2018-05-09 16:02:20,314 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='config') 2018-05-09 16:02:20,319 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='dashboard') 2018-05-09 16:02:20,322 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='index_pattern') 2018-05-09 16:02:20,322 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='search') 2018-05-09 16:02:20,326 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='server') 2018-05-09 16:02:20,332 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='url') 2018-05-09 16:02:20,338 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='visualization') 2018-05-09 16:02:20,339 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='timelion_sheet') 2018-05-09 16:02:20,339 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='elastic_admin', ColumnFamily='metadata') 2018-05-09 16:02:20,340 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='driverperf_v1', ColumnFamily='driverperf_v1') 2018-05-09 16:02:20,340 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='carrierperf', ColumnFamily='carrierperf') 2018-05-09 16:02:20,342 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='bob_v1', ColumnFamily='bob_v1') 2018-05-09 16:02:20,342 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='poc_training', ColumnFamily='data') 2018-05-09 16:02:20,347 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='poc_training', ColumnFamily='poc_training') 2018-05-09 16:02:20,419 INFO [main] org.apache.cassandra.service.StorageService.handleStateNormal(StorageService.java:2303) Node /10.233.117.217 state jump to NORMAL 2018-05-09 16:02:20,486 INFO [main] org.apache.cassandra.gms.Gossiper.waitToSettle(Gossiper.java:1670) Waiting for gossip to settle 2018-05-09 16:02:20,912 INFO [GossipTasks:1] org.apache.cassandra.net.OutboundTcpConnection.<clinit>(OutboundTcpConnection.java:108) OutboundTcpConnection using coalescing strategy DISABLED 2018-05-09 16:02:28,488 INFO [main] org.apache.cassandra.gms.Gossiper.waitToSettle(Gossiper.java:1701) No gossip backlog; proceeding 2018-05-09 16:02:28,704 INFO [main] org.apache.cassandra.service.NativeTransportService.initialize(NativeTransportService.java:75) Netty using Java NIO event loop 2018-05-09 16:02:28,799 INFO [main] org.apache.cassandra.transport.Server.start(Server.java:155) Using Netty Version: [netty-buffer=netty-buffer-4.1.12.Final.3acd5c68ea, netty-codec=netty-codec-4.1.12.Final.3acd5c68ea, netty-codec-dns=netty-codec-dns-4.1.12.Final.3acd5c68ea, netty-codec-haproxy=netty-codec-haproxy-4.1.12.Final.3acd5c68ea, netty-codec-http=netty-codec-http-4.1.12.Final.3acd5c68ea, netty-codec-http2=netty-codec-http2-4.1.12.Final.3acd5c68ea, netty-codec-memcache=netty-codec-memcache-4.1.12.Final.3acd5c68ea, netty-codec-mqtt=netty-codec-mqtt-4.1.12.Final.3acd5c68ea, netty-codec-redis=netty-codec-redis-4.1.12.Final.3acd5c68ea, netty-codec-smtp=netty-codec-smtp-4.1.12.Final.3acd5c68ea, netty-codec-socks=netty-codec-socks-4.1.12.Final.3acd5c68ea, netty-codec-stomp=netty-codec-stomp-4.1.12.Final.3acd5c68ea, netty-codec-xml=netty-codec-xml-4.1.12.Final.3acd5c68ea, netty-common=netty-common-4.1.12.Final.3acd5c68ea, netty-handler=netty-handler-4.1.12.Final.3acd5c68ea, netty-handler-proxy=netty-handler-proxy-4.1.12.Final.3acd5c68ea, netty-resolver=netty-resolver-4.1.12.Final.3acd5c68ea, netty-resolver-dns=netty-resolver-dns-4.1.12.Final.3acd5c68ea, netty-tcnative=netty-tcnative-2.0.3.Final.c3e60ce, netty-transport=netty-transport-4.1.12.Final.3acd5c68ea, netty-transport-native-epoll=netty-transport-native-epoll-4.1.12.Final.3acd5c6, netty-transport-native-kqueue=netty-transport-native-kqueue-4.1.12.Final.3acd5c68ea, netty-transport-native-unix-common=netty-transport-native-unix-common-4.1.12.Final.3acd5c68ea, netty-transport-rxtx=netty-transport-rxtx-4.1.12.Final.3acd5c68ea, netty-transport-sctp=netty-transport-sctp-4.1.12.Final.3acd5c68ea, netty-transport-udt=netty-transport-udt-4.1.12.Final.3acd5c68ea] 2018-05-09 16:02:28,800 INFO [main] org.apache.cassandra.transport.Server.start(Server.java:156) Starting listening for CQL clients on /0.0.0.0:9042 (unencrypted) 2018-05-09 16:02:28,816 INFO [main] org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java:537) Not starting RPC server as requested. Use JMX (StorageService->startRPCServer()) or nodetool (enablethrift) to start it 2018-05-09 16:02:28,822 INFO [main] org.elassandra.discovery.CassandraDiscovery.doStart(CassandraDiscovery.java:153) localNode name=10.233.117.217 id=ab90840a-5ed7-45d7-b816-6545f5103ac5 localAddress=/10.233.117.217 publish_host=10.233.117.217:9300 {5.5.0}: Initialization Failed  - NullPointerException[null] 2018-05-09 16:02:28,832 ERROR [main] org.apache.cassandra.service.ElassandraDaemon.main(ElassandraDaemon.java:584) Exception java.lang.NullPointerException: null at org.elassandra.discovery.CassandraDiscovery.updateClusterGroupsFromGossiper(CassandraDiscovery.java:284) at org.elassandra.discovery.CassandraDiscovery.doStart(CassandraDiscovery.java:181) at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) at org.elasticsearch.node.Node.start(Node.java:755) at org.apache.cassandra.service.ElassandraDaemon.activate(ElassandraDaemon.java:228) at org.apache.cassandra.service.ElassandraDaemon.main(ElassandraDaemon.java:547) 2018-05-09 16:02:28,835 INFO [StorageServiceShutdownHook] org.apache.cassandra.hints.HintsService.pauseDispatch(HintsService.java:220) Paused hints dispatch 2018-05-09 16:02:28,845 INFO [StorageServiceShutdownHook] org.apache.cassandra.transport.Server.close(Server.java:176) Stop listening for CQL clients 2018-05-09 16:02:28,848 INFO [StorageServiceShutdownHook] org.apache.cassandra.gms.Gossiper.stop(Gossiper.java:1540) Announcing shutdown 2018-05-09 16:02:28,849 INFO [StorageServiceShutdownHook] org.apache.cassandra.service.StorageService.handleStateNormal(StorageService.java:2303) Node /10.233.117.217 state jump to shutdown 2018-05-09 16:02:30,498 WARN [OptionalTasks:1] org.apache.cassandra.auth.CassandraRoleManager.setupDefaultRole(CassandraRoleManager.java:361) CassandraRoleManager skipped default role setup: some nodes were not ready 2018-05-09 16:02:30,498 INFO [OptionalTasks:1] org.apache.cassandra.auth.CassandraRoleManager$4.run(CassandraRoleManager.java:400) Setup task failed with error, rescheduling 2018-05-09 16:02:30,851 INFO [StorageServiceShutdownHook] org.apache.cassandra.net.MessagingService.shutdown(MessagingService.java:984) Waiting for messaging service to quiesce 2018-05-09 16:02:30,854 INFO [ACCEPT-/10.233.117.217] org.apache.cassandra.net.MessagingService$SocketThread.run(MessagingService.java:1338) MessagingService has terminated the accept() thread 2018-05-09 16:02:31,379 INFO [StorageServiceShutdownHook] org.apache.cassandra.hints.HintsService.pauseDispatch(HintsService.java:220) Paused hints dispatch",source-file,"Elassandra 5.5.0.15 Team, I updated to 5.5.0.15. It does not start. I roll back to 5.5.0.13 works fine. Here is the log Starting cassandra with org.apache.cassandra.service.ElassandraDaemon 2018-05-09 16:01:50,118 INFO [main] org.apache.cassandra.config.YamlConfigurationLoader.getStorageConfigURL(YamlConfigurationLoader.java:89) Configuration location: file:/opt/elassandra-5.5.0.15/conf/cassandra.yaml 2018-05-09 16:01:50,743 INFO [main] org.apache.cassandra.config.Config.log(Config.java:495) Node configuration:[allocate_tokens_for_keyspace=null; authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=true; auto_snapshot=true; back_pressure_enabled=false; back_pressure_strategy=null; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; broadcast_address=10.233.117.217; broadcast_rpc_address=10.233.117.217; buffer_pool_use_heap_if_exhausted=true; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=null; cdc_total_space_in_mb=0; client_encryption_options=<REDACTED>; cluster_name=Cassandra; column_index_cache_size_in_kb=2; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=null; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_batch_window_in_ms=NaN; commitlog_sync_period_in_ms=10000; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=16; concurrent_compactors=null; concurrent_counter_writes=32; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_writes=32; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=false; data_file_directories=[Ljava.lang.String;@19bb07ed; disk_access_mode=auto; disk_failure_policy=stop; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_materialized_views=true; enable_scripted_user_defined_functions=false; enable_user_defined_functions=false; enable_user_defined_functions_threads=true; encryption_options=null; endpoint_snitch=GossipingPropertyFileSnitch; file_cache_round_up=null; file_cache_size_in_mb=null; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=null; hints_flush_period_in_ms=10000; incremental_backups=false; index_interval=null; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=false; internode_authenticator=null; internode_compression=all; internode_recv_buff_size_in_bytes=0; internode_send_buff_size_in_bytes=0; key_cache_keys_to_save=2147483647; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=10.233.117.217; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=null; memtable_flush_writers=0; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_threads=128; native_transport_port=9042; native_transport_port_ssl=null; num_tokens=8; otc_backlog_expiration_interval_ms=200; otc_coalescing_enough_coalesced_messages=8; otc_coalescing_strategy=DISABLED; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=null; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_scheduler_id=null; request_scheduler_options=null; request_timeout_in_ms=10000; role_manager=CassandraRoleManager; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=0.0.0.0; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; rpc_listen_backlog=50; rpc_max_threads=2147483647; rpc_min_threads=16; rpc_port=9160; rpc_recv_buff_size_in_bytes=null; rpc_send_buff_size_in_bytes=null; rpc_server_type=sync; saved_caches_directory=null; seed_provider=org.apache.cassandra.locator.SimpleSeedProvider{seeds=elassandra-0.elassandra.bigdata.svc.cluster.local}; server_encryption_options=<REDACTED>; slow_query_log_timeout_in_ms=500; snapshot_before_compaction=false; ssl_storage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=false; storage_port=7000; stream_throughput_outbound_megabits_per_sec=200; streaming_keep_alive_period_in_secs=300; streaming_socket_timeout_in_ms=86400000; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; thrift_prepared_statements_cache_size_mb=null; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@10e41621; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; windows_timer_interval=1; write_request_timeout_in_ms=5000] 2018-05-09 16:01:50,744 INFO [main] org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:367) DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap 2018-05-09 16:01:50,745 INFO [main] org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:425) Global memtable on-heap threshold is enabled at 2043MB 2018-05-09 16:01:50,746 INFO [main] org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:429) Global memtable off-heap threshold is enabled at 2043MB 2018-05-09 16:01:50,995 INFO [main] org.apache.cassandra.net.RateBasedBackPressure.<init>(RateBasedBackPressure.java:123) Initialized back-pressure with high ratio: 0.9, factor: 5, flow: FAST, window size: 5000. 2018-05-09 16:01:50,996 INFO [main] org.apache.cassandra.config.DatabaseDescriptor.applySimpleConfig(DatabaseDescriptor.java:729) Back-pressure is disabled with strategy null. 2018-05-09 16:01:51,220 INFO [main] org.apache.cassandra.locator.GossipingPropertyFileSnitch.<init>(GossipingPropertyFileSnitch.java:64) Loaded cassandra-topology.properties for compatibility 2018-05-09 16:01:56,313 INFO [ScheduledTasks:1] org.apache.cassandra.locator.TokenMetadata.updateTopology(TokenMetadata.java:498) Updating topology for all endpoints that have changed 2018-05-09 16:01:58,627 INFO [main] org.apache.cassandra.cql3.QueryProcessor.<clinit>(QueryProcessor.java:116) Initialized prepared statement caches with 31 MB (native) and 31 MB (Thrift) 2018-05-09 16:01:59,970 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.IndexInfo 2018-05-09 16:02:01,729 INFO [SSTableBatchOpen:1] org.apache.cassandra.utils.memory.BufferPool$GlobalPool.<clinit>(BufferPool.java:230) Global buffer pool is enabled, when pool is exhausted (max is 512.000MiB) it will allocate on heap 2018-05-09 16:02:02,075 INFO [main] org.apache.cassandra.service.CacheService.initKeyCache(CacheService.java:112) Initializing key cache with capacity of 100 MBs. 2018-05-09 16:02:02,091 INFO [main] org.apache.cassandra.service.CacheService.initRowCache(CacheService.java:134) Initializing row cache with capacity of 0 MBs 2018-05-09 16:02:02,099 INFO [main] org.apache.cassandra.service.CacheService.initCounterCache(CacheService.java:163) Initializing counter cache with capacity of 50 MBs 2018-05-09 16:02:02,111 INFO [main] org.apache.cassandra.service.CacheService.initCounterCache(CacheService.java:174) Scheduling counter cache save to every 7200 seconds (going to save all keys). 2018-05-09 16:02:02,198 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.batches 2018-05-09 16:02:02,236 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.paxos 2018-05-09 16:02:02,289 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.local 2018-05-09 16:02:02,329 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.peers 2018-05-09 16:02:02,373 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.peer_events 2018-05-09 16:02:02,384 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.range_xfers 2018-05-09 16:02:02,395 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.compaction_history 2018-05-09 16:02:02,421 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.sstable_activity 2018-05-09 16:02:02,452 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.size_estimates 2018-05-09 16:02:02,488 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.available_ranges 2018-05-09 16:02:02,504 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.transferred_ranges 2018-05-09 16:02:02,515 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.views_builds_in_progress 2018-05-09 16:02:02,523 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.built_views 2018-05-09 16:02:02,531 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.hints 2018-05-09 16:02:02,541 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.batchlog 2018-05-09 16:02:02,553 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.prepared_statements 2018-05-09 16:02:02,576 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_keyspaces 2018-05-09 16:02:02,586 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_columnfamilies 2018-05-09 16:02:02,594 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_columns 2018-05-09 16:02:02,602 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_triggers 2018-05-09 16:02:02,611 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_usertypes 2018-05-09 16:02:02,619 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_functions 2018-05-09 16:02:02,628 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system.schema_aggregates 2018-05-09 16:02:02,631 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system as storage service is not initialized 2018-05-09 16:02:02,901 INFO [main] org.apache.cassandra.db.monitoring.ApproximateTime.<clinit>(ApproximateTime.java:44) Scheduling approximate time-check task with a precision of 10 milliseconds 2018-05-09 16:02:08,354 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/QHR0roXvQ66LICG3aZltZA] no index state found - ignoring 2018-05-09 16:02:08,358 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/wQc51tfdQYCmPBffGmgykw] no index state found - ignoring 2018-05-09 16:02:08,360 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/Mw5gBIs8Q-2ZRp1REikJCA] no index state found - ignoring 2018-05-09 16:02:08,363 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/ntyLLHQwQmqAy0Kxd3dZfg] no index state found - ignoring 2018-05-09 16:02:08,365 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/nUIEpqJHR8eqweFbrp8hhA] no index state found - ignoring 2018-05-09 16:02:08,369 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/0A5Tb-GXQrSpmN1oeBDhQQ] no index state found - ignoring 2018-05-09 16:02:08,370 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/zUNifXgSRKyiSv_49_FWJg] no index state found - ignoring 2018-05-09 16:02:08,372 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/huOQhYWQT1WO90QXwADvsA] no index state found - ignoring 2018-05-09 16:02:08,379 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/60q4nNzrTqSqTd5ztckASw] no index state found - ignoring 2018-05-09 16:02:08,380 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/cRLgf28HRH-ygrOUywGCtQ] no index state found - ignoring 2018-05-09 16:02:08,381 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/PvumvsazTgyJnPisTHuRFA] no index state found - ignoring 2018-05-09 16:02:08,382 WARN [main] org.elasticsearch.common.util.IndexFolderUpgrader.upgrade(IndexFolderUpgrader.java:117) [/opt/elassandra-5.5.0.15/data/elasticsearch.data/nodes/0/indices/_a1JvbgAR3-NPZdRUzywAg] no index state found - ignoring 2018-05-09 16:02:09,090 INFO [main] org.apache.cassandra.utils.JMXServerUtils.logJmxServiceUrl(JMXServerUtils.java:246) Configured JMX server at: service:jmx:rmi://127.0.0.1/jndi/rmi://127.0.0.1:7199/jmxrmi 2018-05-09 16:02:09,119 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:481) Hostname: elassandra-0.elassandra.bigdata.svc.cluster.local 2018-05-09 16:02:09,120 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:488) JVM vendor/version: OpenJDK 64-Bit Server VM/1.8.0_162 2018-05-09 16:02:09,122 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:489) Heap size: 7.980GiB/7.980GiB 2018-05-09 16:02:09,123 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Code Cache Non-heap memory: init = 2555904(2496K) used = 11208128(10945K) committed = 11403264(11136K) max = 251658240(245760K) 2018-05-09 16:02:09,124 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Metaspace Non-heap memory: init = 0(0K) used = 59219680(57831K) committed = 62316544(60856K) max = -1(-1K) 2018-05-09 16:02:09,125 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Compressed Class Space Non-heap memory: init = 0(0K) used = 8428504(8230K) committed = 9531392(9308K) max = 1073741824(1048576K) 2018-05-09 16:02:09,125 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Par Eden Space Heap memory: init = 167772160(163840K) used = 167772160(163840K) committed = 167772160(163840K) max = 167772160(163840K) 2018-05-09 16:02:09,126 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) Par Survivor Space Heap memory: init = 20971520(20480K) used = 20971520(20480K) committed = 20971520(20480K) max = 20971520(20480K) 2018-05-09 16:02:09,140 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:494) CMS Old Gen Heap memory: init = 8380219392(8183808K) used = 23008080(22468K) committed = 8380219392(8183808K) max = 8380219392(8183808K) 2018-05-09 16:02:09,141 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:496) Classpath: /opt/elassandra-5.5.0.15/conf:/opt/elassandra-5.5.0.15/lib/HdrHistogram-2.1.9.jar:/opt/elassandra-5.5.0.15/lib/ST4-4.0.8.jar:/opt/elassandra-5.5.0.15/lib/airline-0.6.jar:/opt/elassandra-5.5.0.15/lib/ant-1.7.0.jar:/opt/elassandra-5.5.0.15/lib/ant-launcher-1.7.0.jar:/opt/elassandra-5.5.0.15/lib/antlr-3.5.2.jar:/opt/elassandra-5.5.0.15/lib/antlr-runtime-3.5.2.jar:/opt/elassandra-5.5.0.15/lib/caffeine-2.2.6.jar:/opt/elassandra-5.5.0.15/lib/cassandra-all-3.11.2.jar:/opt/elassandra-5.5.0.15/lib/cassandra-driver-core-3.0.1-shaded.jar:/opt/elassandra-5.5.0.15/lib/cassandra-thrift-3.11.2.jar:/opt/elassandra-5.5.0.15/lib/commons-cli-1.3.1.jar:/opt/elassandra-5.5.0.15/lib/commons-codec-1.10.jar:/opt/elassandra-5.5.0.15/lib/commons-lang3-3.3.1.jar:/opt/elassandra-5.5.0.15/lib/commons-logging-1.2.jar:/opt/elassandra-5.5.0.15/lib/commons-math3-3.2.jar:/opt/elassandra-5.5.0.15/lib/compress-lzf-0.8.4.jar:/opt/elassandra-5.5.0.15/lib/concurrent-trees-2.4.0.jar:/opt/elassandra-5.5.0.15/lib/concurrentlinkedhashmap-lru-1.4.jar:/opt/elassandra-5.5.0.15/lib/disruptor-3.0.1.jar:/opt/elassandra-5.5.0.15/lib/ecj-4.4.2.jar:/opt/elassandra-5.5.0.15/lib/elasticsearch-5.5.0.jar:/opt/elassandra-5.5.0.15/lib/fastutil-6.5.7.jar:/opt/elassandra-5.5.0.15/lib/guava-19.0.jar:/opt/elassandra-5.5.0.15/lib/hibernate-validator-4.3.0.Final.jar:/opt/elassandra-5.5.0.15/lib/high-scale-lib-1.0.6.jar:/opt/elassandra-5.5.0.15/lib/hppc-0.7.1.jar:/opt/elassandra-5.5.0.15/lib/httpclient-4.5.2.jar:/opt/elassandra-5.5.0.15/lib/httpcore-4.4.5.jar:/opt/elassandra-5.5.0.15/lib/jackson-core-2.8.6.jar:/opt/elassandra-5.5.0.15/lib/jackson-core-asl-1.9.13.jar:/opt/elassandra-5.5.0.15/lib/jackson-dataformat-cbor-2.8.6.jar:/opt/elassandra-5.5.0.15/lib/jackson-dataformat-smile-2.8.6.jar:/opt/elassandra-5.5.0.15/lib/jackson-dataformat-yaml-2.8.6.jar:/opt/elassandra-5.5.0.15/lib/jackson-mapper-asl-1.9.13.jar:/opt/elassandra-5.5.0.15/lib/java-version-checker-5.5.0.jar:/opt/elassandra-5.5.0.15/lib/javassist-3.20.0-GA.jar:/opt/elassandra-5.5.0.15/lib/javax.inject-1.jar:/opt/elassandra-5.5.0.15/lib/jbcrypt-0.3m.jar:/opt/elassandra-5.5.0.15/lib/jboss-logging-3.1.0.CR2.jar:/opt/elassandra-5.5.0.15/lib/jcl-over-slf4j-1.7.7.jar:/opt/elassandra-5.5.0.15/lib/jctools-core-1.2.1.jar:/opt/elassandra-5.5.0.15/lib/jflex-1.6.0.jar:/opt/elassandra-5.5.0.15/lib/jna-4.4.0.jar:/opt/elassandra-5.5.0.15/lib/joda-time-2.9.5.jar:/opt/elassandra-5.5.0.15/lib/jopt-simple-5.0.2.jar:/opt/elassandra-5.5.0.15/lib/json-simple-1.1.jar:/opt/elassandra-5.5.0.15/lib/jts-1.13.jar:/opt/elassandra-5.5.0.15/lib/libthrift-0.9.2.jar:/opt/elassandra-5.5.0.15/lib/log4j-api-2.8.2.jar:/opt/elassandra-5.5.0.15/lib/log4j-core-2.8.2.jar:/opt/elassandra-5.5.0.15/lib/log4j-over-slf4j-1.7.7.jar:/opt/elassandra-5.5.0.15/lib/log4j-to-slf4j-2.8.2.jar:/opt/elassandra-5.5.0.15/lib/logback-classic-1.1.8.jar:/opt/elassandra-5.5.0.15/lib/logback-core-1.1.8.jar:/opt/elassandra-5.5.0.15/lib/lucene-analyzers-common-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-backward-codecs-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-core-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-grouping-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-highlighter-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-join-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-memory-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-misc-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-queries-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-queryparser-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-sandbox-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-spatial-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-spatial-extras-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-spatial3d-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lucene-suggest-6.6.0.jar:/opt/elassandra-5.5.0.15/lib/lz4-1.3.0.jar:/opt/elassandra-5.5.0.15/lib/metrics-core-3.1.0.jar:/opt/elassandra-5.5.0.15/lib/metrics-jvm-3.1.0.jar:/opt/elassandra-5.5.0.15/lib/netty-all-4.1.12.Final.jar:/opt/elassandra-5.5.0.15/lib/ohc-core-0.4.4.jar:/opt/elassandra-5.5.0.15/lib/plugin-cli-5.5.0.jar:/opt/elassandra-5.5.0.15/lib/reporter-config-base-3.0.3.jar:/opt/elassandra-5.5.0.15/lib/reporter-config3-3.0.3.jar:/opt/elassandra-5.5.0.15/lib/securesm-1.1.jar:/opt/elassandra-5.5.0.15/lib/sigar-1.6.4.jar:/opt/elassandra-5.5.0.15/lib/slf4j-api-1.7.25.jar:/opt/elassandra-5.5.0.15/lib/snakeyaml-1.15.jar:/opt/elassandra-5.5.0.15/lib/snappy-java-1.1.1.7.jar:/opt/elassandra-5.5.0.15/lib/spatial4j-0.6.jar:/opt/elassandra-5.5.0.15/lib/stream-2.5.2.jar:/opt/elassandra-5.5.0.15/lib/t-digest-3.0.jar:/opt/elassandra-5.5.0.15/lib/thrift-server-0.3.7.jar:/opt/elassandra-5.5.0.15/lib/validation-api-1.0.0.GA.jar:/opt/elassandra-5.5.0.15/lib/jamm-0.3.0.jar 2018-05-09 16:02:09,147 INFO [main] org.apache.cassandra.service.CassandraDaemon.logSystemInfo(CassandraDaemon.java:498) JVM Arguments: [-Djava.library.path=/opt/elassandra-5.5.0.15/lib/sigar-bin, -Xloggc:/opt/elassandra-5.5.0.15/logs/gc.log, -ea, -XX:+UseThreadPriorities, -XX:ThreadPriorityPolicy=42, -XX:+HeapDumpOnOutOfMemoryError, -Xss256k, -XX:StringTableSize=1000003, -XX:+AlwaysPreTouch, -XX:-UseBiasedLocking, -XX:+UseTLAB, -XX:+ResizeTLAB, -XX:+UseNUMA, -XX:+PerfDisableSharedMem, -Djava.net.preferIPv4Stack=true, -XX:+UseParNewGC, -XX:+UseConcMarkSweepGC, -XX:+CMSParallelRemarkEnabled, -XX:SurvivorRatio=8, -XX:MaxTenuringThreshold=1, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:CMSWaitDuration=10000, -XX:+CMSParallelInitialMarkEnabled, -XX:+CMSEdenChunksRecordAlways, -XX:+CMSClassUnloadingEnabled, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -XX:+PrintHeapAtGC, -XX:+PrintTenuringDistribution, -XX:+PrintGCApplicationStoppedTime, -XX:+PrintPromotionFailure, -XX:+UseGCLogFileRotation, -XX:NumberOfGCLogFiles=10, -XX:GCLogFileSize=10M, -Xms8192M, -Xmx8192M, -Xmn200M, -XX:CompileCommandFile=/opt/elassandra-5.5.0.15/conf/hotspot_compiler, -javaagent:/opt/elassandra-5.5.0.15/lib/jamm-0.3.0.jar, -Dcassandra.jmx.local.port=7199, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.password.file=/etc/cassandra/jmxremote.password, -Djava.library.path=/opt/elassandra-5.5.0.15/lib/sigar-bin, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djdk.io.permissionsUseCanonicalPath=true, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j.skipJansi=true, -Dcassandra.libjemalloc=/usr/lib/x86_64-linux-gnu/libjemalloc.so.1, -Djava.awt.headless=true, -Dlogback.configurationFile=/opt/elassandra-5.5.0.15/conf/logback.xml, -Dcassandra.logdir=/var/log/cassandra, -Dcassandra.storagedir=/opt/elassandra-5.5.0.15/data, -Dcassandra-pidfile=/opt/elassandra-5.5.0.15/cassandra.pid, -Dcassandra-foreground=yes] 2018-05-09 16:02:09,471 INFO [main] org.apache.cassandra.utils.NativeLibrary.tryMlockall(NativeLibrary.java:174) JNA mlockall successful 2018-05-09 16:02:09,490 INFO [main] org.apache.cassandra.service.StartupChecks$1.execute(StartupChecks.java:140) jemalloc seems to be preloaded from /usr/lib/x86_64-linux-gnu/libjemalloc.so.1 2018-05-09 16:02:09,491 WARN [main] org.apache.cassandra.service.StartupChecks$3.execute(StartupChecks.java:169) JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info. 2018-05-09 16:02:09,496 WARN [main] org.apache.cassandra.service.StartupChecks$5.checkOutOfMemoryHandling(StartupChecks.java:220) The JVM is not configured to stop on OutOfMemoryError which can cause data corruption. Use one of the following JVM options to configure the behavior on OutOfMemoryError: -XX:+ExitOnOutOfMemoryError, -XX:+CrashOnOutOfMemoryError, or -XX:OnOutOfMemoryError=""<cmd args>;<cmd args>"" 2018-05-09 16:02:09,503 INFO [main] org.apache.cassandra.utils.SigarLibrary.<init>(SigarLibrary.java:44) Initializing SIGAR library OpenJDK 64-Bit Server VM warning: You have loaded library /opt/elassandra-5.5.0.15/lib/sigar-bin/libsigar-amd64-linux.so which might have disabled stack guard. The VM will try to fix the stack guard now. It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'. 2018-05-09 16:02:09,534 INFO [main] org.apache.cassandra.utils.SigarLibrary.<init>(SigarLibrary.java:57) Could not initialize SIGAR library org.hyperic.sigar.Sigar.getFileSystemListNative()[Lorg/hyperic/sigar/FileSystem; 2018-05-09 16:02:09,535 INFO [main] org.apache.cassandra.utils.SigarLibrary.warnIfRunningInDegradedMode(SigarLibrary.java:185) Sigar could not be initialized, test for checking degraded mode omitted. 2018-05-09 16:02:09,536 WARN [main] org.apache.cassandra.service.StartupChecks$8.execute(StartupChecks.java:311) Maximum number of memory map areas per process (vm.max_map_count) 65530 is too low, recommended value: 1048575, you can change it with sysctl. 2018-05-09 16:02:10,389 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.keyspaces 2018-05-09 16:02:10,470 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.tables 2018-05-09 16:02:10,541 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.columns 2018-05-09 16:02:10,616 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.triggers 2018-05-09 16:02:10,693 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.dropped_columns 2018-05-09 16:02:10,758 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.views 2018-05-09 16:02:10,838 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.types 2018-05-09 16:02:10,912 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.functions 2018-05-09 16:02:10,982 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.aggregates 2018-05-09 16:02:11,175 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_schema.indexes 2018-05-09 16:02:11,194 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system_schema as storage service is not initialized 2018-05-09 16:02:12,022 INFO [main] org.apache.cassandra.service.StorageService.populateTokenMetadata(StorageService.java:600) Populating token metadata from system tables 2018-05-09 16:02:12,086 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8362130585556172891 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,087 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6791530300178346392 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,088 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -959123631124296270 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,089 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -2906258939937529727 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,090 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5701683067600102763 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,092 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 7776769257334882293 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,092 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 3566883655066165006 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,093 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5633264194489195507 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:12,100 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -362226123124935217 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,101 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8401438299379969757 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,105 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6275689832852561075 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,109 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4451716466158730928 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,111 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -6090579284089889517 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,114 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4631534558835767927 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,115 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8914019774812791023 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,116 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8592977458636693389 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:12,117 INFO [main] org.apache.cassandra.service.StorageService.populateTokenMetadata(StorageService.java:607) Token metadata: Normal Tokens: /10.233.90.28:[-8362130585556172891, -2906258939937529727, -959123631124296270, 3566883655066165006, 5633264194489195507, 5701683067600102763, 6791530300178346392, 7776769257334882293] /10.233.97.141:[-8248027387514132260, -7318731352128861107, -861916047897630515, 3049595437829094990, 3681862537357852614, 7941763563148319339, 8234545346034199838, 9073971229396420877] /10.233.114.185:[-9048183706652428987, -5086691515524827064, -4260497491636981485, -4164481151685738517, -1054867843544454931, 4437679225950754397, 5141005615383236012, 6372063045572782995] /10.233.117.217:[-7227302454714817399, -5939375512383729793, -2206250258799490034, 1732568509439143634, 2600887383460939089, 4748189529193459068, 8796692000955143727, 9083020370715658495] /10.233.121.123:[-3299701738014063480, -2539197605680580109, -1839508776458638598, -118864622025183534, 1111019062840381676, 6132333345085630748, 6774441214942613853, 8907766337491345741] /10.233.122.175:[-8592977458636693389, -6090579284089889517, -362226123124935217, 4451716466158730928, 4631534558835767927, 6275689832852561075, 8401438299379969757, 8914019774812791023] 2018-05-09 16:02:13,068 INFO [main] org.apache.cassandra.service.ElassandraDaemon.activateAndWaitShards(ElassandraDaemon.java:366) Activating Elasticsearch, shards starting before opening user keyspaces 2018-05-09 16:02:13,546 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.wmsskuet' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:13,546 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.wmsskuet' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,025 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.carrierperf' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,026 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.carrierperf' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,084 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.bob_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,085 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.bob_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,134 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.prdedi' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,135 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.prdedi' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,195 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.gtnx_shipment_v2' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,196 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.gtnx_shipment_v2' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,321 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.gtnx_shipment_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,322 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.gtnx_shipment_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,416 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.driverperf_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,417 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.driverperf_v1' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,551 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.gtnx_purchase_order' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,559 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.gtnx_purchase_order' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,712 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query..kibana' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,735 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch..kibana' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,975 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.twitter' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:14,975 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.twitter' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:15,034 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.query.poc_training' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:15,051 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.apache.cassandra.service.StorageService.setLoggingLevel(StorageService.java:3846) set log level to TRACE for classes under 'index.search.slowlog.fetch.poc_training' (if the level doesn't look like 'TRACE' then the logger couldn't parse 'TRACE') 2018-05-09 16:02:15,302 INFO [elasticsearch[10.233.117.217][clusterService#updateTask][T#1]] org.elassandra.gateway.CassandraGatewayService$GatewayRecoveryListener$1.clusterStateProcessed(CassandraGatewayService.java:134) Recovered [11] indices into cluster_state 2018-05-09 16:02:15,312 INFO [main] org.apache.cassandra.service.ElassandraDaemon.activateAndWaitShards(ElassandraDaemon.java:370) Elasticsearch shards started, ready to go on. 2018-05-09 16:02:15,850 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing driverperf.driverperf 2018-05-09 16:02:15,907 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace driverperf as storage service is not initialized 2018-05-09 16:02:15,937 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_traces.events 2018-05-09 16:02:15,966 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_traces.sessions 2018-05-09 16:02:15,983 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system_traces as storage service is not initialized 2018-05-09 16:02:16,002 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing wmsskuet.wmsskuet 2018-05-09 16:02:16,331 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[wmsskuet.wmsskuet] hashCode=1279536741 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:16,337 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace wmsskuet as storage service is not initialized 2018-05-09 16:02:16,350 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[wmsskuet.wmsskuet] initialized, metadata.version=128 mappingInfo.indices=wmsskuet typeName=wmsskuet 2018-05-09 16:02:16,407 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing twitter.tweet 2018-05-09 16:02:16,432 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[twitter.tweet] hashCode=1590802853 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:16,434 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[twitter.tweet] initialized, metadata.version=128 mappingInfo.indices=twitter typeName=tweet 2018-05-09 16:02:16,468 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing twitter.user 2018-05-09 16:02:16,510 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[twitter.user] hashCode=329594950 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:16,512 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[twitter.user] initialized, metadata.version=128 mappingInfo.indices=twitter typeName=user 2018-05-09 16:02:16,515 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace twitter as storage service is not initialized 2018-05-09 16:02:16,544 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_distributed.parent_repair_history 2018-05-09 16:02:16,594 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_distributed.repair_history 2018-05-09 16:02:16,642 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_distributed.view_build_status 2018-05-09 16:02:16,648 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system_distributed as storage service is not initialized 2018-05-09 16:02:16,686 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing prdedi.prdedi 2018-05-09 16:02:17,100 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[prdedi.prdedi] hashCode=964590191 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,102 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[prdedi.prdedi] initialized, metadata.version=128 mappingInfo.indices=prdedi typeName=prdedi 2018-05-09 16:02:17,105 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace prdedi as storage service is not initialized 2018-05-09 16:02:17,124 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing gtnx_shipment_v2.gtnx_shipment_v2 2018-05-09 16:02:17,140 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[gtnx_shipment_v2.gtnx_shipment_v2] hashCode=179287420 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,144 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[gtnx_shipment_v2.gtnx_shipment_v2] initialized, metadata.version=128 mappingInfo.indices=gtnx_shipment_v2 typeName=gtnx_shipment_v2 2018-05-09 16:02:17,145 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace gtnx_shipment_v2 as storage service is not initialized 2018-05-09 16:02:17,182 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing gtnx_purchase_order.gtnx_purchase_order 2018-05-09 16:02:17,229 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[gtnx_purchase_order.gtnx_purchase_order] hashCode=1507866909 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,232 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[gtnx_purchase_order.gtnx_purchase_order] initialized, metadata.version=128 mappingInfo.indices=gtnx_purchase_order typeName=gtnx_purchase_order 2018-05-09 16:02:17,234 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace gtnx_purchase_order as storage service is not initialized 2018-05-09 16:02:17,254 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing driverperf_2.driverperf_2 2018-05-09 16:02:17,272 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace driverperf_2 as storage service is not initialized 2018-05-09 16:02:17,322 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing gtnx_shipment_v1.gtnx_shipment_v1 2018-05-09 16:02:17,349 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[gtnx_shipment_v1.gtnx_shipment_v1] hashCode=1673354607 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,352 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[gtnx_shipment_v1.gtnx_shipment_v1] initialized, metadata.version=128 mappingInfo.indices=gtnx_shipment_v1 typeName=gtnx_shipment_v1 2018-05-09 16:02:17,354 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace gtnx_shipment_v1 as storage service is not initialized 2018-05-09 16:02:17,378 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.config 2018-05-09 16:02:17,407 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.config] hashCode=702217845 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,409 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.config] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=config 2018-05-09 16:02:17,428 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.dashboard 2018-05-09 16:02:17,435 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.dashboard] hashCode=1588181607 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,437 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.dashboard] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=dashboard 2018-05-09 16:02:17,480 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.index_pattern 2018-05-09 16:02:17,527 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.index_pattern] hashCode=114907262 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,529 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.index_pattern] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=index-pattern 2018-05-09 16:02:17,542 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.search 2018-05-09 16:02:17,563 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.search] hashCode=252066799 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,565 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.search] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=search 2018-05-09 16:02:17,585 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.server 2018-05-09 16:02:17,593 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.server] hashCode=1901151532 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,595 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.server] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=server 2018-05-09 16:02:17,610 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.timelion_sheet 2018-05-09 16:02:17,633 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.timelion_sheet] hashCode=1656271843 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,635 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.timelion_sheet] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=timelion-sheet 2018-05-09 16:02:17,646 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.url 2018-05-09 16:02:17,654 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.url] hashCode=787357026 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,655 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.url] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=url 2018-05-09 16:02:17,671 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing _kibana.visualization 2018-05-09 16:02:17,681 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace _kibana as storage service is not initialized 2018-05-09 16:02:17,681 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[_kibana.visualization] hashCode=269062675 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:17,683 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[_kibana.visualization] initialized, metadata.version=128 mappingInfo.indices=.kibana typeName=visualization 2018-05-09 16:02:17,717 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing elastic_admin.metadata 2018-05-09 16:02:17,977 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace elastic_admin as storage service is not initialized 2018-05-09 16:02:18,015 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing driverperf_v1.driverperf_v1 2018-05-09 16:02:18,086 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[driverperf_v1.driverperf_v1] hashCode=1804262683 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,086 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace driverperf_v1 as storage service is not initialized 2018-05-09 16:02:18,088 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[driverperf_v1.driverperf_v1] initialized, metadata.version=128 mappingInfo.indices=driverperf_v1 typeName=driverperf_v1 2018-05-09 16:02:18,129 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing carrierperf.carrierperf 2018-05-09 16:02:18,330 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[carrierperf.carrierperf] hashCode=1284135970 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,330 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace carrierperf as storage service is not initialized 2018-05-09 16:02:18,337 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[carrierperf.carrierperf] initialized, metadata.version=128 mappingInfo.indices=carrierperf typeName=carrierperf 2018-05-09 16:02:18,364 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing bob_v1.bob_v1 2018-05-09 16:02:18,375 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace bob_v1 as storage service is not initialized 2018-05-09 16:02:18,375 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[bob_v1.bob_v1] hashCode=307322332 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,379 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[bob_v1.bob_v1] initialized, metadata.version=128 mappingInfo.indices=bob_v1 typeName=bob_v1 2018-05-09 16:02:18,392 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_auth.resource_role_permissons_index 2018-05-09 16:02:18,401 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_auth.role_members 2018-05-09 16:02:18,420 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_auth.role_permissions 2018-05-09 16:02:18,444 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing system_auth.roles 2018-05-09 16:02:18,455 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace system_auth as storage service is not initialized 2018-05-09 16:02:18,501 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing poc_training.data 2018-05-09 16:02:18,518 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[poc_training.data] hashCode=1309990031 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,520 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[poc_training.data] initialized, metadata.version=128 mappingInfo.indices=poc_training typeName=data 2018-05-09 16:02:18,526 INFO [main] org.apache.cassandra.db.ColumnFamilyStore.<init>(ColumnFamilyStore.java:411) Initializing poc_training.poc_training 2018-05-09 16:02:18,530 INFO [main] org.apache.cassandra.db.view.ViewManager.reload(ViewManager.java:137) Not submitting build tasks for views in keyspace poc_training as storage service is not initialized 2018-05-09 16:02:18,530 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initialize(ElasticSecondaryIndex.java:2166) Initializing elastic secondary index=[poc_training.poc_training] hashCode=1934340691 initCounter=1 metadata.version=128 indices=[wmsskuet=>wmsskuet/wmsskuet, carrierperf=>carrierperf/carrierperf, bob_v1=>bob_v1/bob_v1, prdedi=>prdedi/prdedi, gtnx_shipment_v2=>gtnx_shipment_v2/gtnx_shipment_v2, gtnx_shipment_v1=>gtnx_shipment_v1/gtnx_shipment_v1, driverperf_v1=>driverperf_v1/driverperf_v1, gtnx_purchase_order=>gtnx_purchase_order/gtnx_purchase_order, .kibana=>.kibana/_kibana, twitter=>twitter/twitter, poc_training=>poc_training/poc_training] 2018-05-09 16:02:18,532 INFO [SecondaryIndexManagement:1] org.elassandra.index.ElasticSecondaryIndex.initMapping(ElasticSecondaryIndex.java:2098) Secondary index=[poc_training.poc_training] initialized, metadata.version=128 mappingInfo.indices=poc_training typeName=poc_training 2018-05-09 16:02:18,607 INFO [pool-5-thread-1] org.apache.cassandra.cache.AutoSavingCache.loadSaved(AutoSavingCache.java:197) reading saved cache /opt/elassandra-5.5.0.15/data/saved_caches/KeyCache-e.db 2018-05-09 16:02:18,648 INFO [pool-5-thread-1] org.apache.cassandra.cache.AutoSavingCache.loadSaved(AutoSavingCache.java:262) Harmless error reading saved cache /opt/elassandra-5.5.0.15/data/saved_caches/KeyCache-e.db java.lang.RuntimeException: Cache schema version f6b19ed5-914c-3f76-978e-b81754b6ccdf does not match current schema version 6baf79fa-364d-3ad2-bc9a-b75ba1b215ec at org.apache.cassandra.cache.AutoSavingCache.loadSaved(AutoSavingCache.java:206) at org.apache.cassandra.cache.AutoSavingCache$3.call(AutoSavingCache.java:164) at org.apache.cassandra.cache.AutoSavingCache$3.call(AutoSavingCache.java:160) at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108) at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41) at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 2018-05-09 16:02:18,653 INFO [pool-5-thread-1] org.apache.cassandra.cache.AutoSavingCache$4.run(AutoSavingCache.java:173) Completed loading (90 ms; 107 keys) KeyCache cache 2018-05-09 16:02:18,712 INFO [main] org.apache.cassandra.db.commitlog.CommitLog.recoverSegmentsOnDisk(CommitLog.java:157) Replaying /opt/elassandra-5.5.0.15/data/commitlog/CommitLog-6-1525881647282.log 2018-05-09 16:02:18,884 INFO [main] org.apache.cassandra.db.commitlog.CommitLog.recoverSegmentsOnDisk(CommitLog.java:159) Log replay complete, 0 replayed mutations 2018-05-09 16:02:18,889 INFO [main] org.apache.cassandra.service.StorageService.populateTokenMetadata(StorageService.java:600) Populating token metadata from system tables 2018-05-09 16:02:18,926 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8362130585556172891 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,935 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6791530300178346392 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,936 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -959123631124296270 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,936 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -2906258939937529727 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,937 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5701683067600102763 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,937 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 7776769257334882293 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,938 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 3566883655066165006 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,938 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5633264194489195507 changing ownership from /10.233.90.28 to /10.233.90.25 2018-05-09 16:02:18,939 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -362226123124935217 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,940 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8401438299379969757 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,941 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6275689832852561075 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,943 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4451716466158730928 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,943 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -6090579284089889517 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,946 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4631534558835767927 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,947 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8914019774812791023 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,947 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8592977458636693389 changing ownership from /10.233.122.175 to /10.233.122.168 2018-05-09 16:02:18,948 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8362130585556172891 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,948 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6791530300178346392 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,949 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -959123631124296270 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,950 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -2906258939937529727 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,951 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5701683067600102763 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,952 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 7776769257334882293 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,952 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 3566883655066165006 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,952 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 5633264194489195507 changing ownership from /10.233.90.25 to /10.233.90.28 2018-05-09 16:02:18,960 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -362226123124935217 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,960 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8401438299379969757 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,961 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 6275689832852561075 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,961 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4451716466158730928 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,961 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -6090579284089889517 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,962 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 4631534558835767927 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,962 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token 8914019774812791023 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,962 WARN [main] org.apache.cassandra.locator.TokenMetadata.updateNormalTokens(TokenMetadata.java:215) Token -8592977458636693389 changing ownership from /10.233.122.168 to /10.233.122.175 2018-05-09 16:02:18,962 INFO [main] org.apache.cassandra.service.StorageService.populateTokenMetadata(StorageService.java:607) Token metadata: Normal Tokens: /10.233.90.28:[-8362130585556172891, -2906258939937529727, -959123631124296270, 3566883655066165006, 5633264194489195507, 5701683067600102763, 6791530300178346392, 7776769257334882293] /10.233.97.141:[-8248027387514132260, -7318731352128861107, -861916047897630515, 3049595437829094990, 3681862537357852614, 7941763563148319339, 8234545346034199838, 9073971229396420877] /10.233.114.185:[-9048183706652428987, -5086691515524827064, -4260497491636981485, -4164481151685738517, -1054867843544454931, 4437679225950754397, 5141005615383236012, 6372063045572782995] /10.233.117.217:[-7227302454714817399, -5939375512383729793, -2206250258799490034, 1732568509439143634, 2600887383460939089, 4748189529193459068, 8796692000955143727, 9083020370715658495] /10.233.121.123:[-3299701738014063480, -2539197605680580109, -1839508776458638598, -118864622025183534, 1111019062840381676, 6132333345085630748, 6774441214942613853, 8907766337491345741] /10.233.122.175:[-8592977458636693389, -6090579284089889517, -362226123124935217, 4451716466158730928, 4631534558835767927, 6275689832852561075, 8401438299379969757, 8914019774812791023] 2018-05-09 16:02:19,376 INFO [main] org.apache.cassandra.cql3.QueryProcessor.preloadPreparedStatement(QueryProcessor.java:163) Preloaded 9 prepared statements 2018-05-09 16:02:19,388 INFO [main] org.apache.cassandra.service.StorageService.initServer(StorageService.java:618) Cassandra version: 3.11.2 2018-05-09 16:02:19,391 INFO [main] org.apache.cassandra.service.StorageService.initServer(StorageService.java:619) Thrift API version: 20.1.0 2018-05-09 16:02:19,392 INFO [main] org.apache.cassandra.service.StorageService.initServer(StorageService.java:620) CQL supported versions: 3.4.4 (default: 3.4.4) 2018-05-09 16:02:19,392 INFO [main] org.apache.cassandra.service.StorageService.initServer(StorageService.java:622) Native protocol supported versions: 3/v3, 4/v4, 5/v5-beta (default: 4/v4) 2018-05-09 16:02:19,592 INFO [main] org.apache.cassandra.io.sstable.IndexSummaryManager.<init>(IndexSummaryManager.java:85) Initializing index summary manager with a memory pool size of 408 MB and a resize interval of 60 minutes 2018-05-09 16:02:19,623 INFO [main] org.apache.cassandra.net.MessagingService.getServerSockets(MessagingService.java:753) Starting Messaging Service on /10.233.117.217:7000 (eth0) 2018-05-09 16:02:19,657 INFO [main] org.apache.cassandra.service.StorageService.loadRingState(StorageService.java:707) Loading persisted ring state 2018-05-09 16:02:19,670 INFO [main] org.apache.cassandra.service.StorageService.prepareToJoin(StorageService.java:825) Starting up server gossip 2018-05-09 16:02:19,907 INFO [main] org.apache.cassandra.locator.TokenMetadata.updateTopology(TokenMetadata.java:479) Updating topology for /10.233.117.217 2018-05-09 16:02:19,911 INFO [main] org.apache.cassandra.locator.TokenMetadata.updateTopology(TokenMetadata.java:479) Updating topology for /10.233.117.217 2018-05-09 16:02:20,131 INFO [main] org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:994) Using saved tokens [-2206250258799490034, -5939375512383729793, -7227302454714817399, 1732568509439143634, 2600887383460939089, 4748189529193459068, 8796692000955143727, 9083020370715658495] 2018-05-09 16:02:20,191 INFO [main] org.apache.cassandra.service.StorageService.setMode(StorageService.java:1455) JOINING: Finish joining ring 2018-05-09 16:02:20,275 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='driverperf', ColumnFamily='driverperf') 2018-05-09 16:02:20,281 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='wmsskuet', ColumnFamily='wmsskuet') 2018-05-09 16:02:20,284 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='twitter', ColumnFamily='user') 2018-05-09 16:02:20,287 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='twitter', ColumnFamily='tweet') 2018-05-09 16:02:20,292 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='prdedi', ColumnFamily='prdedi') 2018-05-09 16:02:20,299 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='gtnx_shipment_v2', ColumnFamily='gtnx_shipment_v2') 2018-05-09 16:02:20,303 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='gtnx_purchase_order', ColumnFamily='gtnx_purchase_order') 2018-05-09 16:02:20,311 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='driverperf_2', ColumnFamily='driverperf_2') 2018-05-09 16:02:20,312 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='gtnx_shipment_v1', ColumnFamily='gtnx_shipment_v1') 2018-05-09 16:02:20,314 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='config') 2018-05-09 16:02:20,319 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='dashboard') 2018-05-09 16:02:20,322 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='index_pattern') 2018-05-09 16:02:20,322 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='search') 2018-05-09 16:02:20,326 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='server') 2018-05-09 16:02:20,332 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='url') 2018-05-09 16:02:20,338 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='visualization') 2018-05-09 16:02:20,339 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='_kibana', ColumnFamily='timelion_sheet') 2018-05-09 16:02:20,339 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='elastic_admin', ColumnFamily='metadata') 2018-05-09 16:02:20,340 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='driverperf_v1', ColumnFamily='driverperf_v1') 2018-05-09 16:02:20,340 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='carrierperf', ColumnFamily='carrierperf') 2018-05-09 16:02:20,342 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='bob_v1', ColumnFamily='bob_v1') 2018-05-09 16:02:20,342 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='poc_training', ColumnFamily='data') 2018-05-09 16:02:20,347 INFO [main] org.apache.cassandra.index.SecondaryIndexManager.executePreJoinTasksBlocking(SecondaryIndexManager.java:518) Executing pre-join tasks for: CFS(Keyspace='poc_training', ColumnFamily='poc_training') 2018-05-09 16:02:20,419 INFO [main] org.apache.cassandra.service.StorageService.handleStateNormal(StorageService.java:2303) Node /10.233.117.217 state jump to NORMAL 2018-05-09 16:02:20,486 INFO [main] org.apache.cassandra.gms.Gossiper.waitToSettle(Gossiper.java:1670) Waiting for gossip to settle 2018-05-09 16:02:20,912 INFO [GossipTasks:1] org.apache.cassandra.net.OutboundTcpConnection.<clinit>(OutboundTcpConnection.java:108) OutboundTcpConnection using coalescing strategy DISABLED 2018-05-09 16:02:28,488 INFO [main] org.apache.cassandra.gms.Gossiper.waitToSettle(Gossiper.java:1701) No gossip backlog; proceeding 2018-05-09 16:02:28,704 INFO [main] org.apache.cassandra.service.NativeTransportService.initialize(NativeTransportService.java:75) Netty using Java NIO event loop 2018-05-09 16:02:28,799 INFO [main] org.apache.cassandra.transport.Server.start(Server.java:155) Using Netty Version: [netty-buffer=netty-buffer-4.1.12.Final.3acd5c68ea, netty-codec=netty-codec-4.1.12.Final.3acd5c68ea, netty-codec-dns=netty-codec-dns-4.1.12.Final.3acd5c68ea, netty-codec-haproxy=netty-codec-haproxy-4.1.12.Final.3acd5c68ea, netty-codec-http=netty-codec-http-4.1.12.Final.3acd5c68ea, netty-codec-http2=netty-codec-http2-4.1.12.Final.3acd5c68ea, netty-codec-memcache=netty-codec-memcache-4.1.12.Final.3acd5c68ea, netty-codec-mqtt=netty-codec-mqtt-4.1.12.Final.3acd5c68ea, netty-codec-redis=netty-codec-redis-4.1.12.Final.3acd5c68ea, netty-codec-smtp=netty-codec-smtp-4.1.12.Final.3acd5c68ea, netty-codec-socks=netty-codec-socks-4.1.12.Final.3acd5c68ea, netty-codec-stomp=netty-codec-stomp-4.1.12.Final.3acd5c68ea, netty-codec-xml=netty-codec-xml-4.1.12.Final.3acd5c68ea, netty-common=netty-common-4.1.12.Final.3acd5c68ea, netty-handler=netty-handler-4.1.12.Final.3acd5c68ea, netty-handler-proxy=netty-handler-proxy-4.1.12.Final.3acd5c68ea, netty-resolver=netty-resolver-4.1.12.Final.3acd5c68ea, netty-resolver-dns=netty-resolver-dns-4.1.12.Final.3acd5c68ea, netty-tcnative=netty-tcnative-2.0.3.Final.c3e60ce, netty-transport=netty-transport-4.1.12.Final.3acd5c68ea, netty-transport-native-epoll=netty-transport-native-epoll-4.1.12.Final.3acd5c6, netty-transport-native-kqueue=netty-transport-native-kqueue-4.1.12.Final.3acd5c68ea, netty-transport-native-unix-common=netty-transport-native-unix-common-4.1.12.Final.3acd5c68ea, netty-transport-rxtx=netty-transport-rxtx-4.1.12.Final.3acd5c68ea, netty-transport-sctp=netty-transport-sctp-4.1.12.Final.3acd5c68ea, netty-transport-udt=netty-transport-udt-4.1.12.Final.3acd5c68ea] 2018-05-09 16:02:28,800 INFO [main] org.apache.cassandra.transport.Server.start(Server.java:156) Starting listening for CQL clients on /0.0.0.0:9042 (unencrypted) 2018-05-09 16:02:28,816 INFO [main] org.apache.cassandra.service.CassandraDaemon.start(CassandraDaemon.java:537) Not starting RPC server as requested. Use JMX (StorageService->startRPCServer()) or nodetool (enablethrift) to start it 2018-05-09 16:02:28,822 INFO [main] org.elassandra.discovery.CassandraDiscovery.doStart(CassandraDiscovery.java:153) localNode name=10.233.117.217 id=ab90840a-5ed7-45d7-b816-6545f5103ac5 localAddress=/10.233.117.217 publish_host=10.233.117.217:9300 {5.5.0}: Initialization Failed  - NullPointerException[null] 2018-05-09 16:02:28,832 ERROR [main] org.apache.cassandra.service.ElassandraDaemon.main(ElassandraDaemon.java:584) Exception java.lang.NullPointerException: null at org.elassandra.discovery.CassandraDiscovery.updateClusterGroupsFromGossiper(CassandraDiscovery.java:284) at org.elassandra.discovery.CassandraDiscovery.doStart(CassandraDiscovery.java:181) at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) at org.elasticsearch.node.Node.start(Node.java:755) at org.apache.cassandra.service.ElassandraDaemon.activate(ElassandraDaemon.java:228) at org.apache.cassandra.service.ElassandraDaemon.main(ElassandraDaemon.java:547) 2018-05-09 16:02:28,835 INFO [StorageServiceShutdownHook] org.apache.cassandra.hints.HintsService.pauseDispatch(HintsService.java:220) Paused hints dispatch 2018-05-09 16:02:28,845 INFO [StorageServiceShutdownHook] org.apache.cassandra.transport.Server.close(Server.java:176) Stop listening for CQL clients 2018-05-09 16:02:28,848 INFO [StorageServiceShutdownHook] org.apache.cassandra.gms.Gossiper.stop(Gossiper.java:1540) Announcing shutdown 2018-05-09 16:02:28,849 INFO [StorageServiceShutdownHook] org.apache.cassandra.service.StorageService.handleStateNormal(StorageService.java:2303) Node /10.233.117.217 state jump to shutdown 2018-05-09 16:02:30,498 WARN [OptionalTasks:1] org.apache.cassandra.auth.CassandraRoleManager.setupDefaultRole(CassandraRoleManager.java:361) CassandraRoleManager skipped default role setup: some nodes were not ready 2018-05-09 16:02:30,498 INFO [OptionalTasks:1] org.apache.cassandra.auth.CassandraRoleManager$4.run(CassandraRoleManager.java:400) Setup task failed with error, rescheduling 2018-05-09 16:02:30,851 INFO [StorageServiceShutdownHook] org.apache.cassandra.net.MessagingService.shutdown(MessagingService.java:984) Waiting for messaging service to quiesce 2018-05-09 16:02:30,854 INFO [ACCEPT-/10.233.117.217] org.apache.cassandra.net.MessagingService$SocketThread.run(MessagingService.java:1338) MessagingService has terminated the accept() thread 2018-05-09 16:02:31,379 INFO [StorageServiceShutdownHook] org.apache.cassandra.hints.HintsService.pauseDispatch(HintsService.java:220) Paused hints dispatch source-file",no-bug,0.95
74,elassandra,https://github.com/strapdata/elassandra/issues/74,Add support for uuid and timeuuid Cassandra Types,"It would be nice to have support for UUID and TIMEUUID Cassandra types, as for now system fails due to lack of mapping with ES types. Even basic mapping (Using ES string type) would be welcome.",source-file | source-file | test-file | test-file | other-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | test-file | source-file | test-file | test-file,"Add support for uuid and timeuuid Cassandra Types It would be nice to have support for UUID and TIMEUUID Cassandra types, as for now system fails due to lack of mapping with ES types. Even basic mapping (Using ES string type) would be welcome. source-file source-file test-file test-file other-file source-file source-file source-file source-file test-file test-file test-file test-file test-file source-file test-file test-file",no-bug,0.8
315,elassandra,https://github.com/strapdata/elassandra/issues/315,Nested objects' fields not indexed,"Hello, I have tried to use Elassandra 6.2.3 and 6.8.4 (on Docker Hub) and a critical issue came out: The steps I made: 1. Created a new index 2. Indexed a document with a field containing a nested object (everything OK for now) Request `{ ""fieldA"": ""A"", ""fieldB"": ""B"", ""nested"": { ""fieldC"": ""C"", ""fieldD"": ""D"", ""fieldE"": ""E"", ""fieldF"": ""F"" } }` 3. Indexed a second document with this same field containing, in the nested object, some different fields from the first document -> the result is that only a random field is saved, even if under **/_mapping** URL all the fields are displayed correctly. Request `{ ""fieldA"": ""A"", ""fieldB"": ""B"", ""nested"": { ""fieldG"": ""G"", ""fieldH"": ""H"", ""fieldI"": ""I"", ""fieldJ"": ""J"" } }` GET output: `{ ""took"": 11, ""timed_out"": false, ""_shards"": { ""total"": 1, ""successful"": 1, ""skipped"": 0, ""failed"": 0 }, ""hits"": { ""total"": 2, ""max_score"": 1.0, ""hits"": [ { ""_index"": ""test-issue-index"", ""_type"": ""test-issue"", ""_id"": ""B0rWGG8Bx4Fl4m8pOw3Q"", ""_score"": 1.0, ""_source"": { ""fieldA"": ""A"", ""fieldB"": ""B"", ""nested"": { ""fieldF"": ""F"", ""fieldC"": ""C"", ""fieldE"": ""E"", ""fieldD"": ""D"" } } }, { ""_index"": ""test-issue-index"", ""_type"": ""test-issue"", ""_id"": ""CErWGG8Bx4Fl4m8p0A26"", ""_score"": 1.0, ""_source"": { ""fieldA"": ""A"", ""fieldB"": ""B"", ""nested"": { ""fieldJ"": ""J"" } } } ] } }` Here the /_mapping endpoint request, just to show to you that every field in the nested object is correctly mapped into the index. `{ ""test-issue-index"": { ""mappings"": { ""test-issue"": { ""properties"": { ""fieldA"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldB"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""nested"": { ""properties"": { ""fieldC"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldD"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldE"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldF"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldG"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldH"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldI"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldJ"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } } } } } } } } }` **NOTE: These behaviour is NOT reproduced on ElasticSearch (not Elassandra) 6.2.3 or 6.8.4** Can you help me, please? Thanks and regards. Paolo",source-file | test-file,"Nested objects' fields not indexed Hello, I have tried to use Elassandra 6.2.3 and 6.8.4 (on Docker Hub) and a critical issue came out: The steps I made: 1. Created a new index 2. Indexed a document with a field containing a nested object (everything OK for now) Request `{ ""fieldA"": ""A"", ""fieldB"": ""B"", ""nested"": { ""fieldC"": ""C"", ""fieldD"": ""D"", ""fieldE"": ""E"", ""fieldF"": ""F"" } }` 3. Indexed a second document with this same field containing, in the nested object, some different fields from the first document -> the result is that only a random field is saved, even if under **/_mapping** URL all the fields are displayed correctly. Request `{ ""fieldA"": ""A"", ""fieldB"": ""B"", ""nested"": { ""fieldG"": ""G"", ""fieldH"": ""H"", ""fieldI"": ""I"", ""fieldJ"": ""J"" } }` GET output: `{ ""took"": 11, ""timed_out"": false, ""_shards"": { ""total"": 1, ""successful"": 1, ""skipped"": 0, ""failed"": 0 }, ""hits"": { ""total"": 2, ""max_score"": 1.0, ""hits"": [ { ""_index"": ""test-issue-index"", ""_type"": ""test-issue"", ""_id"": ""B0rWGG8Bx4Fl4m8pOw3Q"", ""_score"": 1.0, ""_source"": { ""fieldA"": ""A"", ""fieldB"": ""B"", ""nested"": { ""fieldF"": ""F"", ""fieldC"": ""C"", ""fieldE"": ""E"", ""fieldD"": ""D"" } } }, { ""_index"": ""test-issue-index"", ""_type"": ""test-issue"", ""_id"": ""CErWGG8Bx4Fl4m8p0A26"", ""_score"": 1.0, ""_source"": { ""fieldA"": ""A"", ""fieldB"": ""B"", ""nested"": { ""fieldJ"": ""J"" } } } ] } }` Here the /_mapping endpoint request, just to show to you that every field in the nested object is correctly mapped into the index. `{ ""test-issue-index"": { ""mappings"": { ""test-issue"": { ""properties"": { ""fieldA"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldB"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""nested"": { ""properties"": { ""fieldC"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldD"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldE"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldF"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldG"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldH"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldI"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } }, ""fieldJ"": { ""type"": ""text"", ""fields"": { ""keyword"": { ""type"": ""keyword"", ""ignore_above"": 256 } } } } } } } } } }` **NOTE: These behaviour is NOT reproduced on ElasticSearch (not Elassandra) 6.2.3 or 6.8.4** Can you help me, please? Thanks and regards. Paolo source-file test-file",no-bug,0.9
178,elassandra,https://github.com/strapdata/elassandra/issues/178,Partitioned index - Date formatting error,"Hello, I'm trying to use the ""partitioned index"" (http://elassandra.readthedocs.io/en/v5.5.0.9/mapping.html#partitioned-index) but it seems it doesn't work. Elassandra 5.5.0.9 (Elasticsearch 5.5.0, Cassandra 3.11.1.2, JVM 1.8.0_152) To use the ""partitioned index"", I create an elasticsearch template :  curl -XPOST 'http://localhost:9200/_template/partitioned-index-test-template' -d '{ ""template"": ""partitioned-index-test-*"", ""settings"": { ""keyspace"": ""partitioned_index_keyspace"", ""index.partition_function"": ""toDayIndex partitioned-index-test-{0,date,yyyy.MM.dd} timefield"", ""index.partition_function_class"": ""org.elassandra.index.MessageFormatPartitionFunction"" }, ""mappings"": { ""test"": { ""properties"": { ""timefield"": { ""type"": ""date"" }, ""textfield"": { ""type"": ""text"" '  When I POST the first document in an index named ""partitioned-index-test-2018.03.21""  curl -XPOST 'http://localhost:9200/partitioned-index-test-2018.03.21/test' -d '{ ""timefield"": ""2018-03-21T12:17:12.00Z"", ""textfield"": ""My text field"" }'  the new elasticsearch index is well created, and there is a new row in my cassandra table. **But there is no document in the elasticsearch index**, and I can read this error in logs  java.lang.RuntimeException: Cannot format given Object as a Date for ks: partitioned_index_keyspace, table: test at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1357) at org.apache.cassandra.db.Keyspace.applyInternal(Keyspace.java:623) at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:467) at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) at org.apache.cassandra.db.Mutation.apply(Mutation.java:232) at org.apache.cassandra.db.Mutation.apply(Mutation.java:241) at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1408) at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2647) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date at java.text.DateFormat.format(DateFormat.java:310) at java.text.Format.format(Format.java:157) at java.text.MessageFormat.subformat(MessageFormat.java:1322) at java.text.MessageFormat.format(MessageFormat.java:865) at java.text.Format.format(Format.java:157) at org.elassandra.index.MessageFormatPartitionFunction.format(MessageFormatPartitionFunction.java:34) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$ImmutablePartitionFunction.indexName(ElasticSecondaryIndex.java:1010) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo.targetIndices(ElasticSecondaryIndex.java:1241) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1871) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer$SkinnyRowcument.index(ElasticSecondaryIndex.java:1447) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer.flush(ElasticSecondaryIndex.java:1483) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer.finish(ElasticSecondaryIndex.java:1598) at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.commit(SecondaryIndexManager.java:983) at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:181) at org.apache.cassandra.db.Memtable.put(Memtable.java:284) at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1339)  11 common frames omitted  Before looking for a potentially bug, I develop my own very simple partition function. Modify my template and re create all from scratch (and restart elassandra of course). **Now, when I push new documents, there is no errors, but still no documents in the Elasticsearch index.** So I add a log message (with slf4j) at the entrance of my partition function.  @Override public String format(String pattern, Object args) { logger.info(""CUSTOM MESSAGE TO TRACE EXECUTION""); return pattern + ""2018.03.21""; }  With this new version, the first time I push a document, **I can see my log message**. But the message **appears randomly** on each new documents. Anyway, **still no document in my Elasticsearch index**, but every document exists in the cassandra table. Did am I the only guy using this feature ? Could you please help me ? Is it a bug, or did I use it in the wrong way ?",source-file | test-file | source-file | test-file,"Partitioned index - Date formatting error Hello, I'm trying to use the ""partitioned index"" (http://elassandra.readthedocs.io/en/v5.5.0.9/mapping.html#partitioned-index) but it seems it doesn't work. Elassandra 5.5.0.9 (Elasticsearch 5.5.0, Cassandra 3.11.1.2, JVM 1.8.0_152) To use the ""partitioned index"", I create an elasticsearch template :  curl -XPOST 'http://localhost:9200/_template/partitioned-index-test-template' -d '{ ""template"": ""partitioned-index-test-*"", ""settings"": { ""keyspace"": ""partitioned_index_keyspace"", ""index.partition_function"": ""toDayIndex partitioned-index-test-{0,date,yyyy.MM.dd} timefield"", ""index.partition_function_class"": ""org.elassandra.index.MessageFormatPartitionFunction"" }, ""mappings"": { ""test"": { ""properties"": { ""timefield"": { ""type"": ""date"" }, ""textfield"": { ""type"": ""text"" '  When I POST the first document in an index named ""partitioned-index-test-2018.03.21""  curl -XPOST 'http://localhost:9200/partitioned-index-test-2018.03.21/test' -d '{ ""timefield"": ""2018-03-21T12:17:12.00Z"", ""textfield"": ""My text field"" }'  the new elasticsearch index is well created, and there is a new row in my cassandra table. **But there is no document in the elasticsearch index**, and I can read this error in logs  java.lang.RuntimeException: Cannot format given Object as a Date for ks: partitioned_index_keyspace, table: test at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1357) at org.apache.cassandra.db.Keyspace.applyInternal(Keyspace.java:623) at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:467) at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) at org.apache.cassandra.db.Mutation.apply(Mutation.java:232) at org.apache.cassandra.db.Mutation.apply(Mutation.java:241) at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1408) at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2647) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date at java.text.DateFormat.format(DateFormat.java:310) at java.text.Format.format(Format.java:157) at java.text.MessageFormat.subformat(MessageFormat.java:1322) at java.text.MessageFormat.format(MessageFormat.java:865) at java.text.Format.format(Format.java:157) at org.elassandra.index.MessageFormatPartitionFunction.format(MessageFormatPartitionFunction.java:34) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$ImmutablePartitionFunction.indexName(ElasticSecondaryIndex.java:1010) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo.targetIndices(ElasticSecondaryIndex.java:1241) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1871) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer$SkinnyRowcument.index(ElasticSecondaryIndex.java:1447) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer.flush(ElasticSecondaryIndex.java:1483) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer.finish(ElasticSecondaryIndex.java:1598) at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.commit(SecondaryIndexManager.java:983) at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:181) at org.apache.cassandra.db.Memtable.put(Memtable.java:284) at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1339)  11 common frames omitted  Before looking for a potentially bug, I develop my own very simple partition function. Modify my template and re create all from scratch (and restart elassandra of course). **Now, when I push new documents, there is no errors, but still no documents in the Elasticsearch index.** So I add a log message (with slf4j) at the entrance of my partition function.  @Override public String format(String pattern, Object args) { logger.info(""CUSTOM MESSAGE TO TRACE EXECUTION""); return pattern + ""2018.03.21""; }  With this new version, the first time I push a document, **I can see my log message**. But the message **appears randomly** on each new documents. Anyway, **still no document in my Elasticsearch index**, but every document exists in the cassandra table. Did am I the only guy using this feature ? Could you please help me ? Is it a bug, or did I use it in the wrong way ? source-file test-file source-file test-file",no-bug,0.8
135,elassandra,https://github.com/strapdata/elassandra/issues/135,Error while writing unindexed boolean,"<!-- GitHub is reserved for bug reports and feature requests. The best place to ask a general question is at the Elastic Discourse forums at https://discuss.elastic.co. If you are in fact posting a bug report or a feature request, please include one and only one of the below blocks in your new issue. Note that whether you're filing a bug report or a feature request, ensure that your submission is for an [OS that we support](https://www.elastic.co/support/matrix#show_os). Bug reports on an OS that we do not support or feature requests specific to an OS that we do not support will be closed. --> <!-- If you are filing a bug report, please remove the below feature request block and provide responses for all of the below items. --> **Elassandra version**: [ 5.5.0.3, 5.5.0.4, 5.5.0.5 ] **JVM version**: Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode) **OS version**: Linux 4.10.0-38-generic **Description of the problem including expected versus actual behavior**: **Steps to reproduce**: 1. Create an index with a not indexed boolean  PUT elassandra { ""mappings"" : { ""fan"" : { ""dynamic"" : ""strict"", ""properties"" : { ""name"" : { ""type"" : ""text"" }, ""like_elassandra"" : { ""index"" : false, ""type"" : ""boolean"" } } } } }  2. Index a document  PUT elassandra/fan/jxerome { ""name"": ""jxerome"", ""like_elassandra"" : true }  3. The last query fail with this message:  { ""error"": { ""root_cause"": [ { ""type"": ""remote_transport_exception"", ""reason"": ""[127.0.0.1][127.0.0.1:9300][indices:data/write/bulk[s][p]]"" } ], ""type"": ""write_failure_exception"", ""reason"": ""Operation failed - received 0 responses and 1 failures"" }, ""status"": 500 }  **Provide logs (if relevant)**:  2017-11-09 17:22:35,093 ERROR [MutationStage-1] org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1414) Failed to apply mutation locally : {} java.lang.RuntimeException: it doesn't make sense to have a field that is neither indexed nor stored for ks: elassandra, table: fan at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1357) at org.apache.cassandra.db.Keyspace.applyInternal(Keyspace.java:623) at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:467) at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) at org.apache.cassandra.db.Mutation.apply(Mutation.java:232) at org.apache.cassandra.db.Mutation.apply(Mutation.java:241) at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1408) at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2647) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.IllegalArgumentException: it doesn't make sense to have a field that is neither indexed nor stored at org.apache.lucene.document.Field.<init>(Field.java:249) at org.elasticsearch.index.mapper.BooleanFieldMapper.createField(BooleanFieldMapper.java:277) at org.elassandra.index.ElasticSecondaryIndex$Context.addField(ElasticSecondaryIndex.java:404) at org.elassandra.index.ElasticSecondaryIndex$Context.addField(ElasticSecondaryIndex.java:376) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.buildContext(ElasticSecondaryIndex.java:1805) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer$SkinnyRowcument.buildContext(ElasticSecondaryIndex.java:1435) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1874) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1863) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer$SkinnyRowcument.index(ElasticSecondaryIndex.java:1435) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer.flush(ElasticSecondaryIndex.java:1471) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer.finish(ElasticSecondaryIndex.java:1586) at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.commit(SecondaryIndexManager.java:983) at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:181) at org.apache.cassandra.db.Memtable.put(Memtable.java:284) at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1339)  11 common frames omitted ",source-file,"Error while writing unindexed boolean <!-- GitHub is reserved for bug reports and feature requests. The best place to ask a general question is at the Elastic Discourse forums at https://discuss.elastic.co. If you are in fact posting a bug report or a feature request, please include one and only one of the below blocks in your new issue. Note that whether you're filing a bug report or a feature request, ensure that your submission is for an [OS that we support](https://www.elastic.co/support/matrix#show_os). Bug reports on an OS that we do not support or feature requests specific to an OS that we do not support will be closed. --> <!-- If you are filing a bug report, please remove the below feature request block and provide responses for all of the below items. --> **Elassandra version**: [ 5.5.0.3, 5.5.0.4, 5.5.0.5 ] **JVM version**: Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode) **OS version**: Linux 4.10.0-38-generic **Description of the problem including expected versus actual behavior**: **Steps to reproduce**: 1. Create an index with a not indexed boolean  PUT elassandra { ""mappings"" : { ""fan"" : { ""dynamic"" : ""strict"", ""properties"" : { ""name"" : { ""type"" : ""text"" }, ""like_elassandra"" : { ""index"" : false, ""type"" : ""boolean"" } } } } }  2. Index a document  PUT elassandra/fan/jxerome { ""name"": ""jxerome"", ""like_elassandra"" : true }  3. The last query fail with this message:  { ""error"": { ""root_cause"": [ { ""type"": ""remote_transport_exception"", ""reason"": ""[127.0.0.1][127.0.0.1:9300][indices:data/write/bulk[s][p]]"" } ], ""type"": ""write_failure_exception"", ""reason"": ""Operation failed - received 0 responses and 1 failures"" }, ""status"": 500 }  **Provide logs (if relevant)**:  2017-11-09 17:22:35,093 ERROR [MutationStage-1] org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1414) Failed to apply mutation locally : {} java.lang.RuntimeException: it doesn't make sense to have a field that is neither indexed nor stored for ks: elassandra, table: fan at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1357) at org.apache.cassandra.db.Keyspace.applyInternal(Keyspace.java:623) at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:467) at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) at org.apache.cassandra.db.Mutation.apply(Mutation.java:232) at org.apache.cassandra.db.Mutation.apply(Mutation.java:241) at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1408) at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2647) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.IllegalArgumentException: it doesn't make sense to have a field that is neither indexed nor stored at org.apache.lucene.document.Field.<init>(Field.java:249) at org.elasticsearch.index.mapper.BooleanFieldMapper.createField(BooleanFieldMapper.java:277) at org.elassandra.index.ElasticSecondaryIndex$Context.addField(ElasticSecondaryIndex.java:404) at org.elassandra.index.ElasticSecondaryIndex$Context.addField(ElasticSecondaryIndex.java:376) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.buildContext(ElasticSecondaryIndex.java:1805) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer$SkinnyRowcument.buildContext(ElasticSecondaryIndex.java:1435) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1874) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:1863) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer$SkinnyRowcument.index(ElasticSecondaryIndex.java:1435) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$SkinnyRowcumentIndexer.flush(ElasticSecondaryIndex.java:1471) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer.finish(ElasticSecondaryIndex.java:1586) at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.commit(SecondaryIndexManager.java:983) at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:181) at org.apache.cassandra.db.Memtable.put(Memtable.java:284) at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1339)  11 common frames omitted  source-file",no-bug,0.9
2,elassandra,https://github.com/strapdata/elassandra/issues/2,Building and or tarball download,"I am trying to build the source, but I am getting failures due to forbidden method invocations. Failed to execute goal de.thetaphi:forbiddenapis:2.0:check (check-forbidden-apis) on project elassandra: The link to the tarball release also appears to be broken. I would really like to check this project as an alternative to the Datastax distribution and their search based on Solr.",config-file | documentation-file | documentation-file | config-file | documentation-file | documentation-file,"Building and or tarball download I am trying to build the source, but I am getting failures due to forbidden method invocations. Failed to execute goal de.thetaphi:forbiddenapis:2.0:check (check-forbidden-apis) on project elassandra: The link to the tarball release also appears to be broken. I would really like to check this project as an alternative to the Datastax distribution and their search based on Solr. config-file documentation-file documentation-file config-file documentation-file documentation-file",no-bug,0.9
295,elassandra,https://github.com/strapdata/elassandra/issues/295,dots in object mapping ignored,"**Describe the feature**: Dots in object-field names are silently ignored **Elassandra version**: 6.2.3.15 **Plugins installed**: [] **JVM version** (`java -version`): OpenJDK Runtime Environment (build 1.8.0_212-8u212-b01-1~deb9u1-b01) OpenJDK 64-Bit Server VM (build 25.212-b01, mixed mode) **OS version** (`uname -a` if on a Unix-like system): Linux db1-dev 4.9.0-9-amd64 #1 SMP Debian 4.9.168-1+deb9u2 (2019-05-13) x86_64 GNU/Linux **Description of the problem including expected versus actual behavior**: **Steps to reproduce**: **1. Create empty index - e.g. testindex** **2. PUT /testindex/_doc/1** Request-Body: { ""us.er"" : ""test"", ""postdate"" : ""2009-11-15T14:12:12"", ""message"" : ""Test123"" } i get the following response document: { ""_index"": ""testindex"", ""_type"": ""_doc"", ""_id"": ""1"", ""_version"": 1, ""result"": ""created"", ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 } } **3. GET on http://127.0.0.1:9200/testindex/_doc/1** { ""_index"": ""testindex"", ""_type"": ""_doc"", ""_id"": ""1"", ""_version"": 1, ""found"": true, ""_source"": { ""postdate"": ""2009-11-15T14:12:12.000Z"", ""message"": ""Test123"" } } the field with the dot in the name (us.er) is silently ignored.",source-file | test-file,"dots in object mapping ignored **Describe the feature**: Dots in object-field names are silently ignored **Elassandra version**: 6.2.3.15 **Plugins installed**: [] **JVM version** (`java -version`): OpenJDK Runtime Environment (build 1.8.0_212-8u212-b01-1~deb9u1-b01) OpenJDK 64-Bit Server VM (build 25.212-b01, mixed mode) **OS version** (`uname -a` if on a Unix-like system): Linux db1-dev 4.9.0-9-amd64 #1 SMP Debian 4.9.168-1+deb9u2 (2019-05-13) x86_64 GNU/Linux **Description of the problem including expected versus actual behavior**: **Steps to reproduce**: **1. Create empty index - e.g. testindex** **2. PUT /testindex/_doc/1** Request-Body: { ""us.er"" : ""test"", ""postdate"" : ""2009-11-15T14:12:12"", ""message"" : ""Test123"" } i get the following response document: { ""_index"": ""testindex"", ""_type"": ""_doc"", ""_id"": ""1"", ""_version"": 1, ""result"": ""created"", ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 } } **3. GET on http://127.0.0.1:9200/testindex/_doc/1** { ""_index"": ""testindex"", ""_type"": ""_doc"", ""_id"": ""1"", ""_version"": 1, ""found"": true, ""_source"": { ""postdate"": ""2009-11-15T14:12:12.000Z"", ""message"": ""Test123"" } } the field with the dot in the name (us.er) is silently ignored. source-file test-file",bug,0.95
298,elassandra,https://github.com/strapdata/elassandra/issues/298,build_hash and build_date as Unknown after Installing ELS,"Hi, Post installation of elassandra i see output of curl -X GET http://localhost:9200/ having build_hash and build_date as Unknown Could you please fix the same? Thanks Ashish",source-file,"build_hash and build_date as Unknown after Installing ELS Hi, Post installation of elassandra i see output of curl -X GET http://localhost:9200/ having build_hash and build_date as Unknown Could you please fix the same? Thanks Ashish source-file",bug,0.85
257,elassandra,https://github.com/strapdata/elassandra/issues/257,The index is still keeping dynamic update even that index mapping has configured dynamic: false,"<!-- ** Please read the guidelines below. ** Issues that do not follow these guidelines are likely to be closed. 1. GitHub is reserved for bug reports and feature requests. 2. Is this bug report or feature request for a supported OS? If not, it is likely to be closed. See https://www.elastic.co/support/matrix#show_os 3. Please fill out EITHER the feature request block or the bug report block below, and delete the other block. --> <!-- Bug report --> **Elassandra version**: elassandra:5.5.0.24 **Plugins installed**: NONE **JVM version**: openjdk version ""1.8.0_181"" OpenJDK Runtime Environment (build 1.8.0_181-8u181-b13-1~deb9u1-b13) OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode) **OS version**: 3.10.0-862.9.1.el7.x86_64 x86_64 GNU/Linux **Description of the problem including expected versus actual behavior**: We setup a small elassandra cluster(3 nodes) **Problem**: Elassandra dynamically updates the index mapping when inserted a new row with more new keys in a map field, even the index mapping has set the **dynamic** flag to **false** **Expected behavior**: Elassandra keeps the index mapping as it once created. https://www.elastic.co/guide/en/elasticsearch/reference/5.5/dynamic.html **Steps to reproduce**: 1. create the key space 'mytest' and table 'mymaptable': <pre> CREATE KEYSPACE mytest WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'DC1': '2'}; use mytest; CREATE TABLE mymaptable ( id text, name text, counters map<text, int>, PRIMARY KEY ( id ) ); </pre> 2. create index 'dyntest ' `curl -XPUT http://localhost:9200/dyntest -d @/dyn_mapping_check.json` the **dyn_mapping_check.json** content: <pre> { ""settings"": { ""keyspace"": ""mytest"" }, ""mappings"": { ""mymaptable"": { ""dynamic"": false, ""properties"": { ""id"": { ""type"": ""keyword"", ""cql_partition_key"" : true, ""cql_collection"": ""singleton"", ""cql_primary_key_order"": 0 }, ""name"": { ""type"": ""keyword"", ""cql_collection"": ""singleton"" }, ""counters"": { ""dynamic"": false, ""type"": ""nested"", ""cql_struct"": ""map"", ""cql_collection"": ""singleton"", ""properties"": { ""retry"": { ""type"": ""integer"" }, ""fail"": { ""type"": ""integer"" } } } } } } } </pre> 3. use cqlsh tool to insert 2 rows: <pre> insert into mytest.mymaptable (id, name, counters) values ('john.d', 'john', {'tps':1000, 'retry':1}); </pre> <pre> insert into mytest.mymaptable (id, name, counters) values ('Kelly.S', 'kelly', {'tps':1200, 'fail':2, 'pending':100}); </pre> 4. check whether the index mapping keep as it: curl -XGET http://localhost:9200/dyntest?pretty <pre> { ""dyntest"" : { ""aliases"" : { }, ""mappings"" : { ""mymaptable"" : { ""dynamic"" : ""false"", ""properties"" : { ""counters"" : { ""type"" : ""nested"", ""cql_struct"" : ""map"", ""cql_collection"" : ""singleton"", ""dynamic"" : ""false"", ""properties"" : { ""fail"" : { ""type"" : ""integer"" }, ""pending"" : { ""type"" : ""integer"" }, ""retry"" : { ""type"" : ""integer"" }, ""tps"" : { ""type"" : ""integer"" } } }, ""id"" : { ""type"" : ""keyword"", ""cql_collection"" : ""singleton"", ""cql_partition_key"" : true, ""cql_primary_key_order"" : 0 }, ""name"" : { ""type"" : ""keyword"", ""cql_collection"" : ""singleton"" } } } }, ""settings"" : { ""index"" : { ""keyspace"" : ""mytest"", ""number_of_shards"" : ""3"", ""provided_name"" : ""dyntest"", ""creation_date"" : ""1545887324964"", ""number_of_replicas"" : ""1"", ""uuid"" : ""XaWOdvh9STa--IIk6PcNFA"", ""version"" : { ""created"" : ""5050099"" } } } } } </pre> We saw that all the keys in the map field have been updated to the index mapping. The expected behavior is it shall keep as **only having ""retry"" and ""fail""** @vroyer If there is any more information required, please let me know, thanks.",source-file | source-file | test-file,"The index is still keeping dynamic update even that index mapping has configured dynamic: false <!-- ** Please read the guidelines below. ** Issues that do not follow these guidelines are likely to be closed. 1. GitHub is reserved for bug reports and feature requests. 2. Is this bug report or feature request for a supported OS? If not, it is likely to be closed. See https://www.elastic.co/support/matrix#show_os 3. Please fill out EITHER the feature request block or the bug report block below, and delete the other block. --> <!-- Bug report --> **Elassandra version**: elassandra:5.5.0.24 **Plugins installed**: NONE **JVM version**: openjdk version ""1.8.0_181"" OpenJDK Runtime Environment (build 1.8.0_181-8u181-b13-1~deb9u1-b13) OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode) **OS version**: 3.10.0-862.9.1.el7.x86_64 x86_64 GNU/Linux **Description of the problem including expected versus actual behavior**: We setup a small elassandra cluster(3 nodes) **Problem**: Elassandra dynamically updates the index mapping when inserted a new row with more new keys in a map field, even the index mapping has set the **dynamic** flag to **false** **Expected behavior**: Elassandra keeps the index mapping as it once created. https://www.elastic.co/guide/en/elasticsearch/reference/5.5/dynamic.html **Steps to reproduce**: 1. create the key space 'mytest' and table 'mymaptable': <pre> CREATE KEYSPACE mytest WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'DC1': '2'}; use mytest; CREATE TABLE mymaptable ( id text, name text, counters map<text, int>, PRIMARY KEY ( id ) ); </pre> 2. create index 'dyntest ' `curl -XPUT http://localhost:9200/dyntest -d @/dyn_mapping_check.json` the **dyn_mapping_check.json** content: <pre> { ""settings"": { ""keyspace"": ""mytest"" }, ""mappings"": { ""mymaptable"": { ""dynamic"": false, ""properties"": { ""id"": { ""type"": ""keyword"", ""cql_partition_key"" : true, ""cql_collection"": ""singleton"", ""cql_primary_key_order"": 0 }, ""name"": { ""type"": ""keyword"", ""cql_collection"": ""singleton"" }, ""counters"": { ""dynamic"": false, ""type"": ""nested"", ""cql_struct"": ""map"", ""cql_collection"": ""singleton"", ""properties"": { ""retry"": { ""type"": ""integer"" }, ""fail"": { ""type"": ""integer"" } } } } } } } </pre> 3. use cqlsh tool to insert 2 rows: <pre> insert into mytest.mymaptable (id, name, counters) values ('john.d', 'john', {'tps':1000, 'retry':1}); </pre> <pre> insert into mytest.mymaptable (id, name, counters) values ('Kelly.S', 'kelly', {'tps':1200, 'fail':2, 'pending':100}); </pre> 4. check whether the index mapping keep as it: curl -XGET http://localhost:9200/dyntest?pretty <pre> { ""dyntest"" : { ""aliases"" : { }, ""mappings"" : { ""mymaptable"" : { ""dynamic"" : ""false"", ""properties"" : { ""counters"" : { ""type"" : ""nested"", ""cql_struct"" : ""map"", ""cql_collection"" : ""singleton"", ""dynamic"" : ""false"", ""properties"" : { ""fail"" : { ""type"" : ""integer"" }, ""pending"" : { ""type"" : ""integer"" }, ""retry"" : { ""type"" : ""integer"" }, ""tps"" : { ""type"" : ""integer"" } } }, ""id"" : { ""type"" : ""keyword"", ""cql_collection"" : ""singleton"", ""cql_partition_key"" : true, ""cql_primary_key_order"" : 0 }, ""name"" : { ""type"" : ""keyword"", ""cql_collection"" : ""singleton"" } } } }, ""settings"" : { ""index"" : { ""keyspace"" : ""mytest"", ""number_of_shards"" : ""3"", ""provided_name"" : ""dyntest"", ""creation_date"" : ""1545887324964"", ""number_of_replicas"" : ""1"", ""uuid"" : ""XaWOdvh9STa--IIk6PcNFA"", ""version"" : { ""created"" : ""5050099"" } } } } } </pre> We saw that all the keys in the map field have been updated to the index mapping. The expected behavior is it shall keep as **only having ""retry"" and ""fail""** @vroyer If there is any more information required, please let me know, thanks. source-file source-file test-file",no-bug,0.9
199,elassandra,https://github.com/strapdata/elassandra/issues/199,Deletion of ALL elements of a List doesn't removes the document on ES,"**Elassandra version**: 5.5.0.18 The problem occurs from a table with a compound key and a list of any type. When the last element of the list is removed, the row is deleted from cassandra but the document remains on ES without the source. **Steps to reproduce**: 1. Given the table sql CREATE TABLE table_test ( id1 text, id2 text, list list<text>, PRIMARY KEY (id1, id2) );  2. The ES index mapping json { ""settings"": { ""keyspace"": ""ks_test"" }, ""mappings"": { ""table_test"": { ""discover"": "".*"" } } }  3. Insert a row into the table: sql UPDATE table_test SET list = list + ['foo'] where id1='1' and id2='2';  4. Search the document on ES: bash get ks_test/_search?pretty=true  json { ""took"" : 2, ""timed_out"" : false, ""_shards"" : { ""total"" : 1, ""successful"" : 1, ""failed"" : 0 }, ""hits"" : { ""total"" : 1, ""max_score"" : 1.0, ""hits"" : [ { ""_index"" : ""ks_test"", ""_type"" : ""table_test"", ""_id"" : ""[\""1\"",\""2\""]"", ""_score"" : 1.0, ""_source"" : { ""id2"" : ""2"", ""id1"" : ""1"", ""list"" : ""foo"" } } ] }  5. Remove the last element from the list: sql UPDATE table_test SET list = list - ['foo'] where id1='1' and id2='2';  6. Search the document on ES again: bash get ks_test/_search?pretty=true  json { ""took"" : 1, ""timed_out"" : false, ""_shards"" : { ""total"" : 1, ""successful"" : 1, ""failed"" : 0 }, ""hits"" : { ""total"" : 1, ""max_score"" : 1.0, ""hits"" : [ { ""_index"" : ""ks_test"", ""_type"" : ""table_test"", ""_id"" : ""[\""1\"",\""2\""]"", ""_score"" : 1.0 } ] } }  7. But on Cassandra sql SELECT * FROM table_test;  plain id1 | id2 | list ++ (0 rows)  Thanks in advance.",source-file | test-file | source-file | test-file | test-file | source-file,"Deletion of ALL elements of a List doesn't removes the document on ES **Elassandra version**: 5.5.0.18 The problem occurs from a table with a compound key and a list of any type. When the last element of the list is removed, the row is deleted from cassandra but the document remains on ES without the source. **Steps to reproduce**: 1. Given the table sql CREATE TABLE table_test ( id1 text, id2 text, list list<text>, PRIMARY KEY (id1, id2) );  2. The ES index mapping json { ""settings"": { ""keyspace"": ""ks_test"" }, ""mappings"": { ""table_test"": { ""discover"": "".*"" } } }  3. Insert a row into the table: sql UPDATE table_test SET list = list + ['foo'] where id1='1' and id2='2';  4. Search the document on ES: bash get ks_test/_search?pretty=true  json { ""took"" : 2, ""timed_out"" : false, ""_shards"" : { ""total"" : 1, ""successful"" : 1, ""failed"" : 0 }, ""hits"" : { ""total"" : 1, ""max_score"" : 1.0, ""hits"" : [ { ""_index"" : ""ks_test"", ""_type"" : ""table_test"", ""_id"" : ""[\""1\"",\""2\""]"", ""_score"" : 1.0, ""_source"" : { ""id2"" : ""2"", ""id1"" : ""1"", ""list"" : ""foo"" } } ] }  5. Remove the last element from the list: sql UPDATE table_test SET list = list - ['foo'] where id1='1' and id2='2';  6. Search the document on ES again: bash get ks_test/_search?pretty=true  json { ""took"" : 1, ""timed_out"" : false, ""_shards"" : { ""total"" : 1, ""successful"" : 1, ""failed"" : 0 }, ""hits"" : { ""total"" : 1, ""max_score"" : 1.0, ""hits"" : [ { ""_index"" : ""ks_test"", ""_type"" : ""table_test"", ""_id"" : ""[\""1\"",\""2\""]"", ""_score"" : 1.0 } ] } }  7. But on Cassandra sql SELECT * FROM table_test;  plain id1 | id2 | list ++ (0 rows)  Thanks in advance. source-file test-file source-file test-file test-file source-file",no-bug,0.9
283,elassandra,https://github.com/strapdata/elassandra/issues/283,Elassandra multi data center replication,"I have setup multi data center elassandra cluster. Created keyspace with `RF=2` and a table `connects`  CREATE KEYSPACE IF NOT EXISTS mystiko WITH replication = { 'class':'NetworkTopologyStrategy', 'DC1':'2', 'DC2':'2' }; CREATE TABLE IF NOT EXISTS mystiko.connects ( account TEXT, salt TEXT, signature TEXT, verified BOOLEAN, timestamp TIMESTAMP, PRIMARY KEY(account) );  Then created elastic index with the `connects` table from DC1 node.  curl -XPUT ""http://172.31.20.177:9200/connects"" -d '{ ""settings"":{ ""keyspace"": ""mystiko"" }, ""mappings"": { ""connects"" : { ""discover"" : "".*"" } } } '  When I'm looking at the elastic index replications, in one data center it gives `3` and other data center it gives `1`. Is this the known behavior of elassandra? DC1  ""settings"" : { ""index"" : { ""keyspace"" : ""mystiko"", ""number_of_shards"" : ""1"", ""provided_name"" : ""connects"", ""creation_date"" : ""1556749099033"", ""number_of_replicas"" : ""3"", ""uuid"" : ""GUEyLFy6S_m7k39hPqD7lg"", ""version"" : { ""created"" : ""5050099"" } } },  DC2  ""settings"" : { ""index"" : { ""keyspace"" : ""mystiko"", ""number_of_shards"" : ""1"", ""provided_name"" : ""connects"", ""creation_date"" : ""1556749099033"", ""number_of_replicas"" : ""1"", ""uuid"" : ""GUEyLFy6S_m7k39hPqD7lg"", ""version"" : { ""created"" : ""5050099"" } } }  Is there any way to have the same elastic replication on each data center?",source-file,"Elassandra multi data center replication I have setup multi data center elassandra cluster. Created keyspace with `RF=2` and a table `connects`  CREATE KEYSPACE IF NOT EXISTS mystiko WITH replication = { 'class':'NetworkTopologyStrategy', 'DC1':'2', 'DC2':'2' }; CREATE TABLE IF NOT EXISTS mystiko.connects ( account TEXT, salt TEXT, signature TEXT, verified BOOLEAN, timestamp TIMESTAMP, PRIMARY KEY(account) );  Then created elastic index with the `connects` table from DC1 node.  curl -XPUT ""http://172.31.20.177:9200/connects"" -d '{ ""settings"":{ ""keyspace"": ""mystiko"" }, ""mappings"": { ""connects"" : { ""discover"" : "".*"" } } } '  When I'm looking at the elastic index replications, in one data center it gives `3` and other data center it gives `1`. Is this the known behavior of elassandra? DC1  ""settings"" : { ""index"" : { ""keyspace"" : ""mystiko"", ""number_of_shards"" : ""1"", ""provided_name"" : ""connects"", ""creation_date"" : ""1556749099033"", ""number_of_replicas"" : ""3"", ""uuid"" : ""GUEyLFy6S_m7k39hPqD7lg"", ""version"" : { ""created"" : ""5050099"" } } },  DC2  ""settings"" : { ""index"" : { ""keyspace"" : ""mystiko"", ""number_of_shards"" : ""1"", ""provided_name"" : ""connects"", ""creation_date"" : ""1556749099033"", ""number_of_replicas"" : ""1"", ""uuid"" : ""GUEyLFy6S_m7k39hPqD7lg"", ""version"" : { ""created"" : ""5050099"" } } }  Is there any way to have the same elastic replication on each data center? source-file",no-bug,0.9
187,elassandra,https://github.com/strapdata/elassandra/issues/187,"row removed in cassandra, but the the corresponding document not removed from Elasticsearch","**Elassandra version**: 5.5.0.10 **JVM version**: JDK 1.8 **OS version**: CentOS release 6.5 (Final) **Description of the problem including expected versus actual behavior**: I have two data center elassandra which 3 nodes started as ""bin/cassandra"" and 2 other nodes started as ""bin/cassandra -e"" I have the following random problem: sometimes when deletion a row within cql command the row seems deleted successfully from cassandra , but when executing elasticsearch search query the deleted document already exists without _source document as documents ""xxxxx"" and ""yyyyy"" as follow: QUERY GET : my_index/_search RESULT: { ""took"": 5, ""timed_out"": false, ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 }, ""hits"": { ""total"": 6, ""max_score"": 1, ""hits"": [ { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""test_1"", ""_score"": 1, ""_source"": { ""field_id"": ""test_1"", ""field2"": ""description 1"" } }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""test"", ""_score"": 1, ""_source"": { ""field_id"": ""test"" } }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""test_3"", ""_score"": 1, ""_source"": { ""field_id"": ""test_3"", ""field2"": ""description 3"" } }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""test_4"", ""_score"": 1, ""_source"": { ""field_id"": ""test_4"", ""field2"": ""description 4"" } }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""xxxxx"", ""_score"": 1 }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""yyyyy"", ""_score"": 1 } ] } }",source-file | source-file,"row removed in cassandra, but the the corresponding document not removed from Elasticsearch **Elassandra version**: 5.5.0.10 **JVM version**: JDK 1.8 **OS version**: CentOS release 6.5 (Final) **Description of the problem including expected versus actual behavior**: I have two data center elassandra which 3 nodes started as ""bin/cassandra"" and 2 other nodes started as ""bin/cassandra -e"" I have the following random problem: sometimes when deletion a row within cql command the row seems deleted successfully from cassandra , but when executing elasticsearch search query the deleted document already exists without _source document as documents ""xxxxx"" and ""yyyyy"" as follow: QUERY GET : my_index/_search RESULT: { ""took"": 5, ""timed_out"": false, ""_shards"": { ""total"": 1, ""successful"": 1, ""failed"": 0 }, ""hits"": { ""total"": 6, ""max_score"": 1, ""hits"": [ { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""test_1"", ""_score"": 1, ""_source"": { ""field_id"": ""test_1"", ""field2"": ""description 1"" } }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""test"", ""_score"": 1, ""_source"": { ""field_id"": ""test"" } }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""test_3"", ""_score"": 1, ""_source"": { ""field_id"": ""test_3"", ""field2"": ""description 3"" } }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""test_4"", ""_score"": 1, ""_source"": { ""field_id"": ""test_4"", ""field2"": ""description 4"" } }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""xxxxx"", ""_score"": 1 }, { ""_index"": ""my_index"", ""_type"": ""my_type"", ""_id"": ""yyyyy"", ""_score"": 1 } ] } } source-file source-file",no-bug,0.8
262,elassandra,https://github.com/strapdata/elassandra/issues/262,Log corruption edge case when TOKENS= epState is printed to console,"**Elassandra version**: 6.2.3.10 (docker) **Plugins installed**: [] **JVM version** (`java -version`): OpenJDK Runtime Environment (build 1.8.0_181-8u181-b13-2~deb9u1-b13) **OS version** (`uname -a` if on a Unix-like system): Kubernetes, I don't think it matters though. **Description of the problem including expected versus actual behavior**: There's an edge case where the altcharset gets toggled in the logs. When variable `epState` is printed to stdout, it's possible that `TOKENS=` contains data that will render the remaining logs in the terminal's alternate charset. `./server/src/main/java/org/elassandra/discovery/CassandraDiscovery.java`, function `onDead()`: **Steps to reproduce**: 1. Start StatefulSet with strapdata/kubernetes-elassandra. 2. Abnormal output: 2019-02-05 18:57:16,395 INFO [GossipStage:1] org.apache.cassandra.gms.Gossiper.markDead(Gossiper.java:1034) InetAddress /10.20.4.14 is now DOWN 2019-02-05 18:57:16,398 DEBUG [GossipStage:1] org.elassandra.discovery.CassandraDiscovery.onDead(CassandraDiscovery.java:643) Endpoint=/10.20.4.14 ApplicationState=EndpointState: HeartBeatState = HeartBeat: generation = 1549393035, version = 2147483647, AppStateMap = {STATUS=Value(shutdown,true,423), SCHEMA=Value(347c7dcb-ff5e-3f1f-b8a8-ab52c6e23b63,12), DC=Value(DC1,8), RACK=Value(r1,10), RELEASE_VERSION=Value(3.11.3,4), INTERNAL_IP=Value(10.20.4.14,6), RPC_ADDRESS=Value(10.20.4.14,3), NET_VERSION=Value(11,1), HOST_ID=Value(47efcc56-1fd9-4fca-8547-cdde17e13f33,2), TOKENS=Value^z wOxPUB 1!= ;MQ_15) RPC_READY=Ve(e424) Ae=e => de de  dcec 3. Normal output: 2019-02-05 18:55:07,371 INFO [STREAM-IN-/10.20.4.14:47834] org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:219) [Stream #8dc5d370-2977-11e9-8d6d-07bf72afb10a] All sessions completed 2019-02-05 18:55:07,646 INFO [GossipStage:1] org.apache.cassandra.gms.Gossiper.markDead(Gossiper.java:1034) InetAddress /10.20.4.14 is now DOWN 2019-02-05 18:55:07,647 DEBUG [GossipStage:1] org.elassandra.discovery.CassandraDiscovery.onDead(CassandraDiscovery.java:643) Endpoint=/10.20.4.14 ApplicationState=EndpointState: HeartBeatState = HeartBeat: generation = 1549392868, version = 2147483647, AppStateMap = {STATUS=Value(shutdown,true,192), LOAD=Value(30768.0,16), SCHEMA=Value(347c7dcb-ff5e-3f1f-b8a8-ab52c6e23b63,32), DC=Value(DC1,8), RACK=Value(r1,10), RELEASE_VERSION=Value(3.11.3,4), INTERNAL_IP=Value(10.20.4.14,6), RPC_ADDRESS=Value(10.20.4.14,3), NET_VERSION=Value(11,1), HOST_ID=Value(47efcc56-1fd9-4fca-8547-cdde17e13f33,2), TOKENS=Value!= ;}k^z 1MQ_PUndraDiscovery.java:854) Add node host_id=47efcc56-1fd9-4fca-8547-cdde17e13f33 endpoint=10.20.4.14 internal_ip=10.20.4.14, rpc_address=10.20.4.14, status=DISABLED Sorry about lack of code block formatting, Github Markdown was frustrating.",source-file,"Log corruption edge case when TOKENS= epState is printed to console **Elassandra version**: 6.2.3.10 (docker) **Plugins installed**: [] **JVM version** (`java -version`): OpenJDK Runtime Environment (build 1.8.0_181-8u181-b13-2~deb9u1-b13) **OS version** (`uname -a` if on a Unix-like system): Kubernetes, I don't think it matters though. **Description of the problem including expected versus actual behavior**: There's an edge case where the altcharset gets toggled in the logs. When variable `epState` is printed to stdout, it's possible that `TOKENS=` contains data that will render the remaining logs in the terminal's alternate charset. `./server/src/main/java/org/elassandra/discovery/CassandraDiscovery.java`, function `onDead()`: **Steps to reproduce**: 1. Start StatefulSet with strapdata/kubernetes-elassandra. 2. Abnormal output: 2019-02-05 18:57:16,395 INFO [GossipStage:1] org.apache.cassandra.gms.Gossiper.markDead(Gossiper.java:1034) InetAddress /10.20.4.14 is now DOWN 2019-02-05 18:57:16,398 DEBUG [GossipStage:1] org.elassandra.discovery.CassandraDiscovery.onDead(CassandraDiscovery.java:643) Endpoint=/10.20.4.14 ApplicationState=EndpointState: HeartBeatState = HeartBeat: generation = 1549393035, version = 2147483647, AppStateMap = {STATUS=Value(shutdown,true,423), SCHEMA=Value(347c7dcb-ff5e-3f1f-b8a8-ab52c6e23b63,12), DC=Value(DC1,8), RACK=Value(r1,10), RELEASE_VERSION=Value(3.11.3,4), INTERNAL_IP=Value(10.20.4.14,6), RPC_ADDRESS=Value(10.20.4.14,3), NET_VERSION=Value(11,1), HOST_ID=Value(47efcc56-1fd9-4fca-8547-cdde17e13f33,2), TOKENS=Value^z wOxPUB 1!= ;MQ_15) RPC_READY=Ve(e424) Ae=e => de de  dcec 3. Normal output: 2019-02-05 18:55:07,371 INFO [STREAM-IN-/10.20.4.14:47834] org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:219) [Stream #8dc5d370-2977-11e9-8d6d-07bf72afb10a] All sessions completed 2019-02-05 18:55:07,646 INFO [GossipStage:1] org.apache.cassandra.gms.Gossiper.markDead(Gossiper.java:1034) InetAddress /10.20.4.14 is now DOWN 2019-02-05 18:55:07,647 DEBUG [GossipStage:1] org.elassandra.discovery.CassandraDiscovery.onDead(CassandraDiscovery.java:643) Endpoint=/10.20.4.14 ApplicationState=EndpointState: HeartBeatState = HeartBeat: generation = 1549392868, version = 2147483647, AppStateMap = {STATUS=Value(shutdown,true,192), LOAD=Value(30768.0,16), SCHEMA=Value(347c7dcb-ff5e-3f1f-b8a8-ab52c6e23b63,32), DC=Value(DC1,8), RACK=Value(r1,10), RELEASE_VERSION=Value(3.11.3,4), INTERNAL_IP=Value(10.20.4.14,6), RPC_ADDRESS=Value(10.20.4.14,3), NET_VERSION=Value(11,1), HOST_ID=Value(47efcc56-1fd9-4fca-8547-cdde17e13f33,2), TOKENS=Value!= ;}k^z 1MQ_PUndraDiscovery.java:854) Add node host_id=47efcc56-1fd9-4fca-8547-cdde17e13f33 endpoint=10.20.4.14 internal_ip=10.20.4.14, rpc_address=10.20.4.14, status=DISABLED Sorry about lack of code block formatting, Github Markdown was frustrating. source-file",no-bug,0.9
188,elassandra,https://github.com/strapdata/elassandra/issues/188,Index not found on most indexes,"**Elasticsearch version**: 5.5.0.13 **Plugins installed**: [] Tried to and failed **JVM version**: 1.8 **OS version**: ubuntu 16.04 We were trying to install a plugin and it went into jarhell. We stopped elassandra (docker image) and re-downloaded the image and re-installed. Since then we are getting 404 error on most indexes. Here is an example: We created then referenced index and got back an acknowledged. It took some time though. Here is the post curl http://inception.cevalogistics.com:9200/_cat/indices?v -XPUT 'inception.cevalogistics.com:9200/driverperf_v1/driverperf_v1/1' -d ' {""Pkey"":""1"",""STOP_ID"":""383733289"",""TRIP_ID"":""106729811"",""EVENT_TYPE"":""ARRIVAL"",""SCHED_EVENT_DATE"":""2017-02-13 11:59:00Z"",""ACTUAL_EVENT_DATE"":""2017-02-13 14:00:00"",""LATE_STATUS"":""Late"",""ONTIME_STATUS"":""Late"",""EVENT_REASON"":""No Status"",""LEG_TYPE"":""Pickup"",""ROUTE_NAME"":""Demo-Gen"",""DRIVER"":""Wattana Arsanok"",""BUSINESS_UNIT"":""271 CEVA Ground Thailand"",""SVC_PROVIDER"":""CGTO"",""STOP_NBR"":""1"",""SCHED_VS_ACTUAL_MINS"":121,""TRIP_STATUS"":""Complete"",""SERVICE_TIME_MINS"":2,""LOCATION_TYPE"":""Warehouse Facility"",""FINAL_DLVY_STATUS"":""Completed"",""STOP_STATE"":""BKK"",""STOP_COUNTRY"":""THAILAND"",""GEO"":""0,0""} ' {""error"":{""root_cause"":[{""type"":""index_not_found_exception"",""reason"":""no such index"",""index_uuid"":""IhC82nztR76akRo-uV0PRA"",""index"":""driverperf_v1""}],""type"":""index_not_found_exception"",""reason"":""no such index"",""index_uuid"":""IhC82nztR76akRo-uV0PRA"",""index"":""driverperf_v1""},""status"":404} MacBook-Pro-2:~ liottar$ curl http://inception.logistics.corp:9200/_cat/indices green open poc_training PvumvsazTgyJnPisTHuRFA 6 0 2 0 13.4kb 13.4kb red* open driverperf_v1 IhC82nztR76akRo-uV0PRA green open .kibana 60q4nNzrTqSqTd5ztckASw 6 0 9 0 50.9kb 50.9kb red* open wmsskuet QHR0roXvQ66LICG3aZltZA red* open gtnx_purchase_order 0A5Tb-GXQrSpmN1oeBDhQQ red* open prdedi Mw5gBIs8Q-2ZRp1REikJCA red* open gtnx_shipment_v1 ntyLLHQwQmqAy0Kxd3dZfg green open gtnx_shipment_v2 zUNifXgSRKyiSv_49_FWJg 6 0 0 0 618b 618b red* open driverperf ZoF29x-5RJ-v4WGyudFa1g I tried to re-index the ones in red but they all come back 404 Any ideas?",source-file,"Index not found on most indexes **Elasticsearch version**: 5.5.0.13 **Plugins installed**: [] Tried to and failed **JVM version**: 1.8 **OS version**: ubuntu 16.04 We were trying to install a plugin and it went into jarhell. We stopped elassandra (docker image) and re-downloaded the image and re-installed. Since then we are getting 404 error on most indexes. Here is an example: We created then referenced index and got back an acknowledged. It took some time though. Here is the post curl http://inception.cevalogistics.com:9200/_cat/indices?v -XPUT 'inception.cevalogistics.com:9200/driverperf_v1/driverperf_v1/1' -d ' {""Pkey"":""1"",""STOP_ID"":""383733289"",""TRIP_ID"":""106729811"",""EVENT_TYPE"":""ARRIVAL"",""SCHED_EVENT_DATE"":""2017-02-13 11:59:00Z"",""ACTUAL_EVENT_DATE"":""2017-02-13 14:00:00"",""LATE_STATUS"":""Late"",""ONTIME_STATUS"":""Late"",""EVENT_REASON"":""No Status"",""LEG_TYPE"":""Pickup"",""ROUTE_NAME"":""Demo-Gen"",""DRIVER"":""Wattana Arsanok"",""BUSINESS_UNIT"":""271 CEVA Ground Thailand"",""SVC_PROVIDER"":""CGTO"",""STOP_NBR"":""1"",""SCHED_VS_ACTUAL_MINS"":121,""TRIP_STATUS"":""Complete"",""SERVICE_TIME_MINS"":2,""LOCATION_TYPE"":""Warehouse Facility"",""FINAL_DLVY_STATUS"":""Completed"",""STOP_STATE"":""BKK"",""STOP_COUNTRY"":""THAILAND"",""GEO"":""0,0""} ' {""error"":{""root_cause"":[{""type"":""index_not_found_exception"",""reason"":""no such index"",""index_uuid"":""IhC82nztR76akRo-uV0PRA"",""index"":""driverperf_v1""}],""type"":""index_not_found_exception"",""reason"":""no such index"",""index_uuid"":""IhC82nztR76akRo-uV0PRA"",""index"":""driverperf_v1""},""status"":404} MacBook-Pro-2:~ liottar$ curl http://inception.logistics.corp:9200/_cat/indices green open poc_training PvumvsazTgyJnPisTHuRFA 6 0 2 0 13.4kb 13.4kb red* open driverperf_v1 IhC82nztR76akRo-uV0PRA green open .kibana 60q4nNzrTqSqTd5ztckASw 6 0 9 0 50.9kb 50.9kb red* open wmsskuet QHR0roXvQ66LICG3aZltZA red* open gtnx_purchase_order 0A5Tb-GXQrSpmN1oeBDhQQ red* open prdedi Mw5gBIs8Q-2ZRp1REikJCA red* open gtnx_shipment_v1 ntyLLHQwQmqAy0Kxd3dZfg green open gtnx_shipment_v2 zUNifXgSRKyiSv_49_FWJg 6 0 0 0 618b 618b red* open driverperf ZoF29x-5RJ-v4WGyudFa1g I tried to re-index the ones in red but they all come back 404 Any ideas? source-file",no-bug,0.9
296,elassandra,https://github.com/strapdata/elassandra/issues/296,Setting null_value on an integer field causes an exception,"Hello, I am seeing an exception when I attempt to create a mapping for a UDT with the following attributes. Removing the `null_value` from the `foo` property fixes the issue, leading me to believe there is some issue with `null_value` and integers.  ""something"": { ""type"": ""nested"", ""cql_udt_name"": ""something_udt"", ""cql_collection"": ""singleton"", ""properties"": { ""foo"": { ""type"": ""integer"", ""null_value"": ""0"", ""cql_collection"": ""singleton"", ""fields"": { ""raw"": { ""type"": ""integer"", ""null_value"": ""0"" } } }, ""bar"": { ""type"": ""keyword"", ""null_value"": ""NULL"", ""cql_collection"": ""singleton"", ""normalizer"": ""custom_normalizer"", ""fields"": { ""raw"": { ""type"": ""keyword"", ""null_value"": ""NULL"" } } }, ""baz"": { ""type"": ""keyword"", ""null_value"": ""NULL"", ""cql_collection"": ""singleton"", ""normalizer"": ""custom_normalizer"", ""fields"": { ""raw"": { ""type"": ""keyword"", ""null_value"": ""NULL"" } } }, ""value"": { ""type"": ""float"", ""null_value"": ""0"", ""cql_collection"": ""singleton"", ""fields"": { ""raw"": { ""type"": ""float"", ""null_value"": ""0"" } } } } },  The exception:  java.lang.NullPointerException: null at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$6.createFields(NumberFieldMapper.java:696) at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$4.createFields(NumberFieldMapper.java:516) at org.elasticsearch.index.mapper.NumberFieldMapper.createField(NumberFieldMapper.java:1151) at org.elassandra.index.ElasticSecondaryIndex.addField(ElasticSecondaryIndex.java:390) at org.elassandra.index.ElasticSecondaryIndex.addField(ElasticSecondaryIndex.java:485) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.buildContext(ElasticSecondaryIndex.java:2074) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.buildContext(ElasticSecondaryIndex.java:1421) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:2160) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:2144) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.index(ElasticSecondaryIndex.java:1421) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.write(ElasticSecondaryIndex.java:2127) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.write(ElasticSecondaryIndex.java:1421) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer.readBeforeWrite(ElasticSecondaryIndex.java:1474) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer.update(ElasticSecondaryIndex.java:1542) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer.finish(ElasticSecondaryIndex.java:1845) at java.lang.Iterable.forEach(Iterable.java:75) at org.apache.cassandra.index.SecondaryIndexManager.indexPartition(SecondaryIndexManager.java:642) at org.apache.cassandra.index.internal.CollatedViewIndexBuilder.build(CollatedViewIndexBuilder.java:139) at org.apache.cassandra.db.compaction.CompactionManager$14.run(CompactionManager.java:1637) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81) at java.lang.Thread.run(Thread.java:748)  Let me know if you need any information from me. Thanks.",source-file | test-file,"Setting null_value on an integer field causes an exception Hello, I am seeing an exception when I attempt to create a mapping for a UDT with the following attributes. Removing the `null_value` from the `foo` property fixes the issue, leading me to believe there is some issue with `null_value` and integers.  ""something"": { ""type"": ""nested"", ""cql_udt_name"": ""something_udt"", ""cql_collection"": ""singleton"", ""properties"": { ""foo"": { ""type"": ""integer"", ""null_value"": ""0"", ""cql_collection"": ""singleton"", ""fields"": { ""raw"": { ""type"": ""integer"", ""null_value"": ""0"" } } }, ""bar"": { ""type"": ""keyword"", ""null_value"": ""NULL"", ""cql_collection"": ""singleton"", ""normalizer"": ""custom_normalizer"", ""fields"": { ""raw"": { ""type"": ""keyword"", ""null_value"": ""NULL"" } } }, ""baz"": { ""type"": ""keyword"", ""null_value"": ""NULL"", ""cql_collection"": ""singleton"", ""normalizer"": ""custom_normalizer"", ""fields"": { ""raw"": { ""type"": ""keyword"", ""null_value"": ""NULL"" } } }, ""value"": { ""type"": ""float"", ""null_value"": ""0"", ""cql_collection"": ""singleton"", ""fields"": { ""raw"": { ""type"": ""float"", ""null_value"": ""0"" } } } } },  The exception:  java.lang.NullPointerException: null at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$6.createFields(NumberFieldMapper.java:696) at org.elasticsearch.index.mapper.NumberFieldMapper$NumberType$4.createFields(NumberFieldMapper.java:516) at org.elasticsearch.index.mapper.NumberFieldMapper.createField(NumberFieldMapper.java:1151) at org.elassandra.index.ElasticSecondaryIndex.addField(ElasticSecondaryIndex.java:390) at org.elassandra.index.ElasticSecondaryIndex.addField(ElasticSecondaryIndex.java:485) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.buildContext(ElasticSecondaryIndex.java:2074) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.buildContext(ElasticSecondaryIndex.java:1421) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:2160) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.index(ElasticSecondaryIndex.java:2144) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.index(ElasticSecondaryIndex.java:1421) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer$Rowcument.write(ElasticSecondaryIndex.java:2127) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer$WideRowcument.write(ElasticSecondaryIndex.java:1421) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer.readBeforeWrite(ElasticSecondaryIndex.java:1474) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$WideRowcumentIndexer.update(ElasticSecondaryIndex.java:1542) at org.elassandra.index.ElasticSecondaryIndex$ImmutableMappingInfo$RowcumentIndexer.finish(ElasticSecondaryIndex.java:1845) at java.lang.Iterable.forEach(Iterable.java:75) at org.apache.cassandra.index.SecondaryIndexManager.indexPartition(SecondaryIndexManager.java:642) at org.apache.cassandra.index.internal.CollatedViewIndexBuilder.build(CollatedViewIndexBuilder.java:139) at org.apache.cassandra.db.compaction.CompactionManager$14.run(CompactionManager.java:1637) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81) at java.lang.Thread.run(Thread.java:748)  Let me know if you need any information from me. Thanks. source-file test-file",no-bug,0.9
