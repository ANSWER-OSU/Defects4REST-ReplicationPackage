issue_no,repo,issue_url,title,description,patched_file_types,text_for_topic_modeling,prediction,confidence,combined_text
15720,podman,https://github.com/containers/podman/issues/15720,REST API /system/df UsageData.RefCount on volumes is always 1,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** In order to see who is using a volume, I'm using the `RefCount` attribute of `UsageData` field But even if you create a volume without using it, it returns 1. And if you create multiple containers using that volume, it's still using 1 **Steps to reproduce the issue:** 1. Create a volume without using it bash $ dummyVolume=$(podman volume create)  2. Use REST api to see refCount  $ curl --silent --unix-socket /Users/benoitf/.local/share/containers/podman/machine/podman-machine-default/podman.sock ""http:/v1.41/system/df"" | jq --arg volumeName $dummyVolume '.Volumes[] | select(.Name == ($volumeName))' { ""Driver"": """", ""Labels"": {}, ""Mountpoint"": """", ""Name"": ""413f47a2d1656a4ec6e876543dc8a0caa5256c670a425638eff7be9730da0229"", ""Options"": null, ""Scope"": ""local"", ""UsageData"": { ""RefCount"": 1, ""Size"": 0 } }  It's already invalid 3. Now, try to start containers using that volume bash $ podman run -d --mount ""type=volume,src=$dummyVolume,target=/foo"" docker.io/library/httpd $ podman run -d --mount ""type=volume,src=$dummyVolume,target=/foo"" docker.io/library/httpd  4. Rest API is still invalid bash $ curl --silent --unix-socket /Users/benoitf/.local/share/containers/podman/machine/podman-machine-default/podman.sock ""http:/v1.41/system/df"" | jq --arg volumeName $dummyVolume '.Volumes[] | select(.Name == ($volumeName))' { ""Driver"": """", ""Labels"": {}, ""Mountpoint"": """", ""Name"": ""413f47a2d1656a4ec6e876543dc8a0caa5256c670a425638eff7be9730da0229"", ""Options"": null, ""Scope"": ""local"", ""UsageData"": { ""RefCount"": 1, ""Size"": 0 } }  And we still have our container using it bash $ podman inspect 18e7216f21ab0eddb5fab99c388ba04030809b6870cd0c595e7bc84008c7fb3d | jq '.[0].Mounts' [ { ""Type"": ""volume"", ""Name"": ""413f47a2d1656a4ec6e876543dc8a0caa5256c670a425638eff7be9730da0229"", ""Source"": ""/var/home/core/.local/share/containers/storage/volumes/413f47a2d1656a4ec6e876543dc8a0caa5256c670a425638eff7be9730da0229/_data"", ""Destination"": ""/foo"", ""Driver"": ""local"", ""Mode"": """", ""Options"": [ ""nosuid"", ""nodev"", ""rbind"" ], ""RW"": true, ""Propagation"": ""rprivate"" } ]  **Describe the results you received:** RefCount = 1 **Describe the results you expected:** Valid RefCount **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  4.2.1  **Output of `podman info`:**  (paste your output here)  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  (paste your output here)  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes/No **Additional environment details (AWS, VirtualBox, physical, etc.):**",source-file | source-file | test-file | test-file,rest api system usagedata refcount volumes always bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description order see volume refcount attribute usagedata field even create volume without returns create multiple containers volume still steps reproduce create volume without bash dummyvolume volume create use rest api see refcount curl silent unix socket users benoitf local share containers machine machine default sock http system arg volumename dummyvolume volumes select name volumename driver labels mountpoint name caa eff options null scope local usagedata refcount size already invalid start containers volume bash mount type volume dummyvolume target foo docker library httpd mount type volume dummyvolume target foo docker library httpd rest api still invalid bash curl silent unix socket users benoitf local share containers machine machine default sock http system arg volumename dummyvolume volumes select name volumename driver labels mountpoint name caa eff options null scope local usagedata refcount size still container bash inspect eddb fab mounts type volume name caa eff var home core local share containers storage volumes caa eff data destination foo driver local mode options nosuid nodev rbind true propagation rprivate describe results received refcount describe results expected valid refcount additional information deem important happens occasionally output output paste output package output rpm apt list paste output tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc,bug,0.95,"REST API /system/df UsageData.RefCount on volumes is always 1 <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** In order to see who is using a volume, I'm using the `RefCount` attribute of `UsageData` field But even if you create a volume without using it, it returns 1. And if you create multiple containers using that volume, it's still using 1 **Steps to reproduce the issue:** 1. Create a volume without using it bash $ dummyVolume=$(podman volume create)  2. Use REST api to see refCount  $ curl --silent --unix-socket /Users/benoitf/.local/share/containers/podman/machine/podman-machine-default/podman.sock ""http:/v1.41/system/df"" | jq --arg volumeName $dummyVolume '.Volumes[] | select(.Name == ($volumeName))' { ""Driver"": """", ""Labels"": {}, ""Mountpoint"": """", ""Name"": ""413f47a2d1656a4ec6e876543dc8a0caa5256c670a425638eff7be9730da0229"", ""Options"": null, ""Scope"": ""local"", ""UsageData"": { ""RefCount"": 1, ""Size"": 0 } }  It's already invalid 3. Now, try to start containers using that volume bash $ podman run -d --mount ""type=volume,src=$dummyVolume,target=/foo"" docker.io/library/httpd $ podman run -d --mount ""type=volume,src=$dummyVolume,target=/foo"" docker.io/library/httpd  4. Rest API is still invalid bash $ curl --silent --unix-socket /Users/benoitf/.local/share/containers/podman/machine/podman-machine-default/podman.sock ""http:/v1.41/system/df"" | jq --arg volumeName $dummyVolume '.Volumes[] | select(.Name == ($volumeName))' { ""Driver"": """", ""Labels"": {}, ""Mountpoint"": """", ""Name"": ""413f47a2d1656a4ec6e876543dc8a0caa5256c670a425638eff7be9730da0229"", ""Options"": null, ""Scope"": ""local"", ""UsageData"": { ""RefCount"": 1, ""Size"": 0 } }  And we still have our container using it bash $ podman inspect 18e7216f21ab0eddb5fab99c388ba04030809b6870cd0c595e7bc84008c7fb3d | jq '.[0].Mounts' [ { ""Type"": ""volume"", ""Name"": ""413f47a2d1656a4ec6e876543dc8a0caa5256c670a425638eff7be9730da0229"", ""Source"": ""/var/home/core/.local/share/containers/storage/volumes/413f47a2d1656a4ec6e876543dc8a0caa5256c670a425638eff7be9730da0229/_data"", ""Destination"": ""/foo"", ""Driver"": ""local"", ""Mode"": """", ""Options"": [ ""nosuid"", ""nodev"", ""rbind"" ], ""RW"": true, ""Propagation"": ""rprivate"" } ]  **Describe the results you received:** RefCount = 1 **Describe the results you expected:** Valid RefCount **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  4.2.1  **Output of `podman info`:**  (paste your output here)  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  (paste your output here)  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes/No **Additional environment details (AWS, VirtualBox, physical, etc.):**"
18424,podman,https://github.com/containers/podman/issues/18424,Podman ExecIDs report inaccurate Running state.," Issue Description It seems that podman ExecIDs are persisting and reporting as ""running"" for ~5 minutes before being removed. I've only tested this using the podman Golang bindings. Here is a demonstration program: https://gist.github.com/AndroidKitKat/2e1233b17316d96173fe1cf9f3e8aa48  Steps to reproduce the issue Steps to reproduce the issue 1. Create a new container  podman create --name alpine-test --tty alpine:latest  2. Start the container  podman start alpine-test  3. Start an exec in the container using the REST API. I did this using the Go program referenced in the GitHub Gist above I compiled it by doing:  go mod init inspectbug curl ""https://gist.githubusercontent.com/AndroidKitKat/2e1233b17316d96173fe1cf9f3e8aa48/raw/40c2b071a53275d0e270d71aee34051140094e46/main.go"" > main.go go get go build ./inspectbug   Describe the results you received In that file, I have an Exec with the command `sleep 5` and I have a loop running checking the status of the Exec every 1 second. For a duration of 5 seconds (the duration of the sleep command) + 5 minutes, the `inspectResult` struct's `Running` member is `true`, until eventually the program crashes due to no error handling when checking `containers.ExecInspect` because the ExecID seems to no longer exist at all. Here's the output of the program:  [developer@guthix inspectbug]$ ./inspectbug 2023/05/02 14:12:21 Exec ID: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:12:21 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76  2023/05/02 14:17:23 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:17:24 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:17:25 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x43 pc=0xe79322]   Describe the results you expected After 5 seconds, the Exec shows as ""Not running"" due to sleep exiting.  podman info output yaml [developer@guthix inspectbug]$ podman info host: arch: amd64 buildahVersion: 1.27.3 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.4-1.module+el8.7.0+1154+147ffa21.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.4, commit: ddbeffc1e2a247aef04a1be0bc9b1b5ef5f1cd09' cpuUtilization: idlePercent: 99.9 systemPercent: 0.04 userPercent: 0.06 cpus: 8 distribution: distribution: '""rocky""' version: ""8.7"" eventLogger: file hostname: guthix idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 4.18.0-425.19.2.el8_7.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 27185180672 memTotal: 33146671104 networkBackend: cni ociRuntime: name: runc package: runc-1.1.4-1.module+el8.7.0+1154+147ffa21.x86_64 path: /usr/bin/runc version: |- runc version 1.1.4 spec: 1.0.2-dev go: go1.18.9 libseccomp: 2.5.2 os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-2.module+el8.7.0+1154+147ffa21.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 16741560320 swapTotal: 16741560320 uptime: 100h 45m 33.00s (Approximately 4.17 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.access.redhat.com - registry.redhat.io - docker.io store: configFile: /home/developer/.config/containers/storage.conf containerStore: number: 7 paused: 0 running: 7 stopped: 0 graphDriverName: overlay graphOptions: overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: fuse-overlayfs-1.9-1.module+el8.7.0+1154+147ffa21.x86_64 Version: |- fusermount3 version: 3.3.0 fuse-overlayfs: version 1.9 FUSE library version 3.3.0 using FUSE kernel interface version 7.26 graphRoot: /storage/containers/storage graphRootAllocated: 502921392128 graphRootUsed: 1801228288 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 9 runRoot: /run/user/1000 volumePath: /storage/containers/storage/volumes version: APIVersion: 4.2.0 Built: 1677003394 BuiltTime: Tue Feb 21 13:16:34 2023 GitCommit: """" GoVersion: go1.18.9 Os: linux OsArch: linux/amd64 Version: 4.2.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release No  Additional environment details Running on bare metal on Intel NUCs with 11th gen Intel processors. I am accessing Podman using the golang bindings.  Additional information I verified that the sleep command exits by looking at the process list of the container.",source-file | test-file | source-file | test-file,execids report inaccurate running state description seems execids persisting reporting running minutes removed tested golang bindings demonstration program https gist github androidkitkat steps reproduce steps reproduce create new container create name alpine tty alpine latest start container start alpine start exec container rest api program referenced github gist compiled mod init inspectbug curl https gist githubusercontent androidkitkat raw aee get inspectbug describe results received exec command sleep loop running checking status exec every second duration seconds duration sleep command minutes inspectresult struct running member true eventually program crashes due handling checking containers execinspect execid seems longer exist output program developer guthix inspectbug inspectbug exec fbb adf still running fbb adf still running fbb adf still running fbb adf still running fbb adf panic runtime invalid memory address nil pointer dereference signal sigsegv segmentation violation addr describe results expected seconds exec shows running due sleep exiting output yaml developer guthix inspectbug host arch amd buildahversion cgroupcontrollers cgroupmanager cgroupfs cgroupversion conmon package conmon module ffa path conmon conmon ddbeffc aef cpuutilization idlepercent systempercent userpercent cpus distribution distribution rocky eventlogger hostname guthix idmappings gidmap container host size container host size uidmap container host size container host size kernel linkmode dynamic logdriver memfree memtotal networkbackend cni ociruntime name runc package runc module ffa path runc runc spec libseccomp linux remotesocket exists true path user sock security apparmorenabled false capabilities cap raw cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns module ffa slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry access redhat registry redhat docker store configfile home developer config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mount program executable fuse overlayfs package fuse overlayfs module ffa fusermount fuse overlayfs fuse library fuse kernel interface graphroot storage containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff false supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user volumepath storage containers storage volumes apiversion built builttime feb gitcommit goversion linux osarch linux amd container privileged rootless rootless upstream latest additional environment details running bare metal intel nucs gen intel processors accessing golang bindings additional information verified sleep command exits looking process list container,bug,0.95,"Podman ExecIDs report inaccurate Running state.  Issue Description It seems that podman ExecIDs are persisting and reporting as ""running"" for ~5 minutes before being removed. I've only tested this using the podman Golang bindings. Here is a demonstration program: https://gist.github.com/AndroidKitKat/2e1233b17316d96173fe1cf9f3e8aa48  Steps to reproduce the issue Steps to reproduce the issue 1. Create a new container  podman create --name alpine-test --tty alpine:latest  2. Start the container  podman start alpine-test  3. Start an exec in the container using the REST API. I did this using the Go program referenced in the GitHub Gist above I compiled it by doing:  go mod init inspectbug curl ""https://gist.githubusercontent.com/AndroidKitKat/2e1233b17316d96173fe1cf9f3e8aa48/raw/40c2b071a53275d0e270d71aee34051140094e46/main.go"" > main.go go get go build ./inspectbug   Describe the results you received In that file, I have an Exec with the command `sleep 5` and I have a loop running checking the status of the Exec every 1 second. For a duration of 5 seconds (the duration of the sleep command) + 5 minutes, the `inspectResult` struct's `Running` member is `true`, until eventually the program crashes due to no error handling when checking `containers.ExecInspect` because the ExecID seems to no longer exist at all. Here's the output of the program:  [developer@guthix inspectbug]$ ./inspectbug 2023/05/02 14:12:21 Exec ID: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:12:21 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76  2023/05/02 14:17:23 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:17:24 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 2023/05/02 14:17:25 Still running: 20ed50eb719cd691259d66de361be5793ac1f6d70179d5ef6978fbb72adf0c76 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x43 pc=0xe79322]   Describe the results you expected After 5 seconds, the Exec shows as ""Not running"" due to sleep exiting.  podman info output yaml [developer@guthix inspectbug]$ podman info host: arch: amd64 buildahVersion: 1.27.3 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.4-1.module+el8.7.0+1154+147ffa21.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.4, commit: ddbeffc1e2a247aef04a1be0bc9b1b5ef5f1cd09' cpuUtilization: idlePercent: 99.9 systemPercent: 0.04 userPercent: 0.06 cpus: 8 distribution: distribution: '""rocky""' version: ""8.7"" eventLogger: file hostname: guthix idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 4.18.0-425.19.2.el8_7.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 27185180672 memTotal: 33146671104 networkBackend: cni ociRuntime: name: runc package: runc-1.1.4-1.module+el8.7.0+1154+147ffa21.x86_64 path: /usr/bin/runc version: |- runc version 1.1.4 spec: 1.0.2-dev go: go1.18.9 libseccomp: 2.5.2 os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-2.module+el8.7.0+1154+147ffa21.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 16741560320 swapTotal: 16741560320 uptime: 100h 45m 33.00s (Approximately 4.17 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.access.redhat.com - registry.redhat.io - docker.io store: configFile: /home/developer/.config/containers/storage.conf containerStore: number: 7 paused: 0 running: 7 stopped: 0 graphDriverName: overlay graphOptions: overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: fuse-overlayfs-1.9-1.module+el8.7.0+1154+147ffa21.x86_64 Version: |- fusermount3 version: 3.3.0 fuse-overlayfs: version 1.9 FUSE library version 3.3.0 using FUSE kernel interface version 7.26 graphRoot: /storage/containers/storage graphRootAllocated: 502921392128 graphRootUsed: 1801228288 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 9 runRoot: /run/user/1000 volumePath: /storage/containers/storage/volumes version: APIVersion: 4.2.0 Built: 1677003394 BuiltTime: Tue Feb 21 13:16:34 2023 GitCommit: """" GoVersion: go1.18.9 Os: linux OsArch: linux/amd64 Version: 4.2.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release No  Additional environment details Running on bare metal on Intel NUCs with 11th gen Intel processors. I am accessing Podman using the golang bindings.  Additional information I verified that the sleep command exits by looking at the process list of the container."
22989,podman,https://github.com/containers/podman/issues/22989,remote: pod start empty pod: error without message,"console $ bin/podman-remote pod create --infra=false --name=foo a0cb944bf836e95ca0a83f98e1af151879552ac4fc424e29031c5f214227bdf6 $ bin/podman-remote pod start foo Error:  (That's it. Just ""Error colon space""). The expected error message (from podman-local) is:  Error: no containers in pod a0cb944bf836e95ca0a83f98e1af151879552ac4fc424e29031c5f214227bdf6 have no dependencies, cannot start pod: no such container ",source-file | test-file,remote pod start empty pod without message console remote pod create infra false name foo bdf remote pod start foo colon space expected message local containers pod bdf dependencies cannot start pod container,bug,0.9,"remote: pod start empty pod: error without message console $ bin/podman-remote pod create --infra=false --name=foo a0cb944bf836e95ca0a83f98e1af151879552ac4fc424e29031c5f214227bdf6 $ bin/podman-remote pod start foo Error:  (That's it. Just ""Error colon space""). The expected error message (from podman-local) is:  Error: no containers in pod a0cb944bf836e95ca0a83f98e1af151879552ac4fc424e29031c5f214227bdf6 have no dependencies, cannot start pod: no such container "
25026,podman,https://github.com/containers/podman/issues/25026,podman-remote: create command is wrong," Issue Description When checking the `CreateCommand` of a container created through the api we are getting some weird results.  Steps to reproduce the issue Steps to reproduce the issue 1. Create a container using the api (E.g. using Podman-Desktop) 2. Inspect the container Config.CreateCommand 3. assert command is wrong  Describe the results you received  $: podman inspect hello-container | jq .[0].Config.CreateCommand [ ""podman"", ""system"", ""service"", ""--time=0"" ]   Describe the results you expected Empty array or nil.  podman info output yaml host: arch: amd64 buildahVersion: 1.38.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.12-3.fc41.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.12, commit: ' cpuUtilization: idlePercent: 94.31 systemPercent: 0.82 userPercent: 4.87 cpus: 16 databaseBackend: sqlite distribution: distribution: fedora variant: workstation version: ""41"" eventLogger: journald freeLocks: 2031 hostname: fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 kernel: 6.12.8-200.fc41.x86_64 linkmode: dynamic logDriver: journald memFree: 19032514560 memTotal: 67107631104 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.13.1-1.fc41.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.13.1 package: netavark-1.13.1-1.fc41.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.13.1 ociRuntime: name: crun package: crun-1.19.1-1.fc41.x86_64 path: /usr/bin/crun version: |- crun version 1.19.1 commit: 3e32a70c93f5aa5fea69b50256cca7fd4aa23c80 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20241211.g09478d5-1.fc41.x86_64 version: | pasta 0^20241211.g09478d5-1.fc41.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/user/1000/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: """" package: """" version: """" swapFree: 8589930496 swapTotal: 8589930496 uptime: 52h 2m 21.00s (Approximately 2.17 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /home/axel7083/.config/containers/storage.conf containerStore: number: 10 paused: 0 running: 0 stopped: 10 graphDriverName: overlay graphOptions: {} graphRoot: /home/axel7083/.local/share/containers/storage graphRootAllocated: 1022505254912 graphRootUsed: 396294459392 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 670 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/axel7083/.local/share/containers/storage/volumes version: APIVersion: 5.3.1 Built: 1732147200 BuiltTime: Thu Nov 21 01:00:00 2024 GitCommit: """" GoVersion: go1.23.3 Os: linux OsArch: linux/amd64 Version: 5.3.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details _No response_  Additional information Linked issues - https://github.com/containers/podman/issues/6649 - https://github.com/containers/podman/pull/6896",source-file | source-file | source-file | source-file | test-file,remote create command wrong description checking createcommand container created api getting weird results steps reproduce steps reproduce create container api desktop inspect container config createcommand assert command wrong describe results received inspect hello container config createcommand system service time describe results expected empty array nil output yaml host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution fedora variant workstation eventlogger journald freelocks hostname fedora idmappings gidmap container host size container host size uidmap container host size container host size kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns path libexec aardvark dns aardvark dns package netavark path libexec netavark netavark ociruntime name crun package crun path crun crun fea cca rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path user sock rootlessnetworkcmd pasta security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable package swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat docker store configfile home axel config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home axel local share containers storage graphrootallocated graphrootused graphstatus backing filesystem btrfs native overlay diff true supports type true supports shifting false supports volatile true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home axel local share containers storage volumes apiversion built builttime nov gitcommit goversion linux osarch linux amd container privileged rootless none upstream latest yes additional environment details response additional information linked issues https github containers issues https github containers,bug,0.9,"podman-remote: create command is wrong  Issue Description When checking the `CreateCommand` of a container created through the api we are getting some weird results.  Steps to reproduce the issue Steps to reproduce the issue 1. Create a container using the api (E.g. using Podman-Desktop) 2. Inspect the container Config.CreateCommand 3. assert command is wrong  Describe the results you received  $: podman inspect hello-container | jq .[0].Config.CreateCommand [ ""podman"", ""system"", ""service"", ""--time=0"" ]   Describe the results you expected Empty array or nil.  podman info output yaml host: arch: amd64 buildahVersion: 1.38.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.12-3.fc41.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.12, commit: ' cpuUtilization: idlePercent: 94.31 systemPercent: 0.82 userPercent: 4.87 cpus: 16 databaseBackend: sqlite distribution: distribution: fedora variant: workstation version: ""41"" eventLogger: journald freeLocks: 2031 hostname: fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 kernel: 6.12.8-200.fc41.x86_64 linkmode: dynamic logDriver: journald memFree: 19032514560 memTotal: 67107631104 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.13.1-1.fc41.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.13.1 package: netavark-1.13.1-1.fc41.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.13.1 ociRuntime: name: crun package: crun-1.19.1-1.fc41.x86_64 path: /usr/bin/crun version: |- crun version 1.19.1 commit: 3e32a70c93f5aa5fea69b50256cca7fd4aa23c80 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20241211.g09478d5-1.fc41.x86_64 version: | pasta 0^20241211.g09478d5-1.fc41.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/user/1000/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: """" package: """" version: """" swapFree: 8589930496 swapTotal: 8589930496 uptime: 52h 2m 21.00s (Approximately 2.17 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /home/axel7083/.config/containers/storage.conf containerStore: number: 10 paused: 0 running: 0 stopped: 10 graphDriverName: overlay graphOptions: {} graphRoot: /home/axel7083/.local/share/containers/storage graphRootAllocated: 1022505254912 graphRootUsed: 396294459392 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 670 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/axel7083/.local/share/containers/storage/volumes version: APIVersion: 5.3.1 Built: 1732147200 BuiltTime: Thu Nov 21 01:00:00 2024 GitCommit: """" GoVersion: go1.23.3 Os: linux OsArch: linux/amd64 Version: 5.3.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details _No response_  Additional information Linked issues - https://github.com/containers/podman/issues/6649 - https://github.com/containers/podman/pull/6896"
18597,podman,https://github.com/containers/podman/issues/18597,API endpoint /images/create seems to ignore the tag parameter?," Issue Description Hey there. This issue originated when trying to use Podman as a backend for GitLab Runner. The issue presented itself when GitLab Runner was attempting to pull images for performing builds as can be seen by some of the log entries:  podman[400972]: Trying to pull registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66 podman[400972]: @ - - [17/May/2023:10:50:23 +1000] ""POST /v1.40/images/create?fromImage=registry.gitlab.com%2Fgitlab-org%2Fgitlab-runner%2Fgitlab-runner-helper&tag=x86_64-dcfb4b66 HTTP/1.1"" 200 284 """" ""Go-http-client/1.1"" podman[400972]: time=""2023-05-17T10:50:23+10:00"" level=info msg=""Request Failed(Not Found): failed to find image registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: No such image"" podman[400972]: @ - - [17/May/2023:10:50:23 +1000] ""GET /v1.40/images/registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66/json HTTP/1.1"" 404 441 """" ""Go-http-client/1.1"" gitlab-runner[400957]: WARNING: Failed to pull image with policy ""if-not-present"": Error response from daemon: failed to find image registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: No such image (manager.go:241:0s) job=639118 project=39435 runner=r3KQ8vBa gitlab-runner[400957]: WARNING: Preparation failed: failed to pull image ""registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66"" with specified policies [if-not-present]: Error response from daemon: failed to find image registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: No such image (manager.go:241:0s) job=639118 project=39435 runner=r3KQ8vBa  After investigating this further, I can actually reproduce a difference in behaviour between Docker and the Podman Docker API which I believe is resulting in the issue. When hitting the `/images/create` API endpoint with a repo and tag parameter, Docker creates an image with the chosen name and tag while Podman seems to only use the name and set the tag to `latest`. More information is shown below with a repro.  Steps to reproduce the issue Steps to reproduce the issue 1. Ensure you have a system with both Podman and Docker available 2. Create an empty image using each and inspect the results as follows: bash me@myserver:~$ # Create an empty image with Docker. me@myserver:~$ curl -v -XPOST --unix-socket /run/docker.sock 'http:api/images/create?fromSrc=-&repo=myimage&tag=mytag' * Trying /run/docker.sock:0 * Connected to api (/run/docker.sock) port 80 (#0) > POST /images/create?fromSrc=-&repo=myimage&tag=mytag HTTP/1.1 > Host: api > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Docker-Experimental: false < Ostype: linux < Server: Docker/20.10.21 (linux) < Date: Wed, 17 May 2023 06:51:16 GMT < Transfer-Encoding: chunked < {""status"":""sha256:bb944196d717548f774e7d64da0c3b1ab9b567dcef3577d5db11c712b0eb8df1""} * Connection #0 to host api left intact me@myserver:~$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE myimage mytag bb944196d717 6 seconds ago 0B me@myserver:~$ curl -v --unix-socket /run/docker.sock 'http://api/images/myimage:mytag/json' * Trying /run/docker.sock:0 * Connected to api (/run/docker.sock) port 80 (#0) > GET /images/myimage:mytag/json HTTP/1.1 > Host: api > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Docker-Experimental: false < Ostype: linux < Server: Docker/20.10.21 (linux) < Date: Wed, 17 May 2023 06:51:26 GMT < Content-Length: 1424 < {""Id"":""sha256:bb944196d717548f774e7d64da0c3b1ab9b567dcef3577d5db11c712b0eb8df1"",""RepoTags"":[""myimage:mytag""],""RepoDigests"":[],""Parent"":"""",""Comment"":""Imported from -"",""Created"":""2023-05-17T06:51:16.354773741Z"",""Container"":"""",""ContainerConfig"":{""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":false,""AttachStdout"":false,""AttachStderr"":false,""Tty"":false,""OpenStdin"":false,""StdinOnce"":false,""Env"":null,""Cmd"":null,""Image"":"""",""Volumes"":null,""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":null},""DockerVersion"":""20.10.21"",""Author"":"""",""Config"":{""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":false,""AttachStdout"":false,""AttachStderr"":false,""Tty"":false,""OpenStdin"":false,""StdinOnce"":false,""Env"":null,""Cmd"":null,""Image"":"""",""Volumes"":null,""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":null},""Architecture"":""amd64"",""Os"":""linux"",""Size"":0,""VirtualSize"":0,""GraphDriver"":{""Data"":{""MergedDir"":""/var/lib/docker/overlay2/669ba8d7a9fcdf7b1b321ec814400ec4df2964cfdc11c65a0d320afb7e288114/merged"",""UpperDir"":""/var/lib/docker/overlay2/669ba8d7a9fcdf7b1b321ec814400ec4df2964cfdc11c65a0d320afb7e288114/diff"",""WorkDir"":""/var/lib/docker/overlay2/669ba8d7a9fcdf7b1b321ec814400ec4df2964cfdc11c65a0d320afb7e288114/work""},""Name"":""overlay2""},""RootFS"":{""Type"":""layers"",""Layers"":[""sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855""]},""Metadata"":{""LastTagTime"":""2023-05-17T16:51:16.357888207+10:00""}} * Connection #0 to host api left intact me@myserver:~$ # Create an empty image with Podman. me@myserver:~$ curl -v -XPOST --unix-socket /run/user/1000/podman/podman.sock 'http:api/images/create?fromSrc=-&repo=myimage&tag=mytag' * Trying /run/user/1000/podman/podman.sock:0 * Connected to api (/run/user/1000/podman/podman.sock) port 80 (#0) > POST /images/create?fromSrc=-&repo=myimage&tag=mytag HTTP/1.1 > Host: api > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Libpod-Api-Version: 4.5.0 < Server: Libpod/4.5.0 (linux) < X-Reference-Id: 0xc0000c0490 < Date: Wed, 17 May 2023 06:51:45 GMT < Content-Length: 198 < {""status"":""sha256:b27eea98c26530caa6fbb4754d1dd08d401f5c839e0ae4068fff65be1668ddb1"",""progress"":"""",""progressDetail"":{},""id"":""sha256:b27eea98c26530caa6fbb4754d1dd08d401f5c839e0ae4068fff65be1668ddb1""} * Connection #0 to host api left intact me@myserver:~$ podman images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/library/myimage latest b27eea98c265 3 seconds ago 1.09 kB me@myserver:~$ curl -v --unix-socket /run/user/1000/podman/podman.sock 'http://api/images/myimage:mytag/json' * Trying /run/user/1000/podman/podman.sock:0 * Connected to api (/run/user/1000/podman/podman.sock) port 80 (#0) > GET /images/myimage:mytag/json HTTP/1.1 > Host: api > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 404 Not Found < Api-Version: 1.41 < Content-Type: application/json < Libpod-Api-Version: 4.5.0 < Server: Libpod/4.5.0 (linux) < X-Reference-Id: 0xc0000c92a0 < Date: Wed, 17 May 2023 06:51:59 GMT < Content-Length: 205 < {""cause"":""failed to find image myimage:mytag: docker.io/library/myimage:mytag: No such image"",""message"":""failed to find image myimage:mytag: docker.io/library/myimage:mytag: No such image"",""response"":404} * Connection #0 to host api left intact   Describe the results you received As you can see, Docker creates the image `myimage:mytag` while Podman creates the image `docker.io/library/myimage:latest` where the tag has not been respected by Podman.  Describe the results you expected I expected Podman to create the image with the tag `mytag` as Docker does.  podman info output yaml host: arch: amd64 buildahVersion: 1.30.0 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon_100:2.1.2~0_amd64 path: /usr/libexec/podman/conmon version: 'conmon version 2.1.2, commit: ' cpuUtilization: idlePercent: 99.08 systemPercent: 0.23 userPercent: 0.69 cpus: 4 databaseBackend: boltdb distribution: codename: jammy distribution: ubuntu version: ""22.04"" eventLogger: journald hostname: myserver.mydomain idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.15.0-71-generic linkmode: dynamic logDriver: journald memFree: 7083307008 memTotal: 16753397760 networkBackend: cni ociRuntime: name: runc package: runc_1.1.0-0ubuntu1_amd64 path: /usr/sbin/runc version: |- runc version 1.1.0-0ubuntu1 spec: 1.0.2-dev go: go1.17.3 libseccomp: 2.5.3 os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns_1.0.1-2_amd64 version: |- slirp4netns version 1.0.1 commit: 6a7b16babc95b6a3056b33fb45b74a6f62262dd4 libslirp: 4.6.1 swapFree: 4294963200 swapTotal: 4294963200 uptime: 314h 16m 0.00s (Approximately 13.08 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io - quay.io store: configFile: /home/me/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/me/.local/share/containers/storage graphRootAllocated: 103240073216 graphRootUsed: 48463527936 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/me/.local/share/containers/storage/volumes version: APIVersion: 4.5.0 Built: 0 BuiltTime: Thu Jan 1 10:00:00 1970 GitCommit: """" GoVersion: go1.18.1 Os: linux OsArch: linux/amd64 Version: 4.5.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details I've replicated this problem on various versions of Podman ranging from 3.4.4 to the latest on both Ubuntu 22.04 and AlmaLinux 9.  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | test-file | test-file | source-file | test-file | test-file,api endpoint images create seems ignore tag parameter description hey originated trying use backend gitlab runner presented gitlab runner attempting images performing builds seen log entries trying registry gitlab gitlab gitlab runner gitlab runner helper dcfb may post images create fromimage registry gitlab fgitlab fgitlab runner fgitlab runner helper tag dcfb http http client time level msg failed found failed find image registry gitlab gitlab gitlab runner gitlab runner helper dcfb registry gitlab gitlab gitlab runner gitlab runner helper dcfb image may get images registry gitlab gitlab gitlab runner gitlab runner helper dcfb json http http client gitlab runner warning failed image policy present response daemon failed find image registry gitlab gitlab gitlab runner gitlab runner helper dcfb registry gitlab gitlab gitlab runner gitlab runner helper dcfb image manager job project runner vba gitlab runner warning preparation failed failed image registry gitlab gitlab gitlab runner gitlab runner helper dcfb specified policies present response daemon failed find image registry gitlab gitlab gitlab runner gitlab runner helper dcfb registry gitlab gitlab gitlab runner gitlab runner helper dcfb image manager job project runner vba investigating actually reproduce difference behaviour docker docker api believe resulting hitting images create api endpoint repo tag parameter docker creates image chosen name tag seems use name set tag latest information shown repro steps reproduce steps reproduce ensure system docker available create empty image inspect results follows bash myserver create empty image docker myserver curl xpost unix socket docker sock http api images create fromsrc repo myimage tag mytag trying docker sock connected api docker sock port post images create fromsrc repo myimage tag mytag http host api user agent curl accept mark bundle supporting multiuse http api content type application json docker experimental false ostype linux server docker linux date may gmt transfer encoding chunked status sha dcef connection host api left intact myserver docker images repository tag image created size myimage mytag seconds ago myserver curl unix socket docker sock http api images myimage mytag json trying docker sock connected api docker sock port get images myimage mytag json http host api user agent curl accept mark bundle supporting multiuse http api content type application json docker experimental false ostype linux server docker linux date may gmt content length sha dcef repotags myimage mytag repodigests parent comment imported created container containerconfig hostname domainname user attachstdin false attachstdout false attachstderr false tty false openstdin false stdinonce false env null cmd null image volumes null workingdir entrypoint null onbuild null labels null dockerversion config hostname domainname user attachstdin false attachstdout false attachstderr false tty false openstdin false stdinonce false env null cmd null image volumes null workingdir entrypoint null onbuild null labels null architecture amd linux size virtualsize graphdriver data mergeddir var docker overlay fcdf cfdc afb merged upperdir var docker overlay fcdf cfdc afb diff workdir var docker overlay fcdf cfdc afb work name overlay rootfs type layers layers sha afbf metadata lasttagtime connection host api left intact myserver create empty image myserver curl xpost unix socket user sock http api images create fromsrc repo myimage tag mytag trying user sock connected api user sock port post images create fromsrc repo myimage tag mytag http host api user agent curl accept mark bundle supporting multiuse http api content type application json libpod api server libpod linux reference date may gmt content length status sha eea caa fbb fff ddb progress progressdetail sha eea caa fbb fff ddb connection host api left intact myserver images repository tag image created size docker library myimage latest eea seconds ago myserver curl unix socket user sock http api images myimage mytag json trying user sock connected api user sock port get images myimage mytag json http host api user agent curl accept mark bundle supporting multiuse http found api content type application json libpod api server libpod linux reference date may gmt content length cause failed find image myimage mytag docker library myimage mytag image message failed find image myimage mytag docker library myimage mytag image response connection host api left intact describe results received see docker creates image myimage mytag creates image docker library myimage latest tag respected describe results expected expected create image tag mytag docker output yaml host arch amd buildahversion cgroupcontrollers memory pids cgroupmanager systemd cgroupversion conmon package conmon amd path libexec conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend boltdb distribution codename jammy distribution ubuntu eventlogger journald hostname myserver mydomain idmappings gidmap container host size container host size uidmap container host size container host size kernel generic linkmode dynamic logdriver journald memfree memtotal networkbackend cni ociruntime name runc package runc ubuntu amd path sbin runc runc ubuntu spec libseccomp linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns amd slirp netns babc libslirp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search docker quay store configfile home config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home local share containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home local share containers storage volumes apiversion built builttime jan gitcommit goversion linux osarch linux amd container privileged rootless rootless upstream latest yes additional environment details replicated various versions ranging latest ubuntu almalinux additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.95,"API endpoint /images/create seems to ignore the tag parameter?  Issue Description Hey there. This issue originated when trying to use Podman as a backend for GitLab Runner. The issue presented itself when GitLab Runner was attempting to pull images for performing builds as can be seen by some of the log entries:  podman[400972]: Trying to pull registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66 podman[400972]: @ - - [17/May/2023:10:50:23 +1000] ""POST /v1.40/images/create?fromImage=registry.gitlab.com%2Fgitlab-org%2Fgitlab-runner%2Fgitlab-runner-helper&tag=x86_64-dcfb4b66 HTTP/1.1"" 200 284 """" ""Go-http-client/1.1"" podman[400972]: time=""2023-05-17T10:50:23+10:00"" level=info msg=""Request Failed(Not Found): failed to find image registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: No such image"" podman[400972]: @ - - [17/May/2023:10:50:23 +1000] ""GET /v1.40/images/registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66/json HTTP/1.1"" 404 441 """" ""Go-http-client/1.1"" gitlab-runner[400957]: WARNING: Failed to pull image with policy ""if-not-present"": Error response from daemon: failed to find image registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: No such image (manager.go:241:0s) job=639118 project=39435 runner=r3KQ8vBa gitlab-runner[400957]: WARNING: Preparation failed: failed to pull image ""registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66"" with specified policies [if-not-present]: Error response from daemon: failed to find image registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: registry.gitlab.com/gitlab-org/gitlab-runner/gitlab-runner-helper:x86_64-dcfb4b66: No such image (manager.go:241:0s) job=639118 project=39435 runner=r3KQ8vBa  After investigating this further, I can actually reproduce a difference in behaviour between Docker and the Podman Docker API which I believe is resulting in the issue. When hitting the `/images/create` API endpoint with a repo and tag parameter, Docker creates an image with the chosen name and tag while Podman seems to only use the name and set the tag to `latest`. More information is shown below with a repro.  Steps to reproduce the issue Steps to reproduce the issue 1. Ensure you have a system with both Podman and Docker available 2. Create an empty image using each and inspect the results as follows: bash me@myserver:~$ # Create an empty image with Docker. me@myserver:~$ curl -v -XPOST --unix-socket /run/docker.sock 'http:api/images/create?fromSrc=-&repo=myimage&tag=mytag' * Trying /run/docker.sock:0 * Connected to api (/run/docker.sock) port 80 (#0) > POST /images/create?fromSrc=-&repo=myimage&tag=mytag HTTP/1.1 > Host: api > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Docker-Experimental: false < Ostype: linux < Server: Docker/20.10.21 (linux) < Date: Wed, 17 May 2023 06:51:16 GMT < Transfer-Encoding: chunked < {""status"":""sha256:bb944196d717548f774e7d64da0c3b1ab9b567dcef3577d5db11c712b0eb8df1""} * Connection #0 to host api left intact me@myserver:~$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE myimage mytag bb944196d717 6 seconds ago 0B me@myserver:~$ curl -v --unix-socket /run/docker.sock 'http://api/images/myimage:mytag/json' * Trying /run/docker.sock:0 * Connected to api (/run/docker.sock) port 80 (#0) > GET /images/myimage:mytag/json HTTP/1.1 > Host: api > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Docker-Experimental: false < Ostype: linux < Server: Docker/20.10.21 (linux) < Date: Wed, 17 May 2023 06:51:26 GMT < Content-Length: 1424 < {""Id"":""sha256:bb944196d717548f774e7d64da0c3b1ab9b567dcef3577d5db11c712b0eb8df1"",""RepoTags"":[""myimage:mytag""],""RepoDigests"":[],""Parent"":"""",""Comment"":""Imported from -"",""Created"":""2023-05-17T06:51:16.354773741Z"",""Container"":"""",""ContainerConfig"":{""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":false,""AttachStdout"":false,""AttachStderr"":false,""Tty"":false,""OpenStdin"":false,""StdinOnce"":false,""Env"":null,""Cmd"":null,""Image"":"""",""Volumes"":null,""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":null},""DockerVersion"":""20.10.21"",""Author"":"""",""Config"":{""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":false,""AttachStdout"":false,""AttachStderr"":false,""Tty"":false,""OpenStdin"":false,""StdinOnce"":false,""Env"":null,""Cmd"":null,""Image"":"""",""Volumes"":null,""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":null},""Architecture"":""amd64"",""Os"":""linux"",""Size"":0,""VirtualSize"":0,""GraphDriver"":{""Data"":{""MergedDir"":""/var/lib/docker/overlay2/669ba8d7a9fcdf7b1b321ec814400ec4df2964cfdc11c65a0d320afb7e288114/merged"",""UpperDir"":""/var/lib/docker/overlay2/669ba8d7a9fcdf7b1b321ec814400ec4df2964cfdc11c65a0d320afb7e288114/diff"",""WorkDir"":""/var/lib/docker/overlay2/669ba8d7a9fcdf7b1b321ec814400ec4df2964cfdc11c65a0d320afb7e288114/work""},""Name"":""overlay2""},""RootFS"":{""Type"":""layers"",""Layers"":[""sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855""]},""Metadata"":{""LastTagTime"":""2023-05-17T16:51:16.357888207+10:00""}} * Connection #0 to host api left intact me@myserver:~$ # Create an empty image with Podman. me@myserver:~$ curl -v -XPOST --unix-socket /run/user/1000/podman/podman.sock 'http:api/images/create?fromSrc=-&repo=myimage&tag=mytag' * Trying /run/user/1000/podman/podman.sock:0 * Connected to api (/run/user/1000/podman/podman.sock) port 80 (#0) > POST /images/create?fromSrc=-&repo=myimage&tag=mytag HTTP/1.1 > Host: api > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Libpod-Api-Version: 4.5.0 < Server: Libpod/4.5.0 (linux) < X-Reference-Id: 0xc0000c0490 < Date: Wed, 17 May 2023 06:51:45 GMT < Content-Length: 198 < {""status"":""sha256:b27eea98c26530caa6fbb4754d1dd08d401f5c839e0ae4068fff65be1668ddb1"",""progress"":"""",""progressDetail"":{},""id"":""sha256:b27eea98c26530caa6fbb4754d1dd08d401f5c839e0ae4068fff65be1668ddb1""} * Connection #0 to host api left intact me@myserver:~$ podman images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/library/myimage latest b27eea98c265 3 seconds ago 1.09 kB me@myserver:~$ curl -v --unix-socket /run/user/1000/podman/podman.sock 'http://api/images/myimage:mytag/json' * Trying /run/user/1000/podman/podman.sock:0 * Connected to api (/run/user/1000/podman/podman.sock) port 80 (#0) > GET /images/myimage:mytag/json HTTP/1.1 > Host: api > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 404 Not Found < Api-Version: 1.41 < Content-Type: application/json < Libpod-Api-Version: 4.5.0 < Server: Libpod/4.5.0 (linux) < X-Reference-Id: 0xc0000c92a0 < Date: Wed, 17 May 2023 06:51:59 GMT < Content-Length: 205 < {""cause"":""failed to find image myimage:mytag: docker.io/library/myimage:mytag: No such image"",""message"":""failed to find image myimage:mytag: docker.io/library/myimage:mytag: No such image"",""response"":404} * Connection #0 to host api left intact   Describe the results you received As you can see, Docker creates the image `myimage:mytag` while Podman creates the image `docker.io/library/myimage:latest` where the tag has not been respected by Podman.  Describe the results you expected I expected Podman to create the image with the tag `mytag` as Docker does.  podman info output yaml host: arch: amd64 buildahVersion: 1.30.0 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon_100:2.1.2~0_amd64 path: /usr/libexec/podman/conmon version: 'conmon version 2.1.2, commit: ' cpuUtilization: idlePercent: 99.08 systemPercent: 0.23 userPercent: 0.69 cpus: 4 databaseBackend: boltdb distribution: codename: jammy distribution: ubuntu version: ""22.04"" eventLogger: journald hostname: myserver.mydomain idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.15.0-71-generic linkmode: dynamic logDriver: journald memFree: 7083307008 memTotal: 16753397760 networkBackend: cni ociRuntime: name: runc package: runc_1.1.0-0ubuntu1_amd64 path: /usr/sbin/runc version: |- runc version 1.1.0-0ubuntu1 spec: 1.0.2-dev go: go1.17.3 libseccomp: 2.5.3 os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns_1.0.1-2_amd64 version: |- slirp4netns version 1.0.1 commit: 6a7b16babc95b6a3056b33fb45b74a6f62262dd4 libslirp: 4.6.1 swapFree: 4294963200 swapTotal: 4294963200 uptime: 314h 16m 0.00s (Approximately 13.08 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io - quay.io store: configFile: /home/me/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/me/.local/share/containers/storage graphRootAllocated: 103240073216 graphRootUsed: 48463527936 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/me/.local/share/containers/storage/volumes version: APIVersion: 4.5.0 Built: 0 BuiltTime: Thu Jan 1 10:00:00 1970 GitCommit: """" GoVersion: go1.18.1 Os: linux OsArch: linux/amd64 Version: 4.5.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details I've replicated this problem on various versions of Podman ranging from 3.4.4 to the latest on both Ubuntu 22.04 and AlmaLinux 9.  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
20375,podman,https://github.com/containers/podman/issues/20375,"REST API: `/v1.24/images/${img}/history` contains `""Size"":0` where docker has `""Size"":7458929`"," Issue Description REST API: Result from `/v1.24/images/${img}/history` contains `""Size"":0` where docker has `""Size"":7458929`  Steps to reproduce the issue On Fedora CoreOS 39.20231006.1.0 (aarch64) VM perform the following steps: 1. `sudo -i` 2. `systemctl start docker` 3. `useradd test` 4. `usermod -aG docker` 5. `machinectl shell --uid test` 6. `img=$(podman pull alpine:3.17.2)` 7. `docker pull alpine:3.17.2` 8. `systemctl --user start podman.socket` 9. `curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history > docker-result.txt` 10. `curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history > podman-result.txt` 11. `cat result-docker.txt | jq '.[1].Size'` 12. `cat result-podman.txt | jq '.[1].Size'`  Describe the results you received Step 11:  $ cat result-docker.txt | jq '.[1].Size' 7458929  Step 12:  $ cat result-podman.txt | jq '.[1].Size' 0   Describe the results you expected I expected to see the same number in both __Step 11__ and __Step 12__  podman info output yaml host: arch: arm64 buildahVersion: 1.32.0 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-3.fc39.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 97.6 systemPercent: 1.37 userPercent: 1.03 cpus: 1 databaseBackend: boltdb distribution: distribution: fedora variant: coreos version: ""39"" eventLogger: journald freeLocks: 2048 hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1011 size: 1 - container_id: 1 host_id: 1245184 size: 65536 uidmap: - container_id: 0 host_id: 1011 size: 1 - container_id: 1 host_id: 1245184 size: 65536 kernel: 6.5.5-300.fc39.aarch64 linkmode: dynamic logDriver: journald memFree: 1244913664 memTotal: 1980260352 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.7.0-2.fc39.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.7.0 package: netavark-1.7.0-2.fc39.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.7.0 ociRuntime: name: crun package: crun-1.9.2-1.fc39.aarch64 path: /usr/bin/crun version: |- crun version 1.9.2 commit: 35274d346d2e9ffeacb22cc11590b0266a23d634 rundir: /run/user/1011/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20230908.g05627dc-1.fc39.aarch64 version: | pasta 0^20230908.g05627dc-1.fc39.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/user/1011/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.1-1.fc39.aarch64 version: |- slirp4netns version 1.2.1 commit: 09e31e92fa3d2a1d3ca261adaeb012c8d75a8194 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 0h 27m 34.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /var/home/test11/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/test11/.local/share/containers/storage graphRootAllocated: 24091013120 graphRootUsed: 7668953088 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/1011/containers transientStore: false volumePath: /var/home/test11/.local/share/containers/storage/volumes version: APIVersion: 4.7.0 Built: 1695838660 BuiltTime: Wed Sep 27 18:17:40 2023 GitCommit: """" GoVersion: go1.21.1 Os: linux OsArch: linux/arm64 Version: 4.7.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details  $ rpm -q podman podman-4.7.0-1.fc39.aarch64 $ rpm -q moby-engine moby-engine-24.0.5-1.fc39.aarch64 $   Additional information The whole result from the REST API calls above.  $ cat result-docker.txt | jq . [ { ""Comment"": """", ""Created"": 1676064248, ""CreatedBy"": ""/bin/sh -c #(nop) CMD [\""/bin/sh\""]"", ""Id"": ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"", ""Size"": 0, ""Tags"": [ ""alpine:3.17.2"" ] }, { ""Comment"": """", ""Created"": 1676064248, ""CreatedBy"": ""/bin/sh -c #(nop) ADD file:9bd9ea42a9f3bdc769e80c6b8a4b117d65f73ae68e155a6172a1184e7ac8bcc1 in / "", ""Id"": ""<missing>"", ""Size"": 7458929, ""Tags"": null } ]   $ cat result-podman.txt | jq . [ { ""Id"": ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"", ""Created"": 1676064248, ""CreatedBy"": ""/bin/sh -c #(nop) CMD [\""/bin/sh\""]"", ""Tags"": [ ""docker.io/library/alpine:3.17.2"" ], ""Size"": 0, ""Comment"": """" }, { ""Id"": ""sha256:<missing>"", ""Created"": 1676064248, ""CreatedBy"": ""/bin/sh -c #(nop) ADD file:9bd9ea42a9f3bdc769e80c6b8a4b117d65f73ae68e155a6172a1184e7ac8bcc1 in / "", ""Tags"": null, ""Size"": 0, ""Comment"": """" } ] ",other-file | other-file | test-file | source-file | other-file,rest api images img history contains size docker size description rest api result images img history contains size docker size steps reproduce fedora coreos aarch perform following steps sudo systemctl start docker useradd usermod docker machinectl shell uid img alpine docker alpine systemctl user start socket curl unix socket var docker sock http localhost images img history docker result txt curl unix socket xdg runtime dir sock http localhost images img history result txt cat result docker txt size cat result txt size describe results received step cat result docker txt size step cat result txt size describe results expected expected see number step step output yaml host arch arm buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon aarch path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend boltdb distribution distribution fedora variant coreos eventlogger journald freelocks hostname localhost localdomain idmappings gidmap container host size container host size uidmap container host size container host size kernel aarch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns aarch path libexec aardvark dns aardvark dns package netavark aarch path libexec netavark netavark ociruntime name crun package crun aarch path crun crun ffeacb rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt aarch pasta aarch pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns aarch slirp netns adaeb libslirp slirp config max libseccomp swapfree swaptotal uptime plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile var home config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot var home local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff true supports type true supports shifting false supports volatile true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath var home local share containers storage volumes apiversion built builttime sep gitcommit goversion linux osarch linux arm container privileged rootless rootless upstream latest yes additional environment details rpm aarch rpm moby engine moby engine aarch additional information whole result rest api calls cat result docker txt comment created createdby nop cmd sha daadb fab size tags alpine comment created createdby nop bdc bcc missing size tags null cat result txt sha daadb fab created createdby nop cmd tags docker library alpine size comment sha missing created createdby nop bdc bcc tags null size comment,bug,0.95,"REST API: `/v1.24/images/${img}/history` contains `""Size"":0` where docker has `""Size"":7458929`  Issue Description REST API: Result from `/v1.24/images/${img}/history` contains `""Size"":0` where docker has `""Size"":7458929`  Steps to reproduce the issue On Fedora CoreOS 39.20231006.1.0 (aarch64) VM perform the following steps: 1. `sudo -i` 2. `systemctl start docker` 3. `useradd test` 4. `usermod -aG docker` 5. `machinectl shell --uid test` 6. `img=$(podman pull alpine:3.17.2)` 7. `docker pull alpine:3.17.2` 8. `systemctl --user start podman.socket` 9. `curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history > docker-result.txt` 10. `curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history > podman-result.txt` 11. `cat result-docker.txt | jq '.[1].Size'` 12. `cat result-podman.txt | jq '.[1].Size'`  Describe the results you received Step 11:  $ cat result-docker.txt | jq '.[1].Size' 7458929  Step 12:  $ cat result-podman.txt | jq '.[1].Size' 0   Describe the results you expected I expected to see the same number in both __Step 11__ and __Step 12__  podman info output yaml host: arch: arm64 buildahVersion: 1.32.0 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-3.fc39.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 97.6 systemPercent: 1.37 userPercent: 1.03 cpus: 1 databaseBackend: boltdb distribution: distribution: fedora variant: coreos version: ""39"" eventLogger: journald freeLocks: 2048 hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1011 size: 1 - container_id: 1 host_id: 1245184 size: 65536 uidmap: - container_id: 0 host_id: 1011 size: 1 - container_id: 1 host_id: 1245184 size: 65536 kernel: 6.5.5-300.fc39.aarch64 linkmode: dynamic logDriver: journald memFree: 1244913664 memTotal: 1980260352 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.7.0-2.fc39.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.7.0 package: netavark-1.7.0-2.fc39.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.7.0 ociRuntime: name: crun package: crun-1.9.2-1.fc39.aarch64 path: /usr/bin/crun version: |- crun version 1.9.2 commit: 35274d346d2e9ffeacb22cc11590b0266a23d634 rundir: /run/user/1011/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20230908.g05627dc-1.fc39.aarch64 version: | pasta 0^20230908.g05627dc-1.fc39.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/user/1011/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.1-1.fc39.aarch64 version: |- slirp4netns version 1.2.1 commit: 09e31e92fa3d2a1d3ca261adaeb012c8d75a8194 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 0h 27m 34.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /var/home/test11/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/test11/.local/share/containers/storage graphRootAllocated: 24091013120 graphRootUsed: 7668953088 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/1011/containers transientStore: false volumePath: /var/home/test11/.local/share/containers/storage/volumes version: APIVersion: 4.7.0 Built: 1695838660 BuiltTime: Wed Sep 27 18:17:40 2023 GitCommit: """" GoVersion: go1.21.1 Os: linux OsArch: linux/arm64 Version: 4.7.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details  $ rpm -q podman podman-4.7.0-1.fc39.aarch64 $ rpm -q moby-engine moby-engine-24.0.5-1.fc39.aarch64 $   Additional information The whole result from the REST API calls above.  $ cat result-docker.txt | jq . [ { ""Comment"": """", ""Created"": 1676064248, ""CreatedBy"": ""/bin/sh -c #(nop) CMD [\""/bin/sh\""]"", ""Id"": ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"", ""Size"": 0, ""Tags"": [ ""alpine:3.17.2"" ] }, { ""Comment"": """", ""Created"": 1676064248, ""CreatedBy"": ""/bin/sh -c #(nop) ADD file:9bd9ea42a9f3bdc769e80c6b8a4b117d65f73ae68e155a6172a1184e7ac8bcc1 in / "", ""Id"": ""<missing>"", ""Size"": 7458929, ""Tags"": null } ]   $ cat result-podman.txt | jq . [ { ""Id"": ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"", ""Created"": 1676064248, ""CreatedBy"": ""/bin/sh -c #(nop) CMD [\""/bin/sh\""]"", ""Tags"": [ ""docker.io/library/alpine:3.17.2"" ], ""Size"": 0, ""Comment"": """" }, { ""Id"": ""sha256:<missing>"", ""Created"": 1676064248, ""CreatedBy"": ""/bin/sh -c #(nop) ADD file:9bd9ea42a9f3bdc769e80c6b8a4b117d65f73ae68e155a6172a1184e7ac8bcc1 in / "", ""Tags"": null, ""Size"": 0, ""Comment"": """" } ] "
14291,podman,https://github.com/containers/podman/issues/14291,Podman's Docker-compatible REST API and previously pulled images.,"/kind bug **Description** Since podman 4, when using the Docker-compatible REST API, trying to start a container that was previously pulled fails because the container does not exist on Docker Hub. More precisely I get a 404 for docker.io/library/NAME:TAG. This issue is fixed by setting `compat_api_enforce_docker_hub` to `false`. I can also report that Docker is perfectly happy with starting the containers with the same API request. This was originally discussed [here](https://github.com/containers/podman/issues/12320#issuecomment-1131537455) **Steps to reproduce the issue:** 1. Login to a private registry 2. Pull a container 3. Logout from the registry 4. Try to start the container using the Docker-compatible REST API **Describe the results you received:** 404 on `docker.io/library/NAME:TAG` Please note that I removed the environment variables sections of the requests.  # podman --version podman version 4.0.2 # podman --log-level=debug system service -t 0 tcp:0.0.0.0:2376 INFO[0000] podman filtering at log level debug DEBU[0000] Called service.PersistentPreRunE(podman --log-level=debug system service -t 0 tcp:0.0.0.0:2376) DEBU[0000] Merged system config ""/usr/share/containers/containers.conf"" DEBU[0000] Merged system config ""/etc/containers/containers.conf"" DEBU[0000] Using conmon: ""/usr/bin/conmon"" DEBU[0000] Initializing boltdb state at /var/lib/containers/storage/libpod/bolt_state.db DEBU[0000] Using graph driver overlay DEBU[0000] Using graph root /var/lib/containers/storage DEBU[0000] Using run root /run/containers/storage DEBU[0000] Using static dir /var/lib/containers/storage/libpod DEBU[0000] Using tmp dir /run/libpod DEBU[0000] Using volume path /var/lib/containers/storage/volumes DEBU[0000] Set libpod namespace to """" DEBU[0000] [graphdriver] trying provided driver ""overlay"" DEBU[0000] Cached value indicated that overlay is supported DEBU[0000] Cached value indicated that metacopy is being used DEBU[0000] Cached value indicated that native-diff is not being used INFO[0000] Not using native diff for overlay, this may cause degraded performance for building images: kernel has CONFIG_OVERLAY_FS_REDIRECT_DIR enabled DEBU[0000] backingFs=xfs, projectQuotaSupported=false, useNativeDiff=false, usingMetacopy=true DEBU[0000] Initializing event backend file DEBU[0000] Configured OCI runtime runsc initialization failed: no valid executable found for OCI runtime runsc: invalid argument DEBU[0000] Configured OCI runtime krun initialization failed: no valid executable found for OCI runtime krun: invalid argument DEBU[0000] Configured OCI runtime kata initialization failed: no valid executable found for OCI runtime kata: invalid argument DEBU[0000] Using OCI runtime ""/usr/bin/runc"" INFO[0000] Setting parallel job count to 25 DEBU[0000] registered SIGHUP watcher for config DEBU[0000] CORS Headers were not set INFO[0000] API service listening on ""[::]:2376"" DEBU[0000] waiting for SIGHUP to reload configuration DEBU[0000] API service(s) shutting down, idle for 0s DEBU[0000] API service shutdown request ignored as timeout Duration is UnlimitedService DEBU[0020] IdleTracker:new 0m+0h/0t connection(s) X-Reference-Id=0xc000011318 DEBU[0020] IdleTracker:new 0m+0h/1t connection(s) X-Reference-Id=0xc000011320 DEBU[0020] IdleTracker:active 0m+0h/2t connection(s) X-Reference-Id=0xc000011320 DEBU[0020] IdleTracker:active 1m+0h/2t connection(s) X-Reference-Id=0xc000011318 DEBU[0020] Looking up image ""NAME:TAG"" in local containers storage DEBU[0020] Normalized platform linux/amd64 to {amd64 linux [] } DEBU[0020] Trying ""NAME:TAG""  DEBU[0020] Loading registries configuration ""/etc/containers/registries.conf"" DEBU[0020] Looking up image ""NAME:TAG"" in local containers storage DEBU[0020] Normalized platform linux/amd64 to {amd64 linux [] } DEBU[0020] Trying ""NAME:TAG""  DEBU[0020] Loading registries configuration ""/etc/containers/registries.conf.d/000-shortnames.conf"" DEBU[0020] Loading registries configuration ""/etc/containers/registries.conf.d/001-rhel-shortnames.conf"" DEBU[0020] Loading registries configuration ""/etc/containers/registries.conf.d/002-rhel-shortnames-overrides.conf"" DEBU[0020] Trying ""localhost/NAME:TAG""  DEBU[0020] Trying ""registry.fedoraproject.org/NAME:TAG""  DEBU[0020] Trying ""localhost/NAME:TAG""  DEBU[0020] Trying ""registry.access.redhat.com/NAME:TAG""  DEBU[0020] Trying ""registry.fedoraproject.org/NAME:TAG""  DEBU[0020] Trying ""registry.centos.org/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""registry.access.redhat.com/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""registry.centos.org/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""REGISTRY/PATH/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] parsed reference into ""[overlay@/var/lib/containers/storage+/run/containers/storage:overlay.mountopt=nodev,metacopy=on]@5fb70826285b943f31f0c4b0dc0247d29177941c6e01a99b188bdda633244892"" DEBU[0020] Found image ""NAME:TAG"" as ""REGISTRY/PATH/NAME:TAG"" in local containers storage DEBU[0020] Trying ""REGISTRY/PATH/NAME:TAG""  DEBU[0020] parsed reference into ""[overlay@/var/lib/containers/storage+/run/containers/storage:overlay.mountopt=nodev,metacopy=on]@5fb70826285b943f31f0c4b0dc0247d29177941c6e01a99b188bdda633244892"" DEBU[0020] Found image ""NAME:TAG"" as ""REGISTRY/PATH/NAME:TAG"" in local containers storage DEBU[0020] Found image ""NAME:TAG"" as ""REGISTRY/PATH/NAME:TAG"" in local containers storage ([overlay@/var/lib/containers/storage+/run/containers/storage:overlay.mountopt=nodev,metacopy=on]@5fb70826285b943f31f0c4b0dc0247d29177941c6e01a99b188bdda633244892) DEBU[0020] Looking up image ""docker.io/library/NAME:TAG"" in local containers storage DEBU[0020] Normalized platform linux/amd64 to {amd64 linux [] } DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Found image ""NAME:TAG"" as ""REGISTRY/PATH/NAME:TAG"" in local containers storage ([overlay@/var/lib/containers/storage+/run/containers/storage:overlay.mountopt=nodev,metacopy=on]@5fb70826285b943f31f0c4b0dc0247d29177941c6e01a99b188bdda633244892) DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Looking up image ""docker.io/library/NAME:TAG"" in local containers storage DEBU[0020] Normalized platform linux/amd64 to {amd64 linux [] } DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  INFO[0020] Request Failed(Not Found): No such image: docker.io/library/NAME:TAG: image not known DEBU[0020] Trying ""docker.io/library/NAME:TAG""  INFO[0020] Request Failed(Not Found): No such image: docker.io/library/NAME:TAG: image not known 34.74.239.56 - - [19/May/2022:11:31:19 +0000] ""POST /containers/create?Image=NAME%3ATAG&Tty=true&Cmd=%5B%22%2Fopt%2Fbin%2Fentry_point.sh%22%5D&HostConfig=%7B%22Privileged%22%3Atrue%2C%22Binds%22%3A%5B%22%2Fdev%2Fshm%3A%2Fdev%2Fshm%22%2C%22%2Fdata%2Fvideo%3A%2Fvideo%22%2C%22%2Fdata%2Fbrowsers%3A%2Fbrowsers%22%5D%7D&name=overconfident-wish-2&Env=REMOVED_BY_PETER HTTP/1.1"" 404 133 """" """" 34.74.239.56 - - [19/May/2022:11:31:19 +0000] ""POST /containers/create?Image=NAME%3ATAG&Tty=true&Cmd=%5B%22%2Fopt%2Fbin%2Fentry_point.sh%22%5D&HostConfig=%7B%22Privileged%22%3Atrue%2C%22Binds%22%3A%5B%22%2Fdev%2Fshm%3A%2Fdev%2Fshm%22%2C%22%2Fdata%2Fvideo%3A%2Fvideo%22%2C%22%2Fdata%2Fbrowsers%3A%2Fbrowsers%22%5D%2C%22PortBindings%22%3A%7B%225900%2Ftcp%22%3A%5B%7B%22HostPort%22%3A%225900%22%7D%5D%2C%229229%2Ftcp%22%3A%5B%7B%22HostPort%22%3A%229229%22%7D%5D%7D%7D&name=overconfident-wish-1&Env=REMOVED_BY_PETER HTTP/1.1"" 404 133 """" """" DEBU[0020] IdleTracker:closed 2m+0h/2t connection(s) X-Reference-Id=0xc000011320 DEBU[0020] IdleTracker:closed 1m+0h/2t connection(s) X-Reference-Id=0xc000011318  **Describe the results you expected:** The container should start as it is found on local storage. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  podman version 4.0.2  **Output of `podman info --debug`:**  host: arch: amd64 buildahVersion: 1.24.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - rdma cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-1.module_el8.6.0+2877+8e437bf5.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: edfc4e28654b9f8e3597bb8f87c6af099a50261f' cpus: 8 distribution: distribution: '""spearlineos""' version: ""8.6"" eventLogger: file hostname: peter-from-image1 idMappings: gidmap: null uidmap: null kernel: 4.18.0-372.9.1.el8.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 4423311360 memTotal: 8340979712 networkBackend: cni ociRuntime: name: runc package: runc-1.0.3-1.module_el8.6.0+2877+8e437bf5.x86_64 path: /usr/bin/runc version: |- runc version 1.0.3 spec: 1.0.2-dev go: go1.17.7 libseccomp: 2.5.2 os: linux remoteSocket: path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.1.8-2.module_el8.6.0+2877+8e437bf5.x86_64 version: |- slirp4netns version 1.1.8 commit: d361001f495417b880f20329121e3aa431a8f90f libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 2209345536 swapTotal: 2209345536 uptime: 1h 18m 47.63s (Approximately 0.04 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - registry.centos.org - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 4 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.0.2 Built: 1652194338 BuiltTime: Tue May 10 14:52:18 2022 GitCommit: """" GoVersion: go1.17.7 OsArch: linux/amd64 Version: 4.0.2  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman-4.0.2-5.module_el8.6.0+2877+8e437bf5.x86_64  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** No **Additional environment details (AWS, VirtualBox, physical, etc.):** GCP",source-file | test-file | source-file | test-file | source-file | test-file,docker compatible rest api previously pulled images kind bug description since docker compatible rest api trying start container previously pulled fails container exist docker hub precisely get docker library name tag fixed setting compat api enforce docker hub false also report docker perfectly happy starting containers api originally discussed https github containers issues issuecomment steps reproduce login private registry container logout registry start container docker compatible rest api describe results received docker library name tag please note removed environment variables sections requests log level system service tcp filtering log level debu called service persistentprerune log level system service tcp debu merged system config share containers containers conf debu merged system config etc containers containers conf debu conmon conmon debu initializing boltdb state var containers storage libpod bolt state debu graph driver overlay debu graph root var containers storage debu root containers storage debu static dir var containers storage libpod debu tmp dir libpod debu volume path var containers storage volumes debu set libpod namespace debu graphdriver trying provided driver overlay debu cached value indicated overlay supported debu cached value indicated metacopy used debu cached value indicated native diff used native diff overlay may cause degraded performance building images kernel config overlay redirect dir enabled debu backingfs xfs projectquotasupported false usenativediff false usingmetacopy true debu initializing event backend debu configured oci runtime runsc initialization failed valid executable found oci runtime runsc invalid argument debu configured oci runtime krun initialization failed valid executable found oci runtime krun invalid argument debu configured oci runtime kata initialization failed valid executable found oci runtime kata invalid argument debu oci runtime runc setting parallel job count debu registered sighup watcher config debu cors headers set api service listening debu waiting sighup reload configuration debu api service shutting idle debu api service shutdown ignored timeout duration unlimitedservice debu idletracker new connection reference debu idletracker new connection reference debu idletracker active connection reference debu idletracker active connection reference debu looking image name tag local containers storage debu normalized platform linux amd amd linux debu trying name tag debu loading registries configuration etc containers registries conf debu looking image name tag local containers storage debu normalized platform linux amd amd linux debu trying name tag debu loading registries configuration etc containers registries conf shortnames conf debu loading registries configuration etc containers registries conf rhel shortnames conf debu loading registries configuration etc containers registries conf rhel shortnames overrides conf debu trying localhost name tag debu trying registry fedoraproject name tag debu trying localhost name tag debu trying registry access redhat name tag debu trying registry fedoraproject name tag debu trying registry centos name tag debu trying docker library name tag debu trying registry access redhat name tag debu trying docker library name tag debu trying registry centos name tag debu trying docker library name tag debu trying registry path name tag debu trying docker library name tag debu parsed reference overlay var containers storage containers storage overlay mountopt nodev metacopy bdda debu found image name tag registry path name tag local containers storage debu trying registry path name tag debu parsed reference overlay var containers storage containers storage overlay mountopt nodev metacopy bdda debu found image name tag registry path name tag local containers storage debu found image name tag registry path name tag local containers storage overlay var containers storage containers storage overlay mountopt nodev metacopy bdda debu looking image docker library name tag local containers storage debu normalized platform linux amd amd linux debu trying docker library name tag debu found image name tag registry path name tag local containers storage overlay var containers storage containers storage overlay mountopt nodev metacopy bdda debu trying docker library name tag debu trying docker library name tag debu looking image docker library name tag local containers storage debu normalized platform linux amd amd linux debu trying docker library name tag debu trying docker library name tag failed found image docker library name tag image known debu trying docker library name tag failed found image docker library name tag image known may post containers create image name atag tty true cmd fopt fbin fentry point hostconfig privileged atrue binds fdev fshm fdev fshm fdata fvideo fvideo fdata fbrowsers fbrowsers name overconfident wish env removed peter http may post containers create image name atag tty true cmd fopt fbin fentry point hostconfig privileged atrue binds fdev fshm fdev fshm fdata fvideo fvideo fdata fbrowsers fbrowsers portbindings ftcp hostport ftcp hostport name overconfident wish env removed peter http debu idletracker closed connection reference debu idletracker closed connection reference describe results expected container start found local storage additional information deem important happens occasionally output output host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids rdma cgroupmanager systemd cgroupversion conmon package conmon module path conmon conmon edfc cpus distribution distribution spearlineos eventlogger hostname peter image idmappings gidmap null uidmap null kernel linkmode dynamic logdriver memfree memtotal networkbackend cni ociruntime name runc package runc module path runc runc spec libseccomp linux remotesocket path sock security apparmorenabled false capabilities cap raw cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns module slirp netns libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat registry centos docker store configfile etc containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphstatus backing filesystem xfs native overlay diff false supports type true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage volumepath var containers storage volumes apiversion built builttime may gitcommit goversion osarch linux amd package output rpm apt list module tested latest checked troubleshooting guide https github containers blob troubleshooting additional environment details aws virtualbox physical etc gcp,bug,0.95,"Podman's Docker-compatible REST API and previously pulled images. /kind bug **Description** Since podman 4, when using the Docker-compatible REST API, trying to start a container that was previously pulled fails because the container does not exist on Docker Hub. More precisely I get a 404 for docker.io/library/NAME:TAG. This issue is fixed by setting `compat_api_enforce_docker_hub` to `false`. I can also report that Docker is perfectly happy with starting the containers with the same API request. This was originally discussed [here](https://github.com/containers/podman/issues/12320#issuecomment-1131537455) **Steps to reproduce the issue:** 1. Login to a private registry 2. Pull a container 3. Logout from the registry 4. Try to start the container using the Docker-compatible REST API **Describe the results you received:** 404 on `docker.io/library/NAME:TAG` Please note that I removed the environment variables sections of the requests.  # podman --version podman version 4.0.2 # podman --log-level=debug system service -t 0 tcp:0.0.0.0:2376 INFO[0000] podman filtering at log level debug DEBU[0000] Called service.PersistentPreRunE(podman --log-level=debug system service -t 0 tcp:0.0.0.0:2376) DEBU[0000] Merged system config ""/usr/share/containers/containers.conf"" DEBU[0000] Merged system config ""/etc/containers/containers.conf"" DEBU[0000] Using conmon: ""/usr/bin/conmon"" DEBU[0000] Initializing boltdb state at /var/lib/containers/storage/libpod/bolt_state.db DEBU[0000] Using graph driver overlay DEBU[0000] Using graph root /var/lib/containers/storage DEBU[0000] Using run root /run/containers/storage DEBU[0000] Using static dir /var/lib/containers/storage/libpod DEBU[0000] Using tmp dir /run/libpod DEBU[0000] Using volume path /var/lib/containers/storage/volumes DEBU[0000] Set libpod namespace to """" DEBU[0000] [graphdriver] trying provided driver ""overlay"" DEBU[0000] Cached value indicated that overlay is supported DEBU[0000] Cached value indicated that metacopy is being used DEBU[0000] Cached value indicated that native-diff is not being used INFO[0000] Not using native diff for overlay, this may cause degraded performance for building images: kernel has CONFIG_OVERLAY_FS_REDIRECT_DIR enabled DEBU[0000] backingFs=xfs, projectQuotaSupported=false, useNativeDiff=false, usingMetacopy=true DEBU[0000] Initializing event backend file DEBU[0000] Configured OCI runtime runsc initialization failed: no valid executable found for OCI runtime runsc: invalid argument DEBU[0000] Configured OCI runtime krun initialization failed: no valid executable found for OCI runtime krun: invalid argument DEBU[0000] Configured OCI runtime kata initialization failed: no valid executable found for OCI runtime kata: invalid argument DEBU[0000] Using OCI runtime ""/usr/bin/runc"" INFO[0000] Setting parallel job count to 25 DEBU[0000] registered SIGHUP watcher for config DEBU[0000] CORS Headers were not set INFO[0000] API service listening on ""[::]:2376"" DEBU[0000] waiting for SIGHUP to reload configuration DEBU[0000] API service(s) shutting down, idle for 0s DEBU[0000] API service shutdown request ignored as timeout Duration is UnlimitedService DEBU[0020] IdleTracker:new 0m+0h/0t connection(s) X-Reference-Id=0xc000011318 DEBU[0020] IdleTracker:new 0m+0h/1t connection(s) X-Reference-Id=0xc000011320 DEBU[0020] IdleTracker:active 0m+0h/2t connection(s) X-Reference-Id=0xc000011320 DEBU[0020] IdleTracker:active 1m+0h/2t connection(s) X-Reference-Id=0xc000011318 DEBU[0020] Looking up image ""NAME:TAG"" in local containers storage DEBU[0020] Normalized platform linux/amd64 to {amd64 linux [] } DEBU[0020] Trying ""NAME:TAG""  DEBU[0020] Loading registries configuration ""/etc/containers/registries.conf"" DEBU[0020] Looking up image ""NAME:TAG"" in local containers storage DEBU[0020] Normalized platform linux/amd64 to {amd64 linux [] } DEBU[0020] Trying ""NAME:TAG""  DEBU[0020] Loading registries configuration ""/etc/containers/registries.conf.d/000-shortnames.conf"" DEBU[0020] Loading registries configuration ""/etc/containers/registries.conf.d/001-rhel-shortnames.conf"" DEBU[0020] Loading registries configuration ""/etc/containers/registries.conf.d/002-rhel-shortnames-overrides.conf"" DEBU[0020] Trying ""localhost/NAME:TAG""  DEBU[0020] Trying ""registry.fedoraproject.org/NAME:TAG""  DEBU[0020] Trying ""localhost/NAME:TAG""  DEBU[0020] Trying ""registry.access.redhat.com/NAME:TAG""  DEBU[0020] Trying ""registry.fedoraproject.org/NAME:TAG""  DEBU[0020] Trying ""registry.centos.org/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""registry.access.redhat.com/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""registry.centos.org/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""REGISTRY/PATH/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] parsed reference into ""[overlay@/var/lib/containers/storage+/run/containers/storage:overlay.mountopt=nodev,metacopy=on]@5fb70826285b943f31f0c4b0dc0247d29177941c6e01a99b188bdda633244892"" DEBU[0020] Found image ""NAME:TAG"" as ""REGISTRY/PATH/NAME:TAG"" in local containers storage DEBU[0020] Trying ""REGISTRY/PATH/NAME:TAG""  DEBU[0020] parsed reference into ""[overlay@/var/lib/containers/storage+/run/containers/storage:overlay.mountopt=nodev,metacopy=on]@5fb70826285b943f31f0c4b0dc0247d29177941c6e01a99b188bdda633244892"" DEBU[0020] Found image ""NAME:TAG"" as ""REGISTRY/PATH/NAME:TAG"" in local containers storage DEBU[0020] Found image ""NAME:TAG"" as ""REGISTRY/PATH/NAME:TAG"" in local containers storage ([overlay@/var/lib/containers/storage+/run/containers/storage:overlay.mountopt=nodev,metacopy=on]@5fb70826285b943f31f0c4b0dc0247d29177941c6e01a99b188bdda633244892) DEBU[0020] Looking up image ""docker.io/library/NAME:TAG"" in local containers storage DEBU[0020] Normalized platform linux/amd64 to {amd64 linux [] } DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Found image ""NAME:TAG"" as ""REGISTRY/PATH/NAME:TAG"" in local containers storage ([overlay@/var/lib/containers/storage+/run/containers/storage:overlay.mountopt=nodev,metacopy=on]@5fb70826285b943f31f0c4b0dc0247d29177941c6e01a99b188bdda633244892) DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Looking up image ""docker.io/library/NAME:TAG"" in local containers storage DEBU[0020] Normalized platform linux/amd64 to {amd64 linux [] } DEBU[0020] Trying ""docker.io/library/NAME:TAG""  DEBU[0020] Trying ""docker.io/library/NAME:TAG""  INFO[0020] Request Failed(Not Found): No such image: docker.io/library/NAME:TAG: image not known DEBU[0020] Trying ""docker.io/library/NAME:TAG""  INFO[0020] Request Failed(Not Found): No such image: docker.io/library/NAME:TAG: image not known 34.74.239.56 - - [19/May/2022:11:31:19 +0000] ""POST /containers/create?Image=NAME%3ATAG&Tty=true&Cmd=%5B%22%2Fopt%2Fbin%2Fentry_point.sh%22%5D&HostConfig=%7B%22Privileged%22%3Atrue%2C%22Binds%22%3A%5B%22%2Fdev%2Fshm%3A%2Fdev%2Fshm%22%2C%22%2Fdata%2Fvideo%3A%2Fvideo%22%2C%22%2Fdata%2Fbrowsers%3A%2Fbrowsers%22%5D%7D&name=overconfident-wish-2&Env=REMOVED_BY_PETER HTTP/1.1"" 404 133 """" """" 34.74.239.56 - - [19/May/2022:11:31:19 +0000] ""POST /containers/create?Image=NAME%3ATAG&Tty=true&Cmd=%5B%22%2Fopt%2Fbin%2Fentry_point.sh%22%5D&HostConfig=%7B%22Privileged%22%3Atrue%2C%22Binds%22%3A%5B%22%2Fdev%2Fshm%3A%2Fdev%2Fshm%22%2C%22%2Fdata%2Fvideo%3A%2Fvideo%22%2C%22%2Fdata%2Fbrowsers%3A%2Fbrowsers%22%5D%2C%22PortBindings%22%3A%7B%225900%2Ftcp%22%3A%5B%7B%22HostPort%22%3A%225900%22%7D%5D%2C%229229%2Ftcp%22%3A%5B%7B%22HostPort%22%3A%229229%22%7D%5D%7D%7D&name=overconfident-wish-1&Env=REMOVED_BY_PETER HTTP/1.1"" 404 133 """" """" DEBU[0020] IdleTracker:closed 2m+0h/2t connection(s) X-Reference-Id=0xc000011320 DEBU[0020] IdleTracker:closed 1m+0h/2t connection(s) X-Reference-Id=0xc000011318  **Describe the results you expected:** The container should start as it is found on local storage. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  podman version 4.0.2  **Output of `podman info --debug`:**  host: arch: amd64 buildahVersion: 1.24.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - rdma cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-1.module_el8.6.0+2877+8e437bf5.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: edfc4e28654b9f8e3597bb8f87c6af099a50261f' cpus: 8 distribution: distribution: '""spearlineos""' version: ""8.6"" eventLogger: file hostname: peter-from-image1 idMappings: gidmap: null uidmap: null kernel: 4.18.0-372.9.1.el8.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 4423311360 memTotal: 8340979712 networkBackend: cni ociRuntime: name: runc package: runc-1.0.3-1.module_el8.6.0+2877+8e437bf5.x86_64 path: /usr/bin/runc version: |- runc version 1.0.3 spec: 1.0.2-dev go: go1.17.7 libseccomp: 2.5.2 os: linux remoteSocket: path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.1.8-2.module_el8.6.0+2877+8e437bf5.x86_64 version: |- slirp4netns version 1.1.8 commit: d361001f495417b880f20329121e3aa431a8f90f libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 2209345536 swapTotal: 2209345536 uptime: 1h 18m 47.63s (Approximately 0.04 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - registry.centos.org - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 4 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.0.2 Built: 1652194338 BuiltTime: Tue May 10 14:52:18 2022 GitCommit: """" GoVersion: go1.17.7 OsArch: linux/amd64 Version: 4.0.2  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman-4.0.2-5.module_el8.6.0+2877+8e437bf5.x86_64  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** No **Additional environment details (AWS, VirtualBox, physical, etc.):** GCP"
15476,podman,https://github.com/containers/podman/issues/15476,build from API or `podman-remote build` does not supports `--userns=auto` while it works with CLI,"User trying this implementation in Podman 4.2.0. Seems its working via CLI, but API call does not work. **Dockerfile**  cat << EOF > Dockerfile FROM alpine RUN cat /proc/self/uid_map EOF  Works correctly via CLI  podman build -t test --userns=auto .  Does not work via API  tar -czf context.tar.gz Dockerfile curl -s --unix-socket /run/podman/podman.sock -X POST -H ""Content-Type:application/tar"" --data-binary ""@context.tar.gz"" 'http://d/v4.2.0/libpod/build?userns=auto'  _Originally posted by @lukasmrtvy in https://github.com/containers/buildah/issues/4060#issuecomment-1226050854_",source-file | source-file | test-file | test-file,api remote supports userns auto works cli user trying implementation seems working via cli api call work dockerfile cat eof dockerfile alpine cat proc self uid map eof works correctly via cli userns auto work via api tar czf context tar dockerfile curl unix socket sock post content type application tar data binary context tar http libpod userns auto originally posted lukasmrtvy https github containers buildah issues issuecomment,bug,0.95,"build from API or `podman-remote build` does not supports `--userns=auto` while it works with CLI User trying this implementation in Podman 4.2.0. Seems its working via CLI, but API call does not work. **Dockerfile**  cat << EOF > Dockerfile FROM alpine RUN cat /proc/self/uid_map EOF  Works correctly via CLI  podman build -t test --userns=auto .  Does not work via API  tar -czf context.tar.gz Dockerfile curl -s --unix-socket /run/podman/podman.sock -X POST -H ""Content-Type:application/tar"" --data-binary ""@context.tar.gz"" 'http://d/v4.2.0/libpod/build?userns=auto'  _Originally posted by @lukasmrtvy in https://github.com/containers/buildah/issues/4060#issuecomment-1226050854_"
18092,podman,https://github.com/containers/podman/issues/18092,Image Filtering Incompatability with Docker API," Issue Description Attempting to filter images by label value via the compat HTTP API doesn't find images that definitely exist with the set labels. The same requests with the docker socket (after the same set of calls to create a labeled image) do return images. There seems to be something about a new and old format for filters, this seems to only apply to how the new filters are handled.  Steps to reproduce the issue 1. run `podman image pull docker.io/ubuntu:22.04` 2. run:  curl --unix-socket /run/user/1000/podman/podman.sock --get 'http://_/images/json' \ --data-urlencode 'filters={""label"": [""org.opencontainers.image.ref.name=ubuntu"", ""org.opencontainers.image.version=22.04""]}'   Describe the results you received This returns `[]`.  Describe the results you expected I would expect this to return the same thing as:  curl --unix-socket /run/user/1000/podman/podman.sock --get 'http://_/images/json' \ --data-urlencode 'filters={""label"": {""org.opencontainers.image.ref.name=ubuntu"":true, ""org.opencontainers.image.version=22.04"": true}}'  Which returns:  [ { ""Id"": ""sha256:08d22c0ceb150ddeb2237c5fa3129c0183f3cc6f5eeb2e7aa4016da3ad02140a"", ""ParentId"": """", ""RepoTags"": [ ""docker.io/library/ubuntu:22.04"", ""docker.io/library/ubuntu:latest"" ], ""RepoDigests"": [ ""docker.io/library/ubuntu@sha256:67211c14fa74f070d27cc59d69a7fa9aeff8e28ea118ef3babc295a0428a6d21"", ""docker.io/library/ubuntu@sha256:7a57c69fe1e9d5b97c5fe649849e79f2cfc3bf11d10bbd5218b4eb61716aebe6"" ], ""Created"": 1678250667, ""Size"": 80337591, ""SharedSize"": 0, ""VirtualSize"": 80337591, ""Labels"": { ""org.opencontainers.image.ref.name"": ""ubuntu"", ""org.opencontainers.image.version"": ""22.04"" }, ""Containers"": 496, ""Names"": [ ""docker.io/library/ubuntu:22.04"", ""docker.io/library/ubuntu:latest"" ], ""Digest"": ""sha256:67211c14fa74f070d27cc59d69a7fa9aeff8e28ea118ef3babc295a0428a6d21"", ""History"": [ ""docker.io/library/ubuntu:latest"", ""docker.io/library/ubuntu:22.04"" ] } ]   podman info output yaml Client: Podman Engine Version: 4.4.2 API Version: 4.4.2 Go Version: go1.19.6 Built: Wed Mar 1 05:22:59 2023 OS/Arch: linux/amd64   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release No  Additional environment details _No response_  Additional information When the above commands are run, but for the docker command/socket, both curl calls result in the same output.",source-file | test-file | source-file | test-file,image filtering incompatability docker api description attempting filter images label value via compat http api find images definitely exist set labels requests docker socket set calls create labeled image return images seems something new old format filters seems apply new filters handled steps reproduce image docker ubuntu curl unix socket user sock get http images json data urlencode filters label opencontainers image ref name ubuntu opencontainers image describe results received returns describe results expected would expect return thing curl unix socket user sock get http images json data urlencode filters label opencontainers image ref name ubuntu true opencontainers image true returns sha ceb ddeb eeb parentid repotags docker library ubuntu docker library ubuntu latest repodigests docker library ubuntu sha aeff babc docker library ubuntu sha cfc bbd aebe created size sharedsize virtualsize labels opencontainers image ref name ubuntu opencontainers image containers names docker library ubuntu docker library ubuntu latest digest sha aeff babc history docker library ubuntu latest docker library ubuntu output yaml client engine api built mar arch linux amd container privileged rootless rootless upstream latest additional environment details response additional information commands docker command socket curl calls result output,bug,0.95,"Image Filtering Incompatability with Docker API  Issue Description Attempting to filter images by label value via the compat HTTP API doesn't find images that definitely exist with the set labels. The same requests with the docker socket (after the same set of calls to create a labeled image) do return images. There seems to be something about a new and old format for filters, this seems to only apply to how the new filters are handled.  Steps to reproduce the issue 1. run `podman image pull docker.io/ubuntu:22.04` 2. run:  curl --unix-socket /run/user/1000/podman/podman.sock --get 'http://_/images/json' \ --data-urlencode 'filters={""label"": [""org.opencontainers.image.ref.name=ubuntu"", ""org.opencontainers.image.version=22.04""]}'   Describe the results you received This returns `[]`.  Describe the results you expected I would expect this to return the same thing as:  curl --unix-socket /run/user/1000/podman/podman.sock --get 'http://_/images/json' \ --data-urlencode 'filters={""label"": {""org.opencontainers.image.ref.name=ubuntu"":true, ""org.opencontainers.image.version=22.04"": true}}'  Which returns:  [ { ""Id"": ""sha256:08d22c0ceb150ddeb2237c5fa3129c0183f3cc6f5eeb2e7aa4016da3ad02140a"", ""ParentId"": """", ""RepoTags"": [ ""docker.io/library/ubuntu:22.04"", ""docker.io/library/ubuntu:latest"" ], ""RepoDigests"": [ ""docker.io/library/ubuntu@sha256:67211c14fa74f070d27cc59d69a7fa9aeff8e28ea118ef3babc295a0428a6d21"", ""docker.io/library/ubuntu@sha256:7a57c69fe1e9d5b97c5fe649849e79f2cfc3bf11d10bbd5218b4eb61716aebe6"" ], ""Created"": 1678250667, ""Size"": 80337591, ""SharedSize"": 0, ""VirtualSize"": 80337591, ""Labels"": { ""org.opencontainers.image.ref.name"": ""ubuntu"", ""org.opencontainers.image.version"": ""22.04"" }, ""Containers"": 496, ""Names"": [ ""docker.io/library/ubuntu:22.04"", ""docker.io/library/ubuntu:latest"" ], ""Digest"": ""sha256:67211c14fa74f070d27cc59d69a7fa9aeff8e28ea118ef3babc295a0428a6d21"", ""History"": [ ""docker.io/library/ubuntu:latest"", ""docker.io/library/ubuntu:22.04"" ] } ]   podman info output yaml Client: Podman Engine Version: 4.4.2 API Version: 4.4.2 Go Version: go1.19.6 Built: Wed Mar 1 05:22:59 2023 OS/Arch: linux/amd64   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release No  Additional environment details _No response_  Additional information When the above commands are run, but for the docker command/socket, both curl calls result in the same output."
14458,podman,https://github.com/containers/podman/issues/14458,podman logs missing last line from json stdout,"/kind bug **Description** <!-- Using the docker-style API or podman logs command the JSON output from a container is missing the last line leading to malformed JSON and decoding errors. This is present in podman version 4.2.0-dev and 3.4.2 --> **Steps to reproduce the issue:** 1. podman pull docker.io/fkiecad/cwe_checker:stable 2. podman run fkiecad/cwe_checker:stable /bin/echo --json ERROR: instr_001022f0_2: Call target at 00102050 does not exist ERROR: instr_001022f5_2: Call target at 00102050 does not exist ERROR: instr_001022fa_2: Call target at 00102050 does not exist ERROR: instr_001022ff_2: Call target at 00102050 does not exist ERROR: instr_00102304_2: Call target at 00102050 does not exist ERROR: instr_00102309_2: Call target at 00102050 does not exist ERROR: instr_0010230e_2: Call target at 00102050 does not exist ERROR: instr_00102313_2: Call target at 00102050 does not exist ERROR: instr_00102318_2: Call target at 00102050 does not exist ERROR: instr_0010231d_2: Call target at 00102050 does not exist ERROR: instr_00102322_2: Call target at 00102050 does not exist ERROR: instr_00103070_2: Call target at 00102050 does not exist ERROR: instr_001050b0_0: Jump target at 00102327 does not exist ERROR: instr_001050b9_0: Jump target at 00102327 does not exist ERROR: instr_00105b70_2: Call target at 00102050 does not exist DEBUG: Pointer Inference @ instr_001042b2_2: Address not contained in runtime memory image DEBUG: Pointer Inference @ instr_00105963_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104291_0: Address not contained in runtime memory image DEBUG: Pointer Inference @ instr_00105ce4_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_00104d42_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001058a0_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00105c02_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_00105778_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001043d7_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001044fe_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104882_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_001059e8_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104867_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_001048a8_2: Free on a non-pointer value called. DEBUG: Pointer Inference: Adding 4 entry points DEBUG: Pointer Inference: Blocks with state: 14 / 1109 DEBUG: Pointer Inference: Adding 60 speculative entry points DEBUG: Pointer Inference: Blocks with state: 1040 / 1109 DEBUG: Pointer Inference: Adding 0 speculative entry points DEBUG: Pointer Inference: Blocks with state: 1040 / 1109 [ { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""001032a9"" ], ""tids"": [ ""instr_001032a9_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (001032a9) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""0010335c"" ], ""tids"": [ ""instr_0010335c_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (0010335c) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00103398"" ], ""tids"": [ ""instr_00103398_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""memcmp"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (00103398) -> memcmp"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00103c9e"" ], ""tids"": [ ""instr_00103c9e_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (00103c9e) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00104485"" ], ""tids"": [ ""instr_00104485_2"" ], ""symbols"": [ ""FUN_001043f0"" ], ""other"": [ [ ""dangerous_function"", ""memset"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_001043f0 (00104485) -> memset"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105aef"" ], ""tids"": [ ""instr_00105aef_0"" ], ""symbols"": [ ""FUN_00105ac0"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105ac0 (00105aef) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105b0a"" ], ""tids"": [ ""instr_00105b0a_2"" ], ""symbols"": [ ""FUN_00105b00"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105b00 (00105b0a) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105b30"" ], ""tids"": [ ""instr_00105b30_0"" ], ""symbols"": [ ""FUN_00105b00"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105b00 (00105b30) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105d52"" ], ""tids"": [ ""instr_00105d52_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105d52) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105d85"" ], ""tids"": [ ""instr_00105d85_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105d85) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105daa"" ], ""tids"": [ ""instr_00105daa_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105daa) -> memcpy"" }, { ""name"": ""CWE125"", ""version"": ""0.2"", ""addresses"": [ ""001042b2"" ], ""tids"": [ ""instr_001042b2_2"" ], ""symbols"": [], ""other"": [], ""description"": ""(Out-of-bounds Read) Memory load at 001042b2 may be out of bounds"" }, { ""name"": ""CWE125"", ""version"": ""0.2"", ""addresses"": [ ""00104291"" ], ""tids"": [ ""instr_00104291_0"" ], ""symbols"": [], ""other"": [], ""description"": ""(Out-of-bounds Read) Memory load at 00104291 may be out of bounds"" } ] 3. podman logs 90613051c45e ERROR: instr_001022f0_2: Call target at 00102050 does not exist ERROR: instr_001022f5_2: Call target at 00102050 does not exist ERROR: instr_001022fa_2: Call target at 00102050 does not exist ERROR: instr_001022ff_2: Call target at 00102050 does not exist ERROR: instr_00102304_2: Call target at 00102050 does not exist ERROR: instr_00102309_2: Call target at 00102050 does not exist ERROR: instr_0010230e_2: Call target at 00102050 does not exist ERROR: instr_00102313_2: Call target at 00102050 does not exist ERROR: instr_00102318_2: Call target at 00102050 does not exist ERROR: instr_0010231d_2: Call target at 00102050 does not exist ERROR: instr_00102322_2: Call target at 00102050 does not exist ERROR: instr_00103070_2: Call target at 00102050 does not exist ERROR: instr_001050b0_0: Jump target at 00102327 does not exist ERROR: instr_001050b9_0: Jump target at 00102327 does not exist ERROR: instr_00105b70_2: Call target at 00102050 does not exist DEBUG: Pointer Inference @ instr_001042b2_2: Address not contained in runtime memory image DEBUG: Pointer Inference @ instr_00105963_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104291_0: Address not contained in runtime memory image DEBUG: Pointer Inference @ instr_00105ce4_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_00104d42_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001058a0_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00105c02_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_00105778_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001043d7_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001044fe_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104882_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_001059e8_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104867_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_001048a8_2: Free on a non-pointer value called. DEBUG: Pointer Inference: Adding 4 entry points DEBUG: Pointer Inference: Blocks with state: 14 / 1109 DEBUG: Pointer Inference: Adding 60 speculative entry points DEBUG: Pointer Inference: Blocks with state: 1040 / 1109 DEBUG: Pointer Inference: Adding 0 speculative entry points DEBUG: Pointer Inference: Blocks with state: 1040 / 1109 [ { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""001032a9"" ], ""tids"": [ ""instr_001032a9_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (001032a9) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""0010335c"" ], ""tids"": [ ""instr_0010335c_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (0010335c) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00103398"" ], ""tids"": [ ""instr_00103398_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""memcmp"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (00103398) -> memcmp"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00103c9e"" ], ""tids"": [ ""instr_00103c9e_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (00103c9e) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00104485"" ], ""tids"": [ ""instr_00104485_2"" ], ""symbols"": [ ""FUN_001043f0"" ], ""other"": [ [ ""dangerous_function"", ""memset"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_001043f0 (00104485) -> memset"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105aef"" ], ""tids"": [ ""instr_00105aef_0"" ], ""symbols"": [ ""FUN_00105ac0"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105ac0 (00105aef) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105b0a"" ], ""tids"": [ ""instr_00105b0a_2"" ], ""symbols"": [ ""FUN_00105b00"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105b00 (00105b0a) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105b30"" ], ""tids"": [ ""instr_00105b30_0"" ], ""symbols"": [ ""FUN_00105b00"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105b00 (00105b30) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105d52"" ], ""tids"": [ ""instr_00105d52_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105d52) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105d85"" ], ""tids"": [ ""instr_00105d85_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105d85) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105daa"" ], ""tids"": [ ""instr_00105daa_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105daa) -> memcpy"" }, { ""name"": ""CWE125"", ""version"": ""0.2"", ""addresses"": [ ""001042b2"" ], ""tids"": [ ""instr_001042b2_2"" ], ""symbols"": [], ""other"": [], ""description"": ""(Out-of-bounds Read) Memory load at 001042b2 may be out of bounds"" }, { ""name"": ""CWE125"", ""version"": ""0.2"", ""addresses"": [ ""00104291"" ], ""tids"": [ ""instr_00104291_0"" ], ""symbols"": [], ""other"": [], ""description"": ""(Out-of-bounds Read) Memory load at 00104291 may be out of bounds"" } **Describe the results you received:** The stdout from the run command shows the last line with the ""]"", however the logs command is missing the ""]"". If I do the same thing with docker the logs command is not missing the last line. **Describe the results you expected:** I expected the logs command to provide the last line of the stdout. **Additional information you deem important (e.g. issue happens only occasionally):** Issue is always reproducible. **Output of `podman version`:**  podman --version podman version 3.4.2 Also: podman --version podman version 4.2.0-dev followed the source install method on podman.io for 4.2.0. Reverted back to 3.4.2 after seeing same results on latest source.  **Output of `podman info --debug`:**  podman info --debug host: arch: amd64 buildahVersion: 1.23.1 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: 'conmon: /usr/libexec/podman/conmon' path: /usr/libexec/podman/conmon version: 'conmon version 2.0.30, commit: ' cpus: 8 distribution: codename: focal distribution: ubuntu version: ""20.04"" eventLogger: journald hostname: bryce-VirtualBox idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.13.0-44-generic linkmode: dynamic logDriver: journald memFree: 25507426304 memTotal: 39464538112 ociRuntime: name: crun package: 'crun: /usr/bin/crun' path: /usr/bin/crun version: |- crun version UNKNOWN commit: ea1fe3938eefa14eb707f1d22adff4db670645d6 spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: 'slirp4netns: /usr/bin/slirp4netns' version: |- slirp4netns version 1.1.8 commit: unknown libslirp: 4.3.1-git SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.4.3 swapFree: 2147479552 swapTotal: 2147479552 uptime: 1h 10m 20.19s (Approximately 0.04 days) plugins: log: - k8s-file - none - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /home/bryce/.config/containers/storage.conf containerStore: number: 11 paused: 0 running: 3 stopped: 8 graphDriverName: overlay graphOptions: {} graphRoot: /home/bryce/.local/share/containers/storage graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageStore: number: 59 runRoot: /run/user/1000/containers volumePath: /home/bryce/.local/share/containers/storage/volumes version: APIVersion: 3.4.2 Built: 0 BuiltTime: Wed Dec 31 18:00:00 1969 GitCommit: """" GoVersion: go1.15.2 OsArch: linux/amd64 Version: 3.4.2  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  apt list podman Listing Done podman/unknown,now 100:3.4.2-5 amd64 [installed] podman/unknown 100:3.4.2-5 arm64 podman/unknown 100:3.4.2-5 armhf podman/unknown 100:3.4.2-5 s390x  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):** VirtualBox 6.1",source-file | test-file | source-file | test-file,logs missing last json stdout kind bug description docker style api logs command json output container missing last leading malformed json decoding errors present steps reproduce docker fkiecad cwe checker stable fkiecad cwe checker stable echo json instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr jump target exist instr jump target exist instr call target exist pointer inference instr address contained runtime memory image pointer inference instr free non pointer value called pointer inference instr address contained runtime memory image pointer inference instr unexpected stack register value return pointer inference instr unexpected stack register value return pointer inference instr free non pointer value called pointer inference instr unexpected stack register value return pointer inference instr unexpected stack register value return pointer inference instr unexpected stack register value return pointer inference instr free non pointer value called pointer inference instr free non pointer value called pointer inference instr free non pointer value called pointer inference instr free non pointer value called pointer inference instr free non pointer value called pointer inference adding entry points pointer inference blocks state pointer inference adding speculative entry points pointer inference blocks state pointer inference adding speculative entry points pointer inference blocks state name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function memcmp description use potentially dangerous function fun memcmp name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function memset description use potentially dangerous function fun memset name cwe addresses aef tids instr aef symbols fun dangerous function memcpy description use potentially dangerous function fun aef memcpy name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function memcpy description use potentially dangerous function fun memcpy name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function memcpy description use potentially dangerous function fun memcpy name cwe addresses daa tids instr daa symbols fun dangerous function memcpy description use potentially dangerous function fun daa memcpy name cwe addresses tids instr symbols description bounds read memory load may bounds name cwe addresses tids instr symbols description bounds read memory load may bounds logs instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr call target exist instr jump target exist instr jump target exist instr call target exist pointer inference instr address contained runtime memory image pointer inference instr free non pointer value called pointer inference instr address contained runtime memory image pointer inference instr unexpected stack register value return pointer inference instr unexpected stack register value return pointer inference instr free non pointer value called pointer inference instr unexpected stack register value return pointer inference instr unexpected stack register value return pointer inference instr unexpected stack register value return pointer inference instr free non pointer value called pointer inference instr free non pointer value called pointer inference instr free non pointer value called pointer inference instr free non pointer value called pointer inference instr free non pointer value called pointer inference adding entry points pointer inference blocks state pointer inference adding speculative entry points pointer inference blocks state pointer inference adding speculative entry points pointer inference blocks state name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function memcmp description use potentially dangerous function fun memcmp name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function memset description use potentially dangerous function fun memset name cwe addresses aef tids instr aef symbols fun dangerous function memcpy description use potentially dangerous function fun aef memcpy name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function memcpy description use potentially dangerous function fun memcpy name cwe addresses tids instr symbols fun dangerous function strlen description use potentially dangerous function fun strlen name cwe addresses tids instr symbols fun dangerous function memcpy description use potentially dangerous function fun memcpy name cwe addresses daa tids instr daa symbols fun dangerous function memcpy description use potentially dangerous function fun daa memcpy name cwe addresses tids instr symbols description bounds read memory load may bounds name cwe addresses tids instr symbols description bounds read memory load may bounds describe results received stdout command shows last however logs command missing thing docker logs command missing last describe results expected expected logs command provide last stdout additional information deem important happens occasionally always reproducible output also followed install method reverted back seeing results latest output host arch amd buildahversion cgroupcontrollers memory pids cgroupmanager systemd cgroupversion conmon package conmon libexec conmon path libexec conmon conmon cpus distribution codename focal distribution ubuntu eventlogger journald hostname bryce virtualbox idmappings gidmap container host size container host size uidmap container host size container host size kernel generic linkmode dynamic logdriver journald memfree memtotal ociruntime name crun package crun crun path crun crun unknown eefa adff spec systemd selinux apparmor cap seccomp ebpf criu yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns slirp netns unknown libslirp git slirp config max libseccomp swapfree swaptotal uptime approximately days plugins log none journald network bridge macvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile home bryce config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home bryce local share containers storage graphstatus backing filesystem extfs native overlay diff true supports type true metacopy false imagestore number runroot user containers volumepath home bryce local share containers storage volumes apiversion built builttime dec gitcommit goversion osarch linux amd package output rpm apt list apt list listing done unknown amd installed unknown arm unknown armhf unknown tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc virtualbox,bug,0.95,"podman logs missing last line from json stdout /kind bug **Description** <!-- Using the docker-style API or podman logs command the JSON output from a container is missing the last line leading to malformed JSON and decoding errors. This is present in podman version 4.2.0-dev and 3.4.2 --> **Steps to reproduce the issue:** 1. podman pull docker.io/fkiecad/cwe_checker:stable 2. podman run fkiecad/cwe_checker:stable /bin/echo --json ERROR: instr_001022f0_2: Call target at 00102050 does not exist ERROR: instr_001022f5_2: Call target at 00102050 does not exist ERROR: instr_001022fa_2: Call target at 00102050 does not exist ERROR: instr_001022ff_2: Call target at 00102050 does not exist ERROR: instr_00102304_2: Call target at 00102050 does not exist ERROR: instr_00102309_2: Call target at 00102050 does not exist ERROR: instr_0010230e_2: Call target at 00102050 does not exist ERROR: instr_00102313_2: Call target at 00102050 does not exist ERROR: instr_00102318_2: Call target at 00102050 does not exist ERROR: instr_0010231d_2: Call target at 00102050 does not exist ERROR: instr_00102322_2: Call target at 00102050 does not exist ERROR: instr_00103070_2: Call target at 00102050 does not exist ERROR: instr_001050b0_0: Jump target at 00102327 does not exist ERROR: instr_001050b9_0: Jump target at 00102327 does not exist ERROR: instr_00105b70_2: Call target at 00102050 does not exist DEBUG: Pointer Inference @ instr_001042b2_2: Address not contained in runtime memory image DEBUG: Pointer Inference @ instr_00105963_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104291_0: Address not contained in runtime memory image DEBUG: Pointer Inference @ instr_00105ce4_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_00104d42_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001058a0_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00105c02_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_00105778_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001043d7_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001044fe_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104882_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_001059e8_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104867_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_001048a8_2: Free on a non-pointer value called. DEBUG: Pointer Inference: Adding 4 entry points DEBUG: Pointer Inference: Blocks with state: 14 / 1109 DEBUG: Pointer Inference: Adding 60 speculative entry points DEBUG: Pointer Inference: Blocks with state: 1040 / 1109 DEBUG: Pointer Inference: Adding 0 speculative entry points DEBUG: Pointer Inference: Blocks with state: 1040 / 1109 [ { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""001032a9"" ], ""tids"": [ ""instr_001032a9_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (001032a9) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""0010335c"" ], ""tids"": [ ""instr_0010335c_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (0010335c) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00103398"" ], ""tids"": [ ""instr_00103398_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""memcmp"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (00103398) -> memcmp"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00103c9e"" ], ""tids"": [ ""instr_00103c9e_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (00103c9e) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00104485"" ], ""tids"": [ ""instr_00104485_2"" ], ""symbols"": [ ""FUN_001043f0"" ], ""other"": [ [ ""dangerous_function"", ""memset"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_001043f0 (00104485) -> memset"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105aef"" ], ""tids"": [ ""instr_00105aef_0"" ], ""symbols"": [ ""FUN_00105ac0"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105ac0 (00105aef) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105b0a"" ], ""tids"": [ ""instr_00105b0a_2"" ], ""symbols"": [ ""FUN_00105b00"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105b00 (00105b0a) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105b30"" ], ""tids"": [ ""instr_00105b30_0"" ], ""symbols"": [ ""FUN_00105b00"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105b00 (00105b30) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105d52"" ], ""tids"": [ ""instr_00105d52_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105d52) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105d85"" ], ""tids"": [ ""instr_00105d85_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105d85) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105daa"" ], ""tids"": [ ""instr_00105daa_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105daa) -> memcpy"" }, { ""name"": ""CWE125"", ""version"": ""0.2"", ""addresses"": [ ""001042b2"" ], ""tids"": [ ""instr_001042b2_2"" ], ""symbols"": [], ""other"": [], ""description"": ""(Out-of-bounds Read) Memory load at 001042b2 may be out of bounds"" }, { ""name"": ""CWE125"", ""version"": ""0.2"", ""addresses"": [ ""00104291"" ], ""tids"": [ ""instr_00104291_0"" ], ""symbols"": [], ""other"": [], ""description"": ""(Out-of-bounds Read) Memory load at 00104291 may be out of bounds"" } ] 3. podman logs 90613051c45e ERROR: instr_001022f0_2: Call target at 00102050 does not exist ERROR: instr_001022f5_2: Call target at 00102050 does not exist ERROR: instr_001022fa_2: Call target at 00102050 does not exist ERROR: instr_001022ff_2: Call target at 00102050 does not exist ERROR: instr_00102304_2: Call target at 00102050 does not exist ERROR: instr_00102309_2: Call target at 00102050 does not exist ERROR: instr_0010230e_2: Call target at 00102050 does not exist ERROR: instr_00102313_2: Call target at 00102050 does not exist ERROR: instr_00102318_2: Call target at 00102050 does not exist ERROR: instr_0010231d_2: Call target at 00102050 does not exist ERROR: instr_00102322_2: Call target at 00102050 does not exist ERROR: instr_00103070_2: Call target at 00102050 does not exist ERROR: instr_001050b0_0: Jump target at 00102327 does not exist ERROR: instr_001050b9_0: Jump target at 00102327 does not exist ERROR: instr_00105b70_2: Call target at 00102050 does not exist DEBUG: Pointer Inference @ instr_001042b2_2: Address not contained in runtime memory image DEBUG: Pointer Inference @ instr_00105963_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104291_0: Address not contained in runtime memory image DEBUG: Pointer Inference @ instr_00105ce4_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_00104d42_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001058a0_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00105c02_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_00105778_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001043d7_0_r: Unexpected stack register value on return DEBUG: Pointer Inference @ instr_001044fe_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104882_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_001059e8_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_00104867_2: Free on a non-pointer value called. DEBUG: Pointer Inference @ instr_001048a8_2: Free on a non-pointer value called. DEBUG: Pointer Inference: Adding 4 entry points DEBUG: Pointer Inference: Blocks with state: 14 / 1109 DEBUG: Pointer Inference: Adding 60 speculative entry points DEBUG: Pointer Inference: Blocks with state: 1040 / 1109 DEBUG: Pointer Inference: Adding 0 speculative entry points DEBUG: Pointer Inference: Blocks with state: 1040 / 1109 [ { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""001032a9"" ], ""tids"": [ ""instr_001032a9_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (001032a9) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""0010335c"" ], ""tids"": [ ""instr_0010335c_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (0010335c) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00103398"" ], ""tids"": [ ""instr_00103398_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""memcmp"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (00103398) -> memcmp"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00103c9e"" ], ""tids"": [ ""instr_00103c9e_2"" ], ""symbols"": [ ""FUN_00103160"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00103160 (00103c9e) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00104485"" ], ""tids"": [ ""instr_00104485_2"" ], ""symbols"": [ ""FUN_001043f0"" ], ""other"": [ [ ""dangerous_function"", ""memset"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_001043f0 (00104485) -> memset"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105aef"" ], ""tids"": [ ""instr_00105aef_0"" ], ""symbols"": [ ""FUN_00105ac0"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105ac0 (00105aef) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105b0a"" ], ""tids"": [ ""instr_00105b0a_2"" ], ""symbols"": [ ""FUN_00105b00"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105b00 (00105b0a) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105b30"" ], ""tids"": [ ""instr_00105b30_0"" ], ""symbols"": [ ""FUN_00105b00"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105b00 (00105b30) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105d52"" ], ""tids"": [ ""instr_00105d52_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""strlen"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105d52) -> strlen"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105d85"" ], ""tids"": [ ""instr_00105d85_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105d85) -> memcpy"" }, { ""name"": ""CWE676"", ""version"": ""0.1"", ""addresses"": [ ""00105daa"" ], ""tids"": [ ""instr_00105daa_2"" ], ""symbols"": [ ""FUN_00105d30"" ], ""other"": [ [ ""dangerous_function"", ""memcpy"" ] ], ""description"": ""(Use of Potentially Dangerous Function) FUN_00105d30 (00105daa) -> memcpy"" }, { ""name"": ""CWE125"", ""version"": ""0.2"", ""addresses"": [ ""001042b2"" ], ""tids"": [ ""instr_001042b2_2"" ], ""symbols"": [], ""other"": [], ""description"": ""(Out-of-bounds Read) Memory load at 001042b2 may be out of bounds"" }, { ""name"": ""CWE125"", ""version"": ""0.2"", ""addresses"": [ ""00104291"" ], ""tids"": [ ""instr_00104291_0"" ], ""symbols"": [], ""other"": [], ""description"": ""(Out-of-bounds Read) Memory load at 00104291 may be out of bounds"" } **Describe the results you received:** The stdout from the run command shows the last line with the ""]"", however the logs command is missing the ""]"". If I do the same thing with docker the logs command is not missing the last line. **Describe the results you expected:** I expected the logs command to provide the last line of the stdout. **Additional information you deem important (e.g. issue happens only occasionally):** Issue is always reproducible. **Output of `podman version`:**  podman --version podman version 3.4.2 Also: podman --version podman version 4.2.0-dev followed the source install method on podman.io for 4.2.0. Reverted back to 3.4.2 after seeing same results on latest source.  **Output of `podman info --debug`:**  podman info --debug host: arch: amd64 buildahVersion: 1.23.1 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: 'conmon: /usr/libexec/podman/conmon' path: /usr/libexec/podman/conmon version: 'conmon version 2.0.30, commit: ' cpus: 8 distribution: codename: focal distribution: ubuntu version: ""20.04"" eventLogger: journald hostname: bryce-VirtualBox idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.13.0-44-generic linkmode: dynamic logDriver: journald memFree: 25507426304 memTotal: 39464538112 ociRuntime: name: crun package: 'crun: /usr/bin/crun' path: /usr/bin/crun version: |- crun version UNKNOWN commit: ea1fe3938eefa14eb707f1d22adff4db670645d6 spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: 'slirp4netns: /usr/bin/slirp4netns' version: |- slirp4netns version 1.1.8 commit: unknown libslirp: 4.3.1-git SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.4.3 swapFree: 2147479552 swapTotal: 2147479552 uptime: 1h 10m 20.19s (Approximately 0.04 days) plugins: log: - k8s-file - none - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /home/bryce/.config/containers/storage.conf containerStore: number: 11 paused: 0 running: 3 stopped: 8 graphDriverName: overlay graphOptions: {} graphRoot: /home/bryce/.local/share/containers/storage graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageStore: number: 59 runRoot: /run/user/1000/containers volumePath: /home/bryce/.local/share/containers/storage/volumes version: APIVersion: 3.4.2 Built: 0 BuiltTime: Wed Dec 31 18:00:00 1969 GitCommit: """" GoVersion: go1.15.2 OsArch: linux/amd64 Version: 3.4.2  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  apt list podman Listing Done podman/unknown,now 100:3.4.2-5 amd64 [installed] podman/unknown 100:3.4.2-5 arm64 podman/unknown 100:3.4.2-5 armhf podman/unknown 100:3.4.2-5 s390x  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):** VirtualBox 6.1"
25881,podman,https://github.com/containers/podman/issues/25881,Podman Restful API in rootless mode ignores ulimits," Issue Description Hello, when I use the podman in rootless mode, and want to specify ulimit for cpu through the rest api, the limit gets ignored. When I use `--ulimit cpu=10:10 ` in rootless mode on the CLI, the limit gets applied correctly. In rootful mode for rest api the ulimit gets applied. This leads me to believe the issue is connected with rootless and rest api.  Steps to reproduce the issue I am running ubuntu 24.04 and podman v 4.9.3. To see if it happens on latest podman, these steps are using podman in container, but the same behaviour is observed on my system with just rootless podman. This example shows failing use case:  podman run --privileged -u podman -it quay.io/podman/stable bash podman $LOGGING system service -t 0 tcp:0.0.0.0:8081 & # you might need to hit enter for the cmd prompt to appear podman --url tcp://127.0.0.1:8081 image pull alpine curl -X POST ""http://localhost:8081/containers/create?name=test"" \ -H ""Content-Type: application/json"" \ -d '{ ""Image"": ""alpine"", ""Name"": ""test"", ""Cmd"": [""sh"", ""-c"", ""ulimit -Ht""], ""HostConfig"": { ""Ulimits"": [ { ""Name"": ""cpu"", ""Soft"": 1, ""Hard"": 2 } ] } }' podman --url tcp://127.0.0.1:8081 inspect test #""Ulimits"": [],  As seen from the inspect command, Ulimits are empty. If I run this command instead of doing the http request `podman --url tcp://127.0.0.1:8081 run -it --ulimit cpu=1:2 alpine sh -c ""ulimit -Ht""` or start the podman as root (ie. without `-u podman`) `podman run --privileged -it quay.io/podman/stable bash` and then do the http request, the ulimits are applied correctly  ""Ulimits"": [ { ""Name"": ""RLIMIT_CPU"", ""Soft"": 1, ""Hard"": 2 }   Describe the results you received Using rootless mode and rest api, the ulimits are not applied  Describe the results you expected Using rootless mode and rest api, the cpu limit should be applied the same way when passed on CLI `--ulimit `  podman info output yaml Output from my **local** podman with v4.9.3 host: arch: amd64 buildahVersion: 1.33.7 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: Unknown path: /usr/local/libexec/podman/conmon version: 'conmon version 2.1.13, commit: 82de887596ed8ee6d9b2ee85e4f167f307bb569b' cpuUtilization: idlePercent: 99.87 systemPercent: 0.05 userPercent: 0.08 cpus: 4 databaseBackend: sqlite distribution: codename: noble distribution: ubuntu version: ""24.04"" eventLogger: journald freeLocks: 2030 hostname: server idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.11.0-1012-azure linkmode: dynamic logDriver: journald memFree: 11403198464 memTotal: 16713166848 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns_1.4.0-5_amd64 path: /usr/lib/podman/aardvark-dns version: aardvark-dns 1.4.0 package: netavark_1.4.0-4_amd64 path: /usr/lib/podman/netavark version: netavark 1.4.0 ociRuntime: name: crun package: crun_1.14.1-1_amd64 path: /usr/bin/crun version: |- crun version 1.14.1 commit: de537a7965bfbe9992e2cfae0baeb56a08128171 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt_0.0~git20240220.1e6f92b-1_amd64 version: | pasta unknown version Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: false path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns_1.2.1-1build2_amd64 version: |- slirp4netns version 1.2.1 commit: 09e31e92fa3d2a1d3ca261adaeb012c8d75a8194 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.5 swapFree: 0 swapTotal: 0 uptime: 183h 57m 22.00s (Approximately 7.62 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: {} store: configFile: /home/jan/.config/containers/storage.conf containerStore: number: 10 paused: 0 running: 0 stopped: 10 graphDriverName: overlay graphOptions: {} graphRoot: /home/jan/.local/share/containers/storage graphRootAllocated: 30084825088 graphRootUsed: 7610572800 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 2 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/jan/.local/share/containers/storage/volumes version: APIVersion: 4.9.3 Built: 0 BuiltTime: Thu Jan 1 00:00:00 1970 GitCommit: """" GoVersion: go1.22.2 Os: linux OsArch: linux/amd64 Version: 4.9.3 podman info from **podman in container** host: arch: amd64 buildahVersion: 1.39.4 cgroupControllers: - cpu - memory - pids cgroupManager: cgroupfs cgroupVersion: v2 conmon: package: conmon-2.1.13-1.fc41.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.13, commit: ' cpuUtilization: idlePercent: 99.87 systemPercent: 0.06 userPercent: 0.08 cpus: 4 databaseBackend: sqlite distribution: distribution: fedora variant: container version: ""41"" eventLogger: file freeLocks: 2048 hostname: 001ec30a88b2 idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 1 size: 999 - container_id: 1000 host_id: 1001 size: 64535 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 1 size: 999 - container_id: 1000 host_id: 1001 size: 64535 kernel: 6.11.0-1012-azure linkmode: dynamic logDriver: k8s-file memFree: 11347324928 memTotal: 16713166848 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.14.0-1.fc41.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.14.0 package: netavark-1.14.1-1.fc41.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.14.1 ociRuntime: name: crun package: crun-1.21-1.fc41.x86_64 path: /usr/bin/crun version: |- crun version 1.21 commit: 10269840aa07fb7e6b7e1acff6198692d8ff5c88 rundir: /tmp/storage-run-1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20250320.g32f6212-2.fc41.x86_64 version: """" remoteSocket: exists: true path: /tmp/storage-run-1000/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: """" package: """" version: """" swapFree: 0 swapTotal: 0 uptime: 188h 5m 28.00s (Approximately 7.83 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /home/podman/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/podman/.local/share/containers/storage graphRootAllocated: 30084825088 graphRootUsed: 7633362944 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /tmp/storage-run-1000/containers transientStore: false volumePath: /home/podman/.local/share/containers/storage/volumes version: APIVersion: 5.4.2 BuildOrigin: Fedora Project Built: 1743552000 BuiltTime: Wed Apr 2 00:00:00 2025 GitCommit: be85287fcf4590961614ee37be65eeb315e5d9ff GoVersion: go1.23.7 Os: linux OsArch: linux/amd64 Version: 5.4.2   Podman in a container Yes  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details This happens both on my local machine and Azure portal VM running ubuntu 24.04. On my machines, I have podman version 4.9.2. The reproduction is using stable podman image with podman v5.4.2  Additional information _No response_",source-file | test-file,restful api rootless mode ignores ulimits description hello use rootless mode want specify ulimit cpu rest api limit gets ignored use ulimit cpu rootless mode cli limit gets applied correctly rootful mode rest api ulimit gets applied leads believe connected rootless rest api steps reproduce running ubuntu see happens latest steps container behaviour observed system rootless example shows failing use case privileged quay stable bash logging system service tcp might need hit enter cmd prompt appear url tcp image alpine curl post http localhost containers create name content type application json image alpine name cmd ulimit hostconfig ulimits name cpu soft hard url tcp inspect ulimits seen inspect command ulimits empty command instead http url tcp ulimit cpu alpine ulimit start root without privileged quay stable bash http ulimits applied correctly ulimits name rlimit cpu soft hard describe results received rootless mode rest api ulimits applied describe results expected rootless mode rest api cpu limit applied way passed cli ulimit output yaml output local host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package unknown path local libexec conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution codename noble distribution ubuntu eventlogger journald freelocks hostname server idmappings gidmap container host size container host size uidmap container host size container host size kernel azure linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns amd path aardvark dns aardvark dns package netavark amd path netavark netavark ociruntime name crun package crun amd path crun crun bfbe cfae baeb rundir user crun spec systemd selinux apparmor cap seccomp ebpf wasm wasmedge yajl linux pasta executable pasta package passt git amd pasta unknown copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists false path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns amd slirp netns adaeb libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries store configfile home jan config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home jan local share containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff true supports type true supports shifting false supports volatile true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home jan local share containers storage volumes apiversion built builttime jan gitcommit goversion linux osarch linux amd container host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager cgroupfs cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution fedora variant container eventlogger freelocks hostname idmappings gidmap container host size container host size container host size uidmap container host size container host size container host size kernel azure linkmode dynamic logdriver memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns path libexec aardvark dns aardvark dns package netavark path libexec netavark netavark ociruntime name crun package crun path crun crun acff rundir tmp storage crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt remotesocket exists true path tmp storage sock rootlessnetworkcmd pasta security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable package swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat docker store configfile home config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home local share containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff true supports type true supports shifting false supports volatile true metacopy false imagecopytmpdir var tmp imagestore number runroot tmp storage containers transientstore false volumepath home local share containers storage volumes apiversion buildorigin fedora project built builttime apr gitcommit fcf eeb goversion linux osarch linux amd container yes privileged rootless rootless upstream latest yes additional environment details happens local machine azure portal running ubuntu machines reproduction stable image additional information response,bug,0.95,"Podman Restful API in rootless mode ignores ulimits  Issue Description Hello, when I use the podman in rootless mode, and want to specify ulimit for cpu through the rest api, the limit gets ignored. When I use `--ulimit cpu=10:10 ` in rootless mode on the CLI, the limit gets applied correctly. In rootful mode for rest api the ulimit gets applied. This leads me to believe the issue is connected with rootless and rest api.  Steps to reproduce the issue I am running ubuntu 24.04 and podman v 4.9.3. To see if it happens on latest podman, these steps are using podman in container, but the same behaviour is observed on my system with just rootless podman. This example shows failing use case:  podman run --privileged -u podman -it quay.io/podman/stable bash podman $LOGGING system service -t 0 tcp:0.0.0.0:8081 & # you might need to hit enter for the cmd prompt to appear podman --url tcp://127.0.0.1:8081 image pull alpine curl -X POST ""http://localhost:8081/containers/create?name=test"" \ -H ""Content-Type: application/json"" \ -d '{ ""Image"": ""alpine"", ""Name"": ""test"", ""Cmd"": [""sh"", ""-c"", ""ulimit -Ht""], ""HostConfig"": { ""Ulimits"": [ { ""Name"": ""cpu"", ""Soft"": 1, ""Hard"": 2 } ] } }' podman --url tcp://127.0.0.1:8081 inspect test #""Ulimits"": [],  As seen from the inspect command, Ulimits are empty. If I run this command instead of doing the http request `podman --url tcp://127.0.0.1:8081 run -it --ulimit cpu=1:2 alpine sh -c ""ulimit -Ht""` or start the podman as root (ie. without `-u podman`) `podman run --privileged -it quay.io/podman/stable bash` and then do the http request, the ulimits are applied correctly  ""Ulimits"": [ { ""Name"": ""RLIMIT_CPU"", ""Soft"": 1, ""Hard"": 2 }   Describe the results you received Using rootless mode and rest api, the ulimits are not applied  Describe the results you expected Using rootless mode and rest api, the cpu limit should be applied the same way when passed on CLI `--ulimit `  podman info output yaml Output from my **local** podman with v4.9.3 host: arch: amd64 buildahVersion: 1.33.7 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: Unknown path: /usr/local/libexec/podman/conmon version: 'conmon version 2.1.13, commit: 82de887596ed8ee6d9b2ee85e4f167f307bb569b' cpuUtilization: idlePercent: 99.87 systemPercent: 0.05 userPercent: 0.08 cpus: 4 databaseBackend: sqlite distribution: codename: noble distribution: ubuntu version: ""24.04"" eventLogger: journald freeLocks: 2030 hostname: server idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.11.0-1012-azure linkmode: dynamic logDriver: journald memFree: 11403198464 memTotal: 16713166848 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns_1.4.0-5_amd64 path: /usr/lib/podman/aardvark-dns version: aardvark-dns 1.4.0 package: netavark_1.4.0-4_amd64 path: /usr/lib/podman/netavark version: netavark 1.4.0 ociRuntime: name: crun package: crun_1.14.1-1_amd64 path: /usr/bin/crun version: |- crun version 1.14.1 commit: de537a7965bfbe9992e2cfae0baeb56a08128171 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt_0.0~git20240220.1e6f92b-1_amd64 version: | pasta unknown version Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: false path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns_1.2.1-1build2_amd64 version: |- slirp4netns version 1.2.1 commit: 09e31e92fa3d2a1d3ca261adaeb012c8d75a8194 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.5 swapFree: 0 swapTotal: 0 uptime: 183h 57m 22.00s (Approximately 7.62 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: {} store: configFile: /home/jan/.config/containers/storage.conf containerStore: number: 10 paused: 0 running: 0 stopped: 10 graphDriverName: overlay graphOptions: {} graphRoot: /home/jan/.local/share/containers/storage graphRootAllocated: 30084825088 graphRootUsed: 7610572800 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 2 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/jan/.local/share/containers/storage/volumes version: APIVersion: 4.9.3 Built: 0 BuiltTime: Thu Jan 1 00:00:00 1970 GitCommit: """" GoVersion: go1.22.2 Os: linux OsArch: linux/amd64 Version: 4.9.3 podman info from **podman in container** host: arch: amd64 buildahVersion: 1.39.4 cgroupControllers: - cpu - memory - pids cgroupManager: cgroupfs cgroupVersion: v2 conmon: package: conmon-2.1.13-1.fc41.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.13, commit: ' cpuUtilization: idlePercent: 99.87 systemPercent: 0.06 userPercent: 0.08 cpus: 4 databaseBackend: sqlite distribution: distribution: fedora variant: container version: ""41"" eventLogger: file freeLocks: 2048 hostname: 001ec30a88b2 idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 1 size: 999 - container_id: 1000 host_id: 1001 size: 64535 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 1 size: 999 - container_id: 1000 host_id: 1001 size: 64535 kernel: 6.11.0-1012-azure linkmode: dynamic logDriver: k8s-file memFree: 11347324928 memTotal: 16713166848 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.14.0-1.fc41.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.14.0 package: netavark-1.14.1-1.fc41.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.14.1 ociRuntime: name: crun package: crun-1.21-1.fc41.x86_64 path: /usr/bin/crun version: |- crun version 1.21 commit: 10269840aa07fb7e6b7e1acff6198692d8ff5c88 rundir: /tmp/storage-run-1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20250320.g32f6212-2.fc41.x86_64 version: """" remoteSocket: exists: true path: /tmp/storage-run-1000/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: """" package: """" version: """" swapFree: 0 swapTotal: 0 uptime: 188h 5m 28.00s (Approximately 7.83 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /home/podman/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/podman/.local/share/containers/storage graphRootAllocated: 30084825088 graphRootUsed: 7633362944 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /tmp/storage-run-1000/containers transientStore: false volumePath: /home/podman/.local/share/containers/storage/volumes version: APIVersion: 5.4.2 BuildOrigin: Fedora Project Built: 1743552000 BuiltTime: Wed Apr 2 00:00:00 2025 GitCommit: be85287fcf4590961614ee37be65eeb315e5d9ff GoVersion: go1.23.7 Os: linux OsArch: linux/amd64 Version: 5.4.2   Podman in a container Yes  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details This happens both on my local machine and Azure portal VM running ubuntu 24.04. On my machines, I have podman version 4.9.2. The reproduction is using stable podman image with podman v5.4.2  Additional information _No response_"
17542,podman,https://github.com/containers/podman/issues/17542,Docker compatible `/containers/<id or name>/stop` does not support negative timeouts," Issue Description The Docker compatible `/containers/<id or name>/stop` endpoint does not support using a negative timeout. Docker's [spec](https://github.com/moby/moby/blob/master/api/types/container/config.go#L24-L32) for this endpoint states that you can ""use '-1' to wait indefinitely."" rather then having a set timeout after which the container will be killed. Podman's [implementation](https://github.com/containers/podman/blob/main/pkg/api/handlers/compat/containers_stop.go#L27) of this endpoint utilizes a `uint` rather then an `int`, causing a error to be thrown when using negative values.  Steps to reproduce the issue Steps to reproduce the issue 1. Run a container 2. Send stop request with a negative (indefinite) timeout value of `-1` (if using the Docker Go SDK this will need to be `-1 * time.Second`) 3. Notice the error  Describe the results you received Request returns an error and the container continues to run.  failed to parse parameters for /v1.41/containers/<ID>/stop?t=-1: schema: error converting value for ""t""   Describe the results you expected Container is sent a stop signal and is not terminated immediately or after a default timeout.  podman info output yaml host: arch: amd64 buildahVersion: 1.29.0-dev cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.5-3.fc38.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: ' cpuUtilization: idlePercent: 95.57 systemPercent: 1.1 userPercent: 3.33 cpus: 24 distribution: distribution: fedora variant: silverblue version: ""38"" eventLogger: journald hostname: matthew-desktop.local idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.2.0-0.rc7.20230208git0983f6bf2bfc.52.fc38.x86_64 linkmode: dynamic logDriver: journald memFree: 72184705024 memTotal: 134972575744 networkBackend: cni ociRuntime: name: crun package: crun-1.8-1.fc38.x86_64 path: /usr/bin/crun version: |- crun version 1.8 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-12.fc38.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 8589930496 swapTotal: 8589930496 uptime: 5h 45m 24.00s (Approximately 0.21 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: default-route-openshift-image-registry.apps-crc.testing: Blocked: false Insecure: true Location: default-route-openshift-image-registry.apps-crc.testing MirrorByDigestOnly: false Mirrors: null Prefix: default-route-openshift-image-registry.apps-crc.testing PullFromMirror: """" search: - docker.io - quay.io - registry.fedoraproject.org - registry.access.redhat.com store: configFile: /var/home/matthew/.config/containers/storage.conf containerStore: number: 10 paused: 0 running: 8 stopped: 2 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/matthew/.local/share/containers/storage graphRootAllocated: 998483427328 graphRootUsed: 696580554752 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 329 runRoot: /run/user/1000/containers transientStore: false volumePath: /var/home/matthew/.local/share/containers/storage/volumes version: APIVersion: 4.4.0-rc2 Built: 1674134600 BuiltTime: Thu Jan 19 06:23:20 2023 GitCommit: """" GoVersion: go1.20rc3 Os: linux OsArch: linux/amd64 Version: 4.4.0-rc2   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_",source-file | source-file | source-file | source-file | source-file | source-file | source-file | documentation-file | documentation-file | documentation-file | documentation-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file,docker compatible containers name stop negative timeouts description docker compatible containers name stop endpoint negative timeout docker spec https github moby moby blob api types container config endpoint states use wait indefinitely rather set timeout container killed implementation https github containers blob pkg api handlers compat containers stop endpoint utilizes uint rather int causing thrown negative values steps reproduce steps reproduce container send stop negative indefinite timeout value docker sdk need time second notice describe results received returns container continues failed parse parameters containers stop schema converting value describe results expected container sent stop signal terminated immediately default timeout output yaml host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant silverblue eventlogger journald hostname matthew desktop local idmappings gidmap container host size container host size uidmap container host size container host size kernel git bfc linkmode dynamic logdriver journald memfree memtotal networkbackend cni ociruntime name crun package crun path crun crun aff cac rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries default route openshift image registry apps crc testing blocked false insecure true location default route openshift image registry apps crc testing mirrorbydigestonly false mirrors null prefix default route openshift image registry apps crc testing pullfrommirror search docker quay registry fedoraproject registry access redhat store configfile var home matthew config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot var home matthew local share containers storage graphrootallocated graphrootused graphstatus backing filesystem btrfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath var home matthew local share containers storage volumes apiversion built builttime jan gitcommit goversion linux osarch linux amd container privileged rootless rootless upstream latest yes additional environment details response additional information response,bug,0.95,"Docker compatible `/containers/<id or name>/stop` does not support negative timeouts  Issue Description The Docker compatible `/containers/<id or name>/stop` endpoint does not support using a negative timeout. Docker's [spec](https://github.com/moby/moby/blob/master/api/types/container/config.go#L24-L32) for this endpoint states that you can ""use '-1' to wait indefinitely."" rather then having a set timeout after which the container will be killed. Podman's [implementation](https://github.com/containers/podman/blob/main/pkg/api/handlers/compat/containers_stop.go#L27) of this endpoint utilizes a `uint` rather then an `int`, causing a error to be thrown when using negative values.  Steps to reproduce the issue Steps to reproduce the issue 1. Run a container 2. Send stop request with a negative (indefinite) timeout value of `-1` (if using the Docker Go SDK this will need to be `-1 * time.Second`) 3. Notice the error  Describe the results you received Request returns an error and the container continues to run.  failed to parse parameters for /v1.41/containers/<ID>/stop?t=-1: schema: error converting value for ""t""   Describe the results you expected Container is sent a stop signal and is not terminated immediately or after a default timeout.  podman info output yaml host: arch: amd64 buildahVersion: 1.29.0-dev cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.5-3.fc38.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: ' cpuUtilization: idlePercent: 95.57 systemPercent: 1.1 userPercent: 3.33 cpus: 24 distribution: distribution: fedora variant: silverblue version: ""38"" eventLogger: journald hostname: matthew-desktop.local idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.2.0-0.rc7.20230208git0983f6bf2bfc.52.fc38.x86_64 linkmode: dynamic logDriver: journald memFree: 72184705024 memTotal: 134972575744 networkBackend: cni ociRuntime: name: crun package: crun-1.8-1.fc38.x86_64 path: /usr/bin/crun version: |- crun version 1.8 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-12.fc38.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 8589930496 swapTotal: 8589930496 uptime: 5h 45m 24.00s (Approximately 0.21 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: default-route-openshift-image-registry.apps-crc.testing: Blocked: false Insecure: true Location: default-route-openshift-image-registry.apps-crc.testing MirrorByDigestOnly: false Mirrors: null Prefix: default-route-openshift-image-registry.apps-crc.testing PullFromMirror: """" search: - docker.io - quay.io - registry.fedoraproject.org - registry.access.redhat.com store: configFile: /var/home/matthew/.config/containers/storage.conf containerStore: number: 10 paused: 0 running: 8 stopped: 2 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/matthew/.local/share/containers/storage graphRootAllocated: 998483427328 graphRootUsed: 696580554752 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 329 runRoot: /run/user/1000/containers transientStore: false volumePath: /var/home/matthew/.local/share/containers/storage/volumes version: APIVersion: 4.4.0-rc2 Built: 1674134600 BuiltTime: Thu Jan 19 06:23:20 2023 GitCommit: """" GoVersion: go1.20rc3 Os: linux OsArch: linux/amd64 Version: 4.4.0-rc2   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_"
15765,podman,https://github.com/containers/podman/issues/15765,memory Limit is returning invalid result for `/container/stats` REST API on macOS,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** The field `memory_stats.limit` is returning an invalid value **Steps to reproduce the issue:** 1. Start a dummy container like fedora bash $ MY_DUMMY_CONTAINER=$(podman run -d fedora sleep 20000)  2. Display the memory of the container from inside the container bash $ podman exec -ti $MY_DUMMY_CONTAINER cat /proc/meminfo | head -3 MemTotal: 2018452 kB MemFree: 860084 kB MemAvailable: 1556036 kB  3. Now, read the value returned by the REST API bash curl --silent --unix-socket /Users/benoitf/.local/share/containers/podman/machine/podman-machine-default/podman.sock ""http:/v1.41/containers/$MY_DUMMY_CONTAINER/stats?stream=false&one-shot=true"" | jq .memory_stats { ""usage"": 94208, ""max_usage"": 18446744073709552000, ""limit"": 18446744073709552000 }  **Describe the results you received:**  ""limit"": 18446744073709552000  it seems this value is like the maximum value of the int/long/etc **Describe the results you expected:** something displaying around 2GB / 2Gi because it's the size of the machine.  ""limit"": 2066894848  and based from https://docs.docker.com/engine/api/v1.41/#tag/Container/operation/ContainerStats  used_memory = memory_stats.usage - memory_stats.stats.cache available_memory = memory_stats.limit Memory usage % = (used_memory / available_memory) * 100.0  **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  4.2.1  **Output of `podman info`:**  4.2.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  (paste your output here)  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes/No **Additional environment details (AWS, VirtualBox, physical, etc.):**",source-file | test-file | test-file,memory limit returning invalid result container stats rest api macos bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description field memory stats limit returning invalid value steps reproduce start dummy container like fedora bash dummy container fedora sleep display memory container inside container bash exec dummy container cat proc meminfo head memtotal memfree memavailable read value returned rest api bash curl silent unix socket users benoitf local share containers machine machine default sock http containers dummy container stats stream false one shot true memory stats usage max usage limit describe results received limit seems value like maximum value int long etc describe results expected something displaying around size machine limit based https docs docker engine api tag container operation containerstats used memory memory stats usage memory stats stats cache available memory memory stats limit memory usage used memory available memory additional information deem important happens occasionally output output package output rpm apt list paste output tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc,bug,0.95,"memory Limit is returning invalid result for `/container/stats` REST API on macOS <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** The field `memory_stats.limit` is returning an invalid value **Steps to reproduce the issue:** 1. Start a dummy container like fedora bash $ MY_DUMMY_CONTAINER=$(podman run -d fedora sleep 20000)  2. Display the memory of the container from inside the container bash $ podman exec -ti $MY_DUMMY_CONTAINER cat /proc/meminfo | head -3 MemTotal: 2018452 kB MemFree: 860084 kB MemAvailable: 1556036 kB  3. Now, read the value returned by the REST API bash curl --silent --unix-socket /Users/benoitf/.local/share/containers/podman/machine/podman-machine-default/podman.sock ""http:/v1.41/containers/$MY_DUMMY_CONTAINER/stats?stream=false&one-shot=true"" | jq .memory_stats { ""usage"": 94208, ""max_usage"": 18446744073709552000, ""limit"": 18446744073709552000 }  **Describe the results you received:**  ""limit"": 18446744073709552000  it seems this value is like the maximum value of the int/long/etc **Describe the results you expected:** something displaying around 2GB / 2Gi because it's the size of the machine.  ""limit"": 2066894848  and based from https://docs.docker.com/engine/api/v1.41/#tag/Container/operation/ContainerStats  used_memory = memory_stats.usage - memory_stats.stats.cache available_memory = memory_stats.limit Memory usage % = (used_memory / available_memory) * 100.0  **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  4.2.1  **Output of `podman info`:**  4.2.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  (paste your output here)  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes/No **Additional environment details (AWS, VirtualBox, physical, etc.):**"
19219,podman,https://github.com/containers/podman/issues/19219,Multiple filter options do not act as logical AND for volume ls," Issue Description Proximately the same issue as was described for `ps` in containers/podman#1341 Using multiple `--filter` option on volumes is an `OR` but should be `AND`.  Steps to reproduce the issue Steps to reproduce the issue: 1. Create test volumes using the follow commands 2. Query volumes using multiple filters  [root@localhost tmp]# docker volume create --label a=b --label b=a podman-test-a Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-a [root@localhost tmp]# docker volume create --label a=b --label c=d podman-test-b Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-b [root@localhost tmp]# docker volume create --label c=d --label e=f podman-test-c Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-c [root@localhost tmp]#  Query with compound filters:  [root@localhost tmp]# docker volume ls -q --filter label=a=b --filter label=c=d Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-a podman-test-b podman-test-c [root@localhost tmp]#   Describe the results you received Lists all volumes matching either label  [root@localhost tmp]# docker volume ls -q --filter label=a=b --filter label=c=d Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-a podman-test-b podman-test-c [root@localhost tmp]#   Describe the results you expected Lists only the volumes matching _all_ the specified filters:  [root@localhost tmp]# docker volume ls -q --filter label=a=b --filter label=c=d Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-b [root@localhost tmp]#   podman info output yaml host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - hugetlb - pids - rdma cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.5-1.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: ' cpuUtilization: idlePercent: 99.78 systemPercent: 0.02 userPercent: 0.19 cpus: 8 distribution: distribution: fedora variant: container version: ""36"" eventLogger: file hostname: localhost idMappings: gidmap: null uidmap: null kernel: 5.10.102.1-microsoft-standard-WSL2 linkmode: dynamic logDriver: k8s-file memFree: 1144238080 memTotal: 8190472192 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.1-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.8.1 commit: f8a096be060b22ccd3d5f3ebe44108517fbf6c30 rundir: /root/.run/containers/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +WASM:wasmedge +YAJL os: linux remoteSocket: path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 2147483648 swapTotal: 2147483648 uptime: 166h 12m 0.00s (Approximately 6.92 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /etc/containers/storage.conf containerStore: number: 4 paused: 0 running: 2 stopped: 2 graphDriverName: overlay graphOptions: overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: fuse-overlayfs-1.9-6.fc36.x86_64 Version: |- fusermount3 version: 3.10.5 fuse-overlayfs: version 1.9 FUSE library version 3.10.5 using FUSE kernel interface version 7.31 overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 269490393088 graphRootUsed: 14522699776 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 5 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.4.1 Built: 1676629882 BuiltTime: Fri Feb 17 02:31:22 2023 GitCommit: """" GoVersion: go1.18.10 Os: linux OsArch: linux/amd64 Version: 4.4.1   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details WSL environment created using podman-machine  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",other-file | source-file | source-file | source-file | source-file | test-file | other-file | source-file | source-file | source-file | source-file | test-file,multiple filter options act logical volume description proximately described containers multiple filter option volumes steps reproduce steps reproduce create volumes follow commands query volumes multiple filters root localhost tmp docker volume create label label emulate docker cli create etc containers nodocker quiet msg root localhost tmp docker volume create label label emulate docker cli create etc containers nodocker quiet msg root localhost tmp docker volume create label label emulate docker cli create etc containers nodocker quiet msg root localhost tmp query compound filters root localhost tmp docker volume filter label filter label emulate docker cli create etc containers nodocker quiet msg root localhost tmp describe results received lists volumes matching either label root localhost tmp docker volume filter label filter label emulate docker cli create etc containers nodocker quiet msg root localhost tmp describe results expected lists volumes matching specified filters root localhost tmp docker volume filter label filter label emulate docker cli create etc containers nodocker quiet msg root localhost tmp output yaml host arch amd buildahversion cgroupcontrollers cpuset cpu cpuacct blkio memory devices freezer cls perf event prio hugetlb pids rdma cgroupmanager cgroupfs cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant container eventlogger hostname localhost idmappings gidmap null uidmap null kernel microsoft standard wsl linkmode dynamic logdriver memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun ccd ebe fbf rundir root containers crun spec systemd selinux apparmor cap seccomp ebpf criu wasm wasmedge yajl linux remotesocket path sock security apparmorenabled false capabilities cap raw cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns beta slirp netns beta dda libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile etc containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mount program executable fuse overlayfs package fuse overlayfs fusermount fuse overlayfs fuse library fuse kernel interface overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff false supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime feb gitcommit goversion linux osarch linux amd container privileged rootless privileged upstream latest additional environment details wsl environment created machine additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.9,"Multiple filter options do not act as logical AND for volume ls  Issue Description Proximately the same issue as was described for `ps` in containers/podman#1341 Using multiple `--filter` option on volumes is an `OR` but should be `AND`.  Steps to reproduce the issue Steps to reproduce the issue: 1. Create test volumes using the follow commands 2. Query volumes using multiple filters  [root@localhost tmp]# docker volume create --label a=b --label b=a podman-test-a Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-a [root@localhost tmp]# docker volume create --label a=b --label c=d podman-test-b Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-b [root@localhost tmp]# docker volume create --label c=d --label e=f podman-test-c Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-c [root@localhost tmp]#  Query with compound filters:  [root@localhost tmp]# docker volume ls -q --filter label=a=b --filter label=c=d Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-a podman-test-b podman-test-c [root@localhost tmp]#   Describe the results you received Lists all volumes matching either label  [root@localhost tmp]# docker volume ls -q --filter label=a=b --filter label=c=d Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-a podman-test-b podman-test-c [root@localhost tmp]#   Describe the results you expected Lists only the volumes matching _all_ the specified filters:  [root@localhost tmp]# docker volume ls -q --filter label=a=b --filter label=c=d Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman-test-b [root@localhost tmp]#   podman info output yaml host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - hugetlb - pids - rdma cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.5-1.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: ' cpuUtilization: idlePercent: 99.78 systemPercent: 0.02 userPercent: 0.19 cpus: 8 distribution: distribution: fedora variant: container version: ""36"" eventLogger: file hostname: localhost idMappings: gidmap: null uidmap: null kernel: 5.10.102.1-microsoft-standard-WSL2 linkmode: dynamic logDriver: k8s-file memFree: 1144238080 memTotal: 8190472192 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.1-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.8.1 commit: f8a096be060b22ccd3d5f3ebe44108517fbf6c30 rundir: /root/.run/containers/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +WASM:wasmedge +YAJL os: linux remoteSocket: path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 2147483648 swapTotal: 2147483648 uptime: 166h 12m 0.00s (Approximately 6.92 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /etc/containers/storage.conf containerStore: number: 4 paused: 0 running: 2 stopped: 2 graphDriverName: overlay graphOptions: overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: fuse-overlayfs-1.9-6.fc36.x86_64 Version: |- fusermount3 version: 3.10.5 fuse-overlayfs: version 1.9 FUSE library version 3.10.5 using FUSE kernel interface version 7.31 overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 269490393088 graphRootUsed: 14522699776 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 5 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.4.1 Built: 1676629882 BuiltTime: Fri Feb 17 02:31:22 2023 GitCommit: """" GoVersion: go1.18.10 Os: linux OsArch: linux/amd64 Version: 4.4.1   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details WSL environment created using podman-machine  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
19280,podman,https://github.com/containers/podman/issues/19280,Why am I receiving random bytes over podman.socket," Issue Description I sometimes receive a sequence like this: `\SOH\NUL\NUL\NUL\NUL\NUL\NULb` which breaks the json that my script in the exec is outputting. My first workaround was to throw away the first 8 bytes but this then reoccurs later in the stream.  Steps to reproduce the issue Steps to reproduce the issue 1. send  POST /containers/{cid}/exec HTTP/1.1 Host: localhost User-Agent: something Content-Type: application/json Content-Length: 196 {""AttachStderr"":true,""AttachStdin"":false,""AttachStdout"":true,""Cmd"":[""/bin/bash"",""-c"",""ls""],""DetachKeys"":""ctrl-a"",""Logs"":false,""Stream"":true,""Tty"":false,""User"":""root"",""WorkingDir"":""/tmp/compiling""}  2. send  POST /exec/{responseIdFromStep1}/start HTTP/1.1 Host: localhost User-Agent: esystant Content-Type: application/json Content-Length: 27 {""Detach"":false,""Tty"":true}  3. Observe weird bytes prepended. 4. I've also noticed that after reading a lot of bytes, this re-occurs.  Describe the results you received This is what I get: [file1.txt](https://github.com/containers/podman/files/12089248/file1.txt)  Describe the results you expected This is what I expect to get: [file1.txt](https://github.com/containers/podman/files/12089250/file1.txt)  podman info output yaml host: arch: amd64 buildahVersion: 1.30.0 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: /usr/bin/conmon is owned by conmon 1:2.1.7-1 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: f633919178f6c8ee4fb41b848a056ec33f8d707d' cpuUtilization: idlePercent: 97.19 systemPercent: 0.4 userPercent: 2.41 cpus: 12 databaseBackend: boltdb distribution: distribution: arch version: unknown eventLogger: journald hostname: arch idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.4.3-arch1-2 linkmode: dynamic logDriver: journald memFree: 10285826048 memTotal: 33556062208 networkBackend: netavark ociRuntime: name: crun package: /usr/bin/crun is owned by crun 1.8.5-1 path: /usr/bin/crun version: |- crun version 1.8.5 commit: b6f80f766c9a89eb7b1440c0a70ab287434b17ed rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: /usr/bin/slirp4netns is owned by slirp4netns 1.2.0-1 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.4 swapFree: 8589668352 swapTotal: 8589930496 uptime: 11h 28m 53.00s (Approximately 0.46 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /home/merlijn/.config/containers/storage.conf containerStore: number: 5 paused: 0 running: 2 stopped: 3 graphDriverName: overlay graphOptions: {} graphRoot: /home/merlijn/.local/share/containers/storage graphRootAllocated: 973837332480 graphRootUsed: 832484134912 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 33 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/merlijn/.local/share/containers/storage/volumes version: APIVersion: 4.5.1 Built: 1685139594 BuiltTime: Sat May 27 00:19:54 2023 GitCommit: 9eef30051c83f62816a1772a743e5f1271b196d7-dirty GoVersion: go1.20.4 Os: linux OsArch: linux/amd64 Version: 4.5.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release No  Additional environment details Arch linux  Additional information I used `nc -U /run/user/1000/podman/podman.sock > file1.txt 2>&1` to send the http command and create the output files",source-file | source-file,receiving random bytes socket description sometimes receive sequence like soh nul nul nul nul nul nulb breaks json script exec outputting first workaround throw away first bytes reoccurs later stream steps reproduce steps reproduce send post containers cid exec http host localhost user agent something content type application json content length attachstderr true attachstdin false attachstdout true cmd bash detachkeys ctrl logs false stream true tty false user root workingdir tmp compiling send post exec responseidfromstep start http host localhost user agent esystant content type application json content length detach false tty true observe weird bytes prepended also noticed reading lot bytes occurs describe results received get txt https github containers files txt describe results expected expect get txt https github containers files txt output yaml host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon owned conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend boltdb distribution distribution arch unknown eventlogger journald hostname arch idmappings gidmap container host size container host size uidmap container host size container host size kernel arch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun owned crun path crun crun rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath etc containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns owned slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search docker store configfile home merlijn config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home merlijn local share containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff false supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home merlijn local share containers storage volumes apiversion built builttime may gitcommit eef dirty goversion linux osarch linux amd container privileged rootless none upstream latest additional environment details arch linux additional information used user sock txt send http command create output files,bug,0.9,"Why am I receiving random bytes over podman.socket  Issue Description I sometimes receive a sequence like this: `\SOH\NUL\NUL\NUL\NUL\NUL\NULb` which breaks the json that my script in the exec is outputting. My first workaround was to throw away the first 8 bytes but this then reoccurs later in the stream.  Steps to reproduce the issue Steps to reproduce the issue 1. send  POST /containers/{cid}/exec HTTP/1.1 Host: localhost User-Agent: something Content-Type: application/json Content-Length: 196 {""AttachStderr"":true,""AttachStdin"":false,""AttachStdout"":true,""Cmd"":[""/bin/bash"",""-c"",""ls""],""DetachKeys"":""ctrl-a"",""Logs"":false,""Stream"":true,""Tty"":false,""User"":""root"",""WorkingDir"":""/tmp/compiling""}  2. send  POST /exec/{responseIdFromStep1}/start HTTP/1.1 Host: localhost User-Agent: esystant Content-Type: application/json Content-Length: 27 {""Detach"":false,""Tty"":true}  3. Observe weird bytes prepended. 4. I've also noticed that after reading a lot of bytes, this re-occurs.  Describe the results you received This is what I get: [file1.txt](https://github.com/containers/podman/files/12089248/file1.txt)  Describe the results you expected This is what I expect to get: [file1.txt](https://github.com/containers/podman/files/12089250/file1.txt)  podman info output yaml host: arch: amd64 buildahVersion: 1.30.0 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: /usr/bin/conmon is owned by conmon 1:2.1.7-1 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: f633919178f6c8ee4fb41b848a056ec33f8d707d' cpuUtilization: idlePercent: 97.19 systemPercent: 0.4 userPercent: 2.41 cpus: 12 databaseBackend: boltdb distribution: distribution: arch version: unknown eventLogger: journald hostname: arch idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.4.3-arch1-2 linkmode: dynamic logDriver: journald memFree: 10285826048 memTotal: 33556062208 networkBackend: netavark ociRuntime: name: crun package: /usr/bin/crun is owned by crun 1.8.5-1 path: /usr/bin/crun version: |- crun version 1.8.5 commit: b6f80f766c9a89eb7b1440c0a70ab287434b17ed rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: /usr/bin/slirp4netns is owned by slirp4netns 1.2.0-1 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.4 swapFree: 8589668352 swapTotal: 8589930496 uptime: 11h 28m 53.00s (Approximately 0.46 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /home/merlijn/.config/containers/storage.conf containerStore: number: 5 paused: 0 running: 2 stopped: 3 graphDriverName: overlay graphOptions: {} graphRoot: /home/merlijn/.local/share/containers/storage graphRootAllocated: 973837332480 graphRootUsed: 832484134912 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 33 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/merlijn/.local/share/containers/storage/volumes version: APIVersion: 4.5.1 Built: 1685139594 BuiltTime: Sat May 27 00:19:54 2023 GitCommit: 9eef30051c83f62816a1772a743e5f1271b196d7-dirty GoVersion: go1.20.4 Os: linux OsArch: linux/amd64 Version: 4.5.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release No  Additional environment details Arch linux  Additional information I used `nc -U /run/user/1000/podman/podman.sock > file1.txt 2>&1` to send the http command and create the output files"
15828,podman,https://github.com/containers/podman/issues/15828,Create image compat endpoint does not return 404,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** The create image compatibility endpoint does not behave the same as the docker engine endpoint or the documentation https://docs.podman.io/en/latest/_static/api.html#tag/images-(compat) When provided with an image that does not exist on the query parameter `fromImage` the endpoint returns a status code 200 instead of 404. Response body contains the expected error text. <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. cURL the endpoint with the command ` curl -XPOST --unix-socket /var/run/docker.sock -v 'http://d/images/create?fromImage=NON_EXISTING_IMAGE' --header 'X-Registry-Auth: AUTH_TOKEN'` **Describe the results you received:** Received status code 200 OK  * Trying /var/run/docker.sock:0 * Connected to d (/run/user/podman/podman.sock) port 80 (#0) > POST /images/create?fromImage=NON_EXISTING_IMAGE HTTP/1.1 > Host: d > User-Agent: curl/7.83.1 > Accept: */* > X-Registry-Auth: AUTH_TOKEN > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.40 < Libpod-Api-Version: 4.1.0 < Server: Libpod/4.1.0 (linux) < X-Reference-Id: 0xc000010008 < Date: Wed, 14 Sep 2022 08:53:00 GMT < Transfer-Encoding: chunked < {""progressDetail"":{},""error"":""initializing source NON_EXISTING_IMAGE: reading manifest latest in IMAGE: manifest unknown: manifest unknown""} * Connection #0 to host d left intact  **Describe the results you expected:** Expected status code 404 NOT FOUND  * Trying /var/run/docker.sock:0 * Connected to d (/run/user/podman/podman.sock) port 80 (#0) > POST /images/create?fromImage=NON_EXISTING_IMAGE HTTP/1.1 > Host: d > User-Agent: curl/7.83.1 > Accept: */* > X-Registry-Auth: AUTH_TOKEN > * Mark bundle as not supporting multiuse < HTTP/1.1 404 Not Found < Api-Version: 1.40 < Libpod-Api-Version: 4.1.0 < Server: Libpod/4.1.0 (linux) < X-Reference-Id: 0xc000010008 < Date: Wed, 14 Sep 2022 08:53:00 GMT < Transfer-Encoding: chunked < {""progressDetail"":{},""error"":""initializing source NON_EXISTING_IMAGE: reading manifest latest in IMAGE: manifest unknown: manifest unknown""} * Connection #0 to host d left intact  **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Client: Podman Engine Version: 4.1.0 API Version: 4.1.0 Go Version: go1.18.5 Git Commit: c5de69cd3da571c8ebf1c03aa49d07c1e35da67c Built: Tue Aug 2 10:39:40 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  host: arch: amd64 buildahVersion: 1.26.1 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - hugetlb - pids - rdma cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.2-r0 path: /usr/bin/conmon version: 'conmon version 2.1.2, commit: f25214cda836296fe8695c2e582ca79d2246053a' cpuUtilization: idlePercent: 86.72 systemPercent: 4.6 userPercent: 8.68 cpus: 6 distribution: distribution: alpine version: 3.16.2 eventLogger: file hostname: image-builder-0 idMappings: gidmap: null uidmap: null kernel: 5.4.0-121-generic linkmode: dynamic logDriver: k8s-file memFree: 6932779008 memTotal: 50502590464 networkBackend: netavark ociRuntime: name: crun package: crun-1.4.5-r0 path: /usr/bin/crun version: |- crun version 1.4.5 commit: c381048530aa750495cf502ddb7181f2ded5b400 spec: 1.0.0 +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-r0 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.2 swapFree: 0 swapTotal: 0 uptime: 1762h 3m 18.39s (Approximately 73.42 days) plugins: log: - k8s-file - none - passthrough network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev graphRoot: /var/lib/containers/storage graphRootAllocated: 20507869184 graphRootUsed: 46239744 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.1.0 Built: 1659436780 BuiltTime: Tue Aug 2 10:39:40 2022 GitCommit: c5de69cd3da571c8ebf1c03aa49d07c1e35da67c GoVersion: go1.18.5 Os: linux OsArch: linux/amd64 Version: 4.1.0  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman-4.1.0-r3 x86_64 {podman} (Apache-2.0) [installed] podman-4.1.0-r4 x86_64 {podman} (Apache-2.0) [upgradable from: podman-4.1.0-r3]  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):** Running on K8S",other-file | source-file | test-file,create image compat endpoint return bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description create image compatibility endpoint behave docker engine endpoint documentation https docs latest static api html tag images compat provided image exist query parameter fromimage endpoint returns status instead response body contains expected text briefly describe paragraphs steps reproduce curl endpoint command curl xpost unix socket var docker sock http images create fromimage non existing image header registry auth auth token describe results received received status trying var docker sock connected user sock port post images create fromimage non existing image http host user agent curl accept registry auth auth token mark bundle supporting multiuse http api libpod api server libpod linux reference date sep gmt transfer encoding chunked progressdetail initializing non existing image reading manifest latest image manifest unknown manifest unknown connection host left intact describe results expected expected status found trying var docker sock connected user sock port post images create fromimage non existing image http host user agent curl accept registry auth auth token mark bundle supporting multiuse http found api libpod api server libpod linux reference date sep gmt transfer encoding chunked progressdetail initializing non existing image reading manifest latest image manifest unknown manifest unknown connection host left intact additional information deem important happens occasionally output client engine api git ebf built aug arch linux amd output host arch amd buildahversion cgroupcontrollers cpuset cpu cpuacct blkio memory devices freezer cls perf event prio hugetlb pids rdma cgroupmanager cgroupfs cgroupversion conmon package conmon path conmon conmon cda cpuutilization idlepercent systempercent userpercent cpus distribution distribution alpine eventlogger hostname image builder idmappings gidmap null uidmap null kernel generic linkmode dynamic logdriver memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun ddb ded spec selinux apparmor cap seccomp ebpf yajl linux remotesocket path sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath etc containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins log none passthrough network bridge macvlan volume local registries search docker store configfile etc containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot containers storage volumepath var containers storage volumes apiversion built builttime aug gitcommit ebf goversion linux osarch linux amd package output rpm apt list apache installed apache upgradable tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc running,bug,0.95,"Create image compat endpoint does not return 404 <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** The create image compatibility endpoint does not behave the same as the docker engine endpoint or the documentation https://docs.podman.io/en/latest/_static/api.html#tag/images-(compat) When provided with an image that does not exist on the query parameter `fromImage` the endpoint returns a status code 200 instead of 404. Response body contains the expected error text. <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. cURL the endpoint with the command ` curl -XPOST --unix-socket /var/run/docker.sock -v 'http://d/images/create?fromImage=NON_EXISTING_IMAGE' --header 'X-Registry-Auth: AUTH_TOKEN'` **Describe the results you received:** Received status code 200 OK  * Trying /var/run/docker.sock:0 * Connected to d (/run/user/podman/podman.sock) port 80 (#0) > POST /images/create?fromImage=NON_EXISTING_IMAGE HTTP/1.1 > Host: d > User-Agent: curl/7.83.1 > Accept: */* > X-Registry-Auth: AUTH_TOKEN > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.40 < Libpod-Api-Version: 4.1.0 < Server: Libpod/4.1.0 (linux) < X-Reference-Id: 0xc000010008 < Date: Wed, 14 Sep 2022 08:53:00 GMT < Transfer-Encoding: chunked < {""progressDetail"":{},""error"":""initializing source NON_EXISTING_IMAGE: reading manifest latest in IMAGE: manifest unknown: manifest unknown""} * Connection #0 to host d left intact  **Describe the results you expected:** Expected status code 404 NOT FOUND  * Trying /var/run/docker.sock:0 * Connected to d (/run/user/podman/podman.sock) port 80 (#0) > POST /images/create?fromImage=NON_EXISTING_IMAGE HTTP/1.1 > Host: d > User-Agent: curl/7.83.1 > Accept: */* > X-Registry-Auth: AUTH_TOKEN > * Mark bundle as not supporting multiuse < HTTP/1.1 404 Not Found < Api-Version: 1.40 < Libpod-Api-Version: 4.1.0 < Server: Libpod/4.1.0 (linux) < X-Reference-Id: 0xc000010008 < Date: Wed, 14 Sep 2022 08:53:00 GMT < Transfer-Encoding: chunked < {""progressDetail"":{},""error"":""initializing source NON_EXISTING_IMAGE: reading manifest latest in IMAGE: manifest unknown: manifest unknown""} * Connection #0 to host d left intact  **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Client: Podman Engine Version: 4.1.0 API Version: 4.1.0 Go Version: go1.18.5 Git Commit: c5de69cd3da571c8ebf1c03aa49d07c1e35da67c Built: Tue Aug 2 10:39:40 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  host: arch: amd64 buildahVersion: 1.26.1 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - hugetlb - pids - rdma cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.2-r0 path: /usr/bin/conmon version: 'conmon version 2.1.2, commit: f25214cda836296fe8695c2e582ca79d2246053a' cpuUtilization: idlePercent: 86.72 systemPercent: 4.6 userPercent: 8.68 cpus: 6 distribution: distribution: alpine version: 3.16.2 eventLogger: file hostname: image-builder-0 idMappings: gidmap: null uidmap: null kernel: 5.4.0-121-generic linkmode: dynamic logDriver: k8s-file memFree: 6932779008 memTotal: 50502590464 networkBackend: netavark ociRuntime: name: crun package: crun-1.4.5-r0 path: /usr/bin/crun version: |- crun version 1.4.5 commit: c381048530aa750495cf502ddb7181f2ded5b400 spec: 1.0.0 +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-r0 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.2 swapFree: 0 swapTotal: 0 uptime: 1762h 3m 18.39s (Approximately 73.42 days) plugins: log: - k8s-file - none - passthrough network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev graphRoot: /var/lib/containers/storage graphRootAllocated: 20507869184 graphRootUsed: 46239744 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.1.0 Built: 1659436780 BuiltTime: Tue Aug 2 10:39:40 2022 GitCommit: c5de69cd3da571c8ebf1c03aa49d07c1e35da67c GoVersion: go1.18.5 Os: linux OsArch: linux/amd64 Version: 4.1.0  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman-4.1.0-r3 x86_64 {podman} (Apache-2.0) [installed] podman-4.1.0-r4 x86_64 {podman} (Apache-2.0) [upgradable from: podman-4.1.0-r3]  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):** Running on K8S"
14498,podman,https://github.com/containers/podman/issues/14498,container state improper 409 - via stats endpoint for container in created state,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** - Its not possible to attach to stats API endpoint via `/container/{id}/stats` if the container is created via `/containers/create` endpoint and is in created/initialized state. Same applies for CLI (`podman stats {id}`). - Its working for Docker 20.10.13 <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. `containerid=$(curl -s --unix-socket /run/podman/podman.sock -X POST -H ""Content-Type: application/json"" -d @payload.json ""http://d/containers/create"" | jq -r .Id)` 2. `curl -s --unix-socket /run/podman/podman.sock -X GET http://d/containers/$containerid/stats` **Describe the results you received:** Response from step2 `{""cause"":""container state improper"",""message"":""container state improper"",""response"":409}` **Describe the results you expected:** Empty stats are streamed   {""read"":""0001-01-01T00:00:00Z"",""preread"":""0001-01-01T00:00:00Z"",""pids_stats"":{},""blkio_stats"":{""io_service_bytes_recursive"":null,""io_serviced_recursive"":null,""io_queue_recursive"":null,""io_service_time_recursive"":null,""io_wait_time_recursive"":null,""io_merged_recursive"":null,""io_time_recursive"":null,""sectors_recursive"":null},""num_procs"":0,""storage_stats"":{},""cpu_stats"":{""cpu_usage"":{""total_usage"":0,""usage_in_kernelmode"":0,""usage_in_usermode"":0},""throttling_data"":{""periods"":0,""throttled_periods"":0,""throttled_time"":0}},""precpu_stats"":{""cpu_usage"":{""total_usage"":0,""usage_in_kernelmode"":0,""usage_in_usermode"":0},""throttling_data"":{""periods"":0,""throttled_periods"":0,""throttled_time"":0}},""memory_stats"":{},""name"":""/pensive_sanderson"",""id"":""3fb3108ac3ed8e0d41062889e6f442bc79b03b73d78f6a93d0a469324acbdabf""} {""read"":""0001-01-01T00:00:00Z"",""preread"":""0001-01-01T00:00:00Z"",""pids_stats"":{},""blkio_stats"":{""io_service_bytes_recursive"":null,""io_serviced_recursive"":null,""io_queue_recursive"":null,""io_service_time_recursive"":null,""io_wait_time_recursive"":null,""io_merged_recursive"":null,""io_time_recursive"":null,""sectors_recursive"":null},""num_procs"":0,""storage_stats"":{},""cpu_stats"":{""cpu_usage"":{""total_usage"":0,""usage_in_kernelmode"":0,""usage_in_usermode"":0},""throttling_data"":{""periods"":0,""throttled_periods"":0,""throttled_time"":0}},""precpu_stats"":{""cpu_usage"":{""total_usage"":0,""usage_in_kernelmode"":0,""usage_in_usermode"":0},""throttling_data"":{""periods"":0,""throttled_periods"":0,""throttled_time"":0}},""memory_stats"":{},""name"":""/pensive_sanderson"",""id"":""3fb3108ac3ed8e0d41062889e6f442bc79b03b73d78f6a93d0a469324acbdabf""}   **Additional information you deem important (e.g. issue happens only occasionally):** - Podman CLI returns:  podman stats $containerid Error: entities.ContainerStatsReport.Error: decode non empty interface: can not unmarshal into nil, error found in #9 byte of |{""Error"":{},""Stats""|, bigger context |{""Error"":{},""Stats"":null}  **Output of `podman version`:**  Client: Podman Engine Version: 4.0.2 API Version: 4.0.2 Go Version: go1.18beta2 Built: Thu Mar 3 14:56:09 2022 OS/Arch: linux/amd64  **Output of `podman info --debug`:**  (paste your output here)host: arch: amd64 buildahVersion: 1.24.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-2.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: ' cpus: 8 distribution: distribution: fedora variant: coreos version: ""36"" eventLogger: journald hostname: ip-10-2-17-77 idMappings: gidmap: null uidmap: null kernel: 5.17.5-300.fc36.x86_64 linkmode: dynamic logDriver: journald memFree: 13253181440 memTotal: 32935444480 networkBackend: netavark ociRuntime: name: crun package: crun-1.4.4-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.4.4 commit: 6521fcc5806f20f6187eb933f9f45130c86da230 spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 96h 0m 0.13s (Approximately 4.00 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 12 paused: 0 running: 3 stopped: 9 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 26 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.0.2 Built: 1646319369 BuiltTime: Thu Mar 3 14:56:09 2022 GitCommit: """" GoVersion: go1.18beta2 OsArch: linux/amd64 Version: 4.0.2  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman-4.0.2-1.fc36.x86_64  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** No **Additional environment details (AWS, VirtualBox, physical, etc.):** - AWS - Fedora CoreOS 36.20220505.3.2",source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | test-file | test-file,container state improper via stats endpoint container created state bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description possible attach stats api endpoint via container stats container created via containers create endpoint created initialized state applies cli stats working docker briefly describe paragraphs steps reproduce containerid curl unix socket sock post content type application json payload json http containers create curl unix socket sock get http containers containerid stats describe results received response step cause container state improper message container state improper response describe results expected empty stats streamed read preread pids stats blkio stats service bytes recursive null serviced recursive null queue recursive null service time recursive null wait time recursive null merged recursive null time recursive null sectors recursive null num procs storage stats cpu stats cpu usage total usage usage kernelmode usage usermode throttling data periods throttled periods throttled time precpu stats cpu usage total usage usage kernelmode usage usermode throttling data periods throttled periods throttled time memory stats name pensive sanderson acbdabf read preread pids stats blkio stats service bytes recursive null serviced recursive null queue recursive null service time recursive null wait time recursive null merged recursive null time recursive null sectors recursive null num procs storage stats cpu stats cpu usage total usage usage kernelmode usage usermode throttling data periods throttled periods throttled time precpu stats cpu usage total usage usage kernelmode usage usermode throttling data periods throttled periods throttled time memory stats name pensive sanderson acbdabf additional information deem important happens occasionally cli returns stats containerid entities containerstatsreport decode non empty interface unmarshal nil found byte stats bigger context stats null output client engine api beta built mar arch linux amd output paste output host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids misc cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpus distribution distribution fedora variant coreos eventlogger journald hostname idmappings gidmap null uidmap null kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun fcc spec systemd selinux apparmor cap seccomp ebpf criu yajl linux remotesocket exists true path sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns beta slirp netns beta dda libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins log none passthrough journald network bridge macvlan volume local registries search docker store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphstatus backing filesystem xfs native overlay diff false supports type true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage volumepath var containers storage volumes apiversion built builttime mar gitcommit goversion beta osarch linux amd package output rpm apt list tested latest checked troubleshooting guide https github containers blob troubleshooting additional environment details aws virtualbox physical etc aws fedora coreos,bug,0.95,"container state improper 409 - via stats endpoint for container in created state <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** - Its not possible to attach to stats API endpoint via `/container/{id}/stats` if the container is created via `/containers/create` endpoint and is in created/initialized state. Same applies for CLI (`podman stats {id}`). - Its working for Docker 20.10.13 <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. `containerid=$(curl -s --unix-socket /run/podman/podman.sock -X POST -H ""Content-Type: application/json"" -d @payload.json ""http://d/containers/create"" | jq -r .Id)` 2. `curl -s --unix-socket /run/podman/podman.sock -X GET http://d/containers/$containerid/stats` **Describe the results you received:** Response from step2 `{""cause"":""container state improper"",""message"":""container state improper"",""response"":409}` **Describe the results you expected:** Empty stats are streamed   {""read"":""0001-01-01T00:00:00Z"",""preread"":""0001-01-01T00:00:00Z"",""pids_stats"":{},""blkio_stats"":{""io_service_bytes_recursive"":null,""io_serviced_recursive"":null,""io_queue_recursive"":null,""io_service_time_recursive"":null,""io_wait_time_recursive"":null,""io_merged_recursive"":null,""io_time_recursive"":null,""sectors_recursive"":null},""num_procs"":0,""storage_stats"":{},""cpu_stats"":{""cpu_usage"":{""total_usage"":0,""usage_in_kernelmode"":0,""usage_in_usermode"":0},""throttling_data"":{""periods"":0,""throttled_periods"":0,""throttled_time"":0}},""precpu_stats"":{""cpu_usage"":{""total_usage"":0,""usage_in_kernelmode"":0,""usage_in_usermode"":0},""throttling_data"":{""periods"":0,""throttled_periods"":0,""throttled_time"":0}},""memory_stats"":{},""name"":""/pensive_sanderson"",""id"":""3fb3108ac3ed8e0d41062889e6f442bc79b03b73d78f6a93d0a469324acbdabf""} {""read"":""0001-01-01T00:00:00Z"",""preread"":""0001-01-01T00:00:00Z"",""pids_stats"":{},""blkio_stats"":{""io_service_bytes_recursive"":null,""io_serviced_recursive"":null,""io_queue_recursive"":null,""io_service_time_recursive"":null,""io_wait_time_recursive"":null,""io_merged_recursive"":null,""io_time_recursive"":null,""sectors_recursive"":null},""num_procs"":0,""storage_stats"":{},""cpu_stats"":{""cpu_usage"":{""total_usage"":0,""usage_in_kernelmode"":0,""usage_in_usermode"":0},""throttling_data"":{""periods"":0,""throttled_periods"":0,""throttled_time"":0}},""precpu_stats"":{""cpu_usage"":{""total_usage"":0,""usage_in_kernelmode"":0,""usage_in_usermode"":0},""throttling_data"":{""periods"":0,""throttled_periods"":0,""throttled_time"":0}},""memory_stats"":{},""name"":""/pensive_sanderson"",""id"":""3fb3108ac3ed8e0d41062889e6f442bc79b03b73d78f6a93d0a469324acbdabf""}   **Additional information you deem important (e.g. issue happens only occasionally):** - Podman CLI returns:  podman stats $containerid Error: entities.ContainerStatsReport.Error: decode non empty interface: can not unmarshal into nil, error found in #9 byte of |{""Error"":{},""Stats""|, bigger context |{""Error"":{},""Stats"":null}  **Output of `podman version`:**  Client: Podman Engine Version: 4.0.2 API Version: 4.0.2 Go Version: go1.18beta2 Built: Thu Mar 3 14:56:09 2022 OS/Arch: linux/amd64  **Output of `podman info --debug`:**  (paste your output here)host: arch: amd64 buildahVersion: 1.24.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-2.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: ' cpus: 8 distribution: distribution: fedora variant: coreos version: ""36"" eventLogger: journald hostname: ip-10-2-17-77 idMappings: gidmap: null uidmap: null kernel: 5.17.5-300.fc36.x86_64 linkmode: dynamic logDriver: journald memFree: 13253181440 memTotal: 32935444480 networkBackend: netavark ociRuntime: name: crun package: crun-1.4.4-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.4.4 commit: 6521fcc5806f20f6187eb933f9f45130c86da230 spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 96h 0m 0.13s (Approximately 4.00 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 12 paused: 0 running: 3 stopped: 9 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 26 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.0.2 Built: 1646319369 BuiltTime: Thu Mar 3 14:56:09 2022 GitCommit: """" GoVersion: go1.18beta2 OsArch: linux/amd64 Version: 4.0.2  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman-4.0.2-1.fc36.x86_64  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** No **Additional environment details (AWS, VirtualBox, physical, etc.):** - AWS - Fedora CoreOS 36.20220505.3.2"
15430,podman,https://github.com/containers/podman/issues/15430,podman system service uses different syntax to podman-remote for tcp connections,"/kind bug **Description** `podman system service` uses an inconsistent syntax for specifying the listen port compared to `podman --remote --connection` and does not error about it properly. **Steps to reproduce the issue:** 1. Try starting a podman system service on a tcp port with the syntax one would expect from the `--connection` syntax: `podman system service tcp://localhost:2375` **Describe the results you received:** The command appears to succeed, but no listening port on `2375` or any other is created. **Describe the results you expected:** The command should either error, explaining that the syntax is invalid, or better, actually work since the same pseudo-path like syntax is supported for remote connections. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Version: 3.4.4 API Version: 3.4.4 Go Version: go1.17.3 Built: Thu Jan 1 10:00:00 1970 OS/Arch: linux/amd64  **Output of `podman info`:**  host: arch: amd64 buildahVersion: 1.23.1 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: 'conmon: /usr/bin/conmon' path: /usr/bin/conmon version: 'conmon version 2.0.25, commit: unknown' cpus: 16 distribution: codename: jammy distribution: ubuntu version: ""22.04"" eventLogger: file hostname: will-desktop idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.15.0-27-generic linkmode: dynamic logDriver: k8s-file memFree: 34020188160 memTotal: 67362914304 ociRuntime: name: runc package: 'runc: /usr/sbin/runc' path: /usr/sbin/runc version: |- runc version 1.1.0-0ubuntu1 spec: 1.0.2-dev go: go1.17.3 libseccomp: 2.5.3 os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: 'slirp4netns: /usr/bin/slirp4netns' version: |- slirp4netns version 1.0.1 commit: 6a7b16babc95b6a3056b33fb45b74a6f62262dd4 libslirp: 4.6.1 swapFree: 524283904 swapTotal: 524283904 uptime: 69h 14m 23.56s (Approximately 2.88 days) plugins: log: - k8s-file - none - journald network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /home/will/.config/containers/storage.conf containerStore: number: 43 paused: 0 running: 2 stopped: 41 graphDriverName: overlay graphOptions: overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: 'fuse-overlayfs: /usr/bin/fuse-overlayfs' Version: |- fusermount3 version: 3.10.5 fuse-overlayfs: version 1.7.1 FUSE library version 3.10.5 using FUSE kernel interface version 7.31 graphRoot: /home/will/.local/share/containers/storage graphStatus: Backing Filesystem: zfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageStore: number: 524 runRoot: /run/user/1000/containers volumePath: /home/will/.local/share/containers/storage/volumes version: APIVersion: 3.4.4 Built: 0 BuiltTime: Thu Jan 1 10:00:00 1970 GitCommit: """" GoVersion: go1.17.3 OsArch: linux/amd64 Version: 3.4.4  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman/jammy,now 3.4.4+ds1-1ubuntu1 amd64 [installed]  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes. The command exits, but still displays no error message or explanation as to why. **Additional environment details (AWS, VirtualBox, physical, etc.):** Physical",documentation-file | test-file | test-file | test-file | test-file,system service uses different syntax remote tcp connections kind bug description system service uses inconsistent syntax specifying listen port compared remote connection properly steps reproduce starting system service tcp port syntax one would expect connection syntax system service tcp localhost describe results received command appears succeed listening port created describe results expected command either explaining syntax invalid better actually work since pseudo path like syntax supported remote connections additional information deem important happens occasionally output api built jan arch linux amd output host arch amd buildahversion cgroupcontrollers memory pids cgroupmanager systemd cgroupversion conmon package conmon conmon path conmon conmon unknown cpus distribution codename jammy distribution ubuntu eventlogger hostname desktop idmappings gidmap container host size container host size uidmap container host size container host size kernel generic linkmode dynamic logdriver memfree memtotal ociruntime name runc package runc sbin runc path sbin runc runc ubuntu spec libseccomp linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns slirp netns babc libslirp swapfree swaptotal uptime approximately days plugins log none journald network bridge macvlan volume local registries search docker store configfile home config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mount program executable fuse overlayfs package fuse overlayfs fuse overlayfs fusermount fuse overlayfs fuse library fuse kernel interface graphroot home local share containers storage graphstatus backing filesystem zfs native overlay diff false supports type true metacopy false imagestore number runroot user containers volumepath home local share containers storage volumes apiversion built builttime jan gitcommit goversion osarch linux amd package output rpm apt list jammy ubuntu amd installed tested latest checked troubleshooting guide https github containers blob troubleshooting yes command exits still displays message explanation additional environment details aws virtualbox physical etc physical,bug,0.9,"podman system service uses different syntax to podman-remote for tcp connections /kind bug **Description** `podman system service` uses an inconsistent syntax for specifying the listen port compared to `podman --remote --connection` and does not error about it properly. **Steps to reproduce the issue:** 1. Try starting a podman system service on a tcp port with the syntax one would expect from the `--connection` syntax: `podman system service tcp://localhost:2375` **Describe the results you received:** The command appears to succeed, but no listening port on `2375` or any other is created. **Describe the results you expected:** The command should either error, explaining that the syntax is invalid, or better, actually work since the same pseudo-path like syntax is supported for remote connections. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Version: 3.4.4 API Version: 3.4.4 Go Version: go1.17.3 Built: Thu Jan 1 10:00:00 1970 OS/Arch: linux/amd64  **Output of `podman info`:**  host: arch: amd64 buildahVersion: 1.23.1 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: 'conmon: /usr/bin/conmon' path: /usr/bin/conmon version: 'conmon version 2.0.25, commit: unknown' cpus: 16 distribution: codename: jammy distribution: ubuntu version: ""22.04"" eventLogger: file hostname: will-desktop idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.15.0-27-generic linkmode: dynamic logDriver: k8s-file memFree: 34020188160 memTotal: 67362914304 ociRuntime: name: runc package: 'runc: /usr/sbin/runc' path: /usr/sbin/runc version: |- runc version 1.1.0-0ubuntu1 spec: 1.0.2-dev go: go1.17.3 libseccomp: 2.5.3 os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: 'slirp4netns: /usr/bin/slirp4netns' version: |- slirp4netns version 1.0.1 commit: 6a7b16babc95b6a3056b33fb45b74a6f62262dd4 libslirp: 4.6.1 swapFree: 524283904 swapTotal: 524283904 uptime: 69h 14m 23.56s (Approximately 2.88 days) plugins: log: - k8s-file - none - journald network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /home/will/.config/containers/storage.conf containerStore: number: 43 paused: 0 running: 2 stopped: 41 graphDriverName: overlay graphOptions: overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: 'fuse-overlayfs: /usr/bin/fuse-overlayfs' Version: |- fusermount3 version: 3.10.5 fuse-overlayfs: version 1.7.1 FUSE library version 3.10.5 using FUSE kernel interface version 7.31 graphRoot: /home/will/.local/share/containers/storage graphStatus: Backing Filesystem: zfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageStore: number: 524 runRoot: /run/user/1000/containers volumePath: /home/will/.local/share/containers/storage/volumes version: APIVersion: 3.4.4 Built: 0 BuiltTime: Thu Jan 1 10:00:00 1970 GitCommit: """" GoVersion: go1.17.3 OsArch: linux/amd64 Version: 3.4.4  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman/jammy,now 3.4.4+ds1-1ubuntu1 amd64 [installed]  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes. The command exits, but still displays no error message or explanation as to why. **Additional environment details (AWS, VirtualBox, physical, etc.):** Physical"
24910,podman,https://github.com/containers/podman/issues/24910,Container inspect endpoint is not Docker-API compatible," Issue Description I am currently playing with `podman compose` utilizing the upstream `docker-compose` as backend. It always recreates the container because the network config is not as it should be. I added some debug prints to the `docker-compose` code and it cannot match the networks because the `NetworkID` returned by podman is wrong. Running something along the lines of `podman inspect 4cb3ce78cde3 --format=""{{ json .NetworkSettings.Networks }}""|jq` returns: json { ""tmp_default"": { ""EndpointID"": """", ""Gateway"": ""10.89.0.1"", ""IPAddress"": ""10.89.0.3"", ""IPPrefixLen"": 24, ""IPv6Gateway"": """", ""GlobalIPv6Address"": """", ""GlobalIPv6PrefixLen"": 0, ""MacAddress"": ""c2:79:d5:75:e5:09"", ""NetworkID"": ""tmp_default"", ""DriverOpts"": null, ""IPAMConfig"": null, ""Links"": null, ""Aliases"": [ ""tmp-traefik-1"", ""traefik"", ""4cb3ce78cde3"" ] } }  Here we can see that `NetworkID` is the network name and not the id of the network (`podman network inspect tmp_default`): json [ { ""name"": ""tmp_default"", ""id"": ""675bea81a6d49e9f1ae909c58a2269524a9a9c910f91bce12a85b05b882ab5cb"", ""driver"": ""bridge"", ""network_interface"": ""podman1"", ""created"": ""2024-12-28T20:54:28.320995381+01:00"", ""subnets"": [ { ""subnet"": ""10.89.0.0/24"", ""gateway"": ""10.89.0.1"" } ], ""ipv6_enabled"": false, ""internal"": false, ""dns_enabled"": true, ""labels"": { ""com.docker.compose.config-hash"": ""4bd7e5f2ecc11ab238c4eb5931f77d1e2196619bcc8daeeb80428562a7210c37"", ""com.docker.compose.network"": ""default"", ""com.docker.compose.project"": ""tmp"", ""com.docker.compose.version"": ""2.32.1"" }, ""options"": { ""isolate"": ""true"" }, ""ipam_options"": { ""driver"": ""host-local"" }, ""containers"": { ""4cb3ce78cde33f763bdd6abe5b19a5d93f5bb30043c94fa489114a48da5d4290"": { ""name"": ""tmp-traefik-1"", ""interfaces"": { ""eth0"": { ""subnets"": [ { ""ipnet"": ""10.89.0.3/24"", ""gateway"": ""10.89.0.1"" } ], ""mac_address"": ""c2:79:d5:75:e5:09"" } } } } } ]   Steps to reproduce the issue Steps to reproduce the issue 1. `podman run --rm -it --name testing ubuntu:latest sleep infinity` 2. `podman inspect testing --format=""{{ json .NetworkSettings.Networks.podman }}""|jq` 3. Observe that the `NetworkID` is the network name  Describe the results you received I would have expected the actual `NetworkID` to be shown  Describe the results you expected The network name is shown as ID  podman info output yaml host: arch: amd64 buildahVersion: 1.38.0 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.12-3.fc41.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.12, commit: ' cpuUtilization: idlePercent: 97.27 systemPercent: 0.8 userPercent: 1.93 cpus: 16 databaseBackend: sqlite distribution: distribution: fedora variant: workstation version: ""41"" eventLogger: journald freeLocks: 2046 hostname: apollo13 idMappings: gidmap: null uidmap: null kernel: 6.12.4-200.fc41.x86_64 linkmode: dynamic logDriver: journald memFree: 6023499776 memTotal: 32395685888 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.13.1-1.fc41.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.13.1 package: netavark-1.13.1-1.fc41.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.13.1 ociRuntime: name: crun package: crun-1.19.1-1.fc41.x86_64 path: /usr/bin/crun version: |- crun version 1.19.1 commit: 3e32a70c93f5aa5fea69b50256cca7fd4aa23c80 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20241211.g09478d5-1.fc41.x86_64 version: | pasta 0^20241211.g09478d5-1.fc41.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.3.1-1.fc41.x86_64 version: |- slirp4netns version 1.3.1 commit: e5e368c4f5db6ae75c2fce786e31eef9da6bf236 libslirp: 4.8.0 SLIRP_CONFIG_VERSION_MAX: 5 libseccomp: 2.5.5 swapFree: 8589930496 swapTotal: 8589930496 uptime: 11h 16m 31.00s (Approximately 0.46 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 2 paused: 0 running: 2 stopped: 0 graphDriverName: overlay graphOptions: overlay.imagestore: /usr/lib/containers/storage overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 536854134784 graphRootUsed: 403665657856 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 5 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.3.1 Built: 1732147200 BuiltTime: Thu Nov 21 01:00:00 2024 GitCommit: """" GoVersion: go1.23.3 Os: linux OsArch: linux/amd64 Version: 5.3.1   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details _No response_  Additional information _No response_",source-file | source-file | config-file | source-file | test-file | test-file | config-file | source-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | config-file | source-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file | test-file,container inspect endpoint docker api compatible description currently playing compose utilizing upstream docker compose backend always recreates container network config added prints docker compose cannot match networks networkid returned wrong running something along lines inspect cde format json networksettings networks returns json tmp default endpointid gateway ipaddress ipprefixlen ipv gateway globalipv address globalipv prefixlen macaddress networkid tmp default driveropts null ipamconfig null links null aliases tmp cde see networkid network name network network inspect tmp default json name tmp default bea bce driver bridge network interface created subnets subnet gateway ipv enabled false internal false dns enabled true labels docker compose config hash ecc bcc daeeb docker compose network default docker compose project tmp docker compose options isolate true ipam options driver host local containers cde bdd abe name tmp interfaces eth subnets ipnet gateway mac address steps reproduce steps reproduce name testing ubuntu latest sleep infinity inspect testing format json networksettings networks observe networkid network name describe results received would expected actual networkid shown describe results expected network name shown output yaml host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids rdma misc cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution fedora variant workstation eventlogger journald freelocks hostname apollo idmappings gidmap null uidmap null kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns path libexec aardvark dns aardvark dns package netavark path libexec netavark netavark ociruntime name crun package crun path crun crun fea cca rundir crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path sock rootlessnetworkcmd pasta security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns fce eef libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat docker store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay imagestore containers storage overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem btrfs native overlay diff false supports type true supports shifting true supports volatile true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime nov gitcommit goversion linux osarch linux amd container privileged rootless privileged upstream latest additional environment details response additional information response,bug,0.9,"Container inspect endpoint is not Docker-API compatible  Issue Description I am currently playing with `podman compose` utilizing the upstream `docker-compose` as backend. It always recreates the container because the network config is not as it should be. I added some debug prints to the `docker-compose` code and it cannot match the networks because the `NetworkID` returned by podman is wrong. Running something along the lines of `podman inspect 4cb3ce78cde3 --format=""{{ json .NetworkSettings.Networks }}""|jq` returns: json { ""tmp_default"": { ""EndpointID"": """", ""Gateway"": ""10.89.0.1"", ""IPAddress"": ""10.89.0.3"", ""IPPrefixLen"": 24, ""IPv6Gateway"": """", ""GlobalIPv6Address"": """", ""GlobalIPv6PrefixLen"": 0, ""MacAddress"": ""c2:79:d5:75:e5:09"", ""NetworkID"": ""tmp_default"", ""DriverOpts"": null, ""IPAMConfig"": null, ""Links"": null, ""Aliases"": [ ""tmp-traefik-1"", ""traefik"", ""4cb3ce78cde3"" ] } }  Here we can see that `NetworkID` is the network name and not the id of the network (`podman network inspect tmp_default`): json [ { ""name"": ""tmp_default"", ""id"": ""675bea81a6d49e9f1ae909c58a2269524a9a9c910f91bce12a85b05b882ab5cb"", ""driver"": ""bridge"", ""network_interface"": ""podman1"", ""created"": ""2024-12-28T20:54:28.320995381+01:00"", ""subnets"": [ { ""subnet"": ""10.89.0.0/24"", ""gateway"": ""10.89.0.1"" } ], ""ipv6_enabled"": false, ""internal"": false, ""dns_enabled"": true, ""labels"": { ""com.docker.compose.config-hash"": ""4bd7e5f2ecc11ab238c4eb5931f77d1e2196619bcc8daeeb80428562a7210c37"", ""com.docker.compose.network"": ""default"", ""com.docker.compose.project"": ""tmp"", ""com.docker.compose.version"": ""2.32.1"" }, ""options"": { ""isolate"": ""true"" }, ""ipam_options"": { ""driver"": ""host-local"" }, ""containers"": { ""4cb3ce78cde33f763bdd6abe5b19a5d93f5bb30043c94fa489114a48da5d4290"": { ""name"": ""tmp-traefik-1"", ""interfaces"": { ""eth0"": { ""subnets"": [ { ""ipnet"": ""10.89.0.3/24"", ""gateway"": ""10.89.0.1"" } ], ""mac_address"": ""c2:79:d5:75:e5:09"" } } } } } ]   Steps to reproduce the issue Steps to reproduce the issue 1. `podman run --rm -it --name testing ubuntu:latest sleep infinity` 2. `podman inspect testing --format=""{{ json .NetworkSettings.Networks.podman }}""|jq` 3. Observe that the `NetworkID` is the network name  Describe the results you received I would have expected the actual `NetworkID` to be shown  Describe the results you expected The network name is shown as ID  podman info output yaml host: arch: amd64 buildahVersion: 1.38.0 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.12-3.fc41.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.12, commit: ' cpuUtilization: idlePercent: 97.27 systemPercent: 0.8 userPercent: 1.93 cpus: 16 databaseBackend: sqlite distribution: distribution: fedora variant: workstation version: ""41"" eventLogger: journald freeLocks: 2046 hostname: apollo13 idMappings: gidmap: null uidmap: null kernel: 6.12.4-200.fc41.x86_64 linkmode: dynamic logDriver: journald memFree: 6023499776 memTotal: 32395685888 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.13.1-1.fc41.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.13.1 package: netavark-1.13.1-1.fc41.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.13.1 ociRuntime: name: crun package: crun-1.19.1-1.fc41.x86_64 path: /usr/bin/crun version: |- crun version 1.19.1 commit: 3e32a70c93f5aa5fea69b50256cca7fd4aa23c80 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20241211.g09478d5-1.fc41.x86_64 version: | pasta 0^20241211.g09478d5-1.fc41.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.3.1-1.fc41.x86_64 version: |- slirp4netns version 1.3.1 commit: e5e368c4f5db6ae75c2fce786e31eef9da6bf236 libslirp: 4.8.0 SLIRP_CONFIG_VERSION_MAX: 5 libseccomp: 2.5.5 swapFree: 8589930496 swapTotal: 8589930496 uptime: 11h 16m 31.00s (Approximately 0.46 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 2 paused: 0 running: 2 stopped: 0 graphDriverName: overlay graphOptions: overlay.imagestore: /usr/lib/containers/storage overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 536854134784 graphRootUsed: 403665657856 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 5 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.3.1 Built: 1732147200 BuiltTime: Thu Nov 21 01:00:00 2024 GitCommit: """" GoVersion: go1.23.3 Os: linux OsArch: linux/amd64 Version: 5.3.1   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details _No response_  Additional information _No response_"
22616,podman,https://github.com/containers/podman/issues/22616,podman-remote volume rm ambiguous-name: unmarshalling error,"console $ bin/podman-remote volume create myvol1 myvol1 $ bin/podman-remote volume create myvol2 myvol2 $ bin/podman-remote volume rm myv Error: unmarshalling error into &errorhandling.ErrorModel{Because:"""", Message:"""", ResponseCode:0}, data ""{\""cause\"":\""volume already exists\"",\""message\"":\""more than one result for volume name myv: volume already exists\"",\""response\"":500}\n{\""cause\"":\""volume already exists\"",\""message\"":\""more than one result for volume name myv: volume already exists\"",\""response\"":404}\n"": invalid character '{' after top-level value ",source-file | test-file,remote volume ambiguous name unmarshalling console remote volume create myvol myvol remote volume create myvol myvol remote volume myv unmarshalling errorhandling errormodel message responsecode data cause volume already exists message one result volume name myv volume already exists response cause volume already exists message one result volume name myv volume already exists response invalid character top level value,bug,0.9,"podman-remote volume rm ambiguous-name: unmarshalling error console $ bin/podman-remote volume create myvol1 myvol1 $ bin/podman-remote volume create myvol2 myvol2 $ bin/podman-remote volume rm myv Error: unmarshalling error into &errorhandling.ErrorModel{Because:"""", Message:"""", ResponseCode:0}, data ""{\""cause\"":\""volume already exists\"",\""message\"":\""more than one result for volume name myv: volume already exists\"",\""response\"":500}\n{\""cause\"":\""volume already exists\"",\""message\"":\""more than one result for volume name myv: volume already exists\"",\""response\"":404}\n"": invalid character '{' after top-level value "
13824,podman,https://github.com/containers/podman/issues/13824,podman stats as root broken,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. Install podman on Arch Linux (4.0.3), Centos 8 Stream (4.0.2) or use Fedora Coreos (4.0.2) 2. log in as root 3. `podman stats` **Describe the results you received:** It just prints `Error: Link not found` **Describe the results you expected:** not that **Additional information you deem important (e.g. issue happens only occasionally):** `podman stats` seems to work when run as non-root, tested on Arch Linux, but I get the same error there when run as root. Using the socket API: `curl --unix-socket /run/podman/podman.sock 'http://d/v4.0.0/libpod/containers/stats'` {""Error"":{},""Stats"":null} **Output of `podman version`:** 4.0.3 and 4.0.2 ** podman info -D ** From coreos:  host: arch: amd64 buildahVersion: 1.24.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-2.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: ' cpus: 4 distribution: distribution: fedora variant: coreos version: ""36"" eventLogger: journald hostname: dro-1 idMappings: gidmap: null uidmap: null kernel: 5.17.0-300.fc36.x86_64 linkmode: dynamic logDriver: journald memFree: 14985670656 memTotal: 16773632000 networkBackend: netavark ociRuntime: name: crun package: crun-1.4.3-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.4.3 commit: 61c9600d1335127eba65632731e2d72bc3f0b9e8 spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 40h 43m 52.05s (Approximately 1.67 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 11 paused: 0 running: 11 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 8 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.0.2 Built: 1646319369 BuiltTime: Thu Mar 3 14:56:09 2022 GitCommit: """" GoVersion: go1.18beta2 OsArch: linux/amd64 Version: 4.0.2 ",source-file | test-file | source-file | test-file,stats root broken bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description briefly describe paragraphs steps reproduce install arch linux centos stream use fedora coreos log root stats describe results received prints link found describe results expected additional information deem important happens occasionally stats seems work non root tested arch linux get root socket api curl unix socket sock http libpod containers stats stats null output coreos host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids misc cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpus distribution distribution fedora variant coreos eventlogger journald hostname dro idmappings gidmap null uidmap null kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun eba spec systemd selinux apparmor cap seccomp ebpf criu yajl linux remotesocket exists true path sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns beta slirp netns beta dda libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins log none passthrough journald network bridge macvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphstatus backing filesystem xfs native overlay diff false supports type true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage volumepath var containers storage volumes apiversion built builttime mar gitcommit goversion beta osarch linux amd,bug,0.9,"podman stats as root broken <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. Install podman on Arch Linux (4.0.3), Centos 8 Stream (4.0.2) or use Fedora Coreos (4.0.2) 2. log in as root 3. `podman stats` **Describe the results you received:** It just prints `Error: Link not found` **Describe the results you expected:** not that **Additional information you deem important (e.g. issue happens only occasionally):** `podman stats` seems to work when run as non-root, tested on Arch Linux, but I get the same error there when run as root. Using the socket API: `curl --unix-socket /run/podman/podman.sock 'http://d/v4.0.0/libpod/containers/stats'` {""Error"":{},""Stats"":null} **Output of `podman version`:** 4.0.3 and 4.0.2 ** podman info -D ** From coreos:  host: arch: amd64 buildahVersion: 1.24.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-2.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: ' cpus: 4 distribution: distribution: fedora variant: coreos version: ""36"" eventLogger: journald hostname: dro-1 idMappings: gidmap: null uidmap: null kernel: 5.17.0-300.fc36.x86_64 linkmode: dynamic logDriver: journald memFree: 14985670656 memTotal: 16773632000 networkBackend: netavark ociRuntime: name: crun package: crun-1.4.3-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.4.3 commit: 61c9600d1335127eba65632731e2d72bc3f0b9e8 spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 40h 43m 52.05s (Approximately 1.67 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 11 paused: 0 running: 11 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 8 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.0.2 Built: 1646319369 BuiltTime: Thu Mar 3 14:56:09 2022 GitCommit: """" GoVersion: go1.18beta2 OsArch: linux/amd64 Version: 4.0.2 "
17204,podman,https://github.com/containers/podman/issues/17204,APIv2 tests: python something != something-podman,"Seeing this occasionally since Dec 30:  ________________________ ContainerTestCase.test_attach _________________________ self = <python.rest_api.test_v2_0_0_container.ContainerTestCase testMethod=test_attach> def test_attach(self): r = requests.post( self.podman_url + ""/v1.40/containers/create?name=topcontainer"", json={""Cmd"": [""sh"", ""-c"", ""echo podman; sleep 100""], ""Image"": ""alpine:latest""}, ) self.assertEqual(r.status_code, 201, r.text) payload = r.json() r = requests.post( self.podman_url + f""/v1.40/containers/{payload['Id']}/start"" ) self.assertEqual(r.status_code, 204, r.text) r = requests.post( self.podman_url + f""/v1.40/containers/{payload['Id']}/attach?logs=true&stream=false"" ) self.assertIn(r.status_code, (101, 200), r.text) # see the attach format docs, stdout = 1, length = 7, message = podman\n > self.assertEqual(r.content, b""\x01\x00\x00\x00\x00\x00\x00\x07podman\n"", r.text) E AssertionError: b'' != b'\x01\x00\x00\x00\x00\x00\x00\x07podman\n' : test/apiv2/python/rest_api/test_v2_0_0_container.py:155: AssertionError  short test summary info  FAILED test/apiv2/python/rest_api/test_v2_0_0_container.py::ContainerTestCase::test_attach  1 failed, 43 passed in 78.37s (0:01:18)   If I read the URL correctly, this has something to do with `logs`, and ISTR other flakes in podman-remote logs but can't find the issue number. * fedora-37 : APIv2 test on fedora-37 (root) * PR #17165 * [01-19 06:53](https://api.cirrus-ci.com/v1/task/5030036521091072/logs/main.log) * PR #16997 * [01-05 03:10](https://api.cirrus-ci.com/v1/task/4694463075844096/logs/main.log) * PR #16978 * [01-04 03:14](https://api.cirrus-ci.com/v1/task/4749243169112064/logs/main.log) * PR #16810 * [12-30 10:43](https://api.cirrus-ci.com/v1/task/5556295575535616/logs/main.log) * [12-30 10:30](https://api.cirrus-ci.com/v1/task/5214991905718272/logs/main.log)",test-file,apiv tests python something something seeing occasionally since dec containertestcase attach self python rest api container containertestcase testmethod attach def attach self requests post self url containers create name topcontainer json cmd echo sleep image alpine latest self assertequal status text payload json requests post self url containers payload start self assertequal status text requests post self url containers payload attach logs true stream false self assertin status text see attach format docs stdout length message self assertequal content text assertionerror apiv python rest api container assertionerror short summary failed apiv python rest api container containertestcase attach failed passed read url correctly something logs istr flakes remote logs find number fedora apiv fedora root https api cirrus task logs log https api cirrus task logs log https api cirrus task logs log https api cirrus task logs log https api cirrus task logs log,bug,0.9,"APIv2 tests: python something != something-podman Seeing this occasionally since Dec 30:  ________________________ ContainerTestCase.test_attach _________________________ self = <python.rest_api.test_v2_0_0_container.ContainerTestCase testMethod=test_attach> def test_attach(self): r = requests.post( self.podman_url + ""/v1.40/containers/create?name=topcontainer"", json={""Cmd"": [""sh"", ""-c"", ""echo podman; sleep 100""], ""Image"": ""alpine:latest""}, ) self.assertEqual(r.status_code, 201, r.text) payload = r.json() r = requests.post( self.podman_url + f""/v1.40/containers/{payload['Id']}/start"" ) self.assertEqual(r.status_code, 204, r.text) r = requests.post( self.podman_url + f""/v1.40/containers/{payload['Id']}/attach?logs=true&stream=false"" ) self.assertIn(r.status_code, (101, 200), r.text) # see the attach format docs, stdout = 1, length = 7, message = podman\n > self.assertEqual(r.content, b""\x01\x00\x00\x00\x00\x00\x00\x07podman\n"", r.text) E AssertionError: b'' != b'\x01\x00\x00\x00\x00\x00\x00\x07podman\n' : test/apiv2/python/rest_api/test_v2_0_0_container.py:155: AssertionError  short test summary info  FAILED test/apiv2/python/rest_api/test_v2_0_0_container.py::ContainerTestCase::test_attach  1 failed, 43 passed in 78.37s (0:01:18)   If I read the URL correctly, this has something to do with `logs`, and ISTR other flakes in podman-remote logs but can't find the issue number. * fedora-37 : APIv2 test on fedora-37 (root) * PR #17165 * [01-19 06:53](https://api.cirrus-ci.com/v1/task/5030036521091072/logs/main.log) * PR #16997 * [01-05 03:10](https://api.cirrus-ci.com/v1/task/4694463075844096/logs/main.log) * PR #16978 * [01-04 03:14](https://api.cirrus-ci.com/v1/task/4749243169112064/logs/main.log) * PR #16810 * [12-30 10:43](https://api.cirrus-ci.com/v1/task/5556295575535616/logs/main.log) * [12-30 10:30](https://api.cirrus-ci.com/v1/task/5214991905718272/logs/main.log)"
14674,podman,https://github.com/containers/podman/issues/14674,discrepancy in podman network inspect for netmask (compat API),"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** podman main: The netmask of secondaryIPAddresses/SecondaryIPv6Addresses in container network inspect compat API is always zero. podman v3: Wrong type used for secondaryIPAddresses/SecondaryIPv6Addresses (string instead of network.Address) results in broken container inspect compat API in presence of secondary network interfaces. **Steps to reproduce the issue:** Reproduction in **main** branch 1. create a named network namespace and setup two veth interface  ip netns add test ip netns exec test /bin/bash ip link add enp2s0 type veth peer name eth0 ip addr add 10.0.1.0/24 dev eth0 ip link set eth0 up ip link add enp2s1 type veth peer name eth1 ip addr add 10.0.2.0/24 dev eth1 ip link set eth1 up exit  2. run a container and join the created network namespace  podman run --net ns:/run/netns/test --name test -it alpine /bin/sh  3. start a podman service  podman system service tcp:localhost:20000 --log-level=debug --time=0  4. Check output of podman inspect test  curl -X GET 'http://127.0.0.1:20000/v3.0.0/containers/test/json'| jq  **Describe the results you received:** PrefixLen is **0**  ""NetworkSettings"": { ""Bridge"": """", ""SandboxID"": """", ""HairpinMode"": false, ""LinkLocalIPv6Address"": """", ""LinkLocalIPv6PrefixLen"": 0, ""Ports"": {}, ""SandboxKey"": """", ""SecondaryIPAddresses"": [ { ""Addr"": ""10.0.2.0"", ""PrefixLen"": 0 }  **Describe the results you expected:** PrefixLen should be **24** **Output of `podman version`:**  podman version 4.0.0-dev  **Output of `podman info --debug`:**  host: arch: amd64 buildahVersion: 1.24.1 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - pids cgroupManager: systemd cgroupVersion: v1 conmon: package: conmon-2.0.27+git0+3efab3e71c-r0.core2_64 path: /usr/bin/conmon version: 'conmon version 2.0.28-dev, commit: 3efab3e71c4c29f127cd7b8e8a5a885fc17dec88' cpus: 6 distribution: distribution: mbient version: ""1.0"" eventLogger: journald hostname: qemux86-64 idMappings: gidmap: null uidmap: null kernel: 5.10.30-yocto-standard linkmode: dynamic logDriver: journald memFree: 7883513856 memTotal: 22187085824 networkBackend: cni ociRuntime: name: crun package: crun-0.18+gitf302dd8c02c6fddd2c50d1685d82b7a19aae8afe-r0.core2_64 path: /usr/bin/crun version: |- crun version 0.19.5-f302-dirty commit: f302dd8c02c6fddd2c50d1685d82b7a19aae8afe spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: path: /run/podman/podman.sock security: apparmorEnabled: true capabilities: CAP_AUDIT_WRITE,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_MKNOD,CAP_NET_BIND_SERVICE,CAP_NET_RAW,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: """" selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-0.4.1-r0.core2_64 version: |- slirp4netns version 0.4.1 commit: unknown swapFree: 46133248 swapTotal: 46133248 uptime: 6h 6m 42.11s (Approximately 0.25 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io - registry.fedoraproject.org - quay.io - registry.access.redhat.com - registry.centos.org store: configFile: /etc/containers/storage.conf containerStore: number: 6 paused: 0 running: 3 stopped: 3 graphDriverName: overlay graphOptions: overlay.mountopt: nodev graphRoot: /mnt/systemdata/dynamic-contents/podman graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 2 runRoot: /var/run/containers/storage volumePath: /mnt/systemdata/dynamic-contents/podman/volumes version: APIVersion: 4.0.0-dev Built: 1655756421 BuiltTime: Mon Jun 20 22:20:21 2022 GitCommit: 192dea7d981443a8091596eb91e6c4274b8a6f85 GoVersion: go1.18.3 OsArch: linux/amd64 Version: 4.0.0-dev  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes ",source-file | source-file | source-file | test-file | test-file,discrepancy network inspect netmask compat api bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description netmask secondaryipaddresses secondaryipv addresses container network inspect compat api always zero wrong type used secondaryipaddresses secondaryipv addresses string instead network address results broken container inspect compat api presence secondary network interfaces steps reproduce reproduction branch create named network namespace setup two veth interface netns netns exec bash link enp type veth peer name eth addr eth link set eth link enp type veth peer name eth addr eth link set eth exit container join created network namespace netns name alpine start service system service tcp localhost log level time check output inspect curl get http containers json describe results received prefixlen networksettings bridge sandboxid hairpinmode false linklocalipv address linklocalipv prefixlen ports sandboxkey secondaryipaddresses addr prefixlen describe results expected prefixlen output output host arch amd buildahversion cgroupcontrollers cpuset cpu cpuacct blkio memory devices freezer cls perf event prio pids cgroupmanager systemd cgroupversion conmon package conmon git efab core path conmon conmon efab dec cpus distribution distribution mbient eventlogger journald hostname qemux idmappings gidmap null uidmap null kernel yocto standard linkmode dynamic logdriver journald memfree memtotal networkbackend cni ociruntime name crun package crun gitf fddd aae afe core path crun crun dirty fddd aae afe spec systemd selinux apparmor cap seccomp ebpf yajl linux remotesocket path sock security apparmorenabled true capabilities cap audit write cap chown cap dac override cap fowner cap fsetid cap kill cap mknod cap bind service cap raw cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns core slirp netns unknown swapfree swaptotal uptime approximately days plugins log none passthrough journald network bridge macvlan ipvlan volume local registries search docker registry fedoraproject quay registry access redhat registry centos store configfile etc containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev graphroot mnt systemdata dynamic contents graphstatus backing filesystem extfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot var containers storage volumepath mnt systemdata dynamic contents volumes apiversion built builttime jun gitcommit dea goversion osarch linux amd tested latest checked troubleshooting guide https github containers blob troubleshooting yes,bug,0.95,"discrepancy in podman network inspect for netmask (compat API) <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** podman main: The netmask of secondaryIPAddresses/SecondaryIPv6Addresses in container network inspect compat API is always zero. podman v3: Wrong type used for secondaryIPAddresses/SecondaryIPv6Addresses (string instead of network.Address) results in broken container inspect compat API in presence of secondary network interfaces. **Steps to reproduce the issue:** Reproduction in **main** branch 1. create a named network namespace and setup two veth interface  ip netns add test ip netns exec test /bin/bash ip link add enp2s0 type veth peer name eth0 ip addr add 10.0.1.0/24 dev eth0 ip link set eth0 up ip link add enp2s1 type veth peer name eth1 ip addr add 10.0.2.0/24 dev eth1 ip link set eth1 up exit  2. run a container and join the created network namespace  podman run --net ns:/run/netns/test --name test -it alpine /bin/sh  3. start a podman service  podman system service tcp:localhost:20000 --log-level=debug --time=0  4. Check output of podman inspect test  curl -X GET 'http://127.0.0.1:20000/v3.0.0/containers/test/json'| jq  **Describe the results you received:** PrefixLen is **0**  ""NetworkSettings"": { ""Bridge"": """", ""SandboxID"": """", ""HairpinMode"": false, ""LinkLocalIPv6Address"": """", ""LinkLocalIPv6PrefixLen"": 0, ""Ports"": {}, ""SandboxKey"": """", ""SecondaryIPAddresses"": [ { ""Addr"": ""10.0.2.0"", ""PrefixLen"": 0 }  **Describe the results you expected:** PrefixLen should be **24** **Output of `podman version`:**  podman version 4.0.0-dev  **Output of `podman info --debug`:**  host: arch: amd64 buildahVersion: 1.24.1 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - pids cgroupManager: systemd cgroupVersion: v1 conmon: package: conmon-2.0.27+git0+3efab3e71c-r0.core2_64 path: /usr/bin/conmon version: 'conmon version 2.0.28-dev, commit: 3efab3e71c4c29f127cd7b8e8a5a885fc17dec88' cpus: 6 distribution: distribution: mbient version: ""1.0"" eventLogger: journald hostname: qemux86-64 idMappings: gidmap: null uidmap: null kernel: 5.10.30-yocto-standard linkmode: dynamic logDriver: journald memFree: 7883513856 memTotal: 22187085824 networkBackend: cni ociRuntime: name: crun package: crun-0.18+gitf302dd8c02c6fddd2c50d1685d82b7a19aae8afe-r0.core2_64 path: /usr/bin/crun version: |- crun version 0.19.5-f302-dirty commit: f302dd8c02c6fddd2c50d1685d82b7a19aae8afe spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: path: /run/podman/podman.sock security: apparmorEnabled: true capabilities: CAP_AUDIT_WRITE,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_MKNOD,CAP_NET_BIND_SERVICE,CAP_NET_RAW,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: """" selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-0.4.1-r0.core2_64 version: |- slirp4netns version 0.4.1 commit: unknown swapFree: 46133248 swapTotal: 46133248 uptime: 6h 6m 42.11s (Approximately 0.25 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io - registry.fedoraproject.org - quay.io - registry.access.redhat.com - registry.centos.org store: configFile: /etc/containers/storage.conf containerStore: number: 6 paused: 0 running: 3 stopped: 3 graphDriverName: overlay graphOptions: overlay.mountopt: nodev graphRoot: /mnt/systemdata/dynamic-contents/podman graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 2 runRoot: /var/run/containers/storage volumePath: /mnt/systemdata/dynamic-contents/podman/volumes version: APIVersion: 4.0.0-dev Built: 1655756421 BuiltTime: Mon Jun 20 22:20:21 2022 GitCommit: 192dea7d981443a8091596eb91e6c4274b8a6f85 GoVersion: go1.18.3 OsArch: linux/amd64 Version: 4.0.0-dev  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes "
16856,podman,https://github.com/containers/podman/issues/16856,non-tty logs/container attach format broken,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** Podman seems to have a bug in attach format which is described here https://docs.docker.com/engine/api/v1.41/#tag/Container/operation/ContainerAttach The bug only seems to appear for the log items produced *before* the attach command is executed, not after **Steps to reproduce the issue:** 1. Start a container which prints a 4-byte message on stdout each second during 10 seconds 2. Wait for 5 seconds 3. Attach to the container and save the output The same steps in form of a script:  sudo podman run -d --rm --name test alpine sh -c 'for i in $(seq 0 10); do printf ""%03d\n"" $i; sleep 1; done' sleep 5 sudo curl -X POST --unix /run/podman/podman.sock 'http://localhost/containers/test/attach?logs=true&stream=true&stdout=true' --output dump.bin  **Describe the results you received:** Looking at the `dump.bin` produced with the above reproduction procedure, one can clearly see how the `length` field is incorrect (indicates 3 bytes for a 4-byte payload) during the first 5 seconds, and correct (indicates 4 bytes) during the last 5 seconds.  h01:~$ xxd -c12 dump.bin 00000000: 0100 0000 0000 0003 3030 300a 000. 0000000c: 0100 0000 0000 0003 3030 310a 001. 00000018: 0100 0000 0000 0003 3030 320a 002. 00000024: 0100 0000 0000 0003 3030 330a 003. 00000030: 0100 0000 0000 0003 3030 340a 004. 0000003c: 0100 0000 0000 0003 3030 350a 005. 00000048: 0100 0000 0000 0004 3030 360a 006. 00000054: 0100 0000 0000 0004 3030 370a 007. 00000060: 0100 0000 0000 0004 3030 380a 008. 0000006c: 0100 0000 0000 0004 3030 390a 009. 00000078: 0100 0000 0000 0004 3031 300a 010.  **Describe the results you expected:** I expected the `length` to be `4` for all messages. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  $ podman version Client: Podman Engine Version: 4.3.1 API Version: 4.3.1 Go Version: go1.19.4 Built: Tue Dec 13 02:00:33 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  $ podman info host: arch: amd64 buildahVersion: 1.28.0 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.5-r0 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: unknown' cpuUtilization: idlePercent: 99.74 systemPercent: 0.12 userPercent: 0.15 cpus: 1 distribution: distribution: alpine version: 3.17.0 eventLogger: file hostname: h01 idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 uidmap: - container_id: 0 host_id: 1000 size: 1 kernel: 5.15.82-0-virt linkmode: dynamic logDriver: k8s-file memFree: 1847091200 memTotal: 2087096320 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-r0 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /tmp/podman-run-1000/crun spec: 1.0.0 +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: path: /tmp/podman-run-1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-r0 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.4 swapFree: 0 swapTotal: 0 uptime: 0h 46m 48.00s plugins: authorization: null log: - k8s-file - none - passthrough network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /home/docker/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/docker/.local/share/containers/storage graphRootAllocated: 4226809856 graphRootUsed: 286416896 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /tmp/podman-run-1000/containers volumePath: /home/docker/.local/share/containers/storage/volumes version: APIVersion: 4.3.1 Built: 1670896833 BuiltTime: Tue Dec 13 02:00:33 2022 GitCommit: """" GoVersion: go1.19.4 Os: linux OsArch: linux/amd64 Version: 4.3.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman` or `brew info podman`):**  $ apk info podman podman-4.3.1-r1 description: Simple management tool for pods, containers and images podman-4.3.1-r1 webpage: https://podman.io/ podman-4.3.1-r1 installed size: 39 MiB  **Have you tested with the latest version of Podman and have you checked [the Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md)?** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):**",source-file | test-file | test-file,non tty logs container attach format broken bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description seems bug attach format described https docs docker engine api tag container operation containerattach bug seems appear log items produced attach command executed steps reproduce start container prints byte message stdout second seconds wait seconds attach container save output steps form script sudo name alpine seq printf sleep done sleep sudo curl post unix sock http localhost containers attach logs true stream true stdout true output dump describe results received looking dump produced reproduction procedure one clearly see length field incorrect indicates bytes byte payload first seconds correct indicates bytes last seconds xxd dump describe results expected expected length messages additional information deem important happens occasionally output client engine api built dec arch linux amd output host arch amd buildahversion cgroupcontrollers cgroupmanager cgroupfs cgroupversion conmon package conmon path conmon conmon unknown cpuutilization idlepercent systempercent userpercent cpus distribution distribution alpine eventlogger hostname idmappings gidmap container host size uidmap container host size kernel virt linkmode dynamic logdriver memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun aff cac rundir tmp crun spec selinux apparmor cap seccomp ebpf yajl linux remotesocket path tmp sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath etc containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime plugins authorization null log none passthrough network bridge macvlan volume local registries search docker store configfile home docker config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home docker local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot tmp containers volumepath home docker local share containers storage volumes apiversion built builttime dec gitcommit goversion linux osarch linux amd package output rpm apt list brew apk description simple management tool pods containers images webpage https installed size mib tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc,bug,0.95,"non-tty logs/container attach format broken <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** Podman seems to have a bug in attach format which is described here https://docs.docker.com/engine/api/v1.41/#tag/Container/operation/ContainerAttach The bug only seems to appear for the log items produced *before* the attach command is executed, not after **Steps to reproduce the issue:** 1. Start a container which prints a 4-byte message on stdout each second during 10 seconds 2. Wait for 5 seconds 3. Attach to the container and save the output The same steps in form of a script:  sudo podman run -d --rm --name test alpine sh -c 'for i in $(seq 0 10); do printf ""%03d\n"" $i; sleep 1; done' sleep 5 sudo curl -X POST --unix /run/podman/podman.sock 'http://localhost/containers/test/attach?logs=true&stream=true&stdout=true' --output dump.bin  **Describe the results you received:** Looking at the `dump.bin` produced with the above reproduction procedure, one can clearly see how the `length` field is incorrect (indicates 3 bytes for a 4-byte payload) during the first 5 seconds, and correct (indicates 4 bytes) during the last 5 seconds.  h01:~$ xxd -c12 dump.bin 00000000: 0100 0000 0000 0003 3030 300a 000. 0000000c: 0100 0000 0000 0003 3030 310a 001. 00000018: 0100 0000 0000 0003 3030 320a 002. 00000024: 0100 0000 0000 0003 3030 330a 003. 00000030: 0100 0000 0000 0003 3030 340a 004. 0000003c: 0100 0000 0000 0003 3030 350a 005. 00000048: 0100 0000 0000 0004 3030 360a 006. 00000054: 0100 0000 0000 0004 3030 370a 007. 00000060: 0100 0000 0000 0004 3030 380a 008. 0000006c: 0100 0000 0000 0004 3030 390a 009. 00000078: 0100 0000 0000 0004 3031 300a 010.  **Describe the results you expected:** I expected the `length` to be `4` for all messages. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  $ podman version Client: Podman Engine Version: 4.3.1 API Version: 4.3.1 Go Version: go1.19.4 Built: Tue Dec 13 02:00:33 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  $ podman info host: arch: amd64 buildahVersion: 1.28.0 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.5-r0 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: unknown' cpuUtilization: idlePercent: 99.74 systemPercent: 0.12 userPercent: 0.15 cpus: 1 distribution: distribution: alpine version: 3.17.0 eventLogger: file hostname: h01 idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 uidmap: - container_id: 0 host_id: 1000 size: 1 kernel: 5.15.82-0-virt linkmode: dynamic logDriver: k8s-file memFree: 1847091200 memTotal: 2087096320 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-r0 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /tmp/podman-run-1000/crun spec: 1.0.0 +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: path: /tmp/podman-run-1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-r0 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.4 swapFree: 0 swapTotal: 0 uptime: 0h 46m 48.00s plugins: authorization: null log: - k8s-file - none - passthrough network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /home/docker/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/docker/.local/share/containers/storage graphRootAllocated: 4226809856 graphRootUsed: 286416896 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /tmp/podman-run-1000/containers volumePath: /home/docker/.local/share/containers/storage/volumes version: APIVersion: 4.3.1 Built: 1670896833 BuiltTime: Tue Dec 13 02:00:33 2022 GitCommit: """" GoVersion: go1.19.4 Os: linux OsArch: linux/amd64 Version: 4.3.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman` or `brew info podman`):**  $ apk info podman podman-4.3.1-r1 description: Simple management tool for pods, containers and images podman-4.3.1-r1 webpage: https://podman.io/ podman-4.3.1-r1 installed size: 39 MiB  **Have you tested with the latest version of Podman and have you checked [the Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md)?** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):**"
19159,podman,https://github.com/containers/podman/issues/19159,New podman pod remove API error message is less detailed," Issue Description In 4.6.0-rc1 the `libpods/pod` DELETE endpoint's error message changed to: ![image](https://github.com/containers/podman/assets/67428/09887439-128b-42be-92bb-7b9da3b92dcf) From: ![image](https://github.com/containers/podman/assets/67428/8dd91399-3241-451e-8ef2-c7ee13b38979) The new error message does not include anything about it being unable delete running/paused containers.  Steps to reproduce the issue Steps to reproduce the issue  [root@fedora-testing-127-0-0-2-2201 ~]# podman pod ps POD ID NAME STATUS CREATED INFRA ID # OF CONTAINERS 64ec75433156 brave_solomon Running 24 minutes ago c168e97d7e68 2 [root@fedora-testing-127-0-0-2-2201 ~]# curl -X DELETE -s -g --no-buffer --unix-socket /run/podman/podman.sock 'http://localhost/v1.12/libpod/pods/64ec75433156' {""cause"":""removing pod containers"",""message"":""not all containers could be removed from pod 64ec754331564082b0ccbf078268d701ad009a415ad1dfdaca64425cbe8d8821: removing pod containers"",""response"":500}   Describe the results you received See above :)  Describe the results you expected I'm wondering if the error should inform that the container is running/paused so requires force to be removed.  podman info output  Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | test-file | test-file | source-file | test-file | test-file,new pod api message less detailed description libpods pod delete endpoint message changed image https github containers assets dcf image https github containers assets new message include anything unable delete running paused containers steps reproduce steps reproduce root fedora testing pod pod name status created infra containers brave solomon running minutes ago root fedora testing curl delete buffer unix socket sock http localhost libpod pods cause removing pod containers message containers could removed pod ccbf dfdaca cbe removing pod containers response describe results received see describe results expected wondering inform container running paused requires force removed output container privileged rootless none upstream latest yes additional environment details additional environment details additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.9,"New podman pod remove API error message is less detailed  Issue Description In 4.6.0-rc1 the `libpods/pod` DELETE endpoint's error message changed to: ![image](https://github.com/containers/podman/assets/67428/09887439-128b-42be-92bb-7b9da3b92dcf) From: ![image](https://github.com/containers/podman/assets/67428/8dd91399-3241-451e-8ef2-c7ee13b38979) The new error message does not include anything about it being unable delete running/paused containers.  Steps to reproduce the issue Steps to reproduce the issue  [root@fedora-testing-127-0-0-2-2201 ~]# podman pod ps POD ID NAME STATUS CREATED INFRA ID # OF CONTAINERS 64ec75433156 brave_solomon Running 24 minutes ago c168e97d7e68 2 [root@fedora-testing-127-0-0-2-2201 ~]# curl -X DELETE -s -g --no-buffer --unix-socket /run/podman/podman.sock 'http://localhost/v1.12/libpod/pods/64ec75433156' {""cause"":""removing pod containers"",""message"":""not all containers could be removed from pod 64ec754331564082b0ccbf078268d701ad009a415ad1dfdaca64425cbe8d8821: removing pod containers"",""response"":500}   Describe the results you received See above :)  Describe the results you expected I'm wondering if the error should inform that the container is running/paused so requires force to be removed.  podman info output  Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
20013,podman,https://github.com/containers/podman/issues/20013,docker rest api compatibility not honored for error responses.," Issue Description It seems that the compatibility with the api rest of docker is not met for error responses. According to the docker docs, the response should include a field ""message"" but podman has a different schema. This can be reproduced easily running a request to pull an image, for example. As consequence, clients like the official python library for docker doesn't work because the response has a different schema (the message is inside ""errordetail"") and the library expects to have a ""message"" key at the root level as is described in the docs. Docker docs ref: https://docs.docker.com/engine/api/v1.43/#tag/Image/operation/ImageCreate Example of podman response  curl -XPOST ""http://localhost:8888/images/create?fromImage=quay.io/idonotexist/idonotexist:dummy"" | jq { ""progressDetail"": {}, ""errorDetail"": { ""message"": ""initializing source docker://quay.io/idonotexist/idonotexist:dummy: reading manifest dummy in quay.io/idonotexist/idonotexist: unauthorized: access to the requested resource is not authorized"" }, ""error"": ""initializing source docker://quay.io/idonotexist/idonotexist:dummy: reading manifest dummy in quay.io/idonotexist/idonotexist: unauthorized: access to the requested resource is not authorized"" }  Tested with latest podman container 4.6.1  Steps to reproduce the issue  curl -XPOST ""http://localhost:8888/images/create?fromImage=quay.io/idonotexist/idonotexist:dummy""   Describe the results you received The response doesn't meet the spec of docker api response, don't have a ""message"" key in the root level  Describe the results you expected a ""message"" key in the root level with the reason of the error.  podman info output yaml podman v4.6.1   Podman in a container Yes  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_",source-file | test-file,docker rest api compatibility honored responses description seems compatibility api rest docker met responses according docker docs response include field message different schema reproduced easily running image example consequence clients like official python library docker work response different schema message inside errordetail library expects message key root level described docs docker docs ref https docs docker engine api tag image operation imagecreate example response curl xpost http localhost images create fromimage quay idonotexist idonotexist dummy progressdetail errordetail message initializing docker quay idonotexist idonotexist dummy reading manifest dummy quay idonotexist idonotexist unauthorized access requested resource authorized initializing docker quay idonotexist idonotexist dummy reading manifest dummy quay idonotexist idonotexist unauthorized access requested resource authorized tested latest container steps reproduce curl xpost http localhost images create fromimage quay idonotexist idonotexist dummy describe results received response meet spec docker api response message key root level describe results expected message key root level reason output yaml container yes privileged rootless privileged upstream latest yes additional environment details response additional information response,bug,0.95,"docker rest api compatibility not honored for error responses.  Issue Description It seems that the compatibility with the api rest of docker is not met for error responses. According to the docker docs, the response should include a field ""message"" but podman has a different schema. This can be reproduced easily running a request to pull an image, for example. As consequence, clients like the official python library for docker doesn't work because the response has a different schema (the message is inside ""errordetail"") and the library expects to have a ""message"" key at the root level as is described in the docs. Docker docs ref: https://docs.docker.com/engine/api/v1.43/#tag/Image/operation/ImageCreate Example of podman response  curl -XPOST ""http://localhost:8888/images/create?fromImage=quay.io/idonotexist/idonotexist:dummy"" | jq { ""progressDetail"": {}, ""errorDetail"": { ""message"": ""initializing source docker://quay.io/idonotexist/idonotexist:dummy: reading manifest dummy in quay.io/idonotexist/idonotexist: unauthorized: access to the requested resource is not authorized"" }, ""error"": ""initializing source docker://quay.io/idonotexist/idonotexist:dummy: reading manifest dummy in quay.io/idonotexist/idonotexist: unauthorized: access to the requested resource is not authorized"" }  Tested with latest podman container 4.6.1  Steps to reproduce the issue  curl -XPOST ""http://localhost:8888/images/create?fromImage=quay.io/idonotexist/idonotexist:dummy""   Describe the results you received The response doesn't meet the spec of docker api response, don't have a ""message"" key in the root level  Describe the results you expected a ""message"" key in the root level with the reason of the error.  podman info output yaml podman v4.6.1   Podman in a container Yes  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_"
15952,podman,https://github.com/containers/podman/issues/15952,remote: manifest add --annotation failed to add annotations field,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> In help page, podman-remote manifest add --annotation option seems to be supported. However, --annotation option doesn't work.  # podman-remote manifest add --help Add images to a manifest list or image index < snip > Options: --all add all of the list's images if the image is a list --annotation annotation set an annotation for the specified image --arch architecture override the architecture of the specified image --authfile string path of the authentication file. Use REGISTRY_AUTH_FILE environment variable to override --creds [username[:password]] use [username[:password]] for accessing the registry --features features override the features of the specified image --os OS override the OS of the specified image --os-version version override the OS version of the specified image --tls-verify require HTTPS and verify certificates when accessing the registry (default true) --variant Variant override the Variant of the specified image  **Steps to reproduce the issue:**  # podman-remote manifest create test 44f340f882d25deee282e2d9abede61a030a922041d03105b02c22982f1fa8d6 # podman-remote manifest add --annotation foo=bar test quay.io/libpod/testimage:20220615 44f340f882d25deee282e2d9abede61a030a922041d03105b02c22982f1fa8d6  **Describe the results you received:**  # podman-remote manifest inspect test { ""schemaVersion"": 2, ""mediaType"": ""application/vnd.docker.distribution.manifest.list.v2+json"", ""manifests"": [ { ""mediaType"": ""application/vnd.oci.image.manifest.v1+json"", ""size"": 758, ""digest"": ""sha256:a07e678985cd67330fd30a4c8a008cefeb1ca917c25ab0f8468ea17c7b34beb2"", ""platform"": { ""architecture"": ""amd64"", ""os"": ""linux"" } } ] }  **Describe the results you expected:** 1. If --annotation option isn't supported, we need to hide --annotation option from help page. 2. If --annotation option is supported, add annotations field such as below.  # podman-remote manifest inspect test { ""schemaVersion"": 2, ""mediaType"": ""application/vnd.docker.distribution.manifest.list.v2+json"", ""manifests"": [ { ""mediaType"": ""application/vnd.oci.image.manifest.v1+json"", ""size"": 758, ""digest"": ""sha256:a07e678985cd67330fd30a4c8a008cefeb1ca917c25ab0f8468ea17c7b34beb2"", ""platform"": { ""architecture"": ""amd64"", ""os"": ""linux"" }, ""annotations"": { ""foo"": ""bar"" } } ] }  **Additional information you deem important (e.g. issue happens only occasionally):** Succeeded to add annotations field on local enviornment.  # podman manifest inspect test { ""schemaVersion"": 2, ""mediaType"": ""application/vnd.docker.distribution.manifest.list.v2+json"", ""manifests"": [ { ""mediaType"": ""application/vnd.oci.image.manifest.v1+json"", ""size"": 758, ""digest"": ""sha256:a07e678985cd67330fd30a4c8a008cefeb1ca917c25ab0f8468ea17c7b34beb2"", ""platform"": { ""architecture"": ""amd64"", ""os"": ""linux"" }, ""annotations"": { ""foo"": ""bar"" } } ] }  <details> <summary>podman-remote version</summary>  Client: Podman Engine Version: 4.3.0-dev API Version: 4.3.0-dev Go Version: go1.18.3 Git Commit: 98e26278844506e64e311810f97bffcc7efc0b8a Built: Tue Sep 27 13:55:08 2022 OS/Arch: linux/amd64 Server: Podman Engine Version: 4.3.0-dev API Version: 4.3.0-dev Go Version: go1.18.3 Git Commit: 98e26278844506e64e311810f97bffcc7efc0b8a Built: Tue Sep 27 13:54:58 2022 OS/Arch: linux/amd64  </details> <details> <summary>podman-remote info</summary>  host: arch: amd64 buildahVersion: 1.28.0-dev cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-2.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: ' cpuUtilization: idlePercent: 99.98 systemPercent: 0.01 userPercent: 0.01 cpus: 12 distribution: distribution: fedora variant: server version: ""36"" eventLogger: journald hostname: fedora36 idMappings: gidmap: null uidmap: null kernel: 5.18.11-200.fc36.x86_64 linkmode: dynamic logDriver: journald memFree: 6005047296 memTotal: 8326590464 networkBackend: netavark ociRuntime: name: crun package: crun-1.5-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.5 commit: 54ebb8ca8bf7e6ddae2eb919f5b82d1d96863dea spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: unix:run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 8325689344 swapTotal: 8325689344 uptime: 124h 49m 14.00s (Approximately 5.17 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 106285760512 graphRootUsed: 19557855232 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.3.0-dev Built: 1664254498 BuiltTime: Tue Sep 27 13:54:58 2022 GitCommit: 98e26278844506e64e311810f97bffcc7efc0b8a GoVersion: go1.18.3 Os: linux OsArch: linux/amd64 Version: 4.3.0-dev  </details> **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):** KVM, fedora36",source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file,remote manifest annotation failed annotations field bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description briefly describe paragraphs help page remote manifest annotation option seems supported however annotation option work remote manifest help images manifest list image index snip options list images image list annotation annotation set annotation specified image arch architecture override architecture specified image authfile string path authentication use registry auth environment variable override creds username password use username password accessing registry features features override features specified image override specified image override specified image tls verify require https verify certificates accessing registry default true variant variant override variant specified image steps reproduce remote manifest create deee abede remote manifest annotation foo bar quay libpod testimage deee abede describe results received remote manifest inspect schemaversion mediatype application vnd docker distribution manifest list json manifests mediatype application vnd oci image manifest json size digest sha cefeb beb platform architecture amd linux describe results expected annotation option supported need hide annotation option help page annotation option supported annotations field remote manifest inspect schemaversion mediatype application vnd docker distribution manifest list json manifests mediatype application vnd oci image manifest json size digest sha cefeb beb platform architecture amd linux annotations foo bar additional information deem important happens occasionally succeeded annotations field local enviornment manifest inspect schemaversion mediatype application vnd docker distribution manifest list json manifests mediatype application vnd oci image manifest json size digest sha cefeb beb platform architecture amd linux annotations foo bar details summary remote summary client engine api git bffcc efc built sep arch linux amd server engine api git bffcc efc built sep arch linux amd details details summary remote summary host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids misc cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant server eventlogger journald hostname fedora idmappings gidmap null uidmap null kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun ebb ddae dea spec systemd selinux apparmor cap seccomp ebpf criu yajl linux remotesocket exists true path unix sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote true slirp netns executable slirp netns package slirp netns beta slirp netns beta dda libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff false supports type true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage volumepath var containers storage volumes apiversion built builttime sep gitcommit bffcc efc goversion linux osarch linux amd details tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc kvm fedora,bug,0.95,"remote: manifest add --annotation failed to add annotations field <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> In help page, podman-remote manifest add --annotation option seems to be supported. However, --annotation option doesn't work.  # podman-remote manifest add --help Add images to a manifest list or image index < snip > Options: --all add all of the list's images if the image is a list --annotation annotation set an annotation for the specified image --arch architecture override the architecture of the specified image --authfile string path of the authentication file. Use REGISTRY_AUTH_FILE environment variable to override --creds [username[:password]] use [username[:password]] for accessing the registry --features features override the features of the specified image --os OS override the OS of the specified image --os-version version override the OS version of the specified image --tls-verify require HTTPS and verify certificates when accessing the registry (default true) --variant Variant override the Variant of the specified image  **Steps to reproduce the issue:**  # podman-remote manifest create test 44f340f882d25deee282e2d9abede61a030a922041d03105b02c22982f1fa8d6 # podman-remote manifest add --annotation foo=bar test quay.io/libpod/testimage:20220615 44f340f882d25deee282e2d9abede61a030a922041d03105b02c22982f1fa8d6  **Describe the results you received:**  # podman-remote manifest inspect test { ""schemaVersion"": 2, ""mediaType"": ""application/vnd.docker.distribution.manifest.list.v2+json"", ""manifests"": [ { ""mediaType"": ""application/vnd.oci.image.manifest.v1+json"", ""size"": 758, ""digest"": ""sha256:a07e678985cd67330fd30a4c8a008cefeb1ca917c25ab0f8468ea17c7b34beb2"", ""platform"": { ""architecture"": ""amd64"", ""os"": ""linux"" } } ] }  **Describe the results you expected:** 1. If --annotation option isn't supported, we need to hide --annotation option from help page. 2. If --annotation option is supported, add annotations field such as below.  # podman-remote manifest inspect test { ""schemaVersion"": 2, ""mediaType"": ""application/vnd.docker.distribution.manifest.list.v2+json"", ""manifests"": [ { ""mediaType"": ""application/vnd.oci.image.manifest.v1+json"", ""size"": 758, ""digest"": ""sha256:a07e678985cd67330fd30a4c8a008cefeb1ca917c25ab0f8468ea17c7b34beb2"", ""platform"": { ""architecture"": ""amd64"", ""os"": ""linux"" }, ""annotations"": { ""foo"": ""bar"" } } ] }  **Additional information you deem important (e.g. issue happens only occasionally):** Succeeded to add annotations field on local enviornment.  # podman manifest inspect test { ""schemaVersion"": 2, ""mediaType"": ""application/vnd.docker.distribution.manifest.list.v2+json"", ""manifests"": [ { ""mediaType"": ""application/vnd.oci.image.manifest.v1+json"", ""size"": 758, ""digest"": ""sha256:a07e678985cd67330fd30a4c8a008cefeb1ca917c25ab0f8468ea17c7b34beb2"", ""platform"": { ""architecture"": ""amd64"", ""os"": ""linux"" }, ""annotations"": { ""foo"": ""bar"" } } ] }  <details> <summary>podman-remote version</summary>  Client: Podman Engine Version: 4.3.0-dev API Version: 4.3.0-dev Go Version: go1.18.3 Git Commit: 98e26278844506e64e311810f97bffcc7efc0b8a Built: Tue Sep 27 13:55:08 2022 OS/Arch: linux/amd64 Server: Podman Engine Version: 4.3.0-dev API Version: 4.3.0-dev Go Version: go1.18.3 Git Commit: 98e26278844506e64e311810f97bffcc7efc0b8a Built: Tue Sep 27 13:54:58 2022 OS/Arch: linux/amd64  </details> <details> <summary>podman-remote info</summary>  host: arch: amd64 buildahVersion: 1.28.0-dev cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-2.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: ' cpuUtilization: idlePercent: 99.98 systemPercent: 0.01 userPercent: 0.01 cpus: 12 distribution: distribution: fedora variant: server version: ""36"" eventLogger: journald hostname: fedora36 idMappings: gidmap: null uidmap: null kernel: 5.18.11-200.fc36.x86_64 linkmode: dynamic logDriver: journald memFree: 6005047296 memTotal: 8326590464 networkBackend: netavark ociRuntime: name: crun package: crun-1.5-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.5 commit: 54ebb8ca8bf7e6ddae2eb919f5b82d1d96863dea spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: unix:run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 8325689344 swapTotal: 8325689344 uptime: 124h 49m 14.00s (Approximately 5.17 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 106285760512 graphRootUsed: 19557855232 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.3.0-dev Built: 1664254498 BuiltTime: Tue Sep 27 13:54:58 2022 GitCommit: 98e26278844506e64e311810f97bffcc7efc0b8a GoVersion: go1.18.3 Os: linux OsArch: linux/amd64 Version: 4.3.0-dev  </details> **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):** KVM, fedora36"
24632,podman,https://github.com/containers/podman/issues/24632,stats API endpoint crashing 500 when container has no cgroup," Issue Description hello! I found a surprising behavior via use of the podman-exporter to report metrics. In creating a pod via `kube play`, the pod is created fine, but the metrics endpoint is failing with 500:  curl -s localhost:5000/v5.2.5/libpod/containers/stats Request Failed(Internal Server Error): cannot run top on container 0c72.. as it did not create a cgroup: this container does not have a cgroup  error logged:  GET /v5.2.5/libpod/containers/stats?all=false&interval=1&stream=false HTTP/1.1"" 500 239 """" ""Go-http-client/1.1""  Here the container `0c72..` is a pause container. I would not expect the endpoint to crash 500 and deny all stat info. Notably podman is rootless mode and in k8s (ie like DnD). Not seeing the problem in native host mode. Unclear if `containers.conf` is the source of problem. Have not had time to extensively rtfm there, but a latest attempt looked like this (largely inherited from /etc version found at https://quay.io/repository/containers/podman)  [containers] netns=""host"" userns=""host"" ipcns=""host"" utsns=""host"" cgroupns=""host"" cgroups=""disabled"" log_driver = ""k8s-file"" volumes = [ ""/proc:/proc"", ] default_sysctls = [] [engine] cgroup_manager = ""cgroupfs"" events_logger=""file"" runtime=""crun""  Version info  $ podman version Client: Podman Engine Version: 5.2.5 API Version: 5.2.5 Go Version: go1.23.2 Built: Fri Oct 18 00:00:00 2024 OS/Arch: linux/amd64 ",source-file | test-file | source-file | test-file,stats api endpoint crashing container cgroup description hello found surprising behavior via use exporter report metrics creating pod via kube play pod created fine metrics endpoint failing curl localhost libpod containers stats failed internal server cannot top container create cgroup container cgroup logged get libpod containers stats false interval stream false http http client container pause container would expect endpoint crash deny stat notably rootless mode like dnd seeing native host mode unclear containers conf time extensively rtfm latest attempt looked like largely inherited etc found https quay repository containers containers netns host userns host ipcns host utsns host cgroupns host cgroups disabled log driver volumes proc proc default sysctls engine cgroup manager cgroupfs events logger runtime crun client engine api built oct arch linux amd,bug,0.95,"stats API endpoint crashing 500 when container has no cgroup  Issue Description hello! I found a surprising behavior via use of the podman-exporter to report metrics. In creating a pod via `kube play`, the pod is created fine, but the metrics endpoint is failing with 500:  curl -s localhost:5000/v5.2.5/libpod/containers/stats Request Failed(Internal Server Error): cannot run top on container 0c72.. as it did not create a cgroup: this container does not have a cgroup  error logged:  GET /v5.2.5/libpod/containers/stats?all=false&interval=1&stream=false HTTP/1.1"" 500 239 """" ""Go-http-client/1.1""  Here the container `0c72..` is a pause container. I would not expect the endpoint to crash 500 and deny all stat info. Notably podman is rootless mode and in k8s (ie like DnD). Not seeing the problem in native host mode. Unclear if `containers.conf` is the source of problem. Have not had time to extensively rtfm there, but a latest attempt looked like this (largely inherited from /etc version found at https://quay.io/repository/containers/podman)  [containers] netns=""host"" userns=""host"" ipcns=""host"" utsns=""host"" cgroupns=""host"" cgroups=""disabled"" log_driver = ""k8s-file"" volumes = [ ""/proc:/proc"", ] default_sysctls = [] [engine] cgroup_manager = ""cgroupfs"" events_logger=""file"" runtime=""crun""  Version info  $ podman version Client: Podman Engine Version: 5.2.5 API Version: 5.2.5 Go Version: go1.23.2 Built: Fri Oct 18 00:00:00 2024 OS/Arch: linux/amd64 "
18751,podman,https://github.com/containers/podman/issues/18751,docker API returns 200 on push even if it fails," Issue Description docker API returns 200 on push even if it fails  Steps to reproduce the issue Steps to reproduce the issue 1. try to push a image to a private repository 2. the repository has to reject the push 3. podman logs the rejection as error and retries  Describe the results you received 4. podman confirms the push on the API with status 200  Describe the results you expected 4. podman should error on the API with status range reflecting the push error (e.g. 403)  podman info output yaml host: arch: amd64 buildahVersion: 1.30.0 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-2.fc37.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 97.99 systemPercent: 0.4 userPercent: 1.6 cpus: 16 databaseBackend: boltdb distribution: distribution: fedora variant: kde version: ""37"" eventLogger: journald hostname: thinkpad idMappings: gidmap: null uidmap: null kernel: 6.3.0-63.fc39.x86_64 linkmode: dynamic logDriver: journald memFree: 1388929024 memTotal: 29224398848 networkBackend: cni ociRuntime: name: crun package: crun-1.8.4-1.fc37.x86_64 path: /usr/bin/crun version: |- crun version 1.8.4 commit: 5a8fa99a5e41facba2eda4af12fa26313918805b rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 7802028032 swapTotal: 8589930496 uptime: 235h 31m 12.00s (Approximately 9.79 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 201769652224 graphRootUsed: 99855040512 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 4 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.5.0 Built: 1681486976 BuiltTime: Fri Apr 14 17:42:56 2023 GitCommit: """" GoVersion: go1.19.7 Os: linux OsArch: linux/amd64 Version: 4.5.0  Output from `journalctl -u podman`  May 31 11:02:12 thinkpad podman[498506]: @ - - [31/May/2023:11:02:12 +0200] ""POST /build?t=my.private.registry.local%2Fmy.image%2Fmessenger%3A0.0.1&dockerfile=Containerfile&rm=true HTTP/1.1"" 200 1527 """" ""Apache-HttpClient/5.0.3 (Java/17.0.6)"" May 31 11:02:12 thinkpad podman[498506]: time=""2023-05-31T11:02:12+02:00"" level=warning msg=""Failed, retrying in 1s  (1/3). Error: writing blob: initiating layer upload to /v2/my.image/messenger/blobs/uploads/ in my.private.registry.local: unknown: Unable to upload into a virtual repository without default local deployment configured."" May 31 11:02:14 thinkpad podman[498506]: time=""2023-05-31T11:02:14+02:00"" level=warning msg=""Failed, retrying in 1s  (2/3). Error: writing blob: initiating layer upload to /v2/my.image/messenger/blobs/uploads/ in my.private.registry.local: unknown: Unable to upload into a virtual repository without default local deployment configured."" May 31 11:02:15 thinkpad podman[498506]: time=""2023-05-31T11:02:15+02:00"" level=warning msg=""Failed, retrying in 1s  (3/3). Error: writing blob: initiating layer upload to /v2/my.image/messenger/blobs/uploads/ in my.private.registry.local: unknown: Unable to upload into a virtual repository without default local deployment configured."" May 31 11:02:17 thinkpad podman[498506]: @ - - [31/May/2023:11:02:12 +0200] ""POST /images/my.private.registry.local%2Fmy.image%2Fmessenger:0.0.1/push HTTP/1.1"" 200 671 """" ""Apache-HttpClient/5.0.3 (Java/17.0.6)"" May 31 11:02:17 thinkpad podman[498506]: 2023-05-31 11:02:12.320654708 +0200 CEST m=+6.087204790 image push 1d8a277aac651f36677366edc062de55ca26db8821309c6cece21710418f7df0 my.private.registry.local/my.image/messenger:0.0.1  Output from `podman version` (Fedora 37):  [root@thinkpad hargut]# podman version Client: Podman Engine Version: 4.5.0 API Version: 4.5.0 Go Version: go1.19.7 Built: Fri Apr 14 17:42:56 2023 OS/Arch: linux/amd64 [root@thinkpad hargut]# rpm -q podman podman-4.5.0-1.fc37.x86_64 [root@thinkpad hargut]#   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | test-file | test-file,docker api returns push even fails description docker api returns push even fails steps reproduce steps reproduce push image private repository repository reject push logs rejection retries describe results received confirms push api status describe results expected api status range reflecting push output yaml host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids misc cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend boltdb distribution distribution fedora variant kde eventlogger journald hostname thinkpad idmappings gidmap null uidmap null kernel linkmode dynamic logdriver journald memfree memtotal networkbackend cni ociruntime name crun package crun path crun crun facba eda rundir crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux remotesocket exists true path sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff false supports type true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime apr gitcommit goversion linux osarch linux amd output journalctl may thinkpad may post private registry local fmy image fmessenger dockerfile containerfile true http apache httpclient may thinkpad time level warning msg failed retrying writing blob initiating layer upload image messenger blobs uploads private registry local unknown unable upload virtual repository without default local deployment configured may thinkpad time level warning msg failed retrying writing blob initiating layer upload image messenger blobs uploads private registry local unknown unable upload virtual repository without default local deployment configured may thinkpad time level warning msg failed retrying writing blob initiating layer upload image messenger blobs uploads private registry local unknown unable upload virtual repository without default local deployment configured may thinkpad may post images private registry local fmy image fmessenger push http apache httpclient may thinkpad cest image push aac edc cece private registry local image messenger output fedora root thinkpad hargut client engine api built apr arch linux amd root thinkpad hargut rpm root thinkpad hargut container privileged rootless privileged upstream latest additional environment details additional environment details additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.95,"docker API returns 200 on push even if it fails  Issue Description docker API returns 200 on push even if it fails  Steps to reproduce the issue Steps to reproduce the issue 1. try to push a image to a private repository 2. the repository has to reject the push 3. podman logs the rejection as error and retries  Describe the results you received 4. podman confirms the push on the API with status 200  Describe the results you expected 4. podman should error on the API with status range reflecting the push error (e.g. 403)  podman info output yaml host: arch: amd64 buildahVersion: 1.30.0 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-2.fc37.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 97.99 systemPercent: 0.4 userPercent: 1.6 cpus: 16 databaseBackend: boltdb distribution: distribution: fedora variant: kde version: ""37"" eventLogger: journald hostname: thinkpad idMappings: gidmap: null uidmap: null kernel: 6.3.0-63.fc39.x86_64 linkmode: dynamic logDriver: journald memFree: 1388929024 memTotal: 29224398848 networkBackend: cni ociRuntime: name: crun package: crun-1.8.4-1.fc37.x86_64 path: /usr/bin/crun version: |- crun version 1.8.4 commit: 5a8fa99a5e41facba2eda4af12fa26313918805b rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 7802028032 swapTotal: 8589930496 uptime: 235h 31m 12.00s (Approximately 9.79 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 201769652224 graphRootUsed: 99855040512 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 4 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.5.0 Built: 1681486976 BuiltTime: Fri Apr 14 17:42:56 2023 GitCommit: """" GoVersion: go1.19.7 Os: linux OsArch: linux/amd64 Version: 4.5.0  Output from `journalctl -u podman`  May 31 11:02:12 thinkpad podman[498506]: @ - - [31/May/2023:11:02:12 +0200] ""POST /build?t=my.private.registry.local%2Fmy.image%2Fmessenger%3A0.0.1&dockerfile=Containerfile&rm=true HTTP/1.1"" 200 1527 """" ""Apache-HttpClient/5.0.3 (Java/17.0.6)"" May 31 11:02:12 thinkpad podman[498506]: time=""2023-05-31T11:02:12+02:00"" level=warning msg=""Failed, retrying in 1s  (1/3). Error: writing blob: initiating layer upload to /v2/my.image/messenger/blobs/uploads/ in my.private.registry.local: unknown: Unable to upload into a virtual repository without default local deployment configured."" May 31 11:02:14 thinkpad podman[498506]: time=""2023-05-31T11:02:14+02:00"" level=warning msg=""Failed, retrying in 1s  (2/3). Error: writing blob: initiating layer upload to /v2/my.image/messenger/blobs/uploads/ in my.private.registry.local: unknown: Unable to upload into a virtual repository without default local deployment configured."" May 31 11:02:15 thinkpad podman[498506]: time=""2023-05-31T11:02:15+02:00"" level=warning msg=""Failed, retrying in 1s  (3/3). Error: writing blob: initiating layer upload to /v2/my.image/messenger/blobs/uploads/ in my.private.registry.local: unknown: Unable to upload into a virtual repository without default local deployment configured."" May 31 11:02:17 thinkpad podman[498506]: @ - - [31/May/2023:11:02:12 +0200] ""POST /images/my.private.registry.local%2Fmy.image%2Fmessenger:0.0.1/push HTTP/1.1"" 200 671 """" ""Apache-HttpClient/5.0.3 (Java/17.0.6)"" May 31 11:02:17 thinkpad podman[498506]: 2023-05-31 11:02:12.320654708 +0200 CEST m=+6.087204790 image push 1d8a277aac651f36677366edc062de55ca26db8821309c6cece21710418f7df0 my.private.registry.local/my.image/messenger:0.0.1  Output from `podman version` (Fedora 37):  [root@thinkpad hargut]# podman version Client: Podman Engine Version: 4.5.0 API Version: 4.5.0 Go Version: go1.19.7 Built: Fri Apr 14 17:42:56 2023 OS/Arch: linux/amd64 [root@thinkpad hargut]# rpm -q podman podman-4.5.0-1.fc37.x86_64 [root@thinkpad hargut]#   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
17385,podman,https://github.com/containers/podman/issues/17385,[Bug]: network modes `none` and `host` should create entries in `NetworkSettings.Networks`," Issue Description When creating a container with network mode `host` or `none` using docker, the network settings contain entries with those names, respectively. With podman, the networks map is empty.  Steps to reproduce the issue Steps to reproduce the issue 1. run a container with network mode `host` or `none` (`podman run --network=host alpine sleep 1000`) 2. check the container's network settings (`podman inspect $id`)  Describe the results you received No entries in the networks map.  Describe the results you expected Examples from docker json ""Networks"": { ""none"": { ""IPAMConfig"": null, ""Links"": null, ""Aliases"": null, ""NetworkID"": ""840780b61c9fe68c120a0ba5b71158bfab274e9874ff8adba18381c962647e32"", ""EndpointID"": ""21b3555e8d0431ba777bd7e5e0f3e9f38525c5cf98cd9c3ead83d83bcaed15b2"", ""Gateway"": """", ""IPAddress"": """", ""IPPrefixLen"": 0, ""IPv6Gateway"": """", ""GlobalIPv6Address"": """", ""GlobalIPv6PrefixLen"": 0, ""MacAddress"": """", ""DriverOpts"": null } }  json ""Networks"": { ""host"": { ""IPAMConfig"": null, ""Links"": null, ""Aliases"": null, ""NetworkID"": ""7713bb616c867a4104cdd9c1f70f32c7c5b5f1714d5542410386fcb8b33d0ca9"", ""EndpointID"": ""158dea76994f883b58b373a56b4daef5a7b2b4e36cc041a6f09c73832738a2aa"", ""Gateway"": """", ""IPAddress"": """", ""IPPrefixLen"": 0, ""IPv6Gateway"": """", ""GlobalIPv6Address"": """", ""GlobalIPv6PrefixLen"": 0, ""MacAddress"": """", ""DriverOpts"": null } }   podman info output yaml host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.5-1.fc37.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: ' cpuUtilization: idlePercent: 96.34 systemPercent: 0.95 userPercent: 2.71 cpus: 16 distribution: distribution: fedora variant: workstation version: ""37"" eventLogger: journald hostname: honestmistake idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.1.9-200.fc37.x86_64 linkmode: dynamic logDriver: journald memFree: 21072125952 memTotal: 32835108864 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-3.fc37.x86_64 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 8589930496 swapTotal: 8589930496 uptime: 0h 34m 4.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: localhost: Blocked: false Insecure: true Location: localhost MirrorByDigestOnly: false Mirrors: null Prefix: localhost PullFromMirror: """" search: - docker.io store: configFile: /home/jakob/.config/containers/storage.conf containerStore: number: 64 paused: 0 running: 5 stopped: 59 graphDriverName: overlay graphOptions: {} graphRoot: /home/jakob/.local/share/containers/storage graphRootAllocated: 510405902336 graphRootUsed: 358397812736 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 107 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/jakob/.local/share/containers/storage/volumes version: APIVersion: 4.4.0 Built: 1675341170 BuiltTime: Thu Feb 2 13:32:50 2023 GitCommit: """" GoVersion: go1.19.5 Os: linux OsArch: linux/amd64   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information This is required for full docker compatibility, to make the testcontainers-java test suite pass, see https://github.com/testcontainers/testcontainers-java/pull/6158 I'm not sure how big the scope of the required changes for this is, but I'd be happy to contribute a fix if someone can point me in the right direction.",source-file | test-file | test-file,bug network modes none host create entries networksettings networks description creating container network mode host none docker network settings contain entries names respectively networks map empty steps reproduce steps reproduce container network mode host none network host alpine sleep check container network settings inspect describe results received entries networks map describe results expected examples docker json networks none ipamconfig null links null aliases null networkid bfab adba endpointid ead bcaed gateway ipaddress ipprefixlen ipv gateway globalipv address globalipv prefixlen macaddress driveropts null json networks host ipamconfig null links null aliases null networkid cdd fcb endpointid dea daef gateway ipaddress ipprefixlen ipv gateway globalipv address globalipv prefixlen macaddress driveropts null output yaml host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant workstation eventlogger journald hostname honestmistake idmappings gidmap container host size container host size uidmap container host size container host size kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun aff cac rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime plugins authorization null log none passthrough journald network bridge macvlan volume local registries localhost blocked false insecure true location localhost mirrorbydigestonly false mirrors null prefix localhost pullfrommirror search docker store configfile home jakob config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home jakob local share containers storage graphrootallocated graphrootused graphstatus backing filesystem btrfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home jakob local share containers storage volumes apiversion built builttime feb gitcommit goversion linux osarch linux amd container privileged rootless rootless upstream latest yes additional environment details response additional information required full docker compatibility make testcontainers suite pass see https github testcontainers testcontainers sure big scope required changes happy contribute someone point right direction,bug,0.95,"[Bug]: network modes `none` and `host` should create entries in `NetworkSettings.Networks`  Issue Description When creating a container with network mode `host` or `none` using docker, the network settings contain entries with those names, respectively. With podman, the networks map is empty.  Steps to reproduce the issue Steps to reproduce the issue 1. run a container with network mode `host` or `none` (`podman run --network=host alpine sleep 1000`) 2. check the container's network settings (`podman inspect $id`)  Describe the results you received No entries in the networks map.  Describe the results you expected Examples from docker json ""Networks"": { ""none"": { ""IPAMConfig"": null, ""Links"": null, ""Aliases"": null, ""NetworkID"": ""840780b61c9fe68c120a0ba5b71158bfab274e9874ff8adba18381c962647e32"", ""EndpointID"": ""21b3555e8d0431ba777bd7e5e0f3e9f38525c5cf98cd9c3ead83d83bcaed15b2"", ""Gateway"": """", ""IPAddress"": """", ""IPPrefixLen"": 0, ""IPv6Gateway"": """", ""GlobalIPv6Address"": """", ""GlobalIPv6PrefixLen"": 0, ""MacAddress"": """", ""DriverOpts"": null } }  json ""Networks"": { ""host"": { ""IPAMConfig"": null, ""Links"": null, ""Aliases"": null, ""NetworkID"": ""7713bb616c867a4104cdd9c1f70f32c7c5b5f1714d5542410386fcb8b33d0ca9"", ""EndpointID"": ""158dea76994f883b58b373a56b4daef5a7b2b4e36cc041a6f09c73832738a2aa"", ""Gateway"": """", ""IPAddress"": """", ""IPPrefixLen"": 0, ""IPv6Gateway"": """", ""GlobalIPv6Address"": """", ""GlobalIPv6PrefixLen"": 0, ""MacAddress"": """", ""DriverOpts"": null } }   podman info output yaml host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.5-1.fc37.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: ' cpuUtilization: idlePercent: 96.34 systemPercent: 0.95 userPercent: 2.71 cpus: 16 distribution: distribution: fedora variant: workstation version: ""37"" eventLogger: journald hostname: honestmistake idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.1.9-200.fc37.x86_64 linkmode: dynamic logDriver: journald memFree: 21072125952 memTotal: 32835108864 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-3.fc37.x86_64 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 8589930496 swapTotal: 8589930496 uptime: 0h 34m 4.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: localhost: Blocked: false Insecure: true Location: localhost MirrorByDigestOnly: false Mirrors: null Prefix: localhost PullFromMirror: """" search: - docker.io store: configFile: /home/jakob/.config/containers/storage.conf containerStore: number: 64 paused: 0 running: 5 stopped: 59 graphDriverName: overlay graphOptions: {} graphRoot: /home/jakob/.local/share/containers/storage graphRootAllocated: 510405902336 graphRootUsed: 358397812736 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 107 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/jakob/.local/share/containers/storage/volumes version: APIVersion: 4.4.0 Built: 1675341170 BuiltTime: Thu Feb 2 13:32:50 2023 GitCommit: """" GoVersion: go1.19.5 Os: linux OsArch: linux/amd64   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information This is required for full docker compatibility, to make the testcontainers-java test suite pass, see https://github.com/testcontainers/testcontainers-java/pull/6158 I'm not sure how big the scope of the required changes for this is, but I'd be happy to contribute a fix if someone can point me in the right direction."
22986,podman,https://github.com/containers/podman/issues/22986,remote: pod top -eo invalid: unmarshalling error,"console $ bin/podman-remote run -d --pod new:foo quay.io/libpod/testimage:20240123 top b829985a6ffa9e8aa35114e48e44e1814469ddf8a801bc77bc3141d7c1065e47 $ bin/podman-remote pod top foo -eo bar Error: unmarshalling into &handlers.PodTopOKBody{ContainerTopOKBody:container.ContainerTopOKBody{Processes:[][]string(nil), Titles:[]string(nil)}}, data """": unexpected end of JSON input ",source-file | test-file | source-file | test-file,remote pod top invalid unmarshalling console remote pod new foo quay libpod testimage top ffa ddf remote pod top foo bar unmarshalling handlers podtopokbody containertopokbody container containertopokbody processes string nil titles string nil data unexpected end json input,bug,0.95,"remote: pod top -eo invalid: unmarshalling error console $ bin/podman-remote run -d --pod new:foo quay.io/libpod/testimage:20240123 top b829985a6ffa9e8aa35114e48e44e1814469ddf8a801bc77bc3141d7c1065e47 $ bin/podman-remote pod top foo -eo bar Error: unmarshalling into &handlers.PodTopOKBody{ContainerTopOKBody:container.ContainerTopOKBody{Processes:[][]string(nil), Titles:[]string(nil)}}, data """": unexpected end of JSON input "
14676,podman,https://github.com/containers/podman/issues/14676,Wrong memory limit stats from podman's remote stats API," Description `podman` remote stats API reports wrong ""memory_limit"" stats for memory-limited container when the container is launched with `crun`. I am not sure whether the issue comes from `podman` or `crun`, but decided to report here because the issue is gone if I change the runtime to `runc`.  How to reproduce 1. Run **rootful** podman API daemon  podman system service -t 0 tcp:127.0.0.1:12345  2. Launch a container with latest `crun` runtime with memory limit  podman run --rm -it -m 512m --runtime=/crun-1.4.5-linux-amd64 --name test busybox  3. Check the output from `podman`'s remote stats API  curl http://127.0.0.1:12345/containers/test/stats?stream=false  4. Confirm that `memory_stats.limit` is wrongly reported.  { ""read"": ""2022-06-21T05:27:32.81008054Z"", ""preread"": ""0001-01-01T00:00:00Z"", ""pids_stats"": , ""blkio_stats"": , ""num_procs"": , ""storage_stats"": , ""cpu_stats"": ,, ""precpu_stats"": , ""memory_stats"": { ""usage"": 589824, ""max_usage"": 18446744073709551615, ""limit"": 18446744073709551615 }, ""name"": ""test"", ""Id"": , ""networks"":  }  5. Repeat the same procedure with `runc` runtime  podman run --rm -it -m 512m --runtime=/home/ubuntu/runc-1.1.3.amd64 --name test busybox  6. Confirm that `memory_stats.limit` is correctly reported.  { ""read"": ""2022-06-21T05:33:54.710659699Z"", ""preread"": ""0001-01-01T00:00:00Z"", ""pids_stats"": , ""blkio_stats"": , ""num_procs"": , ""storage_stats"": , ""cpu_stats"": ,, ""precpu_stats"": , ""memory_stats"": { ""usage"": 335872, ""max_usage"": 536870912, ""limit"": 536870912 }, ""name"": ""test"", ""Id"": , ""networks"":  }   Environment  root@machine:/home/ubuntu# podman info host: arch: amd64 buildahVersion: 1.23.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: 'conmon: /usr/bin/conmon' path: /usr/bin/conmon version: 'conmon version 2.0.25, commit: unknown' cpus: 16 distribution: codename: jammy distribution: ubuntu version: ""22.04"" eventLogger: journald hostname: {maksed} idMappings: gidmap: null uidmap: null kernel: 5.15.0-1004-aws linkmode: dynamic logDriver: journald memFree: 1502658560 memTotal: 67403698176 ociRuntime: name: crun package: 'crun: /usr/bin/crun' path: /usr/bin/crun version: |- crun version 0.17 commit: 0e9229ae34caaebcb86f1fde18de3acaf18c6d9a spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: true capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: 'slirp4netns: /usr/bin/slirp4netns' version: |- slirp4netns version 1.0.1 commit: 6a7b16babc95b6a3056b33fb45b74a6f62262dd4 libslirp: 4.6.1 swapFree: 0 swapTotal: 0 uptime: {maksed} plugins: log: - k8s-file - none - journald network: - bridge - macvlan volume: - local registries: {} store: configFile: /etc/containers/storage.conf containerStore: number: {maksed} paused: {maksed} running: {maksed} stopped: {maksed} graphDriverName: overlay graphOptions: {} graphRoot: /var/lib/containers/storage graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageStore: number: {maksed} runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 3.4.4 Built: 0 BuiltTime: Thu Jan 1 00:00:00 1970 GitCommit: """" GoVersion: go1.17.3 OsArch: linux/amd64 Version: 3.4.4 ",source-file | test-file,wrong memory limit stats remote stats api description remote stats api reports wrong memory limit stats memory limited container container launched crun sure whether comes crun decided report gone runtime runc reproduce rootful api daemon system service tcp launch container latest crun runtime memory limit runtime crun linux amd name busybox check output remote stats api curl http containers stats stream false confirm memory stats limit wrongly reported read preread pids stats blkio stats num procs storage stats cpu stats precpu stats memory stats usage max usage limit name networks repeat procedure runc runtime runtime home ubuntu runc amd name busybox confirm memory stats limit correctly reported read preread pids stats blkio stats num procs storage stats cpu stats precpu stats memory stats usage max usage limit name networks environment root machine home ubuntu host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids rdma misc cgroupmanager systemd cgroupversion conmon package conmon conmon path conmon conmon unknown cpus distribution codename jammy distribution ubuntu eventlogger journald hostname maksed idmappings gidmap null uidmap null kernel aws linkmode dynamic logdriver journald memfree memtotal ociruntime name crun package crun crun path crun crun caaebcb fde acaf spec systemd selinux apparmor cap seccomp ebpf yajl linux remotesocket exists true path sock security apparmorenabled true capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns slirp netns babc libslirp swapfree swaptotal uptime maksed plugins log none journald network bridge macvlan volume local registries store configfile etc containers storage conf containerstore number maksed paused maksed running maksed stopped maksed graphdrivername overlay graphoptions graphroot var containers storage graphstatus backing filesystem extfs native overlay diff true supports type true metacopy false imagestore number maksed runroot containers storage volumepath var containers storage volumes apiversion built builttime jan gitcommit goversion osarch linux amd,bug,0.95,"Wrong memory limit stats from podman's remote stats API  Description `podman` remote stats API reports wrong ""memory_limit"" stats for memory-limited container when the container is launched with `crun`. I am not sure whether the issue comes from `podman` or `crun`, but decided to report here because the issue is gone if I change the runtime to `runc`.  How to reproduce 1. Run **rootful** podman API daemon  podman system service -t 0 tcp:127.0.0.1:12345  2. Launch a container with latest `crun` runtime with memory limit  podman run --rm -it -m 512m --runtime=/crun-1.4.5-linux-amd64 --name test busybox  3. Check the output from `podman`'s remote stats API  curl http://127.0.0.1:12345/containers/test/stats?stream=false  4. Confirm that `memory_stats.limit` is wrongly reported.  { ""read"": ""2022-06-21T05:27:32.81008054Z"", ""preread"": ""0001-01-01T00:00:00Z"", ""pids_stats"": , ""blkio_stats"": , ""num_procs"": , ""storage_stats"": , ""cpu_stats"": ,, ""precpu_stats"": , ""memory_stats"": { ""usage"": 589824, ""max_usage"": 18446744073709551615, ""limit"": 18446744073709551615 }, ""name"": ""test"", ""Id"": , ""networks"":  }  5. Repeat the same procedure with `runc` runtime  podman run --rm -it -m 512m --runtime=/home/ubuntu/runc-1.1.3.amd64 --name test busybox  6. Confirm that `memory_stats.limit` is correctly reported.  { ""read"": ""2022-06-21T05:33:54.710659699Z"", ""preread"": ""0001-01-01T00:00:00Z"", ""pids_stats"": , ""blkio_stats"": , ""num_procs"": , ""storage_stats"": , ""cpu_stats"": ,, ""precpu_stats"": , ""memory_stats"": { ""usage"": 335872, ""max_usage"": 536870912, ""limit"": 536870912 }, ""name"": ""test"", ""Id"": , ""networks"":  }   Environment  root@machine:/home/ubuntu# podman info host: arch: amd64 buildahVersion: 1.23.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: 'conmon: /usr/bin/conmon' path: /usr/bin/conmon version: 'conmon version 2.0.25, commit: unknown' cpus: 16 distribution: codename: jammy distribution: ubuntu version: ""22.04"" eventLogger: journald hostname: {maksed} idMappings: gidmap: null uidmap: null kernel: 5.15.0-1004-aws linkmode: dynamic logDriver: journald memFree: 1502658560 memTotal: 67403698176 ociRuntime: name: crun package: 'crun: /usr/bin/crun' path: /usr/bin/crun version: |- crun version 0.17 commit: 0e9229ae34caaebcb86f1fde18de3acaf18c6d9a spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: true capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: 'slirp4netns: /usr/bin/slirp4netns' version: |- slirp4netns version 1.0.1 commit: 6a7b16babc95b6a3056b33fb45b74a6f62262dd4 libslirp: 4.6.1 swapFree: 0 swapTotal: 0 uptime: {maksed} plugins: log: - k8s-file - none - journald network: - bridge - macvlan volume: - local registries: {} store: configFile: /etc/containers/storage.conf containerStore: number: {maksed} paused: {maksed} running: {maksed} stopped: {maksed} graphDriverName: overlay graphOptions: {} graphRoot: /var/lib/containers/storage graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageStore: number: {maksed} runRoot: /run/containers/storage volumePath: /var/lib/containers/storage/volumes version: APIVersion: 3.4.4 Built: 0 BuiltTime: Thu Jan 1 00:00:00 1970 GitCommit: """" GoVersion: go1.17.3 OsArch: linux/amd64 Version: 3.4.4 "
17778,podman,https://github.com/containers/podman/issues/17778,Build image `pull` field type mismatch with Docker," Issue Description Docker accepts any string value for the `pull` field to indicate the image should be pulled:https://docs.docker.com/engine/api/v1.42/#tag/Image/operation/ImageBuild Podman expects the value to equal either boolean `true` or string `true`: https://docs.podman.io/en/latest/_static/api.html?version=v4.4#tag/images/operation/ImageBuildLibpod Applications that align with Docker's spec are unable to switch to Podman as building an image with this field fails.  Steps to reproduce the issue 1. POST to the create image endpoint with `pull` set to a string, such as `always`.  Describe the results you received No response stream received  Describe the results you expected Expected a response stream  podman info output yaml host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon_2:2.1.7-0debian9999+obs15.6_amd64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 87.46 systemPercent: 5.69 userPercent: 6.84 cpus: 2 distribution: codename: jammy distribution: ubuntu version: ""22.04"" eventLogger: journald hostname: fv-az646-90 idMappings: gidmap: - container_id: 0 host_id: 123 size: 1 - container_id: 1 host_id: 165536 size: 65536 uidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 165536 size: 65536 kernel: 5.15.0-1034-azure linkmode: dynamic logDriver: journald memFree: 4857856000 memTotal: 7281278976 networkBackend: netavark ociRuntime: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/runner/.local/share/containers/storage graphRootAllocated: 89297309696 graphRootUsed: 58336636928 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /run/user/1001/containers transientStore: false volumePath: /home/runner/.local/share/containers/storage/volumes version: APIVersion: 4.4.2 Built: 0 BuiltTime: Thu Jan 1 00:00:00 1970 GitCommit: """" GoVersion: go1.19.6 Os: linux OsArch: linux/amd64 Version: 4.4.2   Podman in a container Yes  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details `DOCKER_HOST=unix:run/user/$(id -u)/podman/podman.sock`  Additional information _No response_",source-file | source-file | test-file | source-file | source-file | test-file,image field type mismatch docker description docker accepts string value field indicate image pulled https docs docker engine api tag image operation imagebuild expects value equal either boolean true string true https docs latest static api html tag images operation imagebuildlibpod applications align docker spec unable switch building image field fails steps reproduce post create image endpoint set string always describe results received response stream received describe results expected expected response stream output yaml host arch amd buildahversion cgroupcontrollers memory pids cgroupmanager systemd cgroupversion conmon package conmon debian obs amd path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution codename jammy distribution ubuntu eventlogger journald hostname idmappings gidmap container host size container host size uidmap container host size container host size kernel azure linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime number paused running stopped graphdrivername overlay graphoptions graphroot home runner local share containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home runner local share containers storage volumes apiversion built builttime jan gitcommit goversion linux osarch linux amd container yes privileged rootless rootless upstream latest yes additional environment details docker host unix user sock additional information response,bug,0.95,"Build image `pull` field type mismatch with Docker  Issue Description Docker accepts any string value for the `pull` field to indicate the image should be pulled:https://docs.docker.com/engine/api/v1.42/#tag/Image/operation/ImageBuild Podman expects the value to equal either boolean `true` or string `true`: https://docs.podman.io/en/latest/_static/api.html?version=v4.4#tag/images/operation/ImageBuildLibpod Applications that align with Docker's spec are unable to switch to Podman as building an image with this field fails.  Steps to reproduce the issue 1. POST to the create image endpoint with `pull` set to a string, such as `always`.  Describe the results you received No response stream received  Describe the results you expected Expected a response stream  podman info output yaml host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon_2:2.1.7-0debian9999+obs15.6_amd64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 87.46 systemPercent: 5.69 userPercent: 6.84 cpus: 2 distribution: codename: jammy distribution: ubuntu version: ""22.04"" eventLogger: journald hostname: fv-az646-90 idMappings: gidmap: - container_id: 0 host_id: 123 size: 1 - container_id: 1 host_id: 165536 size: 65536 uidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 165536 size: 65536 kernel: 5.15.0-1034-azure linkmode: dynamic logDriver: journald memFree: 4857856000 memTotal: 7281278976 networkBackend: netavark ociRuntime: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/runner/.local/share/containers/storage graphRootAllocated: 89297309696 graphRootUsed: 58336636928 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /run/user/1001/containers transientStore: false volumePath: /home/runner/.local/share/containers/storage/volumes version: APIVersion: 4.4.2 Built: 0 BuiltTime: Thu Jan 1 00:00:00 1970 GitCommit: """" GoVersion: go1.19.6 Os: linux OsArch: linux/amd64 Version: 4.4.2   Podman in a container Yes  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details `DOCKER_HOST=unix:run/user/$(id -u)/podman/podman.sock`  Additional information _No response_"
22071,podman,https://github.com/containers/podman/issues/22071,Unable to build multi-arch via Podman CURL / API.," Issue Description When trying to pass in `--platform` equivalent within the API, I am getting this parsing error:  {""cause"":""invalid argument"",""message"":""failed to parse query parameter 'platform': \""linux/arm64,linux/amd64\"": invalid platform syntax for --platform=\""linux/arm64,linux/amd64\"": \""arm64,linux\"" is an invalid component of \""linux/arm64,linux/amd64\"": platform specifier component must match \""^[A-Za-z0-9_-]+$\"": invalid argument"",""response"":400}   Steps to reproduce the issue Steps to reproduce the issue 1. Package any Containerfile (`tar -czf context.tar.gz -C dir .`) 2. Use the below CURL command: sh curl --unix-socket ~/.local/share/containers/podman/machine/applehv/podman.sock -X POST \ -H ""Content-Type: application/tar"" \ -H ""Content-Encoding: gzip"" \ --data-binary ""@context.tar.gz"" \ ""http://d/v4.0.0/libpod/build?platform=linux/arm64,linux/amd64&t=quay.io/mytestcontainer"" {""cause"":""invalid argument"",""message"":""failed to parse query parameter 'platform': \""linux/arm64,linux/amd64\"": invalid platform syntax for --platform=\""linux/arm64,linux/amd64\"": \""arm64,linux\"" is an invalid component of \""linux/arm64,linux/amd64\"": platform specifier component must match \""^[A-Za-z0-9_-]+$\"": invalid argument"",""response"":400}   Describe the results you received Getting a platform error (see above).  Describe the results you expected Passing, similar to:  podman build --platform=""linux/arm64,linux/amd64"" -t mytestcontainer .   podman info output yaml  podman info host: arch: arm64 buildahVersion: 1.34.1-dev cgroupControllers: - cpuset - cpu - io - memory - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.10-1.fc39.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.10, commit: ' cpuUtilization: idlePercent: 98.84 systemPercent: 0.65 userPercent: 0.51 cpus: 5 databaseBackend: sqlite distribution: distribution: fedora variant: coreos version: ""39"" eventLogger: journald freeLocks: 2020 hostname: localhost.localdomain idMappings: gidmap: null uidmap: null kernel: 6.7.5-200.fc39.aarch64 linkmode: dynamic logDriver: journald memFree: 510242816 memTotal: 2047860736 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.10.0-1.20240229100444279141.main.16.g03ce519.fc39.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.11.0-dev package: netavark-1.10.1-1.20240229113356745230.main.40.g773fd54.fc39.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.11.0-dev ociRuntime: name: crun package: crun-1.14.3-1.20240229113428746398.main.10.g31aab34.fc39.aarch64 path: /usr/bin/crun version: |- crun version UNKNOWN commit: aea8fc0fc7d0aabdbcfd1462d7bf6ea0d1e5215b rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20240220.g1e6f92b-1.fc39.aarch64 version: | pasta 0^20240220.g1e6f92b-1.fc39.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc39.aarch64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 0h 32m 30.00s variant: v8 plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 2 paused: 0 running: 0 stopped: 2 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 106769133568 graphRootUsed: 21349634048 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 10 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.0.0-dev-96f9d0867 Built: 1709164800 BuiltTime: Wed Feb 28 19:00:00 2024 GitCommit: """" GoVersion: go1.21.7 Os: linux OsArch: linux/arm64 Version: 5.0.0-dev-96f9d0867    Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | source-file | test-file,unable multi arch via curl api description trying pass platform equivalent within api getting parsing cause invalid argument message failed parse query parameter platform linux arm linux amd invalid platform syntax platform linux arm linux amd arm linux invalid component linux arm linux amd platform specifier component must match invalid argument response steps reproduce steps reproduce package containerfile tar czf context tar dir use curl command curl unix socket local share containers machine applehv sock post content type application tar content encoding gzip data binary context tar http libpod platform linux arm linux amd quay mytestcontainer cause invalid argument message failed parse query parameter platform linux arm linux amd invalid platform syntax platform linux arm linux amd arm linux invalid component linux arm linux amd platform specifier component must match invalid argument response describe results received getting platform see describe results expected passing similar platform linux arm linux amd mytestcontainer output yaml host arch arm buildahversion cgroupcontrollers cpuset cpu memory pids rdma misc cgroupmanager systemd cgroupversion conmon package conmon aarch path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution fedora variant coreos eventlogger journald freelocks hostname localhost localdomain idmappings gidmap null uidmap null kernel aarch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns aarch path libexec aardvark dns aardvark dns package netavark aarch path libexec netavark netavark ociruntime name crun package crun aab aarch path crun crun unknown aea aabdbcfd rundir crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt aarch pasta aarch pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote true slirp netns executable slirp netns package slirp netns aarch slirp netns faf libslirp slirp config max libseccomp swapfree swaptotal uptime variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search docker store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff false supports type true supports shifting true supports volatile true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime feb gitcommit goversion linux osarch linux arm container privileged rootless none upstream latest yes additional environment details additional environment details additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.95,"Unable to build multi-arch via Podman CURL / API.  Issue Description When trying to pass in `--platform` equivalent within the API, I am getting this parsing error:  {""cause"":""invalid argument"",""message"":""failed to parse query parameter 'platform': \""linux/arm64,linux/amd64\"": invalid platform syntax for --platform=\""linux/arm64,linux/amd64\"": \""arm64,linux\"" is an invalid component of \""linux/arm64,linux/amd64\"": platform specifier component must match \""^[A-Za-z0-9_-]+$\"": invalid argument"",""response"":400}   Steps to reproduce the issue Steps to reproduce the issue 1. Package any Containerfile (`tar -czf context.tar.gz -C dir .`) 2. Use the below CURL command: sh curl --unix-socket ~/.local/share/containers/podman/machine/applehv/podman.sock -X POST \ -H ""Content-Type: application/tar"" \ -H ""Content-Encoding: gzip"" \ --data-binary ""@context.tar.gz"" \ ""http://d/v4.0.0/libpod/build?platform=linux/arm64,linux/amd64&t=quay.io/mytestcontainer"" {""cause"":""invalid argument"",""message"":""failed to parse query parameter 'platform': \""linux/arm64,linux/amd64\"": invalid platform syntax for --platform=\""linux/arm64,linux/amd64\"": \""arm64,linux\"" is an invalid component of \""linux/arm64,linux/amd64\"": platform specifier component must match \""^[A-Za-z0-9_-]+$\"": invalid argument"",""response"":400}   Describe the results you received Getting a platform error (see above).  Describe the results you expected Passing, similar to:  podman build --platform=""linux/arm64,linux/amd64"" -t mytestcontainer .   podman info output yaml  podman info host: arch: arm64 buildahVersion: 1.34.1-dev cgroupControllers: - cpuset - cpu - io - memory - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.10-1.fc39.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.10, commit: ' cpuUtilization: idlePercent: 98.84 systemPercent: 0.65 userPercent: 0.51 cpus: 5 databaseBackend: sqlite distribution: distribution: fedora variant: coreos version: ""39"" eventLogger: journald freeLocks: 2020 hostname: localhost.localdomain idMappings: gidmap: null uidmap: null kernel: 6.7.5-200.fc39.aarch64 linkmode: dynamic logDriver: journald memFree: 510242816 memTotal: 2047860736 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.10.0-1.20240229100444279141.main.16.g03ce519.fc39.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.11.0-dev package: netavark-1.10.1-1.20240229113356745230.main.40.g773fd54.fc39.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.11.0-dev ociRuntime: name: crun package: crun-1.14.3-1.20240229113428746398.main.10.g31aab34.fc39.aarch64 path: /usr/bin/crun version: |- crun version UNKNOWN commit: aea8fc0fc7d0aabdbcfd1462d7bf6ea0d1e5215b rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20240220.g1e6f92b-1.fc39.aarch64 version: | pasta 0^20240220.g1e6f92b-1.fc39.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc39.aarch64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 0h 32m 30.00s variant: v8 plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 2 paused: 0 running: 0 stopped: 2 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 106769133568 graphRootUsed: 21349634048 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 10 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.0.0-dev-96f9d0867 Built: 1709164800 BuiltTime: Wed Feb 28 19:00:00 2024 GitCommit: """" GoVersion: go1.21.7 Os: linux OsArch: linux/arm64 Version: 5.0.0-dev-96f9d0867    Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
18041,podman,https://github.com/containers/podman/issues/18041,"[apiv2] play/kube test: name is in use, pod already exists","Two slightly different variants. Possibly a race in the test itself:  not ok 1202 [80-kube] POST libpod/play/kube : status # expected: 200 # actual: 500 # response: {""cause"":""pod already exists"", ""message"":""playing YAML file: adding pod to state: name \""peacefulgoldberg-pod\"" is in use: pod already exists"", ""response"":500}  and  # response: {""cause"":""pod already exists"", ""message"":""playing YAML file: encountered while bringing up pod modestfeistel-pod-deployment-pod: adding pod to state: name \""modestfeistel-pod-deployment-pod\"" is in use: pod already exists"", ""response"":500}   [APIv2] [80-kube] POST libpod/play/kube : status * fedora-37 : APIv2 test on fedora-37 (rootless) * PR #17993 * [04-03 14:43](https://api.cirrus-ci.com/v1/task/6489412033314816/logs/main.log#t--01209) * PR #17925 * [03-25 06:39](https://api.cirrus-ci.com/v1/task/5563134824415232/logs/main.log#t--01202)",test-file | source-file | source-file | test-file,apiv play kube name use pod already exists two slightly different variants possibly race kube post libpod play kube status expected actual response cause pod already exists message playing yaml adding pod state name peacefulgoldberg pod use pod already exists response response cause pod already exists message playing yaml encountered bringing pod modestfeistel pod deployment pod adding pod state name modestfeistel pod deployment pod use pod already exists response apiv kube post libpod play kube status fedora apiv fedora rootless https api cirrus task logs log https api cirrus task logs log,bug,0.9,"[apiv2] play/kube test: name is in use, pod already exists Two slightly different variants. Possibly a race in the test itself:  not ok 1202 [80-kube] POST libpod/play/kube : status # expected: 200 # actual: 500 # response: {""cause"":""pod already exists"", ""message"":""playing YAML file: adding pod to state: name \""peacefulgoldberg-pod\"" is in use: pod already exists"", ""response"":500}  and  # response: {""cause"":""pod already exists"", ""message"":""playing YAML file: encountered while bringing up pod modestfeistel-pod-deployment-pod: adding pod to state: name \""modestfeistel-pod-deployment-pod\"" is in use: pod already exists"", ""response"":500}   [APIv2] [80-kube] POST libpod/play/kube : status * fedora-37 : APIv2 test on fedora-37 (rootless) * PR #17993 * [04-03 14:43](https://api.cirrus-ci.com/v1/task/6489412033314816/logs/main.log#t--01209) * PR #17925 * [03-25 06:39](https://api.cirrus-ci.com/v1/task/5563134824415232/logs/main.log#t--01202)"
14863,podman,https://github.com/containers/podman/issues/14863,Cirrus: new API clobbers past (flake) runs,"The new logformatter URL mechanism, after #14608, has a serious flaw: flake URLs are lost. Reason: the new URLs include the **BuildID**, and **TaskName**, but not the **TaskID**. TaskID is the crucial one for linking to a flake log. Without TaskID, we have something like `/build/12345/int this that`, but the `int this that` on a successful run clobbers the one of the flaked run. @cevich let's talk about this upon your return please.",other-file | other-file,cirrus new api clobbers past flake runs new logformatter url mechanism serious flaw flake urls lost reason new urls include buildid taskname taskid taskid crucial one linking flake log without taskid something like int int successful clobbers one flaked cevich let talk upon return please,bug,0.85,"Cirrus: new API clobbers past (flake) runs The new logformatter URL mechanism, after #14608, has a serious flaw: flake URLs are lost. Reason: the new URLs include the **BuildID**, and **TaskName**, but not the **TaskID**. TaskID is the crucial one for linking to a flake log. Without TaskID, we have something like `/build/12345/int this that`, but the `int this that` on a successful run clobbers the one of the flaked run. @cevich let's talk about this upon your return please."
18618,podman,https://github.com/containers/podman/issues/18618,"podman events --filter doesn't work for ""volume"" as a key"," Issue Description The command `podman events --filter volume=volume-name` does not print any events  Steps to reproduce the issue Steps to reproduce the issue Open two terminals: 1. podman events --filter volume=volume-name 2. podman volume create volume-name  Describe the results you received No event was created  Describe the results you expected An event should have been printed  podman info output yaml $ podman version Client: Podman Engine Version: 4.5.0 API Version: 4.5.0 Go Version: go1.20.2 Built: Fri Apr 14 21:12:22 2023 OS/Arch: linux/amd64   $ podman info host: arch: amd64 buildahVersion: 1.30.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-2.fc38.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 94.82 systemPercent: 1.74 userPercent: 3.44 cpus: 20 databaseBackend: boltdb distribution: distribution: fedora variant: workstation version: ""38"" eventLogger: journald hostname: fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 kernel: 6.2.14-300.fc38.x86_64 linkmode: dynamic logDriver: journald memFree: 48852434944 memTotal: 67070021632 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.4-1.fc38.x86_64 path: /usr/bin/crun version: |- crun version 1.8.4 commit: 5a8fa99a5e41facba2eda4af12fa26313918805b rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-12.fc38.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 8589930496 swapTotal: 8589930496 uptime: 27h 41m 11.00s (Approximately 1.12 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /home/gvyas/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/gvyas/.local/share/containers/storage graphRootAllocated: 523214258176 graphRootUsed: 20388020224 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 53 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/gvyas/.local/share/containers/storage/volumes version: APIVersion: 4.5.0 Built: 1681486942 BuiltTime: Fri Apr 14 21:12:22 2023 GitCommit: """" GoVersion: go1.20.2 Os: linux OsArch: linux/amd64 Version: 4.5.0    Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_",source-file | test-file | test-file | test-file,events filter work volume key description command events filter volume volume name print events steps reproduce steps reproduce open two terminals events filter volume volume name volume create volume name describe results received event created describe results expected event printed output yaml client engine api built apr arch linux amd host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend boltdb distribution distribution fedora variant workstation eventlogger journald hostname fedora idmappings gidmap container host size container host size uidmap container host size container host size kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun facba eda rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux remotesocket path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile home gvyas config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home gvyas local share containers storage graphrootallocated graphrootused graphstatus backing filesystem btrfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home gvyas local share containers storage volumes apiversion built builttime apr gitcommit goversion linux osarch linux amd container privileged rootless none upstream latest yes additional environment details response additional information response,bug,0.9,"podman events --filter doesn't work for ""volume"" as a key  Issue Description The command `podman events --filter volume=volume-name` does not print any events  Steps to reproduce the issue Steps to reproduce the issue Open two terminals: 1. podman events --filter volume=volume-name 2. podman volume create volume-name  Describe the results you received No event was created  Describe the results you expected An event should have been printed  podman info output yaml $ podman version Client: Podman Engine Version: 4.5.0 API Version: 4.5.0 Go Version: go1.20.2 Built: Fri Apr 14 21:12:22 2023 OS/Arch: linux/amd64   $ podman info host: arch: amd64 buildahVersion: 1.30.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-2.fc38.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 94.82 systemPercent: 1.74 userPercent: 3.44 cpus: 20 databaseBackend: boltdb distribution: distribution: fedora variant: workstation version: ""38"" eventLogger: journald hostname: fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 kernel: 6.2.14-300.fc38.x86_64 linkmode: dynamic logDriver: journald memFree: 48852434944 memTotal: 67070021632 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.4-1.fc38.x86_64 path: /usr/bin/crun version: |- crun version 1.8.4 commit: 5a8fa99a5e41facba2eda4af12fa26313918805b rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-12.fc38.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 8589930496 swapTotal: 8589930496 uptime: 27h 41m 11.00s (Approximately 1.12 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /home/gvyas/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/gvyas/.local/share/containers/storage graphRootAllocated: 523214258176 graphRootUsed: 20388020224 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 53 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/gvyas/.local/share/containers/storage/volumes version: APIVersion: 4.5.0 Built: 1681486942 BuiltTime: Fri Apr 14 21:12:22 2023 GitCommit: """" GoVersion: go1.20.2 Os: linux OsArch: linux/amd64 Version: 4.5.0    Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_"
17869,podman,https://github.com/containers/podman/issues/17869,"Stats response has `""Id""` field instead of `""id""`"," Issue Description The stats API JSON response is inconsistent with Docker, because it incorrectly capitalises the `""id""` field. I discovered this when using the Rust crate [Bollard](https://github.com/fussybeaver/bollard), which reported that the `""id""` field was missing.  Steps to reproduce the issue 1. sh curl --unix-socket /var/run/docker.sock ""http://d/containers/$SOME_CONTAINER_ID/stats"" # {,""id"":"""",}  2. sh curl --unix-socket /run/user/1000/podman/podman.sock ""http://d/containers/$SOME_CONTAINER_ID/stats"" # {,""Id"":"""",}   Describe the results you received JSON response contains `""Id""` field, but no `""id""`.  Describe the results you expected JSON response should contain `""id""` field.  podman info output yaml host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: /usr/bin/conmon is owned by conmon 1:2.1.7-1 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: f633919178f6c8ee4fb41b848a056ec33f8d707d' cpuUtilization: idlePercent: 79.35 systemPercent: 5.16 userPercent: 15.48 cpus: 8 distribution: distribution: arch version: unknown eventLogger: journald hostname: REDACTED idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.2.6-arch1-1 linkmode: dynamic logDriver: journald memFree: 813850624 memTotal: 24844115968 networkBackend: netavark ociRuntime: name: crun package: /usr/bin/crun is owned by crun 1.8.1-1 path: /usr/bin/crun version: |- crun version 1.8.1 commit: f8a096be060b22ccd3d5f3ebe44108517fbf6c30 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: /usr/bin/slirp4netns is owned by slirp4netns 1.2.0-1 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.4 swapFree: 34215489536 swapTotal: 34359734272 uptime: 140h 28m 48.00s (Approximately 5.83 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: {} store: configFile: /home/REDACTED/.config/containers/storage.conf containerStore: number: 8 paused: 0 running: 8 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/REDACTED/.local/share/containers/storage graphRootAllocated: 476673212416 graphRootUsed: 276004855808 graphStatus: Backing Filesystem: f2fs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 202 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/REDACTED/.local/share/containers/storage/volumes version: APIVersion: 4.4.2 Built: 1677255177 BuiltTime: Fri Feb 24 17:12:57 2023 GitCommit: 74afe26887f814d1c39925a1624851ef3590e79c-dirty GoVersion: go1.20.1 Os: linux OsArch: linux/amd64 Version: 4.4.2   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_",source-file | source-file | source-file | test-file,stats response field instead description stats api json response inconsistent docker incorrectly capitalises field discovered rust crate bollard https github fussybeaver bollard reported field missing steps reproduce curl unix socket var docker sock http containers container stats curl unix socket user sock http containers container stats describe results received json response contains field describe results expected json response contain field output yaml host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon owned conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution arch unknown eventlogger journald hostname redacted idmappings gidmap container host size container host size uidmap container host size container host size kernel arch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun owned crun path crun crun ccd ebe fbf rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath etc containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns owned slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan volume local registries store configfile home redacted config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home redacted local share containers storage graphrootallocated graphrootused graphstatus backing filesystem native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home redacted local share containers storage volumes apiversion built builttime feb gitcommit afe dirty goversion linux osarch linux amd container privileged rootless rootless upstream latest yes additional environment details response additional information response,bug,0.95,"Stats response has `""Id""` field instead of `""id""`  Issue Description The stats API JSON response is inconsistent with Docker, because it incorrectly capitalises the `""id""` field. I discovered this when using the Rust crate [Bollard](https://github.com/fussybeaver/bollard), which reported that the `""id""` field was missing.  Steps to reproduce the issue 1. sh curl --unix-socket /var/run/docker.sock ""http://d/containers/$SOME_CONTAINER_ID/stats"" # {,""id"":"""",}  2. sh curl --unix-socket /run/user/1000/podman/podman.sock ""http://d/containers/$SOME_CONTAINER_ID/stats"" # {,""Id"":"""",}   Describe the results you received JSON response contains `""Id""` field, but no `""id""`.  Describe the results you expected JSON response should contain `""id""` field.  podman info output yaml host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - cpu - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: /usr/bin/conmon is owned by conmon 1:2.1.7-1 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: f633919178f6c8ee4fb41b848a056ec33f8d707d' cpuUtilization: idlePercent: 79.35 systemPercent: 5.16 userPercent: 15.48 cpus: 8 distribution: distribution: arch version: unknown eventLogger: journald hostname: REDACTED idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 6.2.6-arch1-1 linkmode: dynamic logDriver: journald memFree: 813850624 memTotal: 24844115968 networkBackend: netavark ociRuntime: name: crun package: /usr/bin/crun is owned by crun 1.8.1-1 path: /usr/bin/crun version: |- crun version 1.8.1 commit: f8a096be060b22ccd3d5f3ebe44108517fbf6c30 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: /usr/bin/slirp4netns is owned by slirp4netns 1.2.0-1 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.4 swapFree: 34215489536 swapTotal: 34359734272 uptime: 140h 28m 48.00s (Approximately 5.83 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: {} store: configFile: /home/REDACTED/.config/containers/storage.conf containerStore: number: 8 paused: 0 running: 8 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/REDACTED/.local/share/containers/storage graphRootAllocated: 476673212416 graphRootUsed: 276004855808 graphStatus: Backing Filesystem: f2fs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 202 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/REDACTED/.local/share/containers/storage/volumes version: APIVersion: 4.4.2 Built: 1677255177 BuiltTime: Fri Feb 24 17:12:57 2023 GitCommit: 74afe26887f814d1c39925a1624851ef3590e79c-dirty GoVersion: go1.20.1 Os: linux OsArch: linux/amd64 Version: 4.4.2   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_"
23712,podman,https://github.com/containers/podman/issues/23712,Compat API endpoints for events and container logs with `follow=true` do not send response immediately like Docker," Issue Description It seems that the Podman compat API does not immediately return an HTTP response when querying `/events` or `/containers/${id}/logs?follow=true&stdout=true&stderr=true` if no events or logs are produced yet. In this case, the client cannot determine whether the request was successful until some data is received. For example, I use [Vector](https://github.com/vectordotdev/vector), which in turn uses the [Bollard](https://github.com/fussybeaver/bollard) library to interact with the Docker API, to collect logs from Docker and Podman. When Vector starts fetching system events and container logs using the Podman 5.2.1 compat API via the socket `unix:run/podman/podman.sock`, the requests fail with error `RequestTimeoutError` after a 2 minute timeout if no response is received from Podman, causing Vector to stop monitoring the container. At the same time, everything works fine with Docker. Vector logs:  vector[19350]: 2024-08-21T17:05:19.072757Z INFO source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::sources::docker_logs: Capturing logs from now on. now=2024-08-21T17:05:19.072742638+00:00 vector[19350]: 2024-08-21T17:05:19.072925Z INFO source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::sources::docker_logs: Listening to docker log events. vector[19350]: 2024-08-21T17:05:19.114233Z INFO source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::internal_events::docker_logs: Started watching for container logs. container_id=6c7b2459bcb71617e192003e88955527b738bb20dc4b6b5cbbc798112b45b357 vector[19350]: 2024-08-21T17:07:19.098385Z ERROR source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::internal_events::docker_logs: Error in communication with Docker daemon. error=RequestTimeoutError error_type=""connection_failed"" stage=""receiving"" container_id=None internal_log_rate_limit=true vector[19350]: 2024-08-21T17:07:19.115508Z ERROR source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::internal_events::docker_logs: Internal log [Error in communication with Docker daemon.] is being suppressed to avoid flooding. vector[19350]: 2024-08-21T17:07:19.115597Z INFO source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::internal_events::docker_logs: Stopped watching for container logs. container_id=6c7b2459bcb71617e192003e88955527b738bb20dc4b6b5cbbc798112b45b357   Steps to reproduce the issue 1. Run any container that does not produce logs: `id=$(podman run -d --rm alpine sleep infinity)` 2. Get events: `curl -v --unix-socket /run/podman/podman.sock ""http://d/events"" -o -` 3. Get container logs: `curl -v --unix-socket /run/podman/podman.sock ""http://d/containers/${id}/logs?follow=true&stdout=true&stderr=true"" -o -`  Describe the results you received There is no HTTP response if no events or logs are produced:  # curl -v --unix-socket /run/podman/podman.sock ""http://d/events"" -o - * Trying /run/podman/podman.sock:0 * Connected to d (/run/podman/podman.sock) port 80 > GET /events HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > ^C # curl -v --unix-socket /run/podman/podman.sock ""http://d/containers/${id}/logs?follow=true&stdout=true&stderr=true"" -o - * Trying /run/podman/podman.sock:0 * Connected to d (/run/podman/podman.sock) port 80 > GET /containers/6c7b2459bcb71617e192003e88955527b738bb20dc4b6b5cbbc798112b45b357/logs?follow=true&stdout=true&stderr=true HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > ^C   Describe the results you expected  For events endpoint Receive the HTTP response even if there are no logs or events. Like with Podman 5.0.3:  # curl -v --unix-socket /run/podman/podman.sock ""http://d/events"" -o - * Trying /run/podman/podman.sock:0 * Connected to d (/run/podman/podman.sock) port 80 > GET /events HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Libpod-Api-Version: 5.0.3 < Server: Libpod/5.0.3 (linux) < X-Reference-Id: 0xc00006a338 < Date: Wed, 21 Aug 2024 19:16:59 GMT < Transfer-Encoding: chunked < ^C  Like with Docker:  # curl -v --unix-socket /run/docker.sock ""http://d/events"" -o - * Trying /run/docker.sock:0 * Connected to d (/run/docker.sock) port 80 > GET /events HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > < HTTP/1.1 200 OK < Api-Version: 1.46 < Content-Type: application/json < Docker-Experimental: false < Ostype: linux < Server: Docker/27.1.2 (linux) < Date: Wed, 21 Aug 2024 20:08:13 GMT < Transfer-Encoding: chunked < ^C   For container logs endpoint Recevice the HTTP response even if there are no logs or events. Like with Docker:  # curl -v --unix-socket /run/docker.sock ""http://d/containers/${id}/logs?follow=true&stdout=true&stderr=true"" -o - * Trying /run/docker.sock:0 * Connected to d (/run/docker.sock) port 80 > GET /containers/c60d242591740394e4ef8f2dd9a4264a931dffd9f357d0adb2b1e53dd0024196/logs?follow=true&stdout=true&stderr=true HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > < HTTP/1.1 200 OK < Api-Version: 1.46 < Content-Type: application/vnd.docker.multiplexed-stream < Docker-Experimental: false < Ostype: linux < Server: Docker/27.1.2 (linux) < Date: Wed, 21 Aug 2024 20:10:30 GMT < Transfer-Encoding: chunked < ^C   podman info output yaml host: arch: amd64 buildahVersion: 1.37.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids cgroupManager: cgroupfs cgroupVersion: v2 conmon: package: conmon-2.1.10-1.fc40.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.10, commit: ' cpuUtilization: idlePercent: 99.44 systemPercent: 0.27 userPercent: 0.29 cpus: 2 databaseBackend: sqlite distribution: distribution: fedora variant: container version: ""40"" eventLogger: file freeLocks: 2048 hostname: 2659a687fd77 idMappings: gidmap: null uidmap: null kernel: 5.15.0-208.159.3.2.el9uek.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 1310531584 memTotal: 3624329216 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.12.1-1.fc40.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.12.1 package: netavark-1.12.1-1.fc40.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.12.1 ociRuntime: name: crun package: crun-1.15-1.fc40.x86_64 path: /usr/bin/crun version: |- crun version 1.15 commit: e6eacaf4034e84185fd8780ac9262bbf57082278 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20240814.g61c0b0d-1.fc40.x86_64 version: | pasta 0^20240814.g61c0b0d-1.fc40.x86_64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: false path: /run/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: """" package: """" version: """" swapFree: 2147479552 swapTotal: 2147479552 uptime: 27h 22m 32.00s (Approximately 1.12 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.imagestore: /usr/lib/containers/storage overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: fuse-overlayfs-1.13-1.fc40.x86_64 Version: |- fusermount3 version: 3.16.2 fuse-overlayfs: version 1.13-dev FUSE library version 3.16.2 using FUSE kernel interface version 7.38 overlay.mountopt: nodev,fsync=0 graphRoot: /var/lib/containers/storage graphRootAllocated: 21027463168 graphRootUsed: 10851258368 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.2.1 Built: 1723593600 BuiltTime: Wed Aug 14 00:00:00 2024 GitCommit: """" GoVersion: go1.22.5 Os: linux OsArch: linux/amd64 Version: 5.2.1   Podman in a container Yes  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | test-file,compat api endpoints events container logs follow true send response immediately like docker description seems compat api immediately return http response querying events containers logs follow true stdout true stderr true events logs produced yet case client cannot determine whether successful data received example use vector https github vectordotdev vector turn uses bollard https github fussybeaver bollard library interact docker api collect logs docker vector starts fetching system events container logs compat api via socket unix sock requests fail requesttimeouterror minute timeout response received causing vector stop monitoring container time everything works fine docker vector logs vector component kind component component type docker logs vector sources docker logs capturing logs vector component kind component component type docker logs vector sources docker logs listening docker log events vector component kind component component type docker logs vector internal events docker logs started watching container logs container bcb cbbc vector component kind component component type docker logs vector internal events docker logs communication docker daemon requesttimeouterror type connection failed stage receiving container none internal log rate limit true vector component kind component component type docker logs vector internal events docker logs internal log communication docker daemon suppressed avoid flooding vector component kind component component type docker logs vector internal events docker logs stopped watching container logs container bcb cbbc steps reproduce container produce logs alpine sleep infinity get events curl unix socket sock http events get container logs curl unix socket sock http containers logs follow true stdout true stderr true describe results received http response events logs produced curl unix socket sock http events trying sock connected sock port get events http host user agent curl accept curl unix socket sock http containers logs follow true stdout true stderr true trying sock connected sock port get containers bcb cbbc logs follow true stdout true stderr true http host user agent curl accept describe results expected events endpoint receive http response even logs events like curl unix socket sock http events trying sock connected sock port get events http host user agent curl accept http api content type application json libpod api server libpod linux reference date aug gmt transfer encoding chunked like docker curl unix socket docker sock http events trying docker sock connected docker sock port get events http host user agent curl accept http api content type application json docker experimental false ostype linux server docker linux date aug gmt transfer encoding chunked container logs endpoint recevice http response even logs events like docker curl unix socket docker sock http containers logs follow true stdout true stderr true trying docker sock connected docker sock port get containers dffd adb logs follow true stdout true stderr true http host user agent curl accept http api content type application vnd docker multiplexed stream docker experimental false ostype linux server docker linux date aug gmt transfer encoding chunked output yaml host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids cgroupmanager cgroupfs cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution fedora variant container eventlogger freelocks hostname idmappings gidmap null uidmap null kernel uek linkmode dynamic logdriver memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns path libexec aardvark dns aardvark dns package netavark path libexec netavark netavark ociruntime name crun package crun path crun crun eacaf bbf rundir crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt pasta pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists false path sock rootlessnetworkcmd pasta security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable package swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat docker store configfile etc containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay imagestore containers storage overlay mount program executable fuse overlayfs package fuse overlayfs fusermount fuse overlayfs fuse library fuse kernel interface overlay mountopt nodev fsync graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff false supports type true supports shifting true supports volatile true metacopy false imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime aug gitcommit goversion linux osarch linux amd container yes privileged rootless privileged upstream latest yes additional environment details additional environment details additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.95,"Compat API endpoints for events and container logs with `follow=true` do not send response immediately like Docker  Issue Description It seems that the Podman compat API does not immediately return an HTTP response when querying `/events` or `/containers/${id}/logs?follow=true&stdout=true&stderr=true` if no events or logs are produced yet. In this case, the client cannot determine whether the request was successful until some data is received. For example, I use [Vector](https://github.com/vectordotdev/vector), which in turn uses the [Bollard](https://github.com/fussybeaver/bollard) library to interact with the Docker API, to collect logs from Docker and Podman. When Vector starts fetching system events and container logs using the Podman 5.2.1 compat API via the socket `unix:run/podman/podman.sock`, the requests fail with error `RequestTimeoutError` after a 2 minute timeout if no response is received from Podman, causing Vector to stop monitoring the container. At the same time, everything works fine with Docker. Vector logs:  vector[19350]: 2024-08-21T17:05:19.072757Z INFO source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::sources::docker_logs: Capturing logs from now on. now=2024-08-21T17:05:19.072742638+00:00 vector[19350]: 2024-08-21T17:05:19.072925Z INFO source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::sources::docker_logs: Listening to docker log events. vector[19350]: 2024-08-21T17:05:19.114233Z INFO source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::internal_events::docker_logs: Started watching for container logs. container_id=6c7b2459bcb71617e192003e88955527b738bb20dc4b6b5cbbc798112b45b357 vector[19350]: 2024-08-21T17:07:19.098385Z ERROR source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::internal_events::docker_logs: Error in communication with Docker daemon. error=RequestTimeoutError error_type=""connection_failed"" stage=""receiving"" container_id=None internal_log_rate_limit=true vector[19350]: 2024-08-21T17:07:19.115508Z ERROR source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::internal_events::docker_logs: Internal log [Error in communication with Docker daemon.] is being suppressed to avoid flooding. vector[19350]: 2024-08-21T17:07:19.115597Z INFO source{component_kind=""source"" component_id=src_podman component_type=docker_logs}: vector::internal_events::docker_logs: Stopped watching for container logs. container_id=6c7b2459bcb71617e192003e88955527b738bb20dc4b6b5cbbc798112b45b357   Steps to reproduce the issue 1. Run any container that does not produce logs: `id=$(podman run -d --rm alpine sleep infinity)` 2. Get events: `curl -v --unix-socket /run/podman/podman.sock ""http://d/events"" -o -` 3. Get container logs: `curl -v --unix-socket /run/podman/podman.sock ""http://d/containers/${id}/logs?follow=true&stdout=true&stderr=true"" -o -`  Describe the results you received There is no HTTP response if no events or logs are produced:  # curl -v --unix-socket /run/podman/podman.sock ""http://d/events"" -o - * Trying /run/podman/podman.sock:0 * Connected to d (/run/podman/podman.sock) port 80 > GET /events HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > ^C # curl -v --unix-socket /run/podman/podman.sock ""http://d/containers/${id}/logs?follow=true&stdout=true&stderr=true"" -o - * Trying /run/podman/podman.sock:0 * Connected to d (/run/podman/podman.sock) port 80 > GET /containers/6c7b2459bcb71617e192003e88955527b738bb20dc4b6b5cbbc798112b45b357/logs?follow=true&stdout=true&stderr=true HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > ^C   Describe the results you expected  For events endpoint Receive the HTTP response even if there are no logs or events. Like with Podman 5.0.3:  # curl -v --unix-socket /run/podman/podman.sock ""http://d/events"" -o - * Trying /run/podman/podman.sock:0 * Connected to d (/run/podman/podman.sock) port 80 > GET /events HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Libpod-Api-Version: 5.0.3 < Server: Libpod/5.0.3 (linux) < X-Reference-Id: 0xc00006a338 < Date: Wed, 21 Aug 2024 19:16:59 GMT < Transfer-Encoding: chunked < ^C  Like with Docker:  # curl -v --unix-socket /run/docker.sock ""http://d/events"" -o - * Trying /run/docker.sock:0 * Connected to d (/run/docker.sock) port 80 > GET /events HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > < HTTP/1.1 200 OK < Api-Version: 1.46 < Content-Type: application/json < Docker-Experimental: false < Ostype: linux < Server: Docker/27.1.2 (linux) < Date: Wed, 21 Aug 2024 20:08:13 GMT < Transfer-Encoding: chunked < ^C   For container logs endpoint Recevice the HTTP response even if there are no logs or events. Like with Docker:  # curl -v --unix-socket /run/docker.sock ""http://d/containers/${id}/logs?follow=true&stdout=true&stderr=true"" -o - * Trying /run/docker.sock:0 * Connected to d (/run/docker.sock) port 80 > GET /containers/c60d242591740394e4ef8f2dd9a4264a931dffd9f357d0adb2b1e53dd0024196/logs?follow=true&stdout=true&stderr=true HTTP/1.1 > Host: d > User-Agent: curl/8.6.0 > Accept: */* > < HTTP/1.1 200 OK < Api-Version: 1.46 < Content-Type: application/vnd.docker.multiplexed-stream < Docker-Experimental: false < Ostype: linux < Server: Docker/27.1.2 (linux) < Date: Wed, 21 Aug 2024 20:10:30 GMT < Transfer-Encoding: chunked < ^C   podman info output yaml host: arch: amd64 buildahVersion: 1.37.1 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids cgroupManager: cgroupfs cgroupVersion: v2 conmon: package: conmon-2.1.10-1.fc40.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.10, commit: ' cpuUtilization: idlePercent: 99.44 systemPercent: 0.27 userPercent: 0.29 cpus: 2 databaseBackend: sqlite distribution: distribution: fedora variant: container version: ""40"" eventLogger: file freeLocks: 2048 hostname: 2659a687fd77 idMappings: gidmap: null uidmap: null kernel: 5.15.0-208.159.3.2.el9uek.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 1310531584 memTotal: 3624329216 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.12.1-1.fc40.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.12.1 package: netavark-1.12.1-1.fc40.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.12.1 ociRuntime: name: crun package: crun-1.15-1.fc40.x86_64 path: /usr/bin/crun version: |- crun version 1.15 commit: e6eacaf4034e84185fd8780ac9262bbf57082278 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20240814.g61c0b0d-1.fc40.x86_64 version: | pasta 0^20240814.g61c0b0d-1.fc40.x86_64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: false path: /run/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: """" package: """" version: """" swapFree: 2147479552 swapTotal: 2147479552 uptime: 27h 22m 32.00s (Approximately 1.12 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.imagestore: /usr/lib/containers/storage overlay.mount_program: Executable: /usr/bin/fuse-overlayfs Package: fuse-overlayfs-1.13-1.fc40.x86_64 Version: |- fusermount3 version: 3.16.2 fuse-overlayfs: version 1.13-dev FUSE library version 3.16.2 using FUSE kernel interface version 7.38 overlay.mountopt: nodev,fsync=0 graphRoot: /var/lib/containers/storage graphRootAllocated: 21027463168 graphRootUsed: 10851258368 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.2.1 Built: 1723593600 BuiltTime: Wed Aug 14 00:00:00 2024 GitCommit: """" GoVersion: go1.22.5 Os: linux OsArch: linux/amd64 Version: 5.2.1   Podman in a container Yes  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
16360,podman,https://github.com/containers/podman/issues/16360,Podman socket: Build API produces different results then Docker's Build API,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> As i am migrating from OL7 -> OL8 (RHEL based), i am wanting to keep my current code working - for that i am relying on podman socket to keep my docker-compose / docker py usage functional. Docker-compose seems fine but docker-py is not, there is an issue where the return values from the build API is different: https://github.com/containers/podman/blob/40e8bcb8482f2a1f60b93524ceda05770d20739e/pkg/api/handlers/compat/images_build.go#L803 The final response includes 2 lines rather than a single line, as this `aux` object is added. This isn't really an issue and i can workaround it, but was wondering if it would be changed to be in line with docker API. **Steps to reproduce the issue:** 1. Use docker py to build an image with docker and podman socket 2. See that the final response from the api is different **Describe the results you received:** {""aux"":{""ID"":""sha256:2d49cc4bc02bb457a9459736c461c52944e68e2a40cf2bb1207494b2b72c5f82""}}\n{""stream"":""Successfully built 2d49cc4bc02b\\n""}\n **Describe the results you expected:** {""stream"":""Successfully built 2d49cc4bc02b\\n""}\n **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Client: Podman Engine Version: 4.1.1 API Version: 4.1.1 Go Version: go1.17.12 Built: Wed Oct 26 15:12:06 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  host: arch: amd64 buildahVersion: 1.26.2 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.3-1.module+el8.6.0+20857+bf01bdf2.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.3, commit: 0e2e290c54cc97af44a8b96f004ff81e8abd8956' cpuUtilization: idlePercent: 98.48 systemPercent: 0.21 userPercent: 1.31 cpus: 104 distribution: distribution: '""ol""' variant: server version: ""8.6"" eventLogger: file hostname: cicd-bm-standard-ol8 idMappings: gidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 165536 size: 65536 uidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 165536 size: 65536 kernel: 5.4.17-2136.310.7.1.el8uek.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 630402412544 memTotal: 809608286208 networkBackend: cni ociRuntime: name: runc package: runc-1.1.3-2.module+el8.6.0+20857+bf01bdf2.x86_64 path: /usr/bin/runc version: |- runc version 1.1.3 spec: 1.0.2-dev go: go1.17.12 libseccomp: 2.5.2 os: linux remoteSocket: path: /run/user/1001/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /bin/slirp4netns package: slirp4netns-1.2.0-2.module+el8.6.0+20857+bf01bdf2.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 8539598848 swapTotal: 8539598848 uptime: 4h 35m 58.6s (Approximately 0.17 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - container-registry.oracle.com - docker.io store: configFile: /home/oracle/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/oracle/.local/share/containers/storage graphRootAllocated: 2187084447744 graphRootUsed: 178915131392 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /run/user/1001/containers volumePath: /home/oracle/.local/share/containers/storage/volumes version: APIVersion: 4.1.1 Built: 1666797126 BuiltTime: Wed Oct 26 15:12:06 2022 GitCommit: """" GoVersion: go1.17.12 Os: linux OsArch: linux/amd64 Version: 4.1.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman` or `brew info podman`):**  podman-4.1.1-7.module+el8.6.0+20857+bf01bdf2.x86_64  Have tested with OL9 which is 4.2.x podman **Additional environment details (AWS, VirtualBox, physical, etc.):** Cloud based vm",source-file,socket api produces different results docker api bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description briefly describe paragraphs migrating rhel based wanting keep current working relying socket keep docker compose docker usage functional docker compose seems fine docker return values api different https github containers blob bcb ceda pkg api handlers compat images final response includes lines rather single aux object added really workaround wondering would changed docker api steps reproduce use docker image docker socket see final response api different describe results received aux sha stream successfully built describe results expected stream successfully built additional information deem important happens occasionally output client engine api built oct arch linux amd output host arch amd buildahversion cgroupcontrollers cgroupmanager cgroupfs cgroupversion conmon package conmon module bdf path conmon conmon abd cpuutilization idlepercent systempercent userpercent cpus distribution distribution variant server eventlogger hostname cicd standard idmappings gidmap container host size container host size uidmap container host size container host size kernel uek linkmode dynamic logdriver memfree memtotal networkbackend cni ociruntime name runc package runc module bdf path runc runc spec libseccomp linux remotesocket path user sock security apparmorenabled false capabilities cap raw cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns module bdf slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins log none passthrough journald network bridge macvlan ipvlan volume local registries search container registry oracle docker store configfile home oracle config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home oracle local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff false supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers volumepath home oracle local share containers storage volumes apiversion built builttime oct gitcommit goversion linux osarch linux amd package output rpm apt list brew module bdf tested additional environment details aws virtualbox physical etc cloud based,bug,0.9,"Podman socket: Build API produces different results then Docker's Build API <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> As i am migrating from OL7 -> OL8 (RHEL based), i am wanting to keep my current code working - for that i am relying on podman socket to keep my docker-compose / docker py usage functional. Docker-compose seems fine but docker-py is not, there is an issue where the return values from the build API is different: https://github.com/containers/podman/blob/40e8bcb8482f2a1f60b93524ceda05770d20739e/pkg/api/handlers/compat/images_build.go#L803 The final response includes 2 lines rather than a single line, as this `aux` object is added. This isn't really an issue and i can workaround it, but was wondering if it would be changed to be in line with docker API. **Steps to reproduce the issue:** 1. Use docker py to build an image with docker and podman socket 2. See that the final response from the api is different **Describe the results you received:** {""aux"":{""ID"":""sha256:2d49cc4bc02bb457a9459736c461c52944e68e2a40cf2bb1207494b2b72c5f82""}}\n{""stream"":""Successfully built 2d49cc4bc02b\\n""}\n **Describe the results you expected:** {""stream"":""Successfully built 2d49cc4bc02b\\n""}\n **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Client: Podman Engine Version: 4.1.1 API Version: 4.1.1 Go Version: go1.17.12 Built: Wed Oct 26 15:12:06 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  host: arch: amd64 buildahVersion: 1.26.2 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.3-1.module+el8.6.0+20857+bf01bdf2.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.3, commit: 0e2e290c54cc97af44a8b96f004ff81e8abd8956' cpuUtilization: idlePercent: 98.48 systemPercent: 0.21 userPercent: 1.31 cpus: 104 distribution: distribution: '""ol""' variant: server version: ""8.6"" eventLogger: file hostname: cicd-bm-standard-ol8 idMappings: gidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 165536 size: 65536 uidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 165536 size: 65536 kernel: 5.4.17-2136.310.7.1.el8uek.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 630402412544 memTotal: 809608286208 networkBackend: cni ociRuntime: name: runc package: runc-1.1.3-2.module+el8.6.0+20857+bf01bdf2.x86_64 path: /usr/bin/runc version: |- runc version 1.1.3 spec: 1.0.2-dev go: go1.17.12 libseccomp: 2.5.2 os: linux remoteSocket: path: /run/user/1001/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /bin/slirp4netns package: slirp4netns-1.2.0-2.module+el8.6.0+20857+bf01bdf2.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 8539598848 swapTotal: 8539598848 uptime: 4h 35m 58.6s (Approximately 0.17 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - container-registry.oracle.com - docker.io store: configFile: /home/oracle/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/oracle/.local/share/containers/storage graphRootAllocated: 2187084447744 graphRootUsed: 178915131392 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /run/user/1001/containers volumePath: /home/oracle/.local/share/containers/storage/volumes version: APIVersion: 4.1.1 Built: 1666797126 BuiltTime: Wed Oct 26 15:12:06 2022 GitCommit: """" GoVersion: go1.17.12 Os: linux OsArch: linux/amd64 Version: 4.1.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman` or `brew info podman`):**  podman-4.1.1-7.module+el8.6.0+20857+bf01bdf2.x86_64  Have tested with OL9 which is 4.2.x podman **Additional environment details (AWS, VirtualBox, physical, etc.):** Cloud based vm"
21754,podman,https://github.com/containers/podman/issues/21754,docker 25 CLI is unable to run a container in quay.io/podman/upstream: default networking argument issue," Issue Description Hi, When using a Docker 25 CLI targetting a podman socket from `quay.io/podman/upstream`, it fails with:  docker: Error response from daemon: container create: invalid config provided: networks and static ip/mac address can only be used with Bridge mode networking.  The docker CLI 24 (and older) does work fine. Investigating a bit with socat the difference between the API calls, I end up with this request from docker 24 CLI (for the `POST /v1.41/containers/create` API call):  {""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":true,""AttachStdout"":true,""AttachStderr"":true,""Tty"":true,""OpenStdin"":true,""StdinOnce"":true,""Env"":null,""Cmd"":null,""Image"":""quay.io/fedora/fedora"",""Volumes"":{},""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":{},""HostConfig"":{""Binds"":null,""ContainerIDFile"":"""",""LogConfig"":{""Type"":"""",""Config"":{}},""NetworkMode"":""default"",""PortBindings"":{},""RestartPolicy"":{""Name"":""no"",""MaximumRetryCount"":0},""AutoRemove"":true,""VolumeDriver"":"""",""VolumesFrom"":null,""ConsoleSize"":[26,227],""CapAdd"":null,""CapDrop"":null,""CgroupnsMode"":"""",""Dns"":[],""DnsOptions"":[],""DnsSearch"":[],""ExtraHosts"":null,""GroupAdd"":null,""IpcMode"":"""",""Cgroup"":"""",""Links"":null,""OomScoreAdj"":0,""PidMode"":"""",""Privileged"":false,""PublishAllPorts"":false,""ReadonlyRootfs"":false,""SecurityOpt"":null,""UTSMode"":"""",""UsernsMode"":"""",""ShmSize"":0,""Isolation"":"""",""CpuShares"":0,""Memory"":0,""NanoCpus"":0,""CgroupParent"":"""",""BlkioWeight"":0,""BlkioWeightDevice"":[],""BlkioDeviceReadBps"":[],""BlkioDeviceWriteBps"":[],""BlkioDeviceReadIOps"":[],""BlkioDeviceWriteIOps"":[],""CpuPeriod"":0,""CpuQuota"":0,""CpuRealtimePeriod"":0,""CpuRealtimeRuntime"":0,""CpusetCpus"":"""",""CpusetMems"":"""",""Devices"":[],""DeviceCgroupRules"":null,""DeviceRequests"":null,""MemoryReservation"":0,""MemorySwap"":0,""MemorySwappiness"":-1,""OomKillDisable"":false,""PidsLimit"":0,""Ulimits"":null,""CpuCount"":0,""CpuPercent"":0,""IOMaximumIOps"":0,""IOMaximumBandwidth"":0,""MaskedPaths"":null,""ReadonlyPaths"":null},""NetworkingConfig"":{""EndpointsConfig"":{  and this request from docker 25 CLI:  {""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":true,""AttachStdout"":true,""AttachStderr"":true,""Tty"":true,""OpenStdin"":true,""StdinOnce"":true,""Env"":null,""Cmd"":null,""Image"":""quay.io/fedora/fedora"",""Volumes"":{},""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":{},""HostConfig"":{""Binds"":null,""ContainerIDFile"":"""",""LogConfig"":{""Type"":"""",""Config"":{}},""NetworkMode"":""default"",""PortBindings"":{},""RestartPolicy"":{""Name"":""no"",""MaximumRetryCount"":0},""AutoRemove"":true,""VolumeDriver"":"""",""VolumesFrom"":null,""ConsoleSize"":[26,227],""CapAdd"":null,""CapDrop"":null,""CgroupnsMode"":"""",""Dns"":[],""DnsOptions"":[],""DnsSearch"":[],""ExtraHosts"":null,""GroupAdd"":null,""IpcMode"":"""",""Cgroup"":"""",""Links"":null,""OomScoreAdj"":0,""PidMode"":"""",""Privileged"":false,""PublishAllPorts"":false,""ReadonlyRootfs"":false,""SecurityOpt"":null,""UTSMode"":"""",""UsernsMode"":"""",""ShmSize"":0,""Isolation"":"""",""CpuShares"":0,""Memory"":0,""NanoCpus"":0,""CgroupParent"":"""",""BlkioWeight"":0,""BlkioWeightDevice"":[],""BlkioDeviceReadBps"":[],""BlkioDeviceWriteBps"":[],""BlkioDeviceReadIOps"":[],""BlkioDeviceWriteIOps"":[],""CpuPeriod"":0,""CpuQuota"":0,""CpuRealtimePeriod"":0,""CpuRealtimeRuntime"":0,""CpusetCpus"":"""",""CpusetMems"":"""",""Devices"":[],""DeviceCgroupRules"":null,""DeviceRequests"":null,""MemoryReservation"":0,""MemorySwap"":0,""MemorySwappiness"":-1,""OomKillDisable"":false,""PidsLimit"":0,""Ulimits"":[],""CpuCount"":0,""CpuPercent"":0,""IOMaximumIOps"":0,""IOMaximumBandwidth"":0,""MaskedPaths"":null,""ReadonlyPaths"":null},""NetworkingConfig"":{""EndpointsConfig"":{""default"":{""IPAMConfig"":null,""Links"":null,""Aliases"":null,""MacAddress"":"""",""NetworkID"":"""",""EndpointID"":"""",""Gateway"":"""",""IPAddress"":"""",""IPPrefixLen"":0,""IPv6Gateway"":"""",""GlobalIPv6Address"":"""",""GlobalIPv6PrefixLen"":0,""DriverOpts"":null,""DNSNames"":null  Using ""jq"" to pretty print it and show the differences, I ended up with this:  rgeissler@ncerndobedev6097:/tmp> diff -u <(cat docker-24|jq) <(cat docker-25|jq) 7:11PM  /proc/self/fd/12 2024-02-19 19:11:54.051981352 +0000  /proc/self/fd/13 2024-02-19 19:11:54.055981487 +0000 @@ -81,7 +81,7 @@ ""MemorySwappiness"": -1, ""OomKillDisable"": false, ""PidsLimit"": 0, - ""Ulimits"": null, + ""Ulimits"": [], ""CpuCount"": 0, ""CpuPercent"": 0, ""IOMaximumIOps"": 0, @@ -90,6 +90,23 @@ ""ReadonlyPaths"": null }, ""NetworkingConfig"": { - ""EndpointsConfig"": {} + ""EndpointsConfig"": { + ""default"": { + ""IPAMConfig"": null, + ""Links"": null, + ""Aliases"": null, + ""MacAddress"": """", + ""NetworkID"": """", + ""EndpointID"": """", + ""Gateway"": """", + ""IPAddress"": """", + ""IPPrefixLen"": 0, + ""IPv6Gateway"": """", + ""GlobalIPv6Address"": """", + ""GlobalIPv6PrefixLen"": 0, + ""DriverOpts"": null, + ""DNSNames"": null + } + } } }  So the ""root cause"" is this new default ""EndpointsConfig"" struct, which seems all default initialized and which podman somehow interprets differently from an empty `{}` json config. I didn't check the code yet to see if there is a quick fix for this issue. Cheers, Romain  Steps to reproduce the issue Steps to reproduce the issue 1. Start a `quay.io/podman/upstream` container start a podman server:  > podman run -t -i --rm --privileged --name=podman-server -v /shared-volume --pull=always quay.io/podman/upstream podman system service -t 0 unix:shared-volume/podman.sock Trying to pull quay.io/podman/upstream:latest Getting image source signatures Copying blob sha256:b2013b443c422f98f009bfb9f930cc424428f8ccb694c84a26ebeb98891687f9 Copying blob sha256:cf73a40571609daa501dab6a62c1d08ca1665278b2355f5a36424804281c62fe Copying blob sha256:439ec636831d395b84ce0dfd6390420c60a8aa2a128a88b7dc55236a5e54c7a1 Copying blob sha256:2026b963063adee0348d722192a5761e34b449d666f6f79a687818f40a96a67f Copying blob sha256:718a00fe32127ad01ddab9fc4b7c968ab2679c92c6385ac6865ae6e2523275e4 Copying blob sha256:d2ea58b809bcf20a5fa73f3bce6c4ac3f371fbd010700dc0979f495f53b7fc76 Copying blob sha256:e16106bb651e790ca91447e2fc47c5a2f86e4824cd3bada6d63419f9801e4f93 Copying blob sha256:7323cd5de043ae967491a338060d6d1c51eed17c19bda023d76f72b326d7b5bf Copying blob sha256:39cd8764a88b128c21ab1816efa5c0179a803ed18ada3aa9c5f09d23b231787f Copying config sha256:8739df1320065867713c219a7efdb999e478796c0059e25143f10f54272fe833 Writing manifest to image destination  2. Try to run a container inside the first one, using a docker 25 CLI. I used explicitly `--oom-score-adj=1000` to workaround the issue fixed by #21487:  > podman run -t -i --rm --pull=always --volumes-from=podman-server -e DOCKER_HOST=unix:shared-volume/podman.sock docker:25-cli docker run -t -i --rm --oom-score-adj=1000 quay.io/fedora/fedora Trying to pull docker.io/library/docker:25-cli Getting image source signatures Copying blob sha256:f23a00be1976186eef218bb9b79ab99203e0c5b235c1b49e77f3ac3264793d78 Copying blob sha256:4abcf20661432fb2d719aaf90656f55c287f8ca915dc1c92ec14ff61e67fbaf8 Copying blob sha256:1bd9561ee09aa7423609ac837068a53ad4a8fd35b8b6d51528d78cb126eb3b07 Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 Copying blob sha256:a48a116699ba1fe77921e9ab9fef2dc65016ac2e483b07f03921526b8a0fcf79 Copying blob sha256:41dc1292823582d19d9bc523915a590652c16d3bedc6099b345ec38efd77e6a0 Copying blob sha256:e56d49cdf5732fc93fbea227838e14f9772a369a669592554ca37cf4695be03d Copying blob sha256:b6735844810a03df9d76e5aa58d3df2f1c56f6c208093eba5f88e5806f1cda04 Copying blob sha256:49704df22e8621ca86fd75cb61b8f23ee280754df0048a7bf46cd8b96ec2551f Copying blob sha256:b0f5f50d82ecbeeeea34901bdac4b25948f5f7146f2842d8a7aeb9a730459567 Copying config sha256:e95f54c1fcc216bc7d10270705e5ce8f98504f69d2afba666d6ce12e940da2f6 Writing manifest to image destination Unable to find image 'quay.io/fedora/fedora:latest' locally 718a00fe3212: Download complete 368a084ba17d: Download complete docker: Error response from daemon: container create: invalid config provided: networks and static ip/mac address can only be used with Bridge mode networking. See 'docker run --help'.  3. Doing exactly the same thing, with `docker:24-cli` instead works just fine:  > podman run -t -i --rm --pull=always --volumes-from=podman-server -e DOCKER_HOST=unix:shared-volume/podman.sock docker:24-cli docker run -t -i --rm --oom-score-adj=1000 quay.io/fedora/fedora Trying to pull docker.io/library/docker:24-cli Getting image source signatures Copying blob sha256:4abcf20661432fb2d719aaf90656f55c287f8ca915dc1c92ec14ff61e67fbaf8 Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 Copying blob sha256:1db5a4f146e2df1f17a2c0db7ffd672b18d1750d31c7e58e352a6536d4b7ad52 Copying blob sha256:248ec8ed73b325a9cff9ec3c5bbd2c249065ee96053dfc3beafb911ef652a195 Copying blob sha256:5aed6b72066db35b8929c11c552f9e827431de2b2de62b4384a1eaed88221787 Copying blob sha256:9908927dc97522b6d63aaaf9953c4095be9b24a1d080edb1ada9124d56bf41ad Copying blob sha256:d280e8e81156b63b7306ac0701738e22b333c7a26bdd96ddafb3ec8f607d2a32 Copying blob sha256:97f6ee5ccb7fa02811eb89d903666095e18e38c42a635369912f9ba0fd11e6eb Copying blob sha256:d4462dfff57f9ac45d562ae18d1ca53fef4918ae18e003d21ebf960b3ade6f94 Copying blob sha256:a474f84a4abb535fa3a05ee5a59bff31a53d0857d4d53bab82a9f2f3684c4c7c Copying config sha256:b4e4d47cb84703dc6042823b7e29e3111074beb09b50848a31cdb9cd9565ed9a Writing manifest to image destination [root@56d0c302cd66 /]# ^C [root@56d0c302cd66 /]# exit exit   Describe the results you received Podman cannot be used with docker 25 CLI (in container mode) while it was working with docker 24 CLI.  Describe the results you expected Podman can be used with docker 25 CLI (in container mode).  podman info output yaml Tried on `quay.io/podman/upstream` on an up to date x86_64 RHEL 9.   Podman in a container Yes  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | test-file | source-file | test-file | source-file | test-file,docker cli unable container quay upstream default networking argument description docker cli targetting socket quay upstream fails docker response daemon container create invalid config provided networks static mac address used bridge mode networking docker cli older work fine investigating bit socat difference api calls end docker cli post containers create api call hostname domainname user attachstdin true attachstdout true attachstderr true tty true openstdin true stdinonce true env null cmd null image quay fedora fedora volumes workingdir entrypoint null onbuild null labels hostconfig binds null containeridfile logconfig type config networkmode default portbindings restartpolicy name maximumretrycount autoremove true volumedriver volumesfrom null consolesize capadd null capdrop null cgroupnsmode dns dnsoptions dnssearch extrahosts null groupadd null ipcmode cgroup links null oomscoreadj pidmode privileged false publishallports false readonlyrootfs false securityopt null utsmode usernsmode shmsize isolation cpushares memory nanocpus cgroupparent blkioweight blkioweightdevice blkiodevicereadbps blkiodevicewritebps blkiodevicereadiops blkiodevicewriteiops cpuperiod cpuquota cpurealtimeperiod cpurealtimeruntime cpusetcpus cpusetmems devices devicecgrouprules null devicerequests null memoryreservation memoryswap memoryswappiness oomkilldisable false pidslimit ulimits null cpucount cpupercent iomaximumiops iomaximumbandwidth maskedpaths null readonlypaths null networkingconfig endpointsconfig docker cli hostname domainname user attachstdin true attachstdout true attachstderr true tty true openstdin true stdinonce true env null cmd null image quay fedora fedora volumes workingdir entrypoint null onbuild null labels hostconfig binds null containeridfile logconfig type config networkmode default portbindings restartpolicy name maximumretrycount autoremove true volumedriver volumesfrom null consolesize capadd null capdrop null cgroupnsmode dns dnsoptions dnssearch extrahosts null groupadd null ipcmode cgroup links null oomscoreadj pidmode privileged false publishallports false readonlyrootfs false securityopt null utsmode usernsmode shmsize isolation cpushares memory nanocpus cgroupparent blkioweight blkioweightdevice blkiodevicereadbps blkiodevicewritebps blkiodevicereadiops blkiodevicewriteiops cpuperiod cpuquota cpurealtimeperiod cpurealtimeruntime cpusetcpus cpusetmems devices devicecgrouprules null devicerequests null memoryreservation memoryswap memoryswappiness oomkilldisable false pidslimit ulimits cpucount cpupercent iomaximumiops iomaximumbandwidth maskedpaths null readonlypaths null networkingconfig endpointsconfig default ipamconfig null links null aliases null macaddress networkid endpointid gateway ipaddress ipprefixlen ipv gateway globalipv address globalipv prefixlen driveropts null dnsnames null pretty print show differences ended rgeissler ncerndobedev tmp diff cat docker cat docker proc self proc self memoryswappiness oomkilldisable false pidslimit ulimits null ulimits cpucount cpupercent iomaximumiops readonlypaths null networkingconfig endpointsconfig endpointsconfig default ipamconfig null links null aliases null macaddress networkid endpointid gateway ipaddress ipprefixlen ipv gateway globalipv address globalipv prefixlen driveropts null dnsnames null root cause new default endpointsconfig struct seems default initialized somehow interprets differently empty json config check yet see quick cheers romain steps reproduce steps reproduce start quay upstream container start server privileged name server shared volume always quay upstream system service unix shared volume sock trying quay upstream latest getting image signatures copying blob sha bfb ccb ebeb copying blob sha daa dab copying blob sha dfd copying blob sha adee copying blob sha ddab copying blob sha bcf bce fbd copying blob sha bada copying blob sha eed bda copying blob sha efa ada copying config sha efdb writing manifest image destination container inside first one docker cli used explicitly oom score adj workaround fixed always volumes server docker host unix shared volume sock docker cli docker oom score adj quay fedora fedora trying docker library docker cli getting image signatures copying blob sha eef copying blob sha abcf aaf fbaf copying blob sha copying blob sha cfa cdb acc copying blob sha fef fcf copying blob sha bedc efd copying blob sha cdf fbea copying blob sha eba cda copying blob sha copying blob sha ecbeeeea bdac aeb copying config sha fcc afba writing manifest image destination unable find image quay fedora fedora latest locally download complete download complete docker response daemon container create invalid config provided networks static mac address used bridge mode networking see docker help exactly thing docker cli instead works fine always volumes server docker host unix shared volume sock docker cli docker oom score adj quay fedora fedora trying docker library docker cli getting image signatures copying blob sha abcf aaf fbaf copying blob sha cfa cdb acc copying blob sha ffd copying blob sha cff bbd dfc beafb copying blob sha aed eaed copying blob sha aaaf edb ada copying blob sha bdd ddafb copying blob sha ccb copying blob sha dfff fef ebf ade copying blob sha abb bff bab copying config sha beb cdb writing manifest image destination root root exit exit describe results received cannot used docker cli container mode working docker cli describe results expected used docker cli container mode output yaml tried quay upstream date rhel container yes privileged rootless rootless upstream latest yes additional environment details response additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.95,"docker 25 CLI is unable to run a container in quay.io/podman/upstream: default networking argument issue  Issue Description Hi, When using a Docker 25 CLI targetting a podman socket from `quay.io/podman/upstream`, it fails with:  docker: Error response from daemon: container create: invalid config provided: networks and static ip/mac address can only be used with Bridge mode networking.  The docker CLI 24 (and older) does work fine. Investigating a bit with socat the difference between the API calls, I end up with this request from docker 24 CLI (for the `POST /v1.41/containers/create` API call):  {""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":true,""AttachStdout"":true,""AttachStderr"":true,""Tty"":true,""OpenStdin"":true,""StdinOnce"":true,""Env"":null,""Cmd"":null,""Image"":""quay.io/fedora/fedora"",""Volumes"":{},""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":{},""HostConfig"":{""Binds"":null,""ContainerIDFile"":"""",""LogConfig"":{""Type"":"""",""Config"":{}},""NetworkMode"":""default"",""PortBindings"":{},""RestartPolicy"":{""Name"":""no"",""MaximumRetryCount"":0},""AutoRemove"":true,""VolumeDriver"":"""",""VolumesFrom"":null,""ConsoleSize"":[26,227],""CapAdd"":null,""CapDrop"":null,""CgroupnsMode"":"""",""Dns"":[],""DnsOptions"":[],""DnsSearch"":[],""ExtraHosts"":null,""GroupAdd"":null,""IpcMode"":"""",""Cgroup"":"""",""Links"":null,""OomScoreAdj"":0,""PidMode"":"""",""Privileged"":false,""PublishAllPorts"":false,""ReadonlyRootfs"":false,""SecurityOpt"":null,""UTSMode"":"""",""UsernsMode"":"""",""ShmSize"":0,""Isolation"":"""",""CpuShares"":0,""Memory"":0,""NanoCpus"":0,""CgroupParent"":"""",""BlkioWeight"":0,""BlkioWeightDevice"":[],""BlkioDeviceReadBps"":[],""BlkioDeviceWriteBps"":[],""BlkioDeviceReadIOps"":[],""BlkioDeviceWriteIOps"":[],""CpuPeriod"":0,""CpuQuota"":0,""CpuRealtimePeriod"":0,""CpuRealtimeRuntime"":0,""CpusetCpus"":"""",""CpusetMems"":"""",""Devices"":[],""DeviceCgroupRules"":null,""DeviceRequests"":null,""MemoryReservation"":0,""MemorySwap"":0,""MemorySwappiness"":-1,""OomKillDisable"":false,""PidsLimit"":0,""Ulimits"":null,""CpuCount"":0,""CpuPercent"":0,""IOMaximumIOps"":0,""IOMaximumBandwidth"":0,""MaskedPaths"":null,""ReadonlyPaths"":null},""NetworkingConfig"":{""EndpointsConfig"":{  and this request from docker 25 CLI:  {""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":true,""AttachStdout"":true,""AttachStderr"":true,""Tty"":true,""OpenStdin"":true,""StdinOnce"":true,""Env"":null,""Cmd"":null,""Image"":""quay.io/fedora/fedora"",""Volumes"":{},""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":{},""HostConfig"":{""Binds"":null,""ContainerIDFile"":"""",""LogConfig"":{""Type"":"""",""Config"":{}},""NetworkMode"":""default"",""PortBindings"":{},""RestartPolicy"":{""Name"":""no"",""MaximumRetryCount"":0},""AutoRemove"":true,""VolumeDriver"":"""",""VolumesFrom"":null,""ConsoleSize"":[26,227],""CapAdd"":null,""CapDrop"":null,""CgroupnsMode"":"""",""Dns"":[],""DnsOptions"":[],""DnsSearch"":[],""ExtraHosts"":null,""GroupAdd"":null,""IpcMode"":"""",""Cgroup"":"""",""Links"":null,""OomScoreAdj"":0,""PidMode"":"""",""Privileged"":false,""PublishAllPorts"":false,""ReadonlyRootfs"":false,""SecurityOpt"":null,""UTSMode"":"""",""UsernsMode"":"""",""ShmSize"":0,""Isolation"":"""",""CpuShares"":0,""Memory"":0,""NanoCpus"":0,""CgroupParent"":"""",""BlkioWeight"":0,""BlkioWeightDevice"":[],""BlkioDeviceReadBps"":[],""BlkioDeviceWriteBps"":[],""BlkioDeviceReadIOps"":[],""BlkioDeviceWriteIOps"":[],""CpuPeriod"":0,""CpuQuota"":0,""CpuRealtimePeriod"":0,""CpuRealtimeRuntime"":0,""CpusetCpus"":"""",""CpusetMems"":"""",""Devices"":[],""DeviceCgroupRules"":null,""DeviceRequests"":null,""MemoryReservation"":0,""MemorySwap"":0,""MemorySwappiness"":-1,""OomKillDisable"":false,""PidsLimit"":0,""Ulimits"":[],""CpuCount"":0,""CpuPercent"":0,""IOMaximumIOps"":0,""IOMaximumBandwidth"":0,""MaskedPaths"":null,""ReadonlyPaths"":null},""NetworkingConfig"":{""EndpointsConfig"":{""default"":{""IPAMConfig"":null,""Links"":null,""Aliases"":null,""MacAddress"":"""",""NetworkID"":"""",""EndpointID"":"""",""Gateway"":"""",""IPAddress"":"""",""IPPrefixLen"":0,""IPv6Gateway"":"""",""GlobalIPv6Address"":"""",""GlobalIPv6PrefixLen"":0,""DriverOpts"":null,""DNSNames"":null  Using ""jq"" to pretty print it and show the differences, I ended up with this:  rgeissler@ncerndobedev6097:/tmp> diff -u <(cat docker-24|jq) <(cat docker-25|jq) 7:11PM  /proc/self/fd/12 2024-02-19 19:11:54.051981352 +0000  /proc/self/fd/13 2024-02-19 19:11:54.055981487 +0000 @@ -81,7 +81,7 @@ ""MemorySwappiness"": -1, ""OomKillDisable"": false, ""PidsLimit"": 0, - ""Ulimits"": null, + ""Ulimits"": [], ""CpuCount"": 0, ""CpuPercent"": 0, ""IOMaximumIOps"": 0, @@ -90,6 +90,23 @@ ""ReadonlyPaths"": null }, ""NetworkingConfig"": { - ""EndpointsConfig"": {} + ""EndpointsConfig"": { + ""default"": { + ""IPAMConfig"": null, + ""Links"": null, + ""Aliases"": null, + ""MacAddress"": """", + ""NetworkID"": """", + ""EndpointID"": """", + ""Gateway"": """", + ""IPAddress"": """", + ""IPPrefixLen"": 0, + ""IPv6Gateway"": """", + ""GlobalIPv6Address"": """", + ""GlobalIPv6PrefixLen"": 0, + ""DriverOpts"": null, + ""DNSNames"": null + } + } } }  So the ""root cause"" is this new default ""EndpointsConfig"" struct, which seems all default initialized and which podman somehow interprets differently from an empty `{}` json config. I didn't check the code yet to see if there is a quick fix for this issue. Cheers, Romain  Steps to reproduce the issue Steps to reproduce the issue 1. Start a `quay.io/podman/upstream` container start a podman server:  > podman run -t -i --rm --privileged --name=podman-server -v /shared-volume --pull=always quay.io/podman/upstream podman system service -t 0 unix:shared-volume/podman.sock Trying to pull quay.io/podman/upstream:latest Getting image source signatures Copying blob sha256:b2013b443c422f98f009bfb9f930cc424428f8ccb694c84a26ebeb98891687f9 Copying blob sha256:cf73a40571609daa501dab6a62c1d08ca1665278b2355f5a36424804281c62fe Copying blob sha256:439ec636831d395b84ce0dfd6390420c60a8aa2a128a88b7dc55236a5e54c7a1 Copying blob sha256:2026b963063adee0348d722192a5761e34b449d666f6f79a687818f40a96a67f Copying blob sha256:718a00fe32127ad01ddab9fc4b7c968ab2679c92c6385ac6865ae6e2523275e4 Copying blob sha256:d2ea58b809bcf20a5fa73f3bce6c4ac3f371fbd010700dc0979f495f53b7fc76 Copying blob sha256:e16106bb651e790ca91447e2fc47c5a2f86e4824cd3bada6d63419f9801e4f93 Copying blob sha256:7323cd5de043ae967491a338060d6d1c51eed17c19bda023d76f72b326d7b5bf Copying blob sha256:39cd8764a88b128c21ab1816efa5c0179a803ed18ada3aa9c5f09d23b231787f Copying config sha256:8739df1320065867713c219a7efdb999e478796c0059e25143f10f54272fe833 Writing manifest to image destination  2. Try to run a container inside the first one, using a docker 25 CLI. I used explicitly `--oom-score-adj=1000` to workaround the issue fixed by #21487:  > podman run -t -i --rm --pull=always --volumes-from=podman-server -e DOCKER_HOST=unix:shared-volume/podman.sock docker:25-cli docker run -t -i --rm --oom-score-adj=1000 quay.io/fedora/fedora Trying to pull docker.io/library/docker:25-cli Getting image source signatures Copying blob sha256:f23a00be1976186eef218bb9b79ab99203e0c5b235c1b49e77f3ac3264793d78 Copying blob sha256:4abcf20661432fb2d719aaf90656f55c287f8ca915dc1c92ec14ff61e67fbaf8 Copying blob sha256:1bd9561ee09aa7423609ac837068a53ad4a8fd35b8b6d51528d78cb126eb3b07 Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 Copying blob sha256:a48a116699ba1fe77921e9ab9fef2dc65016ac2e483b07f03921526b8a0fcf79 Copying blob sha256:41dc1292823582d19d9bc523915a590652c16d3bedc6099b345ec38efd77e6a0 Copying blob sha256:e56d49cdf5732fc93fbea227838e14f9772a369a669592554ca37cf4695be03d Copying blob sha256:b6735844810a03df9d76e5aa58d3df2f1c56f6c208093eba5f88e5806f1cda04 Copying blob sha256:49704df22e8621ca86fd75cb61b8f23ee280754df0048a7bf46cd8b96ec2551f Copying blob sha256:b0f5f50d82ecbeeeea34901bdac4b25948f5f7146f2842d8a7aeb9a730459567 Copying config sha256:e95f54c1fcc216bc7d10270705e5ce8f98504f69d2afba666d6ce12e940da2f6 Writing manifest to image destination Unable to find image 'quay.io/fedora/fedora:latest' locally 718a00fe3212: Download complete 368a084ba17d: Download complete docker: Error response from daemon: container create: invalid config provided: networks and static ip/mac address can only be used with Bridge mode networking. See 'docker run --help'.  3. Doing exactly the same thing, with `docker:24-cli` instead works just fine:  > podman run -t -i --rm --pull=always --volumes-from=podman-server -e DOCKER_HOST=unix:shared-volume/podman.sock docker:24-cli docker run -t -i --rm --oom-score-adj=1000 quay.io/fedora/fedora Trying to pull docker.io/library/docker:24-cli Getting image source signatures Copying blob sha256:4abcf20661432fb2d719aaf90656f55c287f8ca915dc1c92ec14ff61e67fbaf8 Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 Copying blob sha256:1db5a4f146e2df1f17a2c0db7ffd672b18d1750d31c7e58e352a6536d4b7ad52 Copying blob sha256:248ec8ed73b325a9cff9ec3c5bbd2c249065ee96053dfc3beafb911ef652a195 Copying blob sha256:5aed6b72066db35b8929c11c552f9e827431de2b2de62b4384a1eaed88221787 Copying blob sha256:9908927dc97522b6d63aaaf9953c4095be9b24a1d080edb1ada9124d56bf41ad Copying blob sha256:d280e8e81156b63b7306ac0701738e22b333c7a26bdd96ddafb3ec8f607d2a32 Copying blob sha256:97f6ee5ccb7fa02811eb89d903666095e18e38c42a635369912f9ba0fd11e6eb Copying blob sha256:d4462dfff57f9ac45d562ae18d1ca53fef4918ae18e003d21ebf960b3ade6f94 Copying blob sha256:a474f84a4abb535fa3a05ee5a59bff31a53d0857d4d53bab82a9f2f3684c4c7c Copying config sha256:b4e4d47cb84703dc6042823b7e29e3111074beb09b50848a31cdb9cd9565ed9a Writing manifest to image destination [root@56d0c302cd66 /]# ^C [root@56d0c302cd66 /]# exit exit   Describe the results you received Podman cannot be used with docker 25 CLI (in container mode) while it was working with docker 24 CLI.  Describe the results you expected Podman can be used with docker 25 CLI (in container mode).  podman info output yaml Tried on `quay.io/podman/upstream` on an up to date x86_64 RHEL 9.   Podman in a container Yes  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
22657,podman,https://github.com/containers/podman/issues/22657,when host has podman from podman-next and podman-remote is run inside a toolbox : unmarshalling error," Issue Description I was trying to reproduce the issue https://github.com/containers/podman/issues/21974 which is valid for podman < 5 (did not bisect, take this with a grain of salt). I realized that having podman installed from podman next leads to an error.  Steps to reproduce the issue Steps to reproduce the issue 1. Install podman from the podman-next copr on the host 2. Follow the reproducer of https://github.com/containers/podman/issues/21974 until `podman-remote run` 3. Run the step `podman-remote run --cidfile /var/tmp/cidfile fedora:latest true` in the toolbox  Describe the results you received  Error: unmarshalling into &define.InspectContainerData{ID:""221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816"", Created:time.Date(2024, time.May, 9, 15, 37, 24, 363282572, time .Local), Path:""true"", Args:[]string{""true""}, State:(*define.InspectContainerState)(0x4000532000), Image:""a3b2e2a9704e6b54b78f4924f5b1318dbd7aa2553736944dd966cef32da5e37a"", ImageDigest:""sha25 6:a4a66434bd361d9c80cd6fd5b0ee3112a0347aed794141b372ce0c4f09afb791"", ImageName:""registry.fedoraproject.org/fedora:latest"", Rootfs:"""", Pod:"""", ResolvConfPath:"""", HostnamePath:"""", HostsPath:"""" , StaticDir:""/home/nsella/.local/share/containers/storage/overlay-containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816/userdata"", OCIConfigPath:"""", OCIRuntime:""crun"", ConmonPidFile:""/run/user/1000/containers/overlay-containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816/userdata/conmon.pid"", PidFile:""/run/user/1000/containers/overlay- containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816/userdata/pidfile"", Name:""nifty_clarke"", RestartCount:0, Driver:""overlay"", MountLabel:""system_u:object_r:container_ file_t:s0:c139,c898"", ProcessLabel:""system_u:system_r:container_t:s0:c139,c898"", AppArmorProfile:"""", EffectiveCaps:[]string{""CAP_CHOWN"", ""CAP_DAC_OVERRIDE"", ""CAP_FOWNER"", ""CAP_FSETID"", ""CAP_ KILL"", ""CAP_NET_BIND_SERVICE"", ""CAP_SETFCAP"", ""CAP_SETGID"", ""CAP_SETPCAP"", ""CAP_SETUID"", ""CAP_SYS_CHROOT""}, BoundingCaps:[]string{""CAP_CHOWN"", ""CAP_DAC_OVERRIDE"", ""CAP_FOWNER"", ""CAP_FSETID"", ""CAP_KILL"", ""CAP_NET_BIND_SERVICE"", ""CAP_SETFCAP"", ""CAP_SETGID"", ""CAP_SETPCAP"", ""CAP_SETUID"", ""CAP_SYS_CHROOT""}, ExecIDs:[]string{}, GraphDriver:(*define.DriverData)(0x40006b8978), SizeRw:( *int64)(nil), SizeRootFs:0, Mounts:[]define.InspectMount{}, Dependencies:[]string{}, NetworkSettings:(*define.InspectNetworkSettings)(0x40002bf680), Namespace:"""", IsInfra:false, IsService:fa lse, KubeExitCodePropagation:""invalid"", LockNumber:0x1, Config:(*define.InspectContainerConfig)(0x4000636600), HostConfig:(*define.InspectContainerHostConfig)(0x40006c0400)}, data ""{\""Id\"":\ ""221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816\"",\""Created\"":\""2024-05-09T15:37:24.363282572+02:00\"",\""Path\"":\""true\"",\""Args\"":[\""true\""],\""State\"":{\""OciVersion\"":\""1.2. 0\"",\""Status\"":\""created\"",\""Running\"":false,\""Paused\"":false,\""Restarting\"":false,\""OOMKilled\"":false,\""Dead\"":false,\""Pid\"":0,\""ExitCode\"":0,\""Error\"":\""\"",\""StartedAt\"":\""0001-01-01T00:00 :00Z\"",\""FinishedAt\"":\""0001-01-01T00:00:00Z\"",\""CheckpointedAt\"":\""0001-01-01T00:00:00Z\"",\""RestoredAt\"":\""0001-01-01T00:00:00Z\""},\""Image\"":\""a3b2e2a9704e6b54b78f4924f5b1318dbd7aa255373694 4dd966cef32da5e37a\"",\""ImageDigest\"":\""sha256:a4a66434bd361d9c80cd6fd5b0ee3112a0347aed794141b372ce0c4f09afb791\"",\""ImageName\"":\""registry.fedoraproject.org/fedora:latest\"",\""Rootfs\"":\""\"",\"" Pod\"":\""\"",\""ResolvConfPath\"":\""\"",\""HostnamePath\"":\""\"",\""HostsPath\"":\""\"",\""StaticDir\"":\""/home/nsella/.local/share/containers/storage/overlay-containers/221aadce464435e1eed931dffe7326d852 4e40139614e4c1ce0877463f064816/userdata\"",\""OCIRuntime\"":\""crun\"",\""ConmonPidFile\"":\""/run/user/1000/containers/overlay-containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f0 64816/userdata/conmon.pid\"",\""PidFile\"":\""/run/user/1000/containers/overlay-containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816/userdata/pidfile\"",\""Name\"":\""nifty_cl arke\"",\""RestartCount\"":0,\""Driver\"":\""overlay\"",\""MountLabel\"":\""system_u:object_r:container_file_t:s0:c139,c898\"",\""ProcessLabel\"":\""system_u:system_r:container_t:s0:c139,c898\"",\""AppArmor Profile\"":\""\"",\""EffectiveCaps\"":[\""CAP_CHOWN\"",\""CAP_DAC_OVERRIDE\"",\""CAP_FOWNER\"",\""CAP_FSETID\"",\""CAP_KILL\"",\""CAP_NET_BIND_SERVICE\"",\""CAP_SETFCAP\"",\""CAP_SETGID\"",\""CAP_SETPCAP\"",\""CAP_ SETUID\"",\""CAP_SYS_CHROOT\""],\""BoundingCaps\"":[\""CAP_CHOWN\"",\""CAP_DAC_OVERRIDE\"",\""CAP_FOWNER\"",\""CAP_FSETID\"",\""CAP_KILL\"",\""CAP_NET_BIND_SERVICE\"",\""CAP_SETFCAP\"",\""CAP_SETGID\"",\""CAP_SET PCAP\"",\""CAP_SETUID\"",\""CAP_SYS_CHROOT\""],\""ExecIDs\"":[],\""GraphDriver\"":{\""Name\"":\""overlay\"",\""Data\"":{\""LowerDir\"":\""/home/nsella/.local/share/containers/storage/overlay/e46c7a886cbfe1e67 41a81b494cf8f025358b9e74f625b1a930960d1974e7387/diff\"",\""UpperDir\"":\""/home/nsella/.local/share/containers/storage/overlay/45eb3c184e2e64464f1cdc979ca8c5f4b9beca07d7cad9eb911cd889bfab54c6/di ff\"",\""WorkDir\"":\""/home/nsella/.local/share/containers/storage/overlay/45eb3c184e2e64464f1cdc979ca8c5f4b9beca07d7cad9eb911cd889bfab54c6/work\""}},\""Mounts\"":[],\""Dependencies\"":[],\""NetworkS ettings\"":{\""EndpointID\"":\""\"",\""Gateway\"":\""\"",\""IPAddress\"":\""\"",\""IPPrefixLen\"":0,\""IPv6Gateway\"":\""\"",\""GlobalIPv6Address\"":\""\"",\""GlobalIPv6PrefixLen\"":0,\""MacAddress\"":\""\"",\""Bridge\"": \""\"",\""SandboxID\"":\""\"",\""HairpinMode\"":false,\""LinkLocalIPv6Address\"":\""\"",\""LinkLocalIPv6PrefixLen\"":0,\""Ports\"":{},\""SandboxKey\"":\""\"",\""Networks\"":{\""pasta\"":{\""EndpointID\"":\""\"",\""Gatew ay\"":\""\"",\""IPAddress\"":\""\"",\""IPPrefixLen\"":0,\""IPv6Gateway\"":\""\"",\""GlobalIPv6Address\"":\""\"",\""GlobalIPv6PrefixLen\"":0,\""MacAddress\"":\""\"",\""NetworkID\"":\""pasta\"",\""DriverOpts\"":null,\""IPA MConfig\"":null,\""Links\"":null,\""Namespace\"":\""\"",\""IsInfra\"":false,\""IsService\"":false,\""KubeExitCodePropagation\"":\""invalid\"",\""lockNumber\"":1,\""Config\"":{\""Hostname\"":\""221aadce4644\"",\ ""Domainname\"":\""\"",\""User\"":\""\"",\""AttachStdin\"":false,\""AttachStdout\"":false,\""AttachStderr\"":false,\""Tty\"":false,\""OpenStdin\"":false,\""StdinOnce\"":false,\""Env\"":[\""FGC=f39\"",\""PATH=/usr/lo cal/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"",\""container=oci\"",\""DISTTAG=f39container\""],\""Cmd\"":[\""true\""],\""Image\"":\""registry.fedoraproject.org/fedora:latest\"",\""Volumes\"":null ,\""WorkingDir\"":\""/\"",\""Entrypoint\"":null,\""OnBuild\"":null,\""Labels\"":{\""license\"":\""MIT\"",\""name\"":\""fedora\"",\""vendor\"":\""Fedora Project\"",\""version\"":\""39\""},\""Annotations\"":{\""io.podman. annotations.cid-file\"":\""/var/tmp/cidfile\""},\""StopSignal\"":\""SIGTERM\"",\""HealthcheckOnFailureAction\"":\""none\"",\""CreateCommand\"":[\""podman-remote\"",\""run\"",\""--cidfile\"",\""/var/tmp/cidfile\ "",\""fedora:latest\"",\""true\""],\""Umask\"":\""0022\"",\""Timeout\"":0,\""StopTimeout\"":10,\""Passwd\"":true,\""sdNotifyMode\"":\""container\""},\""HostConfig\"":{\""Binds\"":[],\""CgroupManager\"":\""systemd\"",\ ""CgroupMode\"":\""private\"",\""ContainerIDFile\"":\""/var/tmp/cidfile\"",\""LogConfig\"":{\""Type\"":\""journald\"",\""Config\"":null,\""Path\"":\""\"",\""Tag\"":\""\"",\""Size\"":\""0B\""},\""NetworkMode\"":\""pasta\"", \""PortBindings\"":{},\""RestartPolicy\"":{\""Name\"":\""no\"",\""MaximumRetryCount\"":0},\""AutoRemove\"":false,\""Annotations\"":{\""io.podman.annotations.cid-file\"":\""/var/tmp/cidfile\""},\""VolumeDriver\ "":\""\"",\""VolumesFrom\"":null,\""CapAdd\"":[],\""CapDrop\"":[],\""Dns\"":[],\""DnsOptions\"":[],\""DnsSearch\"":[],\""ExtraHosts\"":[],\""GroupAdd\"":[],\""IpcMode\"":\""shareable\"",\""Cgroup\"":\""\"",\""Cgroups\"" :\""default\"",\""Links\"":null,\""OomScoreAdj\"":0,\""PidMode\"":\""private\"",\""Privileged\"":false,\""PublishAllPorts\"":false,\""ReadonlyRootfs\"":false,\""SecurityOpt\"":[],\""Tmpfs\"":{},\""UTSMode\"":\""pr ivate\"",\""UsernsMode\"":\""\"",\""ShmSize\"":65536000,\""Runtime\"":\""oci\"",\""ConsoleSize\"":[0,0],\""Isolation\"":\""\"",\""CpuShares\"":0,\""Memory\"":0,\""NanoCpus\"":0,\""CgroupParent\"":\""user.slice\"",\""Bl kioWeight\"":0,\""BlkioWeightDevice\"":null,\""BlkioDeviceReadBps\"":null,\""BlkioDeviceWriteBps\"":null,\""BlkioDeviceReadIOps\"":null,\""BlkioDeviceWriteIOps\"":null,\""CpuPeriod\"":0,\""CpuQuota\"":0,\"" CpuRealtimePeriod\"":0,\""CpuRealtimeRuntime\"":0,\""CpusetCpus\"":\""\"",\""CpusetMems\"":\""\"",\""Devices\"":[],\""DiskQuota\"":0,\""KernelMemory\"":0,\""MemoryReservation\"":0,\""MemorySwap\"":0,\""MemorySwap piness\"":0,\""OomKillDisable\"":false,\""PidsLimit\"":2048,\""Ulimits\"":[],\""CpuCount\"":0,\""CpuPercent\"":0,\""IOMaximumIOps\"":0,\""IOMaximumBandwidth\"":0,\""CgroupConf\"":null}}\n"": json: cannot unma rshal string into Go struct field InspectContainerConfig.Config.StopSignal of type uint   Describe the results you expected Command should work  podman info output yaml $ podman -v podman version 5.1.0-dev-63ab9275b   $ cat /etc/fedora-release Fedora Asahi Remix release 39 (Thirty Nine)   $ uname -a Linux applem1 6.8.8-400.asahi.fc39.aarch64+16k #1 SMP PREEMPT_DYNAMIC Tue Apr 30 02:30:34 UTC 2024 aarch64 GNU/Linux    Podman in a container Yes  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information I am aware that I am running this on `aarch64` did not try to run it on `x86_64` or other architectures yet.",source-file | source-file | test-file | test-file | source-file | source-file | test-file | test-file,host next remote inside toolbox unmarshalling description trying reproduce https github containers issues valid bisect take grain salt realized installed next leads steps reproduce steps reproduce install next copr host follow reproducer https github containers issues remote step remote cidfile var tmp cidfile fedora latest true toolbox describe results received unmarshalling define inspectcontainerdata aadce eed dffe created time date time may time local path true args string true state define inspectcontainerstate image dbd cef imagedigest sha aed afb imagename registry fedoraproject fedora latest rootfs pod resolvconfpath hostnamepath hostspath staticdir home nsella local share containers storage overlay containers aadce eed dffe userdata ociconfigpath ociruntime crun conmonpidfile user containers overlay containers aadce eed dffe userdata conmon pid pidfile user containers overlay containers aadce eed dffe userdata pidfile name nifty clarke restartcount driver overlay mountlabel system object container processlabel system system container apparmorprofile effectivecaps string cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot boundingcaps string cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot execids string graphdriver define driverdata sizerw int nil sizerootfs mounts define inspectmount dependencies string networksettings define inspectnetworksettings namespace isinfra false isservice lse kubeexitcodepropagation invalid locknumber config define inspectcontainerconfig hostconfig define inspectcontainerhostconfig data aadce eed dffe created path true args true state ociversion status created running false paused false restarting false oomkilled false dead false pid exitcode startedat finishedat checkpointedat restoredat image dbd cef imagedigest sha aed afb imagename registry fedoraproject fedora latest rootfs pod resolvconfpath hostnamepath hostspath staticdir home nsella local share containers storage overlay containers aadce eed dffe userdata ociruntime crun conmonpidfile user containers overlay containers aadce eed dffe userdata conmon pid pidfile user containers overlay containers aadce eed dffe userdata pidfile name nifty arke restartcount driver overlay mountlabel system object container processlabel system system container apparmor profile effectivecaps cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot boundingcaps cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap set pcap cap setuid cap sys chroot execids graphdriver name overlay data lowerdir home nsella local share containers storage overlay cbfe diff upperdir home nsella local share containers storage overlay cdc beca cad bfab workdir home nsella local share containers storage overlay cdc beca cad bfab work mounts dependencies networks ettings endpointid gateway ipaddress ipprefixlen ipv gateway globalipv address globalipv prefixlen macaddress bridge sandboxid hairpinmode false linklocalipv address linklocalipv prefixlen ports sandboxkey networks pasta endpointid gatew ipaddress ipprefixlen ipv gateway globalipv address globalipv prefixlen macaddress networkid pasta driveropts null ipa mconfig null links null namespace isinfra false isservice false kubeexitcodepropagation invalid locknumber config hostname aadce domainname user attachstdin false attachstdout false attachstderr false tty false openstdin false stdinonce false env fgc path cal sbin local sbin sbin container oci disttag container cmd true image registry fedoraproject fedora latest volumes null workingdir entrypoint null onbuild null labels license mit name fedora vendor fedora project annotations annotations cid var tmp cidfile stopsignal sigterm healthcheckonfailureaction none createcommand remote cidfile var tmp cidfile fedora latest true umask timeout stoptimeout passwd true sdnotifymode container hostconfig binds cgroupmanager systemd cgroupmode private containeridfile var tmp cidfile logconfig type journald config null path tag size networkmode pasta portbindings restartpolicy name maximumretrycount autoremove false annotations annotations cid var tmp cidfile volumedriver volumesfrom null capadd capdrop dns dnsoptions dnssearch extrahosts groupadd ipcmode shareable cgroup cgroups default links null oomscoreadj pidmode private privileged false publishallports false readonlyrootfs false securityopt tmpfs utsmode ivate usernsmode shmsize runtime oci consolesize isolation cpushares memory nanocpus cgroupparent user slice kioweight blkioweightdevice null blkiodevicereadbps null blkiodevicewritebps null blkiodevicereadiops null blkiodevicewriteiops null cpuperiod cpuquota cpurealtimeperiod cpurealtimeruntime cpusetcpus cpusetmems devices diskquota kernelmemory memoryreservation memoryswap memoryswap piness oomkilldisable false pidslimit ulimits cpucount cpupercent iomaximumiops iomaximumbandwidth cgroupconf null json cannot unma rshal string struct field inspectcontainerconfig config stopsignal type uint describe results expected command work output yaml cat etc fedora fedora asahi remix thirty nine uname linux applem asahi aarch smp preempt dynamic apr utc aarch gnu linux container yes privileged rootless rootless upstream latest yes additional environment details response additional information aware running aarch architectures yet,bug,0.9,"when host has podman from podman-next and podman-remote is run inside a toolbox : unmarshalling error  Issue Description I was trying to reproduce the issue https://github.com/containers/podman/issues/21974 which is valid for podman < 5 (did not bisect, take this with a grain of salt). I realized that having podman installed from podman next leads to an error.  Steps to reproduce the issue Steps to reproduce the issue 1. Install podman from the podman-next copr on the host 2. Follow the reproducer of https://github.com/containers/podman/issues/21974 until `podman-remote run` 3. Run the step `podman-remote run --cidfile /var/tmp/cidfile fedora:latest true` in the toolbox  Describe the results you received  Error: unmarshalling into &define.InspectContainerData{ID:""221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816"", Created:time.Date(2024, time.May, 9, 15, 37, 24, 363282572, time .Local), Path:""true"", Args:[]string{""true""}, State:(*define.InspectContainerState)(0x4000532000), Image:""a3b2e2a9704e6b54b78f4924f5b1318dbd7aa2553736944dd966cef32da5e37a"", ImageDigest:""sha25 6:a4a66434bd361d9c80cd6fd5b0ee3112a0347aed794141b372ce0c4f09afb791"", ImageName:""registry.fedoraproject.org/fedora:latest"", Rootfs:"""", Pod:"""", ResolvConfPath:"""", HostnamePath:"""", HostsPath:"""" , StaticDir:""/home/nsella/.local/share/containers/storage/overlay-containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816/userdata"", OCIConfigPath:"""", OCIRuntime:""crun"", ConmonPidFile:""/run/user/1000/containers/overlay-containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816/userdata/conmon.pid"", PidFile:""/run/user/1000/containers/overlay- containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816/userdata/pidfile"", Name:""nifty_clarke"", RestartCount:0, Driver:""overlay"", MountLabel:""system_u:object_r:container_ file_t:s0:c139,c898"", ProcessLabel:""system_u:system_r:container_t:s0:c139,c898"", AppArmorProfile:"""", EffectiveCaps:[]string{""CAP_CHOWN"", ""CAP_DAC_OVERRIDE"", ""CAP_FOWNER"", ""CAP_FSETID"", ""CAP_ KILL"", ""CAP_NET_BIND_SERVICE"", ""CAP_SETFCAP"", ""CAP_SETGID"", ""CAP_SETPCAP"", ""CAP_SETUID"", ""CAP_SYS_CHROOT""}, BoundingCaps:[]string{""CAP_CHOWN"", ""CAP_DAC_OVERRIDE"", ""CAP_FOWNER"", ""CAP_FSETID"", ""CAP_KILL"", ""CAP_NET_BIND_SERVICE"", ""CAP_SETFCAP"", ""CAP_SETGID"", ""CAP_SETPCAP"", ""CAP_SETUID"", ""CAP_SYS_CHROOT""}, ExecIDs:[]string{}, GraphDriver:(*define.DriverData)(0x40006b8978), SizeRw:( *int64)(nil), SizeRootFs:0, Mounts:[]define.InspectMount{}, Dependencies:[]string{}, NetworkSettings:(*define.InspectNetworkSettings)(0x40002bf680), Namespace:"""", IsInfra:false, IsService:fa lse, KubeExitCodePropagation:""invalid"", LockNumber:0x1, Config:(*define.InspectContainerConfig)(0x4000636600), HostConfig:(*define.InspectContainerHostConfig)(0x40006c0400)}, data ""{\""Id\"":\ ""221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816\"",\""Created\"":\""2024-05-09T15:37:24.363282572+02:00\"",\""Path\"":\""true\"",\""Args\"":[\""true\""],\""State\"":{\""OciVersion\"":\""1.2. 0\"",\""Status\"":\""created\"",\""Running\"":false,\""Paused\"":false,\""Restarting\"":false,\""OOMKilled\"":false,\""Dead\"":false,\""Pid\"":0,\""ExitCode\"":0,\""Error\"":\""\"",\""StartedAt\"":\""0001-01-01T00:00 :00Z\"",\""FinishedAt\"":\""0001-01-01T00:00:00Z\"",\""CheckpointedAt\"":\""0001-01-01T00:00:00Z\"",\""RestoredAt\"":\""0001-01-01T00:00:00Z\""},\""Image\"":\""a3b2e2a9704e6b54b78f4924f5b1318dbd7aa255373694 4dd966cef32da5e37a\"",\""ImageDigest\"":\""sha256:a4a66434bd361d9c80cd6fd5b0ee3112a0347aed794141b372ce0c4f09afb791\"",\""ImageName\"":\""registry.fedoraproject.org/fedora:latest\"",\""Rootfs\"":\""\"",\"" Pod\"":\""\"",\""ResolvConfPath\"":\""\"",\""HostnamePath\"":\""\"",\""HostsPath\"":\""\"",\""StaticDir\"":\""/home/nsella/.local/share/containers/storage/overlay-containers/221aadce464435e1eed931dffe7326d852 4e40139614e4c1ce0877463f064816/userdata\"",\""OCIRuntime\"":\""crun\"",\""ConmonPidFile\"":\""/run/user/1000/containers/overlay-containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f0 64816/userdata/conmon.pid\"",\""PidFile\"":\""/run/user/1000/containers/overlay-containers/221aadce464435e1eed931dffe7326d8524e40139614e4c1ce0877463f064816/userdata/pidfile\"",\""Name\"":\""nifty_cl arke\"",\""RestartCount\"":0,\""Driver\"":\""overlay\"",\""MountLabel\"":\""system_u:object_r:container_file_t:s0:c139,c898\"",\""ProcessLabel\"":\""system_u:system_r:container_t:s0:c139,c898\"",\""AppArmor Profile\"":\""\"",\""EffectiveCaps\"":[\""CAP_CHOWN\"",\""CAP_DAC_OVERRIDE\"",\""CAP_FOWNER\"",\""CAP_FSETID\"",\""CAP_KILL\"",\""CAP_NET_BIND_SERVICE\"",\""CAP_SETFCAP\"",\""CAP_SETGID\"",\""CAP_SETPCAP\"",\""CAP_ SETUID\"",\""CAP_SYS_CHROOT\""],\""BoundingCaps\"":[\""CAP_CHOWN\"",\""CAP_DAC_OVERRIDE\"",\""CAP_FOWNER\"",\""CAP_FSETID\"",\""CAP_KILL\"",\""CAP_NET_BIND_SERVICE\"",\""CAP_SETFCAP\"",\""CAP_SETGID\"",\""CAP_SET PCAP\"",\""CAP_SETUID\"",\""CAP_SYS_CHROOT\""],\""ExecIDs\"":[],\""GraphDriver\"":{\""Name\"":\""overlay\"",\""Data\"":{\""LowerDir\"":\""/home/nsella/.local/share/containers/storage/overlay/e46c7a886cbfe1e67 41a81b494cf8f025358b9e74f625b1a930960d1974e7387/diff\"",\""UpperDir\"":\""/home/nsella/.local/share/containers/storage/overlay/45eb3c184e2e64464f1cdc979ca8c5f4b9beca07d7cad9eb911cd889bfab54c6/di ff\"",\""WorkDir\"":\""/home/nsella/.local/share/containers/storage/overlay/45eb3c184e2e64464f1cdc979ca8c5f4b9beca07d7cad9eb911cd889bfab54c6/work\""}},\""Mounts\"":[],\""Dependencies\"":[],\""NetworkS ettings\"":{\""EndpointID\"":\""\"",\""Gateway\"":\""\"",\""IPAddress\"":\""\"",\""IPPrefixLen\"":0,\""IPv6Gateway\"":\""\"",\""GlobalIPv6Address\"":\""\"",\""GlobalIPv6PrefixLen\"":0,\""MacAddress\"":\""\"",\""Bridge\"": \""\"",\""SandboxID\"":\""\"",\""HairpinMode\"":false,\""LinkLocalIPv6Address\"":\""\"",\""LinkLocalIPv6PrefixLen\"":0,\""Ports\"":{},\""SandboxKey\"":\""\"",\""Networks\"":{\""pasta\"":{\""EndpointID\"":\""\"",\""Gatew ay\"":\""\"",\""IPAddress\"":\""\"",\""IPPrefixLen\"":0,\""IPv6Gateway\"":\""\"",\""GlobalIPv6Address\"":\""\"",\""GlobalIPv6PrefixLen\"":0,\""MacAddress\"":\""\"",\""NetworkID\"":\""pasta\"",\""DriverOpts\"":null,\""IPA MConfig\"":null,\""Links\"":null,\""Namespace\"":\""\"",\""IsInfra\"":false,\""IsService\"":false,\""KubeExitCodePropagation\"":\""invalid\"",\""lockNumber\"":1,\""Config\"":{\""Hostname\"":\""221aadce4644\"",\ ""Domainname\"":\""\"",\""User\"":\""\"",\""AttachStdin\"":false,\""AttachStdout\"":false,\""AttachStderr\"":false,\""Tty\"":false,\""OpenStdin\"":false,\""StdinOnce\"":false,\""Env\"":[\""FGC=f39\"",\""PATH=/usr/lo cal/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"",\""container=oci\"",\""DISTTAG=f39container\""],\""Cmd\"":[\""true\""],\""Image\"":\""registry.fedoraproject.org/fedora:latest\"",\""Volumes\"":null ,\""WorkingDir\"":\""/\"",\""Entrypoint\"":null,\""OnBuild\"":null,\""Labels\"":{\""license\"":\""MIT\"",\""name\"":\""fedora\"",\""vendor\"":\""Fedora Project\"",\""version\"":\""39\""},\""Annotations\"":{\""io.podman. annotations.cid-file\"":\""/var/tmp/cidfile\""},\""StopSignal\"":\""SIGTERM\"",\""HealthcheckOnFailureAction\"":\""none\"",\""CreateCommand\"":[\""podman-remote\"",\""run\"",\""--cidfile\"",\""/var/tmp/cidfile\ "",\""fedora:latest\"",\""true\""],\""Umask\"":\""0022\"",\""Timeout\"":0,\""StopTimeout\"":10,\""Passwd\"":true,\""sdNotifyMode\"":\""container\""},\""HostConfig\"":{\""Binds\"":[],\""CgroupManager\"":\""systemd\"",\ ""CgroupMode\"":\""private\"",\""ContainerIDFile\"":\""/var/tmp/cidfile\"",\""LogConfig\"":{\""Type\"":\""journald\"",\""Config\"":null,\""Path\"":\""\"",\""Tag\"":\""\"",\""Size\"":\""0B\""},\""NetworkMode\"":\""pasta\"", \""PortBindings\"":{},\""RestartPolicy\"":{\""Name\"":\""no\"",\""MaximumRetryCount\"":0},\""AutoRemove\"":false,\""Annotations\"":{\""io.podman.annotations.cid-file\"":\""/var/tmp/cidfile\""},\""VolumeDriver\ "":\""\"",\""VolumesFrom\"":null,\""CapAdd\"":[],\""CapDrop\"":[],\""Dns\"":[],\""DnsOptions\"":[],\""DnsSearch\"":[],\""ExtraHosts\"":[],\""GroupAdd\"":[],\""IpcMode\"":\""shareable\"",\""Cgroup\"":\""\"",\""Cgroups\"" :\""default\"",\""Links\"":null,\""OomScoreAdj\"":0,\""PidMode\"":\""private\"",\""Privileged\"":false,\""PublishAllPorts\"":false,\""ReadonlyRootfs\"":false,\""SecurityOpt\"":[],\""Tmpfs\"":{},\""UTSMode\"":\""pr ivate\"",\""UsernsMode\"":\""\"",\""ShmSize\"":65536000,\""Runtime\"":\""oci\"",\""ConsoleSize\"":[0,0],\""Isolation\"":\""\"",\""CpuShares\"":0,\""Memory\"":0,\""NanoCpus\"":0,\""CgroupParent\"":\""user.slice\"",\""Bl kioWeight\"":0,\""BlkioWeightDevice\"":null,\""BlkioDeviceReadBps\"":null,\""BlkioDeviceWriteBps\"":null,\""BlkioDeviceReadIOps\"":null,\""BlkioDeviceWriteIOps\"":null,\""CpuPeriod\"":0,\""CpuQuota\"":0,\"" CpuRealtimePeriod\"":0,\""CpuRealtimeRuntime\"":0,\""CpusetCpus\"":\""\"",\""CpusetMems\"":\""\"",\""Devices\"":[],\""DiskQuota\"":0,\""KernelMemory\"":0,\""MemoryReservation\"":0,\""MemorySwap\"":0,\""MemorySwap piness\"":0,\""OomKillDisable\"":false,\""PidsLimit\"":2048,\""Ulimits\"":[],\""CpuCount\"":0,\""CpuPercent\"":0,\""IOMaximumIOps\"":0,\""IOMaximumBandwidth\"":0,\""CgroupConf\"":null}}\n"": json: cannot unma rshal string into Go struct field InspectContainerConfig.Config.StopSignal of type uint   Describe the results you expected Command should work  podman info output yaml $ podman -v podman version 5.1.0-dev-63ab9275b   $ cat /etc/fedora-release Fedora Asahi Remix release 39 (Thirty Nine)   $ uname -a Linux applem1 6.8.8-400.asahi.fc39.aarch64+16k #1 SMP PREEMPT_DYNAMIC Tue Apr 30 02:30:34 UTC 2024 aarch64 GNU/Linux    Podman in a container Yes  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details _No response_  Additional information I am aware that I am running this on `aarch64` did not try to run it on `x86_64` or other architectures yet."
13986,podman,https://github.com/containers/podman/issues/13986,Cannot filter containers for `removing` status in API,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** Cannot filter for `removing` status in API. It looks like `restarting` is missing too, haven't tried other statuses. `is-task` seems to be a wrongfully invalid filter as well **Steps to reproduce the issue:** curl -g --unix-socket /run/podman/podman.sock 'http://d/v4.0.0/libpod/containers/json?filters={""status"":[""removing""]}' **Describe the results you received:** `{""cause"":""removing is not a valid status"",""message"":""removing is not a valid status"",""response"":500}` **Describe the results you expected:** According to the docs this is a valid status: https://docs.podman.io/en/v4.0.0/_static/api.html#operation/ContainerListLibpod **Output of `podman version`:**  Client: Podman Engine Version: 4.0.3 API Version: 4.0.3 Go Version: go1.18 Git Commit: 62534053086fdeba7b93117e7c4dc6e797835a3e Built: Mon Apr 4 05:54:02 2022 OS/Arch: linux/amd64 ",source-file | test-file,cannot filter containers removing status api bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description cannot filter removing status api looks like restarting missing tried statuses task seems wrongfully invalid filter well steps reproduce curl unix socket sock http libpod containers json filters status removing describe results received cause removing valid status message removing valid status response describe results expected according docs valid status https docs static api html operation containerlistlibpod output client engine api git fdeba built apr arch linux amd,bug,0.95,"Cannot filter containers for `removing` status in API <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** Cannot filter for `removing` status in API. It looks like `restarting` is missing too, haven't tried other statuses. `is-task` seems to be a wrongfully invalid filter as well **Steps to reproduce the issue:** curl -g --unix-socket /run/podman/podman.sock 'http://d/v4.0.0/libpod/containers/json?filters={""status"":[""removing""]}' **Describe the results you received:** `{""cause"":""removing is not a valid status"",""message"":""removing is not a valid status"",""response"":500}` **Describe the results you expected:** According to the docs this is a valid status: https://docs.podman.io/en/v4.0.0/_static/api.html#operation/ContainerListLibpod **Output of `podman version`:**  Client: Podman Engine Version: 4.0.3 API Version: 4.0.3 Go Version: go1.18 Git Commit: 62534053086fdeba7b93117e7c4dc6e797835a3e Built: Mon Apr 4 05:54:02 2022 OS/Arch: linux/amd64 "
14769,podman,https://github.com/containers/podman/issues/14769,"Podman system df --format ""{{json .}}"" doesn't output ""Size"" and ""Reclaimable"" columns","<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. podman system df 2. podman system df --format ""{{json ."" **Describe the results you received:** bash $ podman system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 89 5 59.2GB 57.58GB (97%) Containers 0 0 0B 0B (0%) Local Volumes 4 0 124MB 247.9MB (200%) $ podman system df --format ""{{json ."" {""Type"":""Images"",""Total"":89,""Active"":5}} {""Type"":""Containers"",""Total"":0,""Active"":0}} {""Type"":""Local Volumes"",""Total"":4,""Active"":0}}  **Describe the results you expected:** The `podman system df --format ""{{json .""` command should also output the `Size` and `Reclaimable` fields. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Client: Podman Engine Version: 4.1.1 API Version: 4.1.1 Go Version: go1.18.3 Built: Wed Jun 15 16:31:58 2022 OS/Arch: linux/amd64  **Output of `podman info --debug`:**  host: arch: amd64 buildahVersion: 1.26.1 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-2.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: ' cpuUtilization: idlePercent: 63.17 systemPercent: 5.89 userPercent: 30.95 cpus: 4 distribution: distribution: fedora variant: workstation version: ""36"" eventLogger: journald hostname: fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.18.6-200.fc36.x86_64 linkmode: dynamic logDriver: journald memFree: 7157645312 memTotal: 16457158656 networkBackend: cni ociRuntime: name: crun package: crun-1.4.5-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.4.5 commit: c381048530aa750495cf502ddb7181f2ded5b400 spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 8589930496 swapTotal: 8589930496 uptime: 24h 39m 39.32s (Approximately 1.00 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - registry.centos.org - docker.io store: configFile: /home/joachim/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/joachim/.local/share/containers/storage graphRootAllocated: 748592037888 graphRootUsed: 119622201344 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 89 runRoot: /run/user/1000/containers volumePath: /home/joachim/.local/share/containers/storage/volumes version: APIVersion: 4.1.1 Built: 1655303518 BuiltTime: Wed Jun 15 16:31:58 2022 GitCommit: """" GoVersion: go1.18.3 Os: linux OsArch: linux/amd64 Version: 4.1.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman-4.1.1-1.fc36.x86_64  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):** Physical",source-file | test-file,system format json output size reclaimable columns bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description briefly describe paragraphs steps reproduce system system format json describe results received bash system type total active size reclaimable images containers local volumes system format json type images total active type containers total active type local volumes total active describe results expected system format json command also output size reclaimable fields additional information deem important happens occasionally output client engine api built jun arch linux amd output host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant workstation eventlogger journald hostname fedora idmappings gidmap container host size container host size uidmap container host size container host size kernel linkmode dynamic logdriver journald memfree memtotal networkbackend cni ociruntime name crun package crun path crun crun ddb ded spec systemd selinux apparmor cap seccomp ebpf criu yajl linux remotesocket path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns beta slirp netns beta dda libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins log none passthrough journald network bridge macvlan ipvlan volume local registries search registry fedoraproject registry access redhat registry centos docker store configfile home joachim config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home joachim local share containers storage graphrootallocated graphrootused graphstatus backing filesystem btrfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers volumepath home joachim local share containers storage volumes apiversion built builttime jun gitcommit goversion linux osarch linux amd package output rpm apt list tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc physical,bug,0.9,"Podman system df --format ""{{json .}}"" doesn't output ""Size"" and ""Reclaimable"" columns <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. podman system df 2. podman system df --format ""{{json ."" **Describe the results you received:** bash $ podman system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 89 5 59.2GB 57.58GB (97%) Containers 0 0 0B 0B (0%) Local Volumes 4 0 124MB 247.9MB (200%) $ podman system df --format ""{{json ."" {""Type"":""Images"",""Total"":89,""Active"":5}} {""Type"":""Containers"",""Total"":0,""Active"":0}} {""Type"":""Local Volumes"",""Total"":4,""Active"":0}}  **Describe the results you expected:** The `podman system df --format ""{{json .""` command should also output the `Size` and `Reclaimable` fields. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Client: Podman Engine Version: 4.1.1 API Version: 4.1.1 Go Version: go1.18.3 Built: Wed Jun 15 16:31:58 2022 OS/Arch: linux/amd64  **Output of `podman info --debug`:**  host: arch: amd64 buildahVersion: 1.26.1 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.0-2.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.0, commit: ' cpuUtilization: idlePercent: 63.17 systemPercent: 5.89 userPercent: 30.95 cpus: 4 distribution: distribution: fedora variant: workstation version: ""36"" eventLogger: journald hostname: fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.18.6-200.fc36.x86_64 linkmode: dynamic logDriver: journald memFree: 7157645312 memTotal: 16457158656 networkBackend: cni ociRuntime: name: crun package: crun-1.4.5-1.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.4.5 commit: c381048530aa750495cf502ddb7181f2ded5b400 spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-0.2.beta.0.fc36.x86_64 version: |- slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 8589930496 swapTotal: 8589930496 uptime: 24h 39m 39.32s (Approximately 1.00 days) plugins: log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - registry.centos.org - docker.io store: configFile: /home/joachim/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/joachim/.local/share/containers/storage graphRootAllocated: 748592037888 graphRootUsed: 119622201344 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 89 runRoot: /run/user/1000/containers volumePath: /home/joachim/.local/share/containers/storage/volumes version: APIVersion: 4.1.1 Built: 1655303518 BuiltTime: Wed Jun 15 16:31:58 2022 GitCommit: """" GoVersion: go1.18.3 Os: linux OsArch: linux/amd64 Version: 4.1.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  podman-4.1.1-1.fc36.x86_64  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):** Physical"
17762,podman,https://github.com/containers/podman/issues/17762,"REST API: missing string ""sha256"" in returned `Id` attribute ( `/v1.24/images/${img}/history` )"," Issue Description docker returns a string that starts with `sha256:`  $ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Id ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239""  podman does not  $ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Id ""d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239""   Steps to reproduce the issue 1. `sudo -i` 2. `useradd test1` 3. `usermod -aG docker test1` 4. `machinectl shell test1@` 5. `podman pull alpine:3.17.2` 6. `docker pull alpine:3.17.2` 7. run `podman images` and detect the image id. Record the result in a shell variable `img=d74e625d9115` 9. `systemctl --user start podman.socket` 10. `curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id` 11. `curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id`  Describe the results you received  [test1@localhost ~]$ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"" [test1@localhost ~]$ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id ""d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"" [test1@localhost ~]$   Describe the results you expected  [test1@localhost ~]$ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"" [test1@localhost ~]$ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"" [test1@localhost ~]$   podman info output yaml host: arch: arm64 buildahVersion: 1.29.0 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.6-3.fc37.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.6, commit: ' cpuUtilization: idlePercent: 99.65 systemPercent: 0.12 userPercent: 0.24 cpus: 1 distribution: distribution: fedora variant: coreos version: ""37"" eventLogger: journald hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 589824 size: 65536 uidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 589824 size: 65536 kernel: 6.1.14-200.fc37.aarch64 linkmode: dynamic logDriver: journald memFree: 925364224 memTotal: 2050260992 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.1-1.fc37.aarch64 path: /usr/bin/crun version: |- crun version 1.8.1 commit: f8a096be060b22ccd3d5f3ebe44108517fbf6c30 rundir: /run/user/1001/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1001/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.aarch64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 31h 18m 41.00s (Approximately 1.29 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /var/home/test1/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/test1/.local/share/containers/storage graphRootAllocated: 10132369408 graphRootUsed: 1956737024 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/1001/containers transientStore: false volumePath: /var/home/test1/.local/share/containers/storage/volumes version: APIVersion: 4.4.1 Built: 1676629538 BuiltTime: Fri Feb 17 10:25:38 2023 GitCommit: """" GoVersion: go1.19.5 Os: linux OsArch: linux/arm64 Version: 4.4.1   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details The commands above were run with __podman 4.4.1__ on Fedora CoreOS by using qemu on a macOS laptop (operating system: Ventura 13.2.1).  [test1@localhost ~]$ docker version Client: Version: 20.10.23 API version: 1.41 Go version: go1.19.5 Git commit: %{shortcommit_cli} Built: Sun Jan 29 17:38:04 2023 OS/Arch: linux/arm64 Context: default Experimental: true Server: Engine: Version: 20.10.23 API version: 1.41 (minimum version 1.12) Go version: go1.19.5 Git commit: %{shortcommit_moby} Built: Sun Jan 29 17:38:04 2023 OS/Arch: linux/arm64 Experimental: false containerd: Version: 1.6.15 GitCommit: runc: Version: 1.1.4 GitCommit: docker-init: Version: 0.19.0 GitCommit:   [test1@localhost ~]$ podman version Client: Podman Engine Version: 4.4.1 API Version: 4.4.1 Go Version: go1.19.5 Built: Fri Feb 17 10:25:38 2023 OS/Arch: linux/arm64   [test1@localhost ~]$ rpm -q podman podman-4.4.1-3.fc37.aarch64   Additional information I have another computer (arch: amd64) running Fedora 37. I re-run the Podman commands there with __podman 4.4.2__. The container image ID changed and the container image size changed but nothing else.",source-file | test-file | test-file,rest api missing string sha returned attribute images img history description docker returns string starts sha curl unix socket var docker sock http localhost images history sha daadb fab curl unix socket xdg runtime dir sock http localhost images history daadb fab steps reproduce sudo useradd usermod docker machinectl shell alpine docker alpine images detect image record result shell variable img systemctl user start socket curl unix socket var docker sock http localhost images img history curl unix socket xdg runtime dir sock http localhost images img history describe results received localhost curl unix socket var docker sock http localhost images img history sha daadb fab localhost curl unix socket xdg runtime dir sock http localhost images img history daadb fab localhost describe results expected localhost curl unix socket var docker sock http localhost images img history sha daadb fab localhost curl unix socket xdg runtime dir sock http localhost images img history sha daadb fab localhost output yaml host arch arm buildahversion cgroupcontrollers memory pids cgroupmanager systemd cgroupversion conmon package conmon aarch path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant coreos eventlogger journald hostname localhost localdomain idmappings gidmap container host size container host size uidmap container host size container host size kernel aarch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun aarch path crun crun ccd ebe fbf rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns aarch slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile var home config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot var home local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath var home local share containers storage volumes apiversion built builttime feb gitcommit goversion linux osarch linux arm container privileged rootless rootless upstream latest yes additional environment details commands fedora coreos qemu macos laptop operating system ventura localhost docker client api git shortcommit cli built jan arch linux arm context default experimental true server engine api minimum git shortcommit moby built jan arch linux arm experimental false containerd gitcommit runc gitcommit docker init gitcommit localhost client engine api built feb arch linux arm localhost rpm aarch additional information another computer arch amd running fedora commands container image changed container image size changed nothing else,bug,0.95,"REST API: missing string ""sha256"" in returned `Id` attribute ( `/v1.24/images/${img}/history` )  Issue Description docker returns a string that starts with `sha256:`  $ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Id ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239""  podman does not  $ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Id ""d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239""   Steps to reproduce the issue 1. `sudo -i` 2. `useradd test1` 3. `usermod -aG docker test1` 4. `machinectl shell test1@` 5. `podman pull alpine:3.17.2` 6. `docker pull alpine:3.17.2` 7. run `podman images` and detect the image id. Record the result in a shell variable `img=d74e625d9115` 9. `systemctl --user start podman.socket` 10. `curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id` 11. `curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id`  Describe the results you received  [test1@localhost ~]$ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"" [test1@localhost ~]$ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id ""d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"" [test1@localhost ~]$   Describe the results you expected  [test1@localhost ~]$ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"" [test1@localhost ~]$ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Id ""sha256:d74e625d91152966d38fe8a62c60daadb96d4b94c1a366de01fab5f334806239"" [test1@localhost ~]$   podman info output yaml host: arch: arm64 buildahVersion: 1.29.0 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.6-3.fc37.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.6, commit: ' cpuUtilization: idlePercent: 99.65 systemPercent: 0.12 userPercent: 0.24 cpus: 1 distribution: distribution: fedora variant: coreos version: ""37"" eventLogger: journald hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 589824 size: 65536 uidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 589824 size: 65536 kernel: 6.1.14-200.fc37.aarch64 linkmode: dynamic logDriver: journald memFree: 925364224 memTotal: 2050260992 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.1-1.fc37.aarch64 path: /usr/bin/crun version: |- crun version 1.8.1 commit: f8a096be060b22ccd3d5f3ebe44108517fbf6c30 rundir: /run/user/1001/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1001/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.aarch64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 31h 18m 41.00s (Approximately 1.29 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /var/home/test1/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/test1/.local/share/containers/storage graphRootAllocated: 10132369408 graphRootUsed: 1956737024 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/1001/containers transientStore: false volumePath: /var/home/test1/.local/share/containers/storage/volumes version: APIVersion: 4.4.1 Built: 1676629538 BuiltTime: Fri Feb 17 10:25:38 2023 GitCommit: """" GoVersion: go1.19.5 Os: linux OsArch: linux/arm64 Version: 4.4.1   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details The commands above were run with __podman 4.4.1__ on Fedora CoreOS by using qemu on a macOS laptop (operating system: Ventura 13.2.1).  [test1@localhost ~]$ docker version Client: Version: 20.10.23 API version: 1.41 Go version: go1.19.5 Git commit: %{shortcommit_cli} Built: Sun Jan 29 17:38:04 2023 OS/Arch: linux/arm64 Context: default Experimental: true Server: Engine: Version: 20.10.23 API version: 1.41 (minimum version 1.12) Go version: go1.19.5 Git commit: %{shortcommit_moby} Built: Sun Jan 29 17:38:04 2023 OS/Arch: linux/arm64 Experimental: false containerd: Version: 1.6.15 GitCommit: runc: Version: 1.1.4 GitCommit: docker-init: Version: 0.19.0 GitCommit:   [test1@localhost ~]$ podman version Client: Podman Engine Version: 4.4.1 API Version: 4.4.1 Go Version: go1.19.5 Built: Fri Feb 17 10:25:38 2023 OS/Arch: linux/arm64   [test1@localhost ~]$ rpm -q podman podman-4.4.1-3.fc37.aarch64   Additional information I have another computer (arch: amd64) running Fedora 37. I re-run the Podman commands there with __podman 4.4.2__. The container image ID changed and the container image size changed but nothing else."
14208,podman,https://github.com/containers/podman/issues/14208,Image conflict should return HTTP 409,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind feature **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. Attempt to delete image which is still being used by a container using `DELETE /images/sha256:xxxx` **Describe the results you received:** API returns HTTP 500. **Describe the results you expected:** Given the Docker API returns the more appropriate HTTP 409 (CONFLICT), I expected Podman to return 409 as well. **Additional information you deem important (e.g. issue happens only occasionally):** I think it would not only be more appropriate to use a HTTP response with the matching description, but I too think it would help compatibility with Docker API clients. In my case I am using the Docker Java API, which would return a appropriate conflict exception on Docker's 409 response, whereas Podman's 500 results in a very generic server error.",source-file | test-file | source-file | test-file | source-file | test-file,image conflict return http bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind feature description briefly describe paragraphs steps reproduce attempt delete image still used container delete images sha xxxx describe results received api returns http describe results expected given docker api returns appropriate http conflict expected return well additional information deem important happens occasionally think would appropriate use http response matching description think would help compatibility docker api clients case docker api would return appropriate conflict exception docker response whereas results generic server,bug,0.95,"Image conflict should return HTTP 409 <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind feature **Description** <!-- Briefly describe the problem you are having in a few paragraphs. --> **Steps to reproduce the issue:** 1. Attempt to delete image which is still being used by a container using `DELETE /images/sha256:xxxx` **Describe the results you received:** API returns HTTP 500. **Describe the results you expected:** Given the Docker API returns the more appropriate HTTP 409 (CONFLICT), I expected Podman to return 409 as well. **Additional information you deem important (e.g. issue happens only occasionally):** I think it would not only be more appropriate to use a HTTP response with the matching description, but I too think it would help compatibility with Docker API clients. In my case I am using the Docker Java API, which would return a appropriate conflict exception on Docker's 409 response, whereas Podman's 500 results in a very generic server error."
23981,podman,https://github.com/containers/podman/issues/23981,Processes top api service incompatibility, Issue Description Describe your issue The compat endpoints do not behave the same - Api docs of docker <https://docs.docker.com/reference/api/engine/version/v1.39/#tag/Container/operation/ContainerTop> - Api docs of podman <https://docs.podman.io/en/latest/_static/api.html#tag/containers-(compat)/operation/ContainerTop>  Steps to reproduce the issue Steps to reproduce the issue 1. Get processes list using libpod compat endpoint 2. Get processes list using docker api engine endpoint 3. Compare  Describe the results you received Describe the results you received Received a list of strings  Describe the results you expected Describe the results you expected Receive a list of lists of strings  podman info output yaml Podman is working fine on 5.2.2   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details It happens on any environment  Additional information _No response_,source-file | test-file,processes top api service incompatibility description describe compat endpoints behave api docs docker https docs docker reference api engine tag container operation containertop api docs https docs latest static api html tag containers compat operation containertop steps reproduce steps reproduce get processes list libpod compat endpoint get processes list docker api engine endpoint compare describe results received describe results received received list strings describe results expected describe results expected receive list lists strings output yaml working fine container privileged rootless none upstream latest yes additional environment details happens environment additional information response,bug,0.9,Processes top api service incompatibility  Issue Description Describe your issue The compat endpoints do not behave the same - Api docs of docker <https://docs.docker.com/reference/api/engine/version/v1.39/#tag/Container/operation/ContainerTop> - Api docs of podman <https://docs.podman.io/en/latest/_static/api.html#tag/containers-(compat)/operation/ContainerTop>  Steps to reproduce the issue Steps to reproduce the issue 1. Get processes list using libpod compat endpoint 2. Get processes list using docker api engine endpoint 3. Compare  Describe the results you received Describe the results you received Received a list of strings  Describe the results you expected Describe the results you expected Receive a list of lists of strings  podman info output yaml Podman is working fine on 5.2.2   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details It happens on any environment  Additional information _No response_
13831,podman,https://github.com/containers/podman/issues/13831,API build: remote parameter does not work,"I'm trying to build a docker file from my [repository](https://github.com/matheusfenolio/poc), but I'm receiving an error when I call the endpoint `curl -X POST http://localhost:8080/v2.0.0/libpod/build?remote=https%3A%2F%2Fgithub.com%2Fmatheusfenolio%2Fpoc` json { ""cause"": ""stat /var/tmp/libpod_builder4161196413/build/Containerfile: no such file or directory"", ""message"": ""failed to parse query parameter 'dockerfile': \""Dockerfile\"": stat /var/tmp/libpod_builder4161196413/build/Containerfile: no such file or directory"", ""response"": 400 }{ ""errorDetail"": { ""message"": ""stat /var/tmp/libpod_builder4161196413/build/Dockerfile: no such file or directory\n"" }, ""error"": ""stat /var/tmp/libpod_builder4161196413/build/Dockerfile: no such file or directory\n"" }  API reference: https://docs.podman.io/en/v3.2.3/_static/api.html#operation/ImageBuildLibpod",source-file | test-file | source-file | test-file,api remote parameter work trying docker repository https github matheusfenolio poc receiving call endpoint curl post http localhost libpod remote https fgithub fmatheusfenolio fpoc json cause stat var tmp libpod builder containerfile directory message failed parse query parameter dockerfile dockerfile stat var tmp libpod builder containerfile directory response errordetail message stat var tmp libpod builder dockerfile directory stat var tmp libpod builder dockerfile directory api reference https docs static api html operation imagebuildlibpod,bug,0.9,"API build: remote parameter does not work I'm trying to build a docker file from my [repository](https://github.com/matheusfenolio/poc), but I'm receiving an error when I call the endpoint `curl -X POST http://localhost:8080/v2.0.0/libpod/build?remote=https%3A%2F%2Fgithub.com%2Fmatheusfenolio%2Fpoc` json { ""cause"": ""stat /var/tmp/libpod_builder4161196413/build/Containerfile: no such file or directory"", ""message"": ""failed to parse query parameter 'dockerfile': \""Dockerfile\"": stat /var/tmp/libpod_builder4161196413/build/Containerfile: no such file or directory"", ""response"": 400 }{ ""errorDetail"": { ""message"": ""stat /var/tmp/libpod_builder4161196413/build/Dockerfile: no such file or directory\n"" }, ""error"": ""stat /var/tmp/libpod_builder4161196413/build/Dockerfile: no such file or directory\n"" }  API reference: https://docs.podman.io/en/v3.2.3/_static/api.html#operation/ImageBuildLibpod"
14647,podman,https://github.com/containers/podman/issues/14647,containers list api route response header is text/plain instead of application/json,"/kind bug **Description** Response content-type header is not `application/json` for containers list endpoint, although negotiation requests it. Some client libraries do attempt deserializing automatically to their data structures. Although it can be mitigated as an exception for this route, it should respect the negotiation. (v3 and v4 have the same behavior) **Steps to reproduce the issue:** 1. base url `v3.0.0` - `curl -v -X GET --unix-socket ""/run/user/1000/podman/podman.sock"" ""http://d/v3.0.0/libpod/containers/json"" -H ""Accept: application/json"" -H ""Content-Type: application/json""` 2. base url `v4.0.0` - `curl -v -X GET --unix-socket ""/run/user/1000/podman/podman.sock"" ""http://d/v4.0.0/libpod/containers/json"" -H ""Accept: application/json"" -H ""Content-Type: application/json""` **Describe the results you received:**  > GET /v4.0.0/libpod/containers/json HTTP/1.1  < Content-Type: text/plain; charset=us-ascii < Libpod-Api-Version: 4.1.0   **Describe the results you expected:**  > GET /v4.0.0/libpod/containers/json HTTP/1.1  < Content-Type: application/json; charset=us-ascii < Libpod-Api-Version: 4.1.0   If any use, issued the same for docker api and it does have `application/json` as response content-type header  docker --version Docker version 20.10.16, build aa7e414fdc   curl -v -X GET --unix-socket ""/var/run/docker.sock"" ""http://localhost/containers/json"" -H ""Accept: application/json"" -H ""Content-Type: application/json"" Note: Unnecessary use of -X or --request, GET is already inferred. * Trying /var/run/docker.sock:0 * Connected to localhost (/run/docker.sock) port 80 (#0) > GET /containers/json HTTP/1.1 > Host: localhost > User-Agent: curl/7.83.1 > Accept: application/json > Content-Type: application/json > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Docker-Experimental: false < Ostype: linux < Server: Docker/20.10.16 (linux) < Date: Fri, 17 Jun 2022 15:57:22 GMT < Transfer-Encoding: chunked  > IMPORTANT EDIT - It only happens when the list of containers is empty, as soon as at least one is present it respects!",source-file | test-file,containers list api route response header text plain instead application json kind bug description response content type header application json containers list endpoint although negotiation requests client libraries attempt deserializing automatically data structures although mitigated exception route respect negotiation behavior steps reproduce base url curl get unix socket user sock http libpod containers json accept application json content type application json base url curl get unix socket user sock http libpod containers json accept application json content type application json describe results received get libpod containers json http content type text plain charset ascii libpod api describe results expected get libpod containers json http content type application json charset ascii libpod api use issued docker api application json response content type header docker docker fdc curl get unix socket var docker sock http localhost containers json accept application json content type application json note unnecessary use get already inferred trying var docker sock connected localhost docker sock port get containers json http host localhost user agent curl accept application json content type application json mark bundle supporting multiuse http api content type application json docker experimental false ostype linux server docker linux date jun gmt transfer encoding chunked important edit happens list containers empty soon least one present respects,bug,0.95,"containers list api route response header is text/plain instead of application/json /kind bug **Description** Response content-type header is not `application/json` for containers list endpoint, although negotiation requests it. Some client libraries do attempt deserializing automatically to their data structures. Although it can be mitigated as an exception for this route, it should respect the negotiation. (v3 and v4 have the same behavior) **Steps to reproduce the issue:** 1. base url `v3.0.0` - `curl -v -X GET --unix-socket ""/run/user/1000/podman/podman.sock"" ""http://d/v3.0.0/libpod/containers/json"" -H ""Accept: application/json"" -H ""Content-Type: application/json""` 2. base url `v4.0.0` - `curl -v -X GET --unix-socket ""/run/user/1000/podman/podman.sock"" ""http://d/v4.0.0/libpod/containers/json"" -H ""Accept: application/json"" -H ""Content-Type: application/json""` **Describe the results you received:**  > GET /v4.0.0/libpod/containers/json HTTP/1.1  < Content-Type: text/plain; charset=us-ascii < Libpod-Api-Version: 4.1.0   **Describe the results you expected:**  > GET /v4.0.0/libpod/containers/json HTTP/1.1  < Content-Type: application/json; charset=us-ascii < Libpod-Api-Version: 4.1.0   If any use, issued the same for docker api and it does have `application/json` as response content-type header  docker --version Docker version 20.10.16, build aa7e414fdc   curl -v -X GET --unix-socket ""/var/run/docker.sock"" ""http://localhost/containers/json"" -H ""Accept: application/json"" -H ""Content-Type: application/json"" Note: Unnecessary use of -X or --request, GET is already inferred. * Trying /var/run/docker.sock:0 * Connected to localhost (/run/docker.sock) port 80 (#0) > GET /containers/json HTTP/1.1 > Host: localhost > User-Agent: curl/7.83.1 > Accept: application/json > Content-Type: application/json > * Mark bundle as not supporting multiuse < HTTP/1.1 200 OK < Api-Version: 1.41 < Content-Type: application/json < Docker-Experimental: false < Ostype: linux < Server: Docker/20.10.16 (linux) < Date: Fri, 17 Jun 2022 15:57:22 GMT < Transfer-Encoding: chunked  > IMPORTANT EDIT - It only happens when the list of containers is empty, as soon as at least one is present it respects!"
17524,podman,https://github.com/containers/podman/issues/17524,podman socket API top returns Titles as single string instead of array of strings," Issue Description I'm using RHEL 9.1 and podman 4.2.0 with crun 1.5. I was trying to get a container functional with is based on [newrelic infrastructure agent](https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/). The agent was tested with docker initially, but I wanted to test it using podman. As the container requires the docker socket to be mounted into the container I started the podman.socket. However I noticed that there were errors regarding querying container processes using the `docker top` from within the container. That is the container queries the REST API of the podman.socket for processes. Curious on what why this is failing I investigated the podman REST endpoint and found that the GET request documented here: https://docs.podman.io/en/latest/_static/api.html#tag/containers-(compat)/operation/ContainerList behaves different for the ""Titles"" field in the response. This should be an array of strings, however using: curl --silent -XGET --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock -H 'Content-Type: application/json' http://localhost/containers/321be6b5b7264ee5dfe651fe78355c3ce450c3167f245136bcf5cb66ae9107fe/top delivers ONE string for ""Titles"": { ,""Titles"":[**""PID USER TIME COMMAND""**]} However this is ONE string and not an array as stated in the documentation.  Steps to reproduce the issue Steps to reproduce the issue 1. systemctl --user start podman.socket 2. start at least one container and note the id of that container 3. curl --silent -XGET --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock -H 'Content-Type: application/json' http://localhost/containers/<CONTAINER_ID_REPLACE_ME>/top  Describe the results you received The ""Titles"" from the response is: { ,""Titles"":[**""PID USER TIME COMMAND""**]}  Describe the results you expected The ""Titles"" field should be: ""Titles"":[**""PID"", ""USER"", ""TIME"", ""COMMAND""**]}  podman info output yaml host: arch: amd64 buildahVersion: 1.27.3 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.4-1.el9.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.4, commit: 56561007b6a59ea175ee9a67384639721499e160' cpuUtilization: idlePercent: 99.66 systemPercent: 0.08 userPercent: 0.26 cpus: 8 distribution: distribution: '""rhel""' version: ""9.1"" eventLogger: journald hostname: noname idMappings: gidmap: - container_id: 0 host_id: 2019 size: 1 - container_id: 1 host_id: 1476256 size: 65536 uidmap: - container_id: 0 host_id: 2019 size: 1 - container_id: 1 host_id: 1476256 size: 65536 kernel: 5.14.0-162.12.1.el9_1.x86_64 linkmode: dynamic logDriver: journald memFree: 132173471744 memTotal: 134531371008 networkBackend: netavark ociRuntime: name: crun package: crun-1.5-1.el9.x86_64 path: /usr/bin/crun version: |- crun version 1.5 commit: 54ebb8ca8bf7e6ddae2eb919f5b82d1d96863dea spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/user/2019/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-2.el9_0.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 4294963200 swapTotal: 4294963200 uptime: 73h 7m 7.00s (Approximately 3.04 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.access.redhat.com - registry.redhat.io - docker.io store: configFile: /home/noname/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/noname/.local/share/containers/storage graphRootAllocated: 33246150656 graphRootUsed: 2582650880 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 4 runRoot: /run/user/2019/containers volumePath: /home/noname/.local/share/containers/storage/volumes version: APIVersion: 4.2.0 Built: 1670843566 BuiltTime: Mon Dec 12 12:12:46 2022 GitCommit: """" GoVersion: go1.18.4 Os: linux OsArch: linux/amd64 Version: 4.2.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release No  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | source-file | source-file | test-file | source-file | source-file | source-file | test-file,socket api top returns titles single string instead array strings description rhel crun trying get container functional based newrelic infrastructure agent https docs newrelic docs infrastructure install infrastructure agent linux installation docker instrumentation infrastructure monitoring agent tested docker initially wanted container requires docker socket mounted container started socket however noticed errors regarding querying container processes docker top within container container queries rest api socket processes curious failing investigated rest endpoint found get documented https docs latest static api html tag containers compat operation containerlist behaves different titles field response array strings however curl silent xget unix socket xdg runtime dir sock content type application json http localhost containers dfe bcf top delivers one string titles titles pid user time command however one string array stated documentation steps reproduce steps reproduce systemctl user start socket start least one container note container curl silent xget unix socket xdg runtime dir sock content type application json http localhost containers container replace top describe results received titles response titles pid user time command describe results expected titles field titles pid user time command output yaml host arch amd buildahversion cgroupcontrollers memory pids cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution rhel eventlogger journald hostname noname idmappings gidmap container host size container host size uidmap container host size container host size kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun ebb ddae dea spec systemd selinux apparmor cap seccomp ebpf criu yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap raw cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan volume local registries search registry access redhat registry redhat docker store configfile home noname config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home noname local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers volumepath home noname local share containers storage volumes apiversion built builttime dec gitcommit goversion linux osarch linux amd container privileged rootless rootless upstream latest additional environment details additional environment details additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.95,"podman socket API top returns Titles as single string instead of array of strings  Issue Description I'm using RHEL 9.1 and podman 4.2.0 with crun 1.5. I was trying to get a container functional with is based on [newrelic infrastructure agent](https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/docker-instrumentation-infrastructure-monitoring/). The agent was tested with docker initially, but I wanted to test it using podman. As the container requires the docker socket to be mounted into the container I started the podman.socket. However I noticed that there were errors regarding querying container processes using the `docker top` from within the container. That is the container queries the REST API of the podman.socket for processes. Curious on what why this is failing I investigated the podman REST endpoint and found that the GET request documented here: https://docs.podman.io/en/latest/_static/api.html#tag/containers-(compat)/operation/ContainerList behaves different for the ""Titles"" field in the response. This should be an array of strings, however using: curl --silent -XGET --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock -H 'Content-Type: application/json' http://localhost/containers/321be6b5b7264ee5dfe651fe78355c3ce450c3167f245136bcf5cb66ae9107fe/top delivers ONE string for ""Titles"": { ,""Titles"":[**""PID USER TIME COMMAND""**]} However this is ONE string and not an array as stated in the documentation.  Steps to reproduce the issue Steps to reproduce the issue 1. systemctl --user start podman.socket 2. start at least one container and note the id of that container 3. curl --silent -XGET --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock -H 'Content-Type: application/json' http://localhost/containers/<CONTAINER_ID_REPLACE_ME>/top  Describe the results you received The ""Titles"" from the response is: { ,""Titles"":[**""PID USER TIME COMMAND""**]}  Describe the results you expected The ""Titles"" field should be: ""Titles"":[**""PID"", ""USER"", ""TIME"", ""COMMAND""**]}  podman info output yaml host: arch: amd64 buildahVersion: 1.27.3 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.4-1.el9.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.4, commit: 56561007b6a59ea175ee9a67384639721499e160' cpuUtilization: idlePercent: 99.66 systemPercent: 0.08 userPercent: 0.26 cpus: 8 distribution: distribution: '""rhel""' version: ""9.1"" eventLogger: journald hostname: noname idMappings: gidmap: - container_id: 0 host_id: 2019 size: 1 - container_id: 1 host_id: 1476256 size: 65536 uidmap: - container_id: 0 host_id: 2019 size: 1 - container_id: 1 host_id: 1476256 size: 65536 kernel: 5.14.0-162.12.1.el9_1.x86_64 linkmode: dynamic logDriver: journald memFree: 132173471744 memTotal: 134531371008 networkBackend: netavark ociRuntime: name: crun package: crun-1.5-1.el9.x86_64 path: /usr/bin/crun version: |- crun version 1.5 commit: 54ebb8ca8bf7e6ddae2eb919f5b82d1d96863dea spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux remoteSocket: exists: true path: /run/user/2019/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-2.el9_0.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 4294963200 swapTotal: 4294963200 uptime: 73h 7m 7.00s (Approximately 3.04 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.access.redhat.com - registry.redhat.io - docker.io store: configFile: /home/noname/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/noname/.local/share/containers/storage graphRootAllocated: 33246150656 graphRootUsed: 2582650880 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 4 runRoot: /run/user/2019/containers volumePath: /home/noname/.local/share/containers/storage/volumes version: APIVersion: 4.2.0 Built: 1670843566 BuiltTime: Mon Dec 12 12:12:46 2022 GitCommit: """" GoVersion: go1.18.4 Os: linux OsArch: linux/amd64 Version: 4.2.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release No  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
23163,podman,https://github.com/containers/podman/issues/23163,Podman manifest inspect does not display remote annotations," Issue Description Related to [discussions in thread](https://github.com/containers/podman/discussions/23140) If you run `podman manifest inspect quay.io/giuseppe/zstd-chunked:fedora-manifest` on any remote manifest, you are unable to see the annotations which were added to the zstd:chunked manifest. Compare the output of the following commands:  $ skopeo inspect --raw docker://quay.io/giuseppe/zstd-chunked:fedora-manifest | jq .   $ podman manifest inspect quay.io/giuseppe/zstd-chunked:fedora-manifest   Steps to reproduce the issue See above. 1. Push a manifest containing an image with annotations to any remote registry 2. Run `podman manifest inspect` on the local manifest (and see annotations) 3. Run `podman manifest inspect` on the remote manifest (and see no annotations)  Describe the results you received As above  Describe the results you expected I would expect `podman manifest inspect` to show all annotations on the manifests, since an annotation is a requirement for zstd images. When running `skopeo inspect --raw`, we can see the annotations, so I expected Podman to return the same.  podman info output yaml host: arch: amd64 buildahVersion: 1.36.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.10-1.fc40.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.10, commit: ' cpuUtilization: idlePercent: 96.86 systemPercent: 1.56 userPercent: 1.58 cpus: 24 databaseBackend: sqlite distribution: distribution: fedora variant: silverblue version: ""40"" eventLogger: journald freeLocks: 2045 hostname: fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 kernel: 6.8.11-300.fc40.x86_64 linkmode: dynamic logDriver: journald memFree: 13290414080 memTotal: 33364271104 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.11.0-1.fc40.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.11.0 package: netavark-1.11.0-1.fc40.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.11.0 ociRuntime: name: crun package: crun-1.15-1.fc40.x86_64 path: /usr/bin/crun version: |- crun version 1.15 commit: e6eacaf4034e84185fd8780ac9262bbf57082278 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20240624.g1ee2eca-1.fc40.x86_64 version: | pasta 0^20240624.g1ee2eca-1.fc40.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: false path: /run/user/1000/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-2.fc40.x86_64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.5 swapFree: 8589930496 swapTotal: 8589930496 uptime: 2h 16m 4.00s (Approximately 0.08 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: ghcr.io/rsturla: Blocked: false Insecure: false Location: ghcr.io/rsturla MirrorByDigestOnly: false Mirrors: - Insecure: true Location: localhost:5000/rsturla PullFromMirror: """" Prefix: ghcr.io/rsturla PullFromMirror: """" localhost:5000: Blocked: false Insecure: true Location: localhost:5000 MirrorByDigestOnly: false Mirrors: null Prefix: localhost:5000 PullFromMirror: """" search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /var/home/admin/.config/containers/storage.conf containerStore: number: 1 paused: 0 running: 0 stopped: 1 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/admin/.local/share/containers/storage graphRootAllocated: 1998678130688 graphRootUsed: 285504368640 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 9 runRoot: /run/user/1000/containers transientStore: false volumePath: /var/home/admin/.local/share/containers/storage/volumes version: APIVersion: 5.1.1 Built: 1717459200 BuiltTime: Tue Jun 4 01:00:00 2024 GitCommit: """" GoVersion: go1.22.3 Os: linux OsArch: linux/amd64 Version: 5.1.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details N/A  Additional information N/A",source-file | source-file | source-file | source-file | source-file | test-file,manifest inspect display remote annotations description related discussions thread https github containers discussions manifest inspect quay giuseppe zstd chunked fedora manifest remote manifest unable see annotations added zstd chunked manifest compare output following commands skopeo inspect raw docker quay giuseppe zstd chunked fedora manifest manifest inspect quay giuseppe zstd chunked fedora manifest steps reproduce see push manifest containing image annotations remote registry manifest inspect local manifest see annotations manifest inspect remote manifest see annotations describe results received describe results expected would expect manifest inspect show annotations manifests since annotation requirement zstd images running skopeo inspect raw see annotations expected return output yaml host arch amd buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution fedora variant silverblue eventlogger journald freelocks hostname fedora idmappings gidmap container host size container host size uidmap container host size container host size kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns path libexec aardvark dns aardvark dns package netavark path libexec netavark netavark ociruntime name crun package crun path crun crun eacaf bbf rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt eca pasta eca copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists false path user sock rootlessnetworkcmd pasta security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns faf libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries ghcr rsturla blocked false insecure false location ghcr rsturla mirrorbydigestonly false mirrors insecure true location localhost rsturla pullfrommirror prefix ghcr rsturla pullfrommirror localhost blocked false insecure true location localhost mirrorbydigestonly false mirrors null prefix localhost pullfrommirror search registry fedoraproject registry access redhat docker store configfile var home admin config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot var home admin local share containers storage graphrootallocated graphrootused graphstatus backing filesystem btrfs native overlay diff true supports type true supports shifting false supports volatile true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath var home admin local share containers storage volumes apiversion built builttime jun gitcommit goversion linux osarch linux amd container privileged rootless none upstream latest yes additional environment details additional information,bug,0.9,"Podman manifest inspect does not display remote annotations  Issue Description Related to [discussions in thread](https://github.com/containers/podman/discussions/23140) If you run `podman manifest inspect quay.io/giuseppe/zstd-chunked:fedora-manifest` on any remote manifest, you are unable to see the annotations which were added to the zstd:chunked manifest. Compare the output of the following commands:  $ skopeo inspect --raw docker://quay.io/giuseppe/zstd-chunked:fedora-manifest | jq .   $ podman manifest inspect quay.io/giuseppe/zstd-chunked:fedora-manifest   Steps to reproduce the issue See above. 1. Push a manifest containing an image with annotations to any remote registry 2. Run `podman manifest inspect` on the local manifest (and see annotations) 3. Run `podman manifest inspect` on the remote manifest (and see no annotations)  Describe the results you received As above  Describe the results you expected I would expect `podman manifest inspect` to show all annotations on the manifests, since an annotation is a requirement for zstd images. When running `skopeo inspect --raw`, we can see the annotations, so I expected Podman to return the same.  podman info output yaml host: arch: amd64 buildahVersion: 1.36.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.10-1.fc40.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.10, commit: ' cpuUtilization: idlePercent: 96.86 systemPercent: 1.56 userPercent: 1.58 cpus: 24 databaseBackend: sqlite distribution: distribution: fedora variant: silverblue version: ""40"" eventLogger: journald freeLocks: 2045 hostname: fedora idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 524288 size: 65536 kernel: 6.8.11-300.fc40.x86_64 linkmode: dynamic logDriver: journald memFree: 13290414080 memTotal: 33364271104 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.11.0-1.fc40.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.11.0 package: netavark-1.11.0-1.fc40.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.11.0 ociRuntime: name: crun package: crun-1.15-1.fc40.x86_64 path: /usr/bin/crun version: |- crun version 1.15 commit: e6eacaf4034e84185fd8780ac9262bbf57082278 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20240624.g1ee2eca-1.fc40.x86_64 version: | pasta 0^20240624.g1ee2eca-1.fc40.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: false path: /run/user/1000/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-2.fc40.x86_64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.5 swapFree: 8589930496 swapTotal: 8589930496 uptime: 2h 16m 4.00s (Approximately 0.08 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: ghcr.io/rsturla: Blocked: false Insecure: false Location: ghcr.io/rsturla MirrorByDigestOnly: false Mirrors: - Insecure: true Location: localhost:5000/rsturla PullFromMirror: """" Prefix: ghcr.io/rsturla PullFromMirror: """" localhost:5000: Blocked: false Insecure: true Location: localhost:5000 MirrorByDigestOnly: false Mirrors: null Prefix: localhost:5000 PullFromMirror: """" search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io store: configFile: /var/home/admin/.config/containers/storage.conf containerStore: number: 1 paused: 0 running: 0 stopped: 1 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/admin/.local/share/containers/storage graphRootAllocated: 1998678130688 graphRootUsed: 285504368640 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 9 runRoot: /run/user/1000/containers transientStore: false volumePath: /var/home/admin/.local/share/containers/storage/volumes version: APIVersion: 5.1.1 Built: 1717459200 BuiltTime: Tue Jun 4 01:00:00 2024 GitCommit: """" GoVersion: go1.22.3 Os: linux OsArch: linux/amd64 Version: 5.1.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details N/A  Additional information N/A"
20469,podman,https://github.com/containers/podman/issues/20469,"Error when use ""image prune --all"" via forwarding API and docker cli"," Issue Description If an image exists in Podman that is no longer in use and the command ""docker image prune -a"" is executed via the Forward API and Docker CLI, the error message ""Error response from daemon: specifying ""dangling"" filter more than once with different values is not supported"" appears. If the command is executed via ""podman image prune -a"", the cleanup works correctly.  Steps to reproduce the issue Steps to reproduce the issue 1. Download Image `docker pull nginx` 2. Clean Images `docker image prune -a`  Describe the results you received Error Message: Error response from daemon: specifying ""dangling"" filter more than once with different values is not supported  Describe the results you expected The image should be removed.  podman info output yaml host: arch: amd64 buildahVersion: 1.32.0 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - hugetlb - pids - rdma - misc cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.7-2.fc38.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 99.64 systemPercent: 0.2 userPercent: 0.15 cpus: 4 databaseBackend: boltdb distribution: distribution: fedora variant: container version: ""38"" eventLogger: journald freeLocks: 2048 hostname: VGENERAL96 idMappings: gidmap: null uidmap: null kernel: 5.15.133.1-microsoft-standard-WSL2 linkmode: dynamic logDriver: journald memFree: 7665016832 memTotal: 10413207552 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.8.0-1.fc38.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.8.0 package: netavark-1.8.0-2.fc38.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.8.0 ociRuntime: name: crun package: crun-1.10-1.fc38.x86_64 path: /usr/bin/crun version: |- crun version 1.10 commit: c053c83c57551bca13ead8600237341818975974 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20231004.gf851084-1.fc38.x86_64 version: | pasta 0^20231004.gf851084-1.fc38.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc38.x86_64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 3221225472 swapTotal: 3221225472 uptime: 2h 34m 17.00s (Approximately 0.08 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 1081101176832 graphRootUsed: 2787717120 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 47 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.7.0 Built: 1695839078 BuiltTime: Wed Sep 27 20:24:38 2023 GitCommit: """" GoVersion: go1.20.8 Os: linux OsArch: linux/amd64 Version: 4.7.0   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details OS: Windows 2022 WSL version: 2.0.6.0 Kernel version: 5.15.133.1-1 WSLg version: 1.0.59 MSRDC version: 1.2.4677 Direct3D version: 1.611.1-81528511 DXCore version: 10.0.25880.1000-230602-1350.main Windows version: 10.0.20348.1787 Podman Version: 4.7.1 Docker CLI Version 24.0.6, build ed223bc",source-file | test-file,use image prune via forwarding api docker cli description image exists longer use command docker image prune executed via forward api docker cli message response daemon specifying dangling filter different values supported appears command executed via image prune cleanup works correctly steps reproduce steps reproduce download image docker nginx clean images docker image prune describe results received message response daemon specifying dangling filter different values supported describe results expected image removed output yaml host arch amd buildahversion cgroupcontrollers cpuset cpu cpuacct blkio memory devices freezer cls perf event prio hugetlb pids rdma misc cgroupmanager cgroupfs cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend boltdb distribution distribution fedora variant container eventlogger journald freelocks hostname vgeneral idmappings gidmap null uidmap null kernel microsoft standard wsl linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns path libexec aardvark dns aardvark dns package netavark path libexec netavark netavark ociruntime name crun package crun path crun crun bca ead rundir crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote true slirp netns executable slirp netns package slirp netns slirp netns faf libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search docker store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff false supports type true supports shifting false supports volatile true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime sep gitcommit goversion linux osarch linux amd container privileged rootless privileged upstream latest yes additional environment details windows wsl kernel wslg msrdc direct dxcore windows docker cli,bug,0.9,"Error when use ""image prune --all"" via forwarding API and docker cli  Issue Description If an image exists in Podman that is no longer in use and the command ""docker image prune -a"" is executed via the Forward API and Docker CLI, the error message ""Error response from daemon: specifying ""dangling"" filter more than once with different values is not supported"" appears. If the command is executed via ""podman image prune -a"", the cleanup works correctly.  Steps to reproduce the issue Steps to reproduce the issue 1. Download Image `docker pull nginx` 2. Clean Images `docker image prune -a`  Describe the results you received Error Message: Error response from daemon: specifying ""dangling"" filter more than once with different values is not supported  Describe the results you expected The image should be removed.  podman info output yaml host: arch: amd64 buildahVersion: 1.32.0 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - hugetlb - pids - rdma - misc cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.7-2.fc38.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 99.64 systemPercent: 0.2 userPercent: 0.15 cpus: 4 databaseBackend: boltdb distribution: distribution: fedora variant: container version: ""38"" eventLogger: journald freeLocks: 2048 hostname: VGENERAL96 idMappings: gidmap: null uidmap: null kernel: 5.15.133.1-microsoft-standard-WSL2 linkmode: dynamic logDriver: journald memFree: 7665016832 memTotal: 10413207552 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.8.0-1.fc38.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.8.0 package: netavark-1.8.0-2.fc38.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.8.0 ociRuntime: name: crun package: crun-1.10-1.fc38.x86_64 path: /usr/bin/crun version: |- crun version 1.10 commit: c053c83c57551bca13ead8600237341818975974 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20231004.gf851084-1.fc38.x86_64 version: | pasta 0^20231004.gf851084-1.fc38.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc38.x86_64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 3221225472 swapTotal: 3221225472 uptime: 2h 34m 17.00s (Approximately 0.08 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 1081101176832 graphRootUsed: 2787717120 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 47 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.7.0 Built: 1695839078 BuiltTime: Wed Sep 27 20:24:38 2023 GitCommit: """" GoVersion: go1.20.8 Os: linux OsArch: linux/amd64 Version: 4.7.0   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details OS: Windows 2022 WSL version: 2.0.6.0 Kernel version: 5.15.133.1-1 WSLg version: 1.0.59 MSRDC version: 1.2.4677 Direct3D version: 1.611.1-81528511 DXCore version: 10.0.25880.1000-230602-1350.main Windows version: 10.0.20348.1787 Podman Version: 4.7.1 Docker CLI Version 24.0.6, build ed223bc"
24886,podman,https://github.com/containers/podman/issues/24886,"Podman REST API /libpod/containers/create ""r_limits"" is type integer <uint64>"," Issue Description https://docs.podman.io/en/latest/_static/api.html#tag/containers/operation/ContainerCreateLibpod r_limits hard integer <uint64> Hard is the hard limit for the specified type soft integer <uint64> Soft is the soft limit for the specified type There is no direct reference to Ulimits. https://github.com/containers/podman/pull/19879 In PR 19879 Podman added support for passing Ulimits as -1 to mean min / max  Steps to reproduce the issue /podman-py containers_create https://github.com/containers/podman-py/blob/main/podman/domain/containers_create.py  for item in args.pop(""ulimits"", []): params[""r_limits""].append( { ""type"": item[""Name""], ""hard"": item[""Hard""], ""soft"": item[""Soft""], } )  Code Example `client.containers.create(image=img, command=['/bin/bash'], ulimits=[{""Name"": ""memlock"", ""Soft"": -1, ""Hard"": -1}])`  Describe the results you received `podman.errors.exceptions.APIError: 500 Server Error: Internal Server Error (decode(): json: cannot unmarshal number -1 into Go struct field POSIXRlimit.r_limits.hard of type uint64)`  Describe the results you expected Expected successful creation of container with memlock min/max set to maximum values.  podman info output yaml [root@omitted]# podman info host: arch: amd64 buildahVersion: 1.33.11 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - hugetlb - pids - rdma cgroupManager: systemd cgroupVersion: v1 conmon: package: conmon-2.1.10-1.module+el8.10.0+90449+0b7c8529.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.10, commit: 753128cb76d643886a978dba99fab8017289372d' cpuUtilization: idlePercent: 99.97 systemPercent: 0.01 userPercent: 0.02 cpus: 56 databaseBackend: sqlite distribution: distribution: ol variant: server version: ""8.3"" eventLogger: file freeLocks: 2047 hostname: omitted idMappings: gidmap: null uidmap: null kernel: 5.4.17-2011.7.4.el8uek.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 142581444608 memTotal: 200959377408 networkBackend: cni networkBackendInfo: backend: cni dns: package: podman-plugins-4.9.4-18.0.1.module+el8.10.0+90449+0b7c8529.x86_64 path: /usr/libexec/cni/dnsname version: |- CNI dnsname plugin version: 1.4.0-dev commit: unknown CNI protocol versions supported: 0.1.0, 0.2.0, 0.3.0, 0.3.1, 0.4.0, 1.0.0 package: containernetworking-plugins-1.4.0-5.module+el8.10.0+90449+0b7c8529.x86_64 path: /usr/libexec/cni ociRuntime: name: runc package: runc-1.1.12-5.module+el8.10.0+90449+0b7c8529.x86_64 path: /usr/bin/runc version: |- runc version 1.1.12 spec: 1.0.2-dev go: go1.22.7 (Red Hat 1.22.7-1.module+el8.10.0+90426+810ab996) libseccomp: 2.5.2 os: linux pasta: executable: """" package: """" version: """" remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /bin/slirp4netns package: slirp4netns-1.2.0-2.module+el8.8.0+21045+adcb6a64.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 4294963200 swapTotal: 4294963200 uptime: 1341h 26m 16.00s (Approximately 55.88 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - container-registry.oracle.com - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 1 paused: 0 running: 1 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 75125227520 graphRootUsed: 63892619264 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""false"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 33 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.9.4-rhel Built: 1732729681 BuiltTime: Wed Nov 27 17:48:01 2024 GitCommit: """" GoVersion: go1.22.7 (Red Hat 1.22.7-1.module+el8.10.0+90426+810ab996) Os: linux OsArch: linux/amd64 Version: 4.9.4-rhel   Podman in a container Yes  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | test-file | test-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | test-file | source-file | source-file | test-file | test-file | source-file | test-file | test-file | source-file | test-file | test-file,rest api libpod containers create limits type integer uint description https docs latest static api html tag containers operation containercreatelibpod limits hard integer uint hard hard limit specified type soft integer uint soft soft limit specified type direct reference ulimits https github containers added passing ulimits mean min max steps reproduce containers create https github containers blob domain containers create item args pop ulimits params limits append type item name hard item hard soft item soft example client containers create image img command bash ulimits name memlock soft hard describe results received errors exceptions apierror server internal server decode json cannot unmarshal number struct field posixrlimit limits hard type uint describe results expected expected successful creation container memlock min max set maximum values output yaml root omitted host arch amd buildahversion cgroupcontrollers cpuset cpu cpuacct blkio memory devices freezer cls perf event prio hugetlb pids rdma cgroupmanager systemd cgroupversion conmon package conmon module path conmon conmon dba fab cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution variant server eventlogger freelocks hostname omitted idmappings gidmap null uidmap null kernel uek linkmode dynamic logdriver memfree memtotal networkbackend cni networkbackendinfo backend cni dns package plugins module path libexec cni dnsname cni dnsname plugin unknown cni protocol versions supported package containernetworking plugins module path libexec cni ociruntime name runc package runc module path runc runc spec red hat module libseccomp linux pasta executable package remotesocket exists true path sock security apparmorenabled false capabilities cap raw cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns module adcb slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search container registry oracle docker store configfile etc containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff false supports type true supports shifting false supports volatile false metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion rhel built builttime nov gitcommit goversion red hat module linux osarch linux amd rhel container yes privileged rootless privileged upstream latest yes additional environment details additional environment details additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.95,"Podman REST API /libpod/containers/create ""r_limits"" is type integer <uint64>  Issue Description https://docs.podman.io/en/latest/_static/api.html#tag/containers/operation/ContainerCreateLibpod r_limits hard integer <uint64> Hard is the hard limit for the specified type soft integer <uint64> Soft is the soft limit for the specified type There is no direct reference to Ulimits. https://github.com/containers/podman/pull/19879 In PR 19879 Podman added support for passing Ulimits as -1 to mean min / max  Steps to reproduce the issue /podman-py containers_create https://github.com/containers/podman-py/blob/main/podman/domain/containers_create.py  for item in args.pop(""ulimits"", []): params[""r_limits""].append( { ""type"": item[""Name""], ""hard"": item[""Hard""], ""soft"": item[""Soft""], } )  Code Example `client.containers.create(image=img, command=['/bin/bash'], ulimits=[{""Name"": ""memlock"", ""Soft"": -1, ""Hard"": -1}])`  Describe the results you received `podman.errors.exceptions.APIError: 500 Server Error: Internal Server Error (decode(): json: cannot unmarshal number -1 into Go struct field POSIXRlimit.r_limits.hard of type uint64)`  Describe the results you expected Expected successful creation of container with memlock min/max set to maximum values.  podman info output yaml [root@omitted]# podman info host: arch: amd64 buildahVersion: 1.33.11 cgroupControllers: - cpuset - cpu - cpuacct - blkio - memory - devices - freezer - net_cls - perf_event - net_prio - hugetlb - pids - rdma cgroupManager: systemd cgroupVersion: v1 conmon: package: conmon-2.1.10-1.module+el8.10.0+90449+0b7c8529.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.10, commit: 753128cb76d643886a978dba99fab8017289372d' cpuUtilization: idlePercent: 99.97 systemPercent: 0.01 userPercent: 0.02 cpus: 56 databaseBackend: sqlite distribution: distribution: ol variant: server version: ""8.3"" eventLogger: file freeLocks: 2047 hostname: omitted idMappings: gidmap: null uidmap: null kernel: 5.4.17-2011.7.4.el8uek.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 142581444608 memTotal: 200959377408 networkBackend: cni networkBackendInfo: backend: cni dns: package: podman-plugins-4.9.4-18.0.1.module+el8.10.0+90449+0b7c8529.x86_64 path: /usr/libexec/cni/dnsname version: |- CNI dnsname plugin version: 1.4.0-dev commit: unknown CNI protocol versions supported: 0.1.0, 0.2.0, 0.3.0, 0.3.1, 0.4.0, 1.0.0 package: containernetworking-plugins-1.4.0-5.module+el8.10.0+90449+0b7c8529.x86_64 path: /usr/libexec/cni ociRuntime: name: runc package: runc-1.1.12-5.module+el8.10.0+90449+0b7c8529.x86_64 path: /usr/bin/runc version: |- runc version 1.1.12 spec: 1.0.2-dev go: go1.22.7 (Red Hat 1.22.7-1.module+el8.10.0+90426+810ab996) libseccomp: 2.5.2 os: linux pasta: executable: """" package: """" version: """" remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_NET_RAW,CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /bin/slirp4netns package: slirp4netns-1.2.0-2.module+el8.8.0+21045+adcb6a64.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 4294963200 swapTotal: 4294963200 uptime: 1341h 26m 16.00s (Approximately 55.88 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - container-registry.oracle.com - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 1 paused: 0 running: 1 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 75125227520 graphRootUsed: 63892619264 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""false"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 33 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.9.4-rhel Built: 1732729681 BuiltTime: Wed Nov 27 17:48:01 2024 GitCommit: """" GoVersion: go1.22.7 (Red Hat 1.22.7-1.module+el8.10.0+90426+810ab996) Os: linux OsArch: linux/amd64 Version: 4.9.4-rhel   Podman in a container Yes  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
21311,podman,https://github.com/containers/podman/issues/21311,Network connect/disconnect events don't include network ID/name," Issue Description Podman network events as emitted by `podman events` (connect, disconnect) don't include the network name or ID, making it impossible to use events to watch for changes to a specific network. Looking at the source code, the network name is included in the low level event data, but seems to be lost when converting between libpod Events and Docker compatible events via [ConvertToEntitiesEvent](https://github.com/containers/podman/blob/815ae77ab26cea3a5430116db682d9df46fc8845/pkg/domain/entities/events.go#L62) and [ConvertToLibpodEvent](https://github.com/containers/podman/blob/815ae77ab26cea3a5430116db682d9df46fc8845/pkg/domain/entities/events.go#L21).  Steps to reproduce the issue Steps to reproduce the issue 1. Run `podman events --format json` 2. In another terminal window, connect or disconnect a container to any networks `podman network connect <network> <container>` or `podman network disconenct <network> <container>` 3. Check the contents of the `Connect` and `Disconnect` events emitted  Describe the results you received I see events like this emitted: json {""ID"":""3d9d442dab9029e5e1b5d82307972ce3ff9b9f49d0473b4b762f256bdee1f96f"",""Status"":""disconnect"",""Time"":""2024-01-19T13:48:43.873758119-08:00"",""Type"":""network"",""Attributes"":{""podId"":""""}} {""ID"":""3d9d442dab9029e5e1b5d82307972ce3ff9b9f49d0473b4b762f256bdee1f96f"",""Status"":""connect"",""Time"":""2024-01-19T14:10:31.823991946-08:00"",""Type"":""network"",""Attributes"":{""podId"":""""}}  Each network event includes the ID of the relevant container, but not the ID or name of the network the container was connected to (or disconnected from).  Describe the results you expected I expect to see events like: json {""ID"":""3d9d442dab9029e5e1b5d82307972ce3ff9b9f49d0473b4b762f256bdee1f96f"",""Status"":""disconnect"",""Time"":""2024-01-19T13:48:43.873758119-08:00"",""Type"":""network"",""Network"":""test"",""Attributes"":{""podId"":""""}} {""ID"":""3d9d442dab9029e5e1b5d82307972ce3ff9b9f49d0473b4b762f256bdee1f96f"",""Status"":""connect"",""Time"":""2024-01-19T14:10:31.823991946-08:00"",""Type"":""network"",""Network"":""test"",""Attributes"":{""podId"":""""}}   podman info output yaml host: arch: arm64 buildahVersion: 1.33.2 cgroupControllers: - cpuset - cpu - io - memory - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.8-2.fc39.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.8, commit: ' cpuUtilization: idlePercent: 99.54 systemPercent: 0.22 userPercent: 0.24 cpus: 2 databaseBackend: sqlite distribution: distribution: fedora variant: coreos version: ""39"" eventLogger: journald freeLocks: 2045 hostname: localhost.localdomain idMappings: gidmap: null uidmap: null kernel: 6.6.8-200.fc39.aarch64 linkmode: dynamic logDriver: journald memFree: 616837120 memTotal: 3795222528 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.9.0-1.fc39.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.9.0 package: netavark-1.9.0-1.fc39.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.9.0 ociRuntime: name: crun package: crun-1.12-1.fc39.aarch64 path: /usr/bin/crun version: |- crun version 1.12 commit: ce429cb2e277d001c2179df1ac66a470f00802ae rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20231204.gb86afe3-1.fc39.aarch64 version: | pasta 0^20231204.gb86afe3-1.fc39.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc39.aarch64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 36h 19m 18.00s (Approximately 1.50 days) variant: v8 plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 1 paused: 0 running: 1 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 99252940800 graphRootUsed: 4171116544 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 6 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.8.2 Built: 1702300963 BuiltTime: Mon Dec 11 05:22:43 2023 GitCommit: """" GoVersion: go1.21.4 Os: linux OsArch: linux/arm64 Version: 4.8.2   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details Podman Desktop (v1.6.4) on ARM64 MacOS  Additional information _No response_",source-file | test-file,network connect disconnect events include network name description network events emitted events connect disconnect include network name making impossible use events watch changes specific network looking network name included low level event data seems lost converting libpod events docker compatible events via converttoentitiesevent https github containers blob cea pkg domain entities events converttolibpodevent https github containers blob cea pkg domain entities events steps reproduce steps reproduce events format json another terminal window connect disconnect container networks network connect network container network disconenct network container check contents connect disconnect events emitted describe results received see events like emitted json dab bdee status disconnect time type network attributes podid dab bdee status connect time type network attributes podid network event includes relevant container name network container connected disconnected describe results expected expect see events like json dab bdee status disconnect time type network network attributes podid dab bdee status connect time type network network attributes podid output yaml host arch arm buildahversion cgroupcontrollers cpuset cpu memory pids rdma misc cgroupmanager systemd cgroupversion conmon package conmon aarch path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution fedora variant coreos eventlogger journald freelocks hostname localhost localdomain idmappings gidmap null uidmap null kernel aarch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns aarch path libexec aardvark dns aardvark dns package netavark aarch path libexec netavark netavark ociruntime name crun package crun aarch path crun crun rundir crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt afe aarch pasta afe aarch pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote true slirp netns executable slirp netns package slirp netns aarch slirp netns faf libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search docker store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff false supports type true supports shifting true supports volatile true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime dec gitcommit goversion linux osarch linux arm container privileged rootless privileged upstream latest yes additional environment details desktop arm macos additional information response,bug,0.95,"Network connect/disconnect events don't include network ID/name  Issue Description Podman network events as emitted by `podman events` (connect, disconnect) don't include the network name or ID, making it impossible to use events to watch for changes to a specific network. Looking at the source code, the network name is included in the low level event data, but seems to be lost when converting between libpod Events and Docker compatible events via [ConvertToEntitiesEvent](https://github.com/containers/podman/blob/815ae77ab26cea3a5430116db682d9df46fc8845/pkg/domain/entities/events.go#L62) and [ConvertToLibpodEvent](https://github.com/containers/podman/blob/815ae77ab26cea3a5430116db682d9df46fc8845/pkg/domain/entities/events.go#L21).  Steps to reproduce the issue Steps to reproduce the issue 1. Run `podman events --format json` 2. In another terminal window, connect or disconnect a container to any networks `podman network connect <network> <container>` or `podman network disconenct <network> <container>` 3. Check the contents of the `Connect` and `Disconnect` events emitted  Describe the results you received I see events like this emitted: json {""ID"":""3d9d442dab9029e5e1b5d82307972ce3ff9b9f49d0473b4b762f256bdee1f96f"",""Status"":""disconnect"",""Time"":""2024-01-19T13:48:43.873758119-08:00"",""Type"":""network"",""Attributes"":{""podId"":""""}} {""ID"":""3d9d442dab9029e5e1b5d82307972ce3ff9b9f49d0473b4b762f256bdee1f96f"",""Status"":""connect"",""Time"":""2024-01-19T14:10:31.823991946-08:00"",""Type"":""network"",""Attributes"":{""podId"":""""}}  Each network event includes the ID of the relevant container, but not the ID or name of the network the container was connected to (or disconnected from).  Describe the results you expected I expect to see events like: json {""ID"":""3d9d442dab9029e5e1b5d82307972ce3ff9b9f49d0473b4b762f256bdee1f96f"",""Status"":""disconnect"",""Time"":""2024-01-19T13:48:43.873758119-08:00"",""Type"":""network"",""Network"":""test"",""Attributes"":{""podId"":""""}} {""ID"":""3d9d442dab9029e5e1b5d82307972ce3ff9b9f49d0473b4b762f256bdee1f96f"",""Status"":""connect"",""Time"":""2024-01-19T14:10:31.823991946-08:00"",""Type"":""network"",""Network"":""test"",""Attributes"":{""podId"":""""}}   podman info output yaml host: arch: arm64 buildahVersion: 1.33.2 cgroupControllers: - cpuset - cpu - io - memory - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.8-2.fc39.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.8, commit: ' cpuUtilization: idlePercent: 99.54 systemPercent: 0.22 userPercent: 0.24 cpus: 2 databaseBackend: sqlite distribution: distribution: fedora variant: coreos version: ""39"" eventLogger: journald freeLocks: 2045 hostname: localhost.localdomain idMappings: gidmap: null uidmap: null kernel: 6.6.8-200.fc39.aarch64 linkmode: dynamic logDriver: journald memFree: 616837120 memTotal: 3795222528 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.9.0-1.fc39.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.9.0 package: netavark-1.9.0-1.fc39.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.9.0 ociRuntime: name: crun package: crun-1.12-1.fc39.aarch64 path: /usr/bin/crun version: |- crun version 1.12 commit: ce429cb2e277d001c2179df1ac66a470f00802ae rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20231204.gb86afe3-1.fc39.aarch64 version: | pasta 0^20231204.gb86afe3-1.fc39.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc39.aarch64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 36h 19m 18.00s (Approximately 1.50 days) variant: v8 plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 1 paused: 0 running: 1 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 99252940800 graphRootUsed: 4171116544 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 6 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 4.8.2 Built: 1702300963 BuiltTime: Mon Dec 11 05:22:43 2023 GitCommit: """" GoVersion: go1.21.4 Os: linux OsArch: linux/arm64 Version: 4.8.2   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release Yes  Additional environment details Podman Desktop (v1.6.4) on ARM64 MacOS  Additional information _No response_"
19368,podman,https://github.com/containers/podman/issues/19368,Container kill does not return 409 error code for stopped containers," Issue Description podman kill ( compat / libpod ) does not return 409 error code ( https://docs.docker.com/engine/api/v1.43/#tag/Container/operation/ContainerKill ) for stopped containers  Steps to reproduce the issue Steps to reproduce the issue 1. podman -r run -d --name nginx nginx 2. podman -r stop nginx 3. podman -r kill nginx  Describe the results you received  {""cause"":""container state improper"",""message"":""can only kill running containers. 6830d229c01064f76b9de62b76b80492fe4d08136c7b459bc0de926b1581093f is in state exited: container state improper"",""response"":500}   Describe the results you expected 409 is returned  podman info output yaml 4.6.0   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information _No response_",source-file | test-file | source-file | test-file,container kill return stopped containers description kill compat libpod return https docs docker engine api tag container operation containerkill stopped containers steps reproduce steps reproduce name nginx nginx stop nginx kill nginx describe results received cause container state improper message kill running containers state exited container state improper response describe results expected returned output yaml container privileged rootless none upstream latest yes additional environment details additional environment details additional information response,bug,0.95,"Container kill does not return 409 error code for stopped containers  Issue Description podman kill ( compat / libpod ) does not return 409 error code ( https://docs.docker.com/engine/api/v1.43/#tag/Container/operation/ContainerKill ) for stopped containers  Steps to reproduce the issue Steps to reproduce the issue 1. podman -r run -d --name nginx nginx 2. podman -r stop nginx 3. podman -r kill nginx  Describe the results you received  {""cause"":""container state improper"",""message"":""can only kill running containers. 6830d229c01064f76b9de62b76b80492fe4d08136c7b459bc0de926b1581093f is in state exited: container state improper"",""response"":500}   Describe the results you expected 409 is returned  podman info output yaml 4.6.0   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information _No response_"
24152,podman,https://github.com/containers/podman/issues/24152,"podman info fails: Error: parse ""[::]:2376"": first path segment in URL cannot contain colon"," Issue Description Running `podman info` remote via TCP fails with: Error: parse ""[::]:2376"": first path segment in URL cannot contain colon The HTTP request is:  GET /v5.2.3/libpod/info HTTP/1.1 Host: d User-Agent: Go-http-client/1.1  The response is:  HTTP/1.1 500 Internal Server Error Api-Version: 1.41 Content-Type: application/json Libpod-Api-Version: 5.2.3 Server: Libpod/5.2.3 (linux) X-Reference-Id: 0xc000630010 Date: Thu, 03 Oct 2024 18:01:27 GMT Content-Length: 154 {""cause"":""first path segment in URL cannot contain colon"",""message"":""parse \""[::]:2376\"": first path segment in URL cannot contain colon"",""response"":500}   Steps to reproduce the issue Steps to reproduce the issue 1. Make podman listen on TCP via systemd socket activation. Aka append the `podman.socket` unit with  [Socket] ListenStream= ListenStream=2376  2. Execute HTTP request with `echo ""GET /v5.2.3/libpod/info HTTP/1.1\nHost: d\n\n"" | nc -C localhost 2376`  Describe the results you received HTTP 500 and error `parse ""[::]:2376"": first path segment in URL cannot contain colon`  Describe the results you expected A proper info result.  podman info output yaml The request `podman info` does itself fail. * Debian 13 * Podman 5.2.3   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting",source-file | source-file | test-file,fails parse first path segment url cannot contain colon description running remote via tcp fails parse first path segment url cannot contain colon http get libpod http host user agent http client response http internal server api content type application json libpod api server libpod linux reference date oct gmt content length cause first path segment url cannot contain colon message parse first path segment url cannot contain colon response steps reproduce steps reproduce make listen tcp via systemd socket activation aka append socket unit socket listenstream listenstream execute http echo get libpod http nhost localhost describe results received http parse first path segment url cannot contain colon describe results expected proper result output yaml fail debian container privileged rootless privileged upstream latest additional environment details additional environment details additional information additional information like happens occasionally happens particular architecture particular setting,bug,0.95,"podman info fails: Error: parse ""[::]:2376"": first path segment in URL cannot contain colon  Issue Description Running `podman info` remote via TCP fails with: Error: parse ""[::]:2376"": first path segment in URL cannot contain colon The HTTP request is:  GET /v5.2.3/libpod/info HTTP/1.1 Host: d User-Agent: Go-http-client/1.1  The response is:  HTTP/1.1 500 Internal Server Error Api-Version: 1.41 Content-Type: application/json Libpod-Api-Version: 5.2.3 Server: Libpod/5.2.3 (linux) X-Reference-Id: 0xc000630010 Date: Thu, 03 Oct 2024 18:01:27 GMT Content-Length: 154 {""cause"":""first path segment in URL cannot contain colon"",""message"":""parse \""[::]:2376\"": first path segment in URL cannot contain colon"",""response"":500}   Steps to reproduce the issue Steps to reproduce the issue 1. Make podman listen on TCP via systemd socket activation. Aka append the `podman.socket` unit with  [Socket] ListenStream= ListenStream=2376  2. Execute HTTP request with `echo ""GET /v5.2.3/libpod/info HTTP/1.1\nHost: d\n\n"" | nc -C localhost 2376`  Describe the results you received HTTP 500 and error `parse ""[::]:2376"": first path segment in URL cannot contain colon`  Describe the results you expected A proper info result.  podman info output yaml The request `podman info` does itself fail. * Debian 13 * Podman 5.2.3   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details Additional environment details  Additional information Additional information like issue happens only occasionally or issue happens with a particular architecture or on a particular setting"
16150,podman,https://github.com/containers/podman/issues/16150,Podman push image to redhat quay with sigstore was failed caused by send malformed manifest to quay,"Hi Guys, When use podman 4.2.1 to push image to Redhat Quay 3.8.0, hit 500 error code, based on the log error message , seems like podman send malformed json to quay, pls review this issue and give suggestions.  [root@ip-10-0-1-76 fedora]# podman push quayregistry-quay-quay-enterprise-13240.apps.quaytest-13240.qe.azure.devcluster.openshift.com/quay/demo --tls-verify=false --sign-by-sigstore-private-key=./cosign.key Key Passphrase: Getting image source signatures Copying blob 288cf3a46e32 done Copying blob 75ba02937496 done Copying blob 0c7daf9a72c8 done Copying blob 955c9335e041 done Copying blob 8e079fee2186 done Copying blob 186da837555d done Copying blob d172a9e6f9e6 done Copying blob cf399be408ea done Copying blob 793b971ccb99 done Copying config da84e66c3a done Writing manifest to image destination Signing manifest using a sigstore signature Storing signatures Error: writing signatures: uploading manifest sha256-2353c13421e07e3d3dd1bb181cf0b7ad5e6dce3e1bb363c33f48d12e0a0ada49.sig to quayregistry-quay-quay-enterprise-13240.apps.quaytest-13240.qe.azure.devcluster.openshift.com/quay/demo: received unexpected HTTP status: 500 Internal Server Error   gunicorn-registry stdout | 2022-10-11 03:58:52,461 [214] [ERROR] [gunicorn.error] Error handling request /v2/quay/demo/manifests/sha256-2353c13421e07e3d3dd1bb181cf0b7ad5e6dce3e1bb363c33f48d12e0a0ada49.sig gunicorn-registry stdout | Traceback (most recent call last): gunicorn-registry stdout | File ""/quay-registry/image/oci/config.py"", line 209, in __init__ gunicorn-registry stdout | validate_schema(self._parsed, OCIConfig.METASCHEMA) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/jsonschema/validators.py"", line 934, in validate gunicorn-registry stdout | raise error gunicorn-registry stdout | jsonschema.exceptions.ValidationError: '' is not one of ['layers'] gunicorn-registry stdout | Failed validating 'enum' in schema['properties']['rootfs']['properties']['type']: gunicorn-registry stdout | {'description': 'MUST be set to layers.', gunicorn-registry stdout | 'enum': ['layers'], gunicorn-registry stdout | 'type': 'string'} gunicorn-registry stdout | On instance['rootfs']['type']: gunicorn-registry stdout | '' gunicorn-registry stdout | During handling of the above exception, another exception occurred: gunicorn-registry stdout | Traceback (most recent call last): gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/gunicorn/workers/base_async.py"", line 55, in handle gunicorn-registry stdout | self.handle_request(listener_name, req, client, addr) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/gunicorn/workers/ggevent.py"", line 127, in handle_request gunicorn-registry stdout | super().handle_request(listener_name, req, sock, addr) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/gunicorn/workers/base_async.py"", line 108, in handle_request gunicorn-registry stdout | respiter = self.wsgi(environ, resp.start_response) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 2463, in __call__ gunicorn-registry stdout | return self.wsgi_app(environ, start_response) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/werkzeug/middleware/proxy_fix.py"", line 169, in __call__ gunicorn-registry stdout | return self.app(environ, start_response) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 2449, in wsgi_app gunicorn-registry stdout | response = self.handle_exception(e) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 1866, in handle_exception gunicorn-registry stdout | reraise(exc_type, exc_value, tb) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/_compat.py"", line 39, in reraise gunicorn-registry stdout | raise value gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 2446, in wsgi_app gunicorn-registry stdout | response = self.full_dispatch_request() gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 1951, in full_dispatch_request gunicorn-registry stdout | rv = self.handle_user_exception(e) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 1820, in handle_user_exceptiongunicorn-registry stdout | 'x-ms-copy-source': 'REDACTED' ",other-file | other-file | config-file | other-file | documentation-file | source-file | documentation-file | source-file | source-file | source-file | source-file | source-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | other-file,push image redhat quay sigstore failed caused send malformed manifest quay guys use push image redhat quay hit based log message seems like send malformed json quay pls review give suggestions root fedora push quayregistry quay quay enterprise apps quaytest azure devcluster openshift quay demo tls verify false sign sigstore private key cosign key key passphrase getting image signatures copying blob done copying blob done copying blob daf done copying blob done copying blob fee done copying blob done copying blob done copying blob done copying blob ccb done copying config done writing manifest image destination signing manifest sigstore signature storing signatures writing signatures uploading manifest sha dce ada sig quayregistry quay quay enterprise apps quaytest azure devcluster openshift quay demo received unexpected http status internal server gunicorn registry stdout gunicorn handling quay demo manifests sha dce ada sig gunicorn registry stdout traceback recent call last gunicorn registry stdout quay registry image oci config init gunicorn registry stdout validate schema self parsed ociconfig metaschema gunicorn registry stdout local python site packages jsonschema validators validate gunicorn registry stdout raise gunicorn registry stdout jsonschema exceptions validationerror one layers gunicorn registry stdout failed validating enum schema properties rootfs properties type gunicorn registry stdout description must set layers gunicorn registry stdout enum layers gunicorn registry stdout type string gunicorn registry stdout instance rootfs type gunicorn registry stdout gunicorn registry stdout handling exception another exception occurred gunicorn registry stdout traceback recent call last gunicorn registry stdout local python site packages gunicorn workers base async handle gunicorn registry stdout self handle listener name req client addr gunicorn registry stdout local python site packages gunicorn workers ggevent handle gunicorn registry stdout super handle listener name req sock addr gunicorn registry stdout local python site packages gunicorn workers base async handle gunicorn registry stdout respiter self wsgi environ resp start response gunicorn registry stdout local python site packages flask app call gunicorn registry stdout return self wsgi app environ start response gunicorn registry stdout local python site packages werkzeug middleware proxy call gunicorn registry stdout return self app environ start response gunicorn registry stdout local python site packages flask app wsgi app gunicorn registry stdout response self handle exception gunicorn registry stdout local python site packages flask app handle exception gunicorn registry stdout reraise exc type exc value gunicorn registry stdout local python site packages flask compat reraise gunicorn registry stdout raise value gunicorn registry stdout local python site packages flask app wsgi app gunicorn registry stdout response self full dispatch gunicorn registry stdout local python site packages flask app full dispatch gunicorn registry stdout self handle user exception gunicorn registry stdout local python site packages flask app handle user exceptiongunicorn registry stdout copy redacted,bug,0.95,"Podman push image to redhat quay with sigstore was failed caused by send malformed manifest to quay Hi Guys, When use podman 4.2.1 to push image to Redhat Quay 3.8.0, hit 500 error code, based on the log error message , seems like podman send malformed json to quay, pls review this issue and give suggestions.  [root@ip-10-0-1-76 fedora]# podman push quayregistry-quay-quay-enterprise-13240.apps.quaytest-13240.qe.azure.devcluster.openshift.com/quay/demo --tls-verify=false --sign-by-sigstore-private-key=./cosign.key Key Passphrase: Getting image source signatures Copying blob 288cf3a46e32 done Copying blob 75ba02937496 done Copying blob 0c7daf9a72c8 done Copying blob 955c9335e041 done Copying blob 8e079fee2186 done Copying blob 186da837555d done Copying blob d172a9e6f9e6 done Copying blob cf399be408ea done Copying blob 793b971ccb99 done Copying config da84e66c3a done Writing manifest to image destination Signing manifest using a sigstore signature Storing signatures Error: writing signatures: uploading manifest sha256-2353c13421e07e3d3dd1bb181cf0b7ad5e6dce3e1bb363c33f48d12e0a0ada49.sig to quayregistry-quay-quay-enterprise-13240.apps.quaytest-13240.qe.azure.devcluster.openshift.com/quay/demo: received unexpected HTTP status: 500 Internal Server Error   gunicorn-registry stdout | 2022-10-11 03:58:52,461 [214] [ERROR] [gunicorn.error] Error handling request /v2/quay/demo/manifests/sha256-2353c13421e07e3d3dd1bb181cf0b7ad5e6dce3e1bb363c33f48d12e0a0ada49.sig gunicorn-registry stdout | Traceback (most recent call last): gunicorn-registry stdout | File ""/quay-registry/image/oci/config.py"", line 209, in __init__ gunicorn-registry stdout | validate_schema(self._parsed, OCIConfig.METASCHEMA) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/jsonschema/validators.py"", line 934, in validate gunicorn-registry stdout | raise error gunicorn-registry stdout | jsonschema.exceptions.ValidationError: '' is not one of ['layers'] gunicorn-registry stdout | Failed validating 'enum' in schema['properties']['rootfs']['properties']['type']: gunicorn-registry stdout | {'description': 'MUST be set to layers.', gunicorn-registry stdout | 'enum': ['layers'], gunicorn-registry stdout | 'type': 'string'} gunicorn-registry stdout | On instance['rootfs']['type']: gunicorn-registry stdout | '' gunicorn-registry stdout | During handling of the above exception, another exception occurred: gunicorn-registry stdout | Traceback (most recent call last): gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/gunicorn/workers/base_async.py"", line 55, in handle gunicorn-registry stdout | self.handle_request(listener_name, req, client, addr) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/gunicorn/workers/ggevent.py"", line 127, in handle_request gunicorn-registry stdout | super().handle_request(listener_name, req, sock, addr) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/gunicorn/workers/base_async.py"", line 108, in handle_request gunicorn-registry stdout | respiter = self.wsgi(environ, resp.start_response) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 2463, in __call__ gunicorn-registry stdout | return self.wsgi_app(environ, start_response) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/werkzeug/middleware/proxy_fix.py"", line 169, in __call__ gunicorn-registry stdout | return self.app(environ, start_response) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 2449, in wsgi_app gunicorn-registry stdout | response = self.handle_exception(e) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 1866, in handle_exception gunicorn-registry stdout | reraise(exc_type, exc_value, tb) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/_compat.py"", line 39, in reraise gunicorn-registry stdout | raise value gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 2446, in wsgi_app gunicorn-registry stdout | response = self.full_dispatch_request() gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 1951, in full_dispatch_request gunicorn-registry stdout | rv = self.handle_user_exception(e) gunicorn-registry stdout | File ""/usr/local/lib/python3.9/site-packages/flask/app.py"", line 1820, in handle_user_exceptiongunicorn-registry stdout | 'x-ms-copy-source': 'REDACTED' "
17341,podman,https://github.com/containers/podman/issues/17341,[Bug]: Listing network from Docker fails during container removal," Issue Description If you start Podman API server and try to inspect a network from Docker (or Docker-compatible library, e.g. one used by Gitlab Runner) you get also a list of containers in that network (for backward compatibility with Docker, Podman doesn't show that data). But if container is currently being removed -or added, not sure here - this request fails with:  Error response from daemon: container <container id> does not exist in database: no such container  The interesting part is that you get the same error even if you run `docker network ls` instead of `docker network inspect <network>`. I believe it may be the cause of [this Gitlab Runner issue](https://gitlab.com/gitlab-org/gitlab-runner/-/issues/28971) (or it's at least one of the causes) and one similar error that I believe has not been reported to Gitlab yet that I've only observed with Podman 4.4.  Steps to reproduce the issue Steps to reproduce the issue 1. Start Podman API server (`podman system service`). 2. Create a network (`podman network create test`). 3. Configure **native docker** to use Podman's socket (`export DOCKER_HOST=unix://<path to socket>`). 4. Loop container creation (check below the list for an example code). 5. Watch either output of `docker network list` or `docker network inspect test` (check below the list for an example code). Example creation loop: bash while true do podman run -d --rm -ti --network test fedora sleep 1; done  Example watch (you need to open the file to find those lines, terminal control keys used to clear screan are stored in it so simple `cat` won't work): bash watch -tn 0.1 --exec docker network ls | tee -a test.log   Describe the results you received Podman server sometimes fails with container not found error. Log entry:  INFO[0052] Request Failed(Internal Server Error): container cf3b535ee60be15c9b5ed36240caa923119be4f06f9ff80bd98620d3c7e3ef3e does not exist in database: no such container @ - - [02/Feb/2023:17:15:09 +0000] ""GET /v1.41/networks HTTP/1.1"" 500 178 """" ""Docker-Client/20.10.23 (linux)""   Describe the results you expected No errors for either request. Ff Podman finds it cannot retrieve container details because it does no longer exist it should just remove it from `network inspect` output. In case of `network list` I'm not even sure if there is a reason to create this containers list in the first place - does JSON response contain that field? I don't see an option in docker's cli to show containers in this view.  podman info output shell host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - cpuset - cpu - memory - pids cgroupManager: cgroupfs cgroupVersion: v2 conmon: package: Unknown path: /usr/local/libexec/podman/conmon version: 'conmon version 2.1.5, commit: 4cb1e4d73699ce0cef2c3d89b652b3d15be429b3' cpuUtilization: idlePercent: 98.16 systemPercent: 0.57 userPercent: 1.27 cpus: 4 distribution: distribution: fedora variant: cloud version: ""37"" eventLogger: file hostname: <cut> idMappings: gidmap: - container_id: 0 host_id: 993 size: 1 - container_id: 1 host_id: 200000 size: 65536 uidmap: - container_id: 0 host_id: 993 size: 1 - container_id: 1 host_id: 200000 size: 65536 kernel: 6.1.8-200.fc37.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 1381150720 memTotal: 8329515008 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-3.fc37.x86_64 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /run/user/993/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/993/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 8328572928 swapTotal: 8328835072 uptime: 27h 58m 5.00s (Approximately 1.12 days) plugins: authorization: null log: - k8s-file - none - passthrough network: - bridge - macvlan volume: - local registries: docker.io: Blocked: false Insecure: false Location: docker.io MirrorByDigestOnly: false Mirrors: <cut> Prefix: docker.io PullFromMirror: """" : <cut> search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /home/gitlab-runner/.config/containers/storage.conf containerStore: number: 10 paused: 0 running: 1 stopped: 9 graphDriverName: overlay graphOptions: {} graphRoot: /home/gitlab-runner/.local/share/containers/storage graphRootAllocated: 52527345664 graphRootUsed: 5485887488 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 8 runRoot: /run/user/993/containers transientStore: false volumePath: /home/gitlab-runner/.local/share/containers/storage/volumes version: APIVersion: 4.4.0 Built: 1675343283 BuiltTime: Thu Feb 2 13:08:03 2023 GitCommit: """" GoVersion: go1.19.5 Os: linux OsArch: linux/amd64 Version: 4.4.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details Running on Fedora 37 in a VM with self-compiled Podman and conmon. SELinux enabled. Same error observed earlier using latest Fedora 37 packages (Podman 4.3.1, conmon 2.1.5). Same Gitlab Runner issue observed even earlier (on Podman 4.3.0, older conmon, runc, netavark, aardvark, etc.) although I don't have exact versions nor a way to confirm 100% that it means it's caused by the same problem. If this is the case then oldest report (author of that Gitlab issue) comes from Podman 3.4.2.  Additional information _No response_",source-file | source-file,bug listing network docker fails container removal description start api server inspect network docker docker compatible library one used gitlab runner get also list containers network backward compatibility docker show data container currently removed added sure fails response daemon container container exist database container interesting part get even docker network instead docker network inspect network believe may cause gitlab runner https gitlab gitlab gitlab runner issues least one causes one similar believe reported gitlab yet observed steps reproduce steps reproduce start api server system service create network network create configure native docker use socket export docker host unix path socket loop container creation check list example watch either output docker network list docker network inspect check list example example creation loop bash true network fedora sleep done example watch need open find lines terminal control keys used clear screan stored simple cat work bash watch exec docker network tee log describe results received server sometimes fails container found log entry failed internal server container caa exist database container feb get networks http docker client linux describe results expected errors either finds cannot retrieve container details longer exist network inspect output case network list even sure reason create containers list first place json response contain field see option docker cli show containers view output shell host arch amd buildahversion cgroupcontrollers cpuset cpu memory pids cgroupmanager cgroupfs cgroupversion conmon package unknown path local libexec conmon conmon cef cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant cloud eventlogger hostname cut idmappings gidmap container host size container host size uidmap container host size container host size kernel linkmode dynamic logdriver memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun aff cac rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough network bridge macvlan volume local registries docker blocked false insecure false location docker mirrorbydigestonly false mirrors cut prefix docker pullfrommirror cut search registry fedoraproject registry access redhat docker quay store configfile home gitlab runner config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home gitlab runner local share containers storage graphrootallocated graphrootused graphstatus backing filesystem btrfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home gitlab runner local share containers storage volumes apiversion built builttime feb gitcommit goversion linux osarch linux amd container privileged rootless rootless upstream latest yes additional environment details running fedora self compiled conmon selinux enabled observed earlier latest fedora packages conmon gitlab runner observed even earlier older conmon runc netavark aardvark etc although exact versions way confirm means caused case oldest report gitlab comes additional information response,bug,0.95,"[Bug]: Listing network from Docker fails during container removal  Issue Description If you start Podman API server and try to inspect a network from Docker (or Docker-compatible library, e.g. one used by Gitlab Runner) you get also a list of containers in that network (for backward compatibility with Docker, Podman doesn't show that data). But if container is currently being removed -or added, not sure here - this request fails with:  Error response from daemon: container <container id> does not exist in database: no such container  The interesting part is that you get the same error even if you run `docker network ls` instead of `docker network inspect <network>`. I believe it may be the cause of [this Gitlab Runner issue](https://gitlab.com/gitlab-org/gitlab-runner/-/issues/28971) (or it's at least one of the causes) and one similar error that I believe has not been reported to Gitlab yet that I've only observed with Podman 4.4.  Steps to reproduce the issue Steps to reproduce the issue 1. Start Podman API server (`podman system service`). 2. Create a network (`podman network create test`). 3. Configure **native docker** to use Podman's socket (`export DOCKER_HOST=unix://<path to socket>`). 4. Loop container creation (check below the list for an example code). 5. Watch either output of `docker network list` or `docker network inspect test` (check below the list for an example code). Example creation loop: bash while true do podman run -d --rm -ti --network test fedora sleep 1; done  Example watch (you need to open the file to find those lines, terminal control keys used to clear screan are stored in it so simple `cat` won't work): bash watch -tn 0.1 --exec docker network ls | tee -a test.log   Describe the results you received Podman server sometimes fails with container not found error. Log entry:  INFO[0052] Request Failed(Internal Server Error): container cf3b535ee60be15c9b5ed36240caa923119be4f06f9ff80bd98620d3c7e3ef3e does not exist in database: no such container @ - - [02/Feb/2023:17:15:09 +0000] ""GET /v1.41/networks HTTP/1.1"" 500 178 """" ""Docker-Client/20.10.23 (linux)""   Describe the results you expected No errors for either request. Ff Podman finds it cannot retrieve container details because it does no longer exist it should just remove it from `network inspect` output. In case of `network list` I'm not even sure if there is a reason to create this containers list in the first place - does JSON response contain that field? I don't see an option in docker's cli to show containers in this view.  podman info output shell host: arch: amd64 buildahVersion: 1.29.0 cgroupControllers: - cpuset - cpu - memory - pids cgroupManager: cgroupfs cgroupVersion: v2 conmon: package: Unknown path: /usr/local/libexec/podman/conmon version: 'conmon version 2.1.5, commit: 4cb1e4d73699ce0cef2c3d89b652b3d15be429b3' cpuUtilization: idlePercent: 98.16 systemPercent: 0.57 userPercent: 1.27 cpus: 4 distribution: distribution: fedora variant: cloud version: ""37"" eventLogger: file hostname: <cut> idMappings: gidmap: - container_id: 0 host_id: 993 size: 1 - container_id: 1 host_id: 200000 size: 65536 uidmap: - container_id: 0 host_id: 993 size: 1 - container_id: 1 host_id: 200000 size: 65536 kernel: 6.1.8-200.fc37.x86_64 linkmode: dynamic logDriver: k8s-file memFree: 1381150720 memTotal: 8329515008 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-3.fc37.x86_64 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /run/user/993/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/993/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.x86_64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 8328572928 swapTotal: 8328835072 uptime: 27h 58m 5.00s (Approximately 1.12 days) plugins: authorization: null log: - k8s-file - none - passthrough network: - bridge - macvlan volume: - local registries: docker.io: Blocked: false Insecure: false Location: docker.io MirrorByDigestOnly: false Mirrors: <cut> Prefix: docker.io PullFromMirror: """" : <cut> search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /home/gitlab-runner/.config/containers/storage.conf containerStore: number: 10 paused: 0 running: 1 stopped: 9 graphDriverName: overlay graphOptions: {} graphRoot: /home/gitlab-runner/.local/share/containers/storage graphRootAllocated: 52527345664 graphRootUsed: 5485887488 graphStatus: Backing Filesystem: btrfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 8 runRoot: /run/user/993/containers transientStore: false volumePath: /home/gitlab-runner/.local/share/containers/storage/volumes version: APIVersion: 4.4.0 Built: 1675343283 BuiltTime: Thu Feb 2 13:08:03 2023 GitCommit: """" GoVersion: go1.19.5 Os: linux OsArch: linux/amd64 Version: 4.4.0   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details Running on Fedora 37 in a VM with self-compiled Podman and conmon. SELinux enabled. Same error observed earlier using latest Fedora 37 packages (Podman 4.3.1, conmon 2.1.5). Same Gitlab Runner issue observed even earlier (on Podman 4.3.0, older conmon, runc, netavark, aardvark, etc.) although I don't have exact versions nor a way to confirm 100% that it means it's caused by the same problem. If this is the case then oldest report (author of that Gitlab issue) comes from Podman 3.4.2.  Additional information _No response_"
20821,podman,https://github.com/containers/podman/issues/20821,Unmarshalling error when using `podman exec`," Issue Description When I use `podman exec ` for any container, I get the following error:  Error: unmarshalling error into &errorhandling.ErrorModel{Because:"""", Message:"""", ResponseCode:0}, data ""Not Found\n"": invalid character 'N' looking for beginning of value   Steps to reproduce the issue Steps to reproduce the issue 1. Run a detached container: `podman run --name httpd -p 8080:80 -d -i -t docker.io/library/httpd` 2. Try to run podman exec: `podman exec httpd pwd` 3. Error message shows up  Describe the results you received An unexpected error message.  Describe the results you expected No error message, if the command is run correctly.  podman info output yaml host: arch: arm64 buildahVersion: 1.32.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.8-2.fc39.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.8, commit: ' cpuUtilization: idlePercent: 99.33 systemPercent: 0.34 userPercent: 0.33 cpus: 4 databaseBackend: boltdb distribution: distribution: fedora variant: coreos version: ""39"" eventLogger: journald freeLocks: 2039 hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 1000000 uidmap: - container_id: 0 host_id: 501 size: 1 - container_id: 1 host_id: 100000 size: 1000000 kernel: 6.5.11-300.fc39.aarch64 linkmode: dynamic logDriver: journald memFree: 3151986688 memTotal: 6189867008 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.8.0-1.fc39.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.8.0 package: netavark-1.8.0-2.fc39.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.8.0 ociRuntime: name: crun package: crun-1.11.1-1.fc39.aarch64 path: /usr/bin/crun version: |- crun version 1.11.1 commit: 1084f9527c143699b593b44c23555fb3cc4ff2f3 rundir: /run/user/501/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20231004.gf851084-1.fc39.aarch64 version: | pasta 0^20231004.gf851084-1.fc39.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/user/501/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc39.aarch64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 12h 26m 50.00s (Approximately 0.50 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /var/home/core/.config/containers/storage.conf containerStore: number: 3 paused: 0 running: 3 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/core/.local/share/containers/storage graphRootAllocated: 106769133568 graphRootUsed: 6775140352 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 33 runRoot: /run/user/501/containers transientStore: false volumePath: /var/home/core/.local/share/containers/storage/volumes version: APIVersion: 4.7.2 Built: 1698762633 BuiltTime: Tue Oct 31 15:30:33 2023 GitCommit: """" GoVersion: go1.21.1 Os: linux OsArch: linux/arm64 Version: 4.7.2   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details ZSH on MacOS  Additional information When downgrading to v4.7.2 the issue disappeared.",source-file | test-file | source-file | test-file,unmarshalling exec description use exec container get following unmarshalling errorhandling errormodel message responsecode data found invalid character looking beginning value steps reproduce steps reproduce detached container name httpd docker library httpd exec exec httpd pwd message shows describe results received unexpected message describe results expected message command correctly output yaml host arch arm buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon aarch path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend boltdb distribution distribution fedora variant coreos eventlogger journald freelocks hostname localhost localdomain idmappings gidmap container host size container host size uidmap container host size container host size kernel aarch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns aarch path libexec aardvark dns aardvark dns package netavark aarch path libexec netavark netavark ociruntime name crun package crun aarch path crun crun rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt aarch pasta aarch pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote true slirp netns executable slirp netns package slirp netns aarch slirp netns faf libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search docker store configfile var home core config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot var home core local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff true supports type true supports shifting false supports volatile true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath var home core local share containers storage volumes apiversion built builttime oct gitcommit goversion linux osarch linux arm container privileged rootless none upstream latest yes additional environment details zsh macos additional information downgrading disappeared,bug,0.9,"Unmarshalling error when using `podman exec`  Issue Description When I use `podman exec ` for any container, I get the following error:  Error: unmarshalling error into &errorhandling.ErrorModel{Because:"""", Message:"""", ResponseCode:0}, data ""Not Found\n"": invalid character 'N' looking for beginning of value   Steps to reproduce the issue Steps to reproduce the issue 1. Run a detached container: `podman run --name httpd -p 8080:80 -d -i -t docker.io/library/httpd` 2. Try to run podman exec: `podman exec httpd pwd` 3. Error message shows up  Describe the results you received An unexpected error message.  Describe the results you expected No error message, if the command is run correctly.  podman info output yaml host: arch: arm64 buildahVersion: 1.32.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.8-2.fc39.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.8, commit: ' cpuUtilization: idlePercent: 99.33 systemPercent: 0.34 userPercent: 0.33 cpus: 4 databaseBackend: boltdb distribution: distribution: fedora variant: coreos version: ""39"" eventLogger: journald freeLocks: 2039 hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 1000000 uidmap: - container_id: 0 host_id: 501 size: 1 - container_id: 1 host_id: 100000 size: 1000000 kernel: 6.5.11-300.fc39.aarch64 linkmode: dynamic logDriver: journald memFree: 3151986688 memTotal: 6189867008 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.8.0-1.fc39.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.8.0 package: netavark-1.8.0-2.fc39.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.8.0 ociRuntime: name: crun package: crun-1.11.1-1.fc39.aarch64 path: /usr/bin/crun version: |- crun version 1.11.1 commit: 1084f9527c143699b593b44c23555fb3cc4ff2f3 rundir: /run/user/501/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20231004.gf851084-1.fc39.aarch64 version: | pasta 0^20231004.gf851084-1.fc39.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/user/501/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-1.fc39.aarch64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 12h 26m 50.00s (Approximately 0.50 days) variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /var/home/core/.config/containers/storage.conf containerStore: number: 3 paused: 0 running: 3 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/core/.local/share/containers/storage graphRootAllocated: 106769133568 graphRootUsed: 6775140352 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 33 runRoot: /run/user/501/containers transientStore: false volumePath: /var/home/core/.local/share/containers/storage/volumes version: APIVersion: 4.7.2 Built: 1698762633 BuiltTime: Tue Oct 31 15:30:33 2023 GitCommit: """" GoVersion: go1.21.1 Os: linux OsArch: linux/arm64 Version: 4.7.2   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details ZSH on MacOS  Additional information When downgrading to v4.7.2 the issue disappeared."
18792,podman,https://github.com/containers/podman/issues/18792,"Running containers without defined or disabled health checks should not return ""Health"": {}"," Issue Description When running a container with podman that does not define any health check, the following state is returned.  Steps to reproduce the issue Steps to reproduce the issue 1. Run podman with disabled or no health checks in place  podman run --no-healthcheck -e POSTGRES_PASSWORD=password postgres:9.5 or since this image seems not to define any check podman run -e POSTGRES_PASSWORD=password postgres:9.5  2. Check the state  podman inspect $cid ""Health"": { ""Status"": """", ""FailingStreak"": 0, ""Log"": null },   Describe the results you received  podman inspect $cid ""Health"": { ""Status"": """", ""FailingStreak"": 0, ""Log"": null },   Describe the results you expected As with docker, I would expect that there is no ""Health"": section in the first place to indicate that this container is not running any health checks  podman info output yaml podman info host: arch: arm64 buildahVersion: 1.30.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-2.fc38.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 91.22 systemPercent: 2.77 userPercent: 6.01 cpus: 1 databaseBackend: boltdb distribution: distribution: fedora variant: coreos version: ""38"" eventLogger: journald hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 1000000 uidmap: - container_id: 0 host_id: 501 size: 1 - container_id: 1 host_id: 100000 size: 1000000 kernel: 6.2.15-300.fc38.aarch64 linkmode: dynamic logDriver: journald memFree: 363335680 memTotal: 2049069056 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.5-1.fc38.aarch64 path: /usr/bin/crun version: |- crun version 1.8.5 commit: b6f80f766c9a89eb7b1440c0a70ab287434b17ed rundir: /run/user/501/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/501/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-12.fc38.aarch64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 0h 53m 21.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /var/home/core/.config/containers/storage.conf containerStore: number: 8 paused: 0 running: 1 stopped: 7 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/core/.local/share/containers/storage graphRootAllocated: 106769133568 graphRootUsed: 6792806400 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 69 runRoot: /run/user/501/containers transientStore: false volumePath: /var/home/core/.local/share/containers/storage/volumes version: APIVersion: 4.5.0 Built: 1681486872 BuiltTime: Fri Apr 14 17:41:12 2023 GitCommit: """" GoVersion: go1.20.2 Os: linux OsArch: linux/arm64 Version: 4.5.0   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information similar looking * https://github.com/containers/podman/issues/13578",source-file | test-file | test-file,running containers without defined disabled health checks return health description running container define health check following state returned steps reproduce steps reproduce disabled health checks place healthcheck postgres password password postgres since image seems define check postgres password password postgres check state inspect cid health status failingstreak log null describe results received inspect cid health status failingstreak log null describe results expected docker would expect health section first place indicate container running health checks output yaml host arch arm buildahversion cgroupcontrollers cpu memory pids cgroupmanager systemd cgroupversion conmon package conmon aarch path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend boltdb distribution distribution fedora variant coreos eventlogger journald hostname localhost localdomain idmappings gidmap container host size container host size uidmap container host size container host size kernel aarch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun aarch path crun crun rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote true slirp netns executable slirp netns package slirp netns aarch slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search docker store configfile var home core config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot var home core local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath var home core local share containers storage volumes apiversion built builttime apr gitcommit goversion linux osarch linux arm container privileged rootless none upstream latest yes additional environment details additional environment details additional information similar looking https github containers issues,bug,0.9,"Running containers without defined or disabled health checks should not return ""Health"": {}  Issue Description When running a container with podman that does not define any health check, the following state is returned.  Steps to reproduce the issue Steps to reproduce the issue 1. Run podman with disabled or no health checks in place  podman run --no-healthcheck -e POSTGRES_PASSWORD=password postgres:9.5 or since this image seems not to define any check podman run -e POSTGRES_PASSWORD=password postgres:9.5  2. Check the state  podman inspect $cid ""Health"": { ""Status"": """", ""FailingStreak"": 0, ""Log"": null },   Describe the results you received  podman inspect $cid ""Health"": { ""Status"": """", ""FailingStreak"": 0, ""Log"": null },   Describe the results you expected As with docker, I would expect that there is no ""Health"": section in the first place to indicate that this container is not running any health checks  podman info output yaml podman info host: arch: arm64 buildahVersion: 1.30.0 cgroupControllers: - cpu - io - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.7-2.fc38.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.7, commit: ' cpuUtilization: idlePercent: 91.22 systemPercent: 2.77 userPercent: 6.01 cpus: 1 databaseBackend: boltdb distribution: distribution: fedora variant: coreos version: ""38"" eventLogger: journald hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 1000000 uidmap: - container_id: 0 host_id: 501 size: 1 - container_id: 1 host_id: 100000 size: 1000000 kernel: 6.2.15-300.fc38.aarch64 linkmode: dynamic logDriver: journald memFree: 363335680 memTotal: 2049069056 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.5-1.fc38.aarch64 path: /usr/bin/crun version: |- crun version 1.8.5 commit: b6f80f766c9a89eb7b1440c0a70ab287434b17ed rundir: /run/user/501/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/501/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-12.fc38.aarch64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 0h 53m 21.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /var/home/core/.config/containers/storage.conf containerStore: number: 8 paused: 0 running: 1 stopped: 7 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/core/.local/share/containers/storage graphRootAllocated: 106769133568 graphRootUsed: 6792806400 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 69 runRoot: /run/user/501/containers transientStore: false volumePath: /var/home/core/.local/share/containers/storage/volumes version: APIVersion: 4.5.0 Built: 1681486872 BuiltTime: Fri Apr 14 17:41:12 2023 GitCommit: """" GoVersion: go1.20.2 Os: linux OsArch: linux/arm64 Version: 4.5.0   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details Additional environment details  Additional information similar looking * https://github.com/containers/podman/issues/13578"
16857,podman,https://github.com/containers/podman/issues/16857,events API docker compatibility issue,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** Podman expects the podman-style ""died"" name of the event rather than docker-style ""die"" event in an event filter expression. This is a compatibility issue with docker-compatible clients. **Steps to reproduce the issue:** 1. Start a container sleeping for a short period of time 2. Subscribe to events using Docker compatibility API, indicating the following filter `{""event"":[""die""]}` and observe the absence of events. To compare with a working case, repeat steps 1 and 2 substituting the filter for `{""event"": [""died""]}` and observe the event called `die` when the container in step 1 finishes. In form of script, steps 1 and 2 (using docker-style event name):  sudo podman run -d --rm --name test alpine sleep 2 sudo curl --unix /run/podman/podman.sock 'http://localhost/events?filters=%7B""container"":%5B""test""%5D,""event "":%5B""die""%5D%7D' # no event here  Using podman-style event name:  sudo podman run -d --rm --name test alpine sleep 2 sudo curl --unix /run/podman/podman.sock 'http://localhost/events?filters=%7B""container"":%5B""test""%5D,""event "":%5B""died""%5D%7D' # the event is printed  **Describe the results you received:** No event arrives in step 2 of the reproduction example. **Describe the results you expected:** I expected to see the ""die"" event from step 2 in the reproduction example:  {""status"":""die"",""id"":""b04f2ec34e7972ee8cd405474e73805db0aa082b3fb12e20958e9c3a781d5bc0"",""from"":""docker.io/library/alpine:latest"",""Type"":""container"",""Action"":""die"",""Actor"":{""ID"":""b04f2ec34e7972ee8cd405474e73805db0aa082b3fb12e20958e9c3a781d5bc0"",""Attributes"":{""containerExitCode"":""0"",""exitCode"":""0"",""image"":""docker.io/library/alpine:latest"",""name"":""test"",""podId"":""""}},""scope"":""local"",""time"":1671122524,""timeNano"":1671122524154484836}  **Additional information you deem important (e.g. issue happens only occasionally):** I think both `die` and `died` should be supported in a filter expression, for backwards compatibility with previous Podman versions. **Output of `podman version`:**  $ podman version Client: Podman Engine Version: 4.3.1 API Version: 4.3.1 Go Version: go1.19.4 Built: Tue Dec 13 02:00:33 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  $ podman info host: arch: amd64 buildahVersion: 1.28.0 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.5-r0 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: unknown' cpuUtilization: idlePercent: 99.73 systemPercent: 0.11 userPercent: 0.16 cpus: 1 distribution: distribution: alpine version: 3.17.0 eventLogger: file hostname: h01 idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 uidmap: - container_id: 0 host_id: 1000 size: 1 kernel: 5.15.82-0-virt linkmode: dynamic logDriver: k8s-file memFree: 1841414144 memTotal: 2087096320 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-r0 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /tmp/podman-run-1000/crun spec: 1.0.0 +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: path: /tmp/podman-run-1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-r0 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.4 swapFree: 0 swapTotal: 0 uptime: 1h 19m 14.00s (Approximately 0.04 days) plugins: authorization: null log: - k8s-file - none - passthrough network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /home/docker/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/docker/.local/share/containers/storage graphRootAllocated: 4226809856 graphRootUsed: 286445568 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /tmp/podman-run-1000/containers volumePath: /home/docker/.local/share/containers/storage/volumes version: APIVersion: 4.3.1 Built: 1670896833 BuiltTime: Tue Dec 13 02:00:33 2022 GitCommit: """" GoVersion: go1.19.4 Os: linux OsArch: linux/amd64 Version: 4.3.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman` or `brew info podman`):**  $ apk info podman podman-4.3.1-r1 description: Simple management tool for pods, containers and images podman-4.3.1-r1 webpage: https://podman.io/ podman-4.3.1-r1 installed size: 39 MiB  **Have you tested with the latest version of Podman and have you checked [the Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md)?** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):**",documentation-file | source-file | test-file,events api docker compatibility bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description expects style died name event rather docker style die event event filter expression compatibility docker compatible clients steps reproduce start container sleeping short period time subscribe events docker compatibility api indicating following filter event die observe absence events compare working case repeat steps substituting filter event died observe event called die container step finishes form script steps docker style event name sudo name alpine sleep sudo curl unix sock http localhost events filters container event die event style event name sudo name alpine sleep sudo curl unix sock http localhost events filters container event died event printed describe results received event arrives step reproduction example describe results expected expected see die event step reproduction example status die docker library alpine latest type container action die actor attributes containerexitcode exitcode image docker library alpine latest name podid scope local time timenano additional information deem important happens occasionally think die died supported filter expression backwards compatibility previous versions output client engine api built dec arch linux amd output host arch amd buildahversion cgroupcontrollers cgroupmanager cgroupfs cgroupversion conmon package conmon path conmon conmon unknown cpuutilization idlepercent systempercent userpercent cpus distribution distribution alpine eventlogger hostname idmappings gidmap container host size uidmap container host size kernel virt linkmode dynamic logdriver memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun aff cac rundir tmp crun spec selinux apparmor cap seccomp ebpf yajl linux remotesocket path tmp sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath etc containers seccomp json selinuxenabled false serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough network bridge macvlan volume local registries search docker store configfile home docker config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home docker local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot tmp containers volumepath home docker local share containers storage volumes apiversion built builttime dec gitcommit goversion linux osarch linux amd package output rpm apt list brew apk description simple management tool pods containers images webpage https installed size mib tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc,bug,0.9,"events API docker compatibility issue <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** Podman expects the podman-style ""died"" name of the event rather than docker-style ""die"" event in an event filter expression. This is a compatibility issue with docker-compatible clients. **Steps to reproduce the issue:** 1. Start a container sleeping for a short period of time 2. Subscribe to events using Docker compatibility API, indicating the following filter `{""event"":[""die""]}` and observe the absence of events. To compare with a working case, repeat steps 1 and 2 substituting the filter for `{""event"": [""died""]}` and observe the event called `die` when the container in step 1 finishes. In form of script, steps 1 and 2 (using docker-style event name):  sudo podman run -d --rm --name test alpine sleep 2 sudo curl --unix /run/podman/podman.sock 'http://localhost/events?filters=%7B""container"":%5B""test""%5D,""event "":%5B""die""%5D%7D' # no event here  Using podman-style event name:  sudo podman run -d --rm --name test alpine sleep 2 sudo curl --unix /run/podman/podman.sock 'http://localhost/events?filters=%7B""container"":%5B""test""%5D,""event "":%5B""died""%5D%7D' # the event is printed  **Describe the results you received:** No event arrives in step 2 of the reproduction example. **Describe the results you expected:** I expected to see the ""die"" event from step 2 in the reproduction example:  {""status"":""die"",""id"":""b04f2ec34e7972ee8cd405474e73805db0aa082b3fb12e20958e9c3a781d5bc0"",""from"":""docker.io/library/alpine:latest"",""Type"":""container"",""Action"":""die"",""Actor"":{""ID"":""b04f2ec34e7972ee8cd405474e73805db0aa082b3fb12e20958e9c3a781d5bc0"",""Attributes"":{""containerExitCode"":""0"",""exitCode"":""0"",""image"":""docker.io/library/alpine:latest"",""name"":""test"",""podId"":""""}},""scope"":""local"",""time"":1671122524,""timeNano"":1671122524154484836}  **Additional information you deem important (e.g. issue happens only occasionally):** I think both `die` and `died` should be supported in a filter expression, for backwards compatibility with previous Podman versions. **Output of `podman version`:**  $ podman version Client: Podman Engine Version: 4.3.1 API Version: 4.3.1 Go Version: go1.19.4 Built: Tue Dec 13 02:00:33 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  $ podman info host: arch: amd64 buildahVersion: 1.28.0 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.5-r0 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: unknown' cpuUtilization: idlePercent: 99.73 systemPercent: 0.11 userPercent: 0.16 cpus: 1 distribution: distribution: alpine version: 3.17.0 eventLogger: file hostname: h01 idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 uidmap: - container_id: 0 host_id: 1000 size: 1 kernel: 5.15.82-0-virt linkmode: dynamic logDriver: k8s-file memFree: 1841414144 memTotal: 2087096320 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-r0 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /tmp/podman-run-1000/crun spec: 1.0.0 +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL os: linux remoteSocket: path: /tmp/podman-run-1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /etc/containers/seccomp.json selinuxEnabled: false serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-r0 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.4 swapFree: 0 swapTotal: 0 uptime: 1h 19m 14.00s (Approximately 0.04 days) plugins: authorization: null log: - k8s-file - none - passthrough network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /home/docker/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /home/docker/.local/share/containers/storage graphRootAllocated: 4226809856 graphRootUsed: 286445568 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 0 runRoot: /tmp/podman-run-1000/containers volumePath: /home/docker/.local/share/containers/storage/volumes version: APIVersion: 4.3.1 Built: 1670896833 BuiltTime: Tue Dec 13 02:00:33 2022 GitCommit: """" GoVersion: go1.19.4 Os: linux OsArch: linux/amd64 Version: 4.3.1  **Package info (e.g. output of `rpm -q podman` or `apt list podman` or `brew info podman`):**  $ apk info podman podman-4.3.1-r1 description: Simple management tool for pods, containers and images podman-4.3.1-r1 webpage: https://podman.io/ podman-4.3.1-r1 installed size: 39 MiB  **Have you tested with the latest version of Podman and have you checked [the Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md)?** Yes **Additional environment details (AWS, VirtualBox, physical, etc.):**"
25871,podman,https://github.com/containers/podman/issues/25871,Docker compat api image removal with force stops running containers," Issue Description Using the docker compatibility api if an image is in use by a running container and is removed with the force option specified the container is stopped and removed. Whereas in docker, images with running containers results in an error. In docker, force only results in the removal of stopped containers. See: https://docs.docker.com/reference/api/engine/version/v1.48/#tag/Image/operation/ImageDelete Tested against the mac desktop 1.17.2 and podman 5.4.2 built on ubuntu  Steps to reproduce the issue Steps to reproduce the issue 1. Pull an image and get it's ID 2. Start a container from that image e.g. `docker run -d [the id] sleep 300` 3. Run `docker rmi --force [the image ID]` 4. See the container is gone The same can be achieved using the docker go client e.g.  cli, _ := client.NewClientWithOpts(client.FromEnv) _, err = cli.ImageRemove(ctx, ""the image id"", image.RemoveOptions{ Force: true, PruneChildren: true, })   Describe the results you received The running container is stopped and removed  Describe the results you expected An error to occur e.g. `Error response from daemon: conflict: unable to delete aded1e1a5b37 (cannot be forced) - image is being used by running container fe300816e647`  podman info output yaml Client: APIVersion: 5.4.2 BuildOrigin: brew Built: 1743601389 BuiltTime: Wed Apr 2 14:43:09 2025 GitCommit: """" GoVersion: go1.24.2 Os: darwin OsArch: darwin/arm64 Version: 5.4.2 host: arch: arm64 buildahVersion: 1.38.0 cgroupControllers: - cpuset - cpu - io - memory - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.12-2.fc40.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.12, commit: ' cpuUtilization: idlePercent: 98.28 systemPercent: 0.97 userPercent: 0.75 cpus: 6 databaseBackend: sqlite distribution: distribution: fedora variant: coreos version: ""40"" eventLogger: journald freeLocks: 2006 hostname: localhost.localdomain idMappings: gidmap: null uidmap: null kernel: 6.11.3-200.fc40.aarch64 linkmode: dynamic logDriver: journald memFree: 3115659264 memTotal: 3792564224 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.12.2-2.fc40.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.12.2 package: netavark-1.12.2-1.fc40.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.12.2 ociRuntime: name: crun package: crun-1.17-1.fc40.aarch64 path: /usr/bin/crun version: |- crun version 1.17 commit: 000fa0d4eeed8938301f3bcf8206405315bc1017 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20240906.g6b38f07-1.fc40.aarch64 version: | pasta 0^20240906.g6b38f07-1.fc40.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: unix:run/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-2.fc40.aarch64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.5 swapFree: 0 swapTotal: 0 uptime: 0h 1m 44.00s variant: v8 plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 19 paused: 0 running: 0 stopped: 19 graphDriverName: overlay graphOptions: overlay.imagestore: /usr/lib/containers/storage overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 99252940800 graphRootUsed: 54138920960 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 70 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.3.1 Built: 1732147200 BuiltTime: Thu Nov 21 00:00:00 2024 GitCommit: """" GoVersion: go1.22.7 Os: linux OsArch: linux/arm64 Version: 5.3.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details N/A  Additional information It is important that the image ID is used for the removal of the image, and not its tag",source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file,docker compat api image removal force stops running containers description docker compatibility api image use running container removed force option specified container stopped removed whereas docker images running containers results docker force results removal stopped containers see https docs docker reference api engine tag image operation imagedelete tested mac desktop built ubuntu steps reproduce steps reproduce image get start container image docker sleep docker rmi force image see container gone achieved docker client cli client newclientwithopts client fromenv err cli imageremove ctx image image removeoptions force true prunechildren true describe results received running container stopped removed describe results expected occur response daemon conflict unable delete aded cannot forced image used running container output yaml client apiversion buildorigin brew built builttime apr gitcommit goversion darwin osarch darwin arm host arch arm buildahversion cgroupcontrollers cpuset cpu memory pids rdma misc cgroupmanager systemd cgroupversion conmon package conmon aarch path conmon conmon cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution fedora variant coreos eventlogger journald freelocks hostname localhost localdomain idmappings gidmap null uidmap null kernel aarch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns aarch path libexec aardvark dns aardvark dns package netavark aarch path libexec netavark netavark ociruntime name crun package crun aarch path crun crun eeed bcf rundir crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux pasta executable pasta package passt aarch pasta aarch pasta copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path unix sock rootlessnetworkcmd pasta security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote true slirp netns executable slirp netns package slirp netns aarch slirp netns faf libslirp slirp config max libseccomp swapfree swaptotal uptime variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search docker store configfile share containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay imagestore containers storage overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff false supports type true supports shifting true supports volatile true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime nov gitcommit goversion linux osarch linux arm container privileged rootless none upstream latest yes additional environment details additional information important image used removal image tag,bug,0.95,"Docker compat api image removal with force stops running containers  Issue Description Using the docker compatibility api if an image is in use by a running container and is removed with the force option specified the container is stopped and removed. Whereas in docker, images with running containers results in an error. In docker, force only results in the removal of stopped containers. See: https://docs.docker.com/reference/api/engine/version/v1.48/#tag/Image/operation/ImageDelete Tested against the mac desktop 1.17.2 and podman 5.4.2 built on ubuntu  Steps to reproduce the issue Steps to reproduce the issue 1. Pull an image and get it's ID 2. Start a container from that image e.g. `docker run -d [the id] sleep 300` 3. Run `docker rmi --force [the image ID]` 4. See the container is gone The same can be achieved using the docker go client e.g.  cli, _ := client.NewClientWithOpts(client.FromEnv) _, err = cli.ImageRemove(ctx, ""the image id"", image.RemoveOptions{ Force: true, PruneChildren: true, })   Describe the results you received The running container is stopped and removed  Describe the results you expected An error to occur e.g. `Error response from daemon: conflict: unable to delete aded1e1a5b37 (cannot be forced) - image is being used by running container fe300816e647`  podman info output yaml Client: APIVersion: 5.4.2 BuildOrigin: brew Built: 1743601389 BuiltTime: Wed Apr 2 14:43:09 2025 GitCommit: """" GoVersion: go1.24.2 Os: darwin OsArch: darwin/arm64 Version: 5.4.2 host: arch: arm64 buildahVersion: 1.38.0 cgroupControllers: - cpuset - cpu - io - memory - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.12-2.fc40.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.12, commit: ' cpuUtilization: idlePercent: 98.28 systemPercent: 0.97 userPercent: 0.75 cpus: 6 databaseBackend: sqlite distribution: distribution: fedora variant: coreos version: ""40"" eventLogger: journald freeLocks: 2006 hostname: localhost.localdomain idMappings: gidmap: null uidmap: null kernel: 6.11.3-200.fc40.aarch64 linkmode: dynamic logDriver: journald memFree: 3115659264 memTotal: 3792564224 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.12.2-2.fc40.aarch64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.12.2 package: netavark-1.12.2-1.fc40.aarch64 path: /usr/libexec/podman/netavark version: netavark 1.12.2 ociRuntime: name: crun package: crun-1.17-1.fc40.aarch64 path: /usr/bin/crun version: |- crun version 1.17 commit: 000fa0d4eeed8938301f3bcf8206405315bc1017 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux pasta: executable: /usr/bin/pasta package: passt-0^20240906.g6b38f07-1.fc40.aarch64 version: | pasta 0^20240906.g6b38f07-1.fc40.aarch64-pasta Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: unix:run/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.2-2.fc40.aarch64 version: |- slirp4netns version 1.2.2 commit: 0ee2d87523e906518d34a6b423271e4826f71faf libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.5 swapFree: 0 swapTotal: 0 uptime: 0h 1m 44.00s variant: v8 plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - docker.io store: configFile: /usr/share/containers/storage.conf containerStore: number: 19 paused: 0 running: 0 stopped: 19 graphDriverName: overlay graphOptions: overlay.imagestore: /usr/lib/containers/storage overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 99252940800 graphRootUsed: 54138920960 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""true"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 70 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.3.1 Built: 1732147200 BuiltTime: Thu Nov 21 00:00:00 2024 GitCommit: """" GoVersion: go1.22.7 Os: linux OsArch: linux/arm64 Version: 5.3.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details N/A  Additional information It is important that the image ID is used for the removal of the image, and not its tag"
17763,podman,https://github.com/containers/podman/issues/17763,REST API: missing tag from `/v1.24/images/${img}/history`," Issue Description docker returns a tag  $ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Tags [ ""alpine:3.17.2"" ]  podman does not  $ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Tags null   Steps to reproduce the issue 1. `sudo -i` 2. `useradd test1` 3. `usermod -aG docker test1` 4. `machinectl shell test1@` 5. `podman pull alpine:3.17.2` 6. `docker pull alpine:3.17.2` 7. run `podman images` and detect the image id. Record the result in a shell variable `img=d74e625d9115` 9. `systemctl --user start podman.socket` 10. `curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags` 11. `curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Tags`  Describe the results you received  [test1@localhost ~]$ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags [ ""alpine:3.17.2"" ] [test1@localhost ~]$ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags null [test1@localhost ~]$   Describe the results you expected  [test1@localhost ~]$ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags [ ""alpine:3.17.2"" ] [test1@localhost ~]$ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags [ ""alpine:3.17.2"" ] [test1@localhost ~]$   podman info output yaml host: arch: arm64 buildahVersion: 1.29.0 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.6-3.fc37.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.6, commit: ' cpuUtilization: idlePercent: 99.65 systemPercent: 0.12 userPercent: 0.24 cpus: 1 distribution: distribution: fedora variant: coreos version: ""37"" eventLogger: journald hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 589824 size: 65536 uidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 589824 size: 65536 kernel: 6.1.14-200.fc37.aarch64 linkmode: dynamic logDriver: journald memFree: 925364224 memTotal: 2050260992 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.1-1.fc37.aarch64 path: /usr/bin/crun version: |- crun version 1.8.1 commit: f8a096be060b22ccd3d5f3ebe44108517fbf6c30 rundir: /run/user/1001/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1001/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.aarch64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 31h 18m 41.00s (Approximately 1.29 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /var/home/test1/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/test1/.local/share/containers/storage graphRootAllocated: 10132369408 graphRootUsed: 1956737024 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/1001/containers transientStore: false volumePath: /var/home/test1/.local/share/containers/storage/volumes version: APIVersion: 4.4.1 Built: 1676629538 BuiltTime: Fri Feb 17 10:25:38 2023 GitCommit: """" GoVersion: go1.19.5 Os: linux OsArch: linux/arm64 Version: 4.4.1   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details The commands above were run with __podman 4.4.1__ on Fedora CoreOS by using qemu on a macOS laptop (operating system: Ventura 13.2.1).  [test1@localhost ~]$ docker version Client: Version: 20.10.23 API version: 1.41 Go version: go1.19.5 Git commit: %{shortcommit_cli} Built: Sun Jan 29 17:38:04 2023 OS/Arch: linux/arm64 Context: default Experimental: true Server: Engine: Version: 20.10.23 API version: 1.41 (minimum version 1.12) Go version: go1.19.5 Git commit: %{shortcommit_moby} Built: Sun Jan 29 17:38:04 2023 OS/Arch: linux/arm64 Experimental: false containerd: Version: 1.6.15 GitCommit: runc: Version: 1.1.4 GitCommit: docker-init: Version: 0.19.0 GitCommit:   [test1@localhost ~]$ podman version Client: Podman Engine Version: 4.4.1 API Version: 4.4.1 Go Version: go1.19.5 Built: Fri Feb 17 10:25:38 2023 OS/Arch: linux/arm64   [test1@localhost ~]$ rpm -q podman podman-4.4.1-3.fc37.aarch64   Additional information I have another computer (arch: amd64) running Fedora 37. I re-run the Podman commands there with __podman 4.4.2__. The container image ID changed and the container image size changed but nothing else.",source-file | other-file | other-file | source-file | test-file | test-file | source-file | source-file | source-file | other-file,rest api missing tag images img history description docker returns tag curl unix socket var docker sock http localhost images history tags alpine curl unix socket xdg runtime dir sock http localhost images history tags null steps reproduce sudo useradd usermod docker machinectl shell alpine docker alpine images detect image record result shell variable img systemctl user start socket curl unix socket var docker sock http localhost images img history tags curl unix socket xdg runtime dir sock http localhost images history tags describe results received localhost curl unix socket var docker sock http localhost images img history tags alpine localhost curl unix socket xdg runtime dir sock http localhost images img history tags null localhost describe results expected localhost curl unix socket var docker sock http localhost images img history tags alpine localhost curl unix socket xdg runtime dir sock http localhost images img history tags alpine localhost output yaml host arch arm buildahversion cgroupcontrollers memory pids cgroupmanager systemd cgroupversion conmon package conmon aarch path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant coreos eventlogger journald hostname localhost localdomain idmappings gidmap container host size container host size uidmap container host size container host size kernel aarch linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun aarch path crun crun ccd ebe fbf rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu libkrun wasm wasmedge yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns aarch slirp netns cfca eed libslirp slirp config max libseccomp swapfree swaptotal uptime approximately days plugins authorization null log none passthrough journald network bridge macvlan volume local registries search registry fedoraproject registry access redhat docker quay store configfile var home config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot var home local share containers storage graphrootallocated graphrootused graphstatus backing filesystem xfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath var home local share containers storage volumes apiversion built builttime feb gitcommit goversion linux osarch linux arm container privileged rootless rootless upstream latest yes additional environment details commands fedora coreos qemu macos laptop operating system ventura localhost docker client api git shortcommit cli built jan arch linux arm context default experimental true server engine api minimum git shortcommit moby built jan arch linux arm experimental false containerd gitcommit runc gitcommit docker init gitcommit localhost client engine api built feb arch linux arm localhost rpm aarch additional information another computer arch amd running fedora commands container image changed container image size changed nothing else,bug,0.95,"REST API: missing tag from `/v1.24/images/${img}/history`  Issue Description docker returns a tag  $ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Tags [ ""alpine:3.17.2"" ]  podman does not  $ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Tags null   Steps to reproduce the issue 1. `sudo -i` 2. `useradd test1` 3. `usermod -aG docker test1` 4. `machinectl shell test1@` 5. `podman pull alpine:3.17.2` 6. `docker pull alpine:3.17.2` 7. run `podman images` and detect the image id. Record the result in a shell variable `img=d74e625d9115` 9. `systemctl --user start podman.socket` 10. `curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags` 11. `curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/d74e625d9115/history | jq .[0].Tags`  Describe the results you received  [test1@localhost ~]$ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags [ ""alpine:3.17.2"" ] [test1@localhost ~]$ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags null [test1@localhost ~]$   Describe the results you expected  [test1@localhost ~]$ curl -s --unix-socket /var/run/docker.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags [ ""alpine:3.17.2"" ] [test1@localhost ~]$ curl -s --unix-socket $XDG_RUNTIME_DIR/podman/podman.sock http://localhost/v1.24/images/${img}/history | jq .[0].Tags [ ""alpine:3.17.2"" ] [test1@localhost ~]$   podman info output yaml host: arch: arm64 buildahVersion: 1.29.0 cgroupControllers: - memory - pids cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.6-3.fc37.aarch64 path: /usr/bin/conmon version: 'conmon version 2.1.6, commit: ' cpuUtilization: idlePercent: 99.65 systemPercent: 0.12 userPercent: 0.24 cpus: 1 distribution: distribution: fedora variant: coreos version: ""37"" eventLogger: journald hostname: localhost.localdomain idMappings: gidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 589824 size: 65536 uidmap: - container_id: 0 host_id: 1001 size: 1 - container_id: 1 host_id: 589824 size: 65536 kernel: 6.1.14-200.fc37.aarch64 linkmode: dynamic logDriver: journald memFree: 925364224 memTotal: 2050260992 networkBackend: netavark ociRuntime: name: crun package: crun-1.8.1-1.fc37.aarch64 path: /usr/bin/crun version: |- crun version 1.8.1 commit: f8a096be060b22ccd3d5f3ebe44108517fbf6c30 rundir: /run/user/1001/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +LIBKRUN +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1001/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /usr/bin/slirp4netns package: slirp4netns-1.2.0-8.fc37.aarch64 version: |- slirp4netns version 1.2.0 commit: 656041d45cfca7a4176f6b7eed9e4fe6c11e8383 libslirp: 4.7.0 SLIRP_CONFIG_VERSION_MAX: 4 libseccomp: 2.5.3 swapFree: 0 swapTotal: 0 uptime: 31h 18m 41.00s (Approximately 1.29 days) plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - registry.fedoraproject.org - registry.access.redhat.com - docker.io - quay.io store: configFile: /var/home/test1/.config/containers/storage.conf containerStore: number: 0 paused: 0 running: 0 stopped: 0 graphDriverName: overlay graphOptions: {} graphRoot: /var/home/test1/.local/share/containers/storage graphRootAllocated: 10132369408 graphRootUsed: 1956737024 graphStatus: Backing Filesystem: xfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 1 runRoot: /run/user/1001/containers transientStore: false volumePath: /var/home/test1/.local/share/containers/storage/volumes version: APIVersion: 4.4.1 Built: 1676629538 BuiltTime: Fri Feb 17 10:25:38 2023 GitCommit: """" GoVersion: go1.19.5 Os: linux OsArch: linux/arm64 Version: 4.4.1   Podman in a container No  Privileged Or Rootless Rootless  Upstream Latest Release Yes  Additional environment details The commands above were run with __podman 4.4.1__ on Fedora CoreOS by using qemu on a macOS laptop (operating system: Ventura 13.2.1).  [test1@localhost ~]$ docker version Client: Version: 20.10.23 API version: 1.41 Go version: go1.19.5 Git commit: %{shortcommit_cli} Built: Sun Jan 29 17:38:04 2023 OS/Arch: linux/arm64 Context: default Experimental: true Server: Engine: Version: 20.10.23 API version: 1.41 (minimum version 1.12) Go version: go1.19.5 Git commit: %{shortcommit_moby} Built: Sun Jan 29 17:38:04 2023 OS/Arch: linux/arm64 Experimental: false containerd: Version: 1.6.15 GitCommit: runc: Version: 1.1.4 GitCommit: docker-init: Version: 0.19.0 GitCommit:   [test1@localhost ~]$ podman version Client: Podman Engine Version: 4.4.1 API Version: 4.4.1 Go Version: go1.19.5 Built: Fri Feb 17 10:25:38 2023 OS/Arch: linux/arm64   [test1@localhost ~]$ rpm -q podman podman-4.4.1-3.fc37.aarch64   Additional information I have another computer (arch: amd64) running Fedora 37. I re-run the Podman commands there with __podman 4.4.2__. The container image ID changed and the container image size changed but nothing else."
25851,podman,https://github.com/containers/podman/issues/25851,Podman socket doesn't output EXPOSED ports," Issue Description The ports exposed of the containers are not returned by the podman socket (only the ones bind to the host) I'm using rootfull containers, I'm not sure if it's the same for rootless. I haven't been able to find another issue regarding this, so I'm not sure if this behavior is by design  Steps to reproduce the issue Steps to reproduce the issue:  $ sudo podman --version podman version 5.2.2 $ sudo podman run -d --name port-test -p 80:80 nginx:alpine $ sudo curl -s --unix-socket /run/podman/podman.sock http://localhost/containers/json?all=true | jq '.[] | select(.Names[] == ""/port-test"") | .Ports' [ { ""PrivatePort"": 80, ""PublicPort"": 80, ""Type"": ""tcp"" } ] $ sudo podman run -d --name expose-test --expose 80 nginx:alpine $ sudo curl -s --unix-socket /run/podman/podman.sock http://localhost/containers/json?all=true | jq '.[] | select(.Names[] == ""/expose-test"") | .Ports' []   Describe the results you received Exposed ports are not returned by the Podman socket []  Describe the results you expected Docker equivalent  $ sudo docker --version Docker version 27.3.1, build ce12230 $ sudo docker run -d --name port-test -p 80:80 nginx:alpine $ sudo curl -s --unix-socket /run/docker.sock http://localhost/containers/json?all=true | jq '.[] | select(.Names[] == ""/port-test"") | .Ports' [ { ""IP"": ""0.0.0.0"", ""PrivatePort"": 80, ""PublicPort"": 80, ""Type"": ""tcp"" }, ] $ sudo docker run -d --name expose-test --expose 80 nginx:alpine $ sudo curl -s --unix-socket /run/docker.sock http://localhost/containers/json?all=true | jq '.[] | select(.Names[] == ""/expose-test"") | .Ports' [ { ""PrivatePort"": 80, ""Type"": ""tcp"" }, ]   podman info output yaml host: arch: amd64 buildahVersion: 1.37.6 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.12-1.el9.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.12, commit: eb379dceb7efebd9a9d6b3349a57424d83483065' cpuUtilization: idlePercent: 99.61 systemPercent: 0.2 userPercent: 0.19 cpus: 4 databaseBackend: sqlite distribution: distribution: almalinux version: ""9.5"" eventLogger: journald freeLocks: 2046 hostname: almalinux9 idMappings: gidmap: null uidmap: null kernel: 5.14.0-503.35.1.el9_5.x86_64 linkmode: dynamic logDriver: journald memFree: 7268474880 memTotal: 8037085184 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.12.2-1.el9_5.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.12.2 package: netavark-1.12.2-1.el9.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.12.2 ociRuntime: name: crun package: crun-1.16.1-1.el9.x86_64 path: /usr/bin/crun version: |- crun version 1.16.1 commit: afa829ca0122bd5e1d67f1f38e6cc348027e3c32 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux pasta: executable: /bin/pasta package: passt-0^20240806.gee36266-7.el9_5.x86_64 version: | pasta 0^20240806.gee36266-7.el9_5.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /bin/slirp4netns package: slirp4netns-1.3.1-1.el9.x86_64 version: |- slirp4netns version 1.3.1 commit: e5e368c4f5db6ae75c2fce786e31eef9da6bf236 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 0 swapTotal: 0 uptime: 0h 54m 8.00s variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.access.redhat.com - registry.redhat.io - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 2 paused: 0 running: 2 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 40352677888 graphRootUsed: 1982976000 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 2 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.2.2 Built: 1743162783 BuiltTime: Fri Mar 28 11:53:03 2025 GitCommit: """" GoVersion: go1.22.9 (Red Hat 1.22.9-2.el9_5) Os: linux OsArch: linux/amd64 Version: 5.2.2   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details  $ cat /etc/*-release AlmaLinux release 9.5 (Teal Serval) NAME=""AlmaLinux"" VERSION=""9.5 (Teal Serval)"" ID=""almalinux"" ID_LIKE=""rhel centos fedora"" VERSION_ID=""9.5"" PLATFORM_ID=""platform:el9"" PRETTY_NAME=""AlmaLinux 9.5 (Teal Serval)"" ANSI_COLOR=""0;34"" LOGO=""fedora-logo-icon"" CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"" HOME_URL=""https://almalinux.org/"" DOCUMENTATION_URL=""https://wiki.almalinux.org/"" BUG_REPORT_URL=""https://bugs.almalinux.org/"" ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"" ALMALINUX_MANTISBT_PROJECT_VERSION=""9.5"" REDHAT_SUPPORT_PRODUCT=""AlmaLinux"" REDHAT_SUPPORT_PRODUCT_VERSION=""9.5"" SUPPORT_END=2032-06-01 AlmaLinux release 9.5 (Teal Serval) AlmaLinux release 9.5 (Teal Serval)   Additional information I'm using prometheus [docker_sd_config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#docker_sd_config) I want expose the containers metrics port, not bind it",source-file | source-file | test-file | source-file | test-file,socket output exposed ports description ports exposed containers returned socket ones bind host rootfull containers sure rootless able find another regarding sure behavior design steps reproduce steps reproduce sudo sudo name port nginx alpine sudo curl unix socket sock http localhost containers json true select names port ports privateport publicport type tcp sudo name expose expose nginx alpine sudo curl unix socket sock http localhost containers json true select names expose ports describe results received exposed ports returned socket describe results expected docker equivalent sudo docker docker sudo docker name port nginx alpine sudo curl unix socket docker sock http localhost containers json true select names port ports privateport publicport type tcp sudo docker name expose expose nginx alpine sudo curl unix socket docker sock http localhost containers json true select names expose ports privateport type tcp output yaml host arch amd buildahversion cgroupcontrollers cpuset cpu memory hugetlb pids rdma misc cgroupmanager systemd cgroupversion conmon package conmon path conmon conmon dceb efebd cpuutilization idlepercent systempercent userpercent cpus databasebackend sqlite distribution distribution almalinux eventlogger journald freelocks hostname almalinux idmappings gidmap null uidmap null kernel linkmode dynamic logdriver journald memfree memtotal networkbackend netavark networkbackendinfo backend netavark dns package aardvark dns path libexec aardvark dns aardvark dns package netavark path libexec netavark netavark ociruntime name crun package crun path crun crun afa rundir crun spec systemd selinux apparmor cap seccomp ebpf criu yajl linux pasta executable pasta package passt gee pasta gee copyright red hat gnu general public license later https www gnu licenses old licenses gpl html free software free redistribute warranty extent permitted law remotesocket exists true path sock rootlessnetworkcmd pasta security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless false seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled true serviceisremote false slirp netns executable slirp netns package slirp netns slirp netns fce eef libslirp slirp config max libseccomp swapfree swaptotal uptime variant plugins authorization null log none passthrough journald network bridge macvlan ipvlan volume local registries search registry access redhat registry redhat docker store configfile etc containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions overlay mountopt nodev metacopy graphroot var containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff false supports type true supports shifting false supports volatile true metacopy true imagecopytmpdir var tmp imagestore number runroot containers storage transientstore false volumepath var containers storage volumes apiversion built builttime mar gitcommit goversion red hat linux osarch linux amd container privileged rootless privileged upstream latest additional environment details cat etc almalinux teal serval name almalinux teal serval almalinux like rhel centos fedora platform platform pretty name almalinux teal serval ansi color logo fedora logo icon cpe name cpe almalinux almalinux baseos home url https almalinux documentation url https wiki almalinux bug report url https bugs almalinux almalinux mantisbt project almalinux almalinux mantisbt project redhat product almalinux redhat product end almalinux teal serval almalinux teal serval additional information prometheus docker config https prometheus docs prometheus latest configuration configuration docker config want expose containers metrics port bind,bug,0.95,"Podman socket doesn't output EXPOSED ports  Issue Description The ports exposed of the containers are not returned by the podman socket (only the ones bind to the host) I'm using rootfull containers, I'm not sure if it's the same for rootless. I haven't been able to find another issue regarding this, so I'm not sure if this behavior is by design  Steps to reproduce the issue Steps to reproduce the issue:  $ sudo podman --version podman version 5.2.2 $ sudo podman run -d --name port-test -p 80:80 nginx:alpine $ sudo curl -s --unix-socket /run/podman/podman.sock http://localhost/containers/json?all=true | jq '.[] | select(.Names[] == ""/port-test"") | .Ports' [ { ""PrivatePort"": 80, ""PublicPort"": 80, ""Type"": ""tcp"" } ] $ sudo podman run -d --name expose-test --expose 80 nginx:alpine $ sudo curl -s --unix-socket /run/podman/podman.sock http://localhost/containers/json?all=true | jq '.[] | select(.Names[] == ""/expose-test"") | .Ports' []   Describe the results you received Exposed ports are not returned by the Podman socket []  Describe the results you expected Docker equivalent  $ sudo docker --version Docker version 27.3.1, build ce12230 $ sudo docker run -d --name port-test -p 80:80 nginx:alpine $ sudo curl -s --unix-socket /run/docker.sock http://localhost/containers/json?all=true | jq '.[] | select(.Names[] == ""/port-test"") | .Ports' [ { ""IP"": ""0.0.0.0"", ""PrivatePort"": 80, ""PublicPort"": 80, ""Type"": ""tcp"" }, ] $ sudo docker run -d --name expose-test --expose 80 nginx:alpine $ sudo curl -s --unix-socket /run/docker.sock http://localhost/containers/json?all=true | jq '.[] | select(.Names[] == ""/expose-test"") | .Ports' [ { ""PrivatePort"": 80, ""Type"": ""tcp"" }, ]   podman info output yaml host: arch: amd64 buildahVersion: 1.37.6 cgroupControllers: - cpuset - cpu - io - memory - hugetlb - pids - rdma - misc cgroupManager: systemd cgroupVersion: v2 conmon: package: conmon-2.1.12-1.el9.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.12, commit: eb379dceb7efebd9a9d6b3349a57424d83483065' cpuUtilization: idlePercent: 99.61 systemPercent: 0.2 userPercent: 0.19 cpus: 4 databaseBackend: sqlite distribution: distribution: almalinux version: ""9.5"" eventLogger: journald freeLocks: 2046 hostname: almalinux9 idMappings: gidmap: null uidmap: null kernel: 5.14.0-503.35.1.el9_5.x86_64 linkmode: dynamic logDriver: journald memFree: 7268474880 memTotal: 8037085184 networkBackend: netavark networkBackendInfo: backend: netavark dns: package: aardvark-dns-1.12.2-1.el9_5.x86_64 path: /usr/libexec/podman/aardvark-dns version: aardvark-dns 1.12.2 package: netavark-1.12.2-1.el9.x86_64 path: /usr/libexec/podman/netavark version: netavark 1.12.2 ociRuntime: name: crun package: crun-1.16.1-1.el9.x86_64 path: /usr/bin/crun version: |- crun version 1.16.1 commit: afa829ca0122bd5e1d67f1f38e6cc348027e3c32 rundir: /run/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +YAJL os: linux pasta: executable: /bin/pasta package: passt-0^20240806.gee36266-7.el9_5.x86_64 version: | pasta 0^20240806.gee36266-7.el9_5.x86_64 Copyright Red Hat GNU General Public License, version 2 or later <https://www.gnu.org/licenses/old-licenses/gpl-2.0.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. remoteSocket: exists: true path: /run/podman/podman.sock rootlessNetworkCmd: pasta security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: false seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: true serviceIsRemote: false slirp4netns: executable: /bin/slirp4netns package: slirp4netns-1.3.1-1.el9.x86_64 version: |- slirp4netns version 1.3.1 commit: e5e368c4f5db6ae75c2fce786e31eef9da6bf236 libslirp: 4.4.0 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.2 swapFree: 0 swapTotal: 0 uptime: 0h 54m 8.00s variant: """" plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan - ipvlan volume: - local registries: search: - registry.access.redhat.com - registry.redhat.io - docker.io store: configFile: /etc/containers/storage.conf containerStore: number: 2 paused: 0 running: 2 stopped: 0 graphDriverName: overlay graphOptions: overlay.mountopt: nodev,metacopy=on graphRoot: /var/lib/containers/storage graphRootAllocated: 40352677888 graphRootUsed: 1982976000 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""false"" Supports d_type: ""true"" Supports shifting: ""false"" Supports volatile: ""true"" Using metacopy: ""true"" imageCopyTmpDir: /var/tmp imageStore: number: 2 runRoot: /run/containers/storage transientStore: false volumePath: /var/lib/containers/storage/volumes version: APIVersion: 5.2.2 Built: 1743162783 BuiltTime: Fri Mar 28 11:53:03 2025 GitCommit: """" GoVersion: go1.22.9 (Red Hat 1.22.9-2.el9_5) Os: linux OsArch: linux/amd64 Version: 5.2.2   Podman in a container No  Privileged Or Rootless Privileged  Upstream Latest Release No  Additional environment details  $ cat /etc/*-release AlmaLinux release 9.5 (Teal Serval) NAME=""AlmaLinux"" VERSION=""9.5 (Teal Serval)"" ID=""almalinux"" ID_LIKE=""rhel centos fedora"" VERSION_ID=""9.5"" PLATFORM_ID=""platform:el9"" PRETTY_NAME=""AlmaLinux 9.5 (Teal Serval)"" ANSI_COLOR=""0;34"" LOGO=""fedora-logo-icon"" CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"" HOME_URL=""https://almalinux.org/"" DOCUMENTATION_URL=""https://wiki.almalinux.org/"" BUG_REPORT_URL=""https://bugs.almalinux.org/"" ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"" ALMALINUX_MANTISBT_PROJECT_VERSION=""9.5"" REDHAT_SUPPORT_PRODUCT=""AlmaLinux"" REDHAT_SUPPORT_PRODUCT_VERSION=""9.5"" SUPPORT_END=2032-06-01 AlmaLinux release 9.5 (Teal Serval) AlmaLinux release 9.5 (Teal Serval)   Additional information I'm using prometheus [docker_sd_config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#docker_sd_config) I want expose the containers metrics port, not bind it"
15485,podman,https://github.com/containers/podman/issues/15485,invalid event on image removal + missing untag event from REST API,"<!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** Removing an image should send a `delete` event but I'm receiving a `remove` event https://docs.docker.com/engine/api/v1.41/#tag/System/operation/SystemEvents states: Images report these events: `delete`, `import`, `load`, `pull`, `push`, `save`, `tag`, `untag`, and `prune` **Steps to reproduce the issue:** 1. pull an image with docker bash $ docker pull httpd  track events in a separate terminal  $ curl --unix-socket /var/run/docker.sock http:/v1.41/events  remove the image  $ docker rmi a981c8992512  look at the events  {""status"":""untag"",""id"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Type"":""image"",""Action"":""untag"",""Actor"":{""ID"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Attributes"":{""name"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825""}},""scope"":""local"",""time"":1661444877,""timeNano"":1661444877274518985} {""status"":""untag"",""id"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Type"":""image"",""Action"":""untag"",""Actor"":{""ID"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Attributes"":{""name"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825""}},""scope"":""local"",""time"":1661444877,""timeNano"":1661444877278753809} {""status"":""delete"",""id"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Type"":""image"",""Action"":""delete"",""Actor"":{""ID"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Attributes"":{""name"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825""}},""scope"":""local"",""time"":1661444877,""timeNano"":1661444877436313927}  2. Now, try with podman pull httpd image  $ podman pull httpd Resolving ""httpd"" using unqualified-search registries (/etc/containers/registries.conf.d/999-podman-machine.conf) Trying to pull docker.io/library/httpd:latest Getting image source signatures Copying blob sha256:152876b0d24a5561415915c652dceeb3bcd5080dc24c3994e77343a81f64b9f1 Copying blob sha256:7a6db449b51b92eac5c81cdbd82917785343f1664b2be57b22337b0a40c5b29d Copying blob sha256:b4effd428409f1da4dc8c896afb9818ef1ba24be5e7e5e3d86dea650ac3ed8bc Copying blob sha256:6b29c2b62286e254216da297b4066a4bb79b918bc02811ba954bd7b8fd51360b Copying blob sha256:c2123effa3fcb96c62bf4d891147aef09029d429321bfb4c6a535fa3ca7e13d6 Copying config sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825 Writing manifest to image destination Storing signatures a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825  Track events in a separate terminal  $ curl --unix-socket /Users/benoitf/.local/share/containers/podman/machine/podman-machine-default/podman.sock http:/v1.41/events  remove the image  $ podman rmi a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825  Untagged: docker.io/library/httpd:latest Deleted: a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825 look at events  {""status"":""remove"",""id"":""a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Type"":""image"",""Action"":""remove"",""Actor"":{""ID"":""a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Attributes"":{""containerExitCode"":""0"",""image"":"""",""name"":""a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825""}},""scope"":""local"",""time"":1661444997,""timeNano"":1661444997046721781,""HealthStatus"":""""}  we are missing the `untag` event and we receive a `remove` event instead of `delete` **Describe the results you received:** receive `remove` **Describe the results you expected:** expect `untag` + `delete` events **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Client: Podman Engine Version: 4.2.0 API Version: 4.2.0 Go Version: go1.18.5 Built: Wed Aug 10 22:46:05 2022 OS/Arch: darwin/amd64 Server: Podman Engine Version: 4.2.0 API Version: 4.2.0 Go Version: go1.18.4 Built: Thu Aug 11 16:42:17 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  (paste your output here)  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  (paste your output here)  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes/No **Additional environment details (AWS, VirtualBox, physical, etc.):**",source-file | test-file | other-file | other-file | test-file | source-file | other-file | source-file | test-file,invalid event image removal missing untag event rest api bug report information use commands provide key information environment include information feature note large number issues reported often found already fixed current versions project reporting please verify running compare latest documented top readme readme differ please latest possible retry command creating also running list known issues troubleshooting guide https github containers blob troubleshooting please reference page opening new filing bug please instead bug buildah https github containers buildah issues executes buildah perform container builds buildah maintainers best equipped handle bugs bug report feature leave one kind bug description removing image send delete event receiving event https docs docker engine api tag system operation systemevents states images report events delete import load push save tag untag prune steps reproduce image docker bash docker httpd track events separate terminal curl unix socket var docker sock http events image docker rmi look events status untag sha ecabb type image action untag actor sha ecabb attributes name sha ecabb scope local time timenano status untag sha ecabb type image action untag actor sha ecabb attributes name sha ecabb scope local time timenano status delete sha ecabb type image action delete actor sha ecabb attributes name sha ecabb scope local time timenano httpd image httpd resolving httpd unqualified search registries etc containers registries conf machine conf trying docker library httpd latest getting image signatures copying blob sha dceeb bcd copying blob sha eac cdbd copying blob sha effd afb dea copying blob sha copying blob sha effa fcb aef bfb copying config sha ecabb writing manifest image destination storing signatures ecabb track events separate terminal curl unix socket users benoitf local share containers machine machine default sock http events image rmi ecabb untagged docker library httpd latest deleted ecabb look events status ecabb type image action actor ecabb attributes containerexitcode image name ecabb scope local time timenano healthstatus missing untag event receive event instead delete describe results received receive describe results expected expect untag delete events additional information deem important happens occasionally output client engine api built aug arch darwin amd server engine api built aug arch linux amd output paste output package output rpm apt list paste output tested latest checked troubleshooting guide https github containers blob troubleshooting yes additional environment details aws virtualbox physical etc,bug,0.95,"invalid event on image removal + missing untag event from REST API <!--  BUG REPORT INFORMATION  Use the commands below to provide key information from your environment: You do NOT have to include this information if this is a FEATURE REQUEST **NOTE** A large number of issues reported against Podman are often found to already be fixed in more current versions of the project. Before reporting an issue, please verify the version you are running with `podman version` and compare it to the latest release documented on the top of Podman's [README.md](../README.md). If they differ, please update your version of Podman to the latest possible and retry your command before creating an issue. Also, there is a running list of known issues in the [Podman Troubleshooting Guide](https://github.com/containers/podman/blob/main/troubleshooting.md), please reference that page before opening a new issue. If you are filing a bug against `podman build`, please instead file a bug against Buildah (https://github.com/containers/buildah/issues). Podman build executes Buildah to perform container builds, and as such the Buildah maintainers are best equipped to handle these bugs. --> **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** Removing an image should send a `delete` event but I'm receiving a `remove` event https://docs.docker.com/engine/api/v1.41/#tag/System/operation/SystemEvents states: Images report these events: `delete`, `import`, `load`, `pull`, `push`, `save`, `tag`, `untag`, and `prune` **Steps to reproduce the issue:** 1. pull an image with docker bash $ docker pull httpd  track events in a separate terminal  $ curl --unix-socket /var/run/docker.sock http:/v1.41/events  remove the image  $ docker rmi a981c8992512  look at the events  {""status"":""untag"",""id"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Type"":""image"",""Action"":""untag"",""Actor"":{""ID"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Attributes"":{""name"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825""}},""scope"":""local"",""time"":1661444877,""timeNano"":1661444877274518985} {""status"":""untag"",""id"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Type"":""image"",""Action"":""untag"",""Actor"":{""ID"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Attributes"":{""name"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825""}},""scope"":""local"",""time"":1661444877,""timeNano"":1661444877278753809} {""status"":""delete"",""id"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Type"":""image"",""Action"":""delete"",""Actor"":{""ID"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Attributes"":{""name"":""sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825""}},""scope"":""local"",""time"":1661444877,""timeNano"":1661444877436313927}  2. Now, try with podman pull httpd image  $ podman pull httpd Resolving ""httpd"" using unqualified-search registries (/etc/containers/registries.conf.d/999-podman-machine.conf) Trying to pull docker.io/library/httpd:latest Getting image source signatures Copying blob sha256:152876b0d24a5561415915c652dceeb3bcd5080dc24c3994e77343a81f64b9f1 Copying blob sha256:7a6db449b51b92eac5c81cdbd82917785343f1664b2be57b22337b0a40c5b29d Copying blob sha256:b4effd428409f1da4dc8c896afb9818ef1ba24be5e7e5e3d86dea650ac3ed8bc Copying blob sha256:6b29c2b62286e254216da297b4066a4bb79b918bc02811ba954bd7b8fd51360b Copying blob sha256:c2123effa3fcb96c62bf4d891147aef09029d429321bfb4c6a535fa3ca7e13d6 Copying config sha256:a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825 Writing manifest to image destination Storing signatures a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825  Track events in a separate terminal  $ curl --unix-socket /Users/benoitf/.local/share/containers/podman/machine/podman-machine-default/podman.sock http:/v1.41/events  remove the image  $ podman rmi a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825  Untagged: docker.io/library/httpd:latest Deleted: a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825 look at events  {""status"":""remove"",""id"":""a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Type"":""image"",""Action"":""remove"",""Actor"":{""ID"":""a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825"",""Attributes"":{""containerExitCode"":""0"",""image"":"""",""name"":""a981c8992512d65c9b450a9ecabb1cb9d35bb6b03f3640f86471032d5800d825""}},""scope"":""local"",""time"":1661444997,""timeNano"":1661444997046721781,""HealthStatus"":""""}  we are missing the `untag` event and we receive a `remove` event instead of `delete` **Describe the results you received:** receive `remove` **Describe the results you expected:** expect `untag` + `delete` events **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  Client: Podman Engine Version: 4.2.0 API Version: 4.2.0 Go Version: go1.18.5 Built: Wed Aug 10 22:46:05 2022 OS/Arch: darwin/amd64 Server: Podman Engine Version: 4.2.0 API Version: 4.2.0 Go Version: go1.18.4 Built: Thu Aug 11 16:42:17 2022 OS/Arch: linux/amd64  **Output of `podman info`:**  (paste your output here)  **Package info (e.g. output of `rpm -q podman` or `apt list podman`):**  (paste your output here)  **Have you tested with the latest version of Podman and have you checked the Podman Troubleshooting Guide? (https://github.com/containers/podman/blob/main/troubleshooting.md)** Yes/No **Additional environment details (AWS, VirtualBox, physical, etc.):**"
17585,podman,https://github.com/containers/podman/issues/17585,Creating an Existing Network Via REST API Returns Different Status Code vs. Docker," Issue Description When trying to run [Supabase](https://supabase.com) locally with their CLI you will always get a `network already exists` error. Copied [comment](https://github.com/containers/podman/issues/15499#issuecomment-1331508660) from #15499 by @jgraettinger: > I ran into this while attempting to use the supabase CLI tool with podman instead of docker. > > The supabase CLI spins up a bunch of containers, and at several points [attempts to create a docker > network if it doesn't already exist](https://github.com/supabase/cli/blob/main/internal/utils/docker.go?rgh-link-date=2022-11-30T00%3A57%3A59Z#L51-L68), as determined by [docker library error helpers which are explicitly looking for HTTP 409 status](https://github.com/moby/moby/blob/master/errdefs/http_helpers.go?rgh-link-date=2022-11-30T00%3A57%3A59Z#L20), and don't properly interpret podman's 500. > > I'm unsure if this belongs as a separate issue, but it's an example where the HTTP 500 rather than 409 behavior diverges from the Docker REST API.  Steps to reproduce the issue Steps to reproduce the issue 1. Set up and run a Supabase Project locally - [Guide](https://supabase.com/docs/guides/cli/local-development#prerequisites) 2. See error  Describe the results you received Podman says that the network already exists, but when you run `podman network ls` it does not. None of the containers have started.  Describe the results you expected The containers to all be running and accessible.  podman info output yaml  podman info host: arch: amd64 buildahVersion: 1.28.0 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.5-1.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: ' cpuUtilization: idlePercent: 99.68 systemPercent: 0.18 userPercent: 0.14 cpus: 32 distribution: distribution: fedora variant: container version: ""36"" eventLogger: journald hostname: UMBRA idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.15.57.1-microsoft-standard-WSL2+ linkmode: dynamic logDriver: journald memFree: 15241453568 memTotal: 16722722816 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-3.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 4294967296 swapTotal: 4294967296 uptime: 0h 15m 0.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /home/user/.config/containers/storage.conf containerStore: number: 1 paused: 0 running: 0 stopped: 1 graphDriverName: overlay graphOptions: {} graphRoot: /home/user/.local/share/containers/storage graphRootAllocated: 1081101176832 graphRootUsed: 10558271488 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 20 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/user/.local/share/containers/storage/volumes version: APIVersion: 4.3.1 Built: 1668180253 BuiltTime: Fri Nov 11 16:24:13 2022 GitCommit: """" GoVersion: go1.18.7 Os: linux OsArch: linux/amd64 Version: 4.3.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_",source-file | test-file | source-file | test-file,creating existing network via rest api returns different status docker description trying https locally cli always get network already exists copied comment https github containers issues issuecomment jgraettinger ran attempting use cli tool instead docker cli spins bunch containers several points attempts create docker network already exist https github cli blob internal utils docker rgh link date determined docker library helpers explicitly looking http status https github moby moby blob errdefs http helpers rgh link date properly interpret unsure belongs separate example http rather behavior diverges docker rest api steps reproduce steps reproduce set project locally guide https docs guides cli local development prerequisites see describe results received says network already exists network none containers started describe results expected containers running accessible output yaml host arch amd buildahversion cgroupcontrollers cgroupmanager cgroupfs cgroupversion conmon package conmon path conmon conmon cpuutilization idlepercent systempercent userpercent cpus distribution distribution fedora variant container eventlogger journald hostname umbra idmappings gidmap container host size container host size uidmap container host size container host size kernel microsoft standard wsl linkmode dynamic logdriver journald memfree memtotal networkbackend netavark ociruntime name crun package crun path crun crun aff cac rundir user crun spec systemd selinux apparmor cap seccomp ebpf criu wasm wasmedge yajl linux remotesocket exists true path user sock security apparmorenabled false capabilities cap chown cap dac override cap fowner cap fsetid cap kill cap bind service cap setfcap cap setgid cap setpcap cap setuid cap sys chroot rootless true seccompenabled true seccompprofilepath share containers seccomp json selinuxenabled false serviceisremote true slirp netns executable slirp netns slirp netns beta dda libslirp slirp config max libseccomp swapfree swaptotal uptime plugins authorization null log none passthrough journald network bridge macvlan volume local registries search docker store configfile home user config containers storage conf containerstore number paused running stopped graphdrivername overlay graphoptions graphroot home user local share containers storage graphrootallocated graphrootused graphstatus backing filesystem extfs native overlay diff true supports type true metacopy false imagecopytmpdir var tmp imagestore number runroot user containers transientstore false volumepath home user local share containers storage volumes apiversion built builttime nov gitcommit goversion linux osarch linux amd container privileged rootless none upstream latest yes additional environment details response additional information response,bug,0.95,"Creating an Existing Network Via REST API Returns Different Status Code vs. Docker  Issue Description When trying to run [Supabase](https://supabase.com) locally with their CLI you will always get a `network already exists` error. Copied [comment](https://github.com/containers/podman/issues/15499#issuecomment-1331508660) from #15499 by @jgraettinger: > I ran into this while attempting to use the supabase CLI tool with podman instead of docker. > > The supabase CLI spins up a bunch of containers, and at several points [attempts to create a docker > network if it doesn't already exist](https://github.com/supabase/cli/blob/main/internal/utils/docker.go?rgh-link-date=2022-11-30T00%3A57%3A59Z#L51-L68), as determined by [docker library error helpers which are explicitly looking for HTTP 409 status](https://github.com/moby/moby/blob/master/errdefs/http_helpers.go?rgh-link-date=2022-11-30T00%3A57%3A59Z#L20), and don't properly interpret podman's 500. > > I'm unsure if this belongs as a separate issue, but it's an example where the HTTP 500 rather than 409 behavior diverges from the Docker REST API.  Steps to reproduce the issue Steps to reproduce the issue 1. Set up and run a Supabase Project locally - [Guide](https://supabase.com/docs/guides/cli/local-development#prerequisites) 2. See error  Describe the results you received Podman says that the network already exists, but when you run `podman network ls` it does not. None of the containers have started.  Describe the results you expected The containers to all be running and accessible.  podman info output yaml  podman info host: arch: amd64 buildahVersion: 1.28.0 cgroupControllers: [] cgroupManager: cgroupfs cgroupVersion: v1 conmon: package: conmon-2.1.5-1.fc36.x86_64 path: /usr/bin/conmon version: 'conmon version 2.1.5, commit: ' cpuUtilization: idlePercent: 99.68 systemPercent: 0.18 userPercent: 0.14 cpus: 32 distribution: distribution: fedora variant: container version: ""36"" eventLogger: journald hostname: UMBRA idMappings: gidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 uidmap: - container_id: 0 host_id: 1000 size: 1 - container_id: 1 host_id: 100000 size: 65536 kernel: 5.15.57.1-microsoft-standard-WSL2+ linkmode: dynamic logDriver: journald memFree: 15241453568 memTotal: 16722722816 networkBackend: netavark ociRuntime: name: crun package: crun-1.7.2-3.fc36.x86_64 path: /usr/bin/crun version: |- crun version 1.7.2 commit: 0356bf4aff9a133d655dc13b1d9ac9424706cac4 rundir: /run/user/1000/crun spec: 1.0.0 +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +CRIU +WASM:wasmedge +YAJL os: linux remoteSocket: exists: true path: /run/user/1000/podman/podman.sock security: apparmorEnabled: false capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT rootless: true seccompEnabled: true seccompProfilePath: /usr/share/containers/seccomp.json selinuxEnabled: false serviceIsRemote: true slirp4netns: executable: /usr/bin/slirp4netns slirp4netns version 1.2.0-beta.0 commit: 477db14a24ff1a3de3a705e51ca2c4c1fe3dda64 libslirp: 4.6.1 SLIRP_CONFIG_VERSION_MAX: 3 libseccomp: 2.5.3 swapFree: 4294967296 swapTotal: 4294967296 uptime: 0h 15m 0.00s plugins: authorization: null log: - k8s-file - none - passthrough - journald network: - bridge - macvlan volume: - local registries: search: - docker.io store: configFile: /home/user/.config/containers/storage.conf containerStore: number: 1 paused: 0 running: 0 stopped: 1 graphDriverName: overlay graphOptions: {} graphRoot: /home/user/.local/share/containers/storage graphRootAllocated: 1081101176832 graphRootUsed: 10558271488 graphStatus: Backing Filesystem: extfs Native Overlay Diff: ""true"" Supports d_type: ""true"" Using metacopy: ""false"" imageCopyTmpDir: /var/tmp imageStore: number: 20 runRoot: /run/user/1000/containers transientStore: false volumePath: /home/user/.local/share/containers/storage/volumes version: APIVersion: 4.3.1 Built: 1668180253 BuiltTime: Fri Nov 11 16:24:13 2022 GitCommit: """" GoVersion: go1.18.7 Os: linux OsArch: linux/amd64 Version: 4.3.1   Podman in a container No  Privileged Or Rootless None  Upstream Latest Release Yes  Additional environment details _No response_  Additional information _No response_"
16915,podman,https://github.com/containers/podman/issues/16915,--network=default doesn't mean the same thing as --network=,"**Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** While debugging some unexpected interactions between a docker client and podman server on my side, I found out that the flag `--network=default` doesn't mean the same thing as `--network=` (or the absence of `--network=XXX` flag). Note that docker docker client will explicitly pass NetworkMode=default when calling the docker daemon HTTP api, if no `--network` flag was provided to the docker CLI. **Steps to reproduce the issue:** All this was done using the very latest `quay.io/podman/upstream` image started in privileged mode. 1. Create couple of containers, with different `--network` flags:  [root@a3a34f67a163 /]# podman create --cidfile=no-explicit-flag fedora Resolved ""fedora"" as an alias (/etc/containers/registries.conf.d/000-shortnames.conf) Trying to pull registry.fedoraproject.org/fedora:latest Getting image source signatures Copying blob 1842e4e4b562 done Copying config 19c0ae4dd2 done Writing manifest to image destination Storing signatures b987b9bc53e056f024da0ed0cca4fc9e598edd512df7ffad8dc007d740c3b790 [root@a3a34f67a163 /]# podman create --network= --cidfile=explicitly-empty-flag fedora 92023ad1e615bcea04be21569a1139446a1c0aa2b69d3298d926ef4c5de1d045 [root@a3a34f67a163 /]# podman create --network=default --cidfile=explicitly-default-flag fedora b7287211a64864d4bad9872c973be2abbde56d67e0f43caa44348aa7717a1944  2. Now inspect a bit the NetworkMode for each (note: I use the `quay.io/podman/upstream` which has a containers.conf file which hardcodes the network mode to `host`:  [root@a3a34f67a163 /]# podman inspect $(cat no-explicit-flag)|grep NetworkMode ""NetworkMode"": ""host"", [root@a3a34f67a163 /]# podman inspect $(cat explicitly-empty-flag)|grep NetworkMode ""NetworkMode"": ""host"", [root@a3a34f67a163 /]# podman inspect $(cat explicitly-default-flag)|grep NetworkMode ""NetworkMode"": ""bridge"",  3. Now install the Docker CLI, start a podman socket with `system service` (I won't show how to do it), and try to create a container with no explicit `--network` flag with the docker client, it will use the bridge mode by default:  [root@a3a34f67a163 /]# DOCKER_HOST=unix:var/run/podman/podman.sock docker create --cidfile=no-explicit-flag-from-docker-cli fedora 1ebc2db1ef56c75a5588e3c0599c554835a7a352b700856b3fe53fbe1e53b48b [root@a3a34f67a163 /]# podman --remote inspect $(cat no-explicit-flag-from-docker-cli)|grep NetworkMode ""NetworkMode"": ""bridge"",  **Describe the results you received:** The explicit `--network=default` flags resolves to the `bridge` network mode, while I would have expected the `host` one (in my conditions, as this is one overriden in the `containers.conf` file). **Describe the results you expected:** I would expect that in the same conditions, a container started explicitly with `--network=default` (or a container started with the docker CLI without providing any `--network` flag) uses the `host` network mode (as this is one overriden in the `containers.conf` file), just like when we run podman with no explicit `--network` flag. Basically no matter which client podman vs docker is used, the end result should be the same. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  [root@a3a34f67a163 /]# podman version Client: Podman Engine Version: 4.4.0-dev API Version: 4.4.0-dev Go Version: go1.19.3 Built: Thu Jan 1 00:00:00 1970 OS/Arch: linux/amd64",source-file | test-file | test-file,network default mean thing network bug report feature leave one kind bug description debugging unexpected interactions docker client server side found flag network default mean thing network absence network xxx flag note docker docker client explicitly pass networkmode default calling docker daemon http api network flag provided docker cli steps reproduce done latest quay upstream image started privileged mode create couple containers different network flags root create cidfile explicit flag fedora resolved fedora alias etc containers registries conf shortnames conf trying registry fedoraproject fedora latest getting image signatures copying blob done copying config done writing manifest image destination storing signatures cca edd ffad root create network cidfile explicitly empty flag fedora bcea root create network default cidfile explicitly default flag fedora bad abbde caa inspect bit networkmode note use quay upstream containers conf hardcodes network mode host root inspect cat explicit flag grep networkmode networkmode host root inspect cat explicitly empty flag grep networkmode networkmode host root inspect cat explicitly default flag grep networkmode networkmode bridge install docker cli start socket system service show create container explicit network flag docker client use bridge mode default root docker host unix var sock docker create cidfile explicit flag docker cli fedora ebc fbe root remote inspect cat explicit flag docker cli grep networkmode networkmode bridge describe results received explicit network default flags resolves bridge network mode would expected host one conditions one overriden containers conf describe results expected would expect conditions container started explicitly network default container started docker cli without providing network flag uses host network mode one overriden containers conf like explicit network flag basically matter client docker used end result additional information deem important happens occasionally output root client engine api built jan arch linux amd,bug,0.9,"--network=default doesn't mean the same thing as --network= **Is this a BUG REPORT or FEATURE REQUEST? (leave only one on its own line)** /kind bug **Description** While debugging some unexpected interactions between a docker client and podman server on my side, I found out that the flag `--network=default` doesn't mean the same thing as `--network=` (or the absence of `--network=XXX` flag). Note that docker docker client will explicitly pass NetworkMode=default when calling the docker daemon HTTP api, if no `--network` flag was provided to the docker CLI. **Steps to reproduce the issue:** All this was done using the very latest `quay.io/podman/upstream` image started in privileged mode. 1. Create couple of containers, with different `--network` flags:  [root@a3a34f67a163 /]# podman create --cidfile=no-explicit-flag fedora Resolved ""fedora"" as an alias (/etc/containers/registries.conf.d/000-shortnames.conf) Trying to pull registry.fedoraproject.org/fedora:latest Getting image source signatures Copying blob 1842e4e4b562 done Copying config 19c0ae4dd2 done Writing manifest to image destination Storing signatures b987b9bc53e056f024da0ed0cca4fc9e598edd512df7ffad8dc007d740c3b790 [root@a3a34f67a163 /]# podman create --network= --cidfile=explicitly-empty-flag fedora 92023ad1e615bcea04be21569a1139446a1c0aa2b69d3298d926ef4c5de1d045 [root@a3a34f67a163 /]# podman create --network=default --cidfile=explicitly-default-flag fedora b7287211a64864d4bad9872c973be2abbde56d67e0f43caa44348aa7717a1944  2. Now inspect a bit the NetworkMode for each (note: I use the `quay.io/podman/upstream` which has a containers.conf file which hardcodes the network mode to `host`:  [root@a3a34f67a163 /]# podman inspect $(cat no-explicit-flag)|grep NetworkMode ""NetworkMode"": ""host"", [root@a3a34f67a163 /]# podman inspect $(cat explicitly-empty-flag)|grep NetworkMode ""NetworkMode"": ""host"", [root@a3a34f67a163 /]# podman inspect $(cat explicitly-default-flag)|grep NetworkMode ""NetworkMode"": ""bridge"",  3. Now install the Docker CLI, start a podman socket with `system service` (I won't show how to do it), and try to create a container with no explicit `--network` flag with the docker client, it will use the bridge mode by default:  [root@a3a34f67a163 /]# DOCKER_HOST=unix:var/run/podman/podman.sock docker create --cidfile=no-explicit-flag-from-docker-cli fedora 1ebc2db1ef56c75a5588e3c0599c554835a7a352b700856b3fe53fbe1e53b48b [root@a3a34f67a163 /]# podman --remote inspect $(cat no-explicit-flag-from-docker-cli)|grep NetworkMode ""NetworkMode"": ""bridge"",  **Describe the results you received:** The explicit `--network=default` flags resolves to the `bridge` network mode, while I would have expected the `host` one (in my conditions, as this is one overriden in the `containers.conf` file). **Describe the results you expected:** I would expect that in the same conditions, a container started explicitly with `--network=default` (or a container started with the docker CLI without providing any `--network` flag) uses the `host` network mode (as this is one overriden in the `containers.conf` file), just like when we run podman with no explicit `--network` flag. Basically no matter which client podman vs docker is used, the end result should be the same. **Additional information you deem important (e.g. issue happens only occasionally):** **Output of `podman version`:**  [root@a3a34f67a163 /]# podman version Client: Podman Engine Version: 4.4.0-dev API Version: 4.4.0-dev Go Version: go1.19.3 Built: Thu Jan 1 00:00:00 1970 OS/Arch: linux/amd64"
