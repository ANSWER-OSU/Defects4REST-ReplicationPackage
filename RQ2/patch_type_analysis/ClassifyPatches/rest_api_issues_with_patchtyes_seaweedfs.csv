issue_no,repo,issue_url,title,description,patched_file_types
1776,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1776,S3 should return 204 on DELETE to nonexistent file (not 404),"**Describe the bug** The Amazon S3 api specification states that a DELETE request to a non-existing file should return HTTP status `HTTP/1.1 204 No Content`, as described [here](https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObject.html). Currently, seaweedfs S3 implementation returns `404 Not Found`. **System Setup** - List the command line to start: `./weed server -s3 -s3.config=config.json -dir=""/minio/weed"" -volume.max=100` - OS version: `CentOS 8` - output of `weed version`: `version 30GB 2.23 318a3d2 linux amd64` **Expected behavior** Seaweedfs should follow the Amazon S3 API specification and return HTTP 204 status-code when issuing a DELETE request to a non-existing file. This is important for compatibility with applications expecting S3 behavior. **Additional context** I stumbled upon this problem when attempting to use [pgbackrest](https://pgbackrest.org/) postgres backup software configured with seaweedfs S3 API as storage. When performing a regular backup, pgbackrest would almost finish but at the end run into an exception:  2021-02-02 16:04:39.364 P00 DEBUG: common/io/http/request::httpRequestResponse: => {code: 404, reason: Not Found, header: {accept-ranges: 'bytes', content-length: '234', content-type: 'application/xml', date: 'Tue, 02 Feb 2021 15:04:39 GMT', server: 'SeaweedFS S3 30GB 2.23', x-amz-request-id: '1612278279364142795'}, contentChunked: false, contentSize: 234, contentRemaining: 0, closeOnContentEof: false, contentExists: true, contentEof: true, contentCached: true} 2021-02-02 16:04:39.365 P00 DEBUG: common/exit::exitSafe: (result: 0, error: true, signalType: 0) ERROR: [039]: HTTP request failed with 404 (Not Found):  URI/Query : /dev-pgbackrest/backup/dev-pg-f3c001/latest  Request Headers : authorization: <redacted> content-length: 0 host: dev-seaweed-backup001-vip.<redacted> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 x-amz-date: <redacted>  Response Headers : accept-ranges: bytes content-length: 234 content-type: application/xml date: Tue, 02 Feb 2021 15:04:39 GMT server: SeaweedFS S3 30GB 2.23 x-amz-request-id: 1612278279364142795  Response Content : <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Resource>/dev-pgbackrest/backup/dev-pg-f3c001/latest</Resource><RequestId>1612278279364119515</RequestId></Error>  Searching for this error came up with this pgbackrest bug; https://github.com/pgbackrest/pgbackrest/issues/985 which details the same problem of an S3 implementation returning 404 for DELETE. I think this problem stems from issue #1160 where it was incorrectly stated that the API should return 404 in this case. Please let me know if I can provide additional information!",source-file
1988,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1988,Upload file fail via filer WebUI,"**Describe the bug** When ""window.location.href"" is a directory and without ending of ""/"",upload file will get a reponse {""error"":""update entry /xxx/yyy: existing /xxx/yyy is a directory""} directory url like /xxx/yyy/ can be uploaded successfully **Expected behavior** File uploaded. **Additional context** https://github.com/chrislusf/seaweedfs/blob/c42b95c596f762dcca2bc9c7e7a918ab8ca8b206/weed/server/filer_ui/templates.go#L185",source-file
1064,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1064,seaweed s3 list_buckets,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** I'm using s3 gateway and python boto3 and while trying to list all buckets I'm getting the error:   kwrgs = {'endpoint_url': 'http://seaweedfs-s3.default.svc.cluster.local:8333', 'aws_access_key_id': 'accessKey1', 'aws_secret_access_key': 'secretKey1'}  import boto3  cli = boto3.client('s3', **kwrgs)  cli.list_buckets() Traceback (most recent call last): File ""<stdin>"", line 1, in <module> File ""/usr/local/lib/python3.7/site-packages/botocore/client.py"", line 357, in _api_call return self._make_api_call(operation_name, kwargs) File ""/usr/local/lib/python3.7/site-packages/botocore/client.py"", line 661, in _make_api_call raise error_class(parsed_response, operation_name) botocore.exceptions.ClientError: An error occurred (InternalError) when calling the ListBuckets operation (reached max retries: 4): We encountered an internal error, please try again.  I Found only Errors in the s3 gateway:  I0916 09:49:36 1 config.go:25] Reading security.toml from I0916 09:49:36 1 config.go:28] Reading : Config File ""security"" Not Found in ""[/ /root/.seaweedfs /etc/seaweedfs]"" I0916 09:49:36 1 s3.go:92] Start Seaweed S3 API Server 30GB 1.43 at http port 8333 I0916 09:50:58 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:51:18 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627478252701334</RequestId></Error> I0916 09:51:19 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:51:39 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627499203098406</RequestId></Error> I0916 09:51:40 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:00 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627520693419381</RequestId></Error> I0916 09:52:02 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:22 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627542703114894</RequestId></Error> I0916 09:52:30 1 filer_util.go:89] read directory: directory:""/buckets"" limit:2147483647 I0916 09:52:50 1 s3api_handlers.go:78] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/</Resource><RequestId>1568627570429772055</RequestId></Error  FYI : The weed shell can return the colletion.list and fs.tree without any issue The s3cmd can't list buckets too put file is working: cli.put_object(Bucket='test', Key='test', Body='test'). output:  {'ResponseMetadata': {'RequestId': '1568620869872887033', 'HostId': '', 'HTTPStatusCode': 200, 'HTTPHeaders': {'accept-ranges': 'bytes', 'etag': '""098f6bcd4621d373cade4e832627b4f6""', 'x-amz-request-id': '1568620869872887033', 'date': 'Mon, 16 Sep 2019 08:01:09 GMT', 'content-length': '0'}, 'RetryAttempts': 0}, 'ETag': '""098f6bcd4621d373cade4e832627b4f6""'}  **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"":  /usr/bin/weed -v=4 s3 -port=8333 -filer.dir.buckets=/buckets -filer=seaweedfs-filer.default:8888 /usr/bin/weed -v=4 master -port=9333 -mdir=/data -ip.bind=0.0.0.0 -volumeSizeLimitMB=30000 -defaultReplication=000 -ip=seaweedfs-master-0.seaweedfs-master -peers=seaweedfs-master-0.seaweedfs-master:9333 /usr/bin/weed -v=4 volume -port=8080 -dir=/data -max=1000 -ip.bind=0.0.0.0 -read.redirect=true -ip=10.244.83.158 -mserver=seaweedfs-master-0.seaweedfs-master:9333 /usr/bin/weed -v=4 filer -port=8888 -dirListLimit=100000 -ip=10.244.83.155 -master=seaweedfs-master-0.seaweedfs-master:9333  - OS version: Ubuntu 18.04.2 LTS - output of `weed version`: version 30GB 1.43 linux amd64 - if using filer, show the content of `filer.toml`  # A sample TOML config file for SeaweedFS filer store # Used with ""weed filer"" or ""weed server -filer"" [memory] # local in memory, mostly for testing purpose enabled = false [leveldb] # local on disk, mostly for simple single-machine setup, fairly scalable enabled = false dir = ""/data"" # directory to store level db files [leveldb2] # local on disk, mostly for simple single-machine setup, fairly scalable enabled = true dir = ""/data/filerldb2"" # directory to store level db 2 files  # multiple filers on shared storage, fairly scalable  [mysql] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT COMMENT 'first 64 bits of MD5 hash value of directory field', # name VARCHAR(1000) COMMENT 'directory or file name', # directory TEXT COMMENT 'full path to parent directory', # meta BLOB, # PRIMARY KEY (dirhash, name) # ) DEFAULT CHARSET=utf8; enabled = false hostname = ""localhost"" port = 3306 username = ""root"" password = """" database = """" # create or use an existing database connection_max_idle = 2 connection_max_open = 100 [postgres] # CREATE TABLE IF NOT EXISTS filemeta ( # dirhash BIGINT, # name VARCHAR(65535), # directory VARCHAR(65535), # meta bytea, # PRIMARY KEY (dirhash, name) # ); enabled = false hostname = ""localhost"" port = 5432 username = ""postgres"" password = """" database = """" # create or use an existing database sslmode = ""disable"" connection_max_idle = 100 connection_max_open = 100 [cassandra] # CREATE TABLE filemeta ( # directory varchar, # name varchar, # meta blob, # PRIMARY KEY (directory, name) # ) WITH CLUSTERING ORDER BY (name ASC); enabled = false keyspace=""seaweedfs"" hosts=[ ""localhost:9042"", ] [redis] enabled = false address = ""localhost:6379"" password = """" db = 0 [redis_cluster] enabled = false addresses = [ ""localhost:30001"", ""localhost:30002"", ""localhost:30003"", ""localhost:30004"", ""localhost:30005"", ""localhost:30006"", ]  **Expected behavior** List all buckets when has only 1 bucket using python boto3",source-file
1838,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1838,[s3] http: superfluous response.WriteHeader,"**Describe the bug** [s3] http: superfluous response.WriteHeader after `raft.Server: Not current leader` per request  I0225 09:43:38 1 masterclient.go:120] filer masterClient failed to receive from fast-master-0.s3-fast-master-direct.service.dcix.consul:9333: rpc error: code = Unavailable desc = transport is closing 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283) E0225 09:43:38 1 filer_server_handlers_write.go:42] failing to assign a file id: failed to parse master : server should have hostname:port format: I0225 09:43:38 1 common.go:53] response method:PUT URL:/buckets/registry/docker/registry/v2/repositories/b2c/credits-admin/_uploads/71e12cb4-5c6e-405e-a6ca-1d491ec79441/hashstates/sha256/15728640 with httpStatus:500 and JSON:{""error"":""failed to parse master : server should have hostname:port format: ""} E0225 09:43:38 1 s3api_object_handlers.go:330] upload to filer error: failed to parse master : server should have hostname:port format: 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283) 2021/02/25 09:43:38 http: superfluous response.WriteHeader call from github.com/chrislusf/seaweedfs/weed/server.processRangeRequest (common.go:283)  https://github.com/chrislusf/seaweedfs/blob/master/weed/server/common.go#L284 **Expected behavior** automatic recovery after loss of master If there is no content, the S3 API returns 200 and 206 codes, need return 500",config-file | source-file
1724,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1724,One of the two volume servers that contain data returns error: invalid character '\x1f' and MIME type error,"Hi, I have 3 volume servers and 1 master node, I've created a collection name ""Animated_2tacopy_count"" with count=1 and replication=001 I upload my file with following command:  sweed@dev10:~$./weedfs/weed upload -collection=Animated_2tacopy_count=1 -dir=""/home/sweed/animate.mp4 [{""fileName"":""animate.mp4"",""fileUrl"":""192.168.200.23:8081/22,1d9ff15aa7"",""fid"":""22,1d9ff15aa7"",""size"":178481324}]  when I'm asking Master for my file, it return volume servers randomly:  sweed@dev10:~$ curl -I 192.168.200.20:9333/22,24dbfea5ed HTTP/1.1 308 Permanent Redirect Content-Type: text/html; charset=utf-8 Location: http://192.168.200.21:8081/22,24dbfea5ed Date: Thu, 31 Dec 2020 15:06:08 GMT sweed@dev10:~$ curl -I 192.168.200.20:9333/22,24dbfea5ed HTTP/1.1 308 Permanent Redirect Content-Type: text/html; charset=utf-8 Location: http://192.168.200.22:8081/22,24dbfea5ed Date: Thu, 31 Dec 2020 15:06:09 GMT  But in browser I can't see my file from volume serevr 192.168.200.21 but In another volume server ""192.168.200.22"" everything is ok, actully when browser returns the ip address of 200.22 I can see my file but when it return 200.21 I have mime type error: ![image](https://user-images.githubusercontent.com/43205944/103415573-0111fb80-4b98-11eb-9c53-568dab440166.png) And in journalctl of server 200.21 I have this error:  Dec 31 18:23:50 dev11 seaweedfs-volume[20791]: I1231 18:23:50 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:30 dev11 seaweedfs-volume[20791]: I1231 18:25:30 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:37 dev11 seaweedfs-volume[20791]: I1231 18:25:37 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:25:48 dev11 seaweedfs-volume[20791]: I1231 18:25:48 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:29 dev11 seaweedfs-volume[20791]: I1231 18:26:29 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:40 dev11 seaweedfs-volume[20791]: I1231 18:26:40 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:42 dev11 seaweedfs-volume[20791]: I1231 18:26:42 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:26:43 dev11 seaweedfs-volume[20791]: I1231 18:26:43 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value Dec 31 18:27:03 dev11 seaweedfs-volume[20791]: I1231 18:27:03 20791 volume_server_handlers_read.go:187] load chunked manifest (/22,24dbfea5ed) error: invalid character '\x1f' looking for beginning of value",source-file
5155,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5155,s3api v3.60: Missing VersionConfiguration node in get-bucket-versioning response,"Feature introduced in: https://github.com/seaweedfs/seaweedfs/pull/4998 **Describe the bug** When using aws-cli get-bucket-versioning will return no results; this is due to the malformed response. When running with debug, we can see that the response body is missing the VersionConfiguration node.  aws --endpoint-url http://localhost:8333 s3api get-bucket-versioning --bucket mybucket --debug  2024-01-03 01:11:43,611 - MainThread - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:8333 2024-01-03 01:11:43,618 - MainThread - urllib3.connectionpool - DEBUG - http://localhost:8333 ""GET /mybucket?versioning HTTP/1.1"" 200 26 2024-01-03 01:11:43,619 - MainThread - botocore.parsers - DEBUG - Response headers: {'Accept-Ranges': 'bytes', 'Content-Length': '26', 'Content-Type': 'application/xml', 'Server': 'SeaweedFS S3', 'X-Amz-Request-Id': '1704244303617654225' , 'Date': 'Wed, 03 Jan 2024 01:11:43 GMT'} 2024-01-03 01:11:43,619 - MainThread - botocore.parsers - DEBUG - Response body: b'<Status>Suspended</Status>'   **System Setup** - running seaweedfs:3.60_large_disk container image - command: weed server -s3 -iam - `# weed version: version 8000GB 3.60 d4e91b6ad linux amd64` **Expected behavior** Default response **""Status"":""Suspended""**:  aws --endpoint-url http://localhost:8333 s3api get-bucket-versioning --bucket mybucket { ""Status"": ""Suspended"" }",source-file
2593,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2593,"When ""X-Amz-Copy-Source"" a folder, weed create a new file with ""Filer listing Html"" result.","The response of ""CopyObject"" should be 40x.",source-file
814,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/814,Seaweedfs client core dump when calling DeleteFiles,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** When seaweedfs client calls DeleteFiles (e.g. fileId=123,xxx, volume 123 not exist), it ALWAYS crashes. **Screenshots** goroutine 89 [running]: github.com/chrislusf/seaweedfs/weed/operation.DeleteFilesWithLookupVolumeId(0xc42061d578, 0x1, 0x1, 0xc4206a4160, 0x20, 0x20, 0xc4206a4140, 0x7fbfd979d1e0, 0x0) github.com/chrislusf/seaweedfs/weed/operation/delete_content.go:74 +0xce9 github.com/chrislusf/seaweedfs/weed/operation.DeleteFiles(0xc420286090, 0xe, 0xc42061d578, 0x1, 0x1, 0xc42061d538, 0x4126c8, 0x20, 0x9b9ca0, 0x725201) github.com/chrislusf/seaweedfs/weed/operation/delete_content.go:36 +0x8a",source-file
2177,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2177,Volume on ARMv7 throws,"**Describe the bug** Volume on ARM32 throws an ""unaligned 64-bit atomic operation"" error on upload of a file **System Setup** - /usr/bin/weed volume -ip=odroid3.node.dc1.consul -port=9444 -mserver=seaweedfsmaster0.service.dc1.consul:9333,seaweedfsmaster1.service.dc1.consul:9333,seaweedfsmaster2.service.dc1.consul:9333 -dir=/data/vol - OS version = Ubuntu 5.4.118-221 armv7l armv7l armv7l GNU/Linux - `weed version' = version 30GB 2.56 a2979aa linux arm - hardware = Odroid HC1 (Samsung Exynos5422 Cortex-A15 2Ghz and Cortex-A7 Octa cores) **Expected behavior** Not to crash **Additional context** 2021/07/02 15:46:52 http: panic serving 192.168.1.238:40226: unaligned 64-bit atomic operation goroutine 101 [running]: net/http.(*conn).serve.func1(0x32244e0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:1824 +0x104 panic(0x171c1b8, 0x1e1dca8) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/panic.go:971 +0x4b4 runtime/internal/atomic.panicUnaligned() /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/internal/atomic/unaligned.go:8 +0x24 runtime/internal/atomic.Load64(0x31473e4, 0xe5b38, 0x0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/runtime/internal/atomic/asm_arm.s:263 +0x14 github.com/chrislusf/seaweedfs/weed/server.(*VolumeServer).privateStoreHandler(0x3147380, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/gopath/src/github.com/chrislusf/seaweedfs/weed/server/volume_server_handlers.go:49 +0x4bc net/http.HandlerFunc.ServeHTTP(0x300fa88, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2069 +0x34 net/http.(*ServeMux).ServeHTTP(0x325b440, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2448 +0x16c net/http.serverHandler.ServeHTTP(0x30ec360, 0x1e56c4c, 0x34581e0, 0x30de680) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:2887 +0x88 net/http.(*conn).serve(0x32244e0, 0x1e59564, 0x31c09c0) /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:1952 +0x7f0 created by net/http.(*Server).Serve /home/travis/.gimme/versions/go1.16.5.linux.amd64/src/net/http/server.go:3013 +0x318",source-file
1808,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1808,Jwt issue - wrong jwt,"**Describe the bug** Getting wrong jwt code from master.  C:\Users\lennie>curl -i ""http://172.16.100.1:9351/dir/lookup?volumeId=1,18ee7f3466&read=yes"" HTTP/1.1 200 OK Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTI0NDN9.AxGUN17e_RZ5g4tSZLFWfzqnIuYQqxDCMBPTxvnFpdk Content-Type: application/json Date: Tue, 16 Feb 2021 21:52:03 GMT Content-Length: 90 {""volumeId"":""1"",""locations"":[{""url"":""172.16.100.1:9831"",""publicUrl"":""172.16.100.1:9831""}]}  And then volume query.  C:\Users\lennie>curl -i ""http://172.16.100.1:9831/1,18ee7f3466"" -H ""Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTI0NDN9.AxGUN17e_RZ5g4tSZLFWfzqnIuYQqxDCMBPTxvnFpdk"" HTTP/1.1 401 Unauthorized Content-Type: application/json Server: SeaweedFS Volume 30GB 2.26 Date: Tue, 16 Feb 2021 21:52:27 GMT Content-Length: 21 {""error"":""wrong jwt""}  I Have read issue https://github.com/chrislusf/seaweedfs/issues/1399 But i only have one server and the time is correct on the system. When i do some request to the master to get the jwt token i can se this.  curl -i ""http://172.16.100.1:9351/dir/lookup?volumeId=1,18ee7f3466&read=yes""  Jwt response.  Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MTN9.VfbCVHEhBMHMxWZrTpzOTYSU8DqWtKGs5_vaopdLiwY Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MTd9.9yPL3dNuW3J4p68KARMWIAp_XlqDYkAN-NHHnYUrY4Q Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MjB9.crUaZYFBCEDu57dOKAE-rJPw5nS-fpJP11Oz6Bv0Pok Authorization: BEARER eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmaWQiOiIiLCJleHAiOjE2MTM1MTM2MjF9.mRJQ0WtXu5JNfPAKIGiJP0CGrodiM_i8tOws9H7PRdA  There should not be underscore or dash in the base64 encoded values? So the question is. Why do I get underscores? I am running: OS: Ubuntu 18.04.4 LTS And weed version : version 30GB 2.26 b9b5b932 linux amd64 The Master is starting whit this command.  weed master -mdir=""/home/raid6/seaweed/mastershare"" -ip=""172.16.100.1"" -ip.bind=""172.16.100.1"" -port=9351  Log  I0216 22:42:56 19422 file_util.go:23] Folder /home/raid6/seaweed/mastershare Permission: -rwxr-xr-x I0216 22:42:56 19422 master.go:168] current: 172.16.100.1:9351 peers: I0216 22:42:56 19422 master_server.go:107] Volume Size Limit is 30000 MB I0216 22:42:56 19422 master_server.go:192] adminScripts: I0216 22:42:56 19422 master.go:122] Start Seaweed Master 30GB 2.26 b9b5b932 at 172.16.100.1:9351 I0216 22:42:56 19422 raft_server.go:70] Starting RaftServer with 172.16.100.1:9351 I0216 22:42:56 19422 raft_server.go:129] current cluster leader: I0216 22:42:56 19422 master.go:146] Start Seaweed Master 30GB 2.26 b9b5b932 grpc server at 172.16.100.1:19351 I0216 22:42:57 19422 masterclient.go:78] No existing leader found! I0216 22:42:57 19422 raft_server.go:154] Initializing new cluster I0216 22:42:57 19422 master_server.go:141] leader change event: => 172.16.100.1:9351 I0216 22:42:57 19422 master_server.go:143] [ 172.16.100.1:9351 ] 172.16.100.1:9351 becomes leader. I0216 22:43:00 19422 master_grpc_server.go:252] + client filer@172.16.100.1:8888 I0216 22:43:01 19422 masterclient.go:126] redirected to leader 172.16.100.1:9351 I0216 22:43:01 19422 master_grpc_server.go:252] + client master@172.16.100.1:37496 I0216 22:43:04 19422 node.go:322] topo adds child soder I0216 22:43:04 19422 node.go:322] topo:soder adds child r1u1 I0216 22:43:04 19422 node.go:322] topo:soder:r1u1 adds child 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:71] added volume server 172.16.100.1:9831 I0216 22:43:04 19422 volume_layout.go:354] Volume 13 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 10 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 8 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 7 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 6 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 3 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 1 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 11 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 2 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 12 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 5 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 4 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 9 becomes writable I0216 22:43:04 19422 volume_layout.go:354] Volume 14 becomes writable I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 13 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 10 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 8 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 7 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 6 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 3 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 1 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 11 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 2 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 12 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 5 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 4 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 9 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:112] master see new volume 14 from 172.16.100.1:9831 I0216 22:43:04 19422 master_grpc_server.go:157] master send to filer@172.16.100.1:8888: url:""172.16.100.1:9831"" public_url:""172.16.100.1:9831"" new_vids:13 new_vids:10 new_vids:8 new_vids:7 new_vids:6 new_vids:3 new_vids:1 new_vids:11 new_vids:2 new_vids:12 new_vids:5 new_vids:4 new_vids:9 new_vids:14 data_center:""soder"" I0216 22:43:04 19422 master_grpc_server.go:157] master send to master@172.16.100.1:37496: url:""172.16.100.1:9831"" public_url:""172.16.100.1:9831"" new_vids:13 new_vids:10 new_vids:8 new_vids:7 new_vids:6 new_vids:3 new_vids:1 new_vids:11 new_vids:2 new_vids:12 new_vids:5 new_vids:4 new_vids:9 new_vids:14 data_center:""soder""  The volume is starting whit this command.  root@spinky:/home/raid6/seaweed# weed volume -max=100 -ip=""172.16.100.1"" -ip.bind=""172.16.100.1"" -port=9831 -mserver=""172.16.100.1:9351"" -dir=""/home/raid6/seaweed/voltesting"" -dataCenter=""soder"" -rack=""r1u1""  Log  I0216 22:25:09 9983 file_util.go:23] Folder /home/raid6/seaweed/voltesting Permission: -rwxr-xr-x I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/2.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_12.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/5.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/3.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/1.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/7.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/6.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/4.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/2.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/3.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_10.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/7.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_12.dat, replicaPlacement=000 v=3 size=1864 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_13.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_11.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_8.idx to memory I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_14.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/4.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 volume_loading.go:127] loading index /home/raid6/seaweed/voltesting/filestorage_9.idx to memory I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/1.dat, replicaPlacement=000 v=3 size=112 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/5.dat, replicaPlacement=000 v=3 size=104 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/6.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_10.dat, replicaPlacement=000 v=3 size=7900832 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_13.dat, replicaPlacement=000 v=3 size=720 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_9.dat, replicaPlacement=000 v=3 size=8 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_11.dat, replicaPlacement=000 v=3 size=664 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_8.dat, replicaPlacement=000 v=3 size=1600 ttl= I0216 22:25:09 9983 disk_location.go:133] data file /home/raid6/seaweed/voltesting/filestorage_14.dat, replicaPlacement=000 v=3 size=30789912 ttl= I0216 22:25:09 9983 disk_location.go:175] Store started on dir: /home/raid6/seaweed/voltesting with 14 volumes max 100 I0216 22:25:09 9983 disk_location.go:178] Store started on dir: /home/raid6/seaweed/voltesting with 0 ec shards I0216 22:25:09 9983 volume_grpc_client_to_master.go:52] Volume server start with seed master nodes: [172.16.100.1:9351] I0216 22:25:09 9983 volume.go:351] Start Seaweed volume server 30GB 2.26 b9b5b932 at 172.16.100.1:9831 I0216 22:25:09 9983 volume_grpc_client_to_master.go:114] Heartbeat to: 172.16.100.1:9351  This is the Log in volume when wrong jwt  I0216 22:27:26 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:27:27 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:28:32 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""} I0216 22:28:34 9983 common.go:53] response method:GET URL:/1,18ee7f3466 with httpStatus:401 and JSON:{""error"":""wrong jwt""}  Security.toml file syntax:  # Put this file to one of the location, with descending priority # ./security.toml # $HOME/.seaweedfs/security.toml # /etc/seaweedfs/security.toml # this file is read by master, volume server, and filer # the jwt signing key is read by master and volume server. # a jwt defaults to expire after 10 seconds. [jwt.signing] key = ""NotShownToThePublic"" expires_after_seconds = 120 # seconds 10 default # jwt for read is only supported with master+volume setup. Filer does not support this mode. [jwt.signing.read] key = ""NotShownToThePublic"" expires_after_seconds = 120 # seconds # volume server also uses grpc that should be secured. # all grpc tls authentications are mutual # the values for the following ca, cert, and key are paths to the PERM files. # the host name is not checked, so the PERM files can be shared. [grpc] ca = ""/home/certstrap/certstrap/out/smtCertAuth.crt"" [grpc.volume] cert = ""/home/certstrap/certstrap/out/volume01.crt"" key = ""/home/certstrap/certstrap/out/volume01.key"" [grpc.master] cert = ""/home/certstrap/certstrap/out/master01.crt"" key = ""/home/certstrap/certstrap/out/master01.key"" [grpc.filer] cert = ""/home/certstrap/certstrap/out/filer01.crt"" key = ""/home/certstrap/certstrap/out/filer01.key"" # use this for any place needs a grpc client # i.e., ""weed backup|benchmark|filer.copy|filer.replicate|mount|s3|upload"" [grpc.client] cert = ""/home/certstrap/certstrap/out/client01.crt"" key = ""/home/certstrap/certstrap/out/client01.key""  If I turn of the security (jwt). The server is working perfect. I can save, show, delete object",source-file
2039,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2039,Unexpected response to s3 GET call on non-existent bucket,"**Describe the bug** Running a ""GET /nonexistent-bucket?acl"" - which is what a number of libraries use for ""does this bucket exist"" call, returns a ListBucketResult. According to S3 api docs, it should return a 'AccessControlPolicy' or at least a 404 for the nonexistent resource. **System Setup** docker run -p 8333:8333 chrislusf/seaweedfs server -s3  nneul@optic:~ $ curl http://localhost:8333/nonexistent-bucket?acl <?xml version=""1.0"" encoding=""UTF-8""?> <ListBucketResult xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""><Name>nonexistent-bucket</Name><Prefix></Prefix><Marker></Marker><MaxKeys>10000</MaxKeys><IsTruncated>false</IsTruncated></ListBucketResult>  **Expected behavior** AccessControlPolicy in response - even if it's a dummy/empty policy document, or a 404 or other error indicating it couldn't handle the request due to the bucket not being there.",source-file
82,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/82,get content type error,"hi, I use weed-fs 1 years ago. It is an old version [0.45] of weed. I post an image to weedfs, then I get it from browser , It will display correctly. curl -F file=@/home/chris/myphoto.jpg http://localhost:9333/submit when I use 0.67 of weed. I do the same post, But the same images cannot display in the browser correctly. It cannot display then do download in the chrome. what is wrong about the weed version up? How can I config to this get header output ? please help me.",documentation-file | config-file | test-file | ui-file | data-file | source-file | container-file
214,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/214,seaweedfs should check WhiteList before proxyToLeader,"` r.HandleFunc(""/"", ms.uiStatusHandler) r.HandleFunc(""/ui/index.html"", ms.uiStatusHandler) r.HandleFunc(""/dir/assign"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirAssignHandler r.HandleFunc(""/dir/lookup"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirLookupHandler r.HandleFunc(""/dir/join"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirJoinHandler r.HandleFunc(""/dir/status"", ms.proxyToLeader(ms.guard.WhiteList(ms.dirStatusHandler r.HandleFunc(""/col/delete"", ms.proxyToLeader(ms.guard.WhiteList(ms.collectionDeleteHandler r.HandleFunc(""/vol/lookup"", ms.proxyToLeader(ms.guard.WhiteList(ms.volumeLookupHandler ` If a request not in whitelist is sent to a non-leader master, this request will be handled by leader, which is unexpected.",source-file
4143,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4143,The bucket naming rules conflict when docking with minio,"When uploading buckets through java minio, minio prompts me that the buckets to be transferred do not conform to the naming rules of S3 buckets My bucket name is 10000_ test However, it cannot be used in the S3 naming specification_ To name it. aws-cli passed the name, but the seaweedfs server did not verify the bucket name So I suggest checking the incoming bucket name on the seeweedfs server to ensure that the system has stronger compatibility",source-file
26,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/26,File id assign with collection does not work,"File id assign with collection does not work on master server curl http://master:9333/dir/assign?collection=pictures returns {""fid"":""22,0139804a34"",""url"":""127.0.0.1:8080"",""publicUrl"":""172.17.42.1:8080"",""count"":1} But volume id 22 is not collection named volume id such as 22.dat 22.idx No new collection is created with above command. weed version is 0.65 linux amd64 Thanks in advance",documentation-file | config-file | test-file | data-file | source-file
861,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/861,TTL marshal result is empty influencing /vol/status api result,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** because TTL's members are invisible out of package, so when json.Marshal is called, all the TTL info are empty, which influences the /vol/status api golang type TTL struct { count byte unit byte }",source-file
913,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/913,allocating all available volumes fails,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** I tried to allocate all available volumes (which was 6,400 volumes) and it allocated all but 42 of the volumes and then threw an error (then I was able to allocate the last 42 volumes successfully)  $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Failed to assign 6625: rpc error: code = Unknown desc = No more free space left""} $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Only 42 volumes left! Not enough for 6400""} $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=42"" {""count"":42}  (sorry, didn't get screen shots) after deleting all volumes and running again, I got got a different error and strangely I see 6,400 volumes allocated but it says 397 volumes free (which should be 0 volumes free)  $ curl ""http://seaweed-master:9333/vol/grow?collection=test&count=6400"" {""error"":""Failed to assign 6669: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = \""transport: Error while dialing dial tcp 192.168.X.XXX:18080: connect: connection refused\""""}  and strangely it say 397 volumes are free ![image](https://user-images.githubusercontent.com/4112046/55459751-1b730b80-55a5-11e9-9bd8-7121623f067b.png) even though the volume servers show a total of 6400 volumes ![image](https://user-images.githubusercontent.com/4112046/55459802-3c3b6100-55a5-11e9-9249-359442fc9d19.png) **System Setup** `master` `filer` and `s3` on one machine and `volume` on 4 separate machines **Expected behavior** allocating all available volumes should succeed and counts should make sense **Screenshots** n/a **Additional context** n/a",source-file
1161,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1161,How do I create an empty directory?,"This is what I tried: curl -X PUT ""http://localhost:8888/test/"" => {""error"":""can not to write to folder /test/ without a file name""} curl -X POST ""http://localhost:8888/test/"" => {""error"":""request Content-Type isn't multipart/form-data""} curl -X PUT ""http://localhost:8888/test"" => creates a 0 byte file curl -X POST ""http://localhost:8888/test"" => {""error"":""request Content-Type isn't multipart/form-data""}",source-file
543,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/543,benchmark report 404 on /dir/assign,"Hi, I need some help here. I set up a seaweadfs cluster, which works fine. Passed all my reads/writes tests. But when I run ./weed benchmark command, it reports 100% 404 Not Found on /dir/assign request: ./weed benchmark -server=127.0.0.1:9333 -n=100  Writing Benchmark  writing file error: http://127.0.0.1:9333/dir/assign: 404 Not Found writing file error: http://127.0.0.1:9333/dir/assign: 404 Not Found 98 more of this I tested http://127.0.0.1:9333/dir/assign with both curl and browser, it works well: curl http://127.0.0.1:9333/dir/assign {""fid"":""9,07a4983afa"",""url"":""someurl:8080"",""publicUrl"":""someurl:18080"",""count"":1} I use version 0.76, linux_arm64.tar.gz my machine runs on Centos7, kernel 4.4.36-1.el7.elrepo.x86_64 thanks in advance",source-file
5213,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5213,Master timeouts during dirAssign volume growth,"**Describe the bug** Timeouts when requesting a /dir/assign at the master(s). **System Setup** - master(s) 3 of them, but I get the same issues when I only start one: - `/usr/local/bin/weed -v=3 -logdir=/var/log/seaweedfs master -mdir=/etc/seaweedfs -ip=10.0.9.15 -port=9333 -metrics.address=10.0.9.17:9091 -defaultReplication=010 -volumePreallocate -garbageThreshold=0.3 -volumeSizeLimitMB=20000 -peers=10.0.9.17:9333,10.0.9.14:9333,10.0.9.15:9333` - volume(s) 7 of them, I use different IP's, racks, and volumes. - `/usr/local/bin/weed -v=3 -logdir=/var/log/seaweedfs volume -index=leveldb -mserver=10.0.9.17:9333,10.0.9.14:9333,10.0.9.15:9333 -dir=/volumes/98fb3388c280,/volumes/LHHGS,/volumes/e000c055cbe4,/volumes/c5a9aff45527,/volumes/619c9a0827f4,/volumes/f8c44345756f,/volumes/eeedca023938,/volumes/cae089cd2dd9,/volumes/20F30GRVRD,/volumes/KWEGS,/volumes/3d5638f4fd34,/volumes/18f39b04390d,/volumes/6a9e8c97ba2a,/volumes/LDTGS,/volumes/a9a6e2d048de,/volumes/20F308T27D,/volumes/19641ea6d6c5,/volumes/20F30JB3JE,/volumes/6e19dd8da77b,/volumes/3d1614841bcc,/volumes/372cb7e5ac18,/volumes/152d865d39ce,/volumes/20F305249D,/volumes/1289675b7f03,/volumes/222079443d03,/volumes/cc66d284719d,/volumes/ca6f98cd3c16,/volumes/6611045c7cf2,/volumes/381ee044d930,/volumes/ff81968af32c,/volumes/9d611128cfed,/volumes/21F306AD4F,/volumes/595892cb8709,/volumes/0553ccb52b90 -max=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 -concurrentDownloadLimitMB=20000 -concurrentUploadLimitMB=20000 -hasSlowRead=true -readBufferSizeMB=8 -compactionMBps=10 -rack=store02 -ip=10.0.9.2` - - OS version - `Debian GNU/Linux 12 (bookworm) / Linux store02 6.1.0-17-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.69-1 (2023-12-30) x86_64 GNU/Linux` - output of `weed version` - version `30GB 3.62 59b8af99b0aca1b9e88fec7b5f27c7d15e5e8604 linux amd64` - no filer only masters & volume servers, we have an own metadata store. **Expected behavior** When we assign/request multiple keys or a single key at the Leader master, we don't expect timeouts. Normally we get an instant response. But sometimes (every x minutes) we get a timeout on the a request like: http://10.0.9.17:9333/dir/assign?collection=nntp&count=10000&replication=001. Also when we lower the count. We sadly don't get an error at this request, but I noticed when this happens I see the following log entry: ` seaweedfs-master[459769]: I0116 14:50:10.468052 master_server_handlers.go:125 dirAssign volume growth {""collection"":""nntp"",""replication"":{""node"":1},""ttl"":{""Count"":0,""Unit"":0}} from 10.0.9.12:40308` It looks that this always happens when there is a dirAssign volume growth. In parallel there are constantly POST requests directly to the volume servers to store data. I thought a work-around was to use replication 010 or 002, but working only for a while. We just started testing SeaweedFS and started with 3.60, but also after the upgrades to 3.62 we still see this issue. ( I didn't tested older versions ) **Additional context** How I test/reproduce it: `while true; do curl --max-time 3 'http://localhost:9333/dir/assign?collection=nntp&replication=001'; echo """" ; done` I get once in a couple of seconds/minutes a timeout (also when I increase the max-time): `curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received` at that moment I see always a volume growth message in the logging: `seaweedfs-master[459769]: I0116 14:50:10.468052 master_server_handlers.go:125 dirAssign volume growth {""collection"":""nntp"",""replication"":{""node"":1},""ttl"":{""Count"":0,""Unit"":0}} from 10.0.9.12:40308` **Screen shot** ![b13912075ec83a54736ed1da4a98b5fcbe](https://github.com/seaweedfs/seaweedfs/assets/11386125/f6dec3c3-c6ae-40cf-a018-3e27fb7f4760) <img width=""1770"" alt=""Screenshot 2024-01-17 at 23 09 24"" src=""https://github.com/seaweedfs/seaweedfs/assets/11386125/e142a531-b314-442e-938e-c49925f41007"">",source-file
2065,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2065,docker-registry with seaweedfs weed mount has error,"**Describe the bug** docker-registry with seaweedfs weed mount, push image error **System Setup** - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"".  # setup master weed master -port=9333 -mdir=/tmp/master0 -defaultReplication=000 -ip=localhost # setup volume weed volume -port=8080 -dir=/tmp/volume0 -ip=localhost -mserver=localhost:9333 # setup filer weed filer -port=8888 -ip=localhost -master=localhost:9333 #weed mount weed mount -filer=localhost:8888 -cacheCapacityMB=0 -cacheDir=/tmp/cache001 -dir=/root/mnt #setup docker-registry docker run -p 5001:5000 --rm \ --name registry2 \ -v /root/config.yml:/etc/docker/registry/config.yml -v /root/mnt/data:/data registry:2 #push image root@qa-4:~# docker push 10.10.10.224:5001/ubuntu:16.04 The push refers to repository [10.10.10.224:5001/ubuntu] 1a1a19626b20: Pushing [>] 3.072kB 5b7dc8292d9b: Pushing 11.78kB bbc674332e2e: Pushing [>] 15.87kB da2785b7bb16: Pushing [> ] 525.3kB/130.7MB unknown blob  - OS version `Ubuntu 18.04.4 LTS` - output of `weed version` `version 30GB 2.41 8618526 linux amd64` - if using filer, show the content of `filer.toml` default /root/config.yaml(without cache)  version: 0.1 log: fields: service: registry storage: # cache: # blobdescriptor: inmemory filesystem: rootdirectory: /data http: addr: :5000 headers: X-Content-Type-Options: [nosniff] health: storagedriver: enabled: true interval: 10s threshold: 3  **Expected behavior** push & pull image successfully **Screenshots** ![image](https://user-images.githubusercontent.com/28077875/117948127-6abec500-b343-11eb-8a4e-c6a2e81281c0.png) **Additional context** mastervolumefiler and weed mount had no related warning and error log. if use local filesystem, everything is fine. if `/root/configy.yaml` enable cache:  version: 0.1 log: fields: service: registry storage: cache: blobdescriptor: inmemory filesystem: rootdirectory: /data http: addr: :5000 headers: X-Content-Type-Options: [nosniff] health: storagedriver: enabled: true interval: 10s threshold: 3  then, push image can be successful, but pull image will error(some small images pull many times will eventually succeedbut large images will not): **pull big images**: btw, the test image can be pulled down from dockerhub(`docker pull jupyter/tensorflow-notebook:ubuntu-20.04`) ![image](https://user-images.githubusercontent.com/28077875/117952978-444f5880-b348-11eb-92f2-09cca527e42e.png) ![image](https://user-images.githubusercontent.com/28077875/117953890-0f8fd100-b349-11eb-846c-be53c01e471a.png) At this time, if stop registry and restart it, then pull image is ok. restart registry use same command:  docker run -p 5001:5000 --rm \ --name registry2 \ -v /root/config.yml:/etc/docker/registry/config.yml -v /root/mnt/data:/data registry:2  **pull small image**(pull many times, eventually succeed): ![image](https://user-images.githubusercontent.com/28077875/117951873-2c2b0980-b347-11eb-98f7-26cb4a7d8508.png) BTW, `version 30GB 2.28 37f104f linux amd64` version does not seem to have the above problem.",source-file
2583,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2583,[s3] Bug with backward compatibility of accesses 2.85,"version  2.85   Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 auth_credentials.go:219] v4 auth type -- | -- | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 error_handler.go:85] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 auth_credentials.go:248] user name: cdn actions: [Admin:cdn-*], action: Write | Jan 12, 2022 @ 15:05:13.935 | I0112 10:05:13 1 error_handler.go:85] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> | Jan 12, 2022 @ 15:05:13.935 | <Error><Code>AccessDenied</Code><Message>Access Denied.</Message><Resource>/d28547ea7e450b9d42b86d2dd1dd89b02598dce2.original</Resource><RequestId>1641981913107869339</RequestId><Key>d28547ea7e450b9d42b86d2dd1dd89b02598dce2.original</Key><BucketName>cdn</BucketName></Error>",test-file | source-file
2389,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2389,"[s3test] PutObjectTagging, GetObjectTagging and DeleteObjectTagging","Nexus Blob Storage requires PutObjectTagging, GetObjectTagging and DeleteObjectTagging https://help.sonatype.com/repomanager3/repository-management/storage-guide/configuring-blob-stores#ConfiguringBlobStores-AWSSimpleStorageService(S3)  s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_put_obj_with_tags s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11449, in test_put_obj_with_tags s3tests_1 | eq(response_tagset, tagset) s3tests_1 | AssertionError: [{'Key': 'foo', 'Value': 'bar'}] != [{'Key': 'bar', 'Value': ''}, {'Key': 'foo', 'Value': 'bar'}] s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % ([{'Key': 'foo', 'Value': 'bar'}], [{'Key': 'bar', 'Value': ''}, {'Key': 'foo', 'Value': 'bar'}]))   s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_put_delete_tags s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11323, in test_put_delete_tags s3tests_1 | eq(response['ResponseMetadata']['HTTPStatusCode'], 200) s3tests_1 | AssertionError: 204 != 200 s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % (204, 200))   s3tests_1 |  s3tests_1 | FAIL: s3tests_boto3.functional.test_s3.test_get_obj_tagging s3tests_1 |  s3tests_1 | Traceback (most recent call last): s3tests_1 | File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest s3tests_1 | self.test(*self.arg) s3tests_1 | File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 11140, in test_get_obj_tagging s3tests_1 | eq(response['ResponseMetadata']['HTTPStatusCode'], 200) s3tests_1 | AssertionError: 204 != 200 s3tests_1 | >> raise AssertionError(None or ""%r != %r"" % (204, 200))   E1020 11:37:12 1 s3api_object_tagging_handlers.go:59] PutObjectTaggingHandler Unmarshal /package-cache-nexus-proxy-cache/nexus/cache/content/vol-31/chap-12/aecabacb-1999-47b8-80f7-1dad5b639ed0.bytes?tagging: expected element <Tagging> in name space http://s3.amazonaws.com/doc/2006-03-01/ but have no name space",source-file
4967,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4967,webdav bug creates directories in wrong folder,"**Describe the bug** When using `weed webdav -filer.path` for a non `/` path, folders get created on the `/` of the filer instance the `weed webdav` is connected to **System Setup** weed 3.58 on seaweedfs docker container, arguments used for webdav:  -logtostderr webdav -collection=arman -replication=010 -port=${NOMAD_PORT_webdav} -filer=seaweedfs-filer-http.nomad:8888.18888 -filer.path=/buckets/arman -cacheDir=/alloc/data/ -cacheCapacityMB=1024  on seaweedfs docker container, arguments used for filer:  -logtostderr filer -ip=${NOMAD_IP_http} -ip.bind=0.0.0.0 -master=seaweedfs-master-http.nomad:${var.master_port_http}.${var.master_port_grpc} -port=${NOMAD_PORT_http} -port.grpc=${NOMAD_PORT_grpc} -metricsPort=${NOMAD_PORT_metrics} -webdav -webdav.collection= -webdav.replication=020 -webdav.port=${NOMAD_PORT_webdav}  (so as you can see I am running a normal webdav instance with filer, and I am trying to set up a new one on a different container that points to a different path) **Expected behavior** When creating a folder in `weed webdav -filer.path=/buckets/arman` directory gets created under `/buckets/arman` in filer (for the example above). **Actual Behaviour** It gets created under the top-level `/` instead",source-file
4467,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4467,Master assigns write requests to unavailable volumes,"**Describe the bug** We performed reliability test for SeaweedFS in such a manner: - We wrote files through Filer in a loop - Sometimes we restarted one of Volume Servers (by random) to check how it will work, how many time will take recovery process depending on data size stored in SeaweedFS, how write process will work during partial outage (outage one of Volume Servers), etc. And during this simple test sometimes we observed such a problem: Filer reports that it cannot save the file with one of the following errors:  {""error"":""unmarshalled error http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612: failed to write to replicas for volume 16498: [seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444]: upload 489.part 4194304 bytes to http://seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612?ts=1683812487\u0026ttl=\u0026type=replicate: Post \""http://seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444/16498,4f3cc6ea382612?ts=1683812487\u0026ttl=\u0026type=replicate\"": dial tcp 10.183.0.39:8444: connect: connection refused""}  or  {""error"":""upload 486.part 4194304 bytes to http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/5122,1740bcaa7be3be: Post \""http://seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444/5122,1740bcaa7be3be\"": dial tcp 10.161.3.122:8444: connect: connection refused""}  So, on a first sight it looks quite obvious, we shutdown one of Volume Servers, and Filer cannot write to it (we see `connection refused`). The question is: **_why_** Master assigns volumes for write, if they should be unwritable? Deeper investigation into the issue showed that it could be some issue of synchronization between threads on Master's side. This is a piece of SeaweedFS Volume Server log which was shutdown:  I0511 13:40:18.303550 signal_handling.go:48 exec interrupt hook func name:github.com/seaweedfs/seaweedfs/weed/command.VolumeServerOptions.startVolumeServer.func1 I0511 13:40:18.303585 volume_server.go:139 Stopping volume server volume server has been killed I0511 13:40:18.303671 volume_grpc_client_to_master.go:258 volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 stops and deletes all volumes I0511 13:40:19.587873 volume.go:280 stop send heartbeat and wait 10 seconds until shutdown  I0511 13:40:19.587922 store.go:166 In dir /data0 adds volume:16498 collection:test replicaPlacement:001 ttl: I0511 13:40:19.587969 volume_info.go:20 maybeLoadVolumeInfo checks /data0/test_16498.vif I0511 13:40:19.588117 volume_loading.go:121 open to write file /data0/test_16498.idx I0511 13:40:19.588154 volume_loading.go:142 loading memory index /data0/test_16498.idx to memory I0511 13:40:19.588208 needle_map_memory.go:54 max file key: 0 for file: /data0/test_16498.idx I0511 13:40:19.588721 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.588734 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.588750 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:19.606846 common.go:106 error writing JSON status /status 200: write tcp 10.183.0.38:8444->10.183.0.1:46920: write: connection reset by peer I0511 13:40:19.606865 common.go:107 JSON content: map[DiskStatuses:[dir:""/data0"" all:98953909501952 used:9914417262592 free:89039492239360 percent_free:89.980774 percent_used:10.019227] <omitted> I0511 13:40:19.731598 disk_location.go:440 dir /data0 disk free 89.98% >= required 1.00% I0511 13:40:19.916394 store.go:170 add volume 16498 I0511 13:40:19.916412 volume_grpc_admin.go:60 assign volume volume_id:16498 collection:""test"" replication:""001"" I0511 13:40:20.074794 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.074812 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.074826 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798244 store_replicate.go:35 replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798261 common.go:113 error JSON response status 500: replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:20.798275 common.go:70 response method:POST URL:/16496,4f3ade2d2f7065 with httpStatus:500 and JSON:{""error"":""replicating operations [1] is less than volume 16496 replication copy count [2] I0511 13:40:29.588357 volume.go:304 graceful stop cluster http server  I0511 13:40:29.588947 volume.go:309 graceful stop gRPC  I0511 13:40:29.589452 volume_server.go:149 Shutting down volume server I0511 13:40:29.695784 volume_server.go:151 Shut down successfully!  Point to take a look is assignment of new volume (id=16498) on this Volume Server after its termination. And piece of log from Master:  I0511 13:40:18.304201 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 public_url:""seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444"" has_no_volumes:true I0511 13:40:18.446855 cluster_commands.go:32 max volume id 16497 ==> 16498 I0511 13:40:18.464245 volume_growth.go:244 Created Volume 16498 on topo:DefaultDataCenter:DefaultRack:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.464308 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 new_volumes:{id:16498 collection:""test"" replica_placement:1 version:3} I0511 13:40:18.464338 volume_layout.go:223 volume 16498 does not have enough copies I0511 13:40:18.464344 volume_layout.go:228 volume 16498 remove from writable I0511 13:40:18.464453 masterclient.go:277 .master: seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:18.464460 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter:DefaultDataCenter GrpcPort:0} W0511 13:40:18.469625 master_grpc_server.go:100 SendHeartbeat.Recv server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 : rpc error: code = Canceled desc = context canceled I0511 13:40:18.469648 node.go:237 topo:DefaultDataCenter:DefaultRack removes seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.469655 master_grpc_server.go:87 unregister disconnected volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.469659 master_grpc_server.go:58 remove volume server seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444, online volume server: map[seaweedfs-test-volume-0.seaweedfs-test-volume-peer.seaweedfs-test:8444:[b81f6a9c-e4c1-4702-88d5-51974f4ca3d6] seaweedfs-test-volume-1.seaweedfs-test-volume-peer.seaweedfs-test:8444:[58a7e74e-84e2-48df-b52b-dc9555afb548] seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444:[ff43c257-c736-4b6b-a930-db16c409c12b]] I0511 13:40:18.527309 masterclient.go:292 updateVidMap(DefaultDataCenter) .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 volume add: 0, del: 8263, add ec: 0 del ec: 0 I0511 13:40:19.771416 master_grpc_server.go:162 master received heartbeat ip:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test"" port:8444 public_url:""seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444"" max_file_key:5192448 volumes:{id:10324 size:1128282400 <omitted> I0511 13:40:19.916729 volume_growth.go:244 Created Volume 16498 on seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.916752 volume_layout.go:223 volume 16498 does not have enough copies I0511 13:40:19.916756 volume_layout.go:228 volume 16498 remove from writable I0511 13:40:19.916761 volume_growth.go:257 Registered Volume 16498 on topo:DefaultDataCenter:DefaultRack:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.916771 volume_layout.go:393 Volume 16498 becomes writable I0511 13:40:19.916776 volume_growth.go:257 Registered Volume 16498 on seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:19.919012 cluster_commands.go:32 max volume id 16498 ==> 16499 I0511 13:40:19.957609 masterclient.go:277 .master: seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:19.957611 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-2.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter:DefaultDataCenter GrpcPort:0} I0511 13:40:19.957620 masterclient.go:277 .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 masterClient adds volume 16498 I0511 13:40:19.957622 vid_map.go:160 + volume id 16498: {Url:seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 PublicUrl:seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 DataCenter: GrpcPort:0} I0511 13:40:19.957626 masterclient.go:292 updateVidMap() .master: seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 volume add: 1, del: 0, add ec: 0 del ec: 0  There also were a lot of messages like these:  I0511 13:40:18.329755 topology.go:252 removing volume info: Id:2458, Size:1329612128, ReplicaPlacement:001, Collection:test, Version:3, FileCount:317, DeleteCount:0, DeletedByteCount:0, ReadOnly:false from seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444 I0511 13:40:18.431844 master_grpc_server.go:203 master see deleted volume 2458 from seaweedfs-test-volume-3.seaweedfs-test-volume-peer.seaweedfs-test:8444  But there is no such message for Volume 16498, so it is writeable from Master's perspective (but in fact it doesn't), and Filer gets assignments for write requests on this volume. **System Setup** We have SeaweedFS running on Kubernetes via SeaweedFS Operator. There are 3 Masters, 4 Volume Servers, 4 Filers (with Scylla as its backend) - List the command line to start ""weed master"", ""weed volume"", ""weed filer"", ""weed s3"", ""weed mount"": - Master:  weed -v 4 -logtostderr=true master -volumeSizeLimitMB=1024 -defaultReplication=001 -ip=$(POD_NAME).seaweedfs-test-master-peer.seaweedfs-test -peers=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -metricsPort=9999  - Volume Server:  weed -v 4 -logtostderr=true volume -port=8444 -max=0 -ip=$(POD_NAME).seaweedfs-test-volume-peer.seaweedfs-test -metricsPort=9999 -mserver=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -dir=/data0  - Filer:  weed -v 4 -logtostderr=true filer -port=8888 -ip=$(POD_NAME).seaweedfs-test-filer-peer.seaweedfs-test -master=seaweedfs-test-master-0.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-1.seaweedfs-test-master-peer.seaweedfs-test:9333,seaweedfs-test-master-2.seaweedfs-test-master-peer.seaweedfs-test:9333 -metricsPort=9999 -s3  - OS version: Fedora CoreOS 33.20210426.3.0 - output of `weed version`: `version 8000GB 3.43 673214574 linux amd64` - if using filer, show the content of `filer.toml`:  [leveldb2] enabled = false [etcd] enabled = false servers = ""seaweed-etcd.seaweedfs-test:2379"" timeout = ""3s"" [cassandra] enabled = true keyspace=""seaweedfs"" hosts=[ ""seaweed-scylla-client.seaweedfs-test:9042"", ] superLargeDirectories = [ ]  **Expected behavior** We expect unwritable (de facto) volumes will not be assigned for write requests.",data-file | source-file
1722,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1722,s3 gateway ListObjects does not support arbitrary prefix,"**Describe the bug** The S3 gateway of seaweedfs does not support listing objects with arbitrary prefix. **System Setup** - filer leveldb2 backend, seaweedfs master **Expected behavior** Calling `GET` on `http://seaweedfs_s3_gw/bucket/?prefix=arbitrary_prefix` should always return files whose path starts with `arbitrary_prefix`, no matter whether `arbitrary_prefix` is an actual directory or not. **Actual behavior** Calling `GET` on `http://seaweedfs_s3_gw/bucket/?prefix=arbitrary_prefix` returns every single object in the bucket regardless of their prefix if `arbitrary_prefix` is not a folder inside `bucket`. **Additional context** After a bit of digging around myself, it seems that this issue is actually two issues (both of which are about : 1. The `namePattern` parameter passed to `ListDirectoryEntries` in `weed/filer/filer_search.go` should contain a wildcard character `*` at the end of the prefix (i.e. `prefix*`, not `prefix`); this is what caused the list request to return every single file 2. ~~(After making the change above) the `ListDirectoryPrefixedEntries` (at least in the leveldb2 backend) does not seem to work properly (I cannot figure out why yet because I don't really understand the filer store design). In my case, it simply does not return any entry if the prefix should match more than one files. I think it is related to the latest commit that implements hash-prefix-based searching in leveldb / leveldb2.~~ I think https://github.com/chrislusf/seaweedfs/blob/master/weed/filer/leveldb2/leveldb2_store.go#L188 needs to be `continue` instead of `break` Some programs expect ListObjects to be able to list files with arbitrary prefix (such as `s3ql`) and will error if this does not work. Most other S3 implementations, including the official S3 service, support this correctly.",source-file
1160,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1160,Deleting a non-existing file returns a 500 internal server error,"I'm testing a seaweedfs setup with a cassandra filer. When I try to delete a non-existing resource, the filer API returns a 500 error code. I would expect a 404.",source-file
2417,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2417,S3 using IAM action Write does not work properly,"**Describe the bug** I have followed the documentation to enable S3 IAM identities but it seems that the Write action for an identity does not allow to actually create files using S3. **System Setup** - Running seaweedfs from Docker, config below  docker_container: name: seaweedfs image: chrislusf/seaweedfs state: started restart_policy: unless-stopped pull: true user: nobody:20000 command: server -dir=""/data"" -volume.max=0 -master.volumePreallocate=false -master.volumeSizeLimitMB=1024 -s3 -s3.config=/etc/seaweedfs-s3-config.json comparisons: image: strict ports: - ""127.0.0.1:28080:8080"" - ""127.0.0.1:18080:18080"" - ""127.0.0.1:8333:8333"" volumes: - ""/etc/seaweedfs-s3-config.json:/etc/seaweedfs-s3-config.json:ro"" - ""/var/lib/seaweedfs-data:/data""  - `version 30GB 2.76 1b90d607 linux amd64` - Using `rclone` for file operations **Expected behavior** I would expect that the `Write` permission allow to create a file in a bucket, otherwise I have to grant `Admin` which is not very granular. **IAM config**:  { ""identities"": [ { ""name"": ""admin"", ""credentials"": [ { ""accessKey"": ""admin_access"", ""secretKey"": ""admin_secret"" } ], ""actions"": [ ""Admin"", ""Read"", ""List"", ""Tagging"", ""Write"" ] }, { ""name"": ""rclone"", ""credentials"": [ { ""accessKey"": ""rclone_access"", ""secretKey"": ""rclone_secret"" } ], ""actions"": [ ""Read"", ""Write"", ""List"" ] } ] }  **rclone config**:  [weed] type = s3 provider = Other access_key_id = rclone_access secret_access_key = rclone_secret endpoint = http://127.0.0.1:8333 acl = private [weedAdmin] type = s3 provider = Other access_key_id = admin_access secret_access_key = admin_secret endpoint = http://127.0.0.1:8333 acl = private  **Using rclone with low-priv user**:  #Bucket listing works # rclone lsd weed: -1 2021-11-02 15:11:23 -1 photos_staging_dir #File listing works # rclone ls weed:photos_staging_dir #Creating a file fails # rclone touch weed:photos_staging_dir/fstab 2021/11/02 16:06:26 ERROR : Attempt 1/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186380983481, host id: 2021/11/02 16:06:26 ERROR : Attempt 2/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186384910685, host id: 2021/11/02 16:06:26 ERROR : Attempt 3/3 failed with 1 errors and: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186388820806, host id: 2021/11/02 16:06:26 Failed to touch: failed to touch (create): AccessDenied: Access Denied. status code: 403, request id: 1635869186388820806, host id:  Creating empty file with admin identity:  rclone touch weedAdmin:photos_staging_dir/fstab  Created file can now be written/deleted by low-priv identity:  # rclone copy /etc/fstab weed:photos_staging_dir/ # rclone ls weed:photos_staging_dir/ 881 fstab #rclone delete weed:photos_staging_dir/fstab",source-file
93,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/93,"Lots of ""volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01"" errors in our production server log files","Here is the  Deploy structure  10.252.130.159:9333(master) 10.252.130.159:5088(haproxy) / \ 10.252.133.22:5083 (volume1) 10.252.135.207:5084(volume2) Replication Stratage: 001  So, it always gets the content via haproxy from the volume server. But after running few days, we get a 404 error sometimes from the 10.252.130.159:5088 for a special fid such as :5,1001e1b02c1b01. And we did a check and found that one of volume server(different fid on the random different server) always output the following logs:  I0303 15:44:23 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:45:14 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:52:52 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:52:52 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:05 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:06 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:07 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:07 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01 I0303 15:53:18 21828 volume_server_handlers.go:75] read error: <nil> /5,1001e1b02c1b01  It means that the file for [fid:5,1001e1b02c1b01] has be damaged? And how to fix this? How could be happened? any suggestions?",documentation-file | source-file
2648,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2648,[store] failed to write to local disk: invalid argument,"**Describe the bug** logs  upload_content.go:109] uploading to http://fast-volume-6.s3-fast-volume.service.dcdp.consul:8080/825,01366342ecebf5fc: unmarshalled error http://fast-volume-6.s3-fast-volume.service.dcdp.consul:8080/825,01366342ecebf5fc: failed to write to local disk: invalid argument | fast-api-658d59f67b-vd9ct store_replicate.go:48] failed to write to local disk: invalid argument | fast-volume-6 common.go:69] response method:POST URL:/825,01366342ecebf5fc with httpStatus:500 and JSON:{""name"":""0006.part"",""size"":5242880,""error"":""failed to write to local disk: invalid argument"",""eTag"":""971972b3""} | fast-volume-6  **System Setup**  2.88",source-file
5864,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5864,"[webdav] When the webdav service stops, a 404 is returned for an existing file","**Describe the bug** When the webdav service stops, a 404 is returned for an existing file **System Setup** `3.71` **Expected behavior** Returning always 200 or return nothing **Additional context**  1. make server with -webdav option 2. while true; do curl -sI ""http://127.0.0.1:7333/buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd"" | grep HTTP; done 3. Crtl+C stop server 4. Got HTTP/1.1 200 OK HTTP/1.1 404 Not Found  logs:  I0806 14:38:20.436016 filer_grpc_server.go:31 LookupDirectoryEntry /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd: get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed, I0806 14:38:20.436090 filer_pb_helper.go:139 read /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd: rpc error: code = Unknown desc = get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed I0806 14:38:20.436096 filer_client.go:42 read /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd <nil>: LookupEntry1: rpc error: code = Unknown desc = get /buckets/warp-benchmark-bucket/xyla1SAS/99.dIWkjopAvnLG(3VR.rnd : leveldb: closed",source-file
1036,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1036,Update existing file fails - Even possible?,"**Describe the bug** I want to perform updates to existing files by uploading the data to the already existing fid. The first upload works, but then all following updates will fail with an HTTP error: **System Setup** Running version 1.4.2 on Linux64 ./weed master -mdir=""master01"" -defaultReplication=002 ./weed volume -port=8081 -mserver=""localhost:9333"" -dir=""volume01"" -max=100 ./weed volume -port=8082 -mserver=""localhost:9333"" -dir=""volume02"" -max=100 ./weed volume -port=8083 -mserver=""localhost:9333"" -dir=""volume03"" -max=100 **Expected behavior** I would expect that the file upload works like the first with this file. But maybe I'm wrong and the update of an existing file is not possible. An other way would be to assign a new file id for every update and to delete the old. **Sequence** _Client:_ curl -F file=myFile http://127.0.0.1:8083/3,02b3f5780c Response: `{""size"":8,""error"":""failed to write to replicas for volume 3: [127.0.0.1:8081]: unexpected end of JSON input\n[127.0.0.1:8082]: unexpected end of JSON input"",""eTag"":""0ca153a6""}` _Master:_ No related console output _volume01:_ `I0809 23:03:11 11674 common.go:73] error writing JSON {Name: Size:8 Error: ETag:0ca153a6} status 304: http: req` _volume02:_ `I0809 23:03:11 11704 common.go:73] error writing JSON {Name: Size:8 Error: ETag:0ca153a6} status 304: http: request method or response status code does not allow body` _volume03:_  I0809 23:03:11 11688 upload_content.go:136] failing to read upload response http://127.0.0.1:8081/3,02b3f5780c?ts=1565384591&ttl=&type=replicate I0809 23:03:11 11688 upload_content.go:136] failing to read upload response http://127.0.0.1:8082/3,02b3f5780c?ts=1565384591&ttl=&type=replicate  Thank you!",source-file
6497,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6497,Using PUT object with bucket of invalid name leads to unremovable bucket,"root@Hepatitis:~# s3cmd put ab s3://aa/a upload: 'ab' -> 's3://aa/a' [1 of 1] 0 of 0 0% in 0s 0.00 B/s done WARNING: Upload failed: /a (500 (InternalError): We encountered an internal error, please try again.) WARNING: Waiting 3 sec upload: 'ab' -> 's3://aa/a' [1 of 1] 0 of 0 0% in 0s 0.00 B/s done WARNING: Upload failed: /a (500 (InternalError): We encountered an internal error, please try again.) WARNING: Waiting 6 sec ^CSee ya! root@Hepatitis:~# s3cmd put ab s3://aa  The created aa bucket can then not be removed even via ``weed shell`` due to the invalid bucket name of ``aa``",test-file | source-file
2434,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2434,[s3] HeadBucketHandler forbidden if is not super Admin or Owner,"**Describe the bug** HeadBucketHandler forbidden if is not super Admin  I1110 17:30:03 1 auth_credentials.go:225] user name: bennu actions: [Admin:bennu-*], action: Admin I1110 17:30:03 1 s3api_bucket_handlers.go:171] HeadBucketHandler bennu-client-files I1110 17:30:03 1 error_handler.go:79] status 403 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> <Error><Code>AccessDenied</Code><Message>Access Denied.</Message><Resource>/</Resource><RequestId>1636565403160014337</RequestId><BucketName>bennu-client-files</BucketName></Error>   aws --profile bennu --endpoint-url http://localhost:8333 s3api head-bucket --bucket bennu-client-files --debug  I don't quite understand what is being cheked here https://github.com/chrislusf/seaweedfs/blob/35c37562bc34393853de1c54ed06740bdffdf919/weed/s3api/s3api_bucket_handlers.go#L195  > fs.meta.cat /buckets/bennu-client-files { ""name"": ""bennu-client-files"", ""isDirectory"": true, ""chunks"": [ ], ""attributes"": { ""fileSize"": ""0"", ""mtime"": ""1633508622"", ""fileMode"": 2147484159, ""uid"": 0, ""gid"": 0, ""crtime"": ""1633508622"", ""mime"": """", ""replication"": """", ""collection"": """", ""ttlSec"": 0, ""userName"": """", ""groupName"": [ ], ""symlinkTarget"": """", ""md5"": null, ""diskType"": """" }, ""extended"": { ""s3-identity-id"": ""c2VydmljZS1saWJyYXJ5"" }, ""hardLinkId"": null, ""hardLinkCounter"": 0, ""content"": null, ""remoteEntry"": null }  **System Setup**  2.75",source-file
568,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/568,Multi master server setup failure,"Hi, Chirslusf. I have encountered a problem when setting up a multi master server cluster according the wiki. I have 3 vm:  vm1: 10.100.35.21 vm2: 10.100.35.20 vm3: 10.100.35.22  I start weed master server one by one in below order:  vm1: ./weed master -ip 10.100.35.21 -port=9333 -mdir=./master vm2: ./weed master -ip 10.100.35.20 -port=9333 -mdir=./master -peers=10.100.35.21:9333 vm3: ./weed master -ip 10.100.35.22 -port=9333 -mdir=./master -peers=10.100.35.20:9333  And then we can see the log output of each start:  vm1: # ./weed master -ip 10.100.35.21 -port=9333 -mdir=./master I0927 15:13:02 14610 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:02 14610 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:02 14610 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:02 14610 raft_server.go:56] Peers Change: [10.100.35.21:9333] => [] I0927 15:13:02 14610 raft_server.go:98] Initializing new cluster I0927 15:13:02 14610 master_server.go:95] [ 10.100.35.21:9333 ] I am the leader! I0927 15:13:12 14610 raft_server_handlers.go:16] Processing incoming join. Current Leader 10.100.35.21:9333 Self 10.100.35.21:9333 Peers map[] I0927 15:13:12 14610 raft_server_handlers.go:20] Command:{""name"":""10.100.35.20:9333"",""connectionString"":""http://10.100.35.20:9333""} I0927 15:13:12 14610 raft_server_handlers.go:27] join command from Name 10.100.35.20:9333 Connection http://10.100.35.20:9333 vm2: # ./weed master -ip 10.100.35.20 -port=9333 -mdir=./master -peers=10.100.35.21:9333 I0927 15:13:11 3117 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:11 3117 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:11 3117 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:11 3117 raft_server.go:56] Peers Change: [10.100.35.20:9333] => [10.100.35.21:9333] I0927 15:13:11 3117 raft_server.go:78] Joining cluster: 10.100.35.21:9333 I0927 15:13:12 3117 raft_server.go:166] Attempting to connect to: http://10.100.35.21:9333/cluster/join I0927 15:13:12 3117 raft_server.go:211] Post returned status: 200 I0927 15:13:52 3117 raft_server_handlers.go:16] Processing incoming join. Current Leader 10.100.35.21:9333 Self 10.100.35.20:9333 Peers map[10.100.35.21:9333:0xc42021fa40] I0927 15:13:52 3117 raft_server_handlers.go:20] Command:{""name"":""10.100.35.22:9333"",""connectionString"":""http://10.100.35.22:9333""} I0927 15:13:52 3117 raft_server_handlers.go:27] join command from Name 10.100.35.22:9333 Connection http://10.100.35.22:9333 I0927 15:13:52 3117 raft_server_handlers.go:47] Redirecting to 301 http://10.100.35.21:9333/cluster/join vm3: # ./weed master -ip 10.100.35.22 -port=9333 -mdir=./master -peers=10.100.35.20:9333 I0927 15:13:51 2964 file_util.go:20] Folder ./master Permission: -rwxr-xr-x I0927 15:13:51 2964 master_server.go:62] Volume Size Limit is 30000 MB I0927 15:13:51 2964 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333 I0927 15:13:51 2964 raft_server.go:56] Peers Change: [] => [10.100.35.20:9333] I0927 15:13:51 2964 raft_server.go:78] Joining cluster: 10.100.35.20:9333 I0927 15:13:52 2964 raft_server.go:166] Attempting to connect to: http://10.100.35.20:9333/cluster/join I0927 15:13:52 2964 raft_server.go:211] Post returned status: 404 404 page not found I0927 15:13:52 2964 raft_server.go:171] Post returned error: 404 page not found I0927 15:13:52 2964 raft_server.go:82] No existing server found. Starting as leader in the new cluster. I0927 15:13:52 2964 master_server.go:95] [ 10.100.35.22:9333 ] I am the leader!  It seems that the weed master on vm3 did not handle the 301 redirect to connect to the master(current leader) on vm1. Is this a bug? looking forward to your reply. 3ks.",source-file
1239,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1239,filler does not pass query params to volume server,Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** requests to filer like http://172.18.0.18:8888/test/1.jpg?width=200 didnt resize image it looks like something was broken in version 1.59 (1.58 works as expected) **System Setup** version 30GB 1.64 linux amd64,source-file
4270,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4270,filer api should return client error (4XX) code instead 500 if dir already exists,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** Right now if `dir` (filer.path) exists and `/POST` request is sent to that dir, filer returns `500 internal server error` with message `{""error"":""dir /foo already exists""}`. Ideally here filer should return Client Error (4XX) code like `409` instead of `500`. **System Setup** Setup contains empty storage with default settings started using below commands  weed master -mdir=""."" -ip=localhost weed volume -max=100 -mserver=""localhost:9333"" -dir=""./data"" weed filer -ip=localhost -port=8888 -master=localhost:9333  Weed version is `version 30GB 3.33 ee7bf69c0396098bce2d030f24dba5085c392b7c linux amd64`. Below are steps to reproduce  curl -vvv -X POST ""http://localhost:8888/foo/"" * Trying 127.0.0.1:8888 * Connected to localhost (127.0.0.1) port 8888 (#0) > POST /foo/ HTTP/1.1 > Host: localhost:8888 > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 201 Created < Content-Type: application/json < Server: SeaweedFS Filer 30GB 3.33 < Date: Sun, 05 Mar 2023 07:25:46 GMT < Content-Length: 14 < * Connection #0 to host localhost left intact {""name"":""foo""} % curl -vvv -X POST ""http://localhost:8888/foo/"" * Trying 127.0.0.1:8888 * Connected to localhost (127.0.0.1) port 8888 (#0) > POST /foo/ HTTP/1.1 > Host: localhost:8888 > User-Agent: curl/7.81.0 > Accept: */* > * Mark bundle as not supporting multiuse < HTTP/1.1 500 Internal Server Error < Content-Type: application/json < Server: SeaweedFS Filer 30GB 3.33 < Date: Sun, 05 Mar 2023 07:27:18 GMT < Content-Length: 35 < * Connection #0 to host localhost left intact {""error"":""dir /foo already exists""}%  **Expected behavior** filer should return Client Error (4XX) code like `409` instead of `500`",source-file
1999,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1999,[export] huge error output for non-existent volumeId,"**Screenshots** <img width=""1442"" alt=""Screenshot 2021-04-14 at 18 22 40"" src=""https://user-images.githubusercontent.com/9688322/114702666-8f2c7f00-9d4e-11eb-94e0-dccba0df3605.png"">",source-file
37,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/37,redirectOnRead goes to localhost,"I've got it running as a server: ./weed server -filer.redirectOnRead -filer Here's the curl. Note the hostname in the Location header: bash-3.2$ curl -vI http://weed1:8888/path/to/sources/README.md > /dev/null > HEAD /path/to/sources/README.md HTTP/1.1 > User-Agent: curl/7.30.0 > Host: weed1:8888 > Accept: _/_ > > < HTTP/1.1 302 Found > < Location: http://localhost:8080/5,01afbd8c36 > < Date: Sat, 20 Dec 2014 17:15:34 GMT > < Content-Type: text/plain; charset=utf-8 > < > 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 > - Connection #0 to host weed1 left intact > bash-3.2$",documentation-file | config-file | test-file | data-file | source-file
6379,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6379,S3 DeleteMultipleObjectsHandler does not honour AllowEmptyFolder setting,"Sponsors SeaweedFS via Patreon https://www.patreon.com/seaweedfs **Describe the bug** When running the S3 DeleteMultipleObjectsHandler function, the setting ""AllowEmptyFolder"" is not honoured. In circumstances where the filer folders are mistakenly identified as being empty, this causes the entire bucket contents to be deleted. **System Setup** - We setup an integrated Filer + S3 handler, using ""leveldb2"" driver - Photon Linux 5 - Weed version 3.79 **Expected behavior** When AllowEmptyFolder setting is set to true, only the items specified in the DeleteMultipleObjectsHandler call should have been deleted. **Additional context** The environment on which this runs is suspected to have very slow disk access, which we believe to be the cause for the folders being identified as empty.",source-file
4934,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4934,volume.configure.replication seems to not work,"**Describe the bug** When using volume.configure.replication, the actual volume files still retain their old configuration. **Test case** Start a weed master (defaultReplication=020) and 3 volume servers:  weed master -defaultReplication=020 weed volume -port=8081 -dir=/tmp/volume1 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack1 weed volume -port=8082 -dir=/tmp/volume2 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack2 weed volume -port=8083 -dir=/tmp/volume3 -max=100 -mserver=""127.0.0.1:9333"" -dataCenter=dc1 -rack=rack3  Create some volumes:  curl http://localhost:9333/dir/assign  It should look like this: ![Screenshot from 2023-10-23 16-49-42](https://github.com/seaweedfs/seaweedfs/assets/7746192/e9eea85c-6f77-4d12-9b48-740d0cd94c59) Now, let's change the replication settings using weed shell:  weed shell volume.configure.replication -collectionPattern * -replication 010  The volume servers correctly show the change in the logs:  I1023 14:52:01.272205 disk_location.go:182 data file /tmp/volume2/1.dat, replication=010 v=3 size=8 ttl=  The API also thinks, it is changed:  $ curl http://localhost:9333/vol/status?pretty=y|grep ""ReplicaPlacement"" -A 2 ""ReplicaPlacement"": { ""rack"": 1 },  But when we look at the .dat files using `change_superblock.go`, we see that it is still 020:  $ go run change_superblock.go -volumeId=1 -dir=/tmp/volume1 Current Volume Replication: 020 Current Volume TTL:  Just to make sure, we run some tests. First, we fix the replication:  $ weed shell lock volume.fix.replication > volume 2 replication 010, but over replicated +3 > volume 3 replication 010, but over replicated +3 > volume 1 replication 010, but over replicated +3 > deleting volume 2 from 10.23.1.43:8083  > deleting volume 3 from 10.23.1.43:8083  > deleting volume 1 from 10.23.1.43:8083   Looks good. We now have 2 copies of every volume file: ![Screenshot from 2023-10-23 16-58-31](https://github.com/seaweedfs/seaweedfs/assets/7746192/58ec1a28-2cde-4d3d-a590-127338fcd9ca) If we delete one and fix replication again, it should add it back.  weed shell lock volume.delete -node 10.23.1.43:8081 -volumeId 1 volume.fix.replication > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > the number of locations for volume 1 has not increased yet, let's wait > error: replicas volume 1 mismatch in topology  It did restore the missing copy but showed the error `error: replicas volume 1 mismatch in topology`. The volume server log shows that it added the volume with replication 020:  I1023 15:03:29.264620 disk_location.go:182 data file /tmp/volume3/1.dat, replication=020 v=3 size=8 ttl=  If we query the API, it now also shows replication 020 for the restored copy:  curl http://localhost:9333/vol/status?pretty=y|grep ""ReplicaPlacement"" -A 2 ""ReplicaPlacement"": { ""rack"": 1 }, ""ReplicaPlacement"": { ""rack"": 2 },  **System Setup** - Ubuntu 22.04 - output of `weed version`: version 30GB 3.57 0f8168c0c928bba3d2f48b0680d3bdce9c617559 linux amd64 **Expected behavior** `volume.configure.replication` changes the replication setting in the volume files.",source-file
409,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/409,seaweedfs should support 0-size file uploading and downloading,"Now, 0-size text file can be uploaded and download successfully. But, 0-size jpg file(or other not isGzippable()) can not be uploaded, report `{""name"":""empty.doc"",""error"":""Failed to write to local disk""}`. I suggest seaweedfs should support 0-size all format file unploading and downloading, or return `400 bad request` when being uploaded. 0-size text file uploaded successfully:  # curl -F file=@empty.txt 192.168.4.18:28083/45,6c8916e496119e -v * Hostname was NOT found in DNS cache * Trying 192.168.4.18 * Connected to 192.168.4.18 (192.168.4.18) port 28083 (#0) > POST /45,6c8916e496119e HTTP/1.1 > User-Agent: curl/7.35.0 > Host: 192.168.4.18:28083 > Accept: */* > Content-Length: 187 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=bcba47b57757d366 > < HTTP/1.1 100 Continue < HTTP/1.1 201 Created < Content-Type: application/json < Date: Tue, 06 Dec 2016 07:34:49 GMT < Content-Length: 30 < * Connection #0 to host 192.168.4.18 left intact {""name"":""empty.txt"",""size"":23}  0-size doc file uploaded unsuccessfully:  # curl -F file=@empty.doc 192.168.4.18:28083/45,6c8916e496119e -v * Hostname was NOT found in DNS cache * Trying 192.168.4.18 * Connected to 192.168.4.18 (192.168.4.18) port 28083 (#0) > POST /45,6c8916e496119e HTTP/1.1 > User-Agent: curl/7.35.0 > Host: 192.168.4.18:28083 > Accept: */* > Content-Length: 201 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=8228c550c48374e5 > < HTTP/1.1 100 Continue < HTTP/1.1 500 Internal Server Error < Content-Type: application/json < Date: Tue, 06 Dec 2016 07:30:34 GMT < Content-Length: 60 * HTTP error before end of send, stop sending < * Closing connection 0 {""name"":""empty.doc"",""error"":""Failed to write to local disk""}",source-file
524,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/524,hanged when run weed master,"tmp git:(master)  weed master -peers 10.64.7.106:9444,10.4.23.114:9444,10.4.23.115:9444 -ip 10.64.7.106 -ip.bind 10.64.7.106 -port 9444 I0703 19:46:40 39010 file_util.go:20] Folder /tmp Permission: -rwxrwxrwx I0703 19:46:40 39010 master_server.go:62] Volume Size Limit is 30000 MB I0703 19:46:40 39010 master.go:87] Start Seaweed Master 0.76 at 10.64.7.106:9444 I0703 19:46:40 39010 raft_server.go:56] Peers Change: [] => [10.64.7.106:9444 10.4.23.114:9444 10.4.23.115:9444] I0703 19:46:40 39010 raft_server.go:78] Joining cluster: 10.64.7.106:9444,10.4.23.114:9444,10.4.23.115:9444 I0703 19:46:41 39010 raft_server.go:166] Attempting to connect to: http://10.4.23.114:9444/cluster/join  using browser open this url , crashed.  2017/07/03 19:47:13 http: panic serving 10.232.4.175:59240: runtime error: invalid memory address or nil pointer dereference goroutine 55 [running]: net/http.(*conn).serve.func1(0xc4202d6140) /home/jinlei1/os/go/src/net/http/server.go:1721 +0xd0 panic(0xbab320, 0x10782f0) /home/jinlei1/os/go/src/runtime/panic.go:489 +0x2cf github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).uiStatusHandler(0xc4201e2380, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/chrislusf/seaweedfs/weed/server/master_server_handlers_ui.go:24 +0x13b github.com/chrislusf/seaweedfs/weed/server.(*MasterServer).(github.com/chrislusf/seaweedfs/weed/server.uiStatusHandler)-fm(0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/chrislusf/seaweedfs/weed/server/master_server.go:66 +0x48 net/http.HandlerFunc.ServeHTTP(0xc4201c7010, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/os/go/src/net/http/server.go:1942 +0x44 github.com/gorilla/mux.(*Router).ServeHTTP(0xc4201ce960, 0x1047400, 0xc42030a000, 0xc4202de500) /home/jinlei1/ksyun/src/github.com/gorilla/mux/mux.go:114 +0x10c net/http.serverHandler.ServeHTTP(0xc4202049a0, 0x1047400, 0xc42030a000, 0xc4202de300) /home/jinlei1/os/go/src/net/http/server.go:2568 +0x92 net/http.(*conn).serve(0xc4202d6140, 0x1047f00, 0xc4202b0340) /home/jinlei1/os/go/src/net/http/server.go:1825 +0x612 created by net/http.(*Server).Serve /home/jinlei1/os/go/src/net/http/server.go:2668 +0x2ce",source-file
16,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/16,content type from volume post upload always text/plain?,"I'm assuming the return content-type should be application/json?  $ curl -v -F ""file=@/tmp/test.json;type=application/json"" localhost:8080/7,07a27ee211 > POST /7,07a27ee211 HTTP/1.1 > User-Agent: curl/7.30.0 > Host: localhost:8080 > Accept: */* > Content-Length: 223 > Expect: 100-continue > Content-Type: multipart/form-data; boundary=2f1cf300fd2b > < HTTP/1.1 100 Continue < HTTP/1.1 201 Created < Date: Mon, 29 Sep 2014 20:08:45 GMT < Content-Length: 30 < Content-Type: text/plain; charset=utf-8 < * Connection #0 to host localhost left intact {""name"":""test.json"",""size"":74}",documentation-file | config-file | test-file | data-file | source-file
1884,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1884,S3 upload failed for filenames including '%' character,"**Describe the bug** S3 filer API can't handle files with '%' sign despite it being the valid name (and valid object for s3 and minio, I found plenty of those inside Photo library on Mac):  touch %%test.file.txt touch %%test.file.txt aws --endpoint-url http://rpi4node3:8333/ s3 cp %test.file.txt s3://testbucket/ upload failed: ./%test.file.txt to s3://testbucket/%test.file.txt An error occurred (InternalError) when calling the PutObject operation (reached max retries: 2): We encountered an internal error, please try again.  Upload via weed upload works:  > weed upload -master=""rpi4node3:9333"" %%test.file.txt [{""fileName"":""%%test.file.txt"",""url"":""rpi4node3:8088/13,022beaf4f28a09"",""fid"":""13,022beaf4f28a09""}] > weed upload -master=""rpi4node3:9333"" %test.file.txt [{""fileName"":""%test.file.txt"",""url"":""rpi4node3:8088/6,022beb5bdfd3a2"",""fid"":""6,022beb5bdfd3a2""}]  **System Setup** Master started with:  ~/go/bin/weed server -filer -s3 -ip=rpi4node3 -volume.max=0,0 -master.volumeSizeLimitMB=1024 -volume.port=8088 -dir=/mnt/usbslow/weed,/mnt/usbfast/weed/ -master.dir=/mnt/usbfast/weed/master  Filer config:  [redis_cluster2] enabled = true addresses = [ ""rpi4node1:6379"", ""rpi4node2:6379"", ""rpi4node3:6379"" ] password = """" # allows reads from slave servers or the master, but all writes still go to the master readOnly = false # automatically use the closest Redis server for reads routeByLatency = false # This changes the data layout. Only add new directories. Removing/Updating will cause data loss. superLargeDirectories = []  Volumes:  /usr/local/bin/weed volume -mserver=""rpi4node3:9333"" -max=1000,1000 -port=8088 -disk=hdd,ssd -dir=/mnt/usbslow/weed,/mnt/usbfast/weed/ &  Master weed version:  ~/go/bin/weed version version 30GB 2.29 400de380 linux arm64  Complied from:  commit 400de380f48c44c7700fdf7e8f247bf856662c10 (HEAD -> master, origin/master, origin/HEAD) Author: Chris Lu <chris.lu@gmail.com> Date: Fri Mar 5 02:29:38 2021 -0800 volume server: support tcp direct put/get/delete  **Expected behavior** Successful upload of files via S3. **Additional context** You guessed seaweed fs runs on RPI4 cluster. I found it's a really amazing project and very easy to setup.",source-file
5774,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/5774,remote sync unexpected behavior,"Not mounted directory has same prefix as mounted directory pushed to remote storage when running filer.remote.sync. for example, there is two dir, /foo and /foo-bar, only /foo mounted to remote storage remote:/foo, when running: `weed filer.remote.sync -dir=/foo` files in /foo-bar, for example /foo-bar/baz/qux was pushed to remote:/foo/-bar/baz/qux",test-file | source-file
2125,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2125,[filer] Error delete many files with SQL,"**Describe the bug** Error filer store delete Folder Children See https://fromdual.com/keep-your-galera-cluster-up-and-running-by-all-means  filer_1 | I0611 10:13:05 1 abstract_sql_store.go:282] delete /buckets/registry/docker/registry/v2/blobs/sha256 SQL DELETE FROM `filemeta` WHERE dirhash=? AND directory=? -4910119483806141165 filer_1 | I0611 10:13:05 1 filer_delete_entry.go:39] delete directory /buckets/registry: filer store delete: deleteFolderChildren /buckets/registry/docker/registry/v2/blobs/sha256: Error 1180: wsrep_max_ws_rows exceeded filer_1 | I0611 10:13:05 1 error_handler.go:79] status 500 application/xml: <?xml version=""1.0"" encoding=""UTF-8""?> filer_1 | <Error><Code>InternalError</Code><Message>We encountered an internal error, please try again.</Message><Resource>/registry</Resource><RequestId>1623406385367150308</RequestId><BucketName>registry</BucketName></Error>  **System Setup** master branch **Expected behavior** force small transactions when deleting Folder Children",source-file
1917,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1917,[s3] aws s3 copy dir/ fatal error: 'ContentLength',"**Describe the bug**  aws --profile local --endpoint http://127.0.0.1:8333/ s3 cp s3://test/dir /tmp/ fatal error: An error occurred (404) when calling the HeadObject operation: Key ""dir"" does not exist aws --profile local --endpoint http://127.0.0.1:8333/ s3 cp s3://test/dir/ /tmp/ fatal error: 'ContentLength'  **System Setup** `2.34` **Expected behavior** return 404",source-file
166,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/166,"when the former ttl(upload ttl, not assign ttl) expired, same file uploaded without ttl option, but it can't be downloaded","# curl -F file=@start_master.sh http://192.168.23.70:18080/xxxx?ttl=1m {""name"":""start_master.sh"",""size"":645} // after 1m # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 404 Not Found Date: Fri, 10 Jul 2015 15:17:47 GMT Content-Length: 0 # curl -F file=@start_master.sh http://192.168.23.70:18080/xxxx {""name"":""start_master.sh"",""size"":645} # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 404 Not Found Date: Fri, 10 Jul 2015 15:18:12 GMT Content-Length: 0  If I uploaded another file, it can be downloaded:  # curl -F file=@start_volume.sh http://192.168.23.70:18080/xxxx {""name"":""start_volume.sh"",""size"":411} # curl -i http://192.168.23.70:18080/xxxx HTTP/1.1 200 OK Accept-Ranges: bytes Content-Disposition: filename=""start_volume.sh"" Content-Length: 411 Content-Type: text/x-sh; charset=utf-8 Etag: ""63bdc9b5"" Last-Modified: Fri, 10 Jul 2015 15:19:28 GMT Date: Fri, 10 Jul 2015 15:19:31 GMT <>  I think if file unchanged but ttl changed, needle should be written to data file:  golang func (v *Volume) write(n *Needle) (size uint32, err error) { if v.isFileUnchanged(n) { size = n.DataSize glog.V(4).Infof(""needle is unchanged!"") return }",source-file
1436,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/1436,"Volume not found, but it actually exists.","Version: 1.91 There are times that filer return 500 when downloading file. And the error said ""volume 603 not found"". But it actually exists on volume server. Ant when I restart the filer. It will be correct. ![image](https://user-images.githubusercontent.com/11285030/91559504-ca6a7100-e96a-11ea-8ecf-384f7f7cd148.png) ![image](https://user-images.githubusercontent.com/11285030/91559548-dfdf9b00-e96a-11ea-9f41-b85dd81a1a71.png) I didn't open the verbose log on that case. I'm still checking stack trace. I will paste more information here next time it happened",data-file
2371,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2371,[s3] Content Disposition support,"**Describe the bug** ContentDisposition and ResponseContentDisposition parameters are ignored When using s3 api, ContentDisposition is always set to 'inline; filename=<key>' Example with boto3: Setting ContentDisposition during put: python3 s3.put_object(Bucket='test', Key='test.jpeg', Body='test.jpeg', ContentDisposition='attachment; filename=""test.jpeg') {'ResponseMetadata': {'RequestId': '1633946607781063224', 'HostId': '', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:03:27 GMT', 'content-length': '0', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'x-amz-request-id': '1633946607781063224', 'strict-transport-security': 'max-age=15724800; includeSubDomains', }, 'RetryAttempts': 0}, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""'} s3.get_object(Bucket='test', Key='test.jpeg') {'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:03:45 GMT', 'content-type': 'image/jpeg', 'content-length': '9', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'content-disposition': 'inline; filename=""test.jpeg""', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'last-modified': 'Mon, 11 Oct 2021 10:03:27 GMT', 'strict-transport-security': 'max-age=15724800; includeSubDomains', }, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2021, 10, 11, 10, 3, 27, tzinfo=tzutc()), 'ContentLength': 9, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'ContentDisposition': 'inline; filename=""test.jpeg""', 'ContentType': 'image/jpeg', 'Metadata': {}, 'Body': <botocore.response.StreamingBody at 0x1108820d0>}  Setting ResponseContentDisposition: python3 s3.get_object(Bucket='test', Key='test.jpeg', ResponseContentDisposition='attachment; filename=test.jpeg') {'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 11 Oct 2021 10:07:56 GMT', 'content-type': 'image/jpeg', 'content-length': '9', 'connection': 'keep-alive', 'accept-ranges': 'bytes', 'content-disposition': 'inline; filename=""test.jpeg""', 'etag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'last-modified': 'Mon, 11 Oct 2021 10:03:27 GMT', 'strict-transport-security': 'max-age=15724800; includeSubDomains' }, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2021, 10, 11, 10, 3, 27, tzinfo=tzutc()), 'ContentLength': 9, 'ETag': '""bb1469ad3d21a04760cf719a86f2e7be""', 'ContentDisposition': 'inline; filename=""test.jpeg""', 'ContentType': 'image/jpeg', 'Metadata': {}, 'Body': <botocore.response.StreamingBody at 0x110882340>}  **System Setup** seaweedfs 2.70 **Expected behavior** Setting ContentDisposition parameter during put should set the ContentDisposition in object metadata, setting ResponseContentDisposition during get should only set this in reposnse metadata",source-file
3467,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3467,"Filer if-modified-since check doesn't fire on ""exact""","**Describe the bug** Filer does not return HTTP 304 if the `if-modified-since` value is exact the same as the `Last-Modfied` header **System Setup** - `weed server -dataCenter=$HOSTNAME -ip=$HOSTNAME -master.dir=/meta -master.peers=""app1:9333,app2:9333,app3:9333"" -dir=/data -volume.dir.idx=/meta -volume.index=leveldbLarge -volume.max=0 -rack=1 -filer.encryptVolumeData -volume.fileSizeLimitMB=4096 -master.volumeSizeLimitMB=1024 -filer.defaultReplicaPlacement=100 -filer.saveToFilerLimit=4096 -filer""` - Ubuntu Server **Expected behavior** Filer should return 304: Not modified to save bandwidth **Screenshots** bash system@app2:~$ curl --head --http1.1 -H 'if-modified-since: Thu, 18 Aug 2022 15:40:16 GMT' 'http://localhost:8888/qr-code.svg' HTTP/1.1 304 Not Modified Last-Modified: Thu, 18 Aug 2022 15:40:15 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Fri, 19 Aug 2022 15:29:42 GMT system@app2:~$ curl --head --http1.1 -H 'if-modified-since: Thu, 18 Aug 2022 15:40:15 GMT' 'http://localhost:8888/qr-code.svg' HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Cache-Control: no-cache Content-Disposition: inline; filename=""qr-code.svg"" Content-Length: 209510 Content-Type: image/svg+xml Etag: ""8ab857fb2ea442f951af494a746b1abf"" Last-Modified: Thu, 18 Aug 2022 15:40:15 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Fri, 19 Aug 2022 15:29:50 GMT  **Additional context** Filer will say `HTTP/1.1 304 Not Modified` with a value later than it's own `Last-Modified` but this will most likely never be the same in the case of a browser. I was testing via filer web ui in chrome.",source-file
3476,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/3476,HTTP Filer truncates uploads which begin with /etc,"The built-in http server in `filer` cannot handle uploads where the root of the path begins with `/etc`. The file is always truncated to `4MB`. Tested using `Docker version 20.10.12-ce, build 459d0dfbbb51` on `openSUSE Leap 15.3`. There is a `Makefile` and attached server log at the end of this post. Uploading files with `curl`  dd if=/dev/urandom of=rands bs=1k count=100k curl -F file=@rands http://10.1.0.8:8889/petc33333/etc3 {""name"":""rands"",""size"":104857600} curl -F file=@rands http://10.1.0.8:8889/etc33333/etc3 {""name"":""rands"",""size"":4194304} curl -F file=@rands http://10.1.0.8:8889/petc932 {""name"":""rands"",""size"":104857600} curl -F file=@rands http://10.1.0.8:8889/etc932 {""name"":""rands"",""size"":4194304}  Running a `HEAD` request against each uploaded file.  curl -I http://10.1.0.8:8889/petc33333/etc3 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc3"" Content-Length: 104857600 Etag: ""3b3a28a324f125fb2423f4aa627c1e74"" Last-Modified: Sun, 21 Aug 2022 19:32:01 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/etc33333/etc3 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc3"" Content-Length: 4194304 Etag: ""1d65cef5475887ca24f320e9d7cb5d9f"" Last-Modified: Sun, 21 Aug 2022 19:32:02 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/petc932 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""petc932"" Content-Length: 104857600 Etag: ""3b3a28a324f125fb2423f4aa627c1e74"" Last-Modified: Sun, 21 Aug 2022 19:32:03 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT curl -I http://10.1.0.8:8889/etc932 HTTP/1.1 200 OK Accept-Ranges: bytes Access-Control-Expose-Headers: Content-Disposition Content-Disposition: inline; filename=""etc932"" Content-Length: 4194304 Etag: ""1d65cef5475887ca24f320e9d7cb5d9f"" Last-Modified: Sun, 21 Aug 2022 19:32:03 GMT Server: SeaweedFS Filer 30GB 3.22 Date: Sun, 21 Aug 2022 19:32:04 GMT  Makefile to replicate the behavior makefile .PHONY: example upload heads dev-filer HOST:=http://10.1.0.8:8889 dev-filer: docker run -it --rm --name $@ --entrypoint /usr/bin/weed \ -p 8889:8889 -p 6062:6062 \ chrislusf/seaweedfs:3.22 \ -v 2 server -volume.max=5000 -dir=""/data"" -master.volumeSizeLimitMB=2048 -master.electionTimeout 1s -master.port=9444 -volume.port=9445 \ -filer -ip.bind 0.0.0.0 -filer.port=8889 -debug -debug.port 6062 rands: dd if=/dev/urandom of=rands bs=1k count=100k example: upload heads upload: rands curl -F file=@rands ${HOST}/petc33333/etc3 @echo curl -F file=@rands ${HOST}/etc33333/etc3 @echo curl -F file=@rands ${HOST}/petc932 @echo curl -F file=@rands ${HOST}/etc932 @echo @echo heads: curl -I ${HOST}/petc33333/etc3 curl -I ${HOST}/etc33333/etc3 curl -I ${HOST}/petc932 curl -I ${HOST}/etc932  [log.txt](https://github.com/seaweedfs/seaweedfs/files/9389838/log.txt)",source-file
4088,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4088,It is not possible to request a file via master if the volume is in a read-only state,"I have one master server and one volume server, I have moved one of the volumes to the read-only state. The server has lost information about volumes that are in the read-only state. The file can be requested only from the volume server. Procedure of actions: 1) Uploading a file 2) I make the volume read-only  lock volume.marknode 172.16.202.6:8080 -volumeId 3 -readonly unlock  3) Trying to upload a file  wget 172.16.202.6:9333/3,013c6a774d --2022-12-27 11:52:18-- http://172.16.202.6:9333/3,013c6a774d Connecting to 172.16.202.6:9333 connected. HTTP request sent, awaiting response 404 Not Found 2022-12-27 11:52:18 ERROR 404: Not Found.  **System Setup** ./weed master -ip=172.16.202.6 ./weed -v=4 volume -index=leveldb -pprof=true -max=100 -mserver=""172.16.202.6:9333"" -port=8080 -dir=/storage - ubuntu 22/04 - The problem was found on version 3.37, 3.36, 3.28, the latest version on which it works is 3.26 - version 3.27 have problem with set read-only from shell  volume.mark -node 172.16.202.6:8080 -volumeId 3 -readonly error: rpc error: code = Unknown desc = grpc VolumeMarkReadonly with master: 172.16.202.6:9333%!(EXTRA *errors.errorString=set volume 3 to read only on master: rpc error: code = Unimplemented desc = method VolumeMarkReadonly not implemented)  **Expected behavior** I expect that the master will allow requesting files from volumes that have moved to the read-only state.",source-file
2387,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/2387,[s3] FAILED tests,"2.72    FAIL: s3tests_boto3.functional.test_s3.test_copy_object_ifnonematch_failed  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 13028, in test_copy_object_ifnonematch_failed eq(body, 'bar') AssertionError: 'bar\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00' != 'bar'    FAIL: s3tests_boto3.functional.test_s3.test_object_write_check_etag  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 2094, in test_object_write_check_etag eq(response['ETag'], '""37b51d194a7513e45b56f6524f2d51f2""') AssertionError: '""9997a36a88a451df9f4c4552f8e884fa""' != '""37b51d194a7513e45b56f6524f2d51f2""' >> raise AssertionError(None or ""%r != %r"" % ('""9997a36a88a451df9f4c4552f8e884fa""', '""37b51d194a7513e45b56f6524f2d51f2""'))    FAIL: s3tests_boto3.functional.test_s3.test_object_head_zero_bytes  Traceback (most recent call last): File ""/opt/s3-tests/virtualenv/lib/python3.8/site-packages/nose/case.py"", line 198, in runTest self.test(*self.arg) File ""/opt/s3-tests/s3tests_boto3/functional/test_s3.py"", line 2083, in test_object_head_zero_bytes eq(response['ContentLength'], 0) AssertionError: 512 != 0 >> raise AssertionError(None or ""%r != %r"" % (512, 0))",source-file
6262,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6262,Multipart upload without S3 authentication fails with the wrong message,"**Describe the bug** If S3 authentication is not setup, attempting to upload multipart will fail with the error message: Expected hash not equal to calculated hash While trying to make a minimal reproduction of this behavior to report the bug, I noticed that when using the amazon SDK `TransferUtility`, I get a different error message: Signed request requires setting up SeaweedFS S3 authentication This led me to find the otherwise completely opaque issue at hand. **System Setup** `podman run --name seaweed-12312 --rm -p 12312:12312 docker.io/chrislusf/seaweedfs server -s3 -s3.port 12312` To run seaweed. Then in C#: cs var s3Client = new AmazonS3Client( new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } ); var bucketName = ""my-test-bucket""; var keyName = ""dir/file.txt""; var fakeFileData = new StringBuilder(); fakeFileData.AppendLine(""a,b,c,d,e""); for (var i = 0; i < 10000; i++) { fakeFileData.AppendLine($""a{i},b{i},c{i},d{i},e{i}""); } var cancellationToken = CancellationToken.None; var initiateRequest = new InitiateMultipartUploadRequest { BucketName = bucketName, Key = keyName, }; var initiateResponse = await s3Client.InitiateMultipartUploadAsync(initiateRequest, cancellationToken); var partETags = new List<PartETag>(); using (var fakeFileStream = new MemoryStream(Encoding.UTF8.GetBytes(fakeFileData.ToString( { var uploadRequest = new UploadPartRequest { BucketName = bucketName, Key = keyName, UploadId = initiateResponse.UploadId, PartNumber = 1, PartSize = fakeFileStream.Length, InputStream = fakeFileStream }; var uploadResponse = await s3Client.UploadPartAsync(uploadRequest, cancellationToken); partETags.Add(new PartETag(uploadResponse.PartNumber, uploadResponse.ETag)); } var completeRequest = new CompleteMultipartUploadRequest { BucketName = bucketName, Key = keyName, UploadId = initiateResponse.UploadId, PartETags = partETags }; await s3Client.CompleteMultipartUploadAsync(completeRequest, cancellationToken);  The above fails with `Expected hash not equal to calculated hash`. However, running the code below: cs var s3Client = new AmazonS3Client( new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } ); var bucketName = ""my-test-bucket""; var keyName = ""dir/file.txt""; var fakeFileData = new StringBuilder(); fakeFileData.AppendLine(""a,b,c,d,e""); for (var i = 0; i < 10000; i++) { fakeFileData.AppendLine($""a{i},b{i},c{i},d{i},e{i}""); } var fileTransferUtility = new TransferUtility(s3Client); using (var fakeFileStream = new MemoryStream(Encoding.UTF8.GetBytes(fakeFileData.ToString( { var fileTransferUtilityRequest = new TransferUtilityUploadRequest { BucketName = bucketName, InputStream = fakeFileStream, PartSize = 6*1024*1024, // 6 MB. Key = keyName, // DisablePayloadSigning = true, }; await fileTransferUtility.UploadAsync(fileTransferUtilityRequest); }  This fails with the much more useful `Signed request requires setting up SeaweedFS S3 authentication`. It's important to note, that if I setup seaweed using: `podman run --name seaweed-12312 -v /home/$USER/s3_config.json:/app/:Z --rm -p 12312:12312 docker.io/chrislusf/seaweedfs server -s3 -s3.port 12312 -s3.config ""/app/s3_config.json""` While filling `~/s3_config.json` with:  { ""identities"": [ { ""name"": ""me"", ""credentials"": [ { ""accessKey"": ""seaweed"", ""secretKey"": ""seaweed"" } ], ""actions"": [ ""Read"", ""Write"", ""List"", ""Tagging"", ""Admin"" ] } ] }  And then setting up the client accordingly: cs var s3Client = new AmazonS3Client( new BasicAWSCredentials(""seaweed"", ""seaweed""), new AmazonS3Config { ServiceURL = ""http://localhost:12312"", ForcePathStyle = true, } );  Both examples work. **Expected behavior** I'd like for the simple case to fail with an informative error message, instead of giving a hash equality message which implies some usage bug. I'm glad I could find the issue eventually, but I could've saved a lot of time with the right error message!",source-file
6576,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/6576,Seaweed does not handle x-id,AWS SDK's emit an x-id query parameter which is not supported by seaweed leading to issues handling presigned requests,source-file
4305,seaweedfs,https://github.com/seaweedfs/seaweedfs/issues/4305,s3.bucket.list file count mismatch,"**Describe the bug** s3.bucket.list file count is not correct **System Setup** - weed server -s3 -ip.bind=0.0.0.0 -dir=/disk/data1/weed,/disk/data2/weed -master.defaultReplication=002 -master.peers=192.168.3.101:9333,192.168.3.102:9333,192.168.3.103:9333,192.168.3.104:9333,192.168.3.105:9333 - Ubuntu 22.04.1 LTS - version 30GB 3.43 3227e4175e2bf8df2ac8aeeff8cf73a819abc5a7 linux amd64 - content of `filer.toml`  [leveldb2] enabled = false dir = ""./filerldb2"" # directory to store level db files [tikv] enabled = true pdaddrs = ""pdhost1:2379, pdhost2:2379, pdhost3:2379""  **Expected behavior**  > fs.ls /buckets/kuro3 prometheus.yml redirect.html weed > s3.bucket.list kuro3 size:67565992 file:22  file count should be 3 **Screenshots** ![image](https://user-images.githubusercontent.com/12230174/224946805-9e45e296-35b9-4234-8015-61efb289116b.png) ![image](https://user-images.githubusercontent.com/12230174/224947463-8ca7b206-b065-4d5c-b62a-7adb847caa22.png) **Additional context** It seems that filer slices files into segments of 4MB, and `s3.bucket.list` counts each segment as a separate file.",source-file
